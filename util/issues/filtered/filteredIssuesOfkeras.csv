id,Title,Body,User,Label,Created At,Updated At
14128,Latest Keras version is not compatible with Python 2.7 anymore,"Latest Keras version requires tensorflow >= 2.2.0 but tensorflow 2.2.0 only has wheels for Python 3.5+. This means that trying to install keras in Python 2.7 or Python 3.4 leads to the following traceback:

```
DEPRECATION: Python 2.7 reached the end of its life on January 1st, 2020. Please upgrade your Python as Python 2.7 is no longer maintained. pip 21.0 will drop support for Python 2.7 in January 2021. More details about Python 2 support in pip, can be found at https://pip.pypa.io/en/latest/development/release-process/#python-2-support
Collecting keras
  Using cached Keras-2.4.0-py2.py3-none-any.whl (170 kB)
Collecting scipy>=0.14
  Using cached scipy-1.2.3-cp27-cp27mu-manylinux1_x86_64.whl (24.8 MB)
Processing /home/lothiraldan/.cache/pip/wheels/d1/d5/a0/3c27cdc8b0209c5fc1385afeee936cf8a71e13d885388b4be2/PyYAML-5.3.1-cp27-cp27mu-linux_x86_64.whl
Collecting numpy>=1.9.1
  Using cached numpy-1.16.6-cp27-cp27mu-manylinux1_x86_64.whl (17.0 MB)
ERROR: Could not find a version that satisfies the requirement tensorflow>=2.2.0 (from keras) (from versions: 0.12.0rc0, 0.12.0rc1, 0.12.0, 0.12.1, 1.0.0, 1.0.1, 1.1.0rc0, 1.1.0rc1, 1.1.0rc2, 1.1.0, 1.2.0rc0, 1.2.0rc1, 1.2.0rc2, 1.2.0, 1.2.1, 1.3.0rc0, 1.3.0rc1, 1.3.0rc2, 1.3.0, 1.4.0rc0, 1.4.0rc1, 1.4.0, 1.4.1, 1.5.0rc0, 1.5.0rc1, 1.5.0, 1.5.1, 1.6.0rc0, 1.6.0rc1, 1.6.0, 1.7.0rc0, 1.7.0rc1, 1.7.0, 1.7.1, 1.8.0rc0, 1.8.0rc1, 1.8.0, 1.9.0rc0, 1.9.0rc1, 1.9.0rc2, 1.9.0, 1.10.0rc0, 1.10.0rc1, 1.10.0, 1.10.1, 1.11.0rc0, 1.11.0rc1, 1.11.0rc2, 1.11.0, 1.12.0rc0, 1.12.0rc1, 1.12.0rc2, 1.12.0, 1.12.2, 1.12.3, 1.13.0rc0, 1.13.0rc1, 1.13.0rc2, 1.13.1, 1.13.2, 1.14.0rc0, 1.14.0rc1, 1.14.0, 1.15.0rc0, 1.15.0rc1, 1.15.0rc2, 1.15.0rc3, 1.15.0, 2.0.0a0, 2.0.0b0, 2.0.0b1, 2.0.0rc0, 2.0.0rc1, 2.0.0rc2, 2.0.0, 2.1.0rc0, 2.1.0rc1, 2.1.0rc2, 2.1.0)
ERROR: No matching distribution found for tensorflow>=2.2.0 (from keras)
```

If that was planned, I would suggest to update the setup.py file with the correct https://packaging.python.org/guides/distributing-packages-using-setuptools/#python-requires so pip can takes Keras 2.3.1 on incompatible Python versions.

I would also recommend yanking the release 2.4.0 as pip will try to get the 2.4.0 release if a 2.4.1 is released with the correct metadata.",Lothiraldan,b'backend:tensorflow type:bug/performance',2020-06-18T12:12:59Z,2020-06-24T13:18:11Z
14120,Twice as many bias elements in GRU layer weight file,"**System information**  
- Have I written custom code (as opposed to using example directory):  yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  ArchLinux 5.4.46-1-lts
- TensorFlow backend (yes / no):  yes
- TensorFlow version:  2.2.0
- Keras version:  2.3.0-tf
- Python version:  3.6
- CUDA/cuDNN version:  
- GPU model and memory:  

**Describe the current behavior**  
I have noticed, that when a gru layer is saved to a file, two almost identical bias vectors are written to the weight file, even though one of them would be enough. The bias data has the dimension (2x3*kernel_row_dimension) = rank 2. I am not sure whether this is intended, but I think that this is unlikely, given that only one set of kernel tensors is saved. 

**Describe the expected behavior**  
The bias tensor should be of rank 1

**Code to reproduce the issue**  
```python
from tensorflow.keras.layers import Input, GRU
from tensorflow.keras.models import Sequential
model = Sequential([Input((3, 12, )), GRU(3)])
model.save_weights(""test.h5"")

import h5py
F = h5py.File(""test.h5"", ""r"")
F[""gru""][""gru""][""gru_cell""][""bias:0""]
```
The output is
```
<HDF5 dataset ""bias:0"": shape (2,9), type ""<f4"">
```
Whereas I would expect to see something like (1, 9) since for a GRU 3 operations of the form activation(W x input + U x hidden + b) are evaluated, and since dim(hidden) and dim(input) is 3 here, the bias should store 9 elements in total. When the model is trained beforehand, the two bias vectors stored in the two rows are almost identical and can diverge on the order of a few % for increasing vector indices (I tested this with a bias vector of length 32).
",VukanJ,b'backend:tensorflow type:bug/performance',2020-06-15T21:38:19Z,2020-10-01T22:56:48Z
14045,return_dict in evaluate() method doesn't work,"I'm not sure if this is a bug, is a documentation incoherence or it's just an issue with the keras version that kaggle uses.

**System information**  
- Have I written custom code (as opposed to using example directory): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  Docker container for kaggle
- TensorFlow backend (yes / no):  yes
- TensorFlow version:  2.1.0
- Keras version:  2.3.1
- Python version:  3.7.6.

**Describe the current behavior**  

[In the docs for the model.evaluate method](https://keras.io/api/models/model_training_apis/#evaluate-method) it says you can use the argument ""return_dict"" to get a dictionary instead of a list for the output. However, I get an error when I specify such argument:
```
TypeError: evaluate() got an unexpected keyword argument 'return_dict'
```

**Describe the expected behavior**  
No error an dict with the output of the evaluation.

**Code to reproduce the issue**  
`results = model.evaluate(X_test, y_test, batch_size=24, return_dict=True)`

same thing if I use `return_dict = False`.

**Other info / logs**  
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.  
",Akronix,b'backend:tensorflow type:bug/performance',2020-05-12T12:44:26Z,2020-08-13T14:26:31Z
14037,Memory Leak when using keras.layers.Lambda and tf.map_fn,"**System information**  
- Have I written custom code (as opposed to using example directory):  Yes, see below
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  Arch Linux
- TensorFlow backend (yes / no):  yes
- TensorFlow version:  2.2.0-rc3
- Keras version:   2.3.1
- Python version:  3.8.2
- CUDA/cuDNN version:   V10.2.89
- GPU model and memory:  GeForce GTX 1060 6GB


The following program produces a memory leak.

```
#!/usr/bin/env python
import keras
import numpy as np
import tensorflow as tf
import gc
import os

@tf.function
def extractVector(inp):
	return tf.stack([inp[0]]*40, axis=0)

x_train = np.random.rand(3200, 40)
y_train = np.random.rand(3200, 40, 40)
embedding_vecs = np.random.rand(4592, 300)

input_layer = keras.layers.Input(shape=(40,))
embedding_layer = keras.layers.Embedding(4592, 300, weights=[embedding_vecs], input_length=40, trainable=False)(input_layer)
lstm_layer = keras.layers.LSTM(40, return_sequences=True)(embedding_layer)
lambda_layer = keras.layers.Lambda(lambda inp: tf.map_fn(extractVector, inp))(lstm_layer)
output_layer = lambda_layer

model = keras.models.Model(inputs=input_layer, outputs=output_layer)
model.compile(loss=""categorical_crossentropy"", optimizer=""adam"")

class GarbageCollectorCallback(tf.keras.callbacks.Callback):
    def on_epoch_end(self, epoch, logs=None):
        gc.collect()

class PrintRamCallback(tf.keras.callbacks.Callback):
    def on_epoch_end(self, epoch, logs=None):
        os.system(""pmap -x ""+str(os.getpid())+"" | tail -n 1"")

model.fit(x_train, y_train, batch_size=128, epochs=100, callbacks=[GarbageCollectorCallback(), PrintRamCallback()], verbose=0)

```

The output of the program above is:

> 2020-05-08 18:09:00.187454: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
> 2020-05-08 18:09:00.218519: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 3300655000 Hz
> 2020-05-08 18:09:00.218983: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5594d82c4200 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
> 2020-05-08 18:09:00.219023: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
> 2020-05-08 18:09:00.220331: I tensorflow/core/common_runtime/process_util.cc:147] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.
> Using TensorFlow backend.
> WARNING:tensorflow:AutoGraph could not transform <function extractVector at 0x7f74044ca310> and will run it as-is.
> Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
> Cause: module 'gast' has no attribute 'Constant'
> To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
> total kB         3554580  613100  429920
> total kB         3685652  753188  570008
> total kB         3816724  893884  710704
> total kB         3947796 1034252  851072
> total kB         4078868 1174528  991348
> total kB         4209940 1314880 1131700
> total kB         4341012 1455372 1272192
> total kB         4472084 1595540 1412360
> total kB         4603156 1741396 1558216
> total kB         4734228 1881492 1698312
> total kB         4865300 2021600 1838420
> total kB         4996372 2163068 1979888
> total kB         5192980 2303140 2119960
> total kB         5389588 2443292 2260112
> total kB         5520660 2583584 2400404
> total kB         5651732 2723784 2540604
> total kB         5782804 2863836 2680656
> total kB         5913876 3004144 2820964
> total kB         6044948 3144256 2961076
> total kB         6176020 3284412 3101232
> total kB         6307092 3424500 3241320
> total kB         6438164 3564720 3381540
> total kB         6569236 3705064 3521884
> total kB         6700308 3845276 3662096
> total kB         6831380 3985636 3802456
> total kB         7027988 4125896 3942716
> total kB         7159060 4266096 4082916
> total kB         7290132 4406160 4222980
> total kB         7421204 4546380 4363200
> total kB         7552276 4686528 4503348
> total kB         7683348 4826604 4643424
> total kB         7879956 4966828 4783648
> total kB         8011028 5106936 4923756
> total kB         8142100 5247296 5064116
> total kB         8273172 5383988 5204424
> total kB         8404244 5492128 5344856
> total kB         8535316 5494272 5485284
> total kB         8731924 5633596 5625676
> total kB         8862996 5772616 5765768
> total kB         8994068 5912720 5905752
> total kB         9125140 6052912 6045960
> total kB         9256212 6192840 6186032
> total kB         9387284 6236800 6226492
> total kB         9518356 6332196 6321296
> total kB         9649428 6379904 6369476
> total kB         9780500 6442764 6432232
> total kB         9977108 6490412 6480072
> total kB         10108180 6518504 6508008

You can see that it uses 430 MB to complete the first epoch, but 6500 MB for the 48'th Epoch .",Volker-Weissmann,b'backend:tensorflow type:bug/performance',2020-05-08T16:31:13Z,2020-07-17T17:03:50Z
13848,"ValueError: Invalid input_shape argument (None, 13): model has 0 tensor inputs.","**Ensemble model not working after loading from h5**
I'm building ensemble model with Keras and Tensorflow as backend. I have a couple pretrained ANN models saved in .h5 format - all works well. Then I create ensemble as follow:

For each network
 - First remove `Input` with `model.pop(0)`. 
 - Next create `Lambda layer` as firs layer of network
 - Create new `Input layer`  for netwok and crete new model from new Input layer and existing model

Then buidl ensemble model with following code:
```
model_input = Input(shape=(input_count, ))
for i in range(len(self.networks)):
    model = self.networks[i]
    for _layer in model.layers:
        _layer.trainable = False
        _layer.name = 'ensemble_' + str(i) + '_' + _layer.name

yModels=[model(model_input) for model in self.networks]

concatenated = Concatenate()(yModels)

def weighted_sum(x, w):
    """""" weights from formula 7 """"""
    w = K.variable(w)
    tensor = K.sum(x * w, axis= -1)
    return tensor
        
args = {""w"": self.w}
ens_output = Lambda(weighted_sum, arguments=args)(concatenated)
        
# build model
self.ensemble_model = Model(inputs=model_input, outputs=ens_output, name='ensemble')
self.ensemble_model.compile(loss='mean_absolute_error', optimizer = 'adam', metrics=['accuracy'])
```
`esemble_model` predict  OK results. After saving model to .h5 and loading back I get error:

```
Traceback (most recent call last):
  File ""test_laod_models.py"", line 8, in <module>
    model = load_model('ensemble_1.h5')
  File ""C:\Users\krstic\AppData\Local\conda\conda\envs\tensorflow\lib\site-packages\keras\engine\saving.py"", line 419, in load_model
    model = _deserialize_model(f, custom_objects, compile)
  File ""C:\Users\krstic\AppData\Local\conda\conda\envs\tensorflow\lib\site-packages\keras\engine\saving.py"", line 225, in _deserialize_model
    model = model_from_config(model_config, custom_objects=custom_objects)
  File ""C:\Users\krstic\AppData\Local\conda\conda\envs\tensorflow\lib\site-packages\keras\engine\saving.py"", line 458, in model_from_config
    return deserialize(config, custom_objects=custom_objects)
  File ""C:\Users\krstic\AppData\Local\conda\conda\envs\tensorflow\lib\site-packages\keras\layers\__init__.py"", line 55, in deserialize
    printable_module_name='layer')
  File ""C:\Users\krstic\AppData\Local\conda\conda\envs\tensorflow\lib\site-packages\keras\utils\generic_utils.py"", line 145, in deserialize_keras_object
    list(custom_objects.items())))
  File ""C:\Users\krstic\AppData\Local\conda\conda\envs\tensorflow\lib\site-packages\keras\engine\network.py"", line 1032, in from_config
    process_node(layer, node_data)
  File ""C:\Users\krstic\AppData\Local\conda\conda\envs\tensorflow\lib\site-packages\keras\engine\network.py"", line 991, in process_node
    layer(unpack_singleton(input_tensors), **kwargs)
  File ""C:\Users\krstic\AppData\Local\conda\conda\envs\tensorflow\lib\site-packages\keras\engine\base_layer.py"", line 474, in __call__
    output_shape = self.compute_output_shape(input_shape)
  File ""C:\Users\krstic\AppData\Local\conda\conda\envs\tensorflow\lib\site-packages\keras\engine\network.py"", line 593, in compute_output_shape
    str(len(self._input_layers)) + ' tensor inputs.')
ValueError: Invalid input_shape argument (None, 13): model has 0 tensor inputs.
```

In short:
 - enseble_model - works OK
 - save_model() - OK
 - load _model() - raise error",lazarkrstic,b'type:bug/performance',2020-03-01T13:10:10Z,2020-04-01T15:37:36Z
13816,val_loss missing from logs (but computed correctly at epoch end),"**System information**

- OS Platform and Distribution: Windows 10 Enterprise 1803 (build 17134.1246)
- TensorFlow backend: yes
- TensorFlow version: 2.0.0
- Keras version: '2.2.4-tf' (called from tensorflow.keras)
- Python version: 3.7
- CUDA/cuDNN version: -
- GPU model and memory: -

I'm trying to use the `ModelCheckpoint` callback in keras. However, it keeps saying to me that `val_loss` is not available. I added a print statement in the code of `ModelCheckpoint` to check the content of the `logs` variable passed to the callback. You can indeed see below that `val_loss` is not present in the dictionary.

The weird thing is that `val_loss` is correctly reported at the end of each epoch and it is present in the `history` object generated by `model.fit`. Clearly I provide validation data (otherwise val_loss could not be evaluated at the end of each epoch).

```
...
3/3 - 65s - loss: 0.2053 - val_loss: 0.1153
Epoch 2/45
logs={'batch': 0, 'size': 30000, 'loss': 0.20355584}
WARNING:tensorflow:Can save best model only with val_loss available, skipping.
...
```",pj1989,b'type:bug/performance',2020-02-21T09:16:18Z,2020-03-01T12:28:36Z
13777,BUG: Shape inference now works for transposed convolutions,"### Summary
Wrong backend call (K.shape instead of K.int_shape) resulted in undefined output shapes when using transposed convolutions, both when using or not using the output_padding argument.

### PR Overview

- [ ] This PR requires new unit tests [y/n] (make sure tests are included)
- [ ] This PR requires to update the documentation [y/n] (make sure the docs are up-to-date)
- [X] This PR is backwards compatible [y/n]
- [ ] This PR changes the current API [y/n] (all API changes need to be approved by fchollet)
",davideboschetto,None,2020-02-14T15:07:13Z,2020-02-14T15:58:54Z
13742,Incorrect archive link provided for missing cudart64_100.dll,"<em>Please make sure that this is a Bug or a Feature Request and provide all applicable information asked by the template.
If your issue is an **implementation question**, please ask your question on [StackOverflow](http://stackoverflow.com/questions/tagged/keras) or [on the Keras Slack channel](https://keras-slack-autojoin.herokuapp.com/) instead of opening a GitHub issue.</em>  

**System information**  
- Have I written custom code (as opposed to using example directory):  No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  Windows 10 v1809 Build 
- TensorFlow backend (yes / no):  yes
- TensorFlow version:  1.14.0
- Keras version:  2.2.5
- Python version:  3.7.4
- CUDA/cuDNN version:  9
- GPU model and memory:  Nvidia Geforce GTX 1050Ti - 4GB

You can obtain the TensorFlow version with:  
python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""  
You can obtain the Keras version with:  
python -c 'import keras as k; print(k.__version__)'  

**Describe the current behavior**  
The archive link provided for cuda point to 9.0
https://developer.nvidia.com/cuda-90-download-archive

**Describe the expected behavior**  
The download link should currently point to 10:
https://developer.nvidia.com/cuda-10.1-download-archive-update2

**Code to reproduce the issue**  
Provide a reproducible test case that is the bare minimum necessary to generate the problem.  

**Other info / logs**  
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.  

```py
>>> import keras
Using TensorFlow backend.
Traceback (most recent call last):
  File ""C:\Users\drago\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow\python\platform\self_check.py"", line 75, in preload_check
    ctypes.WinDLL(build_info.cudart_dll_name)
  File ""C:\Users\drago\AppData\Local\Programs\Python\Python37\lib\ctypes\__init__.py"", line 364, in __init__
    self._handle = _dlopen(self._name, mode)
OSError: [WinError 126] The specified module could not be found

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""C:\Users\drago\AppData\Local\Programs\Python\Python37\lib\site-packages\keras\__init__.py"", line 3, in <module>
    from . import utils
  File ""C:\Users\drago\AppData\Local\Programs\Python\Python37\lib\site-packages\keras\utils\__init__.py"", line 6, in <module>
    from . import conv_utils
  File ""C:\Users\drago\AppData\Local\Programs\Python\Python37\lib\site-packages\keras\utils\conv_utils.py"", line 9, in <module>
    from .. import backend as K
  File ""C:\Users\drago\AppData\Local\Programs\Python\Python37\lib\site-packages\keras\backend\__init__.py"", line 1, in <module>
    from .load_backend import epsilon
  File ""C:\Users\drago\AppData\Local\Programs\Python\Python37\lib\site-packages\keras\backend\load_backend.py"", line 89, in <module>
    from .tensorflow_backend import *
  File ""C:\Users\drago\AppData\Local\Programs\Python\Python37\lib\site-packages\keras\backend\tensorflow_backend.py"", line 5, in <module>
    import tensorflow as tf
  File ""C:\Users\drago\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow\__init__.py"", line 28, in <module>
    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import
  File ""C:\Users\drago\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow\python\__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""C:\Users\drago\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 30, in <module>
    self_check.preload_check()
  File ""C:\Users\drago\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow\python\platform\self_check.py"", line 82, in preload_check
    % (build_info.cudart_dll_name, build_info.cuda_version_number))
ImportError: Could not find 'cudart64_100.dll'. TensorFlow requires that this DLL be installed in a directory that is named in your %PATH% environment variable. Download and install CUDA 10.0 from this URL: https://developer.nvidia.com/cuda-90-download-archive
```",Hyperclaw79,b'type:bug/performance',2020-02-04T14:46:56Z,2020-02-20T15:54:06Z
13679,"Training Script failed with no Error Stack ""exit code 1073740791 0xc0000409""","-Keras Version: 2.3.1
-Tensorflow Version: 2.0
-OS: Windows 10
-Running on: CPU Processor	Intel(R) Core(TM) i7-8850H
-Developed in: PyCharm

I'm attempting to build a novel model using an implementation of a highway layer (implementation found at: https://gist.github.com/iskandr/a874e4cf358697037d14a17020304535). There was a typo listed on this page which is corrected in my copy of the code.

I have a simplified version of the code I'm using below:

```python
import scipy.io as io
import os
import numpy as np
from keras import layers, losses, Input
from keras.models import Model
from keras2_highway_network import highway_layers

def simple_generator(dim1, dim2, dim3, batch_size=5):
    while True:
        samples = np.random.random_sample((batch_size, dim1, dim2, dim3))
        targets = np.random.random_sample((batch_size, 3))
        yield samples, targets

example_shape = (1100, 4096, 2)

train_gen = simple_generator(example_shape[0], example_shape[1], example_shape[2], batch_size=10)
val_gen = simple_generator(example_shape[0], example_shape[1], example_shape[2])
test_gen = simple_generator(example_shape[0], example_shape[1], example_shape[2])

input_tensor = Input(shape=example_shape)
x = layers.Conv2D(32, 3, activation='relu')(input_tensor)
x = layers.MaxPool2D(pool_size=(3, 3), strides=3)(x)
x = layers.Dense(32, activation='relu')(x)
x = highway_layers(x, 32, activation='relu')
x = highway_layers(x, 32, activation='relu')
x = highway_layers(x, 32, activation='relu')
x = layers.Conv2D(32, 3, activation='relu')(x)
x = layers.MaxPool2D(pool_size=(3, 3), strides=3)(x)
x = layers.Dense(16, activation='relu')(x)
x = highway_layers(x, 16, activation='relu')
x = highway_layers(x, 16, activation='relu')
x = highway_layers(x, 16, activation='relu')
x = layers.Flatten()(x)
output_tensor = layers.Dense(3)(x)

model = Model(input_tensor, output_tensor)

model.compile(loss=losses.mean_absolute_error, optimizer='sgd')
model.summary()

history = model.fit_generator(generator=train_gen, steps_per_epoch=25, epochs=12, validation_data=val_gen, validation_steps=10, verbose=True)
```

The resulting network has around 2.5 million parameters, which despite the warnings my machine prints it can handle no problem. Once training begins I get a warning about the amount of memory I'm using, which I expect, and then the script simply stops running. The only stack trace I get is: ""exit code 1073740791 0xc0000409""

I have seen this is one other issue that was raised in this git, however it has been tagged as ""stale"" with no answer posted, so I thought I'd ask again.

Thanks in advance for your time!
All the best,
Oisín.


",OisinWatkins,b'backend:tensorflow type:bug/performance',2020-01-09T12:11:12Z,2020-02-06T10:56:01Z
13657,Keras 2.3.1 PyQt5 QThread '_thread._local' object has no attribute 'value',"`tensorflow==2.1.0
Keras==2.3.1`

self.model.add(Dense(units=128, input_dim=input_dim, kernel_initializer=self.init, activation='relu'))

throw:

`if _SYMBOLIC_SCOPE.value:
AttributeError: '_thread._local' object has no attribute 'value'
`

but

`tensorflow==1.14
Keras==2.2.5`

OK",tinyms,b'backend:tensorflow type:bug/performance',2019-12-28T16:29:22Z,2020-01-06T08:25:16Z
13549,"fit_generator is slow, and I/O ain't the cause","OS: Ubuntu Server 18.04, with xanmod kernel
Python: Anaconda 3.7
Tensorflow: 2.0.0 MKL
Keras: TF built-in
CPU: Intel(R) Core(TM)2 Quad CPU Q9300
No GPU
model.fit works as expected
```
import numpy as np
import tensorflow.keras as keras
from tensorflow.keras.layers import *
from tensorflow.keras.models import Model
from tensorflow.keras.regularizers import l2
from tensorflow.keras import optimizers
from tensorflow.keras import backend as K
import time, itertools, random

def makeModel(arch, constructor, name):
    inputs = Input(arch)
    model = Model(inputs, constructor(inputs), name=name)
    try:
        model.load_weights(""%s.h5""%name)
    except:
        print(""new %s""%name)
    return model

def saveModel(model):
    model.save_weights(""%s.h5""%model.name)

def g():
    return l2(.00001)

def sr2x(obj):
    for i in range(4):
        obj = Conv1D(96, 1, activation='tanh', kernel_initializer='he_uniform', kernel_regularizer=g(), bias_regularizer=g())(obj)
        obj = GaussianNoise(.001)(obj)
    obj = Conv1D(96, 1, kernel_initializer='he_uniform', kernel_regularizer=g(), bias_regularizer=g())(obj)
    obj = Lambda(lambda x: K.sum(x, axis=1))(obj)
    obj = Reshape((3, 32))(obj)
    obj = Activation(""softmax"")(obj)
    return obj

sr = makeModel((None, 5,), sr2x, ""sr2x"")
sr.summary()
sr.compile(optimizer=optimizers.Adam(.00001), loss='categorical_crossentropy', metrics=['categorical_accuracy'])
i = 0

data = np.mgrid[0:32, 0:32, 0:32].T.reshape(-1, 3)
inp = np.dstack(((np.exp(np.float32(data[:, None])*.1789)-1.0)/255.0, np.zeros((len(data), 1, 2), dtype=np.float32)))
out = keras.utils.to_categorical(data, 32)

print(inp.shape, out.shape)

class MyCallback(keras.callbacks.Callback):
    def on_epoch_end(self, epoch, logs=None):
        saveModel(sr)

try:
    sr.fit(inp, out, 32, epochs=100, callbacks=[MyCallback()])
except KeyboardInterrupt:
    print(""one second..."")
    time.sleep(1)
    print(""saving..."")
saveModel(sr)
print(""saved..."")
```
model.fit_generator is 16x slower. No I/O is performed. My tests show 60000hz minimum performance outside keras.
```
import numpy as np
import tensorflow.keras as keras
from tensorflow.keras.layers import *
from tensorflow.keras.models import Model
from tensorflow.keras.regularizers import l2
from tensorflow.keras import optimizers
from tensorflow.keras import backend as K
import time, itertools, random

def makeModel(arch, constructor, name):
    inputs = Input(arch)
    model = Model(inputs, constructor(inputs), name=name)
    try:
        model.load_weights(""%s.h5""%name)
    except:
        print(""new %s""%name)
    return model

def saveModel(model):
    model.save_weights(""%s.h5""%model.name)

def g():
    return l2(.00001)

def sr2x(obj):
    for i in range(4):
        obj = Conv1D(96, 1, activation='tanh', kernel_initializer='he_uniform', kernel_regularizer=g(), bias_regularizer=g())(obj)
        obj = GaussianNoise(.001)(obj)
    obj = Conv1D(96, 1, kernel_initializer='he_uniform', kernel_regularizer=g(), bias_regularizer=g())(obj)
    obj = Lambda(lambda x: K.sum(x, axis=1))(obj)
    obj = Reshape((3, 32))(obj)
    obj = Activation(""softmax"")(obj)
    return obj

sr = makeModel((None, 5,), sr2x, ""sr2x"")
sr.summary()
sr.compile(optimizer=optimizers.Adam(.00001), loss='categorical_crossentropy', metrics=['categorical_accuracy'])
i = 0



def sampler():
    data = np.mgrid[0:32, 0:32, 0:32].T.reshape(-1, 3)
    inp = np.dstack(((np.exp(np.float32(data[:, None])*.1789)-1.0)/255.0, np.zeros((len(data), 1, 2), dtype=np.float32)))
    out = keras.utils.to_categorical(data, 32)
    rg = np.arange(len(inp), dtype=np.uint32)
    while True:
        np.random.shuffle(rg)
        inpc = inp[rg]
        outc = out[rg]
        for i in range(0, len(rg), 32):
            yield inpc[i:i+32], outc[i:i+32]

class MyCallback(keras.callbacks.Callback):
    def on_epoch_end(self, epoch, logs=None):
        saveModel(sr)

try:
    sr.fit_generator(sampler(), steps_per_epoch=1024, epochs=100, callbacks=[MyCallback()])
except KeyboardInterrupt:
    print(""one second..."")
    time.sleep(1)
    print(""saving..."")
saveModel(sr)
print(""saved..."")
```
Edit: fixed the bug. Data was not shuffled properly.",ghost,b'backend:tensorflow type:bug/performance',2019-11-13T07:13:09Z,2019-11-27T11:56:13Z
13538,Slow import of Keras array_to_img,"trying upload just one function from eras take me considerable time 
this is on ubuntu 18.04 under aws 
other functions such as bumpy are ok 
this is the only line of code I expect it to be much faster maybe 0.2 sec not 1+ why is it like so and is it solvable? how ? 
I hope this is a legit question I looked on the internet and did not find any hint of what to do.

<from keras.preprocessing.image import array_to_img > 

2019-11-10 10:09:51,380 - root - DEBUG - np 1 1573380591.3805187
2019-11-10 10:09:52,989 - root - DEBUG - tf 1 1573380592.9898841
",sivi29y,b'backend:tensorflow type:bug/performance',2019-11-10T10:23:39Z,2019-12-17T09:11:59Z
13402,"tf.keras works, tf.python.keras doesn't","**DOESN'T WORK**:
```python
from tensorflow.python.keras.layers import Input, Dense
from tensorflow.python.keras.models import Model
from tensorflow.python.keras.optimizers import Nadam

ipt = Input(shape=(4,))
out = Dense(1, activation='sigmoid')(ipt)

model = Model(ipt, out)
model.compile(optimizer=Nadam(lr=1e-4), loss='binary_crossentropy')

X = np.random.randn(32,4)
Y = np.random.randint(0,2,(32,1))
model.train_on_batch(X,Y)
```
**WORKS**: remove `.python` from above's imports. Above's error trace below.

Keras 2.3.0 and TensorFlow 2.0.0 freshly-installed via Anaconda, older versions uninstalled. Why the difference?

<hr>

```python

  File ""<ipython-input-7-1e86d21d8fc4>"", line 13, in <module>
    model.train_on_batch(X,Y)

  File ""D:\Anaconda\envs\tf2_env\lib\site-packages\tensorflow_core\python\keras\engine\training.py"", line 1017, in train_on_batch
    self._make_train_function()

  File ""D:\Anaconda\envs\tf2_env\lib\site-packages\tensorflow_core\python\keras\engine\training.py"", line 2116, in _make_train_function
    params=self._collected_trainable_weights, loss=self.total_loss)

  File ""D:\Anaconda\envs\tf2_env\lib\site-packages\tensorflow_core\python\keras\optimizers.py"", line 653, in get_updates
    grads = self.get_gradients(loss, params)

  File ""D:\Anaconda\envs\tf2_env\lib\site-packages\tensorflow_core\python\keras\optimizers.py"", line 92, in get_gradients
    if None in grads:

  File ""D:\Anaconda\envs\tf2_env\lib\site-packages\tensorflow_core\python\ops\math_ops.py"", line 1336, in tensor_equals
    return gen_math_ops.equal(self, other)

  File ""D:\Anaconda\envs\tf2_env\lib\site-packages\tensorflow_core\python\ops\gen_math_ops.py"", line 3627, in equal
    name=name)

  File ""D:\Anaconda\envs\tf2_env\lib\site-packages\tensorflow_core\python\framework\op_def_library.py"", line 545, in _apply_op_helper
    (input_name, err))

ValueError: Tried to convert 'y' to a tensor and failed. Error: None values not supported.
```
<hr>

**UPDATE:** Debugging the two side-by-side, while both use the [same files](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/engine/training.py#L1008), execution diverges fairly quickly:

```python
# .\tensorflow_core\python\keras\engine\training.py

### TF.KERAS
    if self._experimental_run_tf_function: #  TRUE
	
### TF.PYTHON.KERAS
    if self._experimental_run_tf_function: #  FALSE
```
Former proceeds to call `training_v2_utils.train_on_batch(...)` and returns thereafter, latter `self._standardize_user_data(...)` and others before ultimately failing. 

One difference I noted between linked file and mine is, latter's short by ~100 lines - though I installed TF 2 via pip after the file's last update 12 days ago according to Github.",OverLordGoldDragon,b'backend:tensorflow type:bug/performance',2019-10-06T03:09:27Z,2019-10-09T19:32:59Z
13396,TF2 K.get_value() - bug or feature?,"Calling `K.get_value(self.param)` inside `optimizer.get_update()` yields below error: 

```python
NotImplementedError: numpy() is only available when eager execution is enabled.
```

Debugging, I learn that `context.executing_eagerly()` evaluates to `False` in given scope, but to `True` in `optimizer.get_config()`. I note the latter is always called in a declared scope - e.g. `with strategy.scope()` [here](https://github.com/tensorflow/tensorflow/blob/64c3d382cadf7bbe8e7e99884bede8284ff67f56/tensorflow/python/keras/distribute/multi_worker_test.py#L216). 

_However_ - the buggy aspect here is that `K.get_value()` works fine _post-error_ - i.e. if I run `K.get_value(model.optimizer.param)`, it evaluates successfully. This is accomplished via the `K.symbolic` wrapper, which calls `tensorflow_backend.symbolic()` post-error - which, when finishes executing, changes the parameter as follows:

```python
<tf.Variable 'Adam/param:0' shape=() dtype=int64>
# into
<tf.Variable 'Adam/param:0' shape=() dtype=int64, numpy=100>
```
Also, calling `param.numpy()` directly yields the same error. I'm using `Keras 2.3.0` w/ `TensorFlow 2.0.0`. -- Bug or feature? And how do I now retrieve `K.variable` values during optimizer compilation? (usage is boolean - e.g. `if param == 1`)

<hr>
<b>UPDATE</b>: 

`print(self.param); print(tf.executing_eagerly)` under each of below yields, respectively:


```python
# def __init__(self, ...)
<tf.Variable 'Adam/param:0' shape=() dtype=int64, numpy=100>
True

# def get_updates(self)
<tf.Variable 'Adam/param:0' shape=() dtype=int64>
False
```
The wrappers appear to be involved - from `K.symbolic.__doc__`: 

> ""Decorator used in TensorFlow 2.0 to enter the Keras graph""

So this is at the expense of class attribute values getting lost? Should `__init__` also be wrapped then?",OverLordGoldDragon,b'backend:tensorflow type:bug/performance',2019-10-05T01:08:14Z,2019-10-10T21:36:13Z
13336,Calling`model.predict()` from inside batch generator raises thread-local storage error ,"**System information**  
- Have I written custom code (as opposed to using example directory): Some, but the issue arises with a relatively simple case.
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04 in Docker on a Mac 
- TensorFlow backend (yes / no):  Yes
- TensorFlow version:  1.14.0 but also occurs in 2.0.0rc1
- Keras version: 2.3.0
- Python version: 3.7
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A

**Describe the current behavior**
When calling a model during training (e.g., from a batch generator), an attribute error is raised related to thread-local data. This occurs in Keras 2.3.0 but not in Keras <= 2.2.5. It appears the thread-local storage elements were added in Keras 2.3.0.

**Describe the expected behavior**
I expect the model to be callable during training, as has been the case in prior Keras versions. The test code is intentionally trivial to demonstrate the issue. In practice, being able to call a model during batch generation is useful for cases where we generate batches based on current model behavior (e.g., selecting hard examples for a model using triplet loss).

**Code to reproduce the issue**  

```python
import keras
import numpy as np

input_layer = keras.layers.Input((1, ))
x = keras.layers.Dense(1, activation='sigmoid')(input_layer)
model = keras.models.Model(inputs=input_layer, outputs=x)
model.compile(loss='binary_crossentropy', optimizer='sgd')
model._make_predict_function() 
def generate():
    while True:
        # If you comment this next line out, no error is raised.
        yt = model.predict(np.random.randn(5, 1))
        yield np.random.randn(5, 1), np.ones((5, 1))

model.fit_generator(generate(), epochs=3, steps_per_epoch=10)
```

**Other info / logs**  
```
---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
<ipython-input-1-79d7cb1668dc> in <module>
     12         yield np.random.randn(5, 1), np.ones((5, 1))
     13 
---> 14 model.fit_generator(generate(), epochs=3, steps_per_epoch=10)

/usr/src/.venv/lib/python3.7/site-packages/keras/legacy/interfaces.py in wrapper(*args, **kwargs)
     89                 warnings.warn('Update your `' + object_name + '` call to the ' +
     90                               'Keras 2 API: ' + signature, stacklevel=2)
---> 91             return func(*args, **kwargs)
     92         wrapper._original_function = func
     93         return wrapper

/usr/src/.venv/lib/python3.7/site-packages/keras/engine/training.py in fit_generator(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)
   1730             use_multiprocessing=use_multiprocessing,
   1731             shuffle=shuffle,
-> 1732             initial_epoch=initial_epoch)
   1733 
   1734     @interfaces.legacy_generator_methods_support

/usr/src/.venv/lib/python3.7/site-packages/keras/engine/training_generator.py in fit_generator(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)
    183             batch_index = 0
    184             while steps_done < steps_per_epoch:
--> 185                 generator_output = next(output_generator)
    186 
    187                 if not hasattr(generator_output, '__len__'):

/usr/src/.venv/lib/python3.7/site-packages/keras/utils/data_utils.py in get(self)
    740                     ""`use_multiprocessing=False, workers > 1`.""
    741                     ""For more information see issue #1638."")
--> 742             six.reraise(*sys.exc_info())

/usr/src/.venv/lib/python3.7/site-packages/six.py in reraise(tp, value, tb)
    691             if value.__traceback__ is not tb:
    692                 raise value.with_traceback(tb)
--> 693             raise value
    694         finally:
    695             value = None

/usr/src/.venv/lib/python3.7/site-packages/keras/utils/data_utils.py in get(self)
    709                 try:
    710                     future = self.queue.get(block=True)
--> 711                     inputs = future.get(timeout=30)
    712                     self.queue.task_done()
    713                 except mp.TimeoutError:

/usr/local/lib/python3.7/multiprocessing/pool.py in get(self, timeout)
    655             return self._value
    656         else:
--> 657             raise self._value
    658 
    659     def _set(self, i, obj):

/usr/local/lib/python3.7/multiprocessing/pool.py in worker(inqueue, outqueue, initializer, initargs, maxtasks, wrap_exception)
    119         job, i, func, args, kwds = task
    120         try:
--> 121             result = (True, func(*args, **kwds))
    122         except Exception as e:
    123             if wrap_exception and func is not _helper_reraises_exception:

/usr/src/.venv/lib/python3.7/site-packages/keras/utils/data_utils.py in next_sample(uid)
    648         The next value of generator `uid`.
    649     """"""
--> 650     return six.next(_SHARED_SEQUENCES[uid])
    651 
    652 

<ipython-input-1-79d7cb1668dc> in generate()
      9 def generate():
     10     while True:
---> 11         yt = model.predict(np.random.randn(5, 1))
     12         yield np.random.randn(5, 1), np.ones((5, 1))
     13 

/usr/src/.venv/lib/python3.7/site-packages/keras/engine/training.py in predict(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)
   1460                                             verbose=verbose,
   1461                                             steps=steps,
-> 1462                                             callbacks=callbacks)
   1463 
   1464     def train_on_batch(self, x, y,

/usr/src/.venv/lib/python3.7/site-packages/keras/engine/training_arrays.py in predict_loop(model, f, ins, batch_size, verbose, steps, callbacks)
    274             indices_for_conversion_to_dense.append(i)
    275 
--> 276     callbacks.model.stop_training = False
    277     callbacks._call_begin_hook('predict')
    278 

/usr/src/.venv/lib/python3.7/site-packages/keras/engine/network.py in __setattr__(self, name, value)
    321                     'forgot to call `super(YourClass, self).__init__()`.'
    322                     ' Always start with this line.')
--> 323         super(Network, self).__setattr__(name, value)
    324 
    325     @property

/usr/src/.venv/lib/python3.7/site-packages/keras/engine/base_layer.py in __setattr__(self, name, value)
   1213         # We do this so that we can maintain the correct order of metrics by adding
   1214         # the instance to the `metrics` list as soon as it is created.
-> 1215         if not _DISABLE_TRACKING.value:
   1216             from .. import metrics as metrics_module
   1217             if isinstance(value, metrics_module.Metric):

AttributeError: '_thread._local' object has no attribute 'value'
```
",faustomorales,b'backend:tensorflow type:bug/performance',2019-09-18T18:26:12Z,2020-06-19T10:46:57Z
13332,Bug fix: Saving Input layers with predefined tensors,"### Summary

Fixes an issue with saving and loading `Input` layers that have a predefined tensor.

Predefined tensors for `Input` are used to create constant input values for a Model.
However, the data from a predefined tensors provided to `Input` are not saved when a Model is serialized to an hdf5 file. 
Not saving this information causes two main issues:

1.  The ""constant"" layer is interpreted as a ""placeholder"" on loading, leading to a different input signature.
1. Any values provided to the ""constant"" layer are lost

This PR addresses these issues by changing the `get_config` and `from_config` functions of `InputLayer` to store whether an input is a placeholder or not.
Changing these functions also required modifying the `__init__` function of `InputLayer`.

### Related Issues

None that I can find... but I'll dig some more. 

### PR Overview

- [x] This PR requires new unit tests [y/n] (make sure tests are included)
- [ ] This PR requires to update the documentation [y/n] (make sure the docs are up-to-date)
- [x] This PR is backwards compatible [y/n]
- [ ] This PR changes the current API [y/n] (all API changes need to be approved by fchollet)
",WardLT,None,2019-09-17T23:11:14Z,2019-09-18T21:32:51Z
13302,Multi-GPU Model fails to detect CPU,"When running 

`p_model = multi_gpu_model(model)`

I get

ValueError: To call `multi_gpu_model` with `gpus=4`, we expect the following devices to be available: ['/cpu:0', '/gpu:0', '/gpu:1', '/gpu:2', '/gpu:3']. However this machine only has: ['/gpu:0', '/gpu:1', '/gpu:2', '/gpu:3']. Try reducing `gpus`

Running the following correctly lists all GPUs and a CPU:

```
from tensorflow.python.client import device_lib
device_lib.list_local_devices()
```
I have tried :
 with and without 
`os.environ['CUDA_VISIBLE_DEVICES'] = ""0,1,2,3,4"" `
and permutations of those numbers (ie 0,1,2,3)
 building the initial model with and without
`with tf.device('/cpu:0'):`
building the subsequent parallel model with and without
`with tf.device('/cpu:0'):`

this error only happens on the latest branch, I installed via 
`pip3.6 install git+https://github.com/keras-team/keras --upgrade --no-deps`
and have tried with both TF 1.13 and 1.14

",JamesDConley,b'backend:tensorflow type:bug/performance',2019-09-10T14:15:56Z,2019-09-10T18:23:17Z
13221,'recurrent_dropout' with 'relu' in LSTM yields NaNs,"Any non-zero `recurrent_dropout` yields NaN losses and weights; latter are either 0 or NaN. Happens for stacked, shallow, `stateful`, `return_sequences` = any, with & w/o `Bidirectional()`, `activation='relu'`, `loss='binary_crossentropy'`. NaNs occur within a few batches - the more layers, the sooner. 

Any fixes? Help's appreciated.

<hr>
<b>TROUBLESHOOTING ATTEMPTED</b>:

 - `recurrent_dropout=0.2,0.1,0.01,1e-6`
 - `kernel_constraint=maxnorm(0.5,axis=0)`
 - `recurrent_constraint=maxnorm(0.5,axis=0)`
 - `clipnorm=50`  (empirically determined), Nadam optimizer 
 - `activation='tanh'` - no NaNs, weights stable, tested for up to 10 batches
 - `lr=2e-6,2e-5` - no NaNs, weights stable, tested for up to 10 batches
 - `lr=5e-5` - no NaNs, weights stable, for 3 batches - NaNs on batch 4

_NOTE_: `batch_shape=(32,672,16)`, 17 calls to `train_on_batch` per batch

<hr>
<b>ENVIRONMENT</b>:

 - Keras 2.2.4 (TensorFlow backend), Python 3.7, Spyder 3.3.7 via Anaconda
 - GTX 1070 6GB, i7-7700HQ, 12GB RAM, Win-10.0.17134 x64
 - CuDNN 10+, latest Nvidia drives",OverLordGoldDragon,b'backend:tensorflow type:bug/performance',2019-08-15T21:36:08Z,2020-01-09T03:18:16Z
13093,Non-OK-status:  Internal: invalid configuration argument Aborted (core dumped),"<em>Please make sure that this is a Bug or a Feature Request and provide all applicable information asked by the template.
If your issue is an **implementation question**, please ask your question on [StackOverflow](http://stackoverflow.com/questions/tagged/keras) or [on the Keras Slack channel](https://keras-slack-autojoin.herokuapp.com/) instead of opening a GitHub issue.</em>  

**System information**  
- Have I written custom code (as opposed to using example directory):  
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  Linux Ubuntu 16.04
- TensorFlow backend (yes / no):  yes
- TensorFlow version:  v1.14.0-rc1-22-gaf24dc91b5 1.14.0
- Keras version:  2.2.4
- Python version:  3.6
- CUDA/cuDNN version:  Cuda compilation tools, release 10.0, V10.0.130
- GPU model and memory:  2 gpus, each 11 GB

You can obtain the TensorFlow version with:  
python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""  
You can obtain the Keras version with:  
python -c 'import keras as k; print(k.__version__)'  

**Describe the current behavior**  
I was using below code to build a LSTM model.
```
    left = Input(shape=(128, 3072), dtype='float32', name='Input-Left')
    right = Input(shape=(128, 3072), dtype='float32', name='Input-Right')
    lstm = Bidirectional(LSTM(units=768,
                              activation='tanh'),
                         name='Bidirectional-LSTM')
    l_lstm = lstm(left)
    r_lstm = lstm(right)
    subtracted = Subtract(name='Subtract')([l_lstm, r_lstm])
    abs_subtracted = Lambda(function=backend.abs)(subtracted)
    mul = Multiply(name='multiplication')([l_lstm, r_lstm])
    concat = concatenate([abs_subtracted, mul])
    output = Dense(units=1)(concat)
    model = Model(inputs=[left, right],
                  outputs=output)
    model = multi_gpu_model(model, gpus=2)
    model.compile(loss='mean_squared_error',
                  optimizer='Adam',
                  metrics=['acc'])
```

**Describe the expected behavior**  
expect the code run without error.

**Code to reproduce the issue**  
Provide a reproducible test case that is the bare minimum necessary to generate the problem.  

**Other info / logs**  
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.  

get the following error
```
2019-07-11 00:34:47.259516: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-07-11 00:34:47.261497: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-07-11 00:34:47.263346: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-07-11 00:34:47.263979: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-07-11 00:34:47.264617: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0, 1
2019-07-11 00:34:49.404341: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-11 00:34:49.404385: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 1 
2019-07-11 00:34:49.404390: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N Y 
2019-07-11 00:34:49.404394: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 1:   Y N 
2019-07-11 00:34:49.404729: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-07-11 00:34:49.405481: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-07-11 00:34:49.406172: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-07-11 00:34:49.406916: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9428 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
2019-07-11 00:34:49.407465: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-07-11 00:34:49.408128: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 10039 MB memory) -> physical GPU (device: 1, name: GeForce GTX 1080 Ti, pci bus id: 0000:02:00.0, compute capability: 6.1)
2019-07-11 00:34:49.942669: F ./tensorflow/core/kernels/random_op_gpu.h:227] Non-OK-status: CudaLaunchKernel(FillPhiloxRandomKernelLaunch<Distribution>, num_blocks, block_size, 0, d.stream(), gen, data, size, dist) status: Internal: invalid configuration argument
Aborted (core dumped)
```

",xinsu626,b'backend:tensorflow stat:awaiting tensorflower type:bug/performance',2019-07-11T05:42:14Z,2020-09-08T14:56:18Z
13057,multi_gpu_model not working w/ TensorFlow 1.14 ,"
**System information**  
- Have I written custom code (as opposed to using example directory):  No/Yes (very slight change to an example)
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  Ubuntu 16.04
- TensorFlow backend (yes / no):  yes
- TensorFlow version:  1.14
- Keras version: Latest master from github
- Python version:  3.7 (through Anaconda)
- CUDA/cuDNN version:  10.0/7.4.2
- GPU model and memory:  2x Tesla K80 (11GB each)

**Describe the current behavior**  

I am using the cifar-10 ResNet example from the Keras examples directory, with the addition of the following line at Line number 360 (just before compilation) in order to use multiple GPUs while training. However this doesn't work.

Line Added:
`model = keras.utils.multi_gpu_model(model, gpus=2)`

Traceback Error log:

```
Traceback (most recent call last):
  File ""cifar10_resnet_multigpu.py"", line 360, in <module>
    model = keras.utils.multi_gpu_model(model, gpus=2)
  File ""/local/home/manasa/vpds2/conda/anaconda3/envs/tensorflow114/lib/python3.7/site-packages/keras/utils/multi_gpu_utils.py"", line 230, in multi_gpu_model
    outputs = model(inputs)
  File ""/local/home/manasa/vpds2/conda/anaconda3/envs/tensorflow114/lib/python3.7/site-packages/keras/engine/base_layer.py"", line 451, in __call__
    output = self.call(inputs, **kwargs)
  File ""/local/home/manasa/vpds2/conda/anaconda3/envs/tensorflow114/lib/python3.7/site-packages/keras/engine/network.py"", line 570, in call
    output_tensors, _, _ = self.run_internal_graph(inputs, masks)
  File ""/local/home/manasa/vpds2/conda/anaconda3/envs/tensorflow114/lib/python3.7/site-packages/keras/engine/network.py"", line 727, in run_internal_graph
    layer.call(computed_tensor, **kwargs))
  File ""/local/home/manasa/vpds2/conda/anaconda3/envs/tensorflow114/lib/python3.7/site-packages/keras/layers/normalization.py"", line 185, in call
    epsilon=self.epsilon)
  File ""/local/home/manasa/vpds2/conda/anaconda3/envs/tensorflow114/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py"", line 2053, in normalize_batch_in_training
    if not _has_nchw_support() and list(reduction_axes) == [0, 2, 3]:
  File ""/local/home/manasa/vpds2/conda/anaconda3/envs/tensorflow114/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py"", line 299, in _has_nchw_support
    explicitly_on_cpu = _is_current_explicit_device('CPU')
  File ""/local/home/manasa/vpds2/conda/anaconda3/envs/tensorflow114/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py"", line 272, in _is_current_explicit_device
    device = _get_current_tf_device()
  File ""/local/home/manasa/vpds2/conda/anaconda3/envs/tensorflow114/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py"", line 252, in _get_current_tf_device
    g._apply_device_functions(op)
  File ""/local/home/manasa/vpds2/conda/anaconda3/envs/tensorflow114/lib/python3.7/site-packages/tensorflow/python/framework/ops.py"", line 4581, in _apply_device_functions
    op._set_device_from_string(device_string)
AttributeError: '_TfDeviceCaptureOp' object has no attribute '_set_device_from_string'

```

**Describe the expected behavior** 

Previously, this typically worked fine and results in faster training due to parallelization across GPUs. 

**Note:** This works fine if the backend is Tensorflow 1.13, so this is a regression. 
",rohit-gupta,b'backend:tensorflow stat:awaiting tensorflower type:bug/performance',2019-07-03T11:05:14Z,2020-09-29T09:52:42Z
13047,model created through Sequential and Functional APIs behaves differently.,"
Created two same CNN one with Sequential API and another with Functional API. One created using Sequential API outputs good validation accuracy around 80-85% but another created with Functional API behaves weird and output validation accuracy about 10-20%.

",shivg7706,b'backend:tensorflow stat:awaiting tensorflower type:bug/performance',2019-07-02T07:01:22Z,2019-07-31T04:54:30Z
12969,Receiving AttributeError: 'Tensor' object has no attribute 'numpy' in keras backend.,"Okay, so... I'm trying to implement a custom loss function in tf-keras. 

My tf version is 1.13.1, my keras version is 2.2.4, my OS is Linux Mint Ubuntu 16.04, and my python version is Anaconda Python 3.6.8


Basically, this loss function is a Keras dense siamese neural network that I'm trying to get to learn a loss between y_true and y_pred. However I receive the above error every time the model above this loss func. compiles. The input_shape param is (1, 1920), and the code is as follows:

Siamese Net Code:
```
class SiameseNetwork:
    def __init__(self, input_shape):
        self.input_shape = input_shape
        self.true_input = (1,) + input_shape
        
        self.base_net = self.build_base()
        self.input_one = Input(shape=self.input_shape)
        self.input_two = Input(shape=self.input_shape)

        self.processed_one = self.base_net(self.input_one)
        self.processed_two = self.base_net(self.input_two)

        self.distance = Lambda(self.euclidean_distance)([self.processed_one, self.processed_two])
        self.together = Dense(1, activation=self.reverse_sigmoid)(self.distance)

        self.siamese_net = Model([self.input_one, self.input_two], self.together)
        self.siamese_net.summary()

        loss = self.contrastive_meta_loss
        optimizer = RMSprop()

        self.siamese_net.compile(loss=loss, optimizer=optimizer)

        self.loss = 1.0

        self.random_input = np.random.random_sample(self.true_input)

        print(""Random input shape"", self.random_input.shape)

        self.y_pred = self.random_input
        self.y_true = self.random_input
        
        print('debugging: y_true shape:',   self.y_true.shape)
        
    def reverse_sigmoid(self, x):
        return K.sigmoid(-x)

    def contrastive_meta_loss(self, y_true, y_pred):
        margin = 1

        square_pred = K.square(y_pred)
        margin_square = K.square(K.maximum(margin - y_pred, 0))
        return K.mean(y_true * square_pred + (1 - y_true) * margin_square)
    
    def build_base(self):
        inputs = Input(shape=self.input_shape)
        x = Flatten()(inputs)
        x = tf.layers.Dense(1024, activation='relu')(x)
        x = tf.layers.Dropout(.1)(x)
        x = tf.layers.Dense(1024, activation='relu')(x)
        x = tf.layers.Dropout(.1)(x)
        x = tf.layers.Dense(1024, activation='relu')(x)
        model = Model(inputs, x)
        print(""Debugging: 110XA25B:"")
        model.summary()
        return model
    
    def euclidean_distance(self, vects):
        x, y = vects
        sum_sq = K.sum(K.square(x - y), axis = 1, keepdims=True)
        return K.sqrt(K.maximum(sum_sq, K.epsilon()))
    
    def siamese_loss(self, fake_y_true, fake_y_pred):

        print(""Debugging: 110XA1SS:"", self.y_true.shape, self.y_pred.shape)

    
        self.loss = self.siamese_net.predict([self.y_true, self.y_pred])

        self.siamese_net.fit(x=[y_true, y_pred], y=self.loss, epochs=1, verbose=0)
        return self.loss
```

Error + Traceback:

```
Traceback (most recent call last):
  File ""run_mouse_rewards.py"", line 109, in <module>
    run()
  File ""run_mouse_rewards.py"", line 45, in run
    dqn.initialize()
  File ""/home/ai/Downloads/ScreenMouse/Organized/ba2c.py"", line 232, in initialize
    self.actor.compile(loss=self.actor_loss, optimizer = self.optimizer)
  File ""/home/ai/anaconda3/envs/drl/lib/python3.6/site-packages/tensorflow/python/training/checkpointable/base.py"", line 442, in _method_wrapper
    method(self, *args, **kwargs)
  File ""/home/ai/anaconda3/envs/drl/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py"", line 449, in compile
    output_loss = weighted_loss(y_true, y_pred, sample_weight, mask)
  File ""/home/ai/anaconda3/envs/drl/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_utils.py"", line 647, in weighted
    score_array = fn(y_true, y_pred)
  File ""/home/ai/Downloads/ScreenMouse/Organized/ba2c.py"", line 87, in siamese_loss
    self.loss = self.siamese_net.predict([self.y_true, self.y_pred])
  File ""/home/ai/anaconda3/envs/drl/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py"", line 1113, in predict
    self, x, batch_size=batch_size, verbose=verbose, steps=steps)
  File ""/home/ai/anaconda3/envs/drl/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py"", line 329, in model_iteration
    batch_outs = f(ins_batch)
  File ""/home/ai/anaconda3/envs/drl/lib/python3.6/site-packages/tensorflow/python/keras/backend.py"", line 3168, in __call__
    [x.numpy() for x in outputs])
  File ""/home/ai/anaconda3/envs/drl/lib/python3.6/site-packages/tensorflow/python/keras/backend.py"", line 3168, in <listcomp>
    [x.numpy() for x in outputs])
AttributeError: 'Tensor' object has no attribute 'numpy'
```
",ZeroMaxinumXZ,b'backend:tensorflow stat:awaiting response type:bug/performance',2019-06-16T06:28:32Z,2019-06-20T08:23:39Z
12961,keras v 2.2.4-tf save model ValueError: Could not pack sequence.,"I am using tensorflow.keras on colab.research.google.com. It runs good till today.
I notice the tf version upgraded from 1.13 to 1.14.0-rc1, and tf.keras.__version__ is 2.2.4-tf.
I have trained the same model and saved well before. But now, when I call model.save( ... ), an error occurs like:

> 
<ipython-input-7-4c39570d6921> in ChkEvaluate()
     18         MinEvaLoss = EvLoss
     19         if EvLoss < 0.47:
---> 20             mo.save( DIR + 'model3_Rd' )
     21             Saved += 1
     22             print( '--------- model saved. ---------' )

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/network.py in save(self, filepath, overwrite, include_optimizer, save_format)
   1209     ```
   1210     """"""
-> 1211     saving.save_model(self, filepath, overwrite, include_optimizer, save_format)
   1212 
   1213   def save_weights(self, filepath, overwrite=True, save_format=None):

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/save.py in save_model(model, filepath, overwrite, include_optimizer, save_format)
    111           'or using `save_weights`.')
    112     hdf5_format.save_model_to_hdf5(
--> 113         model, filepath, overwrite, include_optimizer)
    114     return
    115 

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/hdf5_format.py in save_model_to_hdf5(model, filepath, overwrite, include_optimizer)
     97         {
     98             'class_name': model.__class__.__name__,
---> 99             'config': model.get_config()
    100         },
    101         default=serialization.get_json_type).encode('utf8')

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/network.py in get_config(self)
    991       model_inputs.append(
    992           tf_utils.ListWrapper([layer.name, new_node_index, tensor_index]))
--> 993     model_inputs = nest.pack_sequence_as(self._nested_inputs, model_inputs)
    994     # Preserve external Keras compat for Models with single input.
    995     if not nest.is_sequence(model_inputs):

/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py in pack_sequence_as(structure, flat_sequence, expand_composites)
    447           ""Could not pack sequence. Structure had %d elements, but ""
    448           ""flat_sequence had %d elements.  Structure: %s, flat_sequence: %s."" %
--> 449           (len(flat_structure), len(flat_sequence), structure, flat_sequence))
    450   return _sequence_like(structure, packed)
    451 

ValueError: Could not pack sequence. Structure had 21 elements, but flat_sequence had 1 elements.  Structure: [<tf.Tensor 'tshare_1:0' shape=(?, 240, 1) dtype=float32>, <tf.Tensor 'm_5_1:0' shape=(?, 3, 20, 1) dtype=float32>, <tf.Tensor 'm_15_1:0' shape=(?, 3, 20, 1) dtype=float32>, <tf.Tensor 'm_60_1:0' shape=(?, 3, 20, 1) dtype=float32>, <tf.Tensor 'm_240_1:0' shape=(?, 3, 20, 1) dtype=float32>, <tf.Tensor 'm1680_1:0' shape=(?, 3, 20, 1) dtype=float32>, <tf.Tensor 'm4800_1:0' shape=(?, 3, 20, 1) dtype=float32>, <tf.Tensor 'r15_1:0' shape=(?, 3, 15, 1) dtype=float32>, <tf.Tensor 'r60_1:0' shape=(?, 3, 15, 1) dtype=float32>, <tf.Tensor 'r240_1:0' shape=(?, 3, 15, 1) dtype=float32>, <tf.Tensor 'r1680_1:0' shape=(?, 3, 15, 1) dtype=float32>, <tf.Tensor 'r4800_1:0' shape=(?, 3, 15, 1) dtype=float32>, <tf.Tensor 'indik15_1:0' shape=(?, 3, 13, 1) dtype=float32>, <tf.Tensor 'indik60_1:0' shape=(?, 3, 13, 1) dtype=float32>, <tf.Tensor 'indik240_1:0' shape=(?, 3, 13, 1) dtype=float32>, <tf.Tensor 'indik1680_1:0' shape=(?, 3, 13, 1) dtype=float32>, <tf.Tensor 'indik4800_1:0' shape=(?, 3, 13, 1) dtype=float32>, <tf.Tensor 'ks_1:0' shape=(?, 60) dtype=float32>, <tf.Tensor 'dayinfo_1:0' shape=(?, 4) dtype=float32>, <tf.Tensor 'maday_1:0' shape=(?, 5, 10, 1) dtype=float32>, <tf.Tensor 'polyline_1:0' shape=(?, 20, 4, 1) dtype=float32>], flat_sequence: [<tensorflow.python.keras.utils.tf_utils.ListWrapper object at 0x7f44949ea2b0>].",saintthor,b'backend:tensorflow stat:awaiting response type:bug/performance',2019-06-14T14:59:49Z,2019-07-09T16:19:18Z
12959,tf.keras.Model.evaluate skews score in custom tf.keras.callbacks.Callback,"**System information**  
- Have I written custom code (as opposed to using example directory): YES
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  Ubuntu 18.04.2 LTS
- TensorFlow backend (yes / no):  YES
- TensorFlow version:  2.0.0-dev20190601
- Keras version:  2.2.4-tf
- Python version:  3.6
- CUDA/cuDNN version:  7.3.1
- GPU model and memory:  4 GeForce GTX 1080 w/8119MiB

**Describe the current behavior**  
I am using the TensorFlow Dataset api with the Keras Model.fit function. When `x` is a Dataset (and therefor no `y` is provided), an error is thrown if we provide a `batch_size` argument. However, a `batch_size` is required is we want to use `validation_data` (I would already classify this as an error).

So, I wrote my own custom callback to perform a call to Model.evaluate with the validation dataset I had already prepared after every `n`-th batch and after every single epoch. 

During training, at, say, step 1000 (and before the first epoch), the accuracy reported by Tensorboard (I use the Tensorboard Keras callback for train loss and accuracy), as well as the accuracy reported by the metrics display next to the progress bar, might be at ~19%. 

However, after the CustomCallback runs it's function on_batch_end(self, batch, logs=None) and a call to self.model.evaluate is made, the training accuracy displayed by the progress bar and by Tensorboard picks up where the validation accuracy left off. That is, if val accuracy happened to be ~28% (higher due to no Dropout), then the training metric would also read 28% from then on.

**Describe the expected behavior**  
Calling the model's evaluate function from within a custom callback should not change what is displayed for train accuracy. Also, built-in Dataset validation would be nice.

**Code to reproduce the issue**  

This is the custom callback. Instantiating this callback with a subdirectory for valdiation events and a Dataset instance, and then including this callback in a call to model.fit should reproduce the error. I invite you to provide the data. I am abandoning the Keras Model.fit pipeline for now due to time constraints but I thought I would still log the error. 

For this bug to be noticeable, the training accuracy must be noticeably lower due to dropout than the val acc. (the color is blue but this is train accuracy, I promise. The jump is at step 1000, at which point Model.evaluate was called).

![batch_acc](https://user-images.githubusercontent.com/11124194/59510020-efcca580-8eb2-11e9-8a3f-0261d69e4fdd.png)

`
class Validation(tf.keras.callbacks.Callback):
    
    def __init__(self, log_dir, dataset, *args, **kwargs):
        self.dataset = dataset
        self.writer = tf.summary.create_file_writer(f""{log_dir}/validation"")

    def on_train_begin(self, logs=None):
        self.history = {}
        self.step = 0

    def on_batch_end(self, batch, logs=None):
        self.step += 1
        if self.step % Config.val_log_freq == 0:
            metrics = self.model.evaluate(self.dataset, verbose=0)
            for k, v in zip(self.model.metrics_names, metrics):
                with self.writer.as_default():
                    tf.summary.scalar(f""batch_{k}"", v, step=self.step)
            self.writer.flush()
        
    def on_epoch_end(self, epoch, logs=None):
        metrics = self.model.evaluate(self.dataset, verbose=0)
        for k, v in zip(self.model.metrics_names, metrics):
            self.history.setdefault(k, []).append(v)
            with self.writer.as_default():
                tf.summary.scalar(f""epoch_{k}"", v, step=self.step)
        self.writer.flush()
            
validation_callback = Validation(log_dir, valid_dataset)`

**Other info / logs**  
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.  
",jkamalu,b'backend:tensorflow type:bug/performance',2019-06-14T12:50:12Z,2019-06-24T22:17:06Z
12931,ValueError: Tried to convert 'shape' to a tensor and failed. Error: None values not supported.,"```
def build_model(input_shape, num_classes):
    x = Input(input_shape)
    x = Embedding(10000, 64)(x)#, input_length=28)(x)
    print(x.shape)
    #x = Bidirectional(GRU(14, input_shape=(28, 64), return_sequences=True))(x)
    x = Bidirectional(GRU(14, return_sequences=True))(x)
    print(x.shape)
    #forw = GRU(14, return_sequences=True)(x)
    #forw = GRU(14)(forw)
    #back = GRU(14, return_sequences=True, go_backwards=True)(x)
    #back = GRU(14, go_backward=True)(x)
    #y = Concatenate(-1)([forw, back])
    y = Reshape((None,28,28,1))(x)
    y = Conv2D(32, (3, 3), activation='relu')(y)
    y = MaxPooling2D((2,2))(y)
    y = Conv2D(64, (3, 3), activation='relu')(y)
    y = MaxPooling2D((2,2))(y)
    y = Flatten()(y)
    y = Dense(num_classes, activation='softmax')(y)
    return Model(x,y)

```

Hi there, I am trying to build this model ,but the error returns as follow:
```
(?, 28, 64)
(?, ?, 28)

ValueErrorTraceback (most recent call last)
<ipython-input-16-66bdf6604ccd> in <module>()
    105 
    106 
--> 107 model = build_model(image_shape, num_classes)
    108 
    109 model.summary()

5 frames
/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.pyc in _apply_op_helper(self, op_type_name, name, **keywords)
    526               raise ValueError(
    527                   ""Tried to convert '%s' to a tensor and failed. Error: %s"" %
--> 528                   (input_name, err))
    529             prefix = (""Input '%s' of '%s' Op has type %s that does not match"" %
    530                       (input_name, op_type_name, observed))

ValueError: Tried to convert 'shape' to a tensor and failed. Error: None values not supported.
```

I print the shape of the data after word embedding and gru. The shape of the output gru is (?,?,28) which is so wierd. Can anyone give some hints? Thanks.",dzhao123,b'backend:tensorflow stat:awaiting response type:bug/performance',2019-06-07T21:33:28Z,2019-06-21T23:05:41Z
12929,Unable to release GPU memory after training Keras model ,"In order to preform a object detection like task, I used a CNN. I am using a custom generator that follows this [example](https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly)

My machine is a MacOS High Sierra 10.13.6, yet I am running my code using Google Colab's GPU so my machine's performances has nothing to do with the issue(right ?). It should be noted that I have tested my code on another platform (FloydHub's Tesla K80 GPU) and had the same problem.

I am using 
- Keras 2.2.4
- Tensorflow backend 1.13.1  
- Python (3.7)
- CUDA release 10.1, V10.1.168
- GPU model and memory:  Tesla K80 (up to my knowledge, this is what google uses on Colab) 

I run out of GPU memory quickly, when passing my model's training in a for loop (looking for optimal hyper-parameters) the program stops on **Out Of Memory Error** after the first iteration. Before the beginning of the first epoch and shortly before the loading arrow for the first epoch appears, the GPU usage jumps to a value of 98%. I put a **gc.collect()** , **del model** and **K.clear_session()** in the end of my training in order to release memory for the next model but it seems to have no effect on GPU which remains at 98% before eventually crashing my notebook.  
```
---------------------------------------------------------------------------
ResourceExhaustedError                    Traceback (most recent call last)
<ipython-input-75-31b4f9e0b883> in <module>()
     15 models={}
     16 compile_model(model,OPTIMIZER,LOSS,METRICS,LR,MOMENTUM,DECAY)
---> 17 allinone2(Hist,model,Data,VAL_SPLIT,OPTIMIZER,LOSS,METRICS,LR,MOMENTUM,DECAY,BATCH_SIZE,EPOCHS,PARAMS,True)

9 frames
<ipython-input-71-125d04498229> in allinone2(Hist, model, Data, validation_split, optimizer, loss, metric, lr, momentum, decay, batch_size, epochs, params, showbboxs)
      2   if TPU :
      3       model = tf.contrib.tpu.keras_to_tpu_model(model,strategy=tf.contrib.tpu.TPUDistributionStrategy(tf.contrib.cluster_resolver.TPUClusterResolver(TPU_WORKER)))
----> 4   train_gen,validation_gen,Hist = fit(model,Hist,Data,VAL_SPLIT,BATCH_SIZE,EPOCHS,PARAMS)
      5   Save_model(SAVE_DIR,name_json=""model"",nameh5=""model"",save=SAVE_MODEL)
      6   training_results(Hist,str(validation_split)+str(batch_size)+str(epochs),savefig=SAVE_FIG)

<ipython-input-64-efd2c5419ad6> in fit(model, Hist, Data, validation_split, batch_size, epochs, params)
     17                    validation_steps = lenvalidation // batch_size,
     18                    callbacks=[Hist],
---> 19                    validation_data = validation_gen
     20                    ) 
     21 

/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py in wrapper(*args, **kwargs)
     89                 warnings.warn('Update your `' + object_name + '` call to the ' +
     90                               'Keras 2 API: ' + signature, stacklevel=2)
---> 91             return func(*args, **kwargs)
     92         wrapper._original_function = func
     93         return wrapper

/usr/local/lib/python3.6/dist-packages/keras/engine/training.py in fit_generator(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)
   1416             use_multiprocessing=use_multiprocessing,
   1417             shuffle=shuffle,
-> 1418             initial_epoch=initial_epoch)
   1419 
   1420     @interfaces.legacy_generator_methods_support

/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py in fit_generator(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)
    215                 outs = model.train_on_batch(x, y,
    216                                             sample_weight=sample_weight,
--> 217                                             class_weight=class_weight)
    218 
    219                 outs = to_list(outs)

/usr/local/lib/python3.6/dist-packages/keras/engine/training.py in train_on_batch(self, x, y, sample_weight, class_weight)
   1215             ins = x + y + sample_weights
   1216         self._make_train_function()
-> 1217         outputs = self.train_function(ins)
   1218         return unpack_singleton(outputs)
   1219 

/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py in __call__(self, inputs)
   2713                 return self._legacy_call(inputs)
   2714 
-> 2715             return self._call(inputs)
   2716         else:
   2717             if py_any(is_tensor(x) for x in inputs):

/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py in _call(self, inputs)
   2673             fetched = self._callable_fn(*array_vals, run_metadata=self.run_metadata)
   2674         else:
-> 2675             fetched = self._callable_fn(*array_vals)
   2676         return fetched[:len(self.outputs)]
   2677 

/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py in __call__(self, *args, **kwargs)
   1437           ret = tf_session.TF_SessionRunCallable(
   1438               self._session._session, self._handle, args, status,
-> 1439               run_metadata_ptr)
   1440         if run_metadata:
   1441           proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)

/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/errors_impl.py in __exit__(self, type_arg, value_arg, traceback_arg)
    526             None, None,
    527             compat.as_text(c_api.TF_Message(self.status.status)),
--> 528             c_api.TF_GetCode(self.status.status))
    529     # Delete the underlying status object from memory otherwise it stays alive
    530     # as there is a reference to status from this from the traceback due to

ResourceExhaustedError: OOM when allocating tensor with shape[3114176,32] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc
	 [[{{node training_3/Adam/gradients/dense_17/MatMul_grad/MatMul_1}}]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.
```
I should be able to free the GPU memory in order to run my tests, It should be noted that my dataset has 1000 images of 800x1000 shape.    

A snippet of the code that causes the problem (.ipynb => .py) :
````
!pip install gputil
!pip install psutil
!pip install humanize
#Imports ...

def penalty(y_true, y_pred):
    a = tf.placeholder(tf.float64)
    p = 20
    loss = K.switch(tf.less(y_true - y_pred, 0.1), K.square(y_true - y_pred) , p * K.square(y_true - y_pred))
    return K.max(loss)
  
def cusloss(y_true,y_pred): 
    return K.mean(K.equal(K.round(100*y_pred , 100*y_true)),tf.zeros_like(y_pred))

# Global parameters
IMG_SIZE = 800,1000,3
BATCH_SIZEs = [4,8,16,32]
EPOCHSs = [10]
PARAMSs = [{""rotation"":20,""scale"":0.1,""shear"":0.1,""translate"":0.1,""scale"":0.1}]
OPTIMIZERs = ['adam']
LOSSEs = [penalty]
METRICSs = [[cusloss,penalty,losses.msle,losses.mae,losses.mse,losses.logcosh]]
LRs = [0.01,0.005]
MOMENTUMs = [0.05,0.1]
DECAYs = [0.2]
VAL_SPLITs = [0.2]

def load_data(*args):
    ...
    return Data

class Generator(keras.utils.Sequence):
    
    def __init__(self, Data, params ,batch_size):
        """"""Initials an image generator""""""
        self.x = col(Data,0,1) 
        self.y = np.array(col(Data,1,5))
        self.batch_size = batch_size
        self.params = params
        self.on_epoch_end()

    def __len__(self):
        """"""Our generator's length""""""
        return int(np.ceil(len(self.x) / float(self.batch_size)))

    def __getitem__(self, idx):
        """""" __getitem__ gives access to an item of our generator which will be a batch of BATCH_SIZE size. It is called via the brackets []""""""
        images_list = self.x
        bboxes = self.y
        batch_size =  self.batch_size
        w,h = IMG_SIZE[:2]
        required_transformations = self.params.keys()
        
        # Generate indexes of the batch
        indexes = self.indexes[idx*self.batch_size:(idx+1)*self.batch_size]
        if sum(indexes) == 0 :        # check if indexes is empty
          return None
        
        # extracting BATCH_SIZE images from the dataset
        x_temp = [self.x[i]  for i in indexes]
        y_temp = np.array([self.y[i,] for i in indexes])
        
        # shuffling our batch's elements
        Ids,y0 = sklearn.utils.shuffle(x_temp,y_temp)
        
        # Initiate our batchs
        X = np.zeros((batch_size,h,w,1))
        y = np.zeros((batch_size,4))
      
        for i,image in enumerate(Ids) :
            image = image[0]
            try : 
                img = cv2.imread(""scans/""+image+"".png"")
            except : 
                print(""Unable to read %s""%(image))
                img = None

            # Starting preprocessing
            if not (img is None) : 
                img = cv2.resize(img,(w,h))
                bbox = y0[i,]
                try :
                    X[i,:,:,:] = np.expand_dims(rgb2gray(img_),axis=2)
                    y[i,:] = bboxes_

                except Exception as exc:
                    # Prints the error without stoping the process
                    print(""Error found at index %d""%(i))
                    print(traceback.format_exc())
                    print(exc)

            else : 
                print(""%s is None""%(image))
        return X,y
    
    def on_epoch_end(self):
        'Updates indexes after each epoch'
        self.indexes = np.arange(len(self.x))
        np.random.shuffle(self.indexes)

def fit(model,Hist,Data,validation_split,batch_size,epochs,params):
  """""" Fits our input to the output""""""
  n = len(Data)
  lenvalidation = int(validation_split*n)
  lentrain =  n - lenvalidation
  train_set = sklearn.utils.shuffle(Data[:lentrain])
  validation_set = sklearn.utils.shuffle(Data[lentrain:])
  train_gen = Generator(train_set,params,batch_size)
  validation_gen = Generator(validation_set,params,batch_size)
  
  print(""starting training..."")
  model.fit_generator(train_gen,
                   steps_per_epoch = lentrain // batch_size,
                   epochs=epochs,
                   validation_steps = lenvalidation // batch_size,
                   callbacks=[Hist],
                   validation_data = validation_gen
                   ) 

  return train_gen,validation_gen,Hist

def create_model():
  # History initialisation
  Hist = History()
  # Defining the architecture of our CNN based NN 
  model = Sequential()
  model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(IMG_SIZE[1],IMG_SIZE[0],1)))
  model.add(MaxPooling2D(pool_size=(2, 2),strides=(2,2)))
  model.add(Dropout(0.25))
  model.add(Conv2D(64, kernel_size=(5, 5), activation='relu'))
  model.add(MaxPooling2D(pool_size=(2, 2),strides=(2,2)))
  model.add(Dropout(0.3))
  model.add(Flatten())
  model.add(Dense(32, activation='relu'))
  model.add(Dropout(0.3))
  model.add(Dense(4))
  return Hist,model

def compile_model(model,optimize,loss,metric,lr,momentum,decay):
  # Compiles the model  
  run_opts = tf.RunOptions(report_tensor_allocations_upon_oom = True)
  model.compile(optimizer=optimize , loss = loss, metrics = metric, options = run_opts)

  # Define optimizers
  K.set_value(model.optimizer.lr, lr)
  K.set_value(model.optimizer.decay, decay)
  try :
      K.set_value(optimizer.momentum, momentum) 
  except :
    pass

def allinone(Hist,model,Data,validation_split,optimizer,loss,metric,lr,momentum,decay,batch_size,epochs,params) : 
  compile_model(model,optimizer,loss,metric,lr,momentum,decay)
  train_gen,validation_gen,Hist = fit(model,Hist,Data,VAL_SPLIT,BATCH_SIZE,EPOCHS,PARAMS)
  torch.cuda.empty_cache()
  del model 
  gc.collect()
  K.clear_session()

def printmm(y_true=0,y_pred=0):
  GPUs = GPUtil.getGPUs()
  gpu = GPUs[0]
  print(GPUtil.showUtilization())
  return(tf.Variable(gpu.memoryUtil*100))

# The Ultimate test
Data = load_data()
Hist,model = create_model()
for EPOCHS in EPOCHSs:
  for BATCH_SIZE in BATCH_SIZEs:
    for PARAMS in PARAMSs :
      for OPTIMIZER in OPTIMIZERs:
        for LOSS in LOSSEs :
          for METRICS in METRICSs:
            for LR in LRs :
              for MOMENTUM in MOMENTUMs:
                for DECAY in DECAYs:
                  for VAL_SPLIT in VAL_SPLITs :
                    allinone(Hist,model,Data,VAL_SPLIT,OPTIMIZER,LOSS,METRICS,LR,MOMENTUM,DECAY,BATCH_SIZE,EPOCHS,PARAMS)

",YKritet,b'backend:tensorflow stat:awaiting response type:bug/performance',2019-06-07T14:34:36Z,2019-07-16T00:02:21Z
12923,Unable to release GPU memory after training a model (OOM),"Hi, 
On a Google Colab notebook with keras(2.2.4) and tensorflow(1.13.1) as a backend, I am trying to tune a CNN, I use a simple and basic table of hyper-parameters and run my tests in a set of loops. 
My problem is that I can't free the GPU memory after each iteration and Keras doesn't seem to be able to release GPU memory automatically. So every time I get a **Ressource Exhausted : Out Of Memory (OOM)**
I did some digging up and run into this function that reassembles different solutions that have been suggested to solve this problem (didn't work for me though) : 
```python
def reset_keras():
    sess = get_session()
    clear_session()
    sess.close()
    sess = get_session()

    try:
        del model # this is from global space - change this as you need
    except:
        pass

    print(gc.collect()) # if it's done something you should see a number being outputted

    # use the same config as you used to create the session
    config = tf.ConfigProto()
    config.gpu_options.per_process_gpu_memory_fraction = 1
    config.gpu_options.visible_device_list = ""0""
    set_session(tf.Session(config=config))
```
The only thing that i didn't fully grasp is the ""*same config as you used to create your model* "" since with Keras we don't chose explicitly a certain configuration. I get by for one iteration, some times two, but I can't go beyond. I already tried to change the batch_size and for the moment I am unable to afford for a machine with higher performances.",YKritet,b'backend:tensorflow stat:awaiting response type:bug/performance',2019-06-06T11:38:37Z,2019-06-10T12:52:32Z
12899,"BugFix of ""AttributeError: 'ProgbarLogger' object has no attribute 'target'"" (or 'log_values') error (#12898) (#12893) (#8944)","This Change set is fixing two missing attribute bugs in `callback.ProgbarLogger` class
* AttributeError: 'ProgbarLogger' object has no attribute 'target' #12898
  Abstract reproduction scenario is provided in ticket
* AttributeError: 'ProgbarLogger' object has no attribute 'log_values' #3657
* AttributeError: 'ProgbarLogger' object has no attribute 'log_values' #8944 (dup)

Related changes:
* Cases of regression are covered by tests.
* Some potential bugs with same nature are prevented and covered by manifestation checks.
* run with empty data array (but having valid shape) is now handled properly
  and yielding related warnings on callback and training routine level without execution fail

Note:
Changes that affect `ProgbarLogger` should be aware of following things:
* proper target initialisation is requiring two attributes: `params` and `use_steps` to be defined
* `use_steps` is guaranteed attribute the is set in the constructor (but could be altered after object instantiation. It's currently safe condition.
* class `params` attribute could be altered between initialisation and training start. And current logic is made to be aware of this
* we don't have `params` initialisation in constructor, this attribute will be assigned on call of `set_params` of base class somewhere on caller level (no strict guarantees :( )
* `seen` attribute is working in pair with `target` during `log_values` initialisation and their initialisation should be under the equal condition, currently thats not true
* `if self.seen < self.target` condition is being checked whenever verbose mode value so both of them should be initialised without any conditions
* `if self.seen < self.target` is checking for training iteration being not finished but in case of degenerate case with zero length it will not be called and `log_values` will stay not initialised but i don't see any explicit logic preventing using it on exit from 0-length training cycle and potentially it is the bug of some kind that is prevented on caller logic level
* `progbar` attribute initialisation is definitely related to output verbosity (log values accumulation are not) and should be left under verbosity condition

<!--
Please make sure you've read and understood our contributing guidelines;
https://github.com/keras-team/keras/blob/master/CONTRIBUTING.md
-->

### Summary

### Related Issues

### PR Overview

- [x] This PR requires new unit tests [y/n] (make sure tests are included)
- [ ] This PR requires to update the documentation [y/n] (make sure the docs are up-to-date)
- [x] This PR is backwards compatible [y/n]
- [ ] This PR changes the current API [y/n] (all API changes need to be approved by fchollet)
",mrjj,None,2019-05-31T04:35:07Z,2019-09-11T21:31:22Z
12897,Run Default code for imdb_cnn.py it gives pickle-errors,"<em>Please make sure that this is a Bug or a Feature Request and provide all applicable information asked by the template.
If your issue is an **implementation question**, please ask your question on [StackOverflow](http://stackoverflow.com/questions/tagged/keras) or [on the Keras Slack channel](https://keras-slack-autojoin.herokuapp.com/) instead of opening a GitHub issue.</em>  

**System information**  
- Have I written custom code (as opposed to using example directory):  
>> I used the default code exactly as written.

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  
Microsoft Windows 10 Enterprise

- TensorFlow backend (yes / no): 
yes
 
- TensorFlow version:  
1.13.1

- Keras version:  
2.2.4

- Python version:  
Python 3.7.3

- CUDA/cuDNN version:  
None.  I'm using cpu-only vanilla keras installed by Anaconda. 

- GPU model and memory:  
NVidia Quadra P1000


**Describe the current behavior**  
It crashes when I hit F5 in Spyder.  It talks about pickle error.

```
using TensorFlow backend.
Loading data...
Traceback (most recent call last):

  File ""<ipython-input-1-4a5d5f4a1034>"", line 1, in <module>
    runfile('C:/work/imdb_cnn.py', wdir='c:/work')

  File ""C:\ProgramData\Anaconda3\envs\Step2\lib\site-packages\spyder_kernels\customize\spydercustomize.py"", line 827, in runfile
    execfile(filename, namespace)

  File ""C:\ProgramData\Anaconda3\envs\Step2\lib\site-packages\spyder_kernels\customize\spydercustomize.py"", line 110, in execfile
    exec(compile(f.read(), filename, 'exec'), namespace)

  File ""C:/work/imdb_cnn.py"", line 28, in <module>
    (x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)

  File ""C:\ProgramData\Anaconda3\envs\Step2\lib\site-packages\keras\datasets\imdb.py"", line 59, in load_data
    x_train, labels_train = f['x_train'], f['y_train']

  File ""C:\ProgramData\Anaconda3\envs\Step2\lib\site-packages\numpy\lib\npyio.py"", line 262, in __getitem__
    pickle_kwargs=self.pickle_kwargs)

  File ""C:\ProgramData\Anaconda3\envs\Step2\lib\site-packages\numpy\lib\format.py"", line 692, in read_array
    raise ValueError(""Object arrays cannot be loaded when ""

ValueError: Object arrays cannot be loaded when allow_pickle=False
```

**Describe the expected behavior**  

I would expect it to get to line 29 and print something about the training sequence count.

Line 28, where it is choking, is 
`(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)`

It doesn't get to print ""train sequences"" after attempting to load data, so it isn't getting past line 29.  

When I re-select line 28, and hit F9 (run highlighted) it gives the same error again.

**Code to reproduce the issue**  
You already have it.  It was literally copy-paste-run-crash

**Other info / logs**  
Traceback is included in what it did.
",EngrStudent,b'backend:tensorflow stat:awaiting response type:bug/performance',2019-05-30T17:33:28Z,2019-05-30T18:57:07Z
12877,keras.examples.cifar10_cnn.py  ignores batch_size in absence of data_augmentation,"
**System information**  
- Have I written custom code (as opposed to using example directory):  No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  Linux Ubuntu 18/04
- TensorFlow backend (yes / no):  yes
- TensorFlow version:  1.13.1
- Keras version:  2.2.4
- Python version:  2.7.16
- CUDA/cuDNN version:  10.1/7.6
- GPU model and memory:  1080M / 8GB

**Describe the current behavior**  
When `cifar10_cnn.py` is run without data_augmentation, it seems to ignore the fact that `batch_size` has been set to 32.

The training output appears as follows:

```
Epoch 1/100
50000/50000 [==============================] - 9s 172us/step - loss: 1.8029 - acc: 0.3383 - val_loss: 1.4823 - val_acc: 0.4573
Epoch 2/100
50000/50000 [==============================] - 7s 135us/step - loss: 1.4775 - acc: 0.4650 - val_loss: 1.3312 - val_acc: 0.5218

```

**Describe the expected behavior**  

It should appear this way (since 50000/32 = 1562)

```
Epoch 1/100
1562/1562 [==============================] - 16s 10ms/step - loss: 1.8887 - acc: 0.3054 - val_loss: 1.5615 - val_acc: 0.4398
Epoch 2/100
1562/1562 [==============================] - 14s 9ms/step - loss: 1.5818 - acc: 0.4231 - val_loss: 1.3624 - val_acc: 0.5110


```
**Code to reproduce the issue**  
Just run `cifar10_cnn.py`, after setting `data_augmentation` to `False`



**Other info / logs**  
I think the problem lies in the way `Progbar` and `ProgbarLogger` are called from `training_arrays.py` in the `fit_loop` method, where around line 110, we see:

```
    if verbose:
        if steps_per_epoch is not None:
            count_mode = 'steps'
        else:
            count_mode = 'samples'
        _callbacks.append(
            cbks.ProgbarLogger(
                count_mode,
                stateful_metrics=model.stateful_metric_names))

```
Where the assumption is that unless `steps_per_batch` is specified, we are counting samples, rather than steps (i.e. batches). This assumption is transferred to the `__init__` method of `ProgbarLogger`, which then transfers it to `Progbar`. My assumption is that if the creation of `Progbar` is prone to this error, then the actual training might be too, but I haven't verified that.

I'd assume that the fix would be to find all the places where `steps_per_epoch` is used to see if mini-batches are being used in training. For now, I think the best quick/dirty fix is to **always** specify `steps_per_epoch` in a manner consistent with `batch_size` 
",smgutstein,b'backend:tensorflow stat:awaiting response type:bug/performance',2019-05-27T03:07:40Z,2019-07-08T21:45:49Z
12872,`AttributeError: 'InputLayer' object has no attribute 'outbound_nodes'`,"I followed the keras blog https://blog.keras.io/using-pre-trained-word-embeddings-in-a-keras-model.html on word embeddings. When reaching this point of the tutorial:
```python
from keras.layers import Input
embedding_layer = Embedding(len(word_index) + 1,EMBEDDING_DIM,weights=[embedding_matrix],input_length=MAX_SEQUENCE_LENGTH,
                            trainable=False)
sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')
embedded_sequences = embedding_layer(sequence_input)
```
I experience a crash:
`'AttributeError: 'InputLayer' object has no attribute 'outbound_nodes''`

**System information**  
- Code taken from:  https://blog.keras.io/using-pre-trained-word-embeddings-in-a-keras-model.html
- OS Platform and Distribution: Outdated version of scientific linux, used anaconda to fetch packages
- TensorFlow backend (yes / no):  yes
- TensorFlow version:  1.13.1 
- Keras version:  2.2.4 
- Python version:  3.7.3
- CUDA/cuDNN version:  not available
- GPU model and memory:  no GPU

**Describe the current behavior**  
`AttributeError: 'InputLayer' object has no attribute 'outbound_nodes'`
**Describe the expected behavior**  
it doesn't crash
**Code to reproduce the issue**  
Provide a reproducible test case that is the bare minimum necessary to generate the problem.  

**Other info / logs**  
Traceback:
```python
AttributeError                            Traceback (most recent call last)
<ipython-input-16-fd4b0bbd5a48> in <module>
      3                             trainable=False)
      4 sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')
----> 5 embedded_sequences = embedding_layer(sequence_input)
      6 x = Conv1D(128, 5, activation='relu')(embedded_sequences)
      7 x = MaxPooling1D(5)(x)

~/share/new_conda_for_me/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py in __call__(self, inputs, *args, **kwargs)
    582           if base_layer_utils.have_all_keras_metadata(inputs):
    583             inputs, outputs = self._set_connectivity_metadata_(
--> 584                 inputs, outputs, args, kwargs)
    585           if hasattr(self, '_set_inputs') and not self.inputs:
    586             # Subclassed network: explicitly set metadata normally set by

~/share/new_conda_for_me/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py in _set_connectivity_metadata_(self, inputs, outputs, args, kwargs)
   1414     kwargs.pop('mask', None)  # `mask` should not be serialized.
   1415     self._add_inbound_node(
-> 1416         input_tensors=inputs, output_tensors=outputs, arguments=kwargs)
   1417     return inputs, outputs
   1418 

~/share/new_conda_for_me/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py in _add_inbound_node(self, input_tensors, output_tensors, arguments)
   1522         input_tensors=input_tensors,
   1523         output_tensors=output_tensors,
-> 1524         arguments=arguments)
   1525 
   1526     # Update tensor history metadata.

~/share/new_conda_for_me/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py in __init__(self, outbound_layer, inbound_layers, node_indices, tensor_indices, input_tensors, output_tensors, arguments)
   1740         # For compatibility with external Keras, we use the deprecated
   1741         # accessor here.
-> 1742         layer.outbound_nodes.append(self)
   1743     # For compatibility with external Keras, we use the deprecated
   1744     # accessor here.

AttributeError: 'InputLayer' object has no attribute 'outbound_nodes'```",luciasalar,b'backend:tensorflow type:bug/performance',2019-05-25T22:39:56Z,2020-06-02T15:43:12Z
12765,Bug in engine/training_arrays while calling call_begin_hook,"fit_loop() method is  calling callback to like ``` callbacks._call_begin_hook('train') ``` but method expects different format as ```_TRAIN```.
```
    def _call_begin_hook(self, mode):
        """"""Helper function for on_{train|test|predict}_begin methods.""""""
        if mode == _TRAIN:
            self.on_train_begin()
        elif mode == _TEST:
            self.on_test_begin()
        else:
            self.on_predict_begin()
```
",mayurnewase,None,2019-04-29T02:22:44Z,2019-04-29T02:23:12Z
12709,I can not load the MobileNet network. ,"This worked fine couple of days ago but today I could not load a base model of the MobileNet getting this error with the traceback below. Also if I use tensorflow.keras instead of simply keras, everywhere in the notebook, this works fine and the model gets loaded. But I need to run it in keras for now. 

import numpy as np
import keras
from keras import backend as K
from keras.layers.core import Dense, Activation
from keras.optimizers import Adam
from keras.metrics import categorical_crossentropy
from keras.preprocessing.image import ImageDataGenerator
from keras.preprocessing import image
from keras.models import Model
from keras.applications import imagenet_utils
from sklearn.metrics import confusion_matrix
import itertools
import matplotlib.pyplot as plt
%matplotlib inline

mobile = keras.applications.mobilenet.MobileNet() #this is where it fails

---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
<ipython-input-2-a135d4b4ac1c> in <module>
----> 1 mobile = keras.applications.mobilenet.MobileNet()

~/anaconda3/envs/python3.6/lib/python3.6/site-packages/keras/applications/__init__.py in wrapper(*args, **kwargs)
     26             kwargs['models'] = models
     27             kwargs['utils'] = utils
---> 28         return base_fun(*args, **kwargs)
     29 
     30     return wrapper

~/anaconda3/envs/python3.6/lib/python3.6/site-packages/keras/applications/mobilenet.py in MobileNet(*args, **kwargs)
      9 @keras_modules_injection
     10 def MobileNet(*args, **kwargs):
---> 11     return mobilenet.MobileNet(*args, **kwargs)
     12 
     13 

~/anaconda3/envs/python3.6/lib/python3.6/site-packages/keras_applications/mobilenet.py in MobileNet(input_shape, alpha, depth_multiplier, dropout, include_top, weights, input_tensor, pooling, classes, **kwargs)
    231 
    232     if input_tensor is None:
--> 233         img_input = layers.Input(shape=input_shape)
    234     else:
    235         if not backend.is_keras_tensor(input_tensor):

~/anaconda3/envs/python3.6/lib/python3.6/site-packages/keras/engine/input_layer.py in Input(shape, batch_shape, name, dtype, sparse, tensor)
    176                              name=name, dtype=dtype,
    177                              sparse=sparse,
--> 178                              input_tensor=tensor)
    179     # Return tensor including _keras_shape and _keras_history.
    180     # Note that in this case train_output and test_output are the same pointer.

~/anaconda3/envs/python3.6/lib/python3.6/site-packages/keras/legacy/interfaces.py in wrapper(*args, **kwargs)
     89                 warnings.warn('Update your `' + object_name + '` call to the ' +
     90                               'Keras 2 API: ' + signature, stacklevel=2)
---> 91             return func(*args, **kwargs)
     92         wrapper._original_function = func
     93         return wrapper

~/anaconda3/envs/python3.6/lib/python3.6/site-packages/keras/engine/input_layer.py in __init__(self, input_shape, batch_size, batch_input_shape, dtype, input_tensor, sparse, name)
     37         if not name:
     38             prefix = 'input'
---> 39             name = prefix + '_' + str(K.get_uid(prefix))
     40         super(InputLayer, self).__init__(dtype=dtype, name=name)
     41 

~/anaconda3/envs/python3.6/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py in get_uid(prefix)
     72     """"""
     73     global _GRAPH_UID_DICTS
---> 74     graph = tf.get_default_graph()
     75     if graph not in _GRAPH_UID_DICTS:
     76         _GRAPH_UID_DICTS[graph] = defaultdict(int)

AttributeError: module 'tensorflow' has no attribute 'get_default_graph'",rachita97,b'backend:tensorflow type:bug/performance',2019-04-21T21:02:56Z,2019-05-07T15:50:16Z
12594,NameError: name 'embed' is not defined,"Please make sure that the boxes below are checked before you submit your issue.
If your issue is an **implementation question**, please ask your question on [StackOverflow](http://stackoverflow.com/questions/tagged/keras) or [on the Keras Slack channel](https://keras-slack-autojoin.herokuapp.com/) instead of opening a GitHub issue.

Thank you!

- [x] Check that you are up-to-date with the master branch of Keras. You can update with:
`pip install git+git://github.com/keras-team/keras.git --upgrade --no-deps`

- [x] Check that your version of TensorFlow is up-to-date. The installation instructions can be found [here](https://www.tensorflow.org/get_started/os_setup).

- [x] Provide a link to a GitHub Gist of a Python script that can reproduce your issue (or just copy the script here if it is short).




I'm working on Keras model which uses Universal Sentence Embedding to encode the provided sentences. However, when I save the model for future usage, the mentioned error is thrown. NameError: name 'embed' is not defined

The sentences are converted to embedding using UniversalEmbedding(x) function. The code of whole model is taken from this link.

```
!wget https://raw.githubusercontent.com/Tony607/Keras-Text-Transfer-Learning/master/train_5500.txt
!wget https://raw.githubusercontent.com/Tony607/Keras-Text-Transfer-Learning/master/test_data.txt

import tensorflow as tf
import tensorflow_hub as hub
import matplotlib.pyplot as plt
import numpy as np
import os
import pandas as pd
import re
import seaborn as sns
import keras.layers as layers
from keras.models import Model
from keras import backend as K
np.random.seed(10)

def get_dataframe(filename):
    lines = open(filename, 'r').read().splitlines()
    data = []
    for i in range(0, len(lines)):
        label = lines[i].split(' ')[0]
        label = label.split("":"")[0]
        text = ' '.join(lines[i].split(' ')[1:])
        text = re.sub('[^A-Za-z0-9 ,\?\'\""-._\+\!/\`@=;:]+', '', text)
        data.append([label, text])

    df = pd.DataFrame(data, columns=['label', 'text'])
    df.label = df.label.astype('category')
    return df

df_train = get_dataframe('train_5500.txt')
df_train = get_dataframe('test_data.txt')

category_counts = len(df_train.label.cat.categories)
module_url = ""https://tfhub.dev/google/universal-sentence-encoder-large/3"" 
embed = hub.Module(module_url)
embed_size = embed.get_output_info_dict()['default'].get_shape()[1].value

def UniversalEmbedding(x):
    return embed(tf.squeeze(tf.cast(x, tf.string)), signature=""default"", as_dict=True)[""default""]

input_text = layers.Input(shape=(1,), dtype='string')
embedding = layers.Lambda(UniversalEmbedding, output_shape=(embed_size,))(input_text)
dense = layers.Dense(256, activation='relu')(embedding)
pred = layers.Dense(category_counts, activation='softmax')(dense)
model = Model(inputs=[input_text], outputs=pred)
model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

train_text = df_train['text'].tolist()
train_text = np.array(train_text, dtype=object)[:, np.newaxis]

train_label = np.asarray(pd.get_dummies(df_train.label), dtype = np.int8)

df_test = get_dataframe('test_data.txt')
test_text = df_test['text'].tolist()
test_text = np.array(test_text, dtype=object)[:, np.newaxis]
test_label = np.asarray(pd.get_dummies(df_test.label), dtype = np.int8)


with tf.Session() as session:
  K.set_session(session)
  session.run(tf.global_variables_initializer())
  session.run(tf.tables_initializer())
  history = model.fit(train_text, 
            train_label,
            validation_data=(test_text, test_label),
            epochs=2,
            batch_size=32)
  model.save_weights('./model.h5')
  model.save('mod.h5')
```

When I try to load the model like

```
from keras.models import load_model

load_model('mod.h5') 
```


",bhaskar-dhariyal,b'backend:tensorflow stat:awaiting tensorflower type:bug/performance',2019-04-01T13:19:07Z,2020-01-31T22:19:22Z
12592,"After training the model of InceptionV3 ,  how to modify the  Atrribute of 'FusedBatchNorm' from 'is_training:True'  to 'is_training:False' ?","After I  trained the model and convert it from '.model' to '.pb'  by keras ,  I found the Attribute of  node named 'FusedBatchNorm'  is 'is_training : True',   so  I add the code to  modify  the attribute from True to False,  but it  did not work,   is there anyone helping me ?

My .pb graph shows as follows, (the attribute 'is_training' of FusedBatchNorm is True )
<img width=""915"" alt=""360截图18141217433342"" src=""https://user-images.githubusercontent.com/14754815/55325327-4c751280-54b7-11e9-9b72-ac1da5ee68f2.png"">


My convertion code from '.hdf5' to '.pb' is as follows  :
`def h5_to_pb(h5_model,output_dir,model_name,out_prefix = ""output_"",log_tensorboard = True):

    if osp.exists(output_dir) == False:
        os.mkdir(output_dir)
        
    out_nodes = []
    for i in range(len(h5_model.outputs)):
        out_nodes.append(out_prefix + str(i + 1))
        tf.identity(h5_model.output[i],out_prefix + str(i + 1))

    from tensorflow.python.framework import graph_util,graph_io
    sess = K.get_session()
    init_graph = sess.graph.as_graph_def()

    **for i in range(len(init_graph.node)):
        node = init_graph.node[i]
        print('node %d :'%i) 
        print (node)
        if node.op == 'FusedBatchNorm':
            if 'is_training' in node.attr: 
                node.attr['is_training'] = False**
    main_graph = graph_util.convert_variables_to_constants(sess,init_graph,out_nodes)
    graph_io.write_graph(main_graph,output_dir,name = model_name,as_text = False)`


when I run the code above , the error occurs as follows:
  File ""model2pb3.py"", line 155, in h5_to_pb
    node.attr['is_training'] = False
ValueError: Direct assignment of submessage not allowed



",ib198669,b'backend:tensorflow type:bug/performance',2019-04-01T11:54:04Z,2019-06-10T09:42:46Z
12547,Cannot restore a frozen graph .pb which contains a tf.keras.layers.BatchNormalization layer,"Freezing a Keras graph which contains a BatchNormalization Layer creates a graph which cannot be loaded by the Tensorflow API. The following error is produced:

```
Traceback (most recent call last):
  File ""C:\Program Files\JetBrains\PyCharm 2018.2.5\helpers\pydev\pydevd.py"", line 1664, in <module>
    main()
  File ""C:\Program Files\JetBrains\PyCharm 2018.2.5\helpers\pydev\pydevd.py"", line 1658, in main
    globals = debugger.run(setup['file'], None, None, is_module)
  File ""C:\Program Files\JetBrains\PyCharm 2018.2.5\helpers\pydev\pydevd.py"", line 1068, in run
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File ""C:\Program Files\JetBrains\PyCharm 2018.2.5\helpers\pydev\_pydev_imps\_pydev_execfile.py"", line 18, in execfile
    exec(compile(contents+""\n"", file, 'exec'), glob, loc)
  File ""C:/code sandbox/keras_load_batchnorm.py"", line 37, in <module>
    tf.import_graph_def(graph_def)
  File ""C:\Users\lukeb\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\util\deprecation.py"", line 488, in new_func
    return func(*args, **kwargs)
  File ""C:\Users\lukeb\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\framework\importer.py"", line 422, in import_graph_def
    raise ValueError(str(e))
ValueError: Input 0 of node import/bn/cond/ReadVariableOp/Switch was passed float from import/bn/gamma:0 incompatible with expected resource.
```

It seems that the ""convert_variables_to_constants"" method doesn't know what to do with the Batch Normalization layer.

Here is a fully working example that demonstrates the error:
```
import os
import tensorflow as tf
from tensorflow.python.framework.graph_util import convert_variables_to_constants
from tensorflow.python.platform import gfile

path = ""graph\\""
dirname = os.path.dirname(os.path.realpath(__file__))
filename = ""frozen_graph.pb""
output_folder = os.path.join(dirname, path)
output_file = os.path.join(output_folder, filename)
os.makedirs(output_folder, exist_ok=True)

sess = tf.Session()
tf.keras.backend.set_session(sess)

input = tf.keras.layers.Input(shape=(1, 1, 1), name=""input"")
x = tf.keras.layers.BatchNormalization(name=""bn"")(input)
x = tf.keras.layers.Activation(""relu"", name=""ouput"")(x)
model = tf.keras.models.Model(input, x)
model.compile(""adam"", loss=""mse"")

sess.run([tf.global_variables_initializer(), tf.local_variables_initializer()])

input_graph_def = sess.graph.as_graph_def()
output_names = [node.op.name for node in model.outputs]
freeze_var_names = list(set(v.op.name for v in tf.global_variables()))

frozen_graph = convert_variables_to_constants(sess, input_graph_def, output_names, freeze_var_names)
tf.train.write_graph(frozen_graph, """", output_file, as_text=False)

with sess:
   with gfile.FastGFile(output_file,'rb') as f:
       graph_def = tf.GraphDef()
   graph_def.ParseFromString(f.read())
   sess.graph.as_default()
   tf.import_graph_def(graph_def)
```

I have tried the solutions suggested by the following:
-[Altering nodes before saving: ](https://github.com/tensorflow/tensorflow/issues/3628#issuecomment-272149052)This one doesn't fix it
-[Setting learning phase: ](https://stackoverflow.com/a/52823701/6936275)This one cannot be used outside of a Keras environment
-[Rolling batchnorm layer into previous layers: ](https://stackoverflow.com/a/51157850/6936275)I started this one but it gets very complicated when your layers are not simply stacked.

This is a real showstopper for getting models into production, especially with Keras becoming the main API for RNN's in tf 2.0.",LukeBolly,b'backend:tensorflow stat:awaiting tensorflower type:bug/performance',2019-03-25T10:10:57Z,2019-04-12T04:03:13Z
12457,"Keras Error: Variable does not exist, or was not created with tf.get_variable()","```
import tensorflow.keras as ks
def scope_error_test():
    input_holder = tf.placeholder(dtype=tf.float32,
                                  shape=(None, 368, 368, 3),
                                  name='input')
    with tf.variable_scope(""scope_1""):
        with tf.variable_scope(""scope_2""):
            conv1 = ks.layers.Conv2D(kernel_size=7,
                                     filters=64,
                                     strides=2,
                                     padding='same',
                                     activation=tf.nn.relu,
                                     name='conv1')(input_holder)
            pool1 = ks.layers.MaxPool2D(pool_size=3, padding='same',
                                        strides=2,
                                        name='pool1')(inputs=conv1)
    print(pool1.get_shape().as_list())
with tf.Session() as sess:
        scope_error_test()
        sess.run(tf.global_variables_initializer())
        print(tf.global_variables())
        with tf.variable_scope('', reuse=True):
            for variable in tf.global_variables():
                var_name = variable.name.split(':')[0]
                var_tf = tf.get_variable(var_name)
```
In this example code, I want to understand why I get this error: ValueError: Variable scope_1/scope_2/conv1/kernel does not exist, or was not created with tf.get_variable(). Did you mean to set reuse=tf.AUTO_REUSE in VarScope?

Note: I used `tensorflow.contrib.layers` instead of `tensorflow.keras.layers` and It was working correctly! Could be a bug !?

I have tried `tensorflow 1.9.0` and `tensorflow 1.12.0`",rafikg,b'backend:tensorflow stat:cross-posting to TF type:bug/performance',2019-03-12T01:25:47Z,2019-05-07T22:22:25Z
12274,"Loss on last training step and sklearn calculated log_loss differ, but validation_loss doesn't","Hi,

I am using Keras 2.2.4, tensorflow 1.12.0.

I am experiencing a problem, where I use the sklearn.metrics log_loss function on my training and validation data to calculate the loss. Upon comparing it to the result that model.fit prints in the last step, I realized that the validation losses of the model.fit and log_loss function are identical (which they should be), but for the training data, they aren't.
I reproduced the issue on a simple iris network.

The model is set up via
`train_x, test_x, train_y, test_y = model_selection.train_test_split(X,Y,test_size = 0.1, random_state = 0)`
`input_dim = len(data.columns) - 1`
`model = Sequential()`
`model.add(Dense(8, input_dim = input_dim , activation = 'relu'))`
`model.add(Dense(10, activation = 'relu'))`
`model.add(Dense(10, activation = 'relu'))`
`model.add(Dense(10, activation = 'relu'))`
`model.add(Dense(3, activation = 'softmax'))`
`model.compile(loss = 'categorical_crossentropy' , optimizer = 'adam' )`
`validation_data = (test_x, test_y)`
`model.fit(train_x, train_y, epochs = 1, batch_size = 2, validation_data=validation_data)`

and afterwards the losses are calculated like this:
`p = model.predict_proba(train_x, batch_size=2)`
`ll = log_loss(train_y, p)`
`p = model.predict_proba(test_x, batch_size=2)`
`ll = log_loss(test_y, p)`

The generated output then is:
 `2/127 [..............................] - ETA: 30s - loss: 0.0097`
`66/127 [==============>...............] - ETA: 0s - loss: 2.4860`
`127/127 [==============================] - 1s 5ms/step - loss: 1.8052 - val_loss: 0.9724`
`# training | log loss: 0.98358043, AUC: 69.53%, accuracy: 0.00%`
`# testing  | log loss: 0.97241303, AUC: 73.33%, accuracy: 0.00%`

Any ideas on why the testing/validation loss are equal, but test loss isn't?",ceroxlol,b'type:bug/performance',2019-02-14T17:17:41Z,2019-02-15T20:25:49Z
12263,Saved model starts with initital loss and accuracy values after loading,"I am building a model for machine comprehension. It's a heavy model required to train on lots of data and this requires me more time. I have used keras callbacks to save model after every epoch and also save a history of loss and accuracy.

The problem is, when I am loading a trained model, and try to continue it's training using `initial_epoch` argument, the loss and accuracy values are same as untrained model.

Here is the code: https://github.com/ParikhKadam/bidaf-keras
The code used to save and load model is in /models/bidaf.py
The script I am using to load the model is:
```

from .models import BidirectionalAttentionFlow
from .scripts.data_generator import load_data_generators
import os
import numpy as np


def main():
    emdim = 400
    bidaf = BidirectionalAttentionFlow(emdim=emdim, num_highway_layers=2,
                                       num_decoders=1, encoder_dropout=0.4, decoder_dropout=0.6)
    bidaf.load_bidaf(os.path.join(os.path.dirname(__file__), 'saved_items', 'bidaf_29.h5')) 
    train_generator, validation_generator = load_data_generators(batch_size=16, emdim=emdim, shuffle=True)
    model = bidaf.train_model(train_generator, epochs=50, validation_generator=validation_generator, initial_epoch=29, 
                              save_history=False, save_model_per_epoch=False)


if __name__ == '__main__':
    main()

```

The training history is quite good which is:

```
epoch,accuracy,loss,val_accuracy,val_loss
0,0.5021367247352657,5.479433422293752,0.502228641179383,5.451400522458351
1,0.5028450897193741,5.234336488338403,0.5037527732234647,5.0748545675049
2,0.5036885394022954,5.042028017280698,0.5039489093881276,5.0298488218407975
3,0.503893446146289,4.996997425685413,0.5040753162241299,4.976164487656699
4,0.5040576918224873,4.955544574118662,0.5041905890181151,4.931354981493792
5,0.5042372655790888,4.909940965651957,0.5043896965802341,4.881359395178988
6,0.504458428129642,4.8542871887472465,0.5045972716586732,4.815464454729135
7,0.50471843351102,4.791098495962496,0.5048680457262408,4.747811231472629
8,0.5050776754196002,4.713560494026321,0.5054184527602898,4.64730478015052
9,0.5058853749443502,4.580552254050073,0.5071290369370443,4.446513280167718
10,0.5081544614246304,4.341471499420364,0.5132941329030303,4.145318906086552
11,0.5123970410575613,4.081624463197288,0.5178775145611896,4.027316586998608
12,0.5149879128865782,3.9577423109634613,0.5187159608315838,3.950151870168726
13,0.5161411008840144,3.8964761709052578,0.5191430166876064,3.906301355196609
14,0.5168211272672539,3.8585826589385697,0.5191263493850466,3.865382308412537
15,0.5173216891201444,3.830764191839807,0.519219763635108,3.8341492204942607
16,0.5177805591697787,3.805340048675155,0.5197178382215892,3.8204319018292585
17,0.5181171635676399,3.7877712072310343,0.5193657963810704,3.798006804522368
18,0.5184295824699279,3.77086071548255,0.5193122694008523,3.7820449101377243
19,0.5187343664397653,3.7555085003534194,0.5203585262348183,3.776260506494833
20,0.519005008308583,3.7430062334375065,0.5195983755362352,3.7605361109533995
21,0.5192872482429703,3.731001830462149,0.5202017035842986,3.7515058917231405
22,0.5195097722222706,3.7194103983513553,0.5207148585133065,3.7446572377159795
23,0.5197511249107636,3.7101052441559905,0.5207420740297026,3.740088335181619
24,0.5199862479678652,3.701593302911729,0.5200187951731082,3.7254406861185188
25,0.5200847805044403,3.6944093077914464,0.520112738649039,3.7203616696860786
26,0.5203289568582412,3.6844954882274092,0.5217114634669081,3.7214983577364547
27,0.5205629846610852,3.6781935968943595,0.520915311442328,3.705435317731209
28,0.5206827641463226,3.6718110897539193,0.5214088439286978,3.7003081666703377

```

Also, I have already taken care of loading custom objects such as layers, loss function and accuracy.

I am kind of frustrated by now as I took me  days to train this model upto epochs and now I can't resume training. I have referred various threads in keras issues and found many people are facing such issues but can't find a solution.

Someone in a thread said that ""Keras will not save RNN states"" (I ain't using stateful RNNs) and someone else said ""Keras reinitializes all the weights before saving which we can handle using a flag."" I mean, if such problems exist in Keras, what will be the use of functions like save().

I have also tried saving only weights after every epoch and then building model from scratch and then loading those weights into it. But that didn't work. You can find the old code I used to save weights only in the above listed github repo's older branches.

I have referred this issue with no help - https://github.com/keras-team/keras/issues/4875

That issue is open from past two years. Can't understand what all the developers are doing! Is anyone here who can help? Should I switch to tensorflow or I will face the same issues in that too?

Please help...",ParikhKadam,b'To investigate type:bug/performance',2019-02-13T09:00:56Z,2020-08-10T05:54:02Z
12202,'Could not compute output Tensor' error when I‘m using clone_model(),"Hi guys, I think I just met a bug. 
There was something wrong when I was using `multi_gpu_model` with `cpu_relocation=True`. After analyzing the traceback I think it is a bug inside `keras.models.clone_model`
The script below can reproduce it

```python
from keras.models import Model, clone_model
from keras.layers import Input, Add, Lambda
from keras.utils import multi_gpu_model


def build_model():
    input_layer = Input(shape=(1,))
    test1, test2 = Lambda(lambda x: [x, x])(input_layer)
    add = Add()([test1, test2])
    model = Model(inputs=[input_layer], outputs=[add])
    return model


if __name__ == '__main__':
    model = build_model()
    model = clone_model(model)
    # model = multi_gpu_model(model, cpu_relocation=True)  # it uses clone_model when set cpu_relocation=True
```
If I didn't make any mistake, the script will raise `AssertionError: Could not compute output Tensor(""add_1/add:0"", shape=(?, 1), dtype=float32)`

My environment:

- Keras 2.2.4
- tensorflow 1.12.0

I met the error on both 4 GTX1080tis and my own laptop with a GTX1060MQ

------

I noticed that `output_masks` here will always be `[None]`(but `[None, None]` is expected)
https://github.com/keras-team/keras/blob/a1397169ddf8595736c01fcea084c8e34e1a3884/keras/models.py#L157

and that's because `layer.compute_mask(...)` will always return `None` since `Lambda` doesn't support using masks
https://github.com/keras-team/keras/blob/a1397169ddf8595736c01fcea084c8e34e1a3884/keras/models.py#L153

So if I'm using a functional model with a layer which has more outputs without a mask support, I think the error can appear.

------

P.S. thanks a lot for your brilliant works :)  
From my perspective, Keras is an amazing gift to everyone. Thank you all!


",Mistariano,b'backend:tensorflow type:bug/performance',2019-02-04T16:52:31Z,2019-02-26T08:06:36Z
12195,ValueError: Unable to create group (Name already exists) with model.save_weights(),"This is a similar issue to https://github.com/keras-team/keras/issues/6005 but I believe it is caused by the way `h5py` defines groups. In particular, if a layer named `foo` is in a network after a layer named `foo/bar`, `h5py` throws an exception. But the same does not occur if `foo` comes first. To reproduce, see the snippet below.

```
from keras import layers, models

# This raises an exception.
input_layer = layers.Input((None, None, 3), name='test_input')
x = layers.Conv2D(1, 1, name='conv1/conv')(input_layer)
x = layers.BatchNormalization(name='conv1/bn')(x)
x = layers.Activation('relu', name='conv1')(x)
models.Model(inputs=input_layer, outputs=x).save_weights('test.h5')

# This doesn't raise an exception
input_layer = layers.Input((None, None, 3), name='test_input')
x = layers.Conv2D(1, 1, name='conv1')(input_layer)
x = layers.BatchNormalization(name='conv1/bn')(x)
x = layers.Activation('relu', name='conv1/relu')(x)
models.Model(inputs=input_layer, outputs=x).save_weights('test.h5')
```

Perhaps we could provide a more helpful error message in `keras/engine/saving.py`? For example, changing part of `save_weights_to_hdf5_group` to the following would help trace the offending layer name.

```
for layer in layers:
    try:
         g = group.create_group(layer.name)
    except ValueError:
         raise ValueError('An error occurred creating weights group for {0}.'.format(layer.name))
    symbolic_weights = layer.weights
    weight_values = K.batch_get_value(symbolic_weights)
```

Happy to create PR if this is helpful.",faustomorales,b'type:bug/performance',2019-02-03T18:01:19Z,2020-09-05T06:35:52Z
12189,Nadam optimizer arguments description missed schedule_decay,"
Both documentation https://keras.io/optimizers/ and the source code https://github.com/keras-team/keras/blob/master/keras/optimizers.py#L605 missed the description of an argument schedule_decay. Currently, it is:  
# Arguments
        lr: float >= 0. Learning rate.
        beta_1/beta_2: floats, 0 < beta < 1. Generally close to 1.
        epsilon: float >= 0. Fuzz factor. If `None`, defaults to `K.epsilon()`.
While actual list of parameters is: lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=None, schedule_decay=0.004
I propose to add a line like schedule_decay: float >= 0, determines ""what it actually does"". Could do it myself also.",slavikkom,b'stat:contributions welcome type:bug/performance',2019-02-01T14:26:48Z,2019-02-02T12:51:09Z
12121,Lambda layer with tf.fft.fft2d error,"I have a problem trying to make a Lambda layer that aplies fft2d to a tensor:
```
from keras.layers import Lambda, Input
import tensorflow as tf


inp = Input(shape=(299,299),dtype='complex64')
tensorTransformada = Lambda(tf.fft2d)(Inp)

```
Even if I have declared the first tensor as 'complex64', the next error appears:

    Traceback (most recent call last):

    File """", line 1, in

    File ""/usr/local/lib/python3.6/dist-packages/keras/engine/base_layer.py"", line 474, in call

    output_shape = self.compute_output_shape(input_shape)

    File ""/usr/local/lib/python3.6/dist-packages/keras/layers/core.py"", line 648, in compute_output_shape x = self.call(x) File ""/usr/local/lib/python3.6/dist-packages/keras/layers/core.py"", line 682, in call return self.function(inputs, **arguments)

    File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_spectral_ops.py"", line 437, in fft2d ""FFT2D"", input=input, name=name)

    File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py"", line 609, in _apply_op_helper param_name=input_name)

    File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py"", line 60, in _SatisfiesTypeConstraint "", "".join(dtypes.as_dtype(x).name for x in allowed_list)))

    TypeError: Value passed to parameter 'input' has DataType float32 not in list of allowed values: complex64, complex128

Please solve this bug

Running on Python 3.6.7, keras 2.2.2, tensorflow 1.11.0 on CPU,",isega24,b'type:bug/performance',2019-01-24T14:01:09Z,2019-04-26T17:54:18Z
12080,Bug in example (cifar10_resnet.py),"Hi,
here is a bug in this example here:
https://github.com/keras-team/keras/blob/master/examples/cifar10_resnet.py#L423

The Exception is:
```
ValueError: `steps_per_epoch=None` is only valid for a generator based on the 
`keras.utils.Sequence` class. Please specify `steps_per_epoch` or use the 
`keras.utils.Sequence` class.
```

`model.fit_generator` whould specify `steps_per_epoch`.

By example:
```
    model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),
                        steps_per_epoch=int(50000/batch_size),
                        validation_data=(x_test, y_test),
                        epochs=epochs, verbose=1, workers=4,
                        callbacks=callbacks)
```",PhilipMay,None,2019-01-20T08:50:20Z,2019-01-31T22:28:35Z
12069,Callback warning error,"I receive the following error when using `fit_generator` with callbacks in Keras:

```
/opt/conda/lib/python3.6/site-packages/Keras-2.2.4-py3.6.egg/keras/callbacks.py in _call_batch_hook(self, mode, hook, batch, logs)
     93                 'Method (%s) is slow compared '
     94                 'to the batch update (%f). Check your callbacks.', hook_name,
---> 95                 delta_t_median)
     96         if hook == 'begin':
     97             self._t_enter_batch = time.time()

TypeError: integer argument expected, got float

```

Apparently it happens with some combination of warnings package and Keras packages, or something else. Any idea for a quick workaround that does not involve removing callbacks?",psinger,b'Good first issue stat:contributions welcome type:bug/performance',2019-01-18T10:18:29Z,2019-02-19T05:51:00Z
12016,metrics are not evaluated if loss is None,"- [x ] Check that you are up-to-date with the master branch of Keras. You can update with:
`pip install git+git://github.com/keras-team/keras.git --upgrade --no-deps`

- [ x] Check that your version of TensorFlow is up-to-date. The installation instructions can be found [here](https://www.tensorflow.org/get_started/os_setup).

- [ x] Provide a link to a GitHub Gist of a Python script that can reproduce your issue (or just copy the script here if it is short).

Using the [VAE example from Keras](https://github.com/keras-team/keras/blob/master/examples/variational_autoencoder.py), one can easily reproduce the effect that any metric defined in the `model.compile` call will not be evaluated if the `loss` argument is None. For instance, substituting `vae.compile(optimizer='adam')` in [line 188](https://github.com/keras-team/keras/blob/master/examples/variational_autoencoder.py#L188) with 
```
    def kl_loss_fun(y_true, y_pred):
        return kl_loss
    def reconstruction_loss_fun(y_true, y_pred):
        return reconstruction_loss
    vae.compile(optimizer='adam', metrics=[kl_loss_fun, reconstruction_loss])
```
shows no output of the metrics when `fit` is called.

I found out that, if [compile](https://github.com/keras-team/keras/blob/master/keras/engine/training.py#L37) is called, that the metrics are just skipped if the corresponding loss per output is None in [line 443](https://github.com/keras-team/keras/blob/master/keras/engine/training.py#L443). Removing the conditional fixes the issue!

**So the main question is, why is the calculation of the metric conditioned on the losses at all? If the user demands it explicitly it should not depend on the loss which is given in the compile call.**",tik0,b'stat:contributions welcome type:bug/performance',2019-01-10T16:30:46Z,2019-01-10T20:22:54Z
11973,Why does LearningRateScheduler not write the learning rate to Tensorboard ?,"The title pretty much says it all, when you use model.fit with ReduceLRonPlateau or without it along with the Tensorboard callback, Keras writes the learning rate by epoch to Tensorboard, but if you LearningRateScheduler, it doesn't ? Is there any particular reason for this ? Its technically not a bug, but its very unexpected behavior.

- [X] Check that you are up-to-date with the master branch of Keras. You can update with:
`pip install git+git://github.com/keras-team/keras.git --upgrade --no-deps`

- [X] Check that your version of TensorFlow is up-to-date. The installation instructions can be found [here](https://www.tensorflow.org/get_started/os_setup).

- [X] Provide a link to a GitHub Gist of a Python script that can reproduce your issue (or just copy the script here if it is short).
",rohit-gupta,b'backend:tensorflow type:bug/performance',2019-01-04T08:34:32Z,2019-03-14T23:08:42Z
11940,keras model add layer created by k.stack in order to create stacked output,"I am using keras with tf backend to create a siamese network, I am trying to create a custom loss function for triplet loss and need to 
pass it with multiple outputs in a one tensor that I can then split in the loss function in order to calculate the gradient. 

I am trying to use what explained [here](https://stackoverflow.com/questions/52095790/concatenate-error-the-added-layer-must-be-an-instance-of-class-layer) as for how to use multiple outputs in a concatenated form, and use it in my code in the following way 

    input_layer = Input(shape=(784,))                               
    a = Dense(100, activation=""relu"")(input_layer)                  
    o = Dense(40, activation=""relu"")(a)                             
    layer1 = Lambda(lambda x: K.expand_dims(x, axis=2))(o)          
    layer2 = Lambda(lambda x: K.expand_dims(x, axis=2))(o)          
    concat_layer = concatenate([layer1, layer2], axis=2)            
                                                                    
    model = Model(input_layer, concat_layer)                        
    model.compile(optimizer=SGD(), loss=triplet_loss_wrapper())     
                                                                    
    (x_train, y_train), (x_test, y_test) = mnist.load_data()        
    x_test = x_test.reshape(x_test.shape[0], 784)                   
                                                                    
                                                                    
    model.fit(x_test, [1] * len(x_test))

                            
I get the following error 

                                                                

> (np_val.shape, subfeed_t.name, str(subfeed_t.get_shape())))
> ValueError: Cannot feed value of shape (32, 1) for Tensor
> 'concatenate_1_target:0', which has shape '(?, ?, ?)'

please also see my connected SO [question](https://stackoverflow.com/posts/53947008/edit) 


  ",thebeancounter,b'backend:tensorflow type:bug/performance',2018-12-28T07:06:06Z,2019-02-22T02:54:53Z
11921,Creating model with shared layers,"I'm trying to implement model for triplet loss using FacenetModel.By far I have written this code :

`        
     def batch_generator(batch_size = 64):
            while True:
                pos = positiveImg[np.random.choice(len(positiveImg), batch_size)]
                neg = negativeImg[np.random.choice(len(negativeImg), batch_size)]
                anc = anchorsImg[np.random.choice(len(anchorsImg), batch_size)]
        
                x_data = {'inp1': anc,
                          'inp2': pos,
                          'inp3': neg
                          }
                y_data = {'y1': np.zeros((64,0)),
                          'y2': np.zeros((64,0)),
                          'y3': np.zeros((64,0))}
                yield (x_data, y_data)
        
        def triplet_loss(y_true, y_pred):    
            anchor, positive, negative = y_pred[0], y_pred[1], y_pred[2]
            pos_dist = tf.reduce_sum(tf.square(tf.subtract(anchor, positive)), axis=-1)
            neg_dist = tf.reduce_sum(tf.square(tf.subtract(anchor, negative)), axis=-1)
            basic_loss = tf.add(tf.subtract(pos_dist, neg_dist), 0.2)
            loss = tf.reduce_sum(tf.maximum(basic_loss, 0.0))
        
            return loss
        
        def getModels():
            FRmodel = keras.models.load_model('FR.h5', custom_objects={'triplet_loss': triplet_loss})
        
            inp1 = Input((3, 96, 96), name= 'inp1')
            inp2 = Input((3, 96, 96), name= 'inp2')
            inp3 = Input((3, 96, 96), name= 'inp3')
        
            pred1 = FRmodel(inp1)
            pred2 = FRmodel(inp2)
            pred3 = FRmodel(inp3)
        
            inputs = [inp1, inp2, inp3]
            outputs = [pred1, pred2, pred3]
        
            model = keras.models.Model(inputs=[inp1, inp2, inp3], outputs= [pred1, pred2, pred3])
        
            return FRmodel, model
        
        generator = batch_generator(64)
        
        FRmodel, my_model = getModels()
        my_model.compile(optimizer = 'adam', loss = triplet_loss, metrics = ['accuracy'])   
        my_model.fit_generator(generator, epochs=5,steps_per_epoch=30)`

But when I compile this model. I get this error: ValueError: No data provided for ""FaceRecoModel"". Need data for each key in: ['FaceRecoModel', 'FaceRecoModel', 'FaceRecoModel']

What is the correct way to do this?

Please don't get mad. I'm not getting any responses on stackoverflow. Please help.",sainimohit23,b'type:bug/performance',2018-12-22T12:53:12Z,2019-01-18T23:28:37Z
11769,The method `evaluate` appears to fail on the following model:,"```python
    inputs = Input(shape=(3,))
    x = Dense(2)(inputs)
    outputs = Dense(3)(x)

    model = Model(inputs, outputs)
    model.compile(loss=losses.MSE,
                  optimizer=optimizers.Adam(),
                  metrics=['mse'],
                  weighted_metrics=['mse'])
```

This is due to the model expecting to be fed sample weights (due to the presence of a weighted metric) yet receiving none.

Note created by @fchollet in the ""Requests for contributions"".",gabrieldemarmiesse,b'stat:contributions welcome type:bug/performance',2018-12-02T12:57:29Z,2018-12-05T00:51:50Z
11753,Bug: Model summary is incorrect with custom layer,"- [x] Check that you are up-to-date with the master branch of Keras. You can update with:
`pip install git+git://github.com/keras-team/keras.git --upgrade --no-deps`

- [x] Check that your version of TensorFlow is up-to-date. The installation instructions can be found [here](https://www.tensorflow.org/get_started/os_setup).

- [x] Provide a link to a GitHub Gist of a Python script that can reproduce your issue (or just copy the script here if it is short).

*Issue*: I have a custom max pooling layer. It works similar to a normal max pooling in terms of dimensionality reduction. So from 32 x 32 to 16 x 16 with `padding=same` and `strides=2`. However I notice that `model.summary` reports the output shape to still be `32 x 32`

Here is the result of `model.summary`:
```
Layer (type)                 Output Shape              Param #
=================================================================
input_1 (InputLayer)         (None, 32, 32, 3)         0
_________________________________________________________________
conv (Conv2D)                (None, 32, 32, 96)        2688
_________________________________________________________________
reshape_conv (Reshape)       (None, 32, 32, 1, 96)     0
_________________________________________________________________
primary_caps (ConvCapsuleLay (None, 32, 32, 8, 96)     664320
_________________________________________________________________
caps_conv_1 (ConvCapsuleLaye (None, 32, 32, 8, 96)     664320
_________________________________________________________________
max_pool_caps_1 (CapsMaxPool (None, 32, 32, 8, 96)     0
_________________________________________________________________
caps_conv_2 (ConvCapsuleLaye (None, 32, 32, 12, 192)   1992960
_________________________________________________________________
caps_conv_3 (ConvCapsuleLaye (None, 32, 32, 12, 192)   3983616
_________________________________________________________________
max_pool_caps_2 (CapsMaxPool (None, 32, 32, 12, 192)   0
_________________________________________________________________
caps_conv_4 (ConvCapsuleLaye (None, 30, 30, 16, 192)   5311488
_________________________________________________________________
caps_conv_5 (ConvCapsuleLaye (None, 30, 30, 16, 192)   5311488
_________________________________________________________________
caps_conv_6 (ConvCapsuleLaye (None, 30, 30, 20, 10)    345800
_________________________________________________________________
caps_norm (CapsuleNorm)      (None, 30, 30, 20)        0
_________________________________________________________________
avg_pool (GlobalAveragePooli (None, 20)                0
_________________________________________________________________
subclass_out (Dense)         (None, 100)               2100
=================================================================
Total params: 18,278,780
Trainable params: 18,278,780
Non-trainable params: 0
```

Both `max_pool_caps_1` and `max_pool_caps_2` has `strides=(2,2)` and I would expect that `model.summary` would report the output to be 16 x 16 not 32 x 32 for `max_pool_caps_1` (the first two dimensions after `None`).

I checked that the output shape is indeed 16 x 16:
```python
max_pool_caps_1 = CapsMaxPool(pool_size=(3,3), strides=(2,2), padding='SAME', name='max_pool_caps_1')(caps_conv_1)
print('max_pool_caps_1 shape', max_pool_caps_1.shape)
```
and result is `max_pool_caps_1 shape (?, 16, 16, 8, 96)`

Now I tried to check inside the `build()` call of the next layer (which is also custom) and I get `caps_conv_2 build() input shape (None, 32, 32, 8, 96)`.

Then I tried to debug to Keras code where `build()` is called. It's called [here](https://github.com/keras-team/keras/blob/d18c564548104c862892a1f73423e333f11f7ce2/keras/engine/base_layer.py#L431). I printed `x_elem._keras_shape` and `x_elem.shape` and this is what I get
`caps_conv_2 x_elem shape (?, 16, 16, 8, 96) caps_conv_2 x_elem keras shape (None, 32, 32, 8, 96)`

Clearly it is wrong. I assume it would help to look at what my custom max pooling layer is doing and here it is:

```python
import tensorflow as tf
from keras.layers import Layer
from keras.utils.conv_utils import conv_output_length

class CapsMaxPool(Layer):
  def __init__(self, pool_size=(2,2), strides=None, padding='VALID', **kwargs):
    """"""Max pooling for [capsules]_

    Layer to perform max pooling given a previous capsule comprised (or treated)
    as capsules.

    Max pooling is done by taking the norm of the capsule which is interpreted as the
    probability of an entity (color, shade, line etc.) exists at a particular region
    of the data. Using the norm we run them through a ""filtering"", similar to usual
    2D max pool with pool size and strides, and choose the capsules which has the greatest
    norm in a particular pooling area over the whole input.

    :param pool_size: Pool size, defaults to (2,2)
    :type pool_size: tuple[int]|list[int], optional - Dimension should be [height x width]
    :param strides: Strides to take for the pooling (only consider along height and axis), defaults to None
    :type strides: tuple[int]|list[int], optional - Dimension should be [height x width]
    :param padding: Padding criteria: see [tensorflow convolution], defaults to 'VALID'
    :type padding: str, optional
    :param kwargs: Some common options to Keras layer
    :type kwargs: dict

    .. [capsules]: https://arxiv.org/pdf/1710.09829.pdf
    .. [tensorflow convolution]: https://www.tensorflow.org/api_guides/python/nn#Convolution
    .. note::
      The implementation is inspired and possible by the following resources:
      * https://www.tensorflow.org/api_docs/python/tf/nn/max_pool_with_argmax
      * https://www.tensorflow.org/api_docs/python/tf/gather_nd
    """"""
    if strides is None:
      strides = pool_size

    assert isinstance(pool_size, list) or isinstance(pool_size, tuple)
    assert len(pool_size) == 2, 'Pool size needs to be over height and width only'
    assert isinstance(strides, list) or isinstance(strides, tuple)
    assert len(strides) == 2, 'Strides need be over height and width only'

    # readjust pool size stride to have dimension [batch size x height x width x capsule channels]
    self.pool_size = [1,*pool_size,1]
    self.strides = [1,*strides,1]
    self.padding = padding
    super().__init__(**kwargs)

  def build(self, input_shape):
    # do nothing because there are no weights during pooling
    super().build(input_shape)

  def call(self, input):
    """"""Capsule max pool call

    Do the max pooling

    :param input: An input Tensor assumed to be coming from a capsule layer.
    :type input: Tensor, [batch size x height x width x capsule channels x atoms (instantiation parameters)]
    """"""
    assert input.shape.ndims == 5, 'Input rank needs to be 5'
    capsule_entity_probabilities = tf.norm(input, ord='euclidean', axis=-1)
    maxpooled_with_argmax = tf.nn.max_pool_with_argmax(
      capsule_entity_probabilities,
      ksize=self.pool_size,
      strides=self.strides,
      padding=self.padding,
      name='entity_probability_max_pool'
    )
    flattened_indices_of_greatest_probabilities = tf.reshape(maxpooled_with_argmax.argmax, shape=[-1], name='flattened_argmax')
    input_shape = input.shape
    input_dynamic_shape = tf.shape(input)
    # will only have two dimensions from here on out [rank x number of elements after max pool]
    unraveled_indices_of_greatest_probabilities = tf.unravel_index(
      flattened_indices_of_greatest_probabilities,
      dims=tf.cast(input_dynamic_shape[:-1], dtype=tf.int64),
      name='map_argmax_indices_to_original'
    )
    unraveled_indices_of_greatest_probabilities = tf.transpose(unraveled_indices_of_greatest_probabilities, (1,0))
    # shape will be rank
    max_pool_on_capsules = tf.gather_nd(
      input,
      indices = unraveled_indices_of_greatest_probabilities,
      name='max_pooling_over_capsules'
    )
    # reshape to be the same shape
    shape_after_maxpool = maxpooled_with_argmax.output.shape
    dynamic_shape_after_maxpool = tf.shape(maxpooled_with_argmax.output)
    shape_for_capsule_maxpool = [
      dynamic_shape_after_maxpool[0],
      shape_after_maxpool[1],
      shape_after_maxpool[2],
      shape_after_maxpool[3],
      input_shape[-1]
    ]
    max_pool_on_capsules = tf.reshape(max_pool_on_capsules, shape_for_capsule_maxpool, name='maxpooled_caps')
    max_pool_on_capsules.set_shape((None, shape_after_maxpool[1], shape_after_maxpool[2], shape_after_maxpool[3], input_shape[-1]))
    return max_pool_on_capsules

  def compute_input_shape(self, input_shape):
    """"""Compute input shape

    Function to compute end input shape result after max pooling.
    Adapted from https://github.com/keras-team/keras/blob/f899d0fb336cce4061093a575a573c4f897106e1/keras/layers/pooling.py#L180

    :param input_shape: Shape of input
    :type input_shape: Tensor, dimension [batch size x height x width x channels x instantiation parameters]
    """"""
    assert input_shape.shape.ndims == 5
    height = input_shape[1]
    width = input_shape[2]

    print(""COMPUTE INPUT SHAPE CALLED"")
    height = conv_output_length(height, self.pool_size[1], self.padding, self.strides[1])
    width = conv_output_length(width, self.pool_size[2], self.padding, self.strides[2])
    return (input_shape[0], height, width, input_shape[-2], input_shape[-1])
```

I can't run my model now, it would output some error about mismatching shapes later down the line in some operations and I assume this is causing that
",btruhand,b'To investigate',2018-11-29T04:38:25Z,2019-12-17T19:50:48Z
11665,Poor memory performance of K.batch_dot under tensorflow backend relative to batched tf.matmul,"- [ x] Check that you are up-to-date with the master branch of Keras. You can update with:
`pip install git+git://github.com/keras-team/keras.git --upgrade --no-deps`

- [ x] Check that your version of TensorFlow is up-to-date. The installation instructions can be found [here](https://www.tensorflow.org/get_started/os_setup).

- [x ] Provide a link to a GitHub Gist of a Python script that can reproduce your issue (or just copy the script here if it is short).

I am performing batch matrix multiplies of two tensors of size (batch, N, M) and (batch, M, K) to get a tensor of size (batch, N, K), with the matrix products. This behavior can be done with both tf.matmul and K.batch_dot with the default axis arguments.

However in K.batch_dot, the elementwise multiplication in the line https://github.com/keras-team/keras/blob/75a35032e194a2d065b0071a9e786adf6cee83ea/keras/backend/tensorflow_backend.py#L1248 eats up a lot of memory. The elementwise multiplication followed by summing over an axis is of course mathematically equivalent to the matrix multiply, but in the two-step implementation, Tensorflow assigns memory to the intermediate very large tensor.

In this simple example, my small GPU (Nvidia 970) is able to perform the calculation using tf.matmul, but using K.batch_dot Tensorflow fails with an OOM error.

```
import numpy as np
import tensorflow as tf
from keras import backend as K

a = np.random.normal(size=(100, 500, 10000)).astype(np.float32)
b = np.random.normal(size=(100, 10000, 32)).astype(np.float32)

a_t = K.placeholder(a.shape)
b_t = K.placeholder(b.shape)

td = tf.matmul(a_t, b_t)
bd = K.batch_dot(a_t, b_t)

sess = K.get_session()
sess.run(td, feed_dict={a_t: a, b_t: b})
sess.run(bd, feed_dict={a_t: a, b_t: b})
```

This fails when it tries to assign a tensor of size (100, 10000, 500, 32) in the elementwise multiply in batch_dot (the dimension of 10000 not being strictly necessary in this case since we are only interested in the sum).",mawright,b'backend:tensorflow type:bug/performance',2018-11-18T07:38:53Z,2018-11-25T14:51:06Z
11661,TensorBoard Callback write_images,"I want to use the TensorBoard callback to visualize my conv layer kernels. But i can only see the first conv layer kernel in TensorBoard and my Dense layers at the end. For the other conv layers i can just see the bias values and not the kernels.

Here is my sample code for the Keras model.
```
# Imports
import tensorflow as tf
import numpy as np
import os
from os import makedirs
from os.path import exists, join
from keras.datasets import mnist
import time

from keras.layers import *
from keras.activations import *
from keras.models import *
from keras.optimizers import *
from keras.initializers import *
from keras.callbacks import TensorBoard
from keras.callbacks import ModelCheckpoint
from keras.utils.np_utils import to_categorical

from plotting import *

log_dir = '""./""

# Load MNIST dataset
(x_train, y_train), (x_test, y_test) = mnist.load_data()

batch_size = 128
epochs = 10
width = 28
height = 28
depth = 1
num_classes = 10
train_size = x_train.shape[0]
test_size = x_test.shape[0]

x_train = x_train.reshape(train_size, width, height, depth)
y_train = to_categorical(y_train, num_classes=num_classes)
x_test = x_test.reshape(test_size, width, height, depth)
y_test = to_categorical(y_test, num_classes=num_classes)

tb = TensorBoard(
    log_dir=log_dir, 
    histogram_freq=1, 
    write_graph=True, 
    write_images=True)

# Define the DNN
model = Sequential()
model.add(Conv2D(filters=16, kernel_size=3, input_shape=(width, height, depth), name=""conv1""))
model.add(Activation(""relu""))
model.add(Conv2D(filters=20, kernel_size=3, name=""conv2""))
model.add(Activation(""relu""))
model.add(MaxPool2D())

model.add(Conv2D(filters=24, kernel_size=3, name=""conv3""))
model.add(Activation(""relu""))
model.add(Conv2D(filters=28, kernel_size=3, name=""conv4""))
model.add(Activation(""relu""))
model.add(MaxPool2D())

model.add(Flatten())
model.add(Dense(128))
model.add(Activation(""relu""))
model.add(Dense(num_classes, name=""features""))
model.add(Activation(""softmax""))

# Print the DNN layers
model.summary()

# Train the DNN
lr = 1e-3
optimizer = Adam(lr=lr)
model.compile(loss=""categorical_crossentropy"", optimizer=optimizer, metrics=[""accuracy""])
model.fit(x_train, y_train, verbose=1, batch_size=batch_size, epochs=epochs, validation_data=(x_test, y_test), callbacks=[tb])

# Test the DNN
score = model.evaluate(x_test, y_test, batch_size=batch_size)
print(""Test performance: "", score)
```
Here is the resulting screenshot from TensorBoard.
![unbenannt](https://user-images.githubusercontent.com/20141069/48664190-37b15880-ea9b-11e8-9339-aad7acf1a8cd.png)
",franneck94,b'backend:tensorflow type:bug/performance',2018-11-17T18:02:35Z,2020-05-06T01:40:46Z
11657,Scikit Learn wrapper predict() inappropriately squashes size-1 batch dimension,"Please make sure that the boxes below are checked before you submit your issue.
If your issue is an **implementation question**, please ask your question on [StackOverflow](http://stackoverflow.com/questions/tagged/keras) or [on the Keras Slack channel](https://keras-slack-autojoin.herokuapp.com/) instead of opening a GitHub issue.

Thank you!

- [X] Check that you are up-to-date with the master branch of Keras. You can update with:
`pip install git+git://github.com/keras-team/keras.git --upgrade --no-deps`
Using Keras version 2.2.4

- [X] Check that your version of TensorFlow is up-to-date. The installation instructions can be found [here](https://www.tensorflow.org/get_started/os_setup).
Using Tensorflow version 1.12.0

- [X] Provide a link to a GitHub Gist of a Python script that can reproduce your issue (or just copy the script here if it is short).

If predict() is called on input with shape `(1, num_features)`, then the output is a 0-dimensional array instead of a 1-dimensional array with 1 element.

```python
import keras
import keras.wrappers.scikit_learn
import numpy as np
import sklearn.linear_model
import sklearn.metrics

def build_net():
    model = keras.models.Sequential([keras.layers.Dense(units=1, input_dim=2)])
    model.compile(loss=keras.losses.mean_squared_error, optimizer=""sgd"")
    return model

regressor = keras.wrappers.scikit_learn.KerasRegressor(build_fn=build_net)
# Works with the sklearn regressors
# regressor = sklearn.linear_model.LinearRegression()
X = np.zeros((1, 2))
Y = np.zeros((1,))
regressor.fit(X, Y)
Y_pred = regressor.predict(X)
print(Y_pred.shape)  # Is (), should be (1,)
# As a result, this fails with an exception
# TypeError: Singleton array array(0., dtype=float32) cannot be considered a valid collection.
print(sklearn.metrics.mean_squared_error(y_true=Y, y_pred=Y_pred))
```",edlanglois,b'type:bug/performance',2018-11-16T23:22:24Z,2018-12-09T14:28:28Z
11634,Using fit_generator and keras.utils.Sequence does not work when use_multiprocessing=True with workers > 1 ,"Hi, as said in the title, if set use_multiprocessing=True while using fit_generator and keras.utils.Sequence the code get stuck and the gpu activity remains at 0%. No errors are shown.

I am using keras 2.2.2 in Ubuntu 18.04.1 LTS.
I am seeing the displayed information:

2018-11-14 11:10:27.834657: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2018-11-14 11:10:28.009869: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1105] Found device 0 with properties: 
name: GeForce GTX 1080 major: 6 minor: 1 memoryClockRate(GHz): 1.7335
pciBusID: 0000:02:00.0
totalMemory: 7.93GiB freeMemory: 7.81GiB
2018-11-14 11:10:28.163209: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1105] Found device 1 with properties: 
name: GeForce GTX 1080 major: 6 minor: 1 memoryClockRate(GHz): 1.7335
pciBusID: 0000:03:00.0
totalMemory: 7.93GiB freeMemory: 7.81GiB
2018-11-14 11:10:28.164488: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Device peer to peer matrix
2018-11-14 11:10:28.164532: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1126] DMA: 0 1 
2018-11-14 11:10:28.164542: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1136] 0:   Y Y 
2018-11-14 11:10:28.164549: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1136] 1:   Y Y 
2018-11-14 11:10:28.164561: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1195] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: GeForce GTX 1080, pci bus id: 0000:02:00.0, compute capability: 6.1)
2018-11-14 11:10:28.164569: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1195] Creating TensorFlow device (/device:GPU:1) -> (device: 1, name: GeForce GTX 1080, pci bus id: 0000:03:00.0, compute capability: 6.1)
",Schiboni,b'backend:tensorflow stat:awaiting response type:bug/performance',2018-11-14T10:46:05Z,2018-11-28T21:53:09Z
11508,bug fix: can't use code blocks in multiple sections in docstrings.,"### Summary

Having blocks of code in multiple sections of the same docstring breaks the rendering of the documentation. To see exactly what I mean, see the test which I added.

### Related Issues

### PR Overview

The problem came from this line:
https://github.com/keras-team/keras/blob/267ccbb4a76913680f4db6b400e05dea7aa84db7/docs/autogen.py#L456

Because the `replace` was used on the full docstring (not the slice of the docstring correnponding to the section being worked on), even code blocks which were in other sections were replaced.

So as the parser progressed, some code blocks were replaced multiple times, and the parser lost the content of the last blocks of code, because the parser only remember what it just replaced. 
See this line which does it: https://github.com/keras-team/keras/blob/267ccbb4a76913680f4db6b400e05dea7aa84db7/docs/autogen.py#L453

When we arrive at this line for the last code block, the code isn't there, only the marker. So the marker gets saved instead of `$CODE_BLOCK_%d`. 

Feel free to use a debugger to understand what I mean. I hope I was clear enough. I advise the reviewer to be very careful, as this PR can potentially break many pages in the docs. I checked most of them, but well... we never know.

- [ ] This PR requires new unit tests [y/n] (make sure tests are included)
- [ ] This PR requires to update the documentation [y/n] (make sure the docs are up-to-date)
- [x] This PR is backwards compatible [y/n]
- [ ] This PR changes the current API [y/n] (all API changes need to be approved by fchollet)
",gabrieldemarmiesse,None,2018-10-27T19:36:10Z,2018-10-29T19:44:41Z
11498,Bug in K.rnn masking of output and states when they have more than 2 dimensions ,"**Summary**
Outputs and states are not masked correctly in `tensorflow_backend.rnn` when the number of dimensions of any of these is larger than 2. The issue is that masks are only ""tiled"" along the second dimension of outputs/states, see e.g. this [line](https://github.com/keras-team/keras/blob/master/keras/backend/tensorflow_backend.py#L2943). Note that the docs [does not state](https://github.com/keras-team/keras/blob/master/keras/backend/tensorflow_backend.py#L2854) that outputs or states should be restricted to 2 dimensions.

**Examples replicating the issue**
Output ndim > 2
```
n_samples = 3
n_timesteps = 4

def step_function(inputs, states):
    outputs = K.tile(K.expand_dims(inputs), [1, 1, 2])
    return outputs, states

inputs_vals = np.ones((n_samples, n_timesteps, 5))
inputs_vals[:, -1] = 0  # this should be ignored due to mask
initial_state_vals = [np.ones((n_samples, 6))]
mask_vals = np.ones((n_samples, n_timesteps))
mask_vals[:, -1] = 0  # final timestep masked

inputs = K.variable(inputs_vals)
initial_state = [K.variable(initial_state_vals[0])]
mask = K.variable(mask_vals)
for unroll in [True , False]:
    last_output, outputs, last_states = K.rnn(
        step_function,
        inputs,
        initial_state,
        mask=mask,
        unroll=unroll)

    expected_outputs = np.ones((n_samples, n_timesteps, 5, 2))
    assert_allclose(K.eval(outputs), expected_outputs)
```
Gives:
```
ValueError: Shapes must be equal rank, but are 3 and 2 for 'Select' (op: 'Select') with input shapes: [3,5], [3,5,2], [3,5,2].
```

States ndim > 2
```
n_samples = 3
n_timesteps = 4

def step_function(inputs, states):
    return inputs, [s + 1 for s in states]

inputs_vals = np.ones((n_samples, n_timesteps, 5))
initial_state_vals = [np.zeros((n_samples, 6, 6))]
mask_vals = np.ones((n_samples, n_timesteps))
mask_vals[:, -1] = 0  # final timestep masked

inputs = K.variable(inputs_vals)
initial_state = [K.variable(initial_state_vals[0])]
mask = K.variable(mask_vals)
for unroll in [True , False]:
    last_output, outputs, last_states = K.rnn(
        step_function,
        inputs,
        initial_state,
        mask=mask,
        unroll=unroll)
    # not updated last timestep:
    expected_last_state = np.ones((n_samples, 6, 6)) * (n_timesteps - 1)
    assert_allclose(K.eval(last_states[0]), expected_last_state)
```
Gives:
```
ValueError: Shapes must be equal rank, but are 3 and 2 for 'Select_1' (op: 'Select') with input shapes: [3,6], [3,6,6], [3,6,6]
```

**Further Implications**
Becasue of this, masking does not work for e.g. `ConvLSTM2D`, modified unit test below:
```
def test_convolutional_recurrent():

    class Masking5D(Masking):
        """"""Regular masking layer returns wrong shape of mask for RNN""""""
        def compute_mask(self, inputs, mask=None):
            return K.any(K.not_equal(inputs, 0.), axis=[2, 3, 4])

    for data_format in ['channels_first', 'channels_last']:

        if data_format == 'channels_first':
            inputs = np.random.rand(num_samples, sequence_len,
                                    input_channel,
                                    input_num_row, input_num_col)
        else:
            inputs = np.random.rand(num_samples, sequence_len,
                                    input_num_row, input_num_col,
                                    input_channel)

        for use_mask in [False, True]:  # MODIFIED
            for return_sequences in [True, False]:
                # test for return state:
                x = Input(batch_shape=inputs.shape)
                kwargs = {'data_format': data_format,
                          'return_sequences': return_sequences,
                          'return_state': True,
                          'stateful': True,
                          'filters': filters,
                          'kernel_size': (num_row, num_col),
                          'padding': 'valid'}
                layer = convolutional_recurrent.ConvLSTM2D(**kwargs)
                layer.build(inputs.shape)
                
                # MODIFIED
                if use_mask:
                    outputs = layer(Masking5D()(x))
                else:
                    outputs = layer(x)
                
                output, states = outputs[0], outputs[1:]
                assert len(states) == 2
                model = Model(x, states[0])
                state = model.predict(inputs)
                np.testing.assert_allclose(
                    K.eval(layer.states[0]), state, atol=1e-4)

                # test for output shape:
                output = layer_test(convolutional_recurrent.ConvLSTM2D,
                                    kwargs={'data_format': data_format,
                                            'return_sequences': return_sequences,
                                            'filters': filters,
                                            'kernel_size': (num_row, num_col),
                                            'padding': 'valid'},
                                    input_shape=inputs.shape)
```
Gives:
```
ValueError: Dimension must be 2 but is 5 for 'conv_lst_m2d_5/transpose_1' (op: 'Transpose') with input shapes: [1,2], [5]
``` ",andhus,None,2018-10-26T17:00:21Z,2018-11-05T23:33:49Z
11472,"Bug in masking of output in K.rnn(..., unroll=False) (for tensorflow and cntk)","**Summary**
Outputs are not masked correctly in `tensorflow_backend.rnn(..., unroll=False)`. The issue is that `states[0]` is assumed to be equal to the `output` of the `step_function` in this [line](https://github.com/keras-team/keras/blob/master/keras/backend/tensorflow_backend.py#L2976) (not so in other backends or with `unroll=True`). This holds for the built-in RNNCells, which is the reason the bug has gone undetected. Especially since the [introduction of `output_size` in the RNNCell](https://github.com/keras-team/keras/commit/66f8cc7ac4942f7f9fe0164a2a854a6264b87735) it is clear that this should not generally be assumed.

**Implications**
1) `RNN` returns the wrong output when mask is used and the `output` is not equal to `states[0]` _but has same size_ - i.e. a **quiet error**:
```
class Cell(keras.layers.Layer):

    def __init__(self):
        self.state_size = None
        self.output_size = None
        super(Cell, self).__init__()

    def build(self, input_shape):
        self.state_size = input_shape[-1]
        self.output_size = input_shape[-1]

    def call(self, inputs, states):
        return inputs, [s + 1 for s in states]

x = Input((3, 1), name=""x"")
x_masked = Masking()(x)
s_0 = Input((1,), name=""s_0"")
y, s = recurrent.RNN(Cell(),
                     return_state=True,
                     unroll=False)(x_masked, initial_state=s_0)
model = Model([x, s_0], [y, s])
model.compile(optimizer='sgd', loss='mse')

# last time step masked
x_arr = np.array([[[1.],[2.],[0.]]])
s_0_arr = np.array([[10.]])
y_arr, s_arr = model.predict([x_arr, s_0_arr])

# 1 is added to initial state two times
assert_allclose(s_arr, s_0_arr + 2)
# expect last output to be the same as last output before masking
assert_allclose(y_arr, x_arr[:, 1, :])  # Fails!
```
Gives:
```
       AssertionError: 
       Not equal to tolerance rtol=1e-07, atol=0
       
       (mismatch 100.0%)
        x: array([12.], dtype=float32)
        y: array([2.])
```

2) Exception is raised when trying to apply an RNN with a cell which `output_size != state_size[0]`
```
class Cell(keras.layers.Layer):

    def __init__(self):
        self.state_size = None
        self.output_size = None
        super(Cell, self).__init__()

    def build(self, input_shape):
        self.state_size = input_shape[-1]
        self.output_size = input_shape[-1] * 2

    def call(self, inputs, states):
        return keras.layers.concatenate([inputs]*2), [s + 1 for s in states]

x = Input((3, 1), name=""x"")
x_masked = Masking()(x)
s_0 = Input((1,), name=""s_0"")
y, s = recurrent.RNN(Cell(),
                     return_state=True,
                     unroll=False)(x_masked, initial_state=s_0)  # Fails!
```
Gives:
```
ValueError: Dimension 1 in both shapes must be equal, but are 2 and 1. Shapes are [?,2] and [?,1]. for 'rnn_1/while/Select' (op: 'Select') with input shapes: [?,?], [?,2], [?,1].
```",andhus,None,2018-10-24T07:44:41Z,2018-11-05T23:33:48Z
11458,Bug fix: Batch dot,"* Almost total rewrite of `batch_dot` for Tensorflow and CNTK backend.
* Fixes various bugs in edge cases(e.g #11035)
* Rewrite `batch_dot` implementation in `reference_operations.py`  (had bugs and overall implementation was bloated)
* Does early input validation with helpful messages.
* Earlier, the methods had partial `tf.tensordot()` like behavior, which was undocumented. This was possibly a bug first introduced in TF backend and the logic was probably copied when writing the CNTK backend. This now returns with a helpful error message.
* Reduces number of ops as much as possible.
* Slightly better docstrings
* Thorough unit tests.
 ",farizrahman4u,None,2018-10-23T06:15:11Z,2018-10-26T22:39:26Z
11289,Bug fix: model save when file already exists,"### Summary

### Related Issues

### PR Overview

- [y ] This PR requires new unit tests [y/n] (make sure tests are included)
- [n ] This PR requires to update the documentation [y/n] (make sure the docs are up-to-date)
- [y ] This PR is backwards compatible [y/n]
- [n ] This PR changes the current API [y/n] (all API changes need to be approved by fchollet)
",farizrahman4u,None,2018-10-03T15:38:31Z,2018-10-03T18:51:29Z
11276,ModelCheckpoint not saving best version due to issue with opening h5py file,"Having checked that everything is as it should be (latest version of keras, and latest version of tensorflow both installed), I have found that running a model with a model checkpoint callback that saves the best model so far causes an issue with serialisation of the model. 

[Here's a script which, when run, shows the issue.](https://gist.github.com/Microno95/cc3a34ba54cc4e7f646ce971486f57ee)

The output during imports and initialisation of the Tensorflow backend is:

~~~~
2018-10-02 12:34:47.868073: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: GeForce GTX 1080 major: 6 minor: 1 memoryClockRate(GHz): 1.7335
pciBusID: 0000:03:00.0
totalMemory: 7.93GiB freeMemory: 7.09GiB
2018-10-02 12:34:47.868102: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2018-10-02 12:34:48.075527: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-10-02 12:34:48.075556: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2018-10-02 12:34:48.075562: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2018-10-02 12:34:48.075728: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6837 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080, pci bus id: 0000:03:00.0, compute capability: 6.1)
Using TensorFlow backend.
2018-10-02 12:34:51.635814: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2018-10-02 12:34:51.635853: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-10-02 12:34:51.635859: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2018-10-02 12:34:51.635863: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2018-10-02 12:34:51.636042: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6837 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080, pci bus id: 0000:03:00.0, compute capability: 6.1)
~~~~

The full error traceback is:

~~~~
Traceback (most recent call last):
  File ""selfcontained.py"", line 107, in <module>
    print(""75th percentile of test predictions is: {:.2e}"".format(main(**CNN_params)))
  File ""selfcontained.py"", line 92, in main
    raise e
  File ""selfcontained.py"", line 76, in main
    shuffle=True, verbose=0, callbacks=[early_stopping_cb, model_saver_cb, test_csv_cb])
  File ""/home/persephone/anaconda3/lib/python3.6/site-packages/keras/engine/training.py"", line 1039, in fit
    validation_steps=validation_steps)
  File ""/home/persephone/anaconda3/lib/python3.6/site-packages/keras/engine/training_arrays.py"", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File ""/home/persephone/anaconda3/lib/python3.6/site-packages/keras/callbacks.py"", line 79, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File ""/home/persephone/anaconda3/lib/python3.6/site-packages/keras/callbacks.py"", line 446, in on_epoch_end
    self.model.save(filepath, overwrite=True)
  File ""/home/persephone/anaconda3/lib/python3.6/site-packages/keras/engine/network.py"", line 1090, in save
    save_model(self, filepath, overwrite, include_optimizer)
  File ""/home/persephone/anaconda3/lib/python3.6/site-packages/keras/engine/saving.py"", line 382, in save_model
    _serialize_model(model, f, include_optimizer)
  File ""/home/persephone/anaconda3/lib/python3.6/site-packages/keras/engine/saving.py"", line 78, in _serialize_model
    f['keras_version'] = str(keras_version).encode('utf8')
  File ""/home/persephone/anaconda3/lib/python3.6/site-packages/keras/utils/io_utils.py"", line 214, in __setitem__
    'Group with name ""{}"" exists.'.format(attr))
KeyError: 'Cannot set attribute. Group with name ""keras_version"" exists.'
~~~~

The problem seems to arise from the fact that the mode flag for opening an h5py file is not propagated through the h5dict class in keras/utils/io_utils.py when opening the file, thus the h5py file is opened with default flags that prevent overwriting existing files. 

The solution is simple (unless I am missing a key aspect of file management when it comes to serialisation) where line 186 in keras/utils/io_utils.py needs to be changed from 

```python
185        elif isinstance(path, str):
>>> 186            self.data = h5py.File(path,)
187            self._is_file = True
```

to

```python
185        elif isinstance(path, str):
>>> 186            self.data = h5py.File(path,mode)
187            self._is_file = True
```

Doing this propagates the mode parameter in the __init__ call to the underlying h5py.File object. 

As I'm not sure what the best way to submit a code patch is, I thought it would be best to create an issue outlining the problem and a potential solution.",Microno95,b'stat:contributions welcome type:bug/performance',2018-10-02T11:49:44Z,2019-07-16T16:18:18Z
11275,Unable to use load_model with Keras 2.2.3,"After updating Keras to 2.2.3 and using Tensorflow version 1.11.0, I am unable to load saved models. 

I am running a script on Google Cloud's Debian machine and am able to save and load the model there, but I am facing the error ""UnboundLocalError: local variable 'name' referenced before assignment"" when calling load_model on my local Ubuntu machine.",nole-lin,b'type:bug/performance',2018-10-02T04:21:34Z,2018-10-05T06:13:42Z
11177,Tensorflow / CNTK compatibility issue for index selection,"The simple code

```
from keras import backend as K

var = K.ones(shape=(3, 4, 5))

print(var[...,1].shape)
```
gives (3, 4) under Tensorflow backend
gives (3,4,1) under CNTK backend.
",christopher5106,b'type:bug/performance wontfix',2018-09-18T19:44:36Z,2018-09-19T07:47:49Z
11159,Bug in loading model with shared layers accross multiple levels.,"There is a bug in the `from_config` method of the Keras Network class. This bug occurs when loading a model from a config when the model uses a layer that is shared at *multiple depths* and the input tensors to the shared layer are not in the order of the layers in the model config file. 

For example, the following model creates a single dense layer then applies it to the reshaped input `x2`. It is then applied to the non-reshaped input `x1`, and again at the reshaped output.
```
sl = Dense(12)

x2 = Input((1, 12))
r2 = Reshape((12,))(x2)
r21 = sl(r2)

x1 = Input((1, 12))
r1 = Reshape((12,))(sl(x1))

r11 = sl(r1)
c1 = Concatenate()([r11, r21])
o1 = Dense(2)(c1)
```

The layers of the model are as follows:
```
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to
==================================================================================================
input_2 (InputLayer)            (None, 1, 12)        0
__________________________________________________________________________________________________
dense_1 (Dense)                 multiple             156         reshape_1[0][0]
                                                                 input_2[0][0]
                                                                 reshape_2[0][0]
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 1, 12)        0
__________________________________________________________________________________________________
reshape_2 (Reshape)             (None, 12)           0           dense_1[1][0]
__________________________________________________________________________________________________
reshape_1 (Reshape)             (None, 12)           0           input_1[0][0]
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 24)           0           dense_1[2][0]
                                                                 dense_1[0][0]
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 2)            50          concatenate_1[0][0]
==================================================================================================
```

Note that the `dense_2` layer has `reshape_1` and `reshape_2` as inputs but those layers come after `dense_2` in the list of layers.

The code in `keras/engine/network.py` contains the `from_config` method that loads the model. Then loading, the layer order of above is followed when recreating the model. At each layer Keras attempts to deserialize the layer using the inputs. When trying to deserialize  the `dense_2` layer Keras tries to create the first output but cannot because the input layers `reshape_1` aren't available, Keras next tries to create the second output using `input_2` which works because these layers are available. Keras will re-queue the first node (and third node) and will creates it at the next attempt when the input layers are available, unfortunately in doing this it swaps the output order of the output nodes of the `dense_2` layer. The model loading then fails at the `concatenate_1` layer as it uses the output nodes [0] and [2] of `dense_2` but the output node [0] is now from `input_2` which has the incorrect shape.

Note that if we change the order that we apply the shared layer so that model layer order changes this bug can be avoided. The code to reproduce the bug including code to create the layers in an order that doesn't trigger the bug is on this gist:
https://gist.github.com/adocherty/5f5c9983310ef2cf28e3ccb63ad39740

The error triggered by this script is as follows:
```
  File ""example_load_bug.py"", line 57, in <module>
    models.load_model(""test.h5"")
  File "".../lib/python3.6/site-packages/keras/engine/saving.py"", line 260, in load_model
    model = model_from_config(model_config, custom_objects=custom_objects)
  File "".../lib/python3.6/site-packages/keras/engine/saving.py"", line 334, in model_from_config
    return deserialize(config, custom_objects=custom_objects)
  File "".../lib/python3.6/site-packages/keras/layers/__init__.py"", line 55, in deserialize
    printable_module_name='layer')
  File "".../lib/python3.6/site-packages/keras/utils/generic_utils.py"", line 145, in deserialize_keras_object
    list(custom_objects.items())))
  File "".../lib/python3.6/site-packages/keras/engine/network.py"", line 1027, in from_config
    process_node(layer, node_data)
  File "".../lib/python3.6/site-packages/keras/engine/network.py"", line 986, in process_node
    layer(unpack_singleton(input_tensors), **kwargs)
  File "".../lib/python3.6/site-packages/keras/engine/base_layer.py"", line 431, in __call__
    self.build(unpack_singleton(input_shapes))
  File "".../lib/python3.6/site-packages/keras/layers/merge.py"", line 354, in build
    'Got inputs shapes: %s' % (input_shape))
ValueError: A `Concatenate` layer requires inputs with matching shapes except for the concat axis. Got inputs shapes: [(None, 12), (None, 1, 12)]
```",adocherty,b'To investigate',2018-09-17T02:27:15Z,2019-01-22T20:16:28Z
11106,Chrome timeline is broken for TensorFlow backend,"Chrome timeline is very useful to profile a Keras model, we can get the execution time for each node in the TF graph. Keras has already supported it since https://github.com/keras-team/keras/pull/6693 . But it seems this feature is broken since Keras 2.2. Run the following code to reproduce this bug:
```
import keras
from keras.datasets import mnist
from keras.models import Sequential
from keras.layers import Dense, Dropout
from keras.optimizers import RMSprop

import tensorflow as tf
from tensorflow.python.client import timeline

(x_train, y_train), (x_test, y_test) = mnist.load_data()

x_train = x_train.reshape(60000, 784).astype('float32')
y_train = keras.utils.to_categorical(y_train, 10)

model = Sequential()
model.add(Dense(512, activation='relu', input_shape=(784,)))
model.add(Dropout(0.2))
model.add(Dense(512, activation='relu'))
model.add(Dropout(0.2))
model.add(Dense(10, activation='softmax'))

run_options = tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE)
run_metadata = tf.RunMetadata()

model.compile(loss='categorical_crossentropy',
              optimizer=RMSprop(),
              metrics=['accuracy'],
              options=run_options,
              run_metadata=run_metadata)

history = model.fit(x_train, y_train,
                    batch_size=128,
                    epochs=1)

trace = timeline.Timeline(step_stats=run_metadata.step_stats)
with open('/tmp/timeline.json', 'w') as f:
    f.write(trace.generate_chrome_trace_format())
```
This is the exception:
```
Using TensorFlow backend.
Traceback (most recent call last):
  File ""test.py"", line 72, in <module>
    epochs=1)
  File ""build/bdist.macosx-10.13-intel/egg/keras/engine/training.py"", line 1016, in fit
  File ""build/bdist.macosx-10.13-intel/egg/keras/engine/training.py"", line 516, in _make_train_function
  File ""build/bdist.macosx-10.13-intel/egg/keras/backend/tensorflow_backend.py"", line 2705, in function
  File ""build/bdist.macosx-10.13-intel/egg/keras/backend/tensorflow_backend.py"", line 2552, in __init__
ValueError: ('Some keys in session_kwargs are not supported at this time: %s', ['run_metadata', 'options'])
```
It seems ```run_metadata``` and ```options``` arguments are not supported by ```K.Function```.",yanboliang,b'type:bug/performance',2018-09-08T02:07:44Z,2018-09-10T17:50:18Z
11104,"Cannot save optimizer weights due to h5 error ""object header message is too large""","When trying to save my model I get the runtime error below. There was a similar issue when model layers names were too long and it can be solved by giving layers shorter names. This time the error pops up when saving optimizer weights. getattr(model.optimizer,'weights') shows

```
[<tf.Variable 'Adam/iterations:0' shape=() dtype=int64_ref>,
 <tf.Variable 'training/Adam/Variable:0' shape=(3, 3, 1, 64) dtype=float32_ref>,
 <tf.Variable 'training/Adam/Variable_1:0' shape=(64,) dtype=float32_ref>,
 <tf.Variable 'training/Adam/Variable_2:0' shape=(64,) dtype=float32_ref>,
...]

```
and if I convert it to numpy array its length is above the 64k limits which gives h5 runtime. I can save the model if I use save_model(....,include_optimizer=False) but I need the optimizer state. Is there any way I can reduce the length of ""training/Adam/Variable:0""... names so as to fit them into 64k hdf5 table limit. Thanks.

```
---------------------------------------------------------------------------
RuntimeError                              Traceback (most recent call last)
<ipython-input-130-d231b4a5a40c> in <module>()
----> 1 model.save('model')

C:\Anaconda3\lib\site-packages\keras\engine\network.py in save(self, filepath, overwrite, include_optimizer)
   1083             raise NotImplementedError
   1084         from ..models import save_model
-> 1085         save_model(self, filepath, overwrite, include_optimizer)
   1086 
   1087     def save_weights(self, filepath, overwrite=True):

C:\Anaconda3\lib\site-packages\keras\engine\saving.py in save_model(model, filepath, overwrite, include_optimizer)
    173                     #print('Weight names',weight_names,len(weight_names),np.asarray(weight_names).nbytes)
    174                     optimizer_weights_group.attrs[
--> 175                         'weight_names'] = weight_names
    176                     for name, val in zip(weight_names, weight_values):
    177                         param_dset = optimizer_weights_group.create_dataset(

h5py\_objects.pyx in h5py._objects.with_phil.wrapper()

h5py\_objects.pyx in h5py._objects.with_phil.wrapper()

C:\Anaconda3\lib\site-packages\h5py\_hl\attrs.py in __setitem__(self, name, value)
     93         use the methods create() and modify().
     94         """"""
---> 95         self.create(name, data=value, dtype=base.guess_dtype(value))
     96 
     97     @with_phil

C:\Anaconda3\lib\site-packages\h5py\_hl\attrs.py in create(self, name, data, shape, dtype)
    186 
    187             try:
--> 188                 attr = h5a.create(self._id, self._e(tempname), htype, space)
    189             except:
    190                 raise

h5py\_objects.pyx in h5py._objects.with_phil.wrapper()

h5py\_objects.pyx in h5py._objects.with_phil.wrapper()

h5py\h5a.pyx in h5py.h5a.create()

RuntimeError: Unable to create attribute (object header message is too large)
```



Please make sure that the boxes below are checked before you submit your issue. If your issue is an implementation question, please ask your question on [StackOverflow](http://stackoverflow.com/questions/tagged/keras) or [join the Keras Slack channel](https://keras-slack-autojoin.herokuapp.com/) and ask there instead of filing a GitHub issue.

Thank you!

- [ ] Check that you are up-to-date with the master branch of Keras. You can update with:
pip install git+git://github.com/keras-team/keras.git --upgrade --no-deps

- [ ] If running on TensorFlow, check that you are up-to-date with the latest version. The installation instructions can be found [here](https://www.tensorflow.org/get_started/os_setup).

- [ ] If running on Theano, check that you are up-to-date with the master branch of Theano. You can update with:
pip install git+git://github.com/Theano/Theano.git --upgrade --no-deps

- [ ] Provide a link to a GitHub Gist of a Python script that can reproduce your issue (or just copy the script here if it is short).
",sakvaua,b'type:bug/performance',2018-09-07T08:36:58Z,2018-09-28T18:59:59Z
11059,Bug fix: batch_dot,"* Almost total rewrite of `batch_dot` for Tensorflow and CNTK backend.
* Fixes various bugs in edge cases(e.g #11035)
* Does early input validation with helpful messages.
* Earlier, the methods had partial `tf.tensordot()` like behavior, which was undocumented. This was possibly a bug first introduced in TF backend and the logic was probably copied when writing the CNTK backend. This now returns with a helpful error message.
* Reduces number of ops as much as possible.
* Slightly better docstrings
* Thorough unit tests.
 ",farizrahman4u,None,2018-09-02T13:41:43Z,2018-10-23T06:14:53Z
11035,batch_dot() behavior inconsistent between different backends,"The following code worked well using the backend of tensorflow.
```python
import numpy as np
np.random.seed=0
a=np.random.uniform(0,100,[2,4,3])
b=np.random.uniform(0,100,[2,3,5])
import keras
k=keras.backend
ka=k.variable(a)
kb=k.variable(b)
kc=k.batch_dot(ka, kb, (2,1))
k.eval(kc)
```
But it returned incorrect result using the backend of cntk: kc.shape=[2,4,2,5].",Giszy,b'type:bug/performance',2018-08-30T11:02:33Z,2018-11-26T21:01:21Z
10944,Keras >= 2.2.1 no longer respects fit_generator(validation_steps=...),"It seems that starting with Keras 2.2.1 `fit_generator()` no longer stops the validation process after `validation_steps` steps, but continues through the entire sequence. See this example code:

```
import numpy
from keras import Input, Model
from keras.layers import Dense
from keras.utils import Sequence

class Gen(Sequence):
    def __init__(self, name):
        super().__init__()
        self.name = name

    def __len__(self):
        return 1000

    def __getitem__(self, index):
        print('Generate %s %d' % (self.name, index))
        return numpy.zeros(shape=(10, 10)), numpy.zeros(shape=(10, 2))

i = Input(shape=(10,))
o = Dense(units=2)(i)
m = Model(i, o)
m.compile('sgd', 'mse')
m.fit_generator(
    generator=Gen('training_data'),
    shuffle=False,
    steps_per_epoch=5,
    validation_data=Gen('validation_data'),
    validation_steps=5,
    workers=1,
    max_queue_size=1,
    verbose=0,
)
```

Which will output

```
Generate validation_data 0
Generate validation_data 1
Generate training_data 0
Generate training_data 1
Generate training_data 2
Generate training_data 3
Generate training_data 4
Generate training_data 5
Generate training_data 6
Generate validation_data 2
Generate validation_data 3
Generate validation_data 4
Generate validation_data 5
Generate validation_data 6
Generate validation_data 7
...
Generate validation_data 998
Generate validation_data 999
```

This was working fine in keras 2.2.0.",jlherren,b'type:bug/performance',2018-08-20T07:47:35Z,2018-08-21T22:51:01Z
10733,BUG FIX #6351: Make sparse_categorical_crossentropy work with 3D outputs.,"### Summary
Make sparse_categorical_crossentropy work with 3D outputs.

### Related Issues
#6351

### PR Overview

- [ ] This PR requires new unit tests [y/n] (make sure tests are included)
- [ ] This PR requires to update the documentation [y/n] (make sure the docs are up-to-date)
- [X] This PR is backwards compatible [y/n]
- [ ] This PR changes the current API [y/n] (all API changes need to be approved by fchollet)
",Cheukting,None,2018-07-19T23:05:13Z,2018-08-22T18:15:43Z
10648,Bug with BatchNormalization(axis=1): ValueError: Shape must be rank 1 but is rank 4 for 'batch_normalization_1/cond/FusedBatchNorm',"Current master version of keras (commit b3cb261b22a73d195a527592b49ca57e8c9ac9f5), TensorFlow 1.8.0

`BatchNormalization(axis=1)` for `'channels_first'` seems to fail.

```python
import os
os.environ['KERAS_BACKEND'] = 'tensorflow'
import keras.backend as K
from keras.layers import Activation, Conv2D, Input
from keras.layers.normalization import BatchNormalization

# declare network model with channels first: ERROR
K.set_image_data_format('channels_first')
input = Input(shape=(3, 1001, 1001), dtype='float32')
x = Conv2D(filters=64, kernel_size=(3, 3), strides=1, padding='same')(input)
x = BatchNormalization(axis=1)(x)
x = Activation('relu')(x)
```

gives the error

```
Traceback (most recent call last):
  File ""/home/rcasero/.conda/envs/cytometer_tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 1567, in _create_c_op
    c_op = c_api.TF_FinishOperation(op_desc)
tensorflow.python.framework.errors_impl.InvalidArgumentError: Shape must be rank 1 but is rank 4 for 'batch_normalization_1/cond/FusedBatchNorm' (op: 'FusedBatchNorm') with input shapes: [?,64,1001,1001], [1,64,1,1], [1,64,1,1], [1,64,1,1], [1,64,1,1].
During handling of the above exception, another exception occurred:
Traceback (most recent call last):
  File ""<input>"", line 11, in <module>
  File ""/home/rcasero/.conda/envs/cytometer_tensorflow/lib/python3.6/site-packages/keras/engine/base_layer.py"", line 459, in __call__
    output = self.call(inputs, **kwargs)
  File ""/home/rcasero/.conda/envs/cytometer_tensorflow/lib/python3.6/site-packages/keras/layers/normalization.py"", line 204, in call
    training=training)
  File ""/home/rcasero/.conda/envs/cytometer_tensorflow/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py"", line 3069, in in_train_phase
    x = switch(training, x, alt)
  File ""/home/rcasero/.conda/envs/cytometer_tensorflow/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py"", line 3004, in switch
    else_expression_fn)
  File ""/home/rcasero/.conda/envs/cytometer_tensorflow/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py"", line 432, in new_func
    return func(*args, **kwargs)
  File ""/home/rcasero/.conda/envs/cytometer_tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py"", line 2072, in cond
    orig_res_f, res_f = context_f.BuildCondBranch(false_fn)
  File ""/home/rcasero/.conda/envs/cytometer_tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py"", line 1913, in BuildCondBranch
    original_result = fn()
  File ""/home/rcasero/.conda/envs/cytometer_tensorflow/lib/python3.6/site-packages/keras/layers/normalization.py"", line 165, in normalize_inference
    epsilon=self.epsilon)
  File ""/home/rcasero/.conda/envs/cytometer_tensorflow/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py"", line 1894, in batch_normalization
    is_training=False
  File ""/home/rcasero/.conda/envs/cytometer_tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/nn_impl.py"", line 904, in fused_batch_norm
    name=name)
  File ""/home/rcasero/.conda/envs/cytometer_tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/gen_nn_ops.py"", line 3429, in _fused_batch_norm
    is_training=is_training, name=name)
  File ""/home/rcasero/.conda/envs/cytometer_tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py"", line 787, in _apply_op_helper
    op_def=op_def)
  File ""/home/rcasero/.conda/envs/cytometer_tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 3392, in create_op
    op_def=op_def)
  File ""/home/rcasero/.conda/envs/cytometer_tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 1734, in __init__
    control_input_ops)
  File ""/home/rcasero/.conda/envs/cytometer_tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 1570, in _create_c_op
    raise ValueError(str(e))
ValueError: Shape must be rank 1 but is rank 4 for 'batch_normalization_1/cond/FusedBatchNorm' (op: 'FusedBatchNorm') with input shapes: [?,64,1001,1001], [1,64,1,1], [1,64,1,1], [1,64,1,1], [1,64,1,1].
```

Meanwhile, `BatchNormalization(axis=3)` for `'channels_last'` works.

```python
import os
os.environ['KERAS_BACKEND'] = 'tensorflow'
import keras.backend as K
from keras.layers import Activation, Conv2D, Input
from keras.layers.normalization import BatchNormalization

# declare network model with channels last: NO ERROR
K.set_image_data_format('channels_last')
input = Input(shape=(1001, 1001, 3), dtype='float32')
x = Conv2D(filters=64, kernel_size=(3, 3), strides=1, padding='same')(input)
x = BatchNormalization(axis=3)(x)
x = Activation('relu')(x)
```

doesn't give any error.
",rcasero,b'backend:tensorflow',2018-07-11T16:11:29Z,2020-09-06T15:55:47Z
10213,Bug---Custom loss with metrics [acc] when using sparse categories.,"when i use a custom loss and the second label is sparse.
if the model.compile like this:
model.compile(loss=['binary_crossentropy', self_loss], optimizer='SGD', loss_weights=[1, 1], metrics=['acc']).
the accuracy of the second output will not be correct, i dig into the source code [keras/engine/training] and find that:

for metric in metrics:
                if metric in ('accuracy', 'acc', 'crossentropy', 'ce'):
                    # custom handling of accuracy/crossentropy
                    # (because of class mode duality)
                    output_shape = K.int_shape(self.outputs[i])
                    if (output_shape[-1] == 1 or
                       self.loss_functions[i] == losses.binary_crossentropy):
                        # case: binary accuracy/crossentropy
                        if metric in ('accuracy', 'acc'):
                            metric_fn = metrics_module.binary_accuracy
                        elif metric in ('crossentropy', 'ce'):
                            metric_fn = metrics_module.binary_crossentropy
                    elif self.loss_functions[i] == losses.sparse_categorical_crossentropy:
                        # case: categorical accuracy/crossentropy
                        # with sparse targets
                        if metric in ('accuracy', 'acc'):
                            metric_fn = metrics_module.sparse_categorical_accuracy
                        elif metric in ('crossentropy', 'ce'):
                            metric_fn = metrics_module.sparse_categorical_crossentropy
                    else:
                        # case: categorical accuracy/crossentropy
                        if metric in ('accuracy', 'acc'):
                            metric_fn = metrics_module.categorical_accuracy
                        elif metric in ('crossentropy', 'ce'):
                            metric_fn = metrics_module.categorical_crossentropy

the source code will use categorical_crossentropy if you do not use sparse_categorical_crossentropy when compile. So, i think may be there is a bug. Hope for answering!",LCorleone,None,2018-05-16T11:52:22Z,2018-05-16T11:53:31Z
10073,Bug of cntk backend,"I found some bug of cntk backend.

Example code:
```python
import keras.backend as K
import cntk as C
import numpy as np

A=np.array([[1,1,1]])[:,:,np.newaxis]
x = K.placeholder(ndim=3)
f = K.function([x],[C.softmax(x,axis=1)])
print f([A])
print C.softmax(A, axis=1).eval()
```

The result is 
```
[array([[[1.],
        [1.],
        [1.]]], dtype=float32)]
[[[0.33333334]
  [0.33333334]
  [0.33333334]]]
```

It should be the same but the result is different.",bobchennan,None,2018-04-30T17:28:58Z,2018-09-13T11:19:17Z
9947,Bug: l2_normalize() broken in Keras 2.1.5 with TensorFlow backend,"Gist with minimal reproduceable example to reproduce the bug:

https://gist.github.com/pierluigiferrari/29664c7cd5787a8713e0623eb08f6ca8

Bug description:

Since Keras 2.1.5, if you use the TensorFlow backend, `l2_normalize()` throws the following error when called:

```
---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
<ipython-input-42-56edaf12926f> in <module>()
      1 tensor = K.ones(shape=(16,10,10,256))
----> 2 tensor = K.l2_normalize(tensor, axis=3)

/Users/pierluigiferrari/anaconda/envs/tf1keras2/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py in l2_normalize(x, axis)
   3149         A tensor.
   3150     """"""
-> 3151     return tf.nn.l2_normalize(x, axis=axis)
   3152 
   3153 

TypeError: l2_normalize() got an unexpected keyword argument 'axis'
```

I get this behavior with TF v1.4.1.",pierluigiferrari,None,2018-04-15T17:29:15Z,2018-04-15T17:54:29Z
9599,bug fix - run_internal_graph(),See #9565,farizrahman4u,None,2018-03-08T20:07:55Z,2019-03-01T11:51:29Z
9520,Bug-fix cifar10 capsule missing K.sum() margin_loss,"Fix https://github.com/keras-team/keras/issues/9519
In accordance to issue 9519 I implemented the missing sum around the margin_loss implementation.",saralajew,None,2018-03-01T08:49:47Z,2018-03-01T19:36:20Z
9506,Sequence as validation_data fails in fit_generator when workers=0,"Calling `fit_generator` with validation_data as a sequence works as expected for `workers > 0` but fails for `workers == 0`.

I get:
```
Traceback (most recent call last):
  File ""sequence_test.py"", line 27, in <module>
    workers=0
  File ""/home/aplotnicki/envs/tf/lib/python3.5/site-packages/keras/legacy/interfaces.py"", line 87, in wrapper
    return func(*args, **kwargs)
  File ""/home/aplotnicki/envs/tf/lib/python3.5/site-packages/keras/engine/training.py"", line 2169, in fit_generator
    use_multiprocessing=use_multiprocessing)
  File ""/home/aplotnicki/envs/tf/lib/python3.5/site-packages/keras/legacy/interfaces.py"", line 87, in wrapper
    return func(*args, **kwargs)
  File ""/home/aplotnicki/envs/tf/lib/python3.5/site-packages/keras/engine/training.py"", line 2280, in evaluate_generator
    generator_output = next(output_generator)
TypeError: 'TestSequence' object is not an iterator
```

When running the following script. If `workers > 0` there is no problem.

```
import keras.utils
from keras.models import Model, Input
import numpy as np

class TestSequence(keras.utils.Sequence):
    def __init__(self):
        pass
        
    def __len__(self):
        return 1
    
    def __getitem__(self, idx):
        return np.array([1.]), np.array([1.])
    
def TestGenerator():
    while True:
        yield np.array([1.]), np.array([1.])
        
input = Input((None,))
model = Model(input, input)
model.compile(optimizer='adam', loss='mse')

model.fit_generator(
    TestGenerator(),
    steps_per_epoch=10,
    validation_data=TestSequence(),
    workers=0
)
```

Why would I want to do this? Testing related to investigating thread safety of my generator and sequence implementations.

What probably causes this?

I expect that [this line](https://github.com/keras-team/keras/blob/master/keras/engine/training.py#L2150) leads to code that handles sequences, but at the `else` clause, [this line](https://github.com/keras-team/keras/blob/master/keras/engine/training.py#L2165) does not.

Checkboxes:

- [X] Check that you are up-to-date with the master branch of Keras. You can update with:
pip install git+git://github.com/keras-team/keras.git --upgrade --no-deps
**Cloned and installed from github as at now. 6b2a04f**

- [ ] If running on TensorFlow, check that you are up-to-date with the latest version. The installation instructions can be found [here](https://www.tensorflow.org/get_started/os_setup).
**tensorflow.__version__ == 1.4.0
Don't believe this is significant.**

- [X] Provide a link to a GitHub Gist of a Python script that can reproduce your issue (or just copy the script here if it is short).
",alekseynp,b'type:bug/performance',2018-02-27T21:07:59Z,2018-03-01T18:54:30Z
9434,Error with multiprocessing on Sequence in fit_generator(),"I'm trying to use a `Sequence` as the generator for `model.fit_generator()`.

With `use_multiprocessing=False` it works fine, but with `use_multiprocessing=True` an error is produced.

**Minimal working example:**
```python
from keras.utils import Sequence
from keras.models import Sequential
from keras.layers import Dense
from keras.utils import to_categorical
import numpy as np

class DummySequence(Sequence):
    
    def __init__(self, x_set, y_set, batch_size):
        self.x, self.y = x_set, y_set
        self.batch_size = batch_size

    def __len__(self):
        return int(np.ceil(len(self.x) / float(self.batch_size)))

    def __getitem__(self, idx):
        batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]
        batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]

        return np.array(batch_x), np.array(batch_y)

if __name__ == '__main__':

    x = np.random.random((100, 3))
    y = to_categorical(np.random.random(100) > .5).astype(int)

    seq = DummySequence(x, y, 10)

    model = Sequential()
    model.add(Dense(32, input_dim=3))
    model.add(Dense(2, activation='softmax'))
    model.compile(optimizer='rmsprop',
                  loss='categorical_crossentropy',
                  metrics=['accuracy'])

    model.fit_generator(generator=seq, workers=2, use_multiprocessing=True)
```
**Error:**
```
Traceback (most recent call last):
  File ""C:\Users\elcombato\AppData\Local\Continuum\Anaconda3\envs\ml\lib\multiprocessing\pool.py"", line 119, in worker
    result = (True, func(*args, **kwds))
  File ""C:\Users\elcombato\AppData\Local\Continuum\Anaconda3\envs\ml\lib\site-packages\keras\utils\data_utils.py"", line 392, in get_index
    return _SHARED_SEQUENCES[uid][i]
KeyError: 0
```

**Setup**
Windows 10
Python 3.6.4
Keras 2.1.3
Tensorflow 1.2.1",elcombato,b'type:bug/performance',2018-02-20T15:49:58Z,2018-02-21T18:52:02Z
8494,bug fix on pandas DataFrame support,"This PR will try to fix some pandas DataFrame related issues, including https://github.com/fchollet/keras/pull/8199 and https://github.com/fchollet/keras/pull/8290.

 - Pandas DataFrame check is moved, in order to make sure that keras will check `array`/`list`/`dict` first, then `numpy.ndarray`/`pandas.DataFrame`.
 - Add standalone `test_pandas_dataframe` unit test, covering `Model.fit`, `Model.predict`, `Model.predict_on_batch`, `Model.evaluate`, `Model.train_on_batch`, `Model.test_on_batch` functions, and `array`/`list`/`dict` inputs.",icyblade,None,2017-11-15T04:16:05Z,2017-11-16T04:29:32Z
8384,Bugs with ImageDataGenerator,"I am using model.predict_generator and ImageDataGenerator to predict my image label, my code is as follows:
    `valid_gen= ImageDataGenerator().flow_from_directory(""../input/valid/valid"", target_size=(input_size, input_size),shuffle=False, batch_size=1)`
   `pred = model.predict_generator(generator=valid_gen, steps = 1, verbose=1)` 

actually I put only one image into folder ""../input/valid/valid"", then I check the predict result, I found it is totally wrong. I test for many images, so I think this is a bug. Anyone got some idea about this?
",jamesben6688,None,2017-11-04T08:54:00Z,2017-11-04T13:22:16Z
8025,Bug fix: Models with shared layers shouldn't be considered Sequential like,"As of now, the following model is being considered as a ""Sequential-like"":

```python
from keras.layers import *
from keras.models import *

a = Input((5,))
dense = Dense(5)
b = dense(a)
c = dense(b)

model = Model(a, c)
model.summary()
```
",farizrahman4u,None,2017-09-30T00:46:25Z,2017-10-02T21:57:37Z
7903,Bug fix: Don't change original dict in from_config,,farizrahman4u,None,2017-09-15T18:39:46Z,2018-06-12T06:52:54Z
7512,bug in sparse_categorical_crossentropy in theano backend,"theano `sparse_categorical_crossentropy` calls `categorical_crossentropy` on line 
https://github.com/fchollet/keras/blob/master/keras/backend/theano_backend.py#L1539
but the call is using the wrong order of parameters. should be 
```
    return categorical_crossentropy(target, output, from_logits)
```
",udibr,b'stale',2017-08-03T16:06:06Z,2017-12-01T17:07:41Z
7222,Bug fix: Support multiple outputs in Lambda layer,#7221 ,farizrahman4u,None,2017-07-03T15:12:26Z,2017-10-11T17:46:49Z
6824,bug in cosine similarity computation of Keras version 2.0.4,"First, let's compare the dot product and cosine similarity in a toy data:
`Dot Product:`
`import numpy as np`
`tensor_a = Input(shape=(4,6,))`
`tensor_b = Input(shape=(4,6,))`
`merged_tensor = merge([tensor_a, tensor_b], mode='dot',dot_axes=-1)`
`m = Model([tensor_a, tensor_b], [merged_tensor])`
`input_a=np.ones((2,4,6))`
`input_b=np.ones((2,4,6))`
`input_a[0][0][0]=0`
`m.predict([input_a, input_b])`

The output is as following, which is **correct**: 
       
         array([[[ 5.,  5.,  5.,  5.],
         [ 6.,  6.,  6.,  6.],
         [ 6.,  6.,  6.,  6.],
         [ 6.,  6.,  6.,  6.]],

       [[ 6.,  6.,  6.,  6.],
        [ 6.,  6.,  6.,  6.],
        [ 6.,  6.,  6.,  6.],
        [ 6.,  6.,  6.,  6.]]], dtype=float32)`

Then simple change the dot similarity to cosine similarity:
`merged_tensor = merge([tensor_a, tensor_b], mode='cos',dot_axes=-1)`
`m = Model([tensor_a, tensor_b], [merged_tensor])`
`m.predict([input_a, input_b])`

The output is as follows, which is **incorrect.** (how can a cosine similarity greater than 1?!):

       array([[[[ 0.91287088,  0.91287088,  0.91287088,  0.91287088],
         [ 1.09544504,  1.        ,  1.        ,  1.        ],
         [ 1.09544504,  1.        ,  1.        ,  1.        ],
         [ 1.09544504,  1.        ,  1.        ,  1.        ]]],


       [[[ 1.        ,  1.        ,  1.        ,  1.        ],
         [ 1.        ,  1.        ,  1.        ,  1.        ],
         [ 1.        ,  1.        ,  1.        ,  1.        ],
         [ 1.        ,  1.        ,  1.        ,  1.        ]]]], dtype=float32)",jinfengr,None,2017-06-01T19:54:55Z,2018-01-13T21:44:05Z
6786,Bugfix: GeneratorEnqueuer should not change the generated batches' order when workers > 1,"This is a proposed fix for the erroneous behaviour described in #6745.
I ran tests on Ubuntu 16.04 with python 3.5 and 2.7, all tests pass.
I also ran tests on Windows with python 3.5 (Tensorflow currently does not support python 2.7 on Windows) and all tests except those using multiprocessing pass.
The tests that fail are affected by the error mentioned in #5071.

**Description of the bug fix**: The idea is to exploit `multiprocessing`'s `Pool.apply_asynch` which does not block and immediately returns a `multiprocessing.pool.ApplyResult` object that is put in the queue.
The generator's batches order is kept by using a lock that guarantees that no thread can get a new batch until the last batch's `ApplyResult` object has been put in the queue.
Note that to keep the `GeneratorEnqueuer`'s external interface the same, I had to define two ""private"" classes that redefine the queues' `get()` method to actually return `ApplyResult.get()` (which may block if the result is not ready yet).

**NOTE**: Incidentally, fixing the original bug also led to the discovery and subsequent fix of a second bug.

**TL;DR**: The second bug would cause a `GeneratorEnqueuer` instance to stall potentially causing a deadlock. Now this cannot happen anymore.

**Second bug explanation:**
If:
1) the queue is full
2) a thread tries to `put()` and blocks until the queue has space again
3) the `GeneratorEnqueuer` instance calls `stop()`.

the thread calling `stop()` would block waiting for the thread waiting on `put()` to unblock. This would happen only if some thread calls `pop()` on the queue. This might lead to deadlock if the only thread popping from the queue is the thread calling `stop()`.

This behaviour is now prevented by the lock before the test on the queue length, which ensures no thread will ever try to `put()` when the queue is full.
",GPhilo,None,2017-05-29T10:01:09Z,2017-05-29T11:13:36Z
6581,Bug fix: convolutional recurrent (again),,farizrahman4u,None,2017-05-10T20:56:56Z,2017-05-15T11:20:52Z
6574,Bug fix in ZeroPadding3D,,Danielhiversen,None,2017-05-10T09:53:01Z,2017-05-11T15:53:15Z
6564,Bug fix + test : Initializing states for ConvLSTM2D,,farizrahman4u,None,2017-05-09T19:50:24Z,2017-05-10T00:32:38Z
6562,Bug : Specifying initial state for ConvLSTM2D layers,"I encountered an error when try to input the initial_state to the ConvLSTM2D layer.

```
lstm_input = Input(shape=(None,) + (32, 32, 3)) 
initial_state_input = Input(shape=(32, 32, 3)) 
x = ConvLSTM2D(128, (3,3), initial_state=initial_state_input, name='lstm')(lstm_input)
```

It gives me an error message: TypeError: ('Keyword argument not understood:', 'initial_state')

Probably ""initial_state"" has not been implemented for ConvLSTM2D layer? If so, what else method I could use to set the hidden state of the ConvLSTM2D layer? #6142 

Thanks!",xn8812,b'stale',2017-05-09T17:20:23Z,2017-09-11T14:11:58Z
6481,Bug loading a model with an add layer,"I created a model with some shared layers (a `Dense` in the example) and use an `add` layer, it fails to `load_model`. This is an example:

    from keras.models import Model, load_model
    from keras.layers import Dense, Input, add 
    x = Input(shape=(100,))
    y = x 
    weights = Dense(100)
    for _ in range(5):
        yp = weights(y)
        y = add([yp, y]) 
    model = Model(x, y)
    model.save('test.h5')
    model2 = load_model('test.h5')

that fails with:
```
Using TensorFlow backend.
Traceback (most recent call last):
  File ""test.py"", line 16, in <module>
    model2 = load_model('test.h5')
  File ""/home/javier/.local/lib/python3.5/site-packages/keras/models.py"", line 240, in load_model
    model = model_from_config(model_config, custom_objects=custom_objects)
  File ""/home/javier/.local/lib/python3.5/site-packages/keras/models.py"", line 304, in model_from_config
    return layer_module.deserialize(config, custom_objects=custom_objects)
  File ""/home/javier/.local/lib/python3.5/site-packages/keras/layers/__init__.py"", line 54, in deserialize
    printable_module_name='layer')
  File ""/home/javier/.local/lib/python3.5/site-packages/keras/utils/generic_utils.py"", line 140, in deserialize_keras_object
    list(custom_objects.items())))
  File ""/home/javier/.local/lib/python3.5/site-packages/keras/engine/topology.py"", line 2416, in from_config
    process_layer(layer_data)
  File ""/home/javier/.local/lib/python3.5/site-packages/keras/engine/topology.py"", line 2403, in process_layer
    raise ValueError('Missing layer: ' + inbound_layer_name)}
 ValueError: Missing layer: add_1
```",javiercorrea,b'stale',2017-05-02T21:07:19Z,2017-12-05T16:22:07Z
6442,Bug with saving the model,"I want to rescale the outputs of my model, so I do the following.

```python
state_in = ...
h = ...
scale_vector = K.variable(value=np_scale_vector) # np_scale_vector is a numpy array
out = Lambda(lambda x: x * scale_vector, output_shape=(n_out,))(h)

model = Model(inputs=[state_in], outputs=[out])
model.save(filename)
```
I get:
```
  File ""/usr/local/lib/python2.7/dist-packages/keras/engine/topology.py"", line 2434, in save
    save_model(self, filepath, overwrite, include_optimizer)
  File ""/usr/local/lib/python2.7/dist-packages/keras/models.py"", line 102, in save_model
    'config': model.get_config()
  File ""/usr/local/lib/python2.7/dist-packages/keras/engine/topology.py"", line 2311, in get_config
    return copy.deepcopy(config)
  File ""/usr/lib/python2.7/copy.py"", line 163, in deepcopy
    y = copier(x, memo)
  File ""/usr/lib/python2.7/copy.py"", line 182, in deepcopy
    rv = reductor(2)
TypeError: can't pickle NotImplementedType objects
```

If I, on the other hand do

```python
out = Lambda(lambda x: x * np_scale_vector, output_shape=(n_out,))(h)
```

I get:
```
  File ""/usr/local/lib/python2.7/dist-packages/keras/engine/topology.py"", line 2434, in save
    save_model(self, filepath, overwrite, include_optimizer)
  File ""/usr/local/lib/python2.7/dist-packages/keras/models.py"", line 103, in save_model
    }, default=get_json_type).encode('utf8')
  File ""/usr/lib/python2.7/json/__init__.py"", line 251, in dumps
    sort_keys=sort_keys, **kw).encode(obj)
  File ""/usr/lib/python2.7/json/encoder.py"", line 207, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File ""/usr/lib/python2.7/json/encoder.py"", line 270, in iterencode
    return _iterencode(o, 0)
  File ""/usr/local/lib/python2.7/dist-packages/keras/models.py"", line 77, in get_json_type
    return obj.item()
ValueError: can only convert an array of size 1 to a Python scalar
```

I want to emphasize that the model compiles, works, I can see that I am getting proper outputs, but the save fails.",hamzamerzic,None,2017-04-29T13:34:29Z,2017-05-01T07:58:50Z
6393,Bug fix in recurrent layer,"The variable `values` is not defined in the file, 

@Joshua-Chin: Could you check that this is correct?",Danielhiversen,None,2017-04-25T08:47:11Z,2017-04-25T18:05:53Z
6308,Bug in Babi MemNN Example in Attention Mechanism,"Please make sure that the boxes below are checked before you submit your issue. If your issue is an implementation question, please ask your question on [StackOverflow](http://stackoverflow.com/questions/tagged/keras) or [join the Keras Slack channel](https://keras-slack-autojoin.herokuapp.com/) and ask there instead of filing a GitHub issue.

Thank you!

- [x] Check that you are up-to-date with the master branch of Keras. You can update with:
pip install git+git://github.com/fchollet/keras.git --upgrade --no-deps

- [x] If running on TensorFlow, check that you are up-to-date with the latest version. The installation instructions can be found [here](https://www.tensorflow.org/get_started/os_setup).

- [ ] If running on Theano, check that you are up-to-date with the master branch of Theano. You can update with:
pip install git+git://github.com/Theano/Theano.git --upgrade --no-deps

- [x] Provide a link to a GitHub Gist of a Python script that can reproduce your issue (or just copy the script here if it is short). (NA)

I was looking at the Keras example for the MemNN model for the babi single supporting task. The paper is here: https://arxiv.org/pdf/1503.08895.pdf (relevant equations/figures are on page 2 in section 2.1)

I believe there is a bug in the implementation here: https://github.com/fchollet/keras/blob/master/examples/babi_memnn.py#L210

`match` is attention over a set of memory vectors represented as `input_encoded_c`. In the paper these are referenced as `p_i` and `c_i` respectively where `p_i` is a scalar and `c_i`is a vector. The formula from the paper broadcasts `p_i` to `c_i` in the sum `o=sum_i p_i*c_i` to produce the final output which in the code is `response`.

The implementation in the models repo uses `response = add([match, input_encoded_c])`. I think this should be something like `response = multiply([match, input_encoded_c])` instead since the current implementation seems to incorrectly correspond to `o=sum_i p_i + c_i`. Perhaps this is also the reason that there is a difference of performance with the paper result of 98.6% vs 100%?

If this does seem like a bug I would be happy to make the change, run the model to make sure it works, and submit a pull request.",EntilZha,b'stale',2017-04-18T18:28:50Z,2017-10-12T06:28:52Z
6219,Bug fix: K.batch_dot(); tf backend,#6173 ,farizrahman4u,None,2017-04-10T20:50:42Z,2017-04-10T23:12:09Z
6173,K.batch_dot() doc example fails w/ Tensorflow backend,"From the batch_dot section of the Backend docs (https://keras.io/backend/):

> Shape inference: Let x's shape be (100, 20) and y's shape be (100, 30, 20). If axes is (1, 2), to find the output shape of resultant tensor, loop through each dimension in x's shape and y's shape:
> 
>     x.shape[0] : 100 : append to output shape
>     x.shape[1] : 20 : do not append to output shape, dimension 1 of x has been summed over. (dot_axes[0] = 1)
>     y.shape[0] : 100 : do not append to output shape, always ignore first dimension of y
>     y.shape[1] : 30 : append to output shape
>     y.shape[2] : 20 : do not append to output shape, dimension 2 of y has been summed over. (dot_axes[1] = 2) output_shape = (100, 30)
> 

Actually running this (see below code) produces errors when using the newest Tensorflow.  Seems to be ok with Theano.


Please make sure that the boxes below are checked before you submit your issue. If your issue is an implementation question, please ask your question on [StackOverflow](http://stackoverflow.com/questions/tagged/keras) or [join the Keras Slack channel](https://keras-slack-autojoin.herokuapp.com/) and ask there instead of filing a GitHub issue.

Thank you!

- [x] Check that you are up-to-date with the master branch of Keras. You can update with:
pip install git+git://github.com/fchollet/keras.git --upgrade --no-deps

- [x] If running on TensorFlow, check that you are up-to-date with the latest version. The installation instructions can be found [here](https://www.tensorflow.org/get_started/os_setup).

- [x] If running on Theano, check that you are up-to-date with the master branch of Theano. You can update with:
pip install git+git://github.com/Theano/Theano.git --upgrade --no-deps

- [x] Provide a link to a GitHub Gist of a Python script that can reproduce your issue (or just copy the script here if it is short).
```
from keras import backend as K

x = K.ones(shape=(100,20))
y = K.ones(shape=(100,30,20))
xy = K.batch_dot(x,y,axes=(1,2))
```

Fails with...
Using TensorFlow backend.
Traceback (most recent call last):
  File ""/opt/anaconda/envs/py35/lib/python3.5/site-packages/tensorflow/python/framework/common_shapes.py"", line 671, in _call_cpp_shape_fn_impl
    input_tensors_as_shapes, status)
  File ""/opt/anaconda/envs/py35/lib/python3.5/contextlib.py"", line 66, in __exit__
    next(self.gen)
  File ""/opt/anaconda/envs/py35/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py"", line 466, in raise_exception_on_not_ok_status
    pywrap_tensorflow.TF_GetCode(status))
tensorflow.python.framework.errors_impl.InvalidArgumentError: Shape must be rank 2 but is rank 3 for 'MatMul' (op: 'MatMul') with input shapes: [100,20], [100,30,20].

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""batch_dot_test.py"", line 6, in <module>
    xy = K.batch_dot(x,y,axes=(1,2))
  File ""/opt/anaconda/envs/py35/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py"", line 917, in batch_dot
    out = tf.matmul(x, y, adjoint_a=adj_x, adjoint_b=adj_y)
  File ""/opt/anaconda/envs/py35/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py"", line 1801, in matmul
    a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)
  File ""/opt/anaconda/envs/py35/lib/python3.5/site-packages/tensorflow/python/ops/gen_math_ops.py"", line 1263, in _mat_mul
    transpose_b=transpose_b, name=name)
  File ""/opt/anaconda/envs/py35/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py"", line 768, in apply_op
    op_def=op_def)
  File ""/opt/anaconda/envs/py35/lib/python3.5/site-packages/tensorflow/python/framework/ops.py"", line 2338, in create_op
    set_shapes_for_outputs(ret)
  File ""/opt/anaconda/envs/py35/lib/python3.5/site-packages/tensorflow/python/framework/ops.py"", line 1719, in set_shapes_for_outputs
    shapes = shape_func(op)
  File ""/opt/anaconda/envs/py35/lib/python3.5/site-packages/tensorflow/python/framework/ops.py"", line 1669, in call_with_requiring
    return call_cpp_shape_fn(op, require_shape_fn=True)
  File ""/opt/anaconda/envs/py35/lib/python3.5/site-packages/tensorflow/python/framework/common_shapes.py"", line 610, in call_cpp_shape_fn
    debug_python_shape_fn, require_shape_fn)
  File ""/opt/anaconda/envs/py35/lib/python3.5/site-packages/tensorflow/python/framework/common_shapes.py"", line 676, in _call_cpp_shape_fn_impl
    raise ValueError(err.message)
ValueError: Shape must be rank 2 but is rank 3 for 'MatMul' (op: 'MatMul') with input shapes: [100,20], [100,30,20].

When using Theano, no output appears at all, indicating success.",drscotthawley,b'type:bug/performance',2017-04-06T04:39:47Z,2017-04-10T22:56:11Z
6169,Embedding layer w/ mask in a nested model,"The following code raises an error on the last line (when attempting to fit the model). However it works fine if mask_zero is set to False. It also works if base_model is added to a Sequential model.

```
import numpy as np

from keras.models import Model
from keras.layers import Input, Embedding, SimpleRNN, Dense


# Base model
base_inputs = Input(shape=(10, ))
embeddings = Embedding(input_dim=100,
                       output_dim=16,
                       mask_zero=True)(base_inputs)
base_out = SimpleRNN(32)(embeddings)
base_model = Model(base_inputs, base_out)

# Using the base model in another model, with the Functional API.
inputs = Input(shape=(10, ))
processed_inputs = base_model(inputs)
out = Dense(1)(processed_inputs)

model = Model(inputs, out)
model.compile(loss='mse', optimizer='rmsprop')

x = np.random.randint(0, 100, (1000, 10))
y = np.random.rand(1000)

model.fit(x, y, epochs=10)
```

Traceback using Tensorflow:
```
Traceback (most recent call last):
  File ""/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1022, in _do_call
    return fn(*args)
  File ""/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1004, in _run_fn
    status, run_metadata)
  File ""/usr/local/Cellar/python3/3.6.0_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/contextlib.py"", line 89, in __exit__
    next(self.gen)
  File ""/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py"", line 469, in raise_exception_on_not_ok_status
    pywrap_tensorflow.TF_GetCode(status))
tensorflow.python.framework.errors_impl.InvalidArgumentError: You must feed a value for placeholder tensor 'input_1' with dtype float
	 [[Node: input_1 = Placeholder[dtype=DT_FLOAT, shape=[], _device=""/job:localhost/replica:0/task:0/cpu:0""]()]]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""temp.py"", line 26, in <module>
    model.fit(x, y, epochs=10)
  File ""/usr/local/lib/python3.6/site-packages/keras/engine/training.py"", line 1486, in fit
    initial_epoch=initial_epoch)
  File ""/usr/local/lib/python3.6/site-packages/keras/engine/training.py"", line 1141, in _fit_loop
    outs = f(ins_batch)
  File ""/usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py"", line 2102, in __call__
    feed_dict=feed_dict)
  File ""/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 767, in run
    run_metadata_ptr)
  File ""/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 965, in _run
    feed_dict_string, options, run_metadata)
  File ""/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1015, in _do_run
    target_list, options, run_metadata)
  File ""/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1035, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.InvalidArgumentError: You must feed a value for placeholder tensor 'input_1' with dtype float
	 [[Node: input_1 = Placeholder[dtype=DT_FLOAT, shape=[], _device=""/job:localhost/replica:0/task:0/cpu:0""]()]]

Caused by op 'input_1', defined at:
  File ""temp.py"", line 8, in <module>
    base_inputs = Input(shape=(10, ))
  File ""/usr/local/lib/python3.6/site-packages/keras/engine/topology.py"", line 1391, in Input
    input_tensor=tensor)
  File ""/usr/local/lib/python3.6/site-packages/keras/engine/topology.py"", line 1302, in __init__
    name=self.name)
  File ""/usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py"", line 350, in placeholder
    x = tf.placeholder(dtype, shape=shape, name=name)
  File ""/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py"", line 1520, in placeholder
    name=name)
  File ""/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py"", line 2149, in _placeholder
    name=name)
  File ""/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py"", line 763, in apply_op
    op_def=op_def)
  File ""/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 2395, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 1264, in __init__
    self._traceback = _extract_stack()

InvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'input_1' with dtype float
	 [[Node: input_1 = Placeholder[dtype=DT_FLOAT, shape=[], _device=""/job:localhost/replica:0/task:0/cpu:0""]()]]
```

Traceback using Theano:
```
Traceback (most recent call last):
  File ""temp.py"", line 26, in <module>
    model.fit(x, y, epochs=10)
  File ""/usr/local/lib/python3.6/site-packages/keras/engine/training.py"", line 1458, in fit
    self._make_train_function()
  File ""/usr/local/lib/python3.6/site-packages/keras/engine/training.py"", line 1008, in _make_train_function
    **self._function_kwargs)
  File ""/usr/local/lib/python3.6/site-packages/keras/backend/theano_backend.py"", line 1132, in function
    return Function(inputs, outputs, updates=updates, **kwargs)
  File ""/usr/local/lib/python3.6/site-packages/keras/backend/theano_backend.py"", line 1118, in __init__
    **kwargs)
  File ""/usr/local/lib/python3.6/site-packages/theano/compile/function.py"", line 326, in function
    output_keys=output_keys)
  File ""/usr/local/lib/python3.6/site-packages/theano/compile/pfunc.py"", line 486, in pfunc
    output_keys=output_keys)
  File ""/usr/local/lib/python3.6/site-packages/theano/compile/function_module.py"", line 1808, in orig_function
    output_keys=output_keys).create(
  File ""/usr/local/lib/python3.6/site-packages/theano/compile/function_module.py"", line 1446, in __init__
    accept_inplace)
  File ""/usr/local/lib/python3.6/site-packages/theano/compile/function_module.py"", line 177, in std_fgraph
    update_mapping=update_mapping)
  File ""/usr/local/lib/python3.6/site-packages/theano/gof/fg.py"", line 174, in __init__
    self.__import_r__(output, reason=""init"")
  File ""/usr/local/lib/python3.6/site-packages/theano/gof/fg.py"", line 345, in __import_r__
    self.__import__(variable.owner, reason=reason)
  File ""/usr/local/lib/python3.6/site-packages/theano/gof/fg.py"", line 390, in __import__
    raise MissingInputError(error_msg, variable=r)
theano.gof.fg.MissingInputError: Input 0 of the graph (indices start from 0), used to compute Elemwise{neq,no_inplace}(/input_1, InplaceDimShuffle{x,x}.0), was not provided and not given a value. Use the Theano flag exception_verbosity='high', for more information on this error.
 
Backtrace when that variable is created:

  File ""temp.py"", line 8, in <module>
    base_inputs = Input(shape=(10, ))
  File ""/usr/local/lib/python3.6/site-packages/keras/engine/topology.py"", line 1391, in Input
    input_tensor=tensor)
  File ""/usr/local/lib/python3.6/site-packages/keras/engine/topology.py"", line 1302, in __init__
    name=self.name)
  File ""/usr/local/lib/python3.6/site-packages/keras/backend/theano_backend.py"", line 184, in placeholder
    x = T.TensorType(dtype, broadcast)(name)
```

OS: Mac OS X
Keras: 2.0.2
Tensorflow (cpu): 1.0.0
Theano: 0.9.0",jpraymond,b'type:bug/performance',2017-04-05T20:48:20Z,2017-04-05T21:41:23Z
6155,"Bug: Input layer with an Input layer as input_tensor results in empty _feed_input_names when building a Model, which makes the model unable to train ","Environment:
```
Ubuntu 16.04,
Python 3.5.3, 
Keras 2.0.2 from pypi, 
Backend: Tensorflow 1.1.0rc0 (with CUDA, self-compiled)
```

Code to reproduce this issue:
```
from keras.engine.topology import get_source_inputs
from keras.layers import Input, Dense
from keras.models import Model

input_shape = (512, 512, 3)

input_tensor = Input(shape = input_shape)
print (input_tensor._keras_history[0].is_placeholder) # True
x_1 = Dense(16)(input_tensor)
model_1 = Model(input_tensor, x_1)
print (len(model_1. _feed_input_names)>0)  #  True

img_input = Input(tensor = input_tensor, shape = input_shape) # <-- Bug here, digested from ./applications/inception_v3.py Line 160

print (img_input._keras_history[0].is_placeholder) # False 
print (input_tensor._keras_history[0].is_placeholder) # False <-- Somehow input_tensor is also modified
x_2 = Dense(16)(img_input)
inputs = get_source_inputs(img_input) # digested from ./applications/inception_v3.py Line 353
model_2 = Model(inputs, x_2) 
print (len(model_2. _feed_input_names)>0)  #  False

# model_2.fit(x, y) will result in 'ValueError: The model expects 0 input arrays', which renders this model untrainable.
```

This bug was originally found when I tried mitigating my code to Keras 2.x utilizing built-in inception-v3 framework. `fit_on_generator` wouldn't start and complained  `ValueError: The model expects 0 input arrays, but only received one array.` A little bit digging into inception-v3 code revealed this bug.

A temporary workaround is to change Line 160 in inception_v3.py into `img_input = input_tensor`.",turtleizzy,b'stale',2017-04-05T06:13:45Z,2017-10-04T12:25:43Z
6142,Bug : Specifying initial state for Recurrent layers,"There are 2 issues:

```python
rnn = SimpleRNN(10)  # Layer not built yet. So state_spec is None
x = Input((7, 5))
h_tm1 = Input((10,))
y = rnn(x, initial_state=h_tm1)  # >> Error
```

Another issue is at : https://github.com/fchollet/keras/blob/master/keras/layers/recurrent.py#L236

```python
if hasattr(initial_state, '_keras_history')
```

Doesn't take into account when `initial_state` is a list. (Such as in LSTM, which has multiple states).
",farizrahman4u,None,2017-04-04T11:31:16Z,2019-10-12T11:44:54Z
6135,Bugfix to ConvLSTM2D in channels_first image_data_format mode.,"### Problem

In Keras master (`3382c0bb894b2ecaac2562238f34c2a46bf413c9`), when using `ConvLSTM2D` with `image_data_format == channels_first` mode, the wrong axis is selected as the channel axis.

```python
>>> import keras as K, keras.layers as KL, keras.engine as KE, keras.backend as KB, numpy as np
Using Theano backend.
NVIDIA: no NVIDIA devices found
>>> input = KL.Input(shape=(100,1,32,1))                                   
>>> convlayer = KL.ConvLSTM2D(32, (3,1), activation=""relu"", padding=""same"")
>>> fseq = convlayer(input)
>>> model = KE.Model(inputs=input, outputs=fseq)        
>>> model.predict(np.random.normal(size=(5,100,1,32,1)))
Traceback (most recent call last):

[snip]

Apply node that caused the error: CorrMM{half, (1, 1), (1, 1)}(Alloc.0, Subtensor{::, ::, ::int64, ::int64}.0)
Toposort index: 37
Inputs types: [TensorType(float32, 4D), TensorType(float32, 4D)]
Inputs shapes: [(5, 1, 32, 1), (32, 100, 3, 1)]
Inputs strides: [(128, 9223372036854775807, 4, 9223372036854775807), (4, 128, -12800, -4)]
Inputs values: ['not shown', 'not shown']
Outputs clients: [[InplaceDimShuffle{x,0,1,2,3}(CorrMM{half, (1, 1), (1, 1)}.0)]]

[snip]
```

### Solution

The cause of the problem is that in `keras/layers/convolutional_recurrent.py:342`, when `self.data_format == 'channels_first'`, the channel axis selected is 1 instead of 2. The solution is simple:

```diff
diff --git a/keras/layers/convolutional_recurrent.py b/keras/layers/convolutional_recurrent.py
index e95b7918..00b69c6d 100644
--- a/keras/layers/convolutional_recurrent.py
+++ b/keras/layers/convolutional_recurrent.py
@@ -340,7 +340,7 @@ class ConvLSTM2D(ConvRecurrent2D):
             self.states = [None, None]
 
         if self.data_format == 'channels_first':
-            channel_axis = 1
+            channel_axis = 2
         else:
             channel_axis = -1
         if input_shape[channel_axis] is None:
```",obilaniu,None,2017-04-03T23:20:54Z,2017-04-04T00:00:35Z
6129,Bug: error when using Activation('linear') as first layer,"Keras throws an error when the first layer is an `Activation` layer with `mode='linear'` (this is a pretty unusual use case, but it should work). This seems to be because the definition of that layer is simply:

    def linear(x):
        return x

So the topology is not properly created.
Here's a simple script to reproduce the error:


	from keras.models import Sequential
	from keras.layers import Dense, Activation
	import numpy as np

	def build_net_bug(activation):
		model = Sequential()
		model.add(Activation(activation,input_shape=(12,)))
		model.add(Dense(2))
		model.compile(loss='categorical_crossentropy', optimizer='sgd')
		return model

	model = build_net_bug('linear')
	model.train_on_batch(np.zeros((32,12)),np.zeros((32,2)))
	print('Ok')

Producted the following error:

    /path/experimental/keras/keras/engine/topology.py:1516: UserWarning: Model inputs must come from a Keras Input layer, they cannot be the output of a previous non-Input layer. Here, a tensor specified as input to ""sequential_1_model"" was not an Input tensor, it was generated by layer activation_1.
    Note that input tensors are instantiated via `tensor = Input(shape)`.
    The tensor that caused the issue was: activation_1_input:0
      str(x.name))
    Traceback (most recent call last):
      File ""test_keras_bug_2.py"", line 12, in <module>
        model = build_net_bug('linear')
      File ""test_keras_bug_2.py"", line 9, in build_net_bug
        model.compile(loss='categorical_crossentropy', optimizer='sgd')
      File ""/path/experimental/keras/keras/models.py"", line 761, in compile
        self.build()
      File ""/path/experimental/keras/keras/models.py"", line 520, in build
        name=self.name + '_model')
      File ""/path/experimental/keras/keras/legacy/interfaces.py"", line 88, in wrapper
        return func(*args, **kwargs)
      File ""/path/experimental/keras/keras/engine/topology.py"", line 1569, in __init__
        if layer.is_placeholder:
    AttributeError: 'Activation' object has no attribute 'is_placeholder'


Replacting `'linear'` with any other activation fixes the issue.
Any suggestions on the best way to fix this (preferably without impacting the performance of `Activation('linear')` ? ",yhenon,None,2017-04-03T17:28:14Z,2017-04-13T17:18:00Z
6100,BugFix: Num of params should be int,"Num of params should be int

np.sum([]) returns  0.0.
So if one layer has zero parameters the total number of params will be a float.
",Danielhiversen,None,2017-04-01T09:24:03Z,2017-04-01T20:43:38Z
6060,Bug fix: ocr example; python 3,,farizrahman4u,None,2017-03-30T08:42:51Z,2017-03-30T11:25:49Z
6057,"bug fix, cast batch_sizes as a list to support indexing","Cannot index a set, so batch_sizes must be cast back as a list or a tuple.",slaterb1,None,2017-03-29T19:33:39Z,2017-03-30T17:09:03Z
6035,Bug fix : Error when applying layer recursively on a list in Keras 2,"Simple script to reproduce:

```python
from keras.layers import*
from keras.models import *

a = Input((None, None))
x = [a, a]
b = concatenate(x, 1)
x += [b]  # This changes b._keras_history[0].input
b = concatenate(x, 1)
model = Model(a, b)
```

Works with legacy merge layer. See #5972
",farizrahman4u,None,2017-03-28T20:20:05Z,2017-06-03T00:27:18Z
6034,"bugfix: recursive layers, merge_test.py reproduces bug (#5972)","**Update:** I merged #6035 directly here, so the test should now succeed if #5972 is fixed.

Reproduces #5972, a bug in the new keras-2 function `concatenate()`. 
If the unit test fails the bug has been reproduced correctly.

To run the test from keras directory:

```
py.test tests/keras/layers/merge_test.py
```

This pull request reproduces the keras-2 concatenate() bug detailed in #5972. 

Edits are allowed for maintainers so a patch fixing the bug could potentially be added directly to this pull request. Here is the error:

```
                            raise RuntimeError(
                                'Graph disconnected: '
                                'cannot obtain value for tensor ' +
                                str(x) + ' at layer ""' + layer.name + '"". '
                                'The following previous layers '
                                'were accessed without issue: ' +
>                               str(layers_with_complete_input))
E                           RuntimeError: Graph disconnected: cannot obtain value for tensor Tensor(""concatenate_3/concat:0"", shape=(?, ?, ?), dtype=float32) at layer ""concatenate_3"". The following previous layers were accessed without issue: ['input_3']
```

While the pull request contents fail, the following keras-1 API code succeeds:

```python
import numpy as np
from numpy.testing import assert_allclose
from keras import layers
from keras import models
from keras import backend as K
from keras.utils.test_utils import layer_test
from keras.utils.test_utils import keras_test
from keras.layers import merge

x3 = np.random.random((1, 1, 1))
nb_layers = 4
x_i = layers.Input(shape=(None, None))
x_list = [x_i]
x = x_i
for i in range(nb_layers):
    x_list.append(x)
    # The concatenate line fails if uncommented + comment merge line
    # x = layers.concatenate(x_list)
    x = layers.merge(x_list, mode='concat', concat_axis=1)
concat_model = models.Model(x_i, x)
concat_out = concat_model.predict([x3])
x3 = np.repeat(x3, 16, axis=1)
assert concat_out.shape == (1, 16, 1)
assert_allclose(concat_out, x3)
```",ahundt,None,2017-03-28T18:48:21Z,2017-06-22T00:38:05Z
6007,`unboundlocalerror: local variable 'class_name' referenced before assignment`,"BUG report  ^.^

I have re-define the top_k_categorical_accuracy to 
`def top_k_categorical_accuracy(y_true, y_pred):
    return metrics.top_k_categorical_accuracy(y_true, y_pred, 1)`

And as the model training finished, I saved it to my local disk by `mode.save(mypath)`, but I have got this exception while I load model to other process:

`unboundlocalerror: local variable 'class_name' referenced before assignment`

It was from:
`File ""<PYTHONPATH>/local/lib/python2.7/site-packages/keras/utils/generic_utils.py"", line 157, in deserialize_keras_object`

Absolutely, it a variable which not been assign before using it. In the exception code block, the unit-test may not cover it or the code's static check issue?

Thanks for read",Mr8,b'stale',2017-03-27T11:42:05Z,2017-12-18T15:50:09Z
5963,Bug in Siamese Example Accuracy Calculation,"The siamese network example for mnist (https://github.com/fchollet/keras/blob/master/examples/mnist_siamese_graph.py) uses the following function to compute accuracy

```
def compute_accuracy(predictions, labels):
    '''Compute classification accuracy with a fixed threshold on distances.
    '''
    return labels[predictions.ravel() < 0.5].mean()
```

This seems flawed to me. For example:
```
import numpy as np
labs = np.array([0,0,0,0,0,1,1,1,1,1])
pred = np.array([1,1,1,1,1,0,0,0,0,0])
print(compute_accuracy(pred, labs))
# >>> 1.0
```

Surely the order of the predictions is important? In the example above, all of the predictions are different from the labels, and yet the compute_accuracy returns 100%. 

Am I missing something obvious, or is this a mistake.




- [X] Check that you are up-to-date with the master branch of Keras. You can update with:
pip install git+git://github.com/fchollet/keras.git --upgrade --no-deps

- [x] If running on TensorFlow, check that you are up-to-date with the latest version. The installation instructions can be found [here](https://www.tensorflow.org/get_started/os_setup).

- [X] If running on Theano, check that you are up-to-date with the master branch of Theano. You can update with:
pip install git+git://github.com/Theano/Theano.git --upgrade --no-deps

- [X] Provide a link to a GitHub Gist of a Python script that can reproduce your issue (or just copy the script here if it is short).
",sixhobbits,b'stale',2017-03-24T13:33:44Z,2017-08-12T13:15:53Z
5827,Bug fixes : Theano shape inference,,farizrahman4u,None,2017-03-16T19:43:15Z,2017-03-19T19:27:58Z
5754,Bug in time_distributed_dense when in tensorflow backend because of set_shape?,"Hi, 

the code below is:

```
#encoding=utf-8

import tensorflow as tf
import os
os.environ[""KERAS_BACKEND""] = ""tensorflow""
from keras import initializations
from keras.models import Model
from keras.layers.recurrent import LSTM, Recurrent, SimpleRNN, time_distributed_dense, GRU
from keras import backend as K

w_c = K.random_normal_variable((2,7), mean=0, scale=1)
x = K.random_normal_variable((1, 2, 2), mean=0, scale=1)
# q = time_distributed_dense(x, w_c, output_dim=7, input_dim=2)
q = time_distributed_dense(x, w_c)

sess = tf.Session()
gini = tf.global_variables_initializer()
sess.run(gini)

qv = sess.run(q)
print(qv.shape)
```
Error is:
```
  File ""E:/project/learn_test/test.py"", line 18, in <module>
    q = time_distributed_dense(x, w_c)
  File ""e:\project\keras\keras\layers\recurrent.py"", line 52, in time_distributed_dense
    x.set_shape([None, None, output_dim])
  File ""D:\Anaconda3\lib\site-packages\tensorflow\python\framework\ops.py"", line 419, in set_shape
    self._shape = self._shape.merge_with(shape)
  File ""D:\Anaconda3\lib\site-packages\tensorflow\python\framework\tensor_shape.py"", line 573, in merge_with
    other = as_shape(other)
  File ""D:\Anaconda3\lib\site-packages\tensorflow\python\framework\tensor_shape.py"", line 821, in as_shape
    return TensorShape(shape)
  File ""D:\Anaconda3\lib\site-packages\tensorflow\python\framework\tensor_shape.py"", line 457, in __init__
    self._dims = [as_dimension(d) for d in dims_iter]
  File ""D:\Anaconda3\lib\site-packages\tensorflow\python\framework\tensor_shape.py"", line 457, in <listcomp>
    self._dims = [as_dimension(d) for d in dims_iter]
  File ""D:\Anaconda3\lib\site-packages\tensorflow\python\framework\tensor_shape.py"", line 378, in as_dimension
    return Dimension(value)
  File ""D:\Anaconda3\lib\site-packages\tensorflow\python\framework\tensor_shape.py"", line 33, in __init__
    self._value = int(value)
TypeError: int() argument must be a string, a bytes-like object or a number, not 'Tensor'
```

But when I set  time_distributed_dense(x, w_c, output_dim=7, input_dim=2), it run ok; 
So what's up here? tf.set_shape can't pass tensor or ? Thanks",liyi193328,None,2017-03-14T06:18:23Z,2017-03-14T15:05:21Z
5730,Bug fix : Model.from_config,"The function pops item from the original `dict` passed to the function. This causes an error when building multiple models from the same config:

```python

config = model.get_config()
model1 = Model.from_config(config) # OK
model2 = Model.from_config(config) # error
```",farizrahman4u,None,2017-03-12T13:31:04Z,2017-03-12T18:29:09Z
5687,Bug Applying TimeDistributed to a Model,"The TimeDistributed wrapper does not appear to be able to be applied to a model because of a conflict with Tensorflow. I am trying to construct something similar to the video question answering model given in the function API guide. I think it may be related to using the latest release of Tensorflow. 

I get the following error:

> InvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'convolution2d_input_1' with dtype float
> 	 [[Node: convolution2d_input_1 = Placeholder[dtype=DT_FLOAT, shape=[], _device=""/job:localhost/replica:0/task:0/gpu:0""]()]]
> 	 [[Node: moments_5/sufficient_statistics/Gather/_99 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device_incarnation=1, tensor_name=""edge_3882_moments_5/sufficient_statistics/Gather"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/cpu:0""]()]]

when running the code bellow. The fullInputShape is (5000, 4, 256, 128, 1)

```python 

def funcMakesCNN(inputDim):

    model = Sequential()
    model.add(Convolution2D(4, 3, 3, activation='relu', init='he_uniform',
                            border_mode='same', W_regularizer=weightReg, input_shape=inputDim))
    model.add(BatchNormalization())
    model.add(AveragePooling2D(strides=(2, 2)))

    model.add(Convolution2D(6, 3, 3, activation='relu', init='he_uniform',
                            border_mode='same', W_regularizer=weightReg))
    model.add(BatchNormalization())
    model.add(AveragePooling2D(strides=(2, 2)))

    model.add(Flatten())
    return model

fullInput = Input(fullInputShape)
frameModel = funcMakesCNNt(frameInputShape)
lagModel = TimeDistributed(frameModel)(fullInput)
gruOut = GRU(256)(lagModel)
finalOut = Dense(lagOutputShape, activation='relu', name='regOut')(gruOut)
fullModel = Model(input=fullInput, output=finalOut)
fullModel.compile(loss='mse', optimizer=Adam(lr=0.005, decay=0.008))
```

Thanks!",gdj0nes,None,2017-03-10T06:09:22Z,2020-02-27T05:59:01Z
5228,Bug Fix in Image Generator - Now Allows FCN's to be used,"I needed FCN's so have altered this preprocessing step, I can also make a gist for the tutorials if anyone else prefers to learn through a simple example.

This does not allow for no sizes to be set if max poolings are used. In that case, the sizes can be none-square but have to be multiple of 2^m - where m is the number of max pooling layers.

In the future it might be possible to auto-resize to the nearest factor, but another variable will need adding to ensure we can disentangle the model from the preprocessing.


Made minor changes to allow for FCN's:
  - Target Size is now a tuple of (None, None) as only this can propagate through the directory iterator
  - Altered batch_x to be created in the loop, as you should only use a batch size of 1 for FCN of shape (None, None, Channels)
  - Allowed the directory iterator to use the folder it is passed if it finds no subfolders for classes (Usual use case in FCN)

Allowed BGR to be specified (for when using caffe converted models).",joeyearsley,None,2017-01-30T17:20:20Z,2017-06-10T03:22:05Z
5153,Bugfix: Fix issue in deep dream example,"The expression of  pictures should be (img_height, img_width, 3) or (3, img_height, img_width), not (img_width, img_height, 3) or (3, img_width, img_height).",mohanson,None,2017-01-24T07:56:36Z,2017-01-24T17:39:26Z
5143,"Bugfix CSVLogger Callback separator and append parameters, added tests","CSVLogger callback did not regard separator value and prepended header to existing files although append argument was specified.
Also, added tests to confirm functionality.",ExpectationMax,None,2017-01-23T21:38:11Z,2017-01-24T17:43:58Z
5083,Bug on the save/load mechanism of version 1.2.0,"I believe there is a bug on the save/load mechanism of version 1.2.0. The problem did not exist on version 1.1.2.

To reproduce the bug I'll be using the following code snippet taken from the Keras documentation: [Fine-tune InceptionV3 on a new set of classes](https://keras.io/applications/)

```python
from keras.preprocessing import image
generator = image.ImageDataGenerator().flow_from_directory('./data/cifar2-train', target_size=(224, 224), batch_size=32, class_mode='categorical', shuffle=True)

# ==== Start of Code Snippet from Keras Documentation: https://keras.io/applications/ ====
from keras.applications.inception_v3 import InceptionV3
from keras.preprocessing import image
from keras.models import Model
from keras.layers import Dense, GlobalAveragePooling2D
from keras import backend as K

base_model = InceptionV3(weights='imagenet', include_top=False)

x = base_model.output
x = GlobalAveragePooling2D()(x)
x = Dense(1024, activation='relu')(x)
predictions = Dense(2, activation='softmax')(x)

model = Model(input=base_model.input, output=predictions)

for layer in base_model.layers:
    layer.trainable = False

model.compile(optimizer='rmsprop', loss='categorical_crossentropy')

model.fit_generator(generator, samples_per_epoch=1000, nb_epoch=1)

for i, layer in enumerate(base_model.layers):
   print(i, layer.name)

for layer in model.layers[:172]:
   layer.trainable = False
for layer in model.layers[172:]:
   layer.trainable = True

from keras.optimizers import SGD
model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='categorical_crossentropy')

model.fit_generator(generator, samples_per_epoch=1000, nb_epoch=1)
# ==== End of Code Snippet ====

model.save('./data/tempModel')
del model
from keras.models import load_model
model = load_model('./data/tempModel')
```
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/usr/local/lib/python2.7/dist-packages/keras/models.py"", line 143, in load_model
    model.load_weights_from_hdf5_group(f['model_weights'])
  File ""/usr/local/lib/python2.7/dist-packages/keras/engine/topology.py"", line 2753, in load_weights_from_hdf5_group
    str(len(flattened_layers)) + ' layers.')
ValueError: You are trying to load a weight file containing 190 layers into a model with 2 layers.",datumbox,None,2017-01-19T12:36:38Z,2017-01-27T22:37:09Z
4863,bug in model.save() ,"Hi
i'm having a problem with using model.save or load_model. i ran this script using theano backend on mac os x 10.11.6 

```
import os
os.environ[""KERAS_BACKEND""] = ""theano""

from keras.models import Sequential, Model, load_model
from keras.layers import Convolution2D
from keras.layers import Dense, Dropout,Flatten,BatchNormalization,Reshape,Input, Activation,UpSampling2D
from keras.optimizers import *
from keras.datasets import mnist
from theano import tensor as T
import matplotlib.pyplot as plt
import numpy as np

g_opt = Adam(lr=1e-4)
noise_W = 4
noise_H = 4
BATCH_SIZE = 200
def build_gen1():

    inp_g = Input(shape=[noise_W*noise_H])

    #g = Dense(14, activation='relu')(inp_g)
    g = Dense(256 * 14 * 14)(inp_g)
    g = BatchNormalization(mode=2)(g)
    g = Activation('relu')(g)
    g = Reshape([256,14,14])(g)
    g = UpSampling2D(dim_ordering='th')(g)
    g = Convolution2D(123,3,3,border_mode='same',dim_ordering='th')(g)
    g = BatchNormalization(mode=2)(g)
    g = Activation('relu')(g)
    g = Convolution2D(61,3,3,border_mode='same',dim_ordering='th')(g)
    g = BatchNormalization(mode=2)(g)
    g = Activation('relu')(g)
    g_out = Convolution2D(1,1,1,activation='sigmoid',border_mode='same',dim_ordering='th')(g)

    return Model(inp_g, g_out)

gen = build_gen1()
gen.compile(loss='binary_crossentropy', optimizer=g_opt)
gen.summary()
gen.save(""ex_gen.h5"")

load_gen = load_model(""/Users/anastasia/PycharmProjects/pro/ex_gen.h5"")
load_gen.summary()
```
this is what returns gen.summary():

```
____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
input_2 (InputLayer)             (None, 16)            0                                            
____________________________________________________________________________________________________
dense_3 (Dense)                  (None, 50176)         852992      input_2[0][0]                    
____________________________________________________________________________________________________
batchnormalization_1 (BatchNorma (None, 50176)         200704      dense_3[0][0]                    
____________________________________________________________________________________________________
activation_1 (Activation)        (None, 50176)         0           batchnormalization_1[0][0]       
____________________________________________________________________________________________________
reshape_1 (Reshape)              (None, 256, 14, 14)   0           activation_1[0][0]               
____________________________________________________________________________________________________
upsampling2d_1 (UpSampling2D)    (None, 256, 28, 28)   0           reshape_1[0][0]                  
____________________________________________________________________________________________________
convolution2d_5 (Convolution2D)  (None, 123, 28, 28)   283515      upsampling2d_1[0][0]             
____________________________________________________________________________________________________
batchnormalization_2 (BatchNorma (None, 123, 28, 28)   112         convolution2d_5[0][0]            
____________________________________________________________________________________________________
activation_2 (Activation)        (None, 123, 28, 28)   0           batchnormalization_2[0][0]       
____________________________________________________________________________________________________
convolution2d_6 (Convolution2D)  (None, 61, 28, 28)    67588       activation_2[0][0]               
____________________________________________________________________________________________________
batchnormalization_3 (BatchNorma (None, 61, 28, 28)    112         convolution2d_6[0][0]            
____________________________________________________________________________________________________
activation_3 (Activation)        (None, 61, 28, 28)    0           batchnormalization_3[0][0]       
____________________________________________________________________________________________________
convolution2d_7 (Convolution2D)  (None, 1, 28, 28)     62          activation_3[0][0]               
====================================================================================================
Total params: 1,405,085
Trainable params: 1,304,621
Non-trainable params: 100,464
```
and this is ex_gen summary

```
____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
input_2 (InputLayer)             (None, 16)            0                                            
____________________________________________________________________________________________________
dense_3 (Dense)                  (None, 50176)         852992      input_2[0][0]                    
____________________________________________________________________________________________________
batchnormalization_1 (BatchNorma (None, 50176)         200704      dense_3[0][0]                    
____________________________________________________________________________________________________
activation_1 (Activation)        (None, 50176)         0           batchnormalization_1[0][0]       
____________________________________________________________________________________________________
reshape_1 (Reshape)              (None, 256, 14, 14)   0           activation_1[0][0]               
____________________________________________________________________________________________________
upsampling2d_1 (UpSampling2D)    (None, 512, 28, 14)   0           reshape_1[0][0]                  
____________________________________________________________________________________________________
convolution2d_5 (Convolution2D)  (None, 123, 28, 14)   283515      upsampling2d_1[0][0]             
____________________________________________________________________________________________________
batchnormalization_2 (BatchNorma (None, 123, 28, 14)   112         convolution2d_5[0][0]            
____________________________________________________________________________________________________
activation_2 (Activation)        (None, 123, 28, 14)   0           batchnormalization_2[0][0]       
____________________________________________________________________________________________________
convolution2d_6 (Convolution2D)  (None, 61, 28, 14)    67588       activation_2[0][0]               
____________________________________________________________________________________________________
batchnormalization_3 (BatchNorma (None, 61, 28, 14)    112         convolution2d_6[0][0]            
____________________________________________________________________________________________________
activation_3 (Activation)        (None, 61, 28, 14)    0           batchnormalization_3[0][0]       
____________________________________________________________________________________________________
convolution2d_7 (Convolution2D)  (None, 1, 28, 14)     62          activation_3[0][0]               
====================================================================================================
Total params: 1,405,085
Trainable params: 1,304,621
Non-trainable params: 100,464
____________________________________________________________________________________________________

```

it looks like model was saved with tensorflow backend instead of theano
Thanks",aurum408,None,2016-12-28T16:25:34Z,2017-04-01T21:51:24Z
4694,examples/mnist_swwae.py tensorflow support,"- [x] Check that you are up-to-date with the master branch of Keras. You can update with:
pip install git+git://github.com/fchollet/keras.git --upgrade --no-deps

- [x] If running on Theano,... (I'm running on tensorflow)

- [x] Provide a link to a GitHub Gist of a Python script that can reproduce your issue (or just copy the script here if it is short).


I successfully ran `python mnist_cnn.py` from 7e2e7a5e5a43443122df0b497f88dd77fd3bfc7c on my GTX1080 with a TensorFlow R0.12rc0 backend. I then ran `python mnist_swwae.py` and got the following failure:

```bash
~/src/keras/examples on master
± python mnist_swwae.py
Using TensorFlow backend.
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcublas.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcudnn.so.5 locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcufft.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcurand.so.8.0 locally
X_train shape: (60000, 1, 28, 28)
60000 train samples
10000 test samples
Traceback (most recent call last):
  File ""mnist_swwae.py"", line 136, in <module>
    y = MaxPooling2D(pool_size=(pool_sizes[i], pool_sizes[i]))(y_prepool)
  File ""/usr/local/lib/python2.7/dist-packages/Keras-1.1.2-py2.7.egg/keras/engine/topology.py"", line 517, in __call__
    self.add_inbound_node(inbound_layers, node_indices, tensor_indices)
  File ""/usr/local/lib/python2.7/dist-packages/Keras-1.1.2-py2.7.egg/keras/engine/topology.py"", line 571, in add_inbound_node
    Node.create_node(self, inbound_layers, node_indices, tensor_indices)
  File ""/usr/local/lib/python2.7/dist-packages/Keras-1.1.2-py2.7.egg/keras/engine/topology.py"", line 155, in create_node
    output_tensors = to_list(outbound_layer.call(input_tensors[0], mask=input_masks[0]))
  File ""/usr/local/lib/python2.7/dist-packages/Keras-1.1.2-py2.7.egg/keras/layers/pooling.py"", line 158, in call
    dim_ordering=self.dim_ordering)
  File ""/usr/local/lib/python2.7/dist-packages/Keras-1.1.2-py2.7.egg/keras/layers/pooling.py"", line 207, in _pooling_function
    border_mode, dim_ordering, pool_mode='max')
  File ""/usr/local/lib/python2.7/dist-packages/Keras-1.1.2-py2.7.egg/keras/backend/tensorflow_backend.py"", line 1853, in pool2d
    x = tf.nn.max_pool(x, pool_size, strides, padding=padding)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/nn_ops.py"", line 1617, in max_pool
    name=name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_nn_ops.py"", line 1598, in _max_pool
    data_format=data_format, name=name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py"", line 759, in apply_op
    op_def=op_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 2242, in create_op
    set_shapes_for_outputs(ret)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 1617, in set_shapes_for_outputs
    shapes = shape_func(op)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 1568, in call_with_requiring
    return call_cpp_shape_fn(op, require_shape_fn=True)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/common_shapes.py"", line 610, in call_cpp_shape_fn
    debug_python_shape_fn, require_shape_fn)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/common_shapes.py"", line 675, in _call_cpp_shape_fn_impl
    raise ValueError(err.message)
ValueError: Negative dimension size caused by subtracting 2 from 1 for 'MaxPool' (op: 'MaxPool') with input shapes: [?,1,32,8].
-> [1]
```

Help or feedback from anyone is welcome, @antonmbk you may be interested in this because you contributed the example. Thanks!",ahundt,b'type:bug/performance',2016-12-13T03:08:02Z,2017-03-29T17:31:51Z
4693,bug in pool2d,"The padding size in `pool2d` is problematic in the sense that  the pixels before and after pooling is NOT aligned.

Below is the code to decide the padding size of `pool2d`
```
def pool2d(x, pool_size, strides=(1, 1), border_mode='valid', dim_ordering='default', pool_mode='max'):
    if dim_ordering == 'default':
        dim_ordering = image_dim_ordering()
    if dim_ordering not in {'th', 'tf'}:
        raise Exception('Unknown dim_ordering ' + str(dim_ordering))
    assert pool_size[0] >= 1 and pool_size[1] >= 1

    if border_mode == 'same':
        w_pad = pool_size[0] - 2 if pool_size[0] > 2 and pool_size[0] % 2 == 1 else pool_size[0] - 1
        h_pad = pool_size[1] - 2 if pool_size[1] > 2 and pool_size[1] % 2 == 1 else pool_size[1] - 1
        padding = (w_pad, h_pad)
```
This setting of `w_pad` and `h_pad` works OK if `strides = pool_size`, but cause a center-shift if `strides = (1,1)`. Below is a fix to ensure the pixels before and after pooling are aligned.
```
        w_pad = pool_size[0] // 2
        h_pad = pool_size[1] // 2
```


",rex-yue-wu,b'stale',2016-12-13T02:05:29Z,2017-06-22T20:10:20Z
4640,Bug in theano_backend for _Pooling1D?,"From **_Pooling1D** subclasses, **K.pool2d** is called with `pool_size = (pool_length, 1)`.
In **theano_backend.pool2d**, when `border_mode = ""same""`, the following line:

`h_pad = pool_size[1] - 2 if pool_size[1] % 2 == 1 else pool_size[1] - 1`

causes h_pad to get the value -1, which results in the following error on my machine:

> WARNING: probably bad CudaNdarray_set_dim arguments: self->ndim=4, idx=3 stride=-1
> Traceback (most recent call last):
>  File ""/opt/anaconda3/lib/python3.5/site-packages/theano/compile/function_module.py"", line 866, in __call__
>    self.fn() if output_subset is None else\
> AssertionError: Can't store in size_t for the bytes requested 18446744073709551615 * 4

I believe the correct value for `h_pad` in this case is `0`, suggesting the following fix:

`h_pad = pool_size[1] - 2 if pool_size[1] > 2 and pool_size[1] % 2 == 1 else pool_size[1] - 1`


Please make sure that the boxes below are checked before you submit your issue. Thank you!

- [x] Check that you are up-to-date with the master branch of Keras. You can update with:
pip install git+git://github.com/fchollet/keras.git --upgrade --no-deps

- [x] If running on Theano, check that you are up-to-date with the master branch of Theano. You can update with:
pip install git+git://github.com/Theano/Theano.git --upgrade --no-deps

- [ ] Provide a link to a GitHub Gist of a Python script that can reproduce your issue (or just copy the script here if it is short).",sunil-at-gh,b'stale',2016-12-08T04:03:30Z,2017-06-22T20:10:11Z
4583,Bug fix: InputLayer is ignoring _keras_shape,"`Input()` is asking for `input_shape` even if a Keras tensor is provided as input tensor.
",farizrahman4u,None,2016-12-03T10:40:03Z,2017-06-03T00:27:30Z
4513,Bug fix: model.summary is ignoring model.trainable,,farizrahman4u,None,2016-11-27T00:07:36Z,2017-06-03T00:27:31Z
4502,Bug Fix : Sequential model is ignoring trainable argument of child containers,"Found this issue while writing a vanilla GAN: Discriminator weights are changing even when trainable=False. Issue only when the final model is Sequential. 

```python
discriminator = Sequential()
discriminator.add(Dense(1, input_dim=10, activation='sigmoid'))

generator = Sequential()
generator.add(Dense(10, input_dim=10))

GAN = Sequential()
GAN.add(generator)

discriminator.trainable = False

GAN.add(discriminator)
GAN.compile(loss='mse', optimizer='sgd')

x = np.random.random((100, 10))
y = np.ones((100, 1))

discriminator_initial_weights = discriminator.get_weights()
GAN.fit(x, y)
assert np.all(discriminator.get_weights()[0] == discriminator_initial_weights[0]), 'Discriminator weights changed!'
```",farizrahman4u,None,2016-11-25T04:22:23Z,2016-11-25T19:23:22Z
4441,Bugfix: K.rnn() is ignoring theano.scan() updates,"Currently, `K.rnn()` is ignoring `theano.scan()` `updates`.
This should not be ignored.
If you ignore this, you cannot use random numbers inside `K.rnn()`.

What I modified:

1. Add the 4th return value to `K.rnn()`. This is `theano.scan()` `updates`. But this change breaks compatibility.
2. Add `updates` argument to `K.eval()`.
3. Add `rnn_updates` to `Layer`. I split `updates` and `rnn_updates` because `rnn_updates` needs for training, testing and predicting phase. `Recurrent` and `TimeDistributed` uses `K.rnn()`, and I passed `updates` to `Layer.add_rnn_updates()`.

By this fix, I can run this code on Theano.
`TimeDistributed` uses `K.rnn()` and `Dropout` uses random numbers.

```python
import numpy as np
from keras.layers import Input, TimeDistributed, Dropout
from keras.models import Model

x = Input(batch_shape=(1, 1, 1))
y = TimeDistributed(Dropout(0.5))(x)
model = Model(input=[x], output=[y])
model.compile(optimizer=""sgd"", loss=""mse"")
model.fit(np.zeros([1, 1, 1], np.float32), np.zeros([1, 1, 1], np.float32), batch_size=1)
```


",yukoba,None,2016-11-20T08:57:27Z,2016-11-24T07:04:45Z
4426,Bugfix: Don't add another header line to CSV logfile when appending to an existing file,"Currently when using the `CSVLogger` callback with `append=True`, at the beginning of a new training run which appends to an existing file the header file will be rewritten to the output

e.g. if training is resumed after epoch 2, the output would be:

```
epoch,categorical_accuracy,loss,val_categorical_accuracy,val_loss
0,0.130208333333,2.32610692581,0.154399999142,2.26858918381
1,0.173394097222,2.17767716779,0.196799999881,2.10534226418
2,0.186197916667,2.07855245802,0.177600000429,2.06805825005
epoch,categorical_accuracy,loss,val_categorical_accuracy,val_loss
3,0.201605902778,2.03062710166,0.199999999762,2.03451372261
4,0.204427083333,1.96939406792,0.229799997854,1.94915147133
```

This PR prevents the writing of the additional header line in the middle of the CSV file, so the output is instead:

```
epoch,categorical_accuracy,loss,val_categorical_accuracy,val_loss
0,0.130208333333,2.32610692581,0.154399999142,2.26858918381
1,0.173394097222,2.17767716779,0.196799999881,2.10534226418
2,0.186197916667,2.07855245802,0.177600000429,2.06805825005
3,0.201605902778,2.03062710166,0.199999999762,2.03451372261
4,0.204427083333,1.96939406792,0.229799997854,1.94915147133
```",kencoken,None,2016-11-18T17:44:09Z,2016-11-25T22:49:50Z
4424,"Bug fix of Bidirectional(LSTM(..., stateful=True))",Please see https://github.com/fchollet/keras/issues/4421,yukoba,None,2016-11-18T14:14:28Z,2016-11-18T20:19:42Z
4402,TensorFlow initialization needs to collect local variables,"Bug in `tensorflow_backend.py`, lines 186-188:

```python
def _initialize_variables():
    variables = tf.all_variables()
    uninitialized_variables = []
```

Some code, e.g.:

```python
def auc_metric(labels, predictions):
  auc, _ = tf.contrib.metrics.streaming_auc(predictions, labels)
  return auc
```

Will fail because local variables are created, but not initialized.

Lines 187 needs to be:

```python
    variables = tf.all_variables() + tf.local_variables()
```",rgobbel,b'stale',2016-11-16T22:19:11Z,2017-06-22T19:09:46Z
4319,Bugfix to CIFAR pickle reading code in Python 3,"The following code for reading in CIFAR batches is currently used in Python 3:

```python
d = cPickle.load(f, encoding=""bytes"")
# decode utf8
print(""keys are: {}"".format(d.keys())  # debug output
for k, v in d.items():
    print(""key is: {}"".format(k))      # debug output
    del(d[k])
    d[k.decode(""utf8"")] = v
```

This errors out with the following (running under Python 3.6b2):

```
keys are: dict_keys([b'batch_label', b'labels', b'data', b'filenames'])
key is: b'batch_label'
key is: b'labels'
key is: batch_label
Traceback (most recent call last):
  File ""run.py"", line 78, in <module>
    main()
  File ""run.py"", line 67, in main
    (X_train, y_train), (X_test, y_test) = cifar10.load_data()
  File ""/usr/local/lib/python3.6/site-packages/keras/datasets/cifar10.py"", line 21, in load_data
    data, labels = load_batch(fpath)
  File ""/usr/local/lib/python3.6/site-packages/keras/datasets/cifar.py"", line 19, in load_batch
    d[k.decode(""utf8"")] = v
AttributeError: 'str' object has no attribute 'decode'
```

So seems like there is a bug due to the modification if the dictionary in the iteration loop. This PR fixes this.",kencoken,None,2016-11-08T12:01:51Z,2016-11-10T01:14:36Z
4251,BUG: Deconvolution2D output shape not correctly referenced,"Error with the  get_config method from Deconvolution2D.

Throws the following error when saving a model with such layer.
Exception: The layer has never been called and thus has no defined output shape.
",mbaradad,None,2016-11-01T17:26:55Z,2016-11-01T18:24:54Z
4200,Bug fix when target is a SparseTensor.,"Bug fix when target is a SparseTensor.
Check for sparsity when creating target placeholder.
Remove shape argument when creating sparse placeholder.
",igormq,None,2016-10-26T10:18:07Z,2016-11-03T17:04:40Z
4181,Bug fix in zca_whitening,"When calculating covariance matrix 'sigma', denominator is # of instances (axis=0), not dimensionality (axis=1)

Proof:
http://ufldl.stanford.edu/wiki/index.php/Implementing_PCA/Whitening
http://ufldl.stanford.edu/wiki/index.php/Exercise:PCA_and_Whitening
Ng uses 2nd dim in denominator because his matrix is [features x instances]
",alexander-rakhlin,None,2016-10-25T14:40:13Z,2016-10-25T20:49:00Z
4159,Bug fix in TensorBoard callback and corresponding test,"Fixes issue: https://github.com/fchollet/keras/issues/4048
",mjdietzx,None,2016-10-23T13:32:50Z,2016-10-24T22:13:39Z
3892,Bug: output shape inference of batch_dot with Theano backend is not correct,"Tested on Mac, python 2.7, theano 0.8.2, tensorflow 0.10.0rc0, keras 1.1.0.
- Problem: with Theano backend, `batch_dot` output shape inference is not correct.
- Quick test code:

``` python
import keras
from keras import backend as K
import numpy as np
from keras.layers import Input, Lambda, merge, Reshape, Permute
from keras.models import Model

print('keras version: ', keras.__version__)
print('dim_ordering: ', K.image_dim_ordering())

x = Input((64, 32)) # (None, 64, 32) in batch
t = K.variable(np.ones((1, 32, 16))) # (1, 32, 16 in batch)
y = Lambda(lambda x: K.batch_dot(x, t, axes=(2, 1)))(x)
model = Model(input=x, output=y)
model.summary(line_length=80)
print('output_shape that the model thinks ', model.output_shape)
dummy_x = np.ones((64, 32))
dummy_y = model.predict(dummy_x[np.newaxis, :])
print('In fact, output shape is ', dummy_y.shape)
```
- test result: with theano

```
Using Theano backend.
('keras version: ', '1.1.0')
('dim_ordering: ', 'th')
________________________________________________________________________________
Layer (type)              Output Shape      Param #  Connected to
================================================================================
input_1 (InputLayer)      (None, 64, 32)    0
________________________________________________________________________________
lambda_1 (Lambda)         (None, 64, 32)    0        input_1[0][0]
================================================================================
Total params: 0
________________________________________________________________________________
('output_shape that the model thinks ', (None, 64, 32))
('In fact, output shape is ', (1, 64, 16))
```
- test result: with tensorflow:

```
Using TensorFlow backend.
('keras version: ', '1.1.0')
('dim_ordering: ', 'th')
________________________________________________________________________________
Layer (type)              Output Shape      Param #  Connected to
================================================================================
input_1 (InputLayer)      (None, 64, 32)    0
________________________________________________________________________________
lambda_1 (Lambda)         (1, 64, 16)       0        input_1[0][0]
================================================================================
Total params: 0
________________________________________________________________________________
('output_shape that the model thinks ', (1, 64, 16))
('In fact, output shape is ', (1, 64, 16))
```
",keunwoochoi,None,2016-09-27T21:14:21Z,2016-09-28T22:02:47Z
3807,Bug? Exception: Graph disconnected,"Please make sure that the boxes below are checked before you submit your issue. Thank you!
- [x] Check that you are up-to-date with the master branch of Keras. You can update with:
  pip install git+git://github.com/fchollet/keras.git --upgrade --no-deps
- [x] If running on Theano, check that you are up-to-date with the master branch of Theano. You can update with:
  pip install git+git://github.com/Theano/Theano.git --upgrade --no-deps
- [x] Provide a link to a GitHub Gist of a Python script that can reproduce your issue (or just copy the script here if it is short).

So I have this model, upon compilation I get
 `Using Theano backend.
/usr/local/lib/python2.7/dist-packages/Keras-1.0.7-py2.7.egg/keras/engine/topology.py:1655: UserWarning: Model inputs must come from a Keras Input layer, they cannot be the output of a previous non-Input layer. Here, a tensor specified as input to ""model_1"" was not an Input tensor, it was generated by layer timedistributed_1.
Note that input tensors are instantiated via`tensor = Input(shape)`.
The tensor that caused the issue was: None
  str(x.name))
Traceback (most recent call last):
  File ""/home/ubuntumax/keras_egg_code/train.py"", line 89, in <module>
    training_function()
  File ""/home/ubuntumax/keras_egg_code/train.py"", line 54, in training_function
    lstm_model = build_model()
  File ""/home/ubuntumax/keras_egg_code/train.py"", line 32, in build_model
    model = Model(input=main_input, output=main_loss)
  File ""/usr/local/lib/python2.7/dist-packages/Keras-1.0.7-py2.7.egg/keras/engine/topology.py"", line 1837, in __init__
    str(layers_with_complete_input))
Exception: Graph disconnected: cannot obtain value for tensor main_input at layer ""main_input"". The following previous layers were accessed without issue: []
`
Any suggestions on what is going wrong?
Thanks

```
    main_input = Input(shape=(240000, 16, 1), name='main_input')
    vision_model = Sequential()
    vision_model.add(Convolution1D(16, 1, activation='relu', border_mode='same', input_shape=(16, 1)))
    vision_model.add(MaxPooling1D(2, 2))
    vision_model.add(Convolution1D(16, 16, activation='relu', border_mode='same'))
    vision_model.add(MaxPooling1D(2, 2))
    vision_model.add(Convolution1D(8, 32, activation='relu', border_mode='same'))
    vision_model.add(MaxPooling1D(2, 2))
    vision_model.add(Convolution1D(4, 64, activation='relu', border_mode='same'))
    vision_model.add(MaxPooling1D(2, 2))
    vision_model.add(Flatten())

    main_input = TimeDistributed(vision_model)(main_input)
    x = LSTM(output_dim=512, return_sequences=True)(main_input)
    x = LSTM(output_dim=64)(x)
    main_loss = Dense(1, activation='sigmoid', name='main_output')(x)
    model = Model(input=main_input, output=main_loss)
    model.compile(optimizer='rmsprop', loss='mse')
    print(model.summary())
```
",AntreasAntoniou,b'stale',2016-09-18T23:40:58Z,2017-06-22T21:12:34Z
3761,Bug: ImageDataGenerator for multiple output and single input fails,"The image data generator image.py fails when I tried to train a single input and multiple output model with data augmentation by saying 'the shape of X and y must be the same. 

But, for multiple output model, I supply a list of ndarrays and since the input is a single input, I supplied just X as is ndarray. I locally fixed it by checking to see if y is a list and bypass the exception and it works just fine.
",esube,b'stale',2016-09-13T17:20:43Z,2019-04-08T15:11:42Z
3630,Bug fix : Sequential model guide,"The mode function of `Merge` layer takes a single argument : the list of tensors being merged.
",farizrahman4u,None,2016-08-30T16:07:44Z,2016-08-30T16:43:41Z
3626,Bug with Timedistributed and shared models,"The following code triggers a bug:

``` python
import numpy as np                                                                                      
from keras.layers import merge, Input, Dense, TimeDistributed, Lambda                                   
from keras.models import Model                                                                          
from keras import backend as K                                                                          
from keras.constraints import maxnorm                                                                   

# first, define the shared model                                                                          
input = Input(shape=(100,))                                                                             
out = Dense(10, W_constraint=maxnorm(10), name='shared_dense')(input)                                   
shared_model = Model(input, out, name='shared_model')                                                   

# then define the inputs                                                                                
a = Input(shape=(100,))                                                                                 
b = Input(shape=(5, 100,))                                                                              
out_a = shared_model(a)                                                                                 
out_b = TimeDistributed(shared_model)(b)                                                                
out_b = Lambda(                                                                                         
    function=lambda x: K.sum(x, axis=1),                                                                
    output_shape=lambda shape: (shape[0],) + shape[2:])(out_b)                                          
concatenated = merge([out_a, out_b], mode='concat')                                                     
out = Dense(1, activation='sigmoid')(concatenated)                                                      

classification_model = Model([a, b], out)                                                               
classification_model.compile(optimizer='sgd', loss='binary_crossentropy')                               

classification_model.train_on_batch(                                                                    
    [np.ones((20, 100)), np.ones((20, 5, 100))],                                                        
    [np.ones(20)]                                                                                       
)                

```

The bug is triggered by the constraint on the shared_dense layer (removing it results in working code), and stems from container:constraints method. 
The max_norm constraint is added both via the `shared_model` and the `shared_dense`.
This also results in regularizations appearing more than once, but silently, as there is no check as in constraints. This bug is only triggered when sharing a model via the TimeDistributed wrapper. 

Any ideas on how to solve this?
",tzachar,None,2016-08-30T12:14:06Z,2016-08-30T20:55:28Z
3590,"Bug fix, batch_size set instead of default one","The evaluate function was called with the default batch_size (32).
So it doesn't work when your GPU does not handle a batch_size of 32.
",pambros,None,2016-08-26T10:13:45Z,2016-08-26T21:30:57Z
3551,Bug: Default 'nb_words' value should be set in 'Tokenizer' constructor,"### Summary

Initializing `keras.preprocessing.text.Tokenizer` without any arguments results in a `MemoryError`. This appears to be because the variable `nb_words` is not set. Setting this to 1000 in the constructor fixes this issue. Suggested fix: if `nb_words` is not set using an argument it should have a sensible default.

See the script below for an example.
### `bug.py` - script to reproduce error

Run this script after [downloading and unzipping the attached data file](https://github.com/fchollet/keras/files/432150/reddit_titles.zip) (17MB). Change the value of the `SOURCE_FILE` variable to point to the unzipped file.

``` python
import io
import json
import keras
from keras.preprocessing import text

SOURCE_FILE = ""/tmp/reddit_titles""
with open(SOURCE_FILE, ""r"") as f:
    data = json.load(f)

data = [d.encode('ascii') for d in data]

tk = text.Tokenizer() # Change this to fix: tk = text.Tokenizer(nb_words=1000)
tk.fit_on_texts(data)
tfidf = tk.texts_to_matrix(data, mode=""tfidf"")
```
### Traceback (`MemoryError`)

```
Traceback (most recent call last):
  File ""bug.py"", line 13, in <module>
    tfidf = tk.texts_to_matrix(data, mode=""tfidf"")
  File ""/home/sumanas/Documents/python/keras/local/lib/python2.7/site-packages/Keras-1.0.7-py2.7.egg/keras/preprocessing/text.py"", line 167, in texts_to_matrix
    return self.sequences_to_matrix(sequences, mode=mode)
  File ""/home/sumanas/Documents/python/keras/local/lib/python2.7/site-packages/Keras-1.0.7-py2.7.egg/keras/preprocessing/text.py"", line 191, in sequences_to_matrix
    X = np.zeros((len(sequences), nb_words))
MemoryError
```

Using Keras version: 

``` bash
$ git describe --abbrev=4 HEAD
1.0.7-40-g090b
```

| Desc | Version |
| --- | --- |
| OS | Ubuntu 14.04.5 64-bit |
| Python | 2.7.6 |
| Numpy | 1.11.1 |

**DATA FILE:** [reddit_titles.zip](https://github.com/fchollet/keras/files/432150/reddit_titles.zip) (17MB)
",insectatorious,b'stale',2016-08-23T10:43:17Z,2017-06-23T00:11:28Z
3550,Bug fix : RNNs,"Avoid concatenating too many tensors (~100) when the actual logic is to tile, as this might cause `Blocks nested too deeply` error in large models (theano backend, Windows). This is actually an issue with Microsoft's Visual C compiler.
",farizrahman4u,None,2016-08-23T10:30:37Z,2016-08-24T00:03:17Z
3459,Bug Keras1.0.7 - Convolution2D or Objectives?,"When I upgrade from Keras1.0.6 to 1.0.7, the following code produces wildly different results for the loss. In 1.0.6, the loss starts ~1.5 and steadily decreases. In 1.0.7, however, the MSE loss starts around 14,000 .. which is clearly not correct. I'm thinking it's either a problem with the MSE objective, the convolution layer, or maybe the regularizer is not getting picked up. Note this code is trivial to reproduce the error.

It happens w/ theano0.8.2 and 0.9.0dev. I'm using NVIDIA GPU with CUDA7.5 and visual studio VC12.0, cuDNN 5005.

```
from __future__ import division
import numpy as np

from keras.models import Sequential
from keras.layers import Dense, Flatten, Convolution2D
from keras.regularizers import l1l2
from keras.optimizers import SGD


images = np.random.randn(10000,1,32,32)

x_train = images[0:8000,:,:,:]
y_train = x_train.copy()
x_test = images[8000:,:,:,:]
y_test = x_test.copy()

ytr = np.empty((y_train.shape[0],y_train.shape[-1]**2))
yte = np.empty((y_test.shape[0],y_test.shape[-1]**2))
for i in range(y_train.shape[0]):
    ytr[i,:] = y_train[i,:,:,:].flatten()
    if i < y_test.shape[0]:
        yte[i,:] = y_test[i,:,:,:].flatten()
y_train = ytr
y_test = yte

stride = (2,2)
kernel_size = (15,15)
nb_kernels = 2

autoencoder = Sequential()
autoencoder.add(Convolution2D(nb_kernels, kernel_size[0], kernel_size[1], 
    border_mode='same', subsample=stride, W_regularizer=l1l2(l1=1.0,l2=0.1),
    activation='relu', input_shape=(1,x_train.shape[-1],x_train.shape[-1])))
autoencoder.add(Flatten())
autoencoder.add(Dense(y_train.shape[-1], 
    activation='tanh', W_regularizer=l1l2(l1=1.0,l2=0.1)))


autoencoder.compile(optimizer=SGD(lr=0.5), loss='mse')

autoencoder.fit(x_train, y_train,
                nb_epoch=100,
                batch_size=512,
                verbose = 1,
                validation_data=(x_test,y_test))
```

1.0.7:

Train on 8000 samples, validate on 2000 samples
Epoch 1/100
8000/8000 [==============================] - 0s - loss: 138498.2220 - val_loss: 1.9168
Epoch 2/100
8000/8000 [==============================] - 0s - loss: 140987.8638 - val_loss: 1.9382
Epoch 3/100
8000/8000 [==============================] - 0s - loss: 141583.5654 - val_loss: 1.9408

1.0.6:

Train on 8000 samples, validate on 2000 samples
Epoch 1/100
8000/8000 [==============================] - 0s - loss: 1.0857 - val_loss: 1.0002
Epoch 2/100
8000/8000 [==============================] - 0s - loss: 1.0361 - val_loss: 0.9999
Epoch 3/100
8000/8000 [==============================] - 0s - loss: 1.0316 - val_loss: 0.9999
",ncullen93,b'stale',2016-08-12T17:03:23Z,2017-06-23T01:11:09Z
3433,Bug fix : squeeze,"Avoid all the broadcasting stuff.
",farizrahman4u,None,2016-08-09T20:17:38Z,2016-08-09T20:59:47Z
3431,Potential Bug in K.squeeze for Theano?,"[Here](https://gist.github.com/jmhessel/ede93c03ed04824c72ad773e13b37265) is an example of a case where Theano and Tensorflow differ in their behavior with respect to the K.squeeze function. Essentially, [K.squeeze(x, 2)](https://github.com/fchollet/keras/blob/master/keras/backend/theano_backend.py#L504-L511) doesn't perform as it should in the example I provided, but only when using the Theano backend.

Has anyone else encountered this? Is this indeed a bug? If so, do folks have thoughts about what could be potentially not working?
#3420 also mentions an issue with this function in the Theano backend, though I'm not sure if this is exactly the same issue
",jmhessel,b'type:bug/performance',2016-08-09T18:55:41Z,2017-01-26T16:46:43Z
3422,Bug in ImageDataGenerator/standartize,"the samplewise operations should be over the spatial axes not over the channel axis. i.e.

x -= np.mean(x, axis=img_channel_index, keepdims=True)

should be:

x -= np.mean(x, axis=(row_index, col_index), keepdims=True)
",eyaler,None,2016-08-08T16:22:13Z,2016-11-23T04:22:06Z
3252,Bug fix + test - Sequential.pop(),"Update inbound nodes after popping last layer. Otherwise `output_shape` of the model will not be updated.

``` python
model = Sequential()
model.add(Dense(10, input_dim=10))
model.add(Dense(20))
print model.output_shape  # >> (None, 20)
model.pop()
print model.output_shape  # >> (None, 20) 
```

Also since `pop()` is sort of a hack, I thought it would be good to have a test.
",farizrahman4u,None,2016-07-18T21:14:11Z,2017-03-07T11:53:45Z
3002,Bug in combination of TimeDistributed with LSTM with param consume_less='cpu',"Hello,
I encountered a problem, which I guess is a Bug. I do combine TimeDistributed with LSTM and run into a broadcast problem when I use the LSTM with parameter `consume_less='cpu'` :
`ValueError: operands could not be broadcast together with shapes (50,64) (100,64) (50,64)`

Using the LSTM with parameter `consume_less='gpu'` works.

Code in Github[(link):](https://github.com/siavash9000/mixed_word_embedding/blob/master/simplified.py)

```
from keras.models import Model
from keras.utils import np_utils
from keras.layers import Dense, Embedding, Input, TimeDistributed, LSTM,  \
    Activation
import numpy as np


def main():
    DATA_SIZE = 1000
    BATCH_SIZE = 100
    WORD_COUNT = 20
    WORD_LENGTH = 10
    CHAR_VOCAB_SIZE = 50
    NB_CLASSES = 5
    CONSUME_LESS = 'cpu'

    X = np.random.randint(CHAR_VOCAB_SIZE, size=(DATA_SIZE, WORD_COUNT, WORD_LENGTH))
    Y = np.random.randint(NB_CLASSES, size=DATA_SIZE)
    Y = np_utils.to_categorical(Y, NB_CLASSES)

    input = Input(batch_shape=(BATCH_SIZE,WORD_COUNT, WORD_LENGTH, ),
                  dtype='int32')
    embedded = TimeDistributed(Embedding(CHAR_VOCAB_SIZE, 128,
                                         input_length=WORD_COUNT))(input)
    char_lstm = TimeDistributed(LSTM(64, consume_less=CONSUME_LESS))(embedded)
    lstm = LSTM(64,consume_less=CONSUME_LESS)(char_lstm)
    dense = Dense(NB_CLASSES, activation='sigmoid')(lstm)
    output = Activation('softmax')(dense)
    model = Model(input=input, output=output)
    model.compile(loss='categorical_crossentropy', optimizer='adam',
                  metrics=['accuracy'])
    model.fit(X, Y, batch_size=BATCH_SIZE, nb_epoch=5)


if __name__ == ""__main__"":
    main()
```

Please make sure that the boxes below are checked before you submit your issue. Thank you!
- [x] Check that you are up-to-date with the master branch of Keras. You can update with:
  pip install git+git://github.com/fchollet/keras.git --upgrade --no-deps
- [x] If running on Theano, check that you are up-to-date with the master branch of Theano. You can update with:
  pip install git+git://github.com/Theano/Theano.git --upgrade --no-deps
- [x] Provide a link to a GitHub Gist of a Python script that can reproduce your issue (or just copy the script here if it is short). 
",siavash9000,b'stale',2016-06-17T08:18:49Z,2017-06-22T22:11:25Z
2966,"Bug: When loading two sequential models, the second gets the input of the first one. ","Hi, following my previous message I can now confirm the bug at loading the models. 

So, a minimum working example is: 

```
from keras.models import model_from_json

with open(model_1_file_name) as f:
    model_1 = model_from_json(f.read())
with open(model_2_file_name) as f:
    model_2 = model_from_json(f.read())
```

Now, if someone checks the `model_1.input` and the `model_2.input` he will see that both are the same. 
",dr-costas,None,2016-06-13T11:17:26Z,2016-06-16T16:08:58Z
2889,bug in get_output_shape_for() function of Flatten layer,"Currently the get_output_shape_for() funciton of Flatten layer requires all dimensions are explicitly defined, otherwise it will raise an exception. However, when building FCN model with variable-sized input, this will be a problem since not all input dimensions are fixed. I suggest modifying the get_output_shape_for() function from 

```
def get_output_shape_for(self, input_shape):
    if not all(input_shape[1:]):
         raise Exception('The shape of the input to ""Flatten"" '
                         'is not fully defined '
                         '(got ' + str(input_shape[1:]) + '. '
                         'Make sure to pass a complete ""input_shape"" '
                         'or ""batch_input_shape"" argument to the first '
                         'layer in your model.')
    return (input_shape[0], np.prod(input_shape[1:]))
```

to 

```
def get_output_shape_for(self, input_shape):
    if not all(input_shape[1:]):
        return (input_shape[0], None)
    return (input_shape[0], np.prod(input_shape[1:]))
```

This will resolve the problem.

_Index: FCN, fully convolutional network_

Please make sure that the boxes below are checked before you submit your issue. Thank you!
- [x] Check that you are up-to-date with the master branch of Keras. You can update with:
  pip install git+git://github.com/fchollet/keras.git --upgrade --no-deps
- [ ] If running on Theano, check that you are up-to-date with the master branch of Theano. You can update with:
  pip install git+git://github.com/Theano/Theano.git --upgrade --no-deps
- [ ] Provide a link to a GitHub Gist of a Python script that can reproduce your issue (or just copy the script here if it is short).
",ghost,b'stale',2016-06-03T06:19:00Z,2017-06-22T22:12:30Z
2665,Bug or misunderstanding in keras  code example mnist_siamese_graph.py,"Hi  
   I am learning the keras code example mnist_siamese_graph.py. The Lambda layer in this example accepts two inputs from below layers, so I think  eucl_dist_output_shape function would also process a list of two corresponding input shapes.  Assume  input ""processed_a"" and processed_b have  shapes with (nsamples,dim)., then the input shape will be like [(nsamples,dim),(nsamples,dim)]
According to function method ""eucl_dist_output_shape(shapes)"", it will give a result (nsampels,dim). But actually, the result of eucl_dist is (nsamples,1). 
I am not sure whether I have a misunderstanding about Lambda layer's input.

---

1.distance = Lambda(euclidean_distance, output_shape=eucl_dist_output_shape)([processed_a, processed_b])
2.def eucl_dist_output_shape(shapes):
    shape1, shape2 = shapes
    return shape1
3.def euclidean_distance(vects):
    x, y = vects
    return K.sqrt(K.sum(K.square(x - y), axis=1, keepdims=True))
",cxfneo,b'stale',2016-05-09T06:27:42Z,2017-06-22T21:10:35Z
2553,Bug? Differences between Graph() of version 0.3.3 and latest Keras API when I built Bidirectional GRU with two layers.,"Two problems happened when I used the latest Keras API.
1. After the model was trained, I saved the model architecture and weights. However, the reloaded model can't do prediction. Then I find I have to recompile a exactly same model and just loaded the weights. Actually, the model architecture can't be reloaded successfully. In addition, I didn't find such problem in 0.3.3.
   GRU_model = model_from_json(open('GRU_model_architecture.json').read()) # -->something wrong in source code?
   GRU_model.load_weights('GRU_model_weights.h5')
2. I built a Bidirectional GRU with two layers with the latest Keras API by the following codes. I find the results haven't been improved by comparing with the normal GRU model with one layer. However, it showed there are huge differences between the simple GRU and complex GRU models when I used the old version 0.3.3 by Graph(). In the latest version, have the model really compiled? No error was reported during running.  Bug or my bad coding..? 
   ### latest version
   
   def Bi_2l_GRU(self, X, Y, vec_dim, sent_length, first_output_dim, drop_percent, nepoch):
   
   ```
   inputs = Input(shape=(None, vec_dim), batch_shape=(1, None, vec_dim), name='inputs')
   layer1_out1 = GRU(sent_length, activation='tanh', return_sequences=True, dropout_U=drop_percent, dropout_W=drop_percent)(inputs)
   layer1_out2 = GRU(sent_length, activation='tanh', return_sequences=True, dropout_U=drop_percent, dropout_W=drop_percent, go_backwards=True)(inputs)
   layer1_loss = TimeDistributed(Dense(first_output_dim, activation='softmax'))(layer1_out1, layer1_out2)
   layer2_out1 = GRU(sent_length, activation='tanh', return_sequences=True, dropout_U=drop_percent, dropout_W=drop_percent)(layer1_loss)
   layer2_out2 = GRU(sent_length, activation='tanh', return_sequences=True, dropout_U=drop_percent, dropout_W=drop_percent, go_backwards=True)(layer1_loss)
   predictions = TimeDistributed(Dense(3, activation='softmax'))(layer2_out1, layer2_out2)
   model = Model(input=inputs, output=predictions)
   model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])
   
   for epoch in xrange(nepoch):
       print 'epoch:', epoch
       for idx, (seq, label) in enumerate(zip(X, Y)):
           #model.train_on_batch(np.array([seq]), np.array([label.T]))
           loss, accuracy = model.train_on_batch(np.array([seq]), np.array([label.T]))
           if idx % 50 == 0:
               print ""\tidx={0}, loss={1}, accuracy={2}"".format(idx, loss, accuracy)
   return model
   ```
### version 0.3.3

```
def Bi_2l_GRU(self, X, Y, vec_dim, HIDDEN_SIZE, nepoch):

    model = Graph()
    model.add_input(name='input', input_shape=(None, vec_dim))
    model.add_node(GRU(HIDDEN_SIZE, activation='tanh', return_sequences=True), name='forward', input='input')
    model.add_node(GRU(HIDDEN_SIZE, activation='tanh', return_sequences=True, go_backwards=True), name='backward', input='input')
    model.add_node(Dropout(0.5), name='dropout', merge_mode='concat', inputs=['forward', 'backward'])
    model.add_node(GRU(HIDDEN_SIZE, activation='tanh', return_sequences=True), name='level2_forward', input='dropout')
    model.add_node(GRU(HIDDEN_SIZE, activation='tanh', return_sequences=True, go_backwards=True), name='level2_backward', input='dropout')
    model.add_node(Dropout(0.5), name='level2_dropout', merge_mode='concat', inputs=['level2_forward', 'level2_backward'])
    model.add_node(TimeDistributed(Dense(3, activation='softmax')), name='softmax', input='level2_dropout')
    model.add_output(name='output', input='softmax')
    model.compile('adam', {'output': 'categorical_crossentropy'}, metrics=[""accuracy""])

    for epoch in xrange(nepoch):
        print 'epoch:', epoch
        for idx, (seq, label) in enumerate(zip(X, Y)):
            loss, accuracy = model.train_on_batch({'input':np.array([seq]), 'output':np.array([label.T])})
            if idx % 50 == 0:
                print ""\tidx={0}, loss={1}, accuracy={2}"".format(idx, loss, accuracy)
    return model
```
- [Yes ] Check that you are up-to-date with the master branch of Keras. You can update with:
  pip install git+git://github.com/fchollet/keras.git --upgrade --no-deps
- [ Yes] If running on Theano, check that you are up-to-date with the master branch of Theano. You can update with:
  pip install git+git://github.com/Theano/Theano.git --upgrade --no-deps
- [ Yes] Provide a link to a GitHub Gist of a Python script that can reproduce your issue (or just copy the script here if it is short).
",TwoScientists,b'stale',2016-04-29T08:25:05Z,2017-06-23T00:12:42Z
2259,Bug: Recurrent dropout fails silenty when set on loaded model,"Pretrained models are often finetuned on small datasets. For these use cases it can be relevant to add dropout to prevent overfitting. However, adding recurrent dropout to a loaded model (and recompiling the model) has no effect at all.

I've modified the `imdb_lstm` to demonstrate this. With recurrent dropout of 0.999, the model should not be able to learn anything, but it actually starts overfitting dramatically (it gets an accuracy of ~99% after 3 epochs). See the code below.

```
'''Train a LSTM on the IMDB sentiment classification task.

The dataset is actually too small for LSTM to be of any advantage
compared to simpler, much faster methods such as TF-IDF+LogReg.

Notes:

- RNNs are tricky. Choice of batch size is important,
choice of loss and optimizer is critical, etc.
Some configurations won't converge.

- LSTM loss decrease patterns during training can be quite different
from what you see with CNNs/MLPs/etc.

GPU command:
    THEANO_FLAGS=mode=FAST_RUN,device=gpu,floatX=float32 python imdb_lstm.py
'''

from __future__ import print_function
import numpy as np
np.random.seed(1337)  # for reproducibility

from keras.preprocessing import sequence
from keras.utils import np_utils
from keras.models import Sequential, model_from_yaml
from keras.layers.core import Dense, Dropout, Activation
from keras.layers.embeddings import Embedding
from keras.layers.recurrent import LSTM
from keras.datasets import imdb

max_features = 20000
maxlen = 100  # cut texts after this number of words (among top max_features most common words)
batch_size = 32

print('Loading data...')
(X_train, y_train), (X_test, y_test) = imdb.load_data(nb_words=max_features,
                                                      test_split=0.2)
print(len(X_train), 'train sequences')
print(len(X_test), 'test sequences')

print(""Pad sequences (samples x time)"")
X_train = sequence.pad_sequences(X_train, maxlen=maxlen)
X_test = sequence.pad_sequences(X_test, maxlen=maxlen)
print('X_train shape:', X_train.shape)
print('X_test shape:', X_test.shape)

print('Build model...')
model = Sequential()
model.add(Embedding(max_features, 128, input_length=maxlen))
model.add(LSTM(128))  # try using a GRU instead, for fun
model.add(Dropout(0.5))
model.add(Dense(1))
model.add(Activation('sigmoid'))

# try using different optimizers and different optimizer configs
model.compile(loss='binary_crossentropy',
              optimizer='adam',
              class_mode=""binary"")

print(""Train..."")
model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=3,
          validation_data=(X_test, y_test), show_accuracy=True)
score, acc = model.evaluate(X_test, y_test,
                            batch_size=batch_size,
                            show_accuracy=True)
print('Test score:', score)
print('Test accuracy:', acc)


print("""")
print('Saving weights.')

yaml_string = model.to_yaml()
open('imdb_lstm_config.yaml', 'w+').write(yaml_string)
model.save_weights('imdb_lstm_weights.h5', overwrite=True)

print('Reloading weights in new model with recurrent dropout.')
print("""")

loaded_model = model_from_yaml(open('imdb_lstm_config.yaml').read())
loaded_model.load_weights('imdb_lstm_weights.h5')
loaded_model.layers[0].dropout = 0.99
loaded_model.layers[1].dropout_U = 0.99
loaded_model.layers[1].dropout_W = 0.99

loaded_model.compile(loss='binary_crossentropy',
              optimizer='adam',
              class_mode=""binary"")

print(""Train..."")
loaded_model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=3,
                 validation_data=(X_test, y_test), show_accuracy=True)
score, acc = loaded_model.evaluate(X_test, y_test,
                                   batch_size=batch_size,
                                   show_accuracy=True)
print('Test score:', score)
print('Test accuracy:', acc)
```
",PiranjaF,None,2016-04-11T15:19:14Z,2016-04-16T19:18:36Z
2217,Bug fix to set correct uses_learning_phase flag,"`test_on_batch` and `predict_on_batch` had the wrong `uses_learning_phase` flag
",the-moliver,None,2016-04-06T23:22:23Z,2016-04-06T23:56:32Z
2160,Bugs in save and load weights,"I want to train a model with parts of parameters fixed. When I tried to load saved weights from the HDF5 file, it fails. It seems the saveweight function does not save none-trainable weights, while loadweight function requires them. See example code below:

<pre><code>
from keras.models import Sequential
from keras.layers.core import Merge
from keras.layers.convolutional import Convolution2D


model_range_5 = Sequential()
model_range_5.add(Convolution2D(128,5,5,dim_ordering='tf',activation='relu',border_mode='same',input_shape=(256,200,3),trainable=False))

model_range_4 = Sequential()
model_range_4.add(Convolution2D(128,5,5,dim_ordering='tf',activation='relu',border_mode='same',input_shape=(256,200,3)))


test_model = Sequential([Merge([model_range_5,model_range_4])])

test_model.compile(optimizer='SGD',loss='mse')
test_model.save_weights('weight.model',overwrite=True)
test_model.load_weights('weight.model')
</code></pre>
",tanxchong,b'stale',2016-04-01T15:13:06Z,2019-12-12T18:21:45Z
2141,Bug in loading the reuters dataset,"There is possibly a bug in the loading of the reuters dataset.

In the data loading section, specifically, 

(X_train, y_train), (X_test, y_test) = reuters.load_data(nb_words=max_words, test_split=0.2)

I get the following ValueError. 

---

ValueError                                Traceback (most recent call last)
<ipython-input-11-20dbe1cbaee1> in <module>()
      1 print('Loading data...')
----> 2 (X_train, y_train), (X_test, y_test) = reuters.load_data(nb_words=max_words, test_split=0.2)
      3 print(len(X_train), 'train sequences')
      4 print(len(X_test), 'test sequences')

/home/debo/.conda/envs/flowers/lib/python2.7/site-packages/keras/datasets/reuters.pyc in load_data(path, nb_words, skip_top, maxlen, test_split, seed, start_char, oov_char, index_from)
     13     path = get_file(path, origin=""https://s3.amazonaws.com/text-datasets/reuters.pkl"")
     14     f = open(path, 'rb')
---> 15     X, labels = cPickle.load(f)
     16     f.close()
     17 

ValueError: could not convert string to int

I checked with the imdb dataset, and the following works:

(X_train, y_train), (X_test, y_test) = imdb.load_data(nb_words=max_features,
                                                      test_split=0.5)
",debajyotidatta,None,2016-03-31T01:08:30Z,2016-11-28T00:50:43Z
2111,Bug: input_shape error for advanced activations,"I just updated Keras and my code stopped functioning due to the error:

`Exception: Layer is not connected. Did you forget to set ""input_shape""?`

Note that my code was running minutes ago before updating Keras. After trying a lot, I found out that by replacing all `LeakyReLU()` by `'relu'`, the error gets resolved. So, I reproduced this issue on the `mnist_cnn.py` script in Keras Examples folder. Even more bizarre phenomena is that if you put some random `input_shape` values, you will be able to get the code compiled. If this was not the case, it would have been at least acceptable, since for each activation layer, user is forced to calculate the **correct** input shape. However, now this behavior is susceptible to user errors.

Script to reproduce the issue: 

```
from __future__ import print_function
import numpy as np
np.random.seed(1337)  # for reproducibility

from keras.datasets import mnist
from keras.models import Sequential
from keras.layers.core import Dense, Dropout, Activation, Flatten
from keras.layers.convolutional import Convolution2D, MaxPooling2D
from keras.utils import np_utils

batch_size = 128
nb_classes = 10
nb_epoch = 12

# input image dimensions
img_rows, img_cols = 28, 28
# number of convolutional filters to use
nb_filters = 32
# size of pooling area for max pooling
nb_pool = 2
# convolution kernel size
nb_conv = 3

# the data, shuffled and split between train and test sets
(X_train, y_train), (X_test, y_test) = mnist.load_data()

X_train = X_train.reshape(X_train.shape[0], 1, img_rows, img_cols)
X_test = X_test.reshape(X_test.shape[0], 1, img_rows, img_cols)
X_train = X_train.astype('float32')
X_test = X_test.astype('float32')
X_train /= 255
X_test /= 255
print('X_train shape:', X_train.shape)
print(X_train.shape[0], 'train samples')
print(X_test.shape[0], 'test samples')

# convert class vectors to binary class matrices
Y_train = np_utils.to_categorical(y_train, nb_classes)
Y_test = np_utils.to_categorical(y_test, nb_classes)

model = Sequential()

model.add(Convolution2D(nb_filters, nb_conv, nb_conv,
                        border_mode='valid',
                        input_shape=(1, img_rows, img_cols)))
model.add(Activation(LeakyReLU()))
model.add(Convolution2D(nb_filters, nb_conv, nb_conv))
model.add(Activation(LeakyReLU()))
model.add(MaxPooling2D(pool_size=(nb_pool, nb_pool)))
model.add(Dropout(0.25))

model.add(Flatten())
model.add(Dense(128))
model.add(Activation(LeakyReLU()))
model.add(Dropout(0.5))
model.add(Dense(nb_classes))
model.add(Activation('softmax'))

model.compile(loss='categorical_crossentropy', optimizer='adadelta')

model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epoch,
          show_accuracy=True, verbose=1, validation_data=(X_test, Y_test))
score = model.evaluate(X_test, Y_test, show_accuracy=True, verbose=0)
print('Test score:', score[0])
print('Test accuracy:', score[1])
```

To make the above script work(?), replace `LeakyReLU()` by `LeakyReLU(input_shape=(20,20,20))`. Its quite obvious that these numbers (20, 20, 20) are random and code works as long as you put some value.

I think this is a serious bug and should be addressed as soon as possible. @fchollet 
",parag2489,b'stale',2016-03-29T05:58:56Z,2017-06-22T21:10:21Z
2020,Bug in Graph model with matrix input ?,"Hi, 
I was trying to train a very simple model using embeddings and LSTM for sentiment prediction.
Basically my input data is a matrix, in which, each row is one sentence, 
and each column, is the index of the word in my embedding matrix. 
Number of columns is fixed and set to the maximum length of a sentence I notice in the
training set, and I do padding from the left. Assuming that I have 500 sentences,
and maximum seen length of a sentence is 52, then I will have a 500x**52** input matrix. 

I didn't pay attention to the maximum length of a sentence in the test data. 
I just created the input matrix for test data and it became a 200x**65** matrix. 
Surely, 65 does not agree with 52, but keras didn't complain at all, and I could train, optimize, and evaluate the whole pipeline! 

the following code, simply demonstrate my problem:  

`import numpy as np ; 
from keras.models import Graph ; 
from keras.layers import Embedding 
import theano.tensor as T ; #for fixing theano error in Graph model ... see: https://github.com/fchollet/keras/issues/340

data1 = np.array ([[1,0],[0,1]])
data2 = np.array ([[0,1,0,1],[1,0,1,0]])

E = np.array ([[10,10,10],[20,20,20]])
max_features      = E.shape[0]
embedding_size = E.shape[1]

model = Graph();
model.add_input (name=""I"" , input_shape = (2,)) ; 
model.inputs[""I""].input = T.imatrix(); ##for fixing theano error in Graph model ... see: https://github.com/fchollet/keras/issues/340

model.add_node (Embedding (input_dim = max_features , output_dim = embedding_size , weights=[E]), input=""I"" , name=""E"")
model.add_output (name=""O"", input=""E"")
model.compile (loss={""O"":'mse'}, optimizer=""sgd"") ; 
print model.predict ({""I"":data1}) , ""\n""
print model.predict ({""I"":data2})
`
and the output is: 
{'O': array([[[ 20.,  20.,  20.],
        [ 10.,  10.,  10.]],

```
   [[ 10.,  10.,  10.],
    [ 20.,  20.,  20.]]])} 
```

{'O': array([[[ 10.,  10.,  10.],
        [ 20.,  20.,  20.],
        [ 10.,  10.,  10.],
        [ 20.,  20.,  20.]],

```
   [[ 20.,  20.,  20.],
    [ 10.,  10.,  10.],
    [ 20.,  20.,  20.],
    [ 10.,  10.,  10.]]])}
```

I was expecting to get an error when doing prediction for data2, since the input shape of the data2 does not agree with what is defined (input_shape). 
1) Isn't it a bug? 
2) Should I care to set the number of columns for train and test matrices EQUALLY when
crating the matrix, especially if the maximum length of a sentence in test set is bigger than train set? 

Thanks in advance.
",farmeh,b'stale',2016-03-21T09:54:55Z,2017-06-22T21:09:53Z
1955,Bug in preprocessing/text.py,"In  sequences_to_matrix, **pass** is used twice, where **continue** should be used (lines 183 and 187). 

Problems should occour when you pass an empty sequence or a sequence containing a word with index >= nb_words.
",seppyr,None,2016-03-11T18:32:54Z,2016-03-11T18:51:39Z
1931,Bug in ImageDataGenerator Whitening procedure?,"I was looking at the source code of the whitening procedure. I found that the data is never mean centered before doing the whitening. Specifically, if we keep all the other options as False and just keep the image whitening to be true, then covariance matrix is computed without mean centering the data! Thus `XX^T` will no longer be the covariance matrix of the data if `mean(X) ~= 0`.

If everyone agrees with me on this, I can submit a pull request to correct this issue.
",parag2489,b'stale',2016-03-09T01:40:32Z,2017-06-22T23:11:34Z
1915,Bug: model_from_json crashes on Graphs with create_output=True layer,"This code:

```
m = krm.Graph()
m.add_input('x', input_shape=(10,))
m.add_node(klc.Dense(5), 'y', input='x', create_output=True)
m.compile(loss={'y': 'mse'}, optimizer='adam')

with open('test.json', 'w') as f:
    f.write(m.to_json())

with open('test.json', 'r') as f:
    m = krm.model_from_json(f.read())
```

crashes with the following error:

```
... models.py"", line 166, in model_from_json
... models.py"", line 177, in model_from_config
... layer_utils.py"", line 64, in container_from_config
... containers.py"", line 568, in add_output
    raise Exception('Duplicate output identifier: ' + name)
Exception: Duplicate output identifier: y
```

I'll see if I can fix it.
",qdbp,None,2016-03-08T00:35:41Z,2016-03-08T01:49:11Z
1835,"Bug in LSTM.build, in setting up regularizers","In `keras.layers.recurrent.LSTM.build()`:

``` python
        for W in [self.W_i, self.W_f, self.W_i, self.W_o]:
            append_regulariser(self.W_regularizer, W, self.regularizers)
        for U in [self.U_i, self.U_f, self.U_i, self.U_o]:
            append_regulariser(self.U_regularizer, U, self.regularizers)
        for b in [self.b_i, self.b_f, self.b_i, self.b_o]:
            append_regulariser(self.b_regularizer, b, self.regularizers)
```

should be

``` python
        for W in [self.W_i, self.W_f, self.W_c, self.W_o]:
            append_regulariser(self.W_regularizer, W, self.regularizers)
        for U in [self.U_i, self.U_f, self.U_c, self.U_o]:
            append_regulariser(self.U_regularizer, U, self.regularizers)
        for b in [self.b_i, self.b_f, self.b_c, self.b_o]:
            append_regulariser(self.b_regularizer, b, self.regularizers)
```

The 3rd element in each of the lists should be `*_c` instead of `*_i`.

Please make sure that the boxes below are checked before you submit your issue. Thank you!
- [x] Check that you are up-to-date with the master branch of Keras. You can update with:
  pip install git+git://github.com/fchollet/keras.git --upgrade --no-deps
- [x] If running on Theano, check that you are up-to-date with the master branch of Theano. You can update with:
  pip install git+git://github.com/Theano/Theano.git --upgrade --no-deps
- [ ] Provide a link to a GitHub Gist of a Python script that can reproduce your issue (or just copy the script here if it is short).
",sunil-at-gh,None,2016-02-26T20:56:26Z,2016-02-26T21:04:49Z
1768,Bug in callbacks.py ModelCheckpoint class,"There is a bug in the constructor of the ModelCheckpoint class (lines 247-259)

See code below (from master branch). If the mode parameter is not recognized, the warning message refers to a self.mode variable that is never initialized, and an exception is thrown:

`AttributeError: 'ModelCheckpoint' object has no attribute 'mode'`

--- Code from callbacks.py ---

```
 def __init__(self, filepath, monitor='val_loss', verbose=0,
                 save_best_only=False, mode='auto'):


        super(Callback, self).__init__()
        self.monitor = monitor
        self.verbose = verbose
        self.filepath = filepath
        self.save_best_only = save_best_only

        if mode not in ['auto', 'min', 'max']:
            warnings.warn('ModelCheckpoint mode %s is unknown, '
                          'fallback to auto mode.' % (self.mode),
                          RuntimeWarning)
```
",mbarison,None,2016-02-19T22:29:11Z,2016-02-20T03:14:39Z
1690,Bug: ImageDataGenerator actually shifts image vertically when used width_shift_range >0 and height_shift_range=0 (and vice-versa),"The title is explains the problem in ImageDataGenerator. I defined the data generator as follows:

```
datagen = ImageDataGenerator(
        featurewise_center=False,  # set input mean to 0 over the dataset
        samplewise_center=False,  # set each sample mean to 0
        featurewise_std_normalization=False,  # divide inputs by std of the dataset
        samplewise_std_normalization=False,  # divide each input by its std
        zca_whitening=False,  # apply ZCA whitening
        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)
        width_shift_range=0.5,  # randomly shift images horizontally (fraction of total width)
        height_shift_range=0.0,  # randomly shift images vertically (fraction of total height)
        horizontal_flip=False,  # randomly flip images
        vertical_flip=False)  # randomly flip images
```

Now one may assume by reading the `ImageDataGenerator` documentation that the images will be shifted by `0.5*image_width` from left to right (or from right to left). What I found by looking at the shifted images was totally opposite. When width_shift_range>0 and height_shift_range=0, it shifts the image from **top to bottom**. 

The culprit is in this line in `image.py`:

```
ndimage.interpolation.shift(x, (0, crop_left_pixels, crop_top_pixels), order=0, 
mode=fill_mode, cval=cval)
```

If we change the order of `crop_left_pixels` and `crop_right_pixels`, the images will shift as expected. One more thing remains, if `crop_left_pixels = 0.2`, then the image shifts in one direction only (I think `ndimage` does it from left to right). This prevents images getting shifted from other direction. Solution? Multiply `crop_left_pixels` by -1 in a random fashion. The modified function looks as follows:

```
def random_shift(x, wrg, hrg, fill_mode=""nearest"", cval=0.):
    crop_left_pixels = 0
    crop_top_pixels = 0

    if wrg:
        crop = random.uniform(0., wrg)
        split = random.uniform(0, 1)
        randSign = 2*np.random.randint(2)-1 #allows cropping from left and right both
        crop_left_pixels = randSign*int(split*crop*x.shape[2]) #x.shape[2] are actually columns
    if hrg:
        crop = random.uniform(0., hrg)
        split = random.uniform(0, 1)
    randSign = 2*np.random.randint(2)-1 #allows cropping from top and bottom both
        crop_top_pixels = randSign*int(split*crop*x.shape[1]) #x.shape[1] are actually rows
    x = ndimage.interpolation.shift(x, (0, crop_top_pixels, crop_left_pixels),
                                    order=0,
                                    mode=fill_mode,
                                    cval=cval)
    return x

```

If @fchollet can comment on this, then I can submit a pull request or anything else needed as per the norms.
",parag2489,None,2016-02-11T03:53:38Z,2016-02-15T07:39:25Z
1670,BUG: Typo in Examples Page?,"In the examples on http://keras.io/examples/, I think the lines that read

```
from keras.layers import Dense, Dropout, Activation
```

should be

```
from keras.layers.core import Dense, Dropout, Activation
```

If not, there is a problem with my installation.;P
",jsphon,None,2016-02-09T06:21:24Z,2016-02-09T21:53:33Z
1639,Bug: Incorrect batch_size in fit_generator (Sequential),"I'm having an issue with the batch sizes showing up correctly; whenever I print out the batch logs using a callback the batch_size is always the 2nd entry in the X.shape tuple. For example, if my X generated was of shape (batch_size, nrow, ncol, nb_channel), the batch_size would always be `nrow`. 
Another user faced a similar issue #1627 (his last comment), where his X.shape tuple was (batch_size, nb_channel, nrow, ncol). As his images had only 1 channel, this resulted in the batch_size being 1, and the loop iterating from 1-6000 instead of 1-1875.

My suspect of the offending line is in models.py line 1017

`batch_logs = {}`
`--->       batch_size = len(X[0])`
`batch_logs['batch'] = batch_index`

I'm looking at other parts of the code to check why it was implemented this way, but from what I see so far it seems like it should be 
`batch_size = len(X)` instead

Let me know if this is an issue faced by others and I'll submit a PR :)
",wongjingping,None,2016-02-04T10:10:22Z,2016-02-04T18:50:26Z
1594,Bug/Issue when loading weights on graph model,"I have included the model.py. Basically I can train the model just fine, however when I attempt to reload weights, it raises an exception that it can't find some part of the weights.

```
Using gpu device 0: GeForce GTX 980 (CNMeM is disabled)
/usr/local/lib/python2.7/dist-packages/theano/tensor/signal/downsample.py:5: UserWarning:

downsample module has been moved to the pool module.

Compiling models...
---------------------------------------------------------------------------
AssertionError                            Traceback (most recent call last)
/usr/lib/python2.7/dist-packages/IPython/utils/py3compat.pyc in execfile(fname, *where)
    202             else:
    203                 filename = fname
--> 204             __builtin__.execfile(filename, *where)

/home/ubuntumax/keras_branch/keras-dsb/experiment.py in <module>()
    309             run(sys.argv[2])
    310         elif sys.argv[1] == 'continue':
--> 311             run(sys.argv[2], cont=True)
    312         elif sys.argv[1] == 'submission':
    313             submission(sys.argv[2])

/home/ubuntumax/keras_branch/keras-dsb/experiment.py in run(experiment_name, cont)
     80     # load weights (if continue experiment)
     81     if cont:
---> 82         model_systole.load_weights(experiment_path + '/' + META_DIR + '/' + MODEL_SYS_W)
     83         model_diastole.load_weights(experiment_path + '/' + META_DIR + '/' + MODEL_DIAS_W)
     84     # import pre-process module

/usr/local/lib/python2.7/dist-packages/keras/models.pyc in load_weights(self, filepath)
   1230         g = f['graph']
   1231         weights = [g['param_{}'.format(p)] for p in range(g.attrs['nb_params'])]
-> 1232         self.set_weights(weights)
   1233         f.close()
   1234 

/usr/local/lib/python2.7/dist-packages/keras/layers/containers.pyc in set_weights(self, weights)
    526         for layer in self.nodes.values():
    527             nb_param = len(layer.get_weights())
--> 528             layer.set_weights(weights[:nb_param])
    529             weights = weights[nb_param:]

/usr/local/lib/python2.7/dist-packages/keras/layers/containers.pyc in set_weights(self, weights)
    157         for i in range(len(self.layers)):
    158             nb_param = len(self.layers[i].params)
--> 159             self.layers[i].set_weights(weights[:nb_param])
    160             weights = weights[nb_param:]
    161 

/usr/local/lib/python2.7/dist-packages/keras/layers/normalization.pyc in set_weights(self, weights)
     70         K.set_value(self.running_mean, weights[-2])
     71         K.set_value(self.running_std, weights[-1])
---> 72         super(BatchNormalization, self).set_weights(weights[:-2])
     73 
     74     def get_output(self, train):

/usr/local/lib/python2.7/dist-packages/keras/layers/core.pyc in set_weights(self, weights)
    211         assert len(self.params) == len(weights), ('Provided weight array does not match layer weights (' +
    212                                                   str(len(self.params)) + ' layer params vs. ' +
--> 213                                                   str(len(weights)) + ' provided weights)')
    214         for p, w in zip(self.params, weights):
    215             if K.get_value(p).shape != w.shape:

AssertionError: Provided weight array does not match layer weights (2 layer params vs. 0 provided weights)

```

Graph used:

```
conv = Sequential()
conv.add(Activation(activation=scale, input_shape=(30, 128, 128)))

conv.add(Convolution2D(64, 3, 3, border_mode='same'))
conv.add(Activation('relu'))
conv.add(Convolution2D(64, 3, 3, border_mode='same'))
conv.add(Activation('relu'))
conv.add(MaxPooling2D(pool_size=(2, 2)))
conv.add(BatchNormalization())
conv.add(Dropout(0.2))

conv.add(Convolution2D(128, 3, 3, border_mode='same'))
conv.add(Activation('relu'))
conv.add(Convolution2D(128, 3, 3, border_mode='same'))
conv.add(Activation('relu'))
conv.add(MaxPooling2D(pool_size=(2, 2)))
conv.add(BatchNormalization())
conv.add(Dropout(0.2))

conv.add(Convolution2D(256, 3, 3, border_mode='same'))
conv.add(Activation('relu'))
conv.add(Convolution2D(256, 3, 3, border_mode='same'))
conv.add(Activation('relu'))
conv.add(MaxPooling2D(pool_size=(2, 2)))
conv.add(BatchNormalization())
conv.add(Dropout(0.2))

conv.add(Convolution2D(512, 3, 3, border_mode='same'))
conv.add(Activation('relu'))
conv.add(Convolution2D(512, 3, 3, border_mode='same'))
conv.add(Activation('relu'))
conv.add(MaxPooling2D(pool_size=(2, 2)))
conv.add(BatchNormalization())
conv.add(Dropout(0.2))

conv.add(Convolution2D(512, 3, 3, border_mode='same'))
conv.add(Activation('relu'))
conv.add(Convolution2D(512, 3, 3, border_mode='same'))
conv.add(Activation('relu'))
conv.add(MaxPooling2D(pool_size=(2, 2)))
conv.add(BatchNormalization())
conv.add(Dropout(0.2))

conv.add(Convolution2D(512, 3, 3, border_mode='same'))
conv.add(Activation('relu'))
conv.add(Convolution2D(512, 3, 3, border_mode='same'))
conv.add(Activation('relu'))
conv.add(MaxPooling2D(pool_size=(2, 2)))
conv.add(BatchNormalization())
conv.add(Dropout(0.2))
conv.add(Flatten())
#conv.add(Reshape((1, 2048)))

meta = Sequential()
# meta.add(Dense(512, input_dim=4))
# meta.add(Activation('relu'))
# meta.add(Reshape((1, 512)))
meta.add(LSTM(512, input_shape=(1, 4), return_sequences=False))
meta.add(Dropout(0.5))
#meta.add(Reshape((1, 512)))

model = Graph()
model.add_input(name='conv_input', input_shape=(30, 128, 128))
model.add_input(name='meta_input', input_shape=(4,))
model.add_node(Reshape((1, 4)),name='meta_reshape', input='meta_input')
model.add_node(conv, name='conv', input='conv_input')
model.add_node(meta, name='meta', input='meta_reshape')
model.add_node(Dense(2048+512, W_regularizer=l2(1e-3)), name='merge', inputs=['conv', 'meta'], merge_mode='concat')
model.add_node(Reshape((1, 2048+512)), name='merge_reshape', input='merge')
model.add_node(LSTM(512, return_sequences=False), name='lstm_0', input='merge_reshape')
model.add_node(Dropout(0.5), name='lstm_do_0', input='lstm_0')
# model.add_node(LSTM(512), name='lstm_1', input='lstm_do_0')
# model.add_node(Dropout(0.5), name='lstm_do_1', input='lstm_1')
model.add_node(Dense(1), name='merge_out', input='lstm_do_0')
model.add_output(name='output', input='merge_out')
```
",AntreasAntoniou,b'stale',2016-01-29T20:45:41Z,2017-06-23T01:11:16Z
1386,BUG: BatchNormalization in nested models throws DisconnectedInputError,"As mentioned by @Sebubu in #1275 the following code results in a DisconnectedInputError:
He notes removing the BatchNormalization layer fixes the code.

``` python
from keras.models import Graph,  Sequential
from keras.layers.core import Dense
from keras.layers.normalization import BatchNormalization
from keras.layers.advanced_activations import PReLU


g = Graph()
g.add_input(""input"", input_shape=[20])
g.add_node(Dense(10), ""dense"", ""input"")
g.add_node(BatchNormalization(),""bn"", ""dense"")
g.add_node(PReLU(),""activ"", ""bn"")
g.add_output(""output"", ""activ"")
print ""g output "" + str(g.output_shape)

g2 = Graph()
g2.add_input(""input"", input_shape=[10])
g2.add_node(Dense(15), ""dense"", ""input"")
g2.add_node(BatchNormalization(),""bn"", ""dense"")
g2.add_node(PReLU(),""activ"", ""bn"")
g2.add_output(""output"", ""activ"")

model = Sequential()

model.add(g)
model.add(g2)

model.compile(loss=""mse"",optimizer=""adadelta"")
```

The problem here is that in the `BatchNormalization` layer the `update` rules of the `running_mean` and `running_std` members are set in the `build` method. When the input of the batch norm layer changes, the `update` rules are not updated accordingly. 
",berleon,None,2015-12-31T15:51:43Z,2016-01-01T20:02:15Z
1315,Bug in /theano/sandbox/cuda/dnn.py,"/usr/bin/python2.7 /home/dell/DLTest/cifar_test/Residul/cifar_residul_net.py
Using Theano backend.
Using gpu device 1: GeForce GTX TITAN X (CNMeM is disabled)
('X_train shape:', (50000, 3, 32, 32))
(50000, 'train samples')
(10000, 'test samples')
Traceback (most recent call last):
  File ""/home/dell/DLTest/cifar_test/Residul/cifar_residul_net.py"", line 87, in <module>
    model.compile(loss='categorical_crossentropy', optimizer=sgd)
  File ""/home/dell/.local/lib/python2.7/site-packages/keras/models.py"", line 372, in compile
    self.y_train = self.get_output(train=True)
  File ""/home/dell/.local/lib/python2.7/site-packages/keras/layers/containers.py"", line 73, in get_output
    return self.layers[-1].get_output(train)
  File ""/home/dell/.local/lib/python2.7/site-packages/keras/layers/core.py"", line 681, in get_output
    X = self.get_input(train)
  File ""/home/dell/.local/lib/python2.7/site-packages/keras/layers/core.py"", line 102, in get_input
    return self.previous.get_output(train=train)
  File ""/home/dell/.local/lib/python2.7/site-packages/keras/layers/core.py"", line 591, in get_output
    X = self.get_input(train)
  File ""/home/dell/.local/lib/python2.7/site-packages/keras/layers/core.py"", line 102, in get_input
    return self.previous.get_output(train=train)
  File ""/home/dell/.local/lib/python2.7/site-packages/keras/layers/containers.py"", line 216, in get_output
    return self.outputs[self.output_order[0]].get_output(train)
  File ""/home/dell/.local/lib/python2.7/site-packages/keras/layers/core.py"", line 389, in get_output
    s = self.layers[0].get_output(train)
  File ""/home/dell/.local/lib/python2.7/site-packages/keras/layers/convolutional.py"", line 212, in get_output
    X = self.get_input(train)
  File ""/home/dell/.local/lib/python2.7/site-packages/keras/layers/core.py"", line 102, in get_input
    return self.previous.get_output(train=train)
  File ""/home/dell/.local/lib/python2.7/site-packages/keras/layers/core.py"", line 98, in get_output
    return self.get_input(train)
  File ""/home/dell/.local/lib/python2.7/site-packages/keras/layers/core.py"", line 102, in get_input
    return self.previous.get_output(train=train)
  File ""/home/dell/.local/lib/python2.7/site-packages/keras/layers/containers.py"", line 216, in get_output
    return self.outputs[self.output_order[0]].get_output(train)
  File ""/home/dell/.local/lib/python2.7/site-packages/keras/layers/core.py"", line 389, in get_output
    s = self.layers[0].get_output(train)
  File ""/home/dell/.local/lib/python2.7/site-packages/keras/layers/convolutional.py"", line 215, in get_output
    dim_ordering=self.dim_ordering)
  File ""/home/dell/.local/lib/python2.7/site-packages/keras/backend/theano_backend.py"", line 543, in conv2d
    border_mode=(pad_x, pad_y))
  File ""/usr/local/lib/python2.7/dist-packages/theano/sandbox/cuda/dnn.py"", line 1191, in dnn_conv
    conv_mode=conv_mode)(img.shape, kerns.shape)
  File ""/usr/local/lib/python2.7/dist-packages/theano/sandbox/cuda/dnn.py"", line 251, in **init**
    border_mode = tuple(map(int, border_mode))
TypeError: int() argument must be a string or a number, not 'TensorVariable'

I got a bug after i delete /usr/local/cuda/lib64/libcudnn\*  and /usr/local/cuda/include/cudnn.h

Then add the same files of cudnn7-5v3 into the same path 
",meank,b'stale',2015-12-20T13:13:50Z,2017-06-22T23:11:15Z
1275,BUG: models with AutoEncoder layers not as first layer cause DisconnectedInputErrors on compilation,"Hi, I've got another bug report, sorry :(

The following sample code causes an error when compiling:

``` python
from keras.models import Sequential
encoder = Dense(input_dim=10, output_dim=2)
decoder = Dense(input_dim=2, output_dim=10)
model = Sequential()
model.add(Dense(input_dim=20, output_dim=10))
model.add(AutoEncoder(encoder=encoder, decoder=decoder, output_reconstruction=False))
model.compile(loss='mse', optimizer='sgd')
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/auto/homes/kc391/event_rnn/env/bin/keras/keras/models.py"", line 432, in compile
    train_loss)
  File ""/auto/homes/kc391/event_rnn/env/bin/keras/keras/optimizers.py"", line 79, in get_updates
    grads = self.get_gradients(loss, params)
  File ""/auto/homes/kc391/event_rnn/env/bin/keras/keras/optimizers.py"", line 47, in get_gradients
    grads = K.gradients(loss, params)
  File ""/auto/homes/kc391/event_rnn/env/bin/keras/keras/backend/theano_backend.py"", line 365, in gradients
    return T.grad(loss, variables)
  File ""/auto/homes/kc391/event_rnn/env/bin/Theano/theano/gradient.py"", line 545, in grad
    handle_disconnected(elem)
  File ""/auto/homes/kc391/event_rnn/env/bin/Theano/theano/gradient.py"", line 532, in handle_disconnected
    raise DisconnectedInputError(message)
theano.gradient.DisconnectedInputError: grad method was asked to compute the gradient with respect to a variable that is not part of the computational graph of the cost, or is used only by a non-differentiable operator: <TensorType(float32, matrix)>
Backtrace when the node is created:
  File ""/auto/homes/kc391/event_rnn/env/bin/keras/keras/backend/theano_backend.py"", line 34, in variable
    return theano.shared(value=value, name=name, strict=False)

```

The error is caused by:
- when AutoEncoder is inited, `self.params` is set by scraping the weights and biases from the encoder and decoder layers.
- when `model.add` is called with an AutoEncoder layer as the argument, this calls `AutoEncoder.set_previous()`, which calls `AutoEncoder.encoder.set_previous()`. 
- this reinitialises the weights and biases on the encoder layer, so that the pointers contained in `AutoEncoder.params` no longer points to the correct weights and biases on the encoder layer.

Possible solutions:
- update `AutoEncoder.params` when `AutoEncoder.set_previous()` is called
- add an ability to call `set_previous()` without overwriting existing weights (similar to #1266)

Thoughts?
Kris
",around1991,b'stale',2015-12-15T14:22:17Z,2017-06-22T23:11:07Z
1254,BUG: Layer.get_input returns the wrong input for shared nodes,"Hi all

I'm trying to build a network that takes in two sentences, turns them into fixed-length representations using a shared feed-forward NN, and then calculates their dot product. Unfortunately, I get an error when I try this.

My code for this is

``` python
from keras.models import Graph, Sequential
from keras.layers.embeddings import Embedding
from keras.layers.core import Dense, Flatten

inner_model = Sequential()

# This is the global word lookup table
embedding = Embedding(input_dim=400, output_dim=300, input_length=4)

inner_model.add(embedding)
inner_model.add(Flatten())
inner_model.add(Dense(output_dim=600))
inner_model.add(Dense(output_dim=300))

model = Graph()
model.add_input(name='left', input_shape=(4,), dtype='int')
model.add_input(name='right', input_shape=(4,), dtype='int')
model.add_shared_node(layer=inner_model,
                      name='arg_comp',
                      inputs=['left', 'right'],
                      merge_mode='dot', dot_axes=((0,), (0,)),
                      create_output=True)

model.compile(loss={'arg_comp': 'binary_crossentropy'}, optimizer='sgd')
```

However, I get the following exception:

```
Traceback (most recent call last):
  File ""src/models/test_arg_comp.py"", line 25, in <module>
    model.compile(loss={'arg_comp': 'binary_crossentropy'}, optimizer='sgd')
  File ""build/bdist.linux-x86_64/egg/keras/models.py"", line 635, in compile
  File ""build/bdist.linux-x86_64/egg/keras/backend/theano_backend.py"", line 361, in function
  File ""build/bdist.linux-x86_64/egg/keras/backend/theano_backend.py"", line 354, in __init__
  File ""/usr/local/lib/python2.7/dist-packages/theano/compile/function.py"", line 266, in function
    profile=profile)
  File ""/usr/local/lib/python2.7/dist-packages/theano/compile/pfunc.py"", line 511, in pfunc
    on_unused_input=on_unused_input)
  File ""/usr/local/lib/python2.7/dist-packages/theano/compile/function_module.py"", line 1465, in orig_function
    on_unused_input=on_unused_input).create(
  File ""/usr/local/lib/python2.7/dist-packages/theano/compile/function_module.py"", line 1124, in __init__
    self._check_unused_inputs(inputs, outputs, on_unused_input)
  File ""/usr/local/lib/python2.7/dist-packages/theano/compile/function_module.py"", line 1244, in _check_unused_inputs
    raise UnusedInputError(msg % (inputs.index(i), i.variable, err_msg))
theano.compile.function_module.UnusedInputError: theano.function was asked to create a function computing outputs given certain inputs, but the provided input variable at index 1 is not part of the computational graph needed to compute the outputs: right.
To make this error into a warning, you can pass the parameter on_unused_input='warn' to theano.function. To disable it completely, use on_unused_input='ignore'.
```

Is this a bug in the Siamese layer? Or am I doing something wrong?

Thanks
Kris
",around1991,b'stale',2015-12-12T18:17:06Z,2017-06-22T23:10:40Z
1233,Bug report in RNN,"Around line 68 in recurrent.py
If we are using float32, line 68 will be a float32 times int32, which will produce a float64. (is it because of theano version?)
changing line 68 to X *= K.expand_dims(mask).astype(X.dtype) will fix this problem. 

```
    if mask:
        # apply mask
        X *= K.expand_dims(mask)   # line 68
        masking = True
```
",jeffzhengye,None,2015-12-10T02:07:09Z,2015-12-11T18:42:07Z
1216,Bug fix - Siamese,,farizrahman4u,None,2015-12-08T17:44:07Z,2015-12-08T18:21:18Z
1212,Bug fix + Allow Layers to be called  with mask argument,"- Current implementation of **call** does not work for models in which the first layer is also a Sequential.
- Added option to provide mask.
",farizrahman4u,None,2015-12-08T10:16:21Z,2015-12-15T07:57:17Z
1211,Bug fix - Cos,,farizrahman4u,None,2015-12-08T09:53:17Z,2015-12-11T20:30:58Z
1106,Bug report in Convolution2D,"We can see in the Convolution2D:

```
self.params = [self.W, self.b]
if weights is not None:
    self.set_weights(weights)
```

and in the set_weights function, we have:

```
def set_weights(self, weights):
    for p, w in zip(self.params, weights):
        if p.eval().shape != w.shape:
            raise Exception(""Layer shape %s not compatible with weight shape %s."" % (p.eval().shape, w.shape))
        p.set_value(floatX(w))
```

Ok, now we have a weight matrix whose shape is (64,3,3,3), means that there are 64 filters in the layer, for each filter there are 3 channels and the size of each filter is 3*3
And we have bias stored in another file, its a (64,1) np array, according to set_weights showed above, kera will check if the weights matrix given matches the initial one, since the params contains two part: weight and bias, we should merge our weight matrix and bias together, for example:

```
merge_weight = (weight, bias)
```

I am very sure that the shape of weight here is (64,3,3,3), but when I was trying to pass the merge_matrix to Convolution2D, it turns out in the conlution2D, merge_weight[0].shape is (64,)
and thus the set_weights raise the exception: 

```
Layer shape (64, 3, 3, 3) not compatible with weight shape (64,)
```

If you trying to access weights[0][0], it's ok although the shape here is showed to be (64,)

Hope to fix this problem as soon as possible....
Thank you very much
",MoyanZitto,None,2015-11-29T07:28:11Z,2016-07-20T13:58:32Z
1081,Bug fix - Siamese layer,,farizrahman4u,None,2015-11-25T20:40:29Z,2015-11-25T21:28:59Z
1031,Bug in the evaluation of the validation data in the Graph model,"Hello all,

I'm experimenting with the `Graph` model and I think I'm not using the `validation_data` parameter properly.

This is the structure of my model where I'm trying to fit a time series using lags:

``` python
f_length = [2,3,4,5]
convs = []
model = Graph()
model.add_input(name='endog', input_shape=(len_ts_y,1))
for i in f_length:
    model.add_node(Convolution1D(nb_filter=nb_filter/2,
                                filter_length=i,
                                border_mode=""full"",
                                activation=""relu"",
                                subsample_length=1,
                                W_regularizer=l1(0.0001)
                                ),
                                name='conv_'+str(i), input='endog')
    model.add_node(MaxPooling1D(pool_length=pool_length),
               name=""Max_pool""+str(i), input='conv_'+str(i))

for i in f_length:
    model.add_node(Convolution1D(nb_filter=nb_filter/2,
                                filter_length=i,
                                border_mode=""full"",
                                activation=""relu"",
                                subsample_length=1,
                                W_regularizer=l1(0.0001)
                                ),
                                name='conv_2'+str(i), input=""Max_pool""+str(i))

    model.add_node(Flatten(), name=""flat_""+str(i), input='conv_2'+str(i))
    convs.append(""flat_""+str(i))

model.add_node(Dense(32, activation=""sigmoid""), name=""Dense_rec2"", inputs=convs)
model.add_node(Dense(32, activation=""sigmoid""), name=""Dense_rec3"", input='Dense_rec2')
model.add_node(Dense(1, activation=""softplus""), name='last_dense', input='Dense_rec3')
model.add_output(name='output', input='last_dense')
model.compile(optimizer='adam', loss={'output':'mse'})
```

The shape of my data is:

``` python
endog_train.shape, y_train.shape
((182725, 60), (182725, 120))
```

And I tried with both `validation_split` and `validation_data`.

``` python
model.fit({'endog': endog_train[:-10000,:,None], 'output': y_train[:-10000,-1]},
          # validation_split=0.3,
          validation_data={'endog':endog_train[-10000:,:,None], 'output': y_train[-10000:,-1]},
          batch_size=batch_size,
          nb_epoch=nb_epoch+4)
```

When the model is evaluated on the test set I get this error:

``` python
Train on 172725 samples, validate on 10000 samples
Epoch 1/8
172544/172725 [============================>.] - ETA: 0s - loss: 0.0155
---------------------------------------------------------------------------
IndexError                                Traceback (most recent call last)
<ipython-input-50-c0aba739c291> in <module>()
      3           validation_data={'endog':endog_train[-10000:,:,None], 'output': y_train[-10000:,-1]},
      4           batch_size=batch_size,
----> 5           nb_epoch=nb_epoch+4)

/media/thomas/data/libraries/keras/keras/models.pyc in fit(self, data, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight)
    680                             verbose=verbose, callbacks=callbacks,
    681                             val_f=val_f, val_ins=val_ins,
--> 682                             shuffle=shuffle, metrics=metrics)
    683         return history
    684 

/media/thomas/data/libraries/keras/keras/models.pyc in _fit(self, f, ins, out_labels, batch_size, nb_epoch, verbose, callbacks, val_f, val_ins, shuffle, metrics)
    226                     if do_validation:
    227                         # replace with self._evaluate
--> 228                         val_outs = self._test_loop(val_f, val_ins, batch_size=batch_size, verbose=0)
    229                         if type(val_outs) != list:
    230                             val_outs = [val_outs]

/media/thomas/data/libraries/keras/keras/models.pyc in _test_loop(self, f, ins, batch_size, verbose)
    280         for batch_index, (batch_start, batch_end) in enumerate(batches):
    281             batch_ids = index_array[batch_start:batch_end]
--> 282             ins_batch = slice_X(ins, batch_ids)
    283 
    284             batch_outs = f(*ins_batch)

/media/thomas/data/libraries/keras/keras/models.pyc in slice_X(X, start, stop)
     56             if hasattr(start, 'shape'):
     57                 start = start.tolist()
---> 58             return [x[start] for x in X]
     59         else:
     60             return [x[start:stop] for x in X]

IndexError: index 1 is out of bounds for axis 1 with size 1
```

Everything is working fine if I use `validation_split`.

Am I doing something wrong?

Thank you!
",tboquet,None,2015-11-18T18:41:09Z,2015-11-18T21:32:45Z
988,Bug with TimeDistributedDense?,"Hello.

It seems there is a bug (??) in TimeDistributedDense, or I may be doing something wrong.
Loading a model from file gives different predictions that the same model b4 saving to file.
I've been banging my head over this for the last couple of days.
Sorry for cross posting in keras-users.

Here is the code:

```
from __future__ import print_function
import numpy as np
from keras.models import Sequential
from keras.layers.core import Dense, TimeDistributedDense, TimeDistributedMerge
from keras.models import model_from_json


def create_model(n_features):
    model = Sequential()

    model.add(
        TimeDistributedDense(
            input_dim=n_features, output_dim=10, init=""one"",
        ))
    model.add(TimeDistributedMerge(mode='ave'))
    model.add(Dense(output_dim=1, init=""one""))
    return model


def save_model(model, fname):
    json_string = model.to_json()
    open(fname, 'w').write(json_string)
    model.save_weights(fname + '.h5', overwrite=True)


def load_model(fname):
    model = model_from_json(open(fname).read())
    model.load_weights(fname + '.h5')
    return model


if __name__ == '__main__':
    np.random.seed(1337)
    n_features = 4000

    model = create_model(n_features)
    model.compile(loss='mse',
                class_mode=""categorical"",
                optimizer='rmsprop')

    input_matrix = np.random.random((1000, 5, n_features))
    ys = np.random.random(1000)

    for i in xrange(5):
        loss = model.train_on_batch(input_matrix, ys)
        print(i, loss)

    probs = model.predict(input_matrix)
    print(probs[:10])
    save_model(model, 'tmp_model')
    model_loaded = load_model('tmp_model')
    print('='*20)
    probs_after = model_loaded.predict(input_matrix)
    print(probs_after[:10])

    print('total diffs:', sum(probs != probs_after))
```
",tzachar,None,2015-11-10T09:39:53Z,2015-11-11T09:46:40Z
865,Update optimizers.py,"Bug:
float() argument must be a string or a number, not 'TensorSharedVariable'
fixed!
",suixudongi8,None,2015-10-21T13:30:53Z,2015-10-23T12:59:58Z
819,Bug fixes:,"“TypeError: Cannot cast ufunc subtract output from dtype('float64') to
dtype('uint8') with casting rule 'same_kind'” in
keras/preprocessing/image.py, line 239, when using data augmentation.
",xingdi-eric-yuan,None,2015-10-12T07:12:42Z,2015-10-13T03:15:13Z
771,Bugfix/reshape,"There's an issue with loading a model from a YAML/JSON file when the network contains a layer which only has *args such as `Reshape`. 

``` py
TypeError: __init__() got an unexpected keyword argument 'dims'
```

This error is due to how the models are loaded in https://github.com/fchollet/keras/blob/master/keras/utils/generic_utils.py#L8.

Layers like `Reshape` that have no keyword arguments simply won't work. This could be fixed by having a `**kwargs` that could catch the provided argument in addition to list arguments (default to list args if `dims` is not empty). However, I'm not sure if there are some unforeseen backwards compatibility issues that I'm not seeing here.

Let me know if you see any issues that I'm missing.
",stephenbalaban,None,2015-10-03T00:04:28Z,2015-10-03T17:10:03Z
488,Bug in BatchNormalization,"I found the implementation of the `BatchNormalization` is wrong. If the `mode` is 0, ""featurewise normalization"" is used and two attributes which named  `running_mean` and `running_std` are used to store the mean and STD of the training data. But both of these attributes are implemented as a Theano expression in the `get_output` function. In the test stage, they refer to mean and STD of the input data, not the mean and STD of the training data as we expected. 

To fix it, the `running_mean` and `running_std` should be implemented as a Theano shared value as model's parameters, and should be updated when training. And I noted that the updating mechanism of them is different from the conventional parameters which are updated by their gradient. Therefore, we need to define individual update methods in some especial `Layer`, and the `update` list should be integrated into the conventional one in the training function of the `Model`.
",alzhusan,None,2015-08-06T08:25:44Z,2015-08-09T06:28:43Z
399,Bug in 'same' border,"Hi,
-            clip_row = (self.nb_row - 1) // 2
-            clip_col = (self.nb_col - 1) // 2
-            output = output[:, :, clip_row:-clip_row, clip_col:-clip_col]

In case of clip_row or  clip_col are 1 (1D input), there will be a crash.
Can you please fix it?

Thanks
",loyeamen,None,2015-07-16T13:33:52Z,2015-07-16T14:30:58Z
304,Bug with Merge when mode='concat'?,"I have the following network configuration:

``` python
nb_feature_maps = 32
embedding_size = 64

ngram_filters = [3, 5, 7, 9]
conv_filters = []

for n_gram in ngram_filters:
    sequential = Sequential()
    conv_filters.append(sequential)

    sequential.add(Embedding(max_features, embedding_size))
    sequential.add(Reshape(1, maxlen, embedding_size))
    sequential.add(Convolution2D(nb_feature_maps, 1, n_gram, embedding_size))
    sequential.add(Activation(""relu""))
    sequential.add(MaxPooling2D(poolsize=(maxlen - n_gram + 1, 1))) #collapses to nb_feature_maps * 1
    sequential.add(Flatten())
    sequential.add(Dense(nb_feature_maps, 32))

model = Sequential()
model.add(Merge(conv_filters, mode='concat'))
model.add(Dense(128, 1)) # len(ngram_filters) * 32
model.add(Activation(""sigmoid""))

model.compile(loss='binary_crossentropy', optimizer='adam', class_mode=""binary"")
```

According to your documentation and tests, the output dimensionality of the merge + concat layer should be 128, 4 \* 32, but this causes the following error when compiling:

  File ""/Users/simon.hughes/Library/Enthought/Canopy_64bit/User/lib/python2.7/site-packages/theano/compile/function_module.py"", line 595, in **call**
    outputs = self.fn()
ValueError: dimension mismatch in args to gemm (16,32)x(128,1)->(16,1)
Apply node that caused the error: GpuDot22(GpuJoin.0, <CudaNdarrayType(float32, matrix)>)
Inputs types: [CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix)]
Inputs shapes: [(16, 32), (128, 1)]
Inputs strides: [(32, 1), (1, 0)]
Inputs values: ['not shown', 'not shown']

Please help! I can get this working with mode='sum', but that doesn't seem to do very well on my problem. I think concat would do much better. 
",simonhughes22,None,2015-06-30T04:58:00Z,2015-06-30T05:05:37Z
