id,Title,Body,User,Label,Created At,Updated At
9336,Bert checkpoint conversion tf1.x to tfhub2.x,"## 1. The entire URL of the file you are using

https://github.com/tensorflow/models/blob/master/official/nlp/bert/tf2_encoder_checkpoint_converter.py
https://github.com/tensorflow/models/blob/master/official/nlp/bert/export_tfhub.py

## 2. Describe the bug

Starting from a Tf1.X bert checkpoint (from https://github.com/google-research/bert) I tried to convert it to a Tf2.x checkpoint using tf2_encoder_checkpoint_converter.py. After this operation using export_tfhub.py I wanted to convert it again into a tfhub2.x format. 
I get errors from .assert_existing_objects_matched() in checkpoint restoration before the tfhub export. 
WARNING:tensorflow:Unresolved object in checkpoint: (root).bert_model.ckpt 
(same for each layer)
## 3. Steps to reproduce

Download a tf1.x checkpoint from from https://github.com/google-research/bert, run tf2_encoder_checkpoint_converter.py and then export_tfhub.py with appropriate file path at each step. 

## 4. Expected behavior

At the end of this (double) conversion from checkpoint tf1.x -> tfhub2.x the saved model should be consistent with the ones downloadable from https://github.com/tensorflow/models/tree/master/official/nlp/bert .

## 5. Additional context

I tried with both master (nightly) and v2.3.0 (tf2.3) branches obtaining same results.

## 6. System information

- OS Platform and Distribution: Ubuntu 18.04
- TensorFlow installed from source
- TensorFlow version 2.3.0 and Nightly (tried both)
- Python version 3.6 and 3.8
- CUDA/cuDNN version 10.1
- GPU model and memory V100 ",pretidav,b'models:official type:bug',2020-10-02T08:22:40Z,2020-10-06T17:28:52Z,,,,,,,
9325,research model bug,"# Prerequisites

Please answer the following questions for yourself before submitting an issue.

- [ ] I am using the latest TensorFlow Model Garden release and TensorFlow 2.
- [ ] I am reporting the issue to the correct repository. (Model Garden official or research directory)
- [ ] I checked to make sure that this issue has not already been filed.

## 1. The entire URL of the file you are using

https://github.com/tensorflow/models/tree/master/research/...

## 2. Describe the bug

A clear and concise description of what the bug is.

## 3. Steps to reproduce

Steps to reproduce the behavior.

## 4. Expected behavior

A clear and concise description of what you expected to happen.

## 5. Additional context

Include any logs that would be helpful to diagnose the problem.

## 6. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device name if the issue happens on a mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below):
- Python version:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

<!-- 
Collect system information using our environment capture script.
https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can also obtain the TensorFlow version with:

1. TensorFlow 1.0
`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

2. TensorFlow 2.0
`python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`
-->
",rthadur,b'models:research type:bug',2020-09-29T05:24:28Z,2020-09-29T05:24:50Z,,,,,,,
9323,model bug,"# Prerequisites

Please answer the following questions for yourself before submitting an issue.

- [ ] I am using the latest TensorFlow Model Garden release and TensorFlow 2.
- [ ] I am reporting the issue to the correct repository. (Model Garden official or research directory)
- [ ] I checked to make sure that this issue has not been filed already.

## 1. The entire URL of the file you are using

https://github.com/tensorflow/models/tree/master/official/...

## 2. Describe the bug

A clear and concise description of what the bug is.

## 3. Steps to reproduce

Steps to reproduce the behavior.

## 4. Expected behavior

A clear and concise description of what you expected to happen.

## 5. Additional context

Include any logs that would be helpful to diagnose the problem.

## 6. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device name if the issue happens on a mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below):
- Python version:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

<!-- 
Collect system information using our environment capture script.
https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can also obtain the TensorFlow version with:

1. TensorFlow 1.0
`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

2. TensorFlow 2.0
`python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`
-->
",rthadur,b'models:official type:bug',2020-09-29T05:10:49Z,2020-09-29T05:24:09Z,,,,,,,
9319,ValueError: Cannot set tensor: Dimension mismatch. Got 3 but expected 4 for input 0.,"I trained the `ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8` model with my custom data. If I load the SavedModel (the .pb file) and inference with it, it works as expected. - the output is correct

Now I converted the model to a TFLite model. Using this model with the same image to inference I get an error saying: 
""ValueError: Cannot set tensor: Dimension mismatch. Got 3 but expected 4 for input 0"" 

The input details of the model are: 
`[{'name': 'serving_default_input:0', 'index': 0, 'shape': array([  1, 640, 640,   3]), 'shape_signature': array([  1, 640, 640,   3]), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]`

If I am not wrong the expected shape is `[  1, 640, 640,   3]` -> so 3 dimensions. But the error says it is expecting 4?

I am using the latest tf-nightly from source. I tried different tensorflow and tflite versions, it is the same error with every version.
Currently I am at '2.4.0-dev20200926'

EDIT:
I am using this script to create the saved model: 
`python export_tflite_graph_tf2.py --trained_checkpoint_dir ./training --output_directory ./inference_graph_tflite --pipeline_config_path ./training/ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8.config`

Then I use the standard code to convert it to a tflite model: 
```
converter = tf.lite.TFLiteConverter.from_saved_model(path + 'saved_model')
converter.optimizations = [tf.lite.Optimize.DEFAULT]
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8, tf.lite.OpsSet.TFLITE_BUILTINS]
tflite_model = converter.convert()

with open(path + 'final_detector.tflite', 'wb') as f:
  f.write(tflite_model)
```

As for testing the tflite model I am using this code:
```
interpreter = tf.lite.Interpreter(model_path=""final_detector.tflite"")

input_details = interpreter.get_input_details()
output_details = interpreter.get_output_details()

interpreter.allocate_tensors()
input_data = np.expand_dims(new_img, axis=0).astype(np.float32)
interpreter.set_tensor(input_details[0]['index'], input_data)

interpreter.invoke()
```
Of course I can expand the dimensions and feed it into the model, but it does not generate an output (the output array is empty).

Is there a link or code snippet on how to generate the SavedModel from the checkpoints for converting it to the TFLite model?",DeRealMorgan,b'models:research type:bug',2020-09-28T09:17:41Z,2020-10-02T08:35:58Z,,,,,,,
9297,"Training SSD-MobilenetV2 fails with Message type ""object_detection.protos.TrainConfig"" has no field named ""fine_tune_checkpoint_version""","# Prerequisites

Please answer the following questions for yourself before submitting an issue.

- [ ] I am using the latest TensorFlow Model Garden release and TensorFlow 2.
I am using the latest release and TensorFlow 2
- [ ] I am reporting the issue to the correct repository. (Model Garden official or research directory)
research directory
- [ ] I checked to make sure that this issue has not already been filed.
yes, by searching for key words

## 1. The entire URL of the file you are using

https://github.com/tensorflow/models/tree/master/research/...

## 2. Describe the bug

So i am trying to train a new model based on the SSD MobileNet V2 FPNLite 320x320 checkpoints with the help of the GCP AI Platform. I am using TPUs for it as mentioned under this page: [link](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_training_and_evaluation.md#training-with-tpu)

I am getting the following error:
`The replica master 0 exited with a non-zero status of 1. 
Traceback (most recent call last):
  [...]
  File ""/usr/local/lib/python3.7/dist-packages/absl/app.py"", line 300, in run
    _run_main(main, args)
  File ""/usr/local/lib/python3.7/dist-packages/absl/app.py"", line 251, in _run_main
    sys.exit(main(argv))
  File ""/root/.local/lib/python3.7/site-packages/object_detection/model_main_tf2.py"", line 110, in main
    record_summaries=FLAGS.record_summaries)
  File ""/root/.local/lib/python3.7/site-packages/object_detection/model_lib_v2.py"", line 470, in train_loop
    pipeline_config_path, config_override=config_override)
  File ""/root/.local/lib/python3.7/site-packages/object_detection/utils/config_util.py"", line 139, in get_configs_from_pipeline_file
    text_format.Merge(proto_str, pipeline_config)
  File ""/usr/local/lib/python3.7/dist-packages/google/protobuf/text_format.py"", line 734, in Merge
    allow_unknown_field=allow_unknown_field)
  File ""/usr/local/lib/python3.7/dist-packages/google/protobuf/text_format.py"", line 802, in MergeLines
    return parser.MergeLines(lines, message)
  File ""/usr/local/lib/python3.7/dist-packages/google/protobuf/text_format.py"", line 827, in MergeLines
    self._ParseOrMerge(lines, message)
  File ""/usr/local/lib/python3.7/dist-packages/google/protobuf/text_format.py"", line 849, in _ParseOrMerge
    self._MergeField(tokenizer, message)
  File ""/usr/local/lib/python3.7/dist-packages/google/protobuf/text_format.py"", line 974, in _MergeField
    merger(tokenizer, message, field)
  File ""/usr/local/lib/python3.7/dist-packages/google/protobuf/text_format.py"", line 1048, in _MergeMessageField
    self._MergeField(tokenizer, sub_message)
  File ""/usr/local/lib/python3.7/dist-packages/google/protobuf/text_format.py"", line 941, in _MergeField
    (message_descriptor.full_name, name))
google.protobuf.text_format.ParseError: 172:3 : Message type ""object_detection.protos.TrainConfig"" has no field named ""fine_tune_checkpoint_version"".`

## 3. Steps to reproduce

Follow the mentioned link and try it with the SSD MobileNet V2 FPNLite 320x320 checkpoints.
My pipeline-config looks like this:
`model {
  ssd {
    num_classes: 4
    image_resizer {
      fixed_shape_resizer {
        height: 320
        width: 320
      }
    }
    feature_extractor {
      type: ""ssd_mobilenet_v2_fpn_keras""
      depth_multiplier: 1.0
      min_depth: 16
      conv_hyperparams {
        regularizer {
          l2_regularizer {
            weight: 3.9999998989515007e-05
          }
        }
        initializer {
          random_normal_initializer {
            mean: 0.0
            stddev: 0.009999999776482582
          }
        }
        activation: RELU_6
        batch_norm {
          decay: 0.996999979019165
          scale: true
          epsilon: 0.0010000000474974513
        }
      }
      use_depthwise: true
      override_base_feature_extractor_hyperparams: true
      fpn {
        min_level: 3
        max_level: 7
        additional_layer_depth: 128
      }
    }
    box_coder {
      faster_rcnn_box_coder {
        y_scale: 10.0
        x_scale: 10.0
        height_scale: 5.0
        width_scale: 5.0
      }
    }
    matcher {
      argmax_matcher {
        matched_threshold: 0.5
        unmatched_threshold: 0.5
        ignore_thresholds: false
        negatives_lower_than_unmatched: true
        force_match_for_each_row: true
        use_matmul_gather: true
      }
    }
    similarity_calculator {
      iou_similarity {
      }
    }
    box_predictor {
      weight_shared_convolutional_box_predictor {
        conv_hyperparams {
          regularizer {
            l2_regularizer {
              weight: 3.9999998989515007e-05
            }
          }
          initializer {
            random_normal_initializer {
              mean: 0.0
              stddev: 0.009999999776482582
            }
          }
          activation: RELU_6
          batch_norm {
            decay: 0.996999979019165
            scale: true
            epsilon: 0.0010000000474974513
          }
        }
        depth: 128
        num_layers_before_predictor: 4
        kernel_size: 3
        class_prediction_bias_init: -4.599999904632568
        share_prediction_tower: true
        use_depthwise: true
      }
    }
    anchor_generator {
      multiscale_anchor_generator {
        min_level: 3
        max_level: 7
        anchor_scale: 4.0
        aspect_ratios: 1.0
        aspect_ratios: 2.0
        aspect_ratios: 0.5
        scales_per_octave: 2
      }
    }
    post_processing {
      batch_non_max_suppression {
        score_threshold: 9.99999993922529e-09
        iou_threshold: 0.6000000238418579
        max_detections_per_class: 100
        max_total_detections: 100
        use_static_shapes: false
      }
      score_converter: SIGMOID
    }
    normalize_loss_by_num_matches: true
    loss {
      localization_loss {
        weighted_smooth_l1 {
        }
      }
      classification_loss {
        weighted_sigmoid_focal {
          gamma: 2.0
          alpha: 0.25
        }
      }
      classification_weight: 1.0
      localization_weight: 1.0
    }
    encode_background_as_zeros: true
    normalize_loc_loss_by_codesize: true
    inplace_batchnorm_update: true
    freeze_batchnorm: false
  }
}
train_config {
  batch_size: 128
  data_augmentation_options {
    random_horizontal_flip {
    }
  }
  data_augmentation_options {
    random_crop_image {
      min_object_covered: 0.0
      min_aspect_ratio: 0.75
      max_aspect_ratio: 3.0
      min_area: 0.75
      max_area: 1.0
      overlap_thresh: 0.0
    }
  }
  sync_replicas: true
  optimizer {
    momentum_optimizer {
      learning_rate {
        cosine_decay_learning_rate {
          learning_rate_base: 0.07999999821186066
          total_steps: 50000
          warmup_learning_rate: 0.026666000485420227
          warmup_steps: 1000
        }
      }
      momentum_optimizer_value: 0.8999999761581421
    }
    use_moving_average: false
  }
  fine_tune_checkpoint: ""gs://tom-master-od-bucket/models/cocossdoid_output/checkpoint/ckpt-0""
  num_steps: 50000
  startup_delay_steps: 0.0
  replicas_to_aggregate: 8
  max_number_of_boxes: 100
  unpad_groundtruth_tensors: false
  fine_tune_checkpoint_type: ""classification""
  fine_tune_checkpoint_version: V2
}
train_input_reader {
  label_map_path: ""gs://tom-master-od-bucket/data/label_bbox.pbtxt""
  tf_record_input_reader {
    input_path: ""gs://tom-master-od-bucket/data/train.tfrecord""
  }
}
eval_config {
  metrics_set: ""coco_detection_metrics""
  use_moving_averages: false
}
eval_input_reader {
  label_map_path: ""gs://tom-master-od-bucket/data/label_bbox.pbtxt""
  shuffle: false
  num_epochs: 1
  tf_record_input_reader {
    input_path: ""gs://tom-master-od-bucket/data/validation.tfrecord""
  }
}
`
I call the gcloud command like this:
`gcloud ai-platform jobs submit training `whoami`_object_detection_`date +%m_%d_%Y_%H_%M_%S` \
    --job-dir=gs://${MODEL_DIR} \
    --package-path=./object_detection \
    --module-name=object_detection.model_main_tf2 \
    --runtime-version=2.2 \
    --python-version=3.7 \
    --scale-tier=BASIC_TPU \
    --region=us-central1 \
    -- \
    --distribution_strategy=tpu \
    --model_dir=gs://${MODEL_DIR} \
    --pipeline_config_path=gs://${PIPELINE_CONFIG_PATH}`


## 4. Expected behavior

The training starts.


Does anyone know what the problem is?

Thanks and best regards,
Tom",acidassassin,b'models:research type:bug',2020-09-24T12:11:09Z,2020-09-24T18:24:50Z,,,,,,,
9286,How the object detection API can be trained on multiple gpu's?,"

## The entire URL of the file you are using

https://github.com/tensorflow/models/tree/r1.12.0/research/object_detection


I'm using model_main.py to train my model on windows. It only works for a while and soon it will report errors about out of memory. I tried to add it in the code, but it doesn't seem to work.Because of the limitation of multiple GPUs, I can only set batchsize=4 at least. I could run the program multiple times to train it, but that doesn't seem like a good way to do it!
I tried to use model_main_tf2.py and had similar problems.

`  # config = tf.estimator.RunConfig(model_dir=FLAGS.model_dir)`
`  session_config = tf.ConfigProto(allow_soft_placement=True, log_device_placement=False)`
`  session_config.gpu_options.allow_growth = True
  session_config.gpu_options.per_process_gpu_memory_fraction = .3
  config=tf.estimator.RunConfig(model_dir=FLAGS.model_dir, session_config=session_config)`


## System information

- OS Platform and Distribution:  windows 10
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below):1.15.0
- Python version: 3.6 64bit
- CUDA/cuDNN version: CUDA10
- GPU model and memory: 1080TI *4 11G",x12901,b'models:research type:bug',2020-09-23T08:53:29Z,2020-09-24T14:50:07Z,,,,,,,
9265,"reader.get_tensor() crashes with no Exception, how to fix it?","## Describe the bug

Im using an example  code of bert4keras with Tensorflow-gpu2.0.0 and CUDA10.0.
![image](https://user-images.githubusercontent.com/22270406/93542793-7dd3ed80-f98c-11ea-87e7-d3aac67baba1.png)
 When I use build_transform_model() the interpreter crashes with following error:
```
C:\Python35\python.exe D:/bert/test.py
2020-09-18 08:58:32.350829: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_100.dll
Using TensorFlow backend.
Tokenizer initial success!
Prepare to load model...
2020-09-18 08:58:35.506116: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library nvcuda.dll
2020-09-18 08:58:35.595480: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: GeForce GTX 1060 with Max-Q Design major: 6 minor: 1 memoryClockRate(GHz): 1.3415
pciBusID: 0000:01:00.0
2020-09-18 08:58:35.595743: I tensorflow/stream_executor/platform/default/dlopen_checker_stub.cc:25] GPU libraries are statically linked, skip dlopen check.
2020-09-18 08:58:35.596581: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
2020-09-18 08:58:35.596924: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2
2020-09-18 08:58:35.599880: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: GeForce GTX 1060 with Max-Q Design major: 6 minor: 1 memoryClockRate(GHz): 1.3415
pciBusID: 0000:01:00.0
2020-09-18 08:58:35.600136: I tensorflow/stream_executor/platform/default/dlopen_checker_stub.cc:25] GPU libraries are statically linked, skip dlopen check.
2020-09-18 08:58:35.601015: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
2020-09-18 08:58:36.214330: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-09-18 08:58:36.214497: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 
2020-09-18 08:58:36.214595: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N 
2020-09-18 08:58:36.215286: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 4708 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1060 with Max-Q Design, pci bus id: 0000:01:00.0, compute capability: 6.1)

Process finished with exit code -1073741819 (0xC0000005)
```
This error also created a .dmp file with over 700MB in windows crashdumps.
I traced this error and found it's tf.train.load_checkpoint() problem. I'm using the following code to analyze:
```
import tensorflow as tf
config_path = '../../chinese_L-12_H-768_A-12/bert_config.json'
checkpoint_path = '../../chinese_L-12_H-768_A-12/bert_model.ckpt'
dict_path = '../../chinese_L-12_H-768_A-12/vocab.txt'

reader=tf.train.load_checkpoint(checkpoint_path)
print(reader)
arr=reader.get_tensor(""bert/embeddings/word_embeddings"")
print(arr)
```
Unfortunately it crashes like this:
```
2020-09-18 09:10:19.136735: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_100.dll
Using TensorFlow backend.
<tensorflow.python.pywrap_tensorflow_internal.CheckpointReader; proxy of <Swig Object of type 'tensorflow::checkpoint::CheckpointReader *' at 0x000001653EEDA570> >
Process finished with exit code -1073741819 (0xC0000005)
```
Just want to know how can I successfully load the checkpoint file. Thanks in advance.
***
## System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- TensorFlow version (use command below):  Tensorflow-gpu-2.0.0
- Python version: Py35
- CUDA/cuDNN version: Cuda 10.0 cudnnv7.6.5.32
- GPU model and memory: GeForce GTX 1060 Max-Q Design 6GB",insomnia1996,b'models:official type:bug',2020-09-18T01:18:30Z,2020-09-21T03:02:27Z,,,,,,,
9263,How do I save and re-load a model after running the Colab Tutorial?,"# Prerequisites

Please answer the following questions for yourself before submitting an issue.

- [x] I am using the latest TensorFlow Model Garden release and TensorFlow 2.
- [x] I am reporting the issue to the correct repository. (Model Garden official or research directory)
- [x] I checked to make sure that this issue has not been filed already.

## 1. The entire URL of the file you are using

https://github.com/tensorflow/models/blob/master/research/object_detection/colab_tutorials/eager_few_shot_od_training_tf2_colab.ipynb

## 2. Describe the bug

I just want to save the model I trained and re-load it elsewhere. I can't use `model.save()` or anything. 

**I am not using anything custom. I just want to save the model resulting from running the Colab as it is.**",nicolas-gervais,b'models:research stalled stat:awaiting response type:bug',2020-09-17T12:43:38Z,2020-10-02T20:45:23Z,,,,,,,
9255,InvalidArgumentError: Index out of range using input dim 1; input has only 1 dims [Op:StridedSlice] name: strided_slice/,"# Prerequisites

Please answer the following questions for yourself before submitting an issue.

- [X] I am using the latest TensorFlow Model Garden release and TensorFlow 2.
- [X] I am reporting the issue to the correct repository. (Model Garden official or research directory)
- [X] I checked to make sure that this issue has not already been filed.

## 1. The entire URL of the file you are using
* The notebook: [Object Detection Tutorial Notebook](https://github.com/tensorflow/models/blob/master/research/object_detection/colab_tutorials/object_detection_tutorial.ipynb)

* The model used: http://download.tensorflow.org/models/object_detection/tf2/20200711/mask_rcnn_inception_resnet_v2_1024x1024_coco17_gpu-8.tar.gz

* The colab notebook that uses the same notebook and the model: [Colab Object Detection Tutorial Copy](https://colab.research.google.com/drive/1OUkIWVpaEnDaZL81Kmm2Jp5xd4fu45pK?usp=sharing)

## 2. Describe the bug
**Error Name** : InvalidArgumentError

**Error Description** : Index out of range using input dim 1; input has only 1 dims [Op:StridedSlice] name: strided_slice/

The code in the [Object Detection Tutorial Notebook](https://github.com/tensorflow/models/blob/master/research/object_detection/colab_tutorials/object_detection_tutorial.ipynb) successfully infers using object detection models but fails to infer using using Mask RCNN Inception Model and causes the above error. 

## 3. Steps to reproduce
Run the following Colab Notebook. It is same as the Object Detection Tutorial but is instead using Mask RCNN Inception Resnet v2 1024x1204 model. 

[Colab Object Detection Tutorial Copy](https://colab.research.google.com/drive/1OUkIWVpaEnDaZL81Kmm2Jp5xd4fu45pK?usp=sharing)

## 4. Expected behavior
Segmentation on the test images same the as the object detection on the test images in the notebook 

## 5. Additional context

The notebook crashes on the default segmentation model used in the [Object Detection Tutorial Notebook](https://github.com/tensorflow/models/blob/master/research/object_detection/colab_tutorials/object_detection_tutorial.ipynb) as well also models that have been further trained to segment or detect other objects

## 6. System information

All the work done was on Colab with GPU enabled

<!-- 
Collect system information using our environment capture script.
https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can also obtain the TensorFlow version with:

1. TensorFlow 1.0
`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

2. TensorFlow 2.0
`python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`
-->
",AliButtar,b'models:research type:bug',2020-09-16T13:48:39Z,2020-09-25T12:18:18Z,,,,,,,
9250,TF2 to TFLite: Restoring SavedModel freezes,"# Prerequisites

Please answer the following questions for yourself before submitting an issue.

- [Y] I am using the latest TensorFlow Model Garden release and TensorFlow 2.
- [Y] I am reporting the issue to the correct repository. (Model Garden official or research directory)
- [Y] I checked to make sure that this issue has not already been filed.

## 1. The entire URL of the file you are using

https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/running_on_mobile_tf2.md

## 2. Describe the bug

I'm trying to convert a TF2 model to TFLite.
I have downloaded ssd_resnet101_v1_fpn_640x640_coco17_tpu-8 from this link http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_resnet101_v1_fpn_640x640_coco17_tpu-8.tar.gz.

Using export_tflite_graph_tf2.py I have generated an intermediate SavedModel.
PB model is 9Mb ,  variables.data file is 125 Mb.
Too big to attach. (wetransfer link https://we.tl/t-vPUSTraLSV)


Next I'm trying to convert to TFLite using these two ways:

1. python script: 

converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)  
tflite_model = converter.convert()  -> code freezes here
with open('model.tflite', 'wb') as f:
        f.write(tflite_model)

2. tflite_convert command

In both cases the system freeze and the last log message is:

tensorflow/cc/saved_model/loader.cc:190] Restoring SavedModel bundle.

In case 1 code freezes here: tflite_model = converter.convert()

 Full logs:

2020-09-15 12:18:39.665457: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudart64_110.dll
2020-09-15 12:18:41.653614: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2020-09-15 12:18:41.654592: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library nvcuda.dll
2020-09-15 12:18:41.680174: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties:
pciBusID: 0000:01:00.0 name: Quadro RTX 4000 computeCapability: 7.5
coreClock: 1.545GHz coreCount: 36 deviceMemorySize: 8.00GiB deviceMemoryBandwidth: 387.49GiB/s
2020-09-15 12:18:41.680288: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudart64_110.dll
2020-09-15 12:18:41.685530: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cublas64_11.dll
2020-09-15 12:18:41.688669: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cufft64_10.dll
2020-09-15 12:18:41.690009: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library curand64_10.dll
2020-09-15 12:18:41.696408: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusolver64_10.dll
2020-09-15 12:18:41.698790: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusparse64_11.dll
2020-09-15 12:18:41.699572: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudnn64_8.dll
2020-09-15 12:18:41.699717: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2020-09-15 12:18:41.700121: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-09-15 12:18:41.769452: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties:
pciBusID: 0000:01:00.0 name: Quadro RTX 4000 computeCapability: 7.5
coreClock: 1.545GHz coreCount: 36 deviceMemorySize: 8.00GiB deviceMemoryBandwidth: 387.49GiB/s
2020-09-15 12:18:41.769588: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudart64_110.dll
2020-09-15 12:18:41.770786: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cublas64_11.dll
2020-09-15 12:18:41.777628: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cufft64_10.dll
2020-09-15 12:18:41.778754: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library curand64_10.dll
2020-09-15 12:18:41.779861: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusolver64_10.dll
2020-09-15 12:18:41.780981: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusparse64_11.dll
2020-09-15 12:18:41.782036: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudnn64_8.dll
2020-09-15 12:18:41.782948: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2020-09-15 12:18:42.224067: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-09-15 12:18:42.224194: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0
2020-09-15 12:18:42.225111: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N
2020-09-15 12:18:42.225779: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6625 MB memory) -> physical GPU (device: 0, name: Quadro RTX 4000, pci bus id: 0000:01:00.0, compute capability: 7.5)
2020-09-15 12:18:42.256543: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
loaded
2020-09-15 12:18:51.848846: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:315] Ignored output_format.
2020-09-15 12:18:51.849002: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:318] Ignored drop_control_dependency.
2020-09-15 12:18:51.850905: I tensorflow/cc/saved_model/reader.cc:32] Reading SavedModel from: ./saved_model
2020-09-15 12:18:51.919436: I tensorflow/cc/saved_model/reader.cc:55] Reading meta graph with tags { serve }
2020-09-15 12:18:51.919598: I tensorflow/cc/saved_model/reader.cc:93] Reading SavedModel debug info (if present) from: ./saved_model
2020-09-15 12:18:51.920771: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-09-15 12:18:51.927520: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]
2020-09-15 12:18:51.927824: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2020-09-15 12:18:52.156920: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:196] None of the MLIR optimization passes are enabled (registered 0 passes)
2020-09-15 12:18:52.188981: I tensorflow/cc/saved_model/loader.cc:190] Restoring SavedModel bundle.

 

## 6. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- TensorFlow installed from (source or binary): tf-nightly installed via pip
- TensorFlow version (use command below): 2.4.0-dev20200912
- Python version: python 3.7.3
- CUDA/cuDNN version: CUDA 11.0,2 - cuDNN 11.0 
- GPU model and memory: Quadro RTX 4000

",MediavoiceSrL,b'models:research stat:awaiting response type:bug',2020-09-15T10:38:44Z,2020-09-24T11:10:46Z,,,,,,,
9242,UnicodeDecodeError: 'utf-8' codec can't decode byte 0xbe in position 135: invalid start byte,"I want to train with mask_rcnn. In order to train on multiple GPUs for win10, I added some code to the main.py line 89
`strategy = tf.distribute.MirroredStrategy(devices=[""/gpu:0"", ""/gpu:1""],
                                            cross_device_ops=tf.distribute.HierarchicalCopyAllReduce())
`
Then the program reported an error, and I tried the solution, but couldn't find anything in the Official directory to change
[https://github.com/tensorflow/models/issues/4082#issuecomment-404763408](url)
[https://github.com/tensorflow/models/issues/5857#issuecomment-447764871](url)


tf-models-nightly                  2.3.0.dev20200913
tf-models-official                 2.3.0
tf-nightly                         2.4.0.dev20200910
tensorflow                         2.3.0

> python official/vision/detection/main.py --strategy_type=mirrored --num_gpus=4 --model_dir=model_dir --mode=train --model=mask_rcnn --config_file=""my_maskrcnn.yaml""
2020-09-14 20:52:45.831075: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found
2020-09-14 20:52:45.837565: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
I0914 20:52:49.855386 22692 main.py:211] Model Parameters: {'anchor': {'anchor_size': 8,
            'aspect_ratios': [1.0, 2.0, 0.5],
            'num_scales': 1},
 'architecture': {'backbone': 'resnet',
                  'include_mask': True,
                  'mask_target_size': 28,
                  'max_level': 6,
                  'min_level': 2,
                  'multilevel_features': 'fpn',
                  'num_classes': 91,
                  'parser': 'maskrcnn_parser',
                  'use_bfloat16': False},
 'enable_summary': False,
 'eval': {'batch_size': 8,
          'eval_dataset_type': 'tfrecord',
          'eval_file_pattern': 'D:\\cwge\\models\\train\\obj-TFRecords-export',
          'eval_samples': 5000,
          'eval_timeout': None,
          'input_sharding': True,
          'min_eval_interval': 180,
          'num_images_to_visualize': 0,
          'num_steps_per_eval': 1000,
          'type': 'box_and_mask',
          'use_json_file': True,
          'val_json_file': 'D:\\cwge\\models\\train'},
 'fpn': {'fpn_feat_dims': 256,
         'use_batch_norm': True,
         'use_separable_conv': False},
 'frcnn_box_loss': {'huber_loss_delta': 1.0},
 'frcnn_head': {'fc_dims': 1024,
                'num_convs': 0,
                'num_fcs': 2,
                'num_filters': 256,
                'use_batch_norm': False,
                'use_separable_conv': False},
 'isolate_session_state': False,
 'mask_sampling': {'num_mask_samples_per_image': 128},
 'maskrcnn_parser': {'aug_rand_hflip': True,
                     'aug_scale_max': 1.0,
                     'aug_scale_min': 1.0,
                     'mask_crop_size': 112,
                     'max_num_instances': 100,
                     'num_channels': 3,
                     'output_size': [1024, 1024],
                     'rpn_batch_size_per_im': 256,
                     'rpn_fg_fraction': 0.5,
                     'rpn_match_threshold': 0.7,
                     'rpn_unmatched_threshold': 0.3,
                     'skip_crowd_during_training': True},
 'model_dir': 'model_dir',
 'mrcnn_head': {'num_convs': 4,
                'num_filters': 256,
                'use_batch_norm': False,
                'use_separable_conv': False},
 'norm_activation': {'activation': 'relu',
                     'batch_norm_epsilon': 0.0001,
                     'batch_norm_momentum': 0.997,
                     'batch_norm_trainable': True,
                     'use_sync_bn': False},
 'postprocess': {'max_total_size': 100,
                 'nms_iou_threshold': 0.5,
                 'pre_nms_num_boxes': 1000,
                 'score_threshold': 0.05,
                 'use_batched_nms': False},
 'predict': {'batch_size': 8},
 'resnet': {'resnet_depth': 50},
 'roi_proposal': {'rpn_min_size_threshold': 0.0,
                  'rpn_nms_threshold': 0.7,
                  'rpn_post_nms_top_k': 1000,
                  'rpn_pre_nms_top_k': 2000,
                  'rpn_score_threshold': 0.0,
                  'test_rpn_min_size_threshold': 0.0,
                  'test_rpn_nms_threshold': 0.7,
                  'test_rpn_post_nms_top_k': 1000,
                  'test_rpn_pre_nms_top_k': 1000,
                  'test_rpn_score_threshold': 0.0,
                  'use_batched_nms': False},
 'roi_sampling': {'bg_iou_thresh_hi': 0.5,
                  'bg_iou_thresh_lo': 0.0,
                  'fg_fraction': 0.25,
                  'fg_iou_thresh': 0.5,
                  'mix_gt_boxes': True,
                  'num_samples_per_image': 512},
 'rpn_box_loss': {'huber_loss_delta': 0.1111111111111111},
 'rpn_head': {'num_convs': 2,
              'num_filters': 256,
              'use_batch_norm': False,
              'use_separable_conv': False},
 'rpn_score_loss': {'rpn_batch_size_per_im': 256},
 'spinenet': {'model_id': '49'},
 'strategy_config': {'all_reduce_alg': None,
                     'distribution_strategy': 'mirrored',
                     'num_gpus': 4,
                     'num_packs': 1,
                     'task_index': -1,
                     'tpu': None,
                     'worker_hosts': None},
 'strategy_type': 'mirrored',
 'train': {'batch_size': 64,
           'checkpoint': {'path': '', 'prefix': ''},
           'frozen_variable_prefix': '',
           'gradient_clip_norm': 0.0,
           'input_partition_dims': None,
           'input_sharding': False,
           'iterations_per_loop': 100,
           'l2_weight_decay': 0.0001,
           'learning_rate': {'init_learning_rate': 0.08,
                             'learning_rate_levels': [0.008, 0.0008],
                             'learning_rate_steps': [15000, 20000],
                             'type': 'step',
                             'warmup_learning_rate': 0.0067,
                             'warmup_steps': 500},
           'num_cores_per_replica': None,
           'optimizer': {'momentum': 0.9, 'nesterov': True, 'type': 'momentum'},
           'regularization_variable_regex': '.*(kernel|weight):0$',
           'total_steps': 22500,
           'train_dataset_type': 'tfrecord',
           'train_file_pattern': 'D:\\cwge\\models\\train\\obj-TFRecords-export',
           'transpose_input': False},
 'type': 'mask_rcnn',
 'use_tpu': False}
I0914 20:52:49.948356 22692 losses.py:152] RpnBoxLoss huber_loss_delta 0.1111111111111111
I0914 20:52:49.956354 22692 losses.py:244] FastrcnnBoxLoss huber_loss_delta 1.0
2020-09-14 20:52:49.959090: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2020-09-14 20:52:49.964820: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library nvcuda.dll
2020-09-14 20:52:50.044086: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties:
pciBusID: 0000:02:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 11.00GiB deviceMemoryBandwidth: 451.17GiB/s
2020-09-14 20:52:50.058631: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 1 with properties:
pciBusID: 0000:03:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 11.00GiB deviceMemoryBandwidth: 451.17GiB/s
2020-09-14 20:52:50.071219: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 2 with properties:
pciBusID: 0000:82:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 11.00GiB deviceMemoryBandwidth: 451.17GiB/s
2020-09-14 20:52:50.086335: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 3 with properties:
pciBusID: 0000:83:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 11.00GiB deviceMemoryBandwidth: 451.17GiB/s
2020-09-14 20:52:50.099883: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found
2020-09-14 20:52:50.108890: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'cublas64_11.dll'; dlerror: cublas64_11.dll not found
2020-09-14 20:52:50.136729: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cufft64_10.dll
2020-09-14 20:52:50.155330: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library curand64_10.dll
2020-09-14 20:52:50.183535: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusolver64_10.dll
2020-09-14 20:52:50.190137: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'cusparse64_11.dll'; dlerror: cusparse64_11.dll not found
2020-09-14 20:52:50.196780: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudnn64_8.dll
2020-09-14 20:52:50.202229: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1753] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2020-09-14 20:52:50.234220: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-09-14 20:52:50.254524: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-09-14 20:52:50.270592: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]
2020-09-14 20:52:50.274777: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
WARNING:tensorflow:Some requested devices in `tf.distribute.Strategy` are not visible to TensorFlow: /job:localhost/replica:0/task:0/device:GPU:1,/job:localhost/replica:0/task:0/device:GPU:3,/job:localhost/replica:0/task:0/device:GPU:2,/job:localhost/replica:0/task:0/device:GPU:0
W0914 20:52:50.291249 22692 cross_device_ops.py:1173] Some requested devices in `tf.distribute.Strategy` are not visible to TensorFlow: /job:localhost/replica:0/task:0/device:GPU:1,/job:localhost/replica:0/task:0/device:GPU:3,/job:localhost/replica:0/task:0/device:GPU:2,/job:localhost/replica:0/task:0/device:GPU:0
INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')
I0914 20:52:50.293247 22692 mirrored_strategy.py:347] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')
INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')
I0914 20:52:50.297248 22692 mirrored_strategy.py:347] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')
I0914 20:52:50.298247 22692 main.py:101] Train num_replicas_in_sync 2 num_workers 1 is_multi_host False
W0914 20:52:50.300244 22692 distributed_executor.py:381] It is sematically wrong to run callbacks when iterations_per_loop is not one (100)
I0914 20:52:50.301245 22692 distributed_executor.py:181] Save config to model_dir model_dir.
WARNING:tensorflow:From C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\util\deprecation.py:574: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Use fn_output_signature instead
W0914 20:52:51.157972 22692 deprecation.py:506] From C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\util\deprecation.py:574: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Use fn_output_signature instead
2020-09-14 20:52:59.444012: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 1)
WARNING:tensorflow:`tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.
W0914 20:53:00.796903 22692 backend.py:428] `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.
INFO:tensorflow:batch_all_reduce: 1 all-reduces with algorithm = hierarchical_copy, num_packs = 1
I0914 20:53:00.833891 22692 cross_device_ops.py:742] batch_all_reduce: 1 all-reduces with algorithm = hierarchical_copy, num_packs = 1
INFO:tensorflow:batch_all_reduce: 1 all-reduces with algorithm = hierarchical_copy, num_packs = 1
I0914 20:53:00.837890 22692 cross_device_ops.py:742] batch_all_reduce: 1 all-reduces with algorithm = hierarchical_copy, num_packs = 1
INFO:tensorflow:batch_all_reduce: 1 all-reduces with algorithm = hierarchical_copy, num_packs = 1
I0914 20:53:00.843889 22692 cross_device_ops.py:742] batch_all_reduce: 1 all-reduces with algorithm = hierarchical_copy, num_packs = 1
INFO:tensorflow:batch_all_reduce: 1 all-reduces with algorithm = hierarchical_copy, num_packs = 1
I0914 20:53:00.849885 22692 cross_device_ops.py:742] batch_all_reduce: 1 all-reduces with algorithm = hierarchical_copy, num_packs = 1
INFO:tensorflow:batch_all_reduce: 1 all-reduces with algorithm = hierarchical_copy, num_packs = 1
I0914 20:53:00.866881 22692 cross_device_ops.py:742] batch_all_reduce: 1 all-reduces with algorithm = hierarchical_copy, num_packs = 1
INFO:tensorflow:batch_all_reduce: 1 all-reduces with algorithm = hierarchical_copy, num_packs = 1
I0914 20:53:00.897871 22692 cross_device_ops.py:742] batch_all_reduce: 1 all-reduces with algorithm = hierarchical_copy, num_packs = 1
INFO:tensorflow:batch_all_reduce: 1 all-reduces with algorithm = hierarchical_copy, num_packs = 1
I0914 20:53:00.970848 22692 cross_device_ops.py:742] batch_all_reduce: 1 all-reduces with algorithm = hierarchical_copy, num_packs = 1
INFO:tensorflow:batch_all_reduce: 1 all-reduces with algorithm = hierarchical_copy, num_packs = 1
I0914 20:53:00.975848 22692 cross_device_ops.py:742] batch_all_reduce: 1 all-reduces with algorithm = hierarchical_copy, num_packs = 1
INFO:tensorflow:batch_all_reduce: 1 all-reduces with algorithm = hierarchical_copy, num_packs = 1
I0914 20:53:00.981844 22692 cross_device_ops.py:742] batch_all_reduce: 1 all-reduces with algorithm = hierarchical_copy, num_packs = 1
INFO:tensorflow:batch_all_reduce: 1 all-reduces with algorithm = hierarchical_copy, num_packs = 1
I0914 20:53:00.984845 22692 cross_device_ops.py:742] batch_all_reduce: 1 all-reduces with algorithm = hierarchical_copy, num_packs = 1
I0914 20:54:39.201575 22692 distributed_executor.py:434] Checkpoint file model_dir\ctl_step_0.ckpt-1 found and restoring from checkpoint
WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.

Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.core.Dense object at 0x0000024A824D2A20> and <tensorflow.python.keras.engine.base_layer.TensorFlowOpLayer object at 0x0000024B0835D390>).
W0914 20:56:51.118577 22692 base.py:320] Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.

Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.core.Dense object at 0x0000024A824D2A20> and <tensorflow.python.keras.engine.base_layer.TensorFlowOpLayer object at 0x0000024B0835D390>).
WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.

Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.core.Dense object at 0x0000024A824D2C50> and <tensorflow.python.keras.engine.base_layer.TensorFlowOpLayer object at 0x0000024B08DC45F8>).
W0914 20:56:51.325511 22692 base.py:320] Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.

Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.core.Dense object at 0x0000024A824D2C50> and <tensorflow.python.keras.engine.base_layer.TensorFlowOpLayer object at 0x0000024B08DC45F8>).
WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.

Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.core.Dense object at 0x0000024A824F30F0> and <tensorflow.python.keras.engine.base_layer.TensorFlowOpLayer object at 0x0000024B09189EB8>).
W0914 20:56:51.513483 22692 base.py:320] Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.

Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.core.Dense object at 0x0000024A824F30F0> and <tensorflow.python.keras.engine.base_layer.TensorFlowOpLayer object at 0x0000024B09189EB8>).
WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.

Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.core.Dense object at 0x0000024A824D2EF0> and <tensorflow.python.keras.engine.base_layer.TensorFlowOpLayer object at 0x0000024B08973080>).
W0914 20:56:59.484933 22692 base.py:320] Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.

Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.core.Dense object at 0x0000024A824D2EF0> and <tensorflow.python.keras.engine.base_layer.TensorFlowOpLayer object at 0x0000024B08973080>).
WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.

Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x0000024A824F33C8> and <tensorflow.python.keras.engine.base_layer.TensorFlowOpLayer object at 0x0000024B4B7C8208>).
W0914 21:00:08.138855 22692 base.py:320] Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.

Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x0000024A824F33C8> and <tensorflow.python.keras.engine.base_layer.TensorFlowOpLayer object at 0x0000024B4B7C8208>).
WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.

Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x0000024A824F3550> and <tensorflow.python.keras.engine.base_layer.TensorFlowOpLayer object at 0x0000024B4B81C828>).
W0914 21:00:22.576261 22692 base.py:320] Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.

Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x0000024A824F3550> and <tensorflow.python.keras.engine.base_layer.TensorFlowOpLayer object at 0x0000024B4B81C828>).
WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.

Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x0000024A824F36D8> and <tensorflow.python.keras.engine.base_layer.TensorFlowOpLayer object at 0x0000024B4D497C18>).
W0914 21:00:36.712757 22692 base.py:320] Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.

Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x0000024A824F36D8> and <tensorflow.python.keras.engine.base_layer.TensorFlowOpLayer object at 0x0000024B4D497C18>).
WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.

Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x0000024A824F3860> and <tensorflow.python.keras.engine.base_layer.TensorFlowOpLayer object at 0x0000024B4B715AC8>).
W0914 21:00:57.225227 22692 base.py:320] Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.

Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x0000024A824F3860> and <tensorflow.python.keras.engine.base_layer.TensorFlowOpLayer object at 0x0000024B4B715AC8>).
WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.

Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.convolutional.Conv2DTranspose object at 0x0000024A824F3B00> and <tensorflow.python.keras.engine.base_layer.TensorFlowOpLayer object at 0x0000024B4ABED240>).
W0914 21:01:11.759604 22692 base.py:320] Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.

Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.convolutional.Conv2DTranspose object at 0x0000024A824F3B00> and <tensorflow.python.keras.engine.base_layer.TensorFlowOpLayer object at 0x0000024B4ABED240>).
WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.

Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x0000024B4A738160> and <tensorflow.python.keras.engine.base_layer.TensorFlowOpLayer object at 0x0000024B4ABED320>).
W0914 21:01:26.223995 22692 base.py:320] Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.

Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x0000024B4A738160> and <tensorflow.python.keras.engine.base_layer.TensorFlowOpLayer object at 0x0000024B4ABED320>).
I0914 21:01:35.866925 22692 distributed_executor.py:438] Loading from checkpoint file completed. Init step 0
I0914 21:01:36.035874 22692 detection_executor.py:65] Filter trainable variables from 213 to 213
E0914 21:01:36.036876 22692 detection_executor.py:71] Detection: train metric is not an instance of tf.keras.metrics.Metric.
I0914 21:01:36.038870 22692 distributed_executor.py:485] Training started
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0', '/job:localhost/replica:0/task:0/device:CPU:0').
I0914 21:02:06.800077 22692 cross_device_ops.py:477] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0', '/job:localhost/replica:0/task:0/device:CPU:0').
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0', '/job:localhost/replica:0/task:0/device:CPU:0').
I0914 21:02:06.806080 22692 cross_device_ops.py:477] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0', '/job:localhost/replica:0/task:0/device:CPU:0').
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0', '/job:localhost/replica:0/task:0/device:CPU:0').
I0914 21:02:06.810074 22692 cross_device_ops.py:477] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0', '/job:localhost/replica:0/task:0/device:CPU:0').
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0', '/job:localhost/replica:0/task:0/device:CPU:0').
I0914 21:02:06.816072 22692 cross_device_ops.py:477] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0', '/job:localhost/replica:0/task:0/device:CPU:0').
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0', '/job:localhost/replica:0/task:0/device:CPU:0').
I0914 21:02:06.820072 22692 cross_device_ops.py:477] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0', '/job:localhost/replica:0/task:0/device:CPU:0').
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0', '/job:localhost/replica:0/task:0/device:CPU:0').
I0914 21:02:06.825071 22692 cross_device_ops.py:477] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0', '/job:localhost/replica:0/task:0/device:CPU:0').
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0', '/job:localhost/replica:0/task:0/device:CPU:0').
I0914 21:02:06.829073 22692 cross_device_ops.py:477] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0', '/job:localhost/replica:0/task:0/device:CPU:0').
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0', '/job:localhost/replica:0/task:0/device:CPU:0').
I0914 21:02:06.832066 22692 cross_device_ops.py:477] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0', '/job:localhost/replica:0/task:0/device:CPU:0').
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0', '/job:localhost/replica:0/task:0/device:CPU:0').
I0914 21:02:06.845062 22692 cross_device_ops.py:477] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0', '/job:localhost/replica:0/task:0/device:CPU:0').
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0', '/job:localhost/replica:0/task:0/device:CPU:0').
I0914 21:02:06.848064 22692 cross_device_ops.py:477] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0', '/job:localhost/replica:0/task:0/device:CPU:0').
Traceback (most recent call last):
  File ""official/vision/detection/main.py"", line 264, in <module>
    app.run(main)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\absl\app.py"", line 300, in run
    _run_main(main, args)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\absl\app.py"", line 251, in _run_main
    sys.exit(main(argv))
  File ""official/vision/detection/main.py"", line 259, in main
    run()
  File ""official/vision/detection/main.py"", line 253, in run
    callbacks=callbacks)
  File ""official/vision/detection/main.py"", line 125, in run_executor
    save_config=True)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\official\modeling\training\distributed_executor.py"", line 492, in train
    tf.convert_to_tensor(num_steps, dtype=tf.int32))
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\eager\def_function.py"", line 787, in __call__
    result = self._call(*args, **kwds)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\eager\def_function.py"", line 847, in _call
    return self._stateless_fn(*args, **kwds)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\eager\function.py"", line 2929, in __call__
    filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\eager\function.py"", line 1920, in _call_flat
    ctx, args, cancellation_manager=cancellation_manager))
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\eager\function.py"", line 561, in call
    ctx=ctx)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\eager\execute.py"", line 60, in quick_execute
    inputs, attrs, num_outputs)
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xbe in position 135: invalid start byte",x12901,b'models:official type:bug',2020-09-14T13:13:18Z,2020-09-22T03:39:31Z,,,,,,,
9239, No OpKernel was registered to support Op 'NcclAllReduce',"I'm trying to train my model using mask_rcnn, but it's reporting an error.
`python official/vision/detection/main.py --strategy_type=mirrored --num_gpus=4 --model_dir=model_dir --mode=train --model=mask_rcnn --config_file=""my_maskrcnn.yaml""`
I tried training with 1 GPU and it didn't work.
`python official/vision/detection/main.py --strategy_type=one_device --num_gpus=1 --model_dir=model_dir --mode=train --model=mask_rcnn --config_file=""my_maskrcnn.yaml""`
I inquired about other solutions, upgraded my cuda. tried again and still no training success!
cuda   10.1
cudnn 8.0.3
tensorflow 2.3.0

> python official/vision/detection/main.py --strategy_type=mirrored --num_gpus=4 --model_dir=model_dir --mode=train --model=mask_rcnn --config_file=""my_maskrcnn.yaml""
2020-09-14 14:03:59.248261: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudart64_101.dll
C:\ProgramData\Anaconda3\lib\site-packages\official\modeling\hyperparams\params_dict.py:431: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  params_dict = yaml.load(dict_or_string_or_yaml_file)
C:\ProgramData\Anaconda3\lib\site-packages\official\modeling\hyperparams\params_dict.py:436: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  params.override(yaml.load(f), is_strict)
I0914 14:04:01.670982 14292 main.py:219] Model Parameters: {'anchor': {'anchor_size': 8,
            'aspect_ratios': [1.0, 2.0, 0.5],
            'num_scales': 1},
 'architecture': {'backbone': 'resnet',
                  'include_mask': True,
                  'mask_target_size': 28,
                  'max_level': 6,
                  'min_level': 2,
                  'multilevel_features': 'fpn',
                  'num_classes': 91,
                  'parser': 'maskrcnn_parser',
                  'use_bfloat16': False},
 'enable_summary': False,
 'eval': {'batch_size': 8,
          'eval_dataset_type': 'tfrecord',
          'eval_file_pattern': 'D:\\cwge\\models\\train\\obj-TFRecords-export',
          'eval_samples': 5000,
          'eval_timeout': None,
          'input_sharding': True,
          'min_eval_interval': 180,
          'num_images_to_visualize': 0,
          'num_steps_per_eval': 1000,
          'type': 'box_and_mask',
          'use_json_file': True,
          'val_json_file': 'D:\\cwge\\models\\train'},
 'fpn': {'fpn_feat_dims': 256,
         'use_batch_norm': True,
         'use_separable_conv': False},
 'frcnn_box_loss': {'huber_loss_delta': 1.0},
 'frcnn_head': {'fc_dims': 1024,
                'num_convs': 0,
                'num_fcs': 2,
                'num_filters': 256,
                'use_batch_norm': False,
                'use_separable_conv': False},
 'isolate_session_state': False,
 'mask_sampling': {'num_mask_samples_per_image': 128},
 'maskrcnn_parser': {'aug_rand_hflip': True,
                     'aug_scale_max': 1.0,
                     'aug_scale_min': 1.0,
                     'mask_crop_size': 112,
                     'max_num_instances': 100,
                     'num_channels': 3,
                     'output_size': [1024, 1024],
                     'rpn_batch_size_per_im': 256,
                     'rpn_fg_fraction': 0.5,
                     'rpn_match_threshold': 0.7,
                     'rpn_unmatched_threshold': 0.3,
                     'skip_crowd_during_training': True},
 'model_dir': 'model_dir',
 'mrcnn_head': {'num_convs': 4,
                'num_filters': 256,
                'use_batch_norm': False,
                'use_separable_conv': False},
 'norm_activation': {'activation': 'relu',
                     'batch_norm_epsilon': 0.0001,
                     'batch_norm_momentum': 0.997,
                     'batch_norm_trainable': True,
                     'use_sync_bn': False},
 'postprocess': {'max_total_size': 100,
                 'nms_iou_threshold': 0.5,
                 'pre_nms_num_boxes': 1000,
                 'score_threshold': 0.05,
                 'use_batched_nms': False},
 'predict': {'batch_size': 8},
 'resnet': {'resnet_depth': 50},
 'roi_proposal': {'rpn_min_size_threshold': 0.0,
                  'rpn_nms_threshold': 0.7,
                  'rpn_post_nms_top_k': 1000,
                  'rpn_pre_nms_top_k': 2000,
                  'rpn_score_threshold': 0.0,
                  'test_rpn_min_size_threshold': 0.0,
                  'test_rpn_nms_threshold': 0.7,
                  'test_rpn_post_nms_top_k': 1000,
                  'test_rpn_pre_nms_top_k': 1000,
                  'test_rpn_score_threshold': 0.0,
                  'use_batched_nms': False},
 'roi_sampling': {'bg_iou_thresh_hi': 0.5,
                  'bg_iou_thresh_lo': 0.0,
                  'fg_fraction': 0.25,
                  'fg_iou_thresh': 0.5,
                  'mix_gt_boxes': True,
                  'num_samples_per_image': 512},
 'rpn_box_loss': {'huber_loss_delta': 0.1111111111111111},
 'rpn_head': {'anchors_per_location': 3,
              'num_convs': 2,
              'num_filters': 256,
              'use_batch_norm': False,
              'use_separable_conv': False},
 'rpn_score_loss': {'rpn_batch_size_per_im': 256},
 'strategy_config': {'all_reduce_alg': None,
                     'distribution_strategy': 'mirrored',
                     'num_gpus': 4,
                     'num_packs': 1,
                     'task_index': -1,
                     'tpu': None,
                     'worker_hosts': None},
 'strategy_type': 'mirrored',
 'train': {'batch_size': 64,
           'checkpoint': {'path': '', 'prefix': ''},
           'frozen_variable_prefix': '',
           'gradient_clip_norm': 0.0,
           'input_partition_dims': None,
           'input_sharding': False,
           'iterations_per_loop': 100,
           'l2_weight_decay': 0.0001,
           'learning_rate': {'init_learning_rate': 0.08,
                             'learning_rate_levels': [0.008, 0.0008],
                             'learning_rate_steps': [15000, 20000],
                             'type': 'step',
                             'warmup_learning_rate': 0.0067,
                             'warmup_steps': 500},
           'num_cores_per_replica': None,
           'optimizer': {'momentum': 0.9, 'nesterov': True, 'type': 'momentum'},
           'regularization_variable_regex': '.*(kernel|weight):0$',
           'total_steps': 22500,
           'train_dataset_type': 'tfrecord',
           'train_file_pattern': 'D:\\cwge\\models\\train\\obj-TFRecords-export',
           'transpose_input': False},
 'type': 'mask_rcnn',
 'use_tpu': False}
I0914 14:04:01.770950 14292 losses.py:152] RpnBoxLoss huber_loss_delta 0.1111111111111111
I0914 14:04:01.770950 14292 losses.py:244] FastrcnnBoxLoss huber_loss_delta 1.0
2020-09-14 14:04:01.776499: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library nvcuda.dll
2020-09-14 14:04:01.894504: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties:
pciBusID: 0000:02:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 11.00GiB deviceMemoryBandwidth: 451.17GiB/s
2020-09-14 14:04:01.910350: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 1 with properties:
pciBusID: 0000:03:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 11.00GiB deviceMemoryBandwidth: 451.17GiB/s
2020-09-14 14:04:01.926693: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 2 with properties:
pciBusID: 0000:82:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 11.00GiB deviceMemoryBandwidth: 451.17GiB/s
2020-09-14 14:04:01.941732: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 3 with properties:
pciBusID: 0000:83:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 11.00GiB deviceMemoryBandwidth: 451.17GiB/s
2020-09-14 14:04:01.955368: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudart64_101.dll
2020-09-14 14:04:01.968628: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cublas64_10.dll
2020-09-14 14:04:01.979013: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cufft64_10.dll
2020-09-14 14:04:01.986508: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library curand64_10.dll
2020-09-14 14:04:01.997805: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusolver64_10.dll
2020-09-14 14:04:02.007622: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusparse64_10.dll
2020-09-14 14:04:02.027831: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudnn64_7.dll
2020-09-14 14:04:02.034248: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0, 1, 2, 3
2020-09-14 14:04:02.040587: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-09-14 14:04:02.071991: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x17bcbd2a1a0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-09-14 14:04:02.078745: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-09-14 14:04:02.838330: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties:
pciBusID: 0000:02:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 11.00GiB deviceMemoryBandwidth: 451.17GiB/s
2020-09-14 14:04:02.851809: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 1 with properties:
pciBusID: 0000:03:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 11.00GiB deviceMemoryBandwidth: 451.17GiB/s
2020-09-14 14:04:02.865257: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 2 with properties:
pciBusID: 0000:82:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 11.00GiB deviceMemoryBandwidth: 451.17GiB/s
2020-09-14 14:04:02.879649: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 3 with properties:
pciBusID: 0000:83:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 11.00GiB deviceMemoryBandwidth: 451.17GiB/s
2020-09-14 14:04:02.891302: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudart64_101.dll
2020-09-14 14:04:02.899479: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cublas64_10.dll
2020-09-14 14:04:02.907082: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cufft64_10.dll
2020-09-14 14:04:02.912780: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library curand64_10.dll
2020-09-14 14:04:02.919560: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusolver64_10.dll
2020-09-14 14:04:02.926127: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusparse64_10.dll
2020-09-14 14:04:02.933353: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudnn64_7.dll
2020-09-14 14:04:02.939169: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0, 1, 2, 3
2020-09-14 14:04:04.938483: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-09-14 14:04:04.948402: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 1 2 3
2020-09-14 14:04:04.954277: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N N N N
2020-09-14 14:04:04.961884: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 1:   N N N N
2020-09-14 14:04:04.968803: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 2:   N N N N
2020-09-14 14:04:04.974100: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 3:   N N N N
2020-09-14 14:04:04.979507: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 8678 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:02:00.0, compute capability: 6.1)
2020-09-14 14:04:04.993621: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 8678 MB memory) -> physical GPU (device: 1, name: GeForce GTX 1080 Ti, pci bus id: 0000:03:00.0, compute capability: 6.1)
2020-09-14 14:04:05.008754: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 8679 MB memory) -> physical GPU (device: 2, name: GeForce GTX 1080 Ti, pci bus id: 0000:82:00.0, compute capability: 6.1)
2020-09-14 14:04:05.022460: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:3 with 8678 MB memory) -> physical GPU (device: 3, name: GeForce GTX 1080 Ti, pci bus id: 0000:83:00.0, compute capability: 6.1)
2020-09-14 14:04:05.043731: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x17c2c4b1c30 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-09-14 14:04:05.051100: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce GTX 1080 Ti, Compute Capability 6.1
2020-09-14 14:04:05.057392: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (1): GeForce GTX 1080 Ti, Compute Capability 6.1
2020-09-14 14:04:05.065059: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (2): GeForce GTX 1080 Ti, Compute Capability 6.1
2020-09-14 14:04:05.071924: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (3): GeForce GTX 1080 Ti, Compute Capability 6.1
INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')
I0914 14:04:05.084040 14292 mirrored_strategy.py:341] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')
I0914 14:04:05.085038 14292 main.py:109] Train num_replicas_in_sync 4 num_workers 1 is_multi_host False
W0914 14:04:05.551125 14292 distributed_executor.py:386] It is sematically wrong to run callbacks when iterations_per_loop is not one (100)
I0914 14:04:05.551125 14292 distributed_executor.py:187] Save config to model_dir model_dir.
WARNING:tensorflow:From C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\util\deprecation.py:574: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Use fn_output_signature instead
W0914 14:04:06.674531 14292 deprecation.py:506] From C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\util\deprecation.py:574: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Use fn_output_signature instead
WARNING:tensorflow:From C:\ProgramData\Anaconda3\lib\site-packages\official\modeling\training\distributed_executor.py:422: set_learning_phase (from tensorflow.python.keras.backend) is deprecated and will be removed after 2020-10-11.
Instructions for updating:
Simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.
W0914 14:04:14.898379 14292 deprecation.py:323] From C:\ProgramData\Anaconda3\lib\site-packages\official\modeling\training\distributed_executor.py:422: set_learning_phase (from tensorflow.python.keras.backend) is deprecated and will be removed after 2020-10-11.
Instructions for updating:
Simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
I0914 14:04:14.967356 14292 cross_device_ops.py:443] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
I0914 14:04:14.975355 14292 cross_device_ops.py:443] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
I0914 14:04:15.026335 14292 cross_device_ops.py:443] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
I0914 14:04:15.034337 14292 cross_device_ops.py:443] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
I0914 14:04:15.077326 14292 cross_device_ops.py:443] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
I0914 14:04:15.085321 14292 cross_device_ops.py:443] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
I0914 14:04:15.131283 14292 cross_device_ops.py:443] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
I0914 14:04:15.139305 14292 cross_device_ops.py:443] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
I0914 14:04:15.182301 14292 cross_device_ops.py:443] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
I0914 14:04:15.190292 14292 cross_device_ops.py:443] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
I0914 14:05:32.890244 14292 distributed_executor.py:439] Checkpoint file model_dir\ctl_step_0.ckpt-1 found and restoring from checkpoint
I0914 14:11:06.265516 14292 distributed_executor.py:443] Loading from checkpoint file completed. Init step 0
I0914 14:11:06.947770 14292 detection_executor.py:65] Filter trainable variables from 213 to 213
E0914 14:11:06.947770 14292 detection_executor.py:71] Detection: train metric is not an instance of tf.keras.metrics.Metric.
I0914 14:11:06.948742 14292 distributed_executor.py:491] Training started
INFO:tensorflow:batch_all_reduce: 213 all-reduces with algorithm = nccl, num_packs = 1
I0914 14:11:42.760163 14292 cross_device_ops.py:702] batch_all_reduce: 213 all-reduces with algorithm = nccl, num_packs = 1
INFO:tensorflow:batch_all_reduce: 213 all-reduces with algorithm = nccl, num_packs = 1
I0914 14:12:20.195042 14292 cross_device_ops.py:702] batch_all_reduce: 213 all-reduces with algorithm = nccl, num_packs = 1
INFO:tensorflow:batch_all_reduce: 213 all-reduces with algorithm = nccl, num_packs = 1
I0914 14:13:25.904150 14292 cross_device_ops.py:702] batch_all_reduce: 213 all-reduces with algorithm = nccl, num_packs = 1
INFO:tensorflow:batch_all_reduce: 213 all-reduces with algorithm = nccl, num_packs = 1
I0914 14:14:05.912061 14292 cross_device_ops.py:702] batch_all_reduce: 213 all-reduces with algorithm = nccl, num_packs = 1
Traceback (most recent call last):
  File ""official/vision/detection/main.py"", line 272, in <module>
    app.run(main)
  File ""C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\absl\app.py"", line 300, in run
    _run_main(main, args)
  File ""C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\absl\app.py"", line 251, in _run_main
    sys.exit(main(argv))
  File ""official/vision/detection/main.py"", line 267, in main
    run()
  File ""official/vision/detection/main.py"", line 261, in run
    callbacks=callbacks)
  File ""official/vision/detection/main.py"", line 133, in run_executor
    save_config=True)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\official\modeling\training\distributed_executor.py"", line 498, in train
    tf.convert_to_tensor(num_steps, dtype=tf.int32))
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\eager\def_function.py"", line 780, in __call__
    result = self._call(*args, **kwds)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\eager\def_function.py"", line 840, in _call
    return self._stateless_fn(*args, **kwds)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\eager\function.py"", line 2829, in __call__
    return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\eager\function.py"", line 1848, in _filtered_call
    cancellation_manager=cancellation_manager)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\eager\function.py"", line 1924, in _call_flat
    ctx, args, cancellation_manager=cancellation_manager))
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\eager\function.py"", line 550, in call
    ctx=ctx)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\eager\execute.py"", line 60, in quick_execute
    inputs, attrs, num_outputs)
tensorflow.python.framework.errors_impl.InvalidArgumentError: No OpKernel was registered to support Op 'NcclAllReduce' used by {{node SGD/NcclAllReduce}} with these attrs: [reduction=""sum"", shared_name=""c2"", T=DT_FLOAT, num_devices=4]
Registered devices: [CPU, GPU, XLA_CPU, XLA_GPU]
Registered kernels:
  <no registered kernels>

         [[SGD/NcclAllReduce]] [Op:__inference_train_step_456253]",x12901,b'models:official type:bug',2020-09-14T06:15:45Z,2020-09-14T16:38:58Z,,,,,,,
9235,ValueError: call() should not modify its Python input arguments,"# Prerequisites

Please answer the following questions for yourself before submitting an issue.

- [yes] I am using the latest TensorFlow Model Garden release and TensorFlow 2.
- [yes] I am reporting the issue to the correct repository. (Model Garden official or research directory)
- [yes] I checked to make sure that this issue has not been filed already.

## 1. The entire URL of the file you are using

https://github.com/tensorflow/models/tree/master/official/nlp/transformer/transformer_main.py

## 2. Describe the bug

I need a "".pb"" model(savedModel) for tf.serving. 

I trained and saved the model(save_weights_only=True), and successfully restored the weights in the prediction mode(by setting mode=""predict"").

Then I tried to save the model in the protocol buffer format(savedModel), but the error occured:

""**ValueError: call() should not modify its Python input arguments. Check if it modifies any lists or dicts passed as arguments. Modifying a copy is allowed.**""

## 3. Steps to reproduce

I just followed the tutorial. 

I trained and saved a model(.ckpt), then restored its weights in the prediction mode(by setting mode=""predict""). I tried to save the inference model in savedModel format for tf.serving.

my code:
```
with tf.name_scope(""model""):
    model = transformer.create_model(params, is_train=False)
    self._load_weights_if_possible(model, tf.train.latest_checkpoint(self.flags_obj.model_dir))  
    model.summary()

# I tried to save the inference model in .pb format for tf.serving
logging.info(""Save inference graph into the .pb format."")
model.save(os.path.join(flags_obj.model_dir, ""1""), 
                    include_optimizer=False, options=save_options_lib.SaveOptions())  #  ----> error here
logging.info(""successfully."")
```

## 4. Expected behavior

The inference model can be saved as a .pb model for tf.serving.

## 5. Additional context
**pycharm logs, it seems the ""decoder_stack"" is the source of the error:**

Traceback (most recent call last):
  File ""/home/xxx/pycharm_proj/models-master-0907/official/nlp/transformer/transformer_main.py"", line 955, in <module>
    app.run(main)
  File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""/home/xxx/pycharm_proj/models-master-0907/official/nlp/transformer/transformer_main.py"", line 944, in main
    task.predict(chunk_list, line=line, use_bsrule=False)
  File ""/home/xxx/pycharm_proj/models-master-0907/official/nlp/transformer/transformer_main.py"", line 541, in predict
    options=save_options_lib.SaveOptions())
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py"", line 1950, in save
    signatures, options)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/save.py"", line 135, in save_model
    signatures, options)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/saved_model/save.py"", line 80, in save
    save_lib.save(model, filepath, signatures, options)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/save.py"", line 1000, in save
    obj, export_dir, signatures, options, meta_graph_def)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/save.py"", line 1148, in _build_meta_graph
    meta_graph_def)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/save.py"", line 1095, in _build_meta_graph_impl
    checkpoint_graph_view)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/signature_serialization.py"", line 75, in find_function_to_export
    functions = saveable_view.list_functions(saveable_view.root)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/save.py"", line 147, in list_functions
    self._serialization_cache)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py"", line 2561, in _list_functions_for_serialization
    Model, self)._list_functions_for_serialization(serialization_cache)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py"", line 3047, in _list_functions_for_serialization
    .list_functions_for_serialization(serialization_cache))
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/saved_model/base_serialization.py"", line 87, in list_functions_for_serialization
    fns = self.functions_to_serialize(serialization_cache)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/saved_model/layer_serialization.py"", line 79, in functions_to_serialize
    serialization_cache).functions_to_serialize)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/saved_model/layer_serialization.py"", line 95, in _get_serialized_attributes
    serialization_cache)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/saved_model/model_serialization.py"", line 57, in _get_serialized_attributes_internal
    serialization_cache))
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/saved_model/layer_serialization.py"", line 104, in _get_serialized_attributes_internal
    functions = save_impl.wrap_layer_functions(self.obj, serialization_cache)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/saved_model/save_impl.py"", line 155, in wrap_layer_functions
    original_fns = _replace_child_layer_functions(layer, serialization_cache)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/saved_model/save_impl.py"", line 274, in _replace_child_layer_functions
    serialization_cache).functions)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/saved_model/layer_serialization.py"", line 95, in _get_serialized_attributes
    serialization_cache)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/saved_model/model_serialization.py"", line 57, in _get_serialized_attributes_internal
    serialization_cache))
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/saved_model/layer_serialization.py"", line 104, in _get_serialized_attributes_internal
    functions = save_impl.wrap_layer_functions(self.obj, serialization_cache)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/saved_model/save_impl.py"", line 165, in wrap_layer_functions
    '{}_layer_call_and_return_conditional_losses'.format(layer.name))
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/saved_model/save_impl.py"", line 505, in add_function
    self.add_trace(*self._input_signature)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/saved_model/save_impl.py"", line 420, in add_trace
    trace_with_training(True)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/saved_model/save_impl.py"", line 418, in trace_with_training
    fn.get_concrete_function(*args, **kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/saved_model/save_impl.py"", line 549, in get_concrete_function
    return super(LayerCall, self).get_concrete_function(*args, **kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py"", line 1176, in get_concrete_function
    concrete = self._get_concrete_function_garbage_collected(*args, **kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py"", line 1082, in _get_concrete_function_garbage_collected
    self._initialize(args, kwargs, add_initializers_to=initializers)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py"", line 717, in _initialize
    *args, **kwds))
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py"", line 2955, in _get_concrete_function_internal_garbage_collected
    graph_function, _, _ = self._maybe_define_function(args, kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py"", line 3333, in _maybe_define_function
    graph_function = self._create_graph_function(args, kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py"", line 3188, in _create_graph_function
    capture_by_value=self._capture_by_value),
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py"", line 987, in func_graph_from_py_func
    func_outputs = python_func(*func_args, **func_kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py"", line 625, in wrapped_fn
    out = weak_wrapped_fn().__wrapped__(*args, **kwds)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/saved_model/save_impl.py"", line 526, in wrapper
    ret = method(*args, **kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/saved_model/utils.py"", line 169, in wrap_with_training_arg
    lambda: replace_training_and_call(False))
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/control_flow_util.py"", line 113, in smart_cond
    pred, true_fn=true_fn, false_fn=false_fn, name=name)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/smart_cond.py"", line 54, in smart_cond
    return true_fn()
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/saved_model/utils.py"", line 168, in <lambda>
    training, lambda: replace_training_and_call(True),
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/saved_model/utils.py"", line 165, in replace_training_and_call
    return wrapped_call(*args, **kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/saved_model/save_impl.py"", line 569, in call_and_return_conditional_losses
    call_output = layer_call(inputs, *args, **kwargs)
  File ""/home/xxx/pycharm_proj/models-master-0907/official/nlp/transformer/transformer.py"", line 154, in call
    return self.predict(encoder_outputs, attention_bias, training)
  File ""/home/xxx/pycharm_proj/models-master-0907/official/nlp/transformer/transformer.py"", line 349, in predict
    dtype=self.params[""dtype""])
  File ""/home/xxx/pycharm_proj/models-master-0907/official/nlp/modeling/ops/beam_search.py"", line 635, in sequence_beam_search
    return sbs.search(initial_ids, initial_cache)
  File ""/home/xxx/pycharm_proj/models-master-0907/official/nlp/modeling/ops/beam_search.py"", line 414, in search
    parallel_iterations=1))
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py"", line 574, in new_func
    return func(*args, **kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/control_flow_ops.py"", line 2499, in while_loop_v2
    return_same_structure=True)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/control_flow_ops.py"", line 2696, in while_loop
    back_prop=back_prop)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/while_v2.py"", line 196, in while_loop
    add_control_dependencies=add_control_dependencies)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py"", line 987, in func_graph_from_py_func
    func_outputs = python_func(*func_args, **func_kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/while_v2.py"", line 174, in wrapped_body
    outputs = body(*_pack_sequence_as(orig_loop_vars, args))
  File ""/home/xxx/pycharm_proj/models-master-0907/official/nlp/modeling/ops/beam_search.py"", line 390, in _search_step
    new_seq, new_log_probs, topk_ids, new_cache = _grow_alive_seq(state)
  File ""/home/xxx/pycharm_proj/models-master-0907/official/nlp/modeling/ops/beam_search.py"", line 238, in _grow_alive_seq
    flat_ids, i, flat_cache)
  **File ""/home/xxx/pycharm_proj/models-master-0907/official/nlp/transformer/transformer.py"", line 287, in symbols_to_logits_fn
    decode_loop_step=i if self.params[""padded_decode""] else None)**
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py"", line 990, in __call__
    outputs = call_fn(inputs, *args, **kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/saved_model/utils.py"", line 71, in return_outputs_and_add_losses
    outputs, losses = fn(inputs, *args, **kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/saved_model/utils.py"", line 169, in wrap_with_training_arg
    lambda: replace_training_and_call(False))
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/control_flow_util.py"", line 113, in smart_cond
    pred, true_fn=true_fn, false_fn=false_fn, name=name)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/smart_cond.py"", line 54, in smart_cond
    return true_fn()
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/saved_model/utils.py"", line 168, in <lambda>
    training, lambda: replace_training_and_call(True),
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/saved_model/utils.py"", line 165, in replace_training_and_call
    return wrapped_call(*args, **kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/saved_model/save_impl.py"", line 543, in __call__
    self.call_collection.add_trace(*args, **kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/saved_model/save_impl.py"", line 420, in add_trace
    trace_with_training(True)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/saved_model/save_impl.py"", line 418, in trace_with_training
    fn.get_concrete_function(*args, **kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/saved_model/save_impl.py"", line 549, in get_concrete_function
    return super(LayerCall, self).get_concrete_function(*args, **kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py"", line 1176, in get_concrete_function
    concrete = self._get_concrete_function_garbage_collected(*args, **kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py"", line 1082, in _get_concrete_function_garbage_collected
    self._initialize(args, kwargs, add_initializers_to=initializers)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py"", line 717, in _initialize
    *args, **kwds))
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py"", line 2955, in _get_concrete_function_internal_garbage_collected
    graph_function, _, _ = self._maybe_define_function(args, kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py"", line 3333, in _maybe_define_function
    graph_function = self._create_graph_function(args, kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py"", line 3188, in _create_graph_function
    capture_by_value=self._capture_by_value),
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py"", line 994, in func_graph_from_py_func
    check_mutation(func_args_before, func_args, original_func)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py"", line 1078, in check_mutation
    raise ValueError(errmsg)
ValueError: call() should not modify its Python input arguments. Check if it modifies any lists or dicts passed as arguments. Modifying a copy is allowed.


## 6. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  Ubuntu 18.04.3 LTS
- Mobile device name if the issue happens on a mobile device:  None
- TensorFlow installed from (source or binary):  pip
- TensorFlow version (use command below):  tensorflow-gpu 2.3.0
- Python version:  3.6.8
- Bazel version (if compiling from source):  None
- GCC/Compiler version (if compiling from source):  None
- CUDA/cuDNN version:  CUDA 10.1   Driver Version: 430.50
- GPU model and memory:  one GTX1080TI, 11G memory

<!-- 
Collect system information using our environment capture script.
https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can also obtain the TensorFlow version with:

1. TensorFlow 1.0
`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

2. TensorFlow 2.0
`python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`
-->
",2020zyc,b'models:official type:bug',2020-09-13T05:09:23Z,2020-09-18T19:43:52Z,,,,,,,
9232,Loading trained DELG model problem,"# Prerequisites

Please answer the following questions for yourself before submitting an issue.

- [x] I am using the latest TensorFlow Model Garden release and TensorFlow 2.
- [x] I am reporting the issue to the correct repository. (Model Garden official or research directory)
- [x] I checked to make sure that this issue has not already been filed.

## 1. The entire URL of the file you are using

https://github.com/tensorflow/models/blob/master/research/delf/delf/python/training/README.md

## 2. Describe the bug

I was trying to train DELG model and extract local and global feature. The process of training and extracting model was fine. However, when I tried to load saved model with [GLRec2020 Baseline](https://www.kaggle.com/camaskew/host-baseline-example) code, I got error in the following line:
```
GLOBAL_FEATURE_EXTRACTION_FN = DELG_MODEL.prune(DELG_INPUT_TENSOR_NAMES,
                                                ['global_descriptors:0'])
```
```
AttributeError: '_UserObject' object has no attribute 'prune'
```

## 3. Steps to reproduce

I followed the code to train DELG model. I did 2 steps:
- Training with Local and Global Features
- Extracting DELG local+global feature model

Next, I tried to load model with code from [GLRec2020 Baseline](https://www.kaggle.com/camaskew/host-baseline-example) and problem came in the following line:
```
GLOBAL_FEATURE_EXTRACTION_FN = DELG_MODEL.prune(DELG_INPUT_TENSOR_NAMES,
                                                ['global_descriptors:0'])
```

## 4. Expected behavior

I will really appreciate any help if you point out where I do wrong or what to do to fix the problem.

## 5. Additional context

## 6. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux (Kaggle kernel)
- Mobile device name if the issue happens on a mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below): 2.3.0
- Python version: python 3.7.6
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 10.1
- GPU model and memory: Tesla P100
",ngokhoa96,b'models:research type:bug',2020-09-11T20:14:39Z,2020-09-12T18:55:27Z,,,,,,,
9231,"Custom Training, no custom code - checkpoint won't load for training but will for evaluation","# Prerequisites

Please answer the following questions for yourself before submitting an issue.

- [x] I am using the latest TensorFlow Model Garden release and TensorFlow 2.
- [x] I am reporting the issue to the correct repository. (Model Garden official or research directory)
- [x] I checked to make sure that this issue has not already been filed.

## 1. The entire URL of the file you are using

https://github.com/tensorflow/models/tree/master/research/...


## 2. Describe the bug

When running in training mode using:
python object_detection/model_main_tf2.py  --pipeline_config_path=${PIPELINE_CONFIG_PATH}  --model_dir=${MODEL_DIR}  --alsologtostder

I run into the following error:
RuntimeError: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for xxxxx/ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/checkpoint/model.ckpt

(NOTE: model.ckpt has been tried as resnet101.ckpt, model.ckpt-0, ckpt, resnet101.ckpt-00000, resnet.ckpt-00000, and model.ckpt-00000 and resnet101.ckpt-1 based on sample config files found online. I have also attempted to point it at the checkpoint directory. Error remains the same.)

When all information on a fine_tune_checkpoint is removed from the config file to attempt a ""from scratch"" training session the following error is given:

tensorflow.python.framework.errors_impl.FailedPreconditionError: xxxxxx/models-09-08-20/research/object_detection/ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/checkpoint.tmp166c5c2524dc4ab68f02f82edc5b0c11; Is a directory

I do not know how it was directed to this path. I have unset the CHECKPOINT_DIR and results remain the same.

When running in evaluation mode, the checkpoint is detected, but all output is set to 0 (as expected as custom dataset does not correspond to typical images).

## 3. Steps to reproduce

Download model directory from 09/08/2020, pull the SSD_resnet101 model from the TF2 model detection zoo. Modify the config file as shown below:

 fine_tune_checkpoint: ""/xxxxx/models-09-08-20/research/object_detection/ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/checkpoint/model.ckpt""
  num_steps: 25000
  startup_delay_steps: 0.0
  replicas_to_aggregate: 8
  max_number_of_boxes: 100
  unpad_groundtruth_tensors: false
  fine_tune_checkpoint_type: ""detection""
  use_bfloat16: true
  fine_tune_checkpoint_version: V2
}
train_input_reader {
  label_map_path: ""/xxxxx/models-09-08-20/research/object_detection/data/object-detection.pbtxt""
  tf_record_input_reader {
    input_path: ""/xxxxx/models-09-08-20/research/object_detection/data/train.record""
  }
}
eval_config {
  metrics_set: ""coco_detection_metrics""
  use_moving_averages: false
}
eval_input_reader {
  label_map_path: ""/xxxxx/models-09-08-20/research/object_detection/data""
  shuffle: false
  num_epochs: 1
  tf_record_input_reader {
    input_path: ""/xxxxx/models-09-08-20/research/object_detection/data/test.record""
  }
}



Move test.record, train.record, object-detection.pbtxt to the data directory.

Move images directory to the object detection directory.


Set the following via command line from the research directory:
PIPELINE_CONFIG_PATH=/xxxxx/models-09-08-20/research/object_detection/ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/pipeline.config

MODEL_DIR=/xxxxx/models-09-08-20/research/object_detection/ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/

run the following command from the research directory:
python object_detection/model_main_tf2.py \
    --pipeline_config_path=${PIPELINE_CONFIG_PATH} \
    --model_dir=${MODEL_DIR} \
    --alsologtostder

## 4. Expected behavior

I expect that the code would begin training on my custom dataset.

## 5. Additional context

(SSD) USER$ python object_detection/model_main_tf2.py     --pipeline_config_path=${PIPELINE_CONFIG_PATH}     --model_dir=${MODEL_DIR}     --alsologtostder
2020-09-10 09:38:48.794458: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-09-10 09:38:48.806430: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fb7c6883500 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-09-10 09:38:48.806468: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.
W0910 09:38:48.807556 4723258816 cross_device_ops.py:1175] There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.
INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)
I0910 09:38:48.807872 4723258816 mirrored_strategy.py:500] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)
INFO:tensorflow:Maybe overwriting record_summaries: True
I0910 09:38:48.811570 4723258816 config_util.py:552] Maybe overwriting record_summaries: True
INFO:tensorflow:Ignoring config override key: record_summaries
I0910 09:38:48.811643 4723258816 config_util.py:562] Ignoring config override key: record_summaries
INFO:tensorflow:Maybe overwriting train_steps: None
I0910 09:38:48.811934 4723258816 config_util.py:552] Maybe overwriting train_steps: None
INFO:tensorflow:Maybe overwriting use_bfloat16: False
I0910 09:38:48.812007 4723258816 config_util.py:552] Maybe overwriting use_bfloat16: False
Traceback (most recent call last):
  File ""/xxxxx/opt/anaconda3/envs/SSD/lib/python3.6/site-packages/tensorflow/python/training/py_checkpoint_reader.py"", line 95, in NewCheckpointReader
    return CheckpointReader(compat.as_bytes(filepattern))
RuntimeError: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for /xxxxx/models-09-08-20/research/object_detection/ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8/checkpoint/model.ckpt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""object_detection/model_main_tf2.py"", line 113, in <module>
    tf.compat.v1.app.run()
  File ""/xxxxx/opt/anaconda3/envs/SSD/lib/python3.6/site-packages/tensorflow/python/platform/app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""/xxxxx/opt/anaconda3/envs/SSD/lib/python3.6/site-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/xxxxx/opt/anaconda3/envs/SSD/lib/python3.6/site-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""object_detection/model_main_tf2.py"", line 110, in main
    record_summaries=FLAGS.record_summaries)
  File ""/xxxxx/opt/anaconda3/envs/SSD/lib/python3.6/site-packages/object_detection/model_lib_v2.py"", line 554, in train_loop
    unpad_groundtruth_tensors)
  File ""/xxxxx/opt/anaconda3/envs/SSD/lib/python3.6/site-packages/object_detection/model_lib_v2.py"", line 335, in load_fine_tune_checkpoint
    if not is_object_based_checkpoint(checkpoint_path):
  File ""/xxxxx/opt/anaconda3/envs/SSD/lib/python3.6/site-packages/object_detection/model_lib_v2.py"", line 298, in is_object_based_checkpoint
    var_names = [var[0] for var in tf.train.list_variables(checkpoint_path)]
  File ""/xxxxx/opt/anaconda3/envs/SSD/lib/python3.6/site-packages/tensorflow/python/training/checkpoint_utils.py"", line 98, in list_variables
    reader = load_checkpoint(ckpt_dir_or_file)
  File ""/xxxxx/opt/anaconda3/envs/SSD/lib/python3.6/site-packages/tensorflow/python/training/checkpoint_utils.py"", line 67, in load_checkpoint
    return py_checkpoint_reader.NewCheckpointReader(filename)
  File ""/xxxxx/opt/anaconda3/envs/SSD/lib/python3.6/site-packages/tensorflow/python/training/py_checkpoint_reader.py"", line 99, in NewCheckpointReader
    error_translator(e)
  File ""/xxxxx/opt/anaconda3/envs/SSD/lib/python3.6/site-packages/tensorflow/python/training/py_checkpoint_reader.py"", line 35, in error_translator
    raise errors_impl.NotFoundError(None, None, error_message)
tensorflow.python.framework.errors_impl.NotFoundError: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for /xxxxx/Desktop/models-09-08-20/research/object_detection/ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8/checkpoint/model.ckpt



## 6. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Mojave 10.14.6
- TensorFlow installed from (source or binary): pypi
- TensorFlow version (use command below): 2.2.0
- Python version: 3.6.10
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A",mgon5170,b'models:research type:bug',2020-09-11T16:32:12Z,2020-09-24T13:00:02Z,,,,,,,
9218,8-bit Quantization of RetinaNet,"# Prerequisites
## 1. The entire URL of the file you are using

https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md

## 2. Describe the bug

Applying 8-bit quantization to RetinaNet produces the following error:
```
RuntimeError: Quantization not yet supported for op: 'CUSTOM'.
```
I am using the new converter and have `allow_custom_ops` set to `True`, so this is unexpected. 

## 3. Steps to reproduce
1. Download the ssd resnet50 640x640 retinanet model from the [model zoo](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md)
2. Convert the model to a frozen graph using @srjoglekar246 's new script [here](https://github.com/tensorflow/models/blob/master/research/object_detection/export_tflite_ssd_graph.py)
3. Convert the frozen graph to a quantized tflite file with the new MLIR converter, with the following parameters: 
```
converter.allow_custom_ops = True
converter.representative_dataset = representative_dataset_gen
converter.optimizations = [tf.lite.Optimize.DEFAULT]
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]    # Problematic
```

## 4. Expected behavior

The script should successfully produce a quantized model by emitting a ""custom"" op for each custom operation. 

It would also be helpful if a member of the team could elucidate what these custom operations are, so that they can be passed to the tflite runtime.

## 5. Additional context

The TFLiteConverter successfully emits when quantization is disabled and when the experimental 8/16 quantization happens. It's the 8-bit-only-quantization that causes the crash. 

Include any logs that would be helpful to diagnose the problem.
```
  File ""quantize.py"", line 39, in <module>
    tflite_quant_model = converter.convert()
  File ""/home/rsaini/.pyenv/versions/tf2/lib/python3.7/site-packages/tensorflow/lite/python/lite.py"", line 726, in convert
    output_tensors)
  File ""/home/rsaini/.pyenv/versions/tf2/lib/python3.7/site-packages/tensorflow/lite/python/lite.py"", line 648, in convert
    result = self._calibrate_quantize_model(result, **flags)
  File ""/home/rsaini/.pyenv/versions/tf2/lib/python3.7/site-packages/tensorflow/lite/python/lite.py"", line 476, in _calibrate_quantize_model
    inference_output_type, allow_float, activations_type)
  File ""/home/rsaini/.pyenv/versions/tf2/lib/python3.7/site-packages/tensorflow/lite/python/optimize/calibrator.py"", line 98, in calibrate_and_quantize
    np.dtype(activations_type.as_numpy_dtype()).num)
RuntimeError: Quantization not yet supported for op: 'CUSTOM'.
```
## 6. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 20.04
- Mobile device name if the issue happens on a mobile device: N/A (targeting Google Coral)
- TensorFlow installed from (source or binary): Binary (pip)
- TensorFlow version (use command below): 2.4.0-dev20200908
- Python version: 3.7.7
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: 11
- GPU model and memory:
",rajansaini691,b'models:research type:bug',2020-09-09T23:18:38Z,2020-09-09T23:39:37Z,,,,,,,
9211,AttributeError: use_cpu_nms,"
## 1. The entire URL of the file you are using

https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2.md

## 2. Describe the bug

I followed instructions to install tensorflow 2 as described in the link above in ""Python Package Installation"" section.
The installation ends whitout errors.

## 3. Steps to reproduce

When I try to run test 

python object_detection/builders/model_builder_tf2_test.py 

I obtain the following errors:

AttributeError: use_cpu_nms

======================================================================
ERROR: test_create_faster_rcnn_from_config_with_crop_feature(True) (__main__.ModelBuilderTF2Test)
test_create_faster_rcnn_from_config_with_crop_feature(True) (__main__.ModelBuilderTF2Test)
test_create_faster_rcnn_from_config_with_crop_feature(True)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""C:\Users\deep-user\.conda\envs\tensorflow2\lib\site-packages\absl\testing\parameterized.py"", line 267, in bound_param_test
    test_method(self, testcase_params)
  File ""D:\faster_rcnn\models\research\object_detection\builders\model_builder_test.py"", line 292, in test_create_faster_rcnn_from_config_with_crop_feature
    _ = model_builder.build(model_proto, is_training=True)
  File ""D:\faster_rcnn\models\research\object_detection\builders\model_builder.py"", line 1062, in build
    add_summaries)
  File ""D:\faster_rcnn\models\research\object_detection\builders\model_builder.py"", line 663, in _build_faster_rcnn_model
    ) = post_processing_builder.build(frcnn_config.second_stage_post_processing)
  File ""D:\faster_rcnn\models\research\object_detection\builders\post_processing_builder.py"", line 59, in build
    post_processing_config.batch_non_max_suppression)
  File ""D:\faster_rcnn\models\research\object_detection\builders\post_processing_builder.py"", line 107, in _build_non_max_suppressor
    use_cpu_nms=nms_config.use_cpu_nms)
AttributeError: use_cpu_nms

======================================================================
ERROR: test_create_faster_rcnn_from_config_with_crop_feature(False) (__main__.ModelBuilderTF2Test)
test_create_faster_rcnn_from_config_with_crop_feature(False) (__main__.ModelBuilderTF2Test)
test_create_faster_rcnn_from_config_with_crop_feature(False)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""C:\Users\deep-user\.conda\envs\tensorflow2\lib\site-packages\absl\testing\parameterized.py"", line 267, in bound_param_test
    test_method(self, testcase_params)
  File ""D:\faster_rcnn\models\research\object_detection\builders\model_builder_test.py"", line 292, in test_create_faster_rcnn_from_config_with_crop_feature
    _ = model_builder.build(model_proto, is_training=True)
  File ""D:\faster_rcnn\models\research\object_detection\builders\model_builder.py"", line 1062, in build
    add_summaries)
  File ""D:\faster_rcnn\models\research\object_detection\builders\model_builder.py"", line 663, in _build_faster_rcnn_model
    ) = post_processing_builder.build(frcnn_config.second_stage_post_processing)
  File ""D:\faster_rcnn\models\research\object_detection\builders\post_processing_builder.py"", line 59, in build
    post_processing_config.batch_non_max_suppression)
  File ""D:\faster_rcnn\models\research\object_detection\builders\post_processing_builder.py"", line 107, in _build_non_max_suppressor
    use_cpu_nms=nms_config.use_cpu_nms)
AttributeError: use_cpu_nms

======================================================================
ERROR: test_create_faster_rcnn_model_from_config_with_example_miner (__main__.ModelBuilderTF2Test)
test_create_faster_rcnn_model_from_config_with_example_miner (__main__.ModelBuilderTF2Test)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""D:\faster_rcnn\models\research\object_detection\builders\model_builder_test.py"", line 271, in test_create_faster_rcnn_model_from_config_with_example_miner
    model = model_builder.build(model_proto, is_training=True)
  File ""D:\faster_rcnn\models\research\object_detection\builders\model_builder.py"", line 1062, in build
    add_summaries)
  File ""D:\faster_rcnn\models\research\object_detection\builders\model_builder.py"", line 663, in _build_faster_rcnn_model
    ) = post_processing_builder.build(frcnn_config.second_stage_post_processing)
  File ""D:\faster_rcnn\models\research\object_detection\builders\post_processing_builder.py"", line 59, in build
    post_processing_config.batch_non_max_suppression)
  File ""D:\faster_rcnn\models\research\object_detection\builders\post_processing_builder.py"", line 107, in _build_non_max_suppressor
    use_cpu_nms=nms_config.use_cpu_nms)
AttributeError: use_cpu_nms

======================================================================
ERROR: test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul (__main__.ModelBuilderTF2Test)
test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul (__main__.ModelBuilderTF2Test)
test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul(use_matmul_crop_and_resize=False, enable_mask_prediction=False)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""C:\Users\deep-user\.conda\envs\tensorflow2\lib\site-packages\absl\testing\parameterized.py"", line 263, in bound_param_test
    test_method(self, **testcase_params)
  File ""D:\faster_rcnn\models\research\object_detection\builders\model_builder_test.py"", line 262, in test_create_faster_rcnn_models_from_config
    model = model_builder.build(model_proto, is_training=True)
  File ""D:\faster_rcnn\models\research\object_detection\builders\model_builder.py"", line 1062, in build
    add_summaries)
  File ""D:\faster_rcnn\models\research\object_detection\builders\model_builder.py"", line 663, in _build_faster_rcnn_model
    ) = post_processing_builder.build(frcnn_config.second_stage_post_processing)
  File ""D:\faster_rcnn\models\research\object_detection\builders\post_processing_builder.py"", line 59, in build
    post_processing_config.batch_non_max_suppression)
  File ""D:\faster_rcnn\models\research\object_detection\builders\post_processing_builder.py"", line 107, in _build_non_max_suppressor
    use_cpu_nms=nms_config.use_cpu_nms)
AttributeError: use_cpu_nms

======================================================================
ERROR: test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul (__main__.ModelBuilderTF2Test)
test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul (__main__.ModelBuilderTF2Test)
test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul(use_matmul_crop_and_resize=True, enable_mask_prediction=False)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""C:\Users\deep-user\.conda\envs\tensorflow2\lib\site-packages\absl\testing\parameterized.py"", line 263, in bound_param_test
    test_method(self, **testcase_params)
  File ""D:\faster_rcnn\models\research\object_detection\builders\model_builder_test.py"", line 262, in test_create_faster_rcnn_models_from_config
    model = model_builder.build(model_proto, is_training=True)
  File ""D:\faster_rcnn\models\research\object_detection\builders\model_builder.py"", line 1062, in build
    add_summaries)
  File ""D:\faster_rcnn\models\research\object_detection\builders\model_builder.py"", line 663, in _build_faster_rcnn_model
    ) = post_processing_builder.build(frcnn_config.second_stage_post_processing)
  File ""D:\faster_rcnn\models\research\object_detection\builders\post_processing_builder.py"", line 59, in build
    post_processing_config.batch_non_max_suppression)
  File ""D:\faster_rcnn\models\research\object_detection\builders\post_processing_builder.py"", line 107, in _build_non_max_suppressor
    use_cpu_nms=nms_config.use_cpu_nms)
AttributeError: use_cpu_nms

======================================================================
ERROR: test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul (__main__.ModelBuilderTF2Test)
test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul (__main__.ModelBuilderTF2Test)
test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul(use_matmul_crop_and_resize=False, enable_mask_prediction=True)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""C:\Users\deep-user\.conda\envs\tensorflow2\lib\site-packages\absl\testing\parameterized.py"", line 263, in bound_param_test
    test_method(self, **testcase_params)
  File ""D:\faster_rcnn\models\research\object_detection\builders\model_builder_test.py"", line 262, in test_create_faster_rcnn_models_from_config
    model = model_builder.build(model_proto, is_training=True)
  File ""D:\faster_rcnn\models\research\object_detection\builders\model_builder.py"", line 1062, in build
    add_summaries)
  File ""D:\faster_rcnn\models\research\object_detection\builders\model_builder.py"", line 663, in _build_faster_rcnn_model
    ) = post_processing_builder.build(frcnn_config.second_stage_post_processing)
  File ""D:\faster_rcnn\models\research\object_detection\builders\post_processing_builder.py"", line 59, in build
    post_processing_config.batch_non_max_suppression)
  File ""D:\faster_rcnn\models\research\object_detection\builders\post_processing_builder.py"", line 107, in _build_non_max_suppressor
    use_cpu_nms=nms_config.use_cpu_nms)
AttributeError: use_cpu_nms

======================================================================
ERROR: test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul (__main__.ModelBuilderTF2Test)
test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul (__main__.ModelBuilderTF2Test)
test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul(use_matmul_crop_and_resize=True, enable_mask_prediction=True)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""C:\Users\deep-user\.conda\envs\tensorflow2\lib\site-packages\absl\testing\parameterized.py"", line 263, in bound_param_test
    test_method(self, **testcase_params)
  File ""D:\faster_rcnn\models\research\object_detection\builders\model_builder_test.py"", line 262, in test_create_faster_rcnn_models_from_config
    model = model_builder.build(model_proto, is_training=True)
  File ""D:\faster_rcnn\models\research\object_detection\builders\model_builder.py"", line 1062, in build
    add_summaries)
  File ""D:\faster_rcnn\models\research\object_detection\builders\model_builder.py"", line 663, in _build_faster_rcnn_model
    ) = post_processing_builder.build(frcnn_config.second_stage_post_processing)
  File ""D:\faster_rcnn\models\research\object_detection\builders\post_processing_builder.py"", line 59, in build
    post_processing_config.batch_non_max_suppression)
  File ""D:\faster_rcnn\models\research\object_detection\builders\post_processing_builder.py"", line 107, in _build_non_max_suppressor
    use_cpu_nms=nms_config.use_cpu_nms)
AttributeError: use_cpu_nms

======================================================================
ERROR: test_create_rfcn_model_from_config (__main__.ModelBuilderTF2Test)
test_create_rfcn_model_from_config (__main__.ModelBuilderTF2Test)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""D:\faster_rcnn\models\research\object_detection\builders\model_builder_test.py"", line 282, in test_create_rfcn_model_from_config
    model = model_builder.build(model_proto, is_training=True)
  File ""D:\faster_rcnn\models\research\object_detection\builders\model_builder.py"", line 1062, in build
    add_summaries)
  File ""D:\faster_rcnn\models\research\object_detection\builders\model_builder.py"", line 663, in _build_faster_rcnn_model
    ) = post_processing_builder.build(frcnn_config.second_stage_post_processing)
  File ""D:\faster_rcnn\models\research\object_detection\builders\post_processing_builder.py"", line 59, in build
    post_processing_config.batch_non_max_suppression)
  File ""D:\faster_rcnn\models\research\object_detection\builders\post_processing_builder.py"", line 107, in _build_non_max_suppressor
    use_cpu_nms=nms_config.use_cpu_nms)
AttributeError: use_cpu_nms

======================================================================
ERROR: test_create_ssd_fpn_model_from_config (__main__.ModelBuilderTF2Test)
test_create_ssd_fpn_model_from_config (__main__.ModelBuilderTF2Test)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""D:\faster_rcnn\models\research\object_detection\builders\model_builder_test.py"", line 220, in test_create_ssd_fpn_model_from_config
    model = model_builder.build(model_proto, is_training=True)
  File ""D:\faster_rcnn\models\research\object_detection\builders\model_builder.py"", line 1062, in build
    add_summaries)
  File ""D:\faster_rcnn\models\research\object_detection\builders\model_builder.py"", line 402, in _build_ssd_model
    ssd_config.post_processing)
  File ""D:\faster_rcnn\models\research\object_detection\builders\post_processing_builder.py"", line 59, in build
    post_processing_config.batch_non_max_suppression)
  File ""D:\faster_rcnn\models\research\object_detection\builders\post_processing_builder.py"", line 107, in _build_non_max_suppressor
    use_cpu_nms=nms_config.use_cpu_nms)
AttributeError: use_cpu_nms

======================================================================
ERROR: test_create_ssd_models_from_config (__main__.ModelBuilderTF2Test)
test_create_ssd_models_from_config (__main__.ModelBuilderTF2Test)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""D:\faster_rcnn\models\research\object_detection\builders\model_builder_test.py"", line 212, in test_create_ssd_models_from_config
    model = model_builder.build(model_proto, is_training=True)
  File ""D:\faster_rcnn\models\research\object_detection\builders\model_builder.py"", line 1062, in build
    add_summaries)
  File ""D:\faster_rcnn\models\research\object_detection\builders\model_builder.py"", line 402, in _build_ssd_model
    ssd_config.post_processing)
  File ""D:\faster_rcnn\models\research\object_detection\builders\post_processing_builder.py"", line 59, in build
    post_processing_config.batch_non_max_suppression)
  File ""D:\faster_rcnn\models\research\object_detection\builders\post_processing_builder.py"", line 107, in _build_non_max_suppressor
    use_cpu_nms=nms_config.use_cpu_nms)
AttributeError: use_cpu_nms

----------------------------------------------------------------------
Ran 20 tests in 2.246s

FAILED (errors=11, skipped=1)
 

## 6. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
 
- TensorFlow installed from (source or binary): tensorflow installed using ""python -m pip install --use-feature=2020-resolver ."" as described in ""https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2.md""
- TensorFlow version: 2.4.0-dev20200907
- Python version: 3.6

- CUDA/cuDNN version: 10.1
- GPU model and memory: NVIDIA Quadro RTX4000 8Gb


",MediavoiceSrL,b'models:research type:bug',2020-09-08T14:14:15Z,2020-09-15T09:51:15Z,,,,,,,
9202,gpuoptions in ConfigProto is not applied properly while running transformer model.,"# Prerequisites

Please answer the following questions for yourself before submitting an issue.

- [ ] I am using the latest TensorFlow Model Garden release and TensorFlow 2.
- [x] I am reporting the issue to the correct repository. (Model Garden official or research directory)
- [x] I checked to make sure that this issue has not been filed already.

## 1. The entire URL of the file you are using

https://github.com/tensorflow/models/tree/v1.13.0/official/transformer

## 2. Describe the bug

I want to add gpuoptions through ConfigProto such as ""allow_growth"" or ""per_process_gpu_memory_fraction"". I manually add this options into the transformer_main.py. Transformer is implemented via tf.Estimator so I followed Estimator API to insert ConfigProto. However, it is not applied.
Here is my code
![image](https://user-images.githubusercontent.com/20127356/92301385-65340280-ef9e-11ea-81a4-66e7571c6915.png)
 
After doing it, model training takes up the whole GPU memory which is supposed to take up only around 6GB. (base model)

## 3. Steps to reproduce

Just insert codes I attached in ""2. Describe the bug"" and run ""base"" transformer model and check gpu memory consumption using ""nvidia-smi -l 1"".

## 4. Expected behavior

It should have taken up the gpu memory only around 6GB.

## 5. Additional context

Include any logs that would be helpful to diagnose the problem.

## 6. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- Mobile device name if the issue happens on a mobile device:
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): 1.13.1
- Python version: 3.7
- Bazel version (if compiling from source): 0.21.0
- GCC/Compiler version (if compiling from source): 7.4.0
- CUDA/cuDNN version: 10.0 / 7
- GPU model and memory: NVIDIA Tesla V100, 32GB

<!-- 
Collect system information using our environment capture script.
https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can also obtain the TensorFlow version with:

1. TensorFlow 1.0
`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

2. TensorFlow 2.0
`python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`
-->
",gangmuk,b'models:official type:bug',2020-09-05T08:41:01Z,2020-09-25T19:45:49Z,,,,,,,
9193,there has the bug when use keras,"https://github.com/tensorflow/models/blob/f2c76e41f668b30cc6714ed8a866c07cc2f2275a/official/nlp/modeling/networks/bert_encoder.py#L215
The right code should be:
```
def get_config(self):
    base_config = super(TransformerEncoder, self).get_config()
    return dict(list(base_config.items()) + list(self._config_dict.items()))
```
tf.keras.models.load_model(
    filepath, custom_objects=None, compile=True, options=None
)
The api should work fine with this code rewrite",ImMrMa,b'models:official type:bug',2020-09-03T07:55:54Z,2020-09-06T06:22:55Z,,,,,,,
9186,"TypeError: ('Not JSON Serializable:', tf.float32)","# Prerequisites

Please answer the following questions for yourself before submitting an issue.

- [yes] I am using the latest TensorFlow Model Garden release and TensorFlow 2.
- [yes] I am reporting the issue to the correct repository. (Model Garden official or research directory)
- [yes] I checked to make sure that this issue has not been filed already.

## 1. The entire URL of the file you are using

https://github.com/tensorflow/models/tree/master/official/nlp/transformer/transformer_main.py

## 2. Describe the bug
I need a "".pb"" model(savedModel) for tf.serving, not just a "".ckpt"" model created by save_weights_only=TRUE.
When changed the ""save_weights_only"" option(in line 418) from ""True"" to ""False"",
the error occured: TypeError: ('Not JSON Serializable:', tf.float32)
![image](https://user-images.githubusercontent.com/7539692/91956469-45e76c00-ed37-11ea-8c1a-f215d0b2f063.png)


## 3. Steps to reproduce

I just ran the code in the URL above following its example tutorial. 
Two params were changed: hidden_size=256(default 512) AND filter_size=512(default 2048)
With the above configuration, weights could be saved successfully with the default ""save_weights_only=True"".

## 4. Expected behavior

if save_weights_only=False, a savedModel(not ckpt) would be generated.

## 5. Additional context

pycharm logs:

> 2020-09-02 07:46:07.054060: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
I0902 07:47:15.653520 140510663464768 keras_utils.py:122] TimeHistory: 87.05 seconds, 2352.78 examples/second between steps 0 and 100
2020-09-02 07:47:19.791337: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.
**INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(None, None, 256), dtype=tf.float32, name='inputs'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fc97e2fcc88>), {}).**
I0902 07:47:26.516451 140510663464768 def_function.py:1038] Unsupported signature for serialization: ((TensorSpec(shape=(None, None, 256), dtype=tf.float32, name='inputs'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fc97e2fcc88>), {}).
**INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(None, None), dtype=tf.int64, name='inputs'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fc97e7d0d68>), {}).**
I0902 07:47:26.516770 140510663464768 def_function.py:1038] Unsupported signature for serialization: ((TensorSpec(shape=(None, None), dtype=tf.int64, name='inputs'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fc97e7d0d68>), {}).
INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(None, None), dtype=tf.int64, name='inputs'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fc97e7e5a20>), {}).
I0902 07:47:26.516961 140510663464768 def_function.py:1038] Unsupported signature for serialization: ((TensorSpec(shape=(None, None), dtype=tf.int64, name='inputs'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fc97e7e5a20>), {}).
INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(None, None, 256), dtype=tf.float32, name='inputs'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fc97e30d860>), {}).
I0902 07:47:26.517098 140510663464768 def_function.py:1038] Unsupported signature for serialization: ((TensorSpec(shape=(None, None, 256), dtype=tf.float32, name='inputs'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fc97e30d860>), {}).
INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(None, None), dtype=tf.int64, name='inputs'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fc97e7e5a20>), {}).
I0902 07:47:27.793794 140510663464768 def_function.py:1038] Unsupported signature for serialization: ((TensorSpec(shape=(None, None), dtype=tf.int64, name='inputs'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fc97e7e5a20>), {}).
INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(None, None, 256), dtype=tf.float32, name='inputs'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fc97e30d860>), {}).
I0902 07:47:27.794195 140510663464768 def_function.py:1038] Unsupported signature for serialization: ((TensorSpec(shape=(None, None, 256), dtype=tf.float32, name='inputs'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fc97e30d860>), {}).
INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(None, None, 256), dtype=tf.float32, name='inputs'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fc97e2fcc88>), {}).
I0902 07:47:27.794377 140510663464768 def_function.py:1038] Unsupported signature for serialization: ((TensorSpec(shape=(None, None, 256), dtype=tf.float32, name='inputs'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fc97e2fcc88>), {}).
INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(None, None), dtype=tf.int64, name='inputs'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fc97e7d0d68>), {}).
I0902 07:47:27.794553 140510663464768 def_function.py:1038] Unsupported signature for serialization: ((TensorSpec(shape=(None, None), dtype=tf.int64, name='inputs'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fc97e7d0d68>), {}).
INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(None, None, 256), dtype=tf.float32, name='inputs'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fc97e2fcc88>), {}).
I0902 07:47:27.794695 140510663464768 def_function.py:1038] Unsupported signature for serialization: ((TensorSpec(shape=(None, None, 256), dtype=tf.float32, name='inputs'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fc97e2fcc88>), {}).
INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(None, None), dtype=tf.int64, name='inputs'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fc97e7d0d68>), {}).
I0902 07:47:27.794836 140510663464768 def_function.py:1038] Unsupported signature for serialization: ((TensorSpec(shape=(None, None), dtype=tf.int64, name='inputs'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fc97e7d0d68>), {}).
INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(None, None, 256), dtype=tf.float32, name='inputs'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fc97e2fcc88>), {}).
I0902 07:47:28.309843 140510663464768 def_function.py:1038] Unsupported signature for serialization: ((TensorSpec(shape=(None, None, 256), dtype=tf.float32, name='inputs'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fc97e2fcc88>), {}).
INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(None, None), dtype=tf.int64, name='inputs'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fc97e7d0d68>), {}).
I0902 07:47:28.310060 140510663464768 def_function.py:1038] Unsupported signature for serialization: ((TensorSpec(shape=(None, None), dtype=tf.int64, name='inputs'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fc97e7d0d68>), {}).
INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(None, None), dtype=tf.int64, name='inputs'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fc97e7e5a20>), {}).
I0902 07:47:28.310272 140510663464768 def_function.py:1038] Unsupported signature for serialization: ((TensorSpec(shape=(None, None), dtype=tf.int64, name='inputs'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fc97e7e5a20>), {}).
INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(None, None, 256), dtype=tf.float32, name='inputs'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fc97e30d860>), {}).
I0902 07:47:28.310407 140510663464768 def_function.py:1038] Unsupported signature for serialization: ((TensorSpec(shape=(None, None, 256), dtype=tf.float32, name='inputs'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fc97e30d860>), {}).
INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(None, None), dtype=tf.int64, name='inputs'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fc97e7e5a20>), {}).
I0902 07:47:28.359903 140510663464768 def_function.py:1038] Unsupported signature for serialization: ((TensorSpec(shape=(None, None), dtype=tf.int64, name='inputs'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fc97e7e5a20>), {}).
INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(None, None, 256), dtype=tf.float32, name='inputs'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fc97e30d860>), {}).
I0902 07:47:28.360061 140510663464768 def_function.py:1038] Unsupported signature for serialization: ((TensorSpec(shape=(None, None, 256), dtype=tf.float32, name='inputs'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fc97e30d860>), {}).
INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(None, None, 256), dtype=tf.float32, name='inputs'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fc97e2fcc88>), {}).
I0902 07:47:28.360238 140510663464768 def_function.py:1038] Unsupported signature for serialization: ((TensorSpec(shape=(None, None, 256), dtype=tf.float32, name='inputs'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fc97e2fcc88>), {}).
INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(None, None), dtype=tf.int64, name='inputs'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fc97e7d0d68>), {}).
I0902 07:47:28.360367 140510663464768 def_function.py:1038] Unsupported signature for serialization: ((TensorSpec(shape=(None, None), dtype=tf.int64, name='inputs'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fc97e7d0d68>), {}).
INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(None, None, 256), dtype=tf.float32, name='inputs'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fc97e2fcc88>), {}).
I0902 07:47:28.360511 140510663464768 def_function.py:1038] Unsupported signature for serialization: ((TensorSpec(shape=(None, None, 256), dtype=tf.float32, name='inputs'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fc97e2fcc88>), {}).
INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(None, None), dtype=tf.int64, name='inputs'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fc97e7d0d68>), {}).
I0902 07:47:28.360628 140510663464768 def_function.py:1038] Unsupported signature for serialization: ((TensorSpec(shape=(None, None), dtype=tf.int64, name='inputs'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fc97e7d0d68>), {}).
Traceback (most recent call last):
  File ""/home/xxx/pycharm_proj/models-master/official/nlp/transformer/transformer_main.py"", line 628, in <module>
    app.run(main)
  File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""/home/xxx/pycharm_proj/models-master/official/nlp/transformer/transformer_main.py"", line 609, in main
    task.train()
  File ""/home/xxx/pycharm_proj/models-master/official/nlp/transformer/transformer_main.py"", line 437, in train
    verbose=(2 if flags_obj.enable_time_history else 1))
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py"", line 108, in _method_wrapper
    return method(self, *args, **kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py"", line 1137, in fit
    callbacks.on_epoch_end(epoch, epoch_logs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py"", line 412, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py"", line 1249, in on_epoch_end
    self._save_model(epoch=epoch, logs=logs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py"", line 1313, in _save_model
    self.model.save(filepath, overwrite=True, options=self._options)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py"", line 1979, in save
    signatures, options)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/save.py"", line 134, in save_model
    signatures, options)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/saved_model/save.py"", line 80, in save
    save_lib.save(model, filepath, signatures, options)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/save.py"", line 976, in save
    obj, export_dir, signatures, options, meta_graph_def)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/save.py"", line 1076, in _build_meta_graph
    asset_info.asset_index)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/save.py"", line 721, in _serialize_object_graph
    saveable_view.function_name_map)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/save.py"", line 761, in _write_object_proto
    metadata=obj._tracking_metadata)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py"", line 3011, in _tracking_metadata
    return self._trackable_saved_model_saver.tracking_metadata
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/saved_model/base_serialization.py"", line 54, in tracking_metadata
    return json_utils.Encoder().encode(self.python_properties)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/saved_model/json_utils.py"", line 44, in encode
    return super(Encoder, self).encode(_encode_tuple(obj))
  File ""/usr/lib/python3.6/json/encoder.py"", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File ""/usr/lib/python3.6/json/encoder.py"", line 257, in iterencode
    return _iterencode(o, 0)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/saved_model/json_utils.py"", line 41, in default
    return serialization.get_json_type(obj)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/serialization.py"", line 72, in get_json_type
    raise TypeError('Not JSON Serializable:', obj)
TypeError: ('Not JSON Serializable:', tf.float32)

## 6. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  Ubuntu 18.04.3 LTS
- Mobile device name if the issue happens on a mobile device:  None
- TensorFlow installed from (source or binary):  pip
- TensorFlow version (use command below):  tensorflow-gpu 2.3.0
- Python version:  3.6.8
- Bazel version (if compiling from source):  None
- GCC/Compiler version (if compiling from source):  None
- CUDA/cuDNN version:  CUDA 10.1   Driver Version: 430.50
- GPU model and memory:  one GTX1080TI, 11G memory

<!-- 
Collect system information using our environment capture script.
https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can also obtain the TensorFlow version with:

1. TensorFlow 1.0
`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

2. TensorFlow 2.0
`python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`
-->
",2020zyc,b'models:official type:bug',2020-09-02T08:26:47Z,2020-09-14T01:54:45Z,,,,,,,
9183,"[TF 2 Object Detection API] Unable to run evaluation - TypeError: expected str, bytes or os.PathLike object, not NoneType","# Prerequisites

Please answer the following questions for yourself before submitting an issue.

- [ Y ] I am using the latest TensorFlow Model Garden release and TensorFlow 2.
- [ Y ] I am reporting the issue to the correct repository. (Model Garden official or research directory)
- [ Y ] I checked to make sure that this issue has not already been filed.

## 1. The entire URL of the file you are using

https://github.com/tensorflow/models/blob/master/research/object_detection/model_main_tf2.py

## 2. Describe the bug

When I run model_main_tf2.py using the steps mentioned in the official guide [(here)](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_training_and_evaluation.md) and execute following code (I left out references to my local files):

```
python model_main_tf2.py \
--pipeline_config_path=C:/Users/User/Documents/TensorFlow/workspace/mgr_holes/pre-trained/faster_rcnn_resnet50_v1_640x640_coco17_tpu-8/pipeline.config \
--checkpoint_dir=models/faster_rcnn_resnet50_v1_640x640_coco17_tpu-8_groceries \
 --alsologtostderr 

```
The TF2 initializes correctly, load the model, latest checkpoint is loaded and then I get the below error message:

```
I0901 22:21:48.011265 49544 checkpoint_utils.py:134] Found new checkpoint at kodels/faster_rcnn_resnet50_v1_640x640_coco17_tpu-8_groceries\ckpt-30
Traceback (most recent call last):
  File ""model_main_tf2.py"", line 113, in <module>
    tf.compat.v1.app.run()
  File ""C:\Users\User\anaconda3\envs\Mgr_TF2_P8\lib\site-packages\tensorflow\python\platform\app.py"", line 40, in run
_run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""C:\Users\User\anaconda3\envs\Mgr_TF2_P8\lib\site-packages\absl\app.py"", line 300, in run
    _run_main(main, args)
  File ""C:\Users\User\anaconda3\envs\Mgr_TF2_P8\lib\site-packages\absl\app.py"", line 251, in _run_main
    sys.exit(main(argv))
  File ""model_main_tf2.py"", line 80, in main
    model_lib_v2.eval_continuously(
  File ""C:\Users\User\anaconda3\envs\Mgr_TF2_P8\lib\site-packages\object_detection\model_lib_v2.py"", line 974, in eval_continuously
    os.path.join(model_dir, 'eval', eval_name))
  File ""C:\Users\User\anaconda3\envs\Mgr_TF2_P8\lib\ntpath.py"", line 78, in join
    path = os.fspath(path)
TypeError: expected str, bytes or os.PathLike object, not NoneType
```

This error message is consistent across my 3 conda environments (on python 3.7, python 3.8 with TF 2.2 and python 3.8 with TF 2.3). I am able to execute the training just as expected but evaluation, no matter what model is used and what evaluation metric is specified in the config file, always fails on the below message.

## 3. Steps to reproduce

As stated above, the script which I execute is following the below template:

```
# From the tensorflow/models/research/ directory
PIPELINE_CONFIG_PATH=""XXXX/models/research/object_detection/configs/tf2/uhuru.config""
MODEL_DIR=""XXXX""
CHECKPOINT_DIR=${MODEL_DIR}
SAMPLE_1_OF_N_EVAL_EXAMPLES=1
nohup python XXXX/models/research/object_detection/model_main_tf2.py \
        --pipeline_config_path=${PIPELINE_CONFIG_PATH} \
        --model_dir=${MODEL_DIR} \
        --checkpoint_dir=${CHECKPOINT_DIR} \
        --alsologtostderr 
```

Below I have also attached example of one of the config files used during training and when trying to execute eval:

```
# Faster R-CNN with Resnet-50 (v1)
# Trained on COCO, initialized from Imagenet classification checkpoint

# Achieves -- mAP on COCO14 minival dataset.

# This config is TPU compatible.

model {
  faster_rcnn {
    num_classes: 4
    image_resizer {
      keep_aspect_ratio_resizer {
        min_dimension: 640
        max_dimension: 640
        pad_to_max_dimension: true
      }
    }
    feature_extractor {
      type: 'faster_rcnn_resnet50_keras'
      batch_norm_trainable: true
    }
    first_stage_anchor_generator {
      grid_anchor_generator {
        scales: [0.25, 0.5, 1.0, 2.0]
        aspect_ratios: [0.5, 1.0, 2.0]
        height_stride: 16
        width_stride: 16
      }
    }
    first_stage_box_predictor_conv_hyperparams {
      op: CONV
      regularizer {
        l2_regularizer {
          weight: 0.0
        }
      }
      initializer {
        truncated_normal_initializer {
          stddev: 0.01
        }
      }
    }
    first_stage_nms_score_threshold: 0.0
    first_stage_nms_iou_threshold: 0.7
    first_stage_max_proposals: 300
    first_stage_localization_loss_weight: 2.0
    first_stage_objectness_loss_weight: 1.0
    initial_crop_size: 14
    maxpool_kernel_size: 2
    maxpool_stride: 2
    second_stage_box_predictor {
      mask_rcnn_box_predictor {
        use_dropout: false
        dropout_keep_probability: 1.0
        fc_hyperparams {
          op: FC
          regularizer {
            l2_regularizer {
              weight: 0.0
            }
          }
          initializer {
            variance_scaling_initializer {
              factor: 1.0
              uniform: true
              mode: FAN_AVG
            }
          }
        }
        share_box_across_classes: true
      }
    }
    second_stage_post_processing {
      batch_non_max_suppression {
        score_threshold: 0.0
        iou_threshold: 0.6
        max_detections_per_class: 100
        max_total_detections: 300
      }
      score_converter: SOFTMAX
    }
    second_stage_localization_loss_weight: 2.0
    second_stage_classification_loss_weight: 1.0
    use_static_shapes: true
    use_matmul_crop_and_resize: true
    clip_anchors_to_image: true
    use_static_balanced_label_sampler: true
    use_matmul_gather_in_matcher: true
  }
}

train_config: {
  batch_size: 1
  sync_replicas: true
  startup_delay_steps: 0
  replicas_to_aggregate: 8
  num_steps: 250000
  optimizer {
    momentum_optimizer: {
      learning_rate: {
        cosine_decay_learning_rate {
          learning_rate_base: .04
          total_steps: 25000
          warmup_learning_rate: .013333
          warmup_steps: 2000
        }
      }
      momentum_optimizer_value: 0.9
    }
    use_moving_average: false
  }
  fine_tune_checkpoint_version: V2
  fine_tune_checkpoint: ""C:/Users/User/Documents/TensorFlow/workspace/mgr_holes/pre-trained/faster_rcnn_resnet50_v1_640x640_coco17_tpu-8_groceries/checkpoint/ckpt-0""
  fine_tune_checkpoint_type: ""detection""
  data_augmentation_options {
    random_horizontal_flip {
    }
  }

  max_number_of_boxes: 100
  unpad_groundtruth_tensors: false
  use_bfloat16: false  # works only on TPUs
}

train_input_reader: {
  label_map_path: ""C:/Users/User/Documents/TensorFlow/workspace/mgr_training_demo/annotations/label_map.pbtxt""
  tf_record_input_reader {
    input_path: ""C:/Users/User/Documents/TensorFlow/workspace/mgr_training_demo/annotations/train.record""
  }
}

eval_config: {
  metrics_set: ""oid_V2_detection_metrics""
  use_moving_averages: false
  batch_size: 1;
}

eval_input_reader: {
  label_map_path: ""C:/Users/User/Documents/TensorFlow/workspace/mgr_training_demo/annotations/label_map.pbtxt""
  shuffle: true
  num_epochs: 1
  tf_record_input_reader {
    input_path: ""C:/Users/User/Documents/TensorFlow/workspace/mgr_holes/annotations/test.record""
  }
}

```
## 4. Expected behavior

I expect the evaluation process to start and print evaluation metrics (like mAP) to the Tensorboard. Currently, even during the training, no evaluation data is visible.

## 5. Additional context

Training works perfectly as expected. Evaluation cannot be launched and even when eval options are added when launching model_main_tf2.py, no evaluation metrics are printed to the Tensorflow.
Only loss, steps and train images are visible in the Tensorboard.

## 6. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- Mobile device name if the issue happens on a mobile device:
- TensorFlow installed from (source or binary): TF installed in conda environment via pip
- TensorFlow version (use command below): v2.3.0-rc2-23-gb36436b087 2.3.0
- Python version: 3.8
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 10.1.243
- GPU model and memory: NVIDIA GeForce RTX 2060

<!-- 
Collect system information using our environment capture script.
https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can also obtain the TensorFlow version with:

1. TensorFlow 1.0
`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

2. TensorFlow 2.0
`python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`
-->
",Panaroja,b'models:research type:bug',2020-09-01T22:03:53Z,2020-09-01T22:41:41Z,,,,,,,
9181,W0901 18:59:43.630363 140028609734464 deprecation.py:317] From /home/ayennam/.virtualenvs/sensable3_8/lib/python3.8/site-packages/object_detection/inputs.py:259: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating: Use `tf.cast` instead.,"

## 6. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):18.04
- Mobile device name if the issue happens on a mobile device:
- TensorFlow installed from (source or binary):na
- TensorFlow version (use command below):2.2.0
- Python version:3.8
- Bazel version (if compiling from source):na
- GCC/Compiler version (if compiling from source):na
- CUDA/cuDNN version: 10.1/7.6.5
- GPU model and memory: 2080ti 





",angyee,b'models:research stalled stat:awaiting response type:bug',2020-09-01T13:40:08Z,2020-10-06T05:09:27Z,,,,,,,
9179,DELG export model problem,"# Trianing

`python3 train.py \
  --train_file_pattern=gldv2_dataset/tfrecord/train* \
  --validation_file_pattern=gldv2_dataset/tfrecord/validation* \
  --imagenet_checkpoint=resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5 \
  --dataset_version=gld_v2_clean \
  --logdir=gldv2_training/ \
  --delg_global_features`

# Export model
`python3 model/export_global_model.py --ckpt_path=gldv3_training_delg/delf_weights --export_path=delg_gldv3_model_global --input_scales_list=0.70710677,1.0,1.4142135 --multi_scale_pool_type=sum --normalize_global_descriptor
`

Below is my export model logs.

`2020-09-01 17:58:00.038762: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 11210 MB memory) -> physical GPU (device: 1, name: TITAN Xp COLLECTORS EDITION, pci bus id: 0000:08:00.0, compute capability: 6.1)
Checkpoint loaded from  gldv3_training_delg/delf_weights
multi_scale_pool_type is  sum
multi_scale_pool_type is  sum
WARNING:tensorflow:Skipping full serialization of Keras layer <delf.python.training.model.delf_model.Delf object at 0x7f38f3b58c88>, because it is not built.
W0901 17:58:03.413664 139884055152384 save_impl.py:78] Skipping full serialization of Keras layer <delf.python.training.model.delf_model.Delf object at 0x7f38f3b58c88>, because it is not built.
WARNING:tensorflow:Skipping full serialization of Keras layer <delf.python.training.model.resnet50.ResNet50 object at 0x7f38e0369780>, because it is not built.
W0901 17:58:03.413844 139884055152384 save_impl.py:78] Skipping full serialization of Keras layer <delf.python.training.model.resnet50.ResNet50 object at 0x7f38e0369780>, because it is not built.
WARNING:tensorflow:Skipping full serialization of Keras layer <delf.python.training.model.delf_model.AttentionModel object at 0x7f38e024ab38>, because it is not built.
W0901 17:58:03.413996 139884055152384 save_impl.py:78] Skipping full serialization of Keras layer <delf.python.training.model.delf_model.AttentionModel object at 0x7f38e024ab38>, because it is not built.
WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.pooling.AveragePooling2D object at 0x7f38e024a908>, because it is not built.
W0901 17:58:06.836568 139884055152384 save_impl.py:78] Skipping full serialization of Keras layer <tensorflow.python.keras.layers.pooling.AveragePooling2D object at 0x7f38e024a908>, because it is not built.
WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f38e024ae80>, because it is not built.
W0901 17:58:06.836720 139884055152384 save_impl.py:78] Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f38e024ae80>, because it is not built.
WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f38e0257198>, because it is not built.
W0901 17:58:06.836797 139884055152384 save_impl.py:78] Skipping full serialization of Keras layer <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f38e0257198>, because it is not built.
WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f38e0257400>, because it is not built.
W0901 17:58:06.836868 139884055152384 save_impl.py:78] Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f38e0257400>, because it is not built.
WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Activation object at 0x7f38e0257668>, because it is not built.
W0901 17:58:06.836937 139884055152384 save_impl.py:78] Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Activation object at 0x7f38e0257668>, because it is not built.
2020-09-01 17:58:06.927586: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.
INFO:tensorflow:Assets written to: delg_gldv3_model_global/assets
I0901 17:58:12.971750 139884055152384 builder_impl.py:775] Assets written to: delg_gldv3_model_global/assets
WARNING:tensorflow:Unresolved object in checkpoint: (root).cosine_weights
W0901 17:58:13.241488 139884055152384 util.py:150] Unresolved object in checkpoint: (root).cosine_weights
WARNING:tensorflow:Unresolved object in checkpoint: (root).scale_factor
W0901 17:58:13.241673 139884055152384 util.py:150] Unresolved object in checkpoint: (root).scale_factor
WARNING:tensorflow:Unresolved object in checkpoint: (root).attn_classification
W0901 17:58:13.241752 139884055152384 util.py:150] Unresolved object in checkpoint: (root).attn_classification
WARNING:tensorflow:Unresolved object in checkpoint: (root).backbone.subsampling_layer
W0901 17:58:13.241827 139884055152384 util.py:150] Unresolved object in checkpoint: (root).backbone.subsampling_layer
WARNING:tensorflow:Unresolved object in checkpoint: (root).backbone.embedding_layer
W0901 17:58:13.241896 139884055152384 util.py:150] Unresolved object in checkpoint: (root).backbone.embedding_layer
WARNING:tensorflow:Unresolved object in checkpoint: (root).attn_classification.kernel
W0901 17:58:13.241961 139884055152384 util.py:150] Unresolved object in checkpoint: (root).attn_classification.kernel
WARNING:tensorflow:Unresolved object in checkpoint: (root).attn_classification.bias
W0901 17:58:13.241998 139884055152384 util.py:150] Unresolved object in checkpoint: (root).attn_classification.bias
WARNING:tensorflow:Unresolved object in checkpoint: (root).backbone.embedding_layer.kernel
W0901 17:58:13.242039 139884055152384 util.py:150] Unresolved object in checkpoint: (root).backbone.embedding_layer.kernel
WARNING:tensorflow:Unresolved object in checkpoint: (root).backbone.embedding_layer.bias
W0901 17:58:13.242076 139884055152384 util.py:150] Unresolved object in checkpoint: (root).backbone.embedding_layer.bias
WARNING:tensorflow:Unresolved object in checkpoint: (root).attention.conv1.kernel
W0901 17:58:13.242113 139884055152384 util.py:150] Unresolved object in checkpoint: (root).attention.conv1.kernel
WARNING:tensorflow:Unresolved object in checkpoint: (root).attention.conv1.bias
W0901 17:58:13.242150 139884055152384 util.py:150] Unresolved object in checkpoint: (root).attention.conv1.bias
WARNING:tensorflow:Unresolved object in checkpoint: (root).attention.bn_conv1.axis
W0901 17:58:13.242186 139884055152384 util.py:150] Unresolved object in checkpoint: (root).attention.bn_conv1.axis
WARNING:tensorflow:Unresolved object in checkpoint: (root).attention.bn_conv1.gamma
W0901 17:58:13.242222 139884055152384 util.py:150] Unresolved object in checkpoint: (root).attention.bn_conv1.gamma
WARNING:tensorflow:Unresolved object in checkpoint: (root).attention.bn_conv1.beta
W0901 17:58:13.242258 139884055152384 util.py:150] Unresolved object in checkpoint: (root).attention.bn_conv1.beta
WARNING:tensorflow:Unresolved object in checkpoint: (root).attention.bn_conv1.moving_mean
W0901 17:58:13.242294 139884055152384 util.py:150] Unresolved object in checkpoint: (root).attention.bn_conv1.moving_mean
WARNING:tensorflow:Unresolved object in checkpoint: (root).attention.bn_conv1.moving_variance
W0901 17:58:13.242329 139884055152384 util.py:150] Unresolved object in checkpoint: (root).attention.bn_conv1.moving_variance
WARNING:tensorflow:Unresolved object in checkpoint: (root).attention.conv2.kernel
W0901 17:58:13.242365 139884055152384 util.py:150] Unresolved object in checkpoint: (root).attention.conv2.kernel
WARNING:tensorflow:Unresolved object in checkpoint: (root).attention.conv2.bias
W0901 17:58:13.242400 139884055152384 util.py:150] Unresolved object in checkpoint: (root).attention.conv2.bias
WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.
W0901 17:58:13.242486 139884055152384 util.py:158] A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.`

# Extract Features
` python ../examples/extract_features.py --config_path ../delg/delg_gld_config.pbtxt --list_images_path ../examples/list_images.txt --output_dir ../delg/features
`

Below is my extract features error logs.

`2020-09-01 18:00:25.127793: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
Reading list of images...
done! Found 2 images
2020-09-01 18:00:26.965288: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 11210 MB memory) -> physical GPU (device: 1, name: TITAN Xp COLLECTORS EDITION, pci bus id: 0000:08:00.0, compute capability: 6.1)
Traceback (most recent call last):
  File ""../examples/extract_features.py"", line 144, in <module>
    app.run(main=main, argv=[sys.argv[0]] + unparsed)
  File ""/home/ss/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/platform/app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""/home/ss/anaconda3/envs/tf/lib/python3.6/site-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/home/ss/anaconda3/envs/tf/lib/python3.6/site-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""../examples/extract_features.py"", line 81, in main
    extractor_fn = extractor.MakeExtractor(config)
  File ""/home/ss/ai-competition/models/research/delf/delf/python/examples/extractor.py"", line 132, in MakeExtractor
    model = model.prune(feeds=feeds, fetches=fetches)
AttributeError: '_UserObject' object has no attribute 'prune'`

How to solve this error? Thanks in advance.
",ChenYingpeng,b'models:research type:bug',2020-09-01T10:03:10Z,2020-09-11T16:47:48Z,,,,,,,
9175,Converting SSD MobileNet v2 320x320 From Saved Model to TFLite - tensorflow.lite.python.convert.ConverterError: requires all operands and results to have compatible element types,"# Prerequisites

Please answer the following questions for yourself before submitting an issue.

- [x] I am using the latest TensorFlow Model Garden release and TensorFlow 2.
- [x] I am reporting the issue to the correct repository. (Model Garden official or research directory)
- [x] I checked to make sure that this issue has not already been filed.

## 1. The entire URL of the file you are using

Python file below which is based upon https://www.tensorflow.org/lite/convert/python_api#converting_a_savedmodel_

## 2. Describe the bug

When I am trying to convert the `SSD MobileNet v2 320x320` from `saved_model` to a `TFLite file`, it gives me an error when calling `converter.convert()` (Python file under the Steps to Reproduce section) `ConverterError: <unknown>:0: error: loc(""Func/StatefulPartitionedCall/input/_0""): requires all operands and results to have compatible element types`

```
raceback (most recent call last):
  File ""/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/lite/python/convert.py"", line 196, in toco_convert_protos
    model_str = wrap_toco.wrapped_toco_convert(model_flags_str,
  File ""/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/lite/python/wrap_toco.py"", line 32, in wrapped_toco_convert
    return _pywrap_toco_api.TocoConvert(
Exception: <unknown>:0: error: loc(""Func/StatefulPartitionedCall/input/_0""): requires all operands and results to have compatible element types
<unknown>:0: note: loc(""Func/StatefulPartitionedCall/input/_0""): see current operation: %1 = ""tf.Identity""(%arg0) {device = """"} : (tensor<1x?x?x3x!tf.quint8>) -> tensor<1x?x?x3xui8>


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/Users/Data/TFOD/tf2convertTest.py"", line 7, in <module>
    tflite_quant_model = converter.convert()
  File ""/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/lite/python/lite.py"", line 1076, in convert
    return super(TFLiteConverterV2, self).convert()
  File ""/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/lite/python/lite.py"", line 899, in convert
    return super(TFLiteFrozenGraphConverterV2,
  File ""/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/lite/python/lite.py"", line 629, in convert
    result = _toco_convert_impl(
  File ""/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/lite/python/convert.py"", line 569, in toco_convert_impl
    data = toco_convert_protos(
  File ""/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/lite/python/convert.py"", line 202, in toco_convert_protos
    raise ConverterError(str(e))
tensorflow.lite.python.convert.ConverterError: <unknown>:0: error: loc(""Func/StatefulPartitionedCall/input/_0""): requires all operands and results to have compatible element types
<unknown>:0: note: loc(""Func/StatefulPartitionedCall/input/_0""): see current operation: %1 = ""tf.Identity""(%arg0) {device = """"} : (tensor<1x?x?x3x!tf.quint8>) -> tensor<1x?x?x3xui8>
```

## 3. Steps to reproduce

I downloaded the [SSD MobileNet v2 320x320](http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_320x320_coco17_tpu-8.tar.gz) model from the TensorFlow Object Detection 2 API and wanted to test converting just the base model to a TFLite model, but when I run the following Python script, it gives the error that it `requires all operands and results to have compatible element types`.

Here is the Python File:

```
import tensorflow as tf

converter = tf.lite.TFLiteConverter.from_saved_model('ssd_mobilenet_v2_320x320_coco17_tpu-8/saved_model')
converter.optimizations = [tf.lite.Optimize.DEFAULT]
converter.experimental_new_converter = True
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]
tflite_model = converter.convert()
with tf.io.gfile.GFile('model.tflite', 'wb') as f:
  f.write(tflite_model)
```

## 4. Expected behavior

The base model should be able to convert to a TFLite without error and I have also tested with a custom trained model and both give the same error when using this same exact file to convert.

## 5. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Tested on both Windows 10 and MacOS 10.15.6
- Mobile device name if the issue happens on a mobile device: None
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.3.0
- Python version: 3.8.5
- Bazel version (if compiling from source): None
- GCC/Compiler version (if compiling from source): None
- CUDA/cuDNN version: None
- GPU model and memory: None

<!-- 
Collect system information using our environment capture script.
https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can also obtain the TensorFlow version with:

1. TensorFlow 1.0
`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

2. TensorFlow 2.0
`python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`
-->
",mihir-chauhan,b'models:research type:bug',2020-09-01T04:17:11Z,2020-09-02T07:34:45Z,,,,,,,
9169,TFLiteConverter (Saved Model -> TFLite) NameError: name 'graph_matcher' is not defined,"# Prerequisites

Please answer the following questions for yourself before submitting an issue.

- [x] I am using the latest TensorFlow Model Garden release and TensorFlow 2.
- [x] I am reporting the issue to the correct repository. (Model Garden official or research directory)
- [x] I checked to make sure that this issue has not already been filed.

## 1. The entire URL of the file you are using

https://github.com/tensorflow/models/blob/master/research/object_detection/export_tflite_ssd_graph.py

## 2. Describe the bug

When I use the export_tflite_ssd_graph.py file, it gives an error that `NameError: name 'graph_matcher' is not defined` when calling `input_pattern = graph_matcher.OpTypePattern(` in `File ""C:\Users\me\AppData\Roaming\Python\Python38\site-packages\object_detection\exporter.py"", line 100, in remove_nn`.

Here is the entire Traceback:

```
Traceback (most recent call last):
  File ""C:\models\research\object_detection\export_tflite_ssd_graph.py"", line 146, in <module>
    tf.app.run(main)
  File ""C:\Users\me\AppData\Roaming\Python\Python38\site-packages\tensorflow\python\platform\app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""C:\Users\me\AppData\Roaming\Python\Python38\site-packages\absl\app.py"", line 299, in run
    _run_main(main, args)
  File ""C:\Users\me\AppData\Roaming\Python\Python38\site-packages\absl\app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""C:\models\research\object_detection\export_tflite_ssd_graph.py"", line 139, in main
    export_tflite_ssd_graph_lib.export_tflite_graph(
  File ""C:\Users\me\AppData\Roaming\Python\Python38\site-packages\object_detection\export_tflite_ssd_graph_lib.py"", line 282, in export_tflite_graph
    exporter.rewrite_nn_resize_op(is_quantized)
  File ""C:\Users\me\AppData\Roaming\Python\Python38\site-packages\object_detection\exporter.py"", line 145, in rewrite_nn_resize_op
    while remove_nn():
  File ""C:\Users\me\AppData\Roaming\Python\Python38\site-packages\object_detection\exporter.py"", line 100, in remove_nn
    input_pattern = graph_matcher.OpTypePattern(
NameError: name 'graph_matcher' is not defined
```

## 3. Steps to reproduce

I am using `model_main_tf2.py` to train my model and then I use `exporter_main_v2` to convert the ckpt files to a saved model from which I then use `export_tflite_ssd_graph.py` and then would use `tflite_convert.exe` (if the bug were not there).

## 4. Expected behavior

The expected behavior is that it should run both python files without getting an error. Since `export_tflite_ssd_graph.py` gives an error of `NameError: name 'graph_matcher' is not defined`, I cannot use `tflite_convert.exe` because the first file didn't execute without errors

## 6. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- Mobile device name if the issue happens on a mobile device: None
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.3.0
- Python version: 3.8
- Bazel version (if compiling from source): None
- GCC/Compiler version (if compiling from source): None
- CUDA/cuDNN version: None
- GPU model and memory: No GPU

<!-- 
Collect system information using our environment capture script.
https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can also obtain the TensorFlow version with:

1. TensorFlow 1.0
`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

2. TensorFlow 2.0
`python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`
-->
",mihir-chauhan,b'models:research type:bug',2020-08-30T20:16:20Z,2020-09-04T15:35:03Z,,,,,,,
9147,Customize log_steps for object detection model,"I am using latest TF with the latest TF models. I am trying to run object detection models (Retinanet and maskrcnn). I want to check the performance after each step. That's why I put the flag --log_steps=1, but for some reason it's showing performance result after 100 steps. Then I tried to change the default value

/official/utils/flags/_benchmark.py

def define_log_steps():
  flags.DEFINE_integer(
      name=""log_steps"",
      default=1,
      help=""Frequency with which to log timing information with TimeHistory."")

But didn't work.

Any suggestions?",ashiqimranintel,b'models:official type:bug',2020-08-25T00:03:01Z,2020-08-25T04:12:05Z,,,,,,,
9126,ValueError: ssd_mobilenet_v2 is not supported. See `model_builder.py` for features extractors compatible with different versions of Tensorflow,"# Prerequisites

Please answer the following questions for yourself before submitting an issue.

- [x] I am using the latest TensorFlow Model Garden release and TensorFlow 2.
- [ ] I am reporting the issue to the correct repository. (Model Garden official or research directory)
- [ ] I checked to make sure that this issue has not already been filed.

## 1. The entire URL of the file you are using

https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf1_detection_zoo.md **ssd_mobilenet_v2_coco**
The same issue happened with **ssd_mobilenet_v1_coco** and **faster_rcnn_inception_v2_coco_2018_01_28**

## 2. Describe the bug

After issuing the comand 
**$ python train.py --logtostderr --train_dir=training/ --pipeline_config_path=training/ssd_mobilenet_v2_coco.config**

I get a Traceback:

Traceback (most recent call last):
  File ""train.py"", line 186, in <module>
    tf.app.run()
  File ""/home/quad/anaconda3/envs/gputest/lib/python3.6/site-packages/tensorflow/python/platform/app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""/home/quad/anaconda3/envs/gputest/lib/python3.6/site-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/home/quad/anaconda3/envs/gputest/lib/python3.6/site-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""/home/quad/anaconda3/envs/gputest/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py"", line 324, in new_func
    return func(*args, **kwargs)
  File ""train.py"", line 182, in main
    graph_hook_fn=graph_rewriter_fn)
  File ""/home/quad/tensorflow1/models/research/object_detection/legacy/trainer.py"", line 248, in train
    detection_model = create_model_fn()
  File ""/home/quad/tensorflow1/models/research/object_detection/builders/model_builder.py"", line 1062, in build
    add_summaries)
  File ""/home/quad/tensorflow1/models/research/object_detection/builders/model_builder.py"", line 369, in _build_ssd_model
    _check_feature_extractor_exists(ssd_config.feature_extractor.type)
  File ""/home/quad/tensorflow1/models/research/object_detection/builders/model_builder.py"", line 243, in _check_feature_extractor_exists
    'Tensorflow'.format(feature_extractor_type))
ValueError: ssd_mobilenet_v2 is not supported. See `model_builder.py` for features extractors compatible with different versions of Tensorflow

## 3. Steps to reproduce
1. Configure $PYTHONPATH with following:  $ export PYTHONPATH=$PYTHONPATH~/models:~/models/research:~/models/research/slim
2. Configure ~/models/research/object_detection/training/ssd_mobilenet_v2_coco.config with path to _test.record, train.record, label.pbtxt, num of examples, num of classes_
3. From directory ~/models/research/object_detection issue the comand: **$ python train.py --logtostderr --train_dir=training/ --pipeline_config_path=training/ssd_mobilenet_v2_coco.config**

## 4. Expected behavior

The network must start training process.

## 5. Additional context

Traceback (most recent call last):
  File ""train.py"", line 186, in <module>
    tf.app.run()
  File ""/home/quad/anaconda3/envs/gputest/lib/python3.6/site-packages/tensorflow/python/platform/app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""/home/quad/anaconda3/envs/gputest/lib/python3.6/site-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/home/quad/anaconda3/envs/gputest/lib/python3.6/site-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""/home/quad/anaconda3/envs/gputest/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py"", line 324, in new_func
    return func(*args, **kwargs)
  File ""train.py"", line 182, in main
    graph_hook_fn=graph_rewriter_fn)
  File ""/home/quad/tensorflow1/models/research/object_detection/legacy/trainer.py"", line 248, in train
    detection_model = create_model_fn()
  File ""/home/quad/tensorflow1/models/research/object_detection/builders/model_builder.py"", line 1062, in build
    add_summaries)
  File ""/home/quad/tensorflow1/models/research/object_detection/builders/model_builder.py"", line 369, in _build_ssd_model
    _check_feature_extractor_exists(ssd_config.feature_extractor.type)
  File ""/home/quad/tensorflow1/models/research/object_detection/builders/model_builder.py"", line 243, in _check_feature_extractor_exists
    'Tensorflow'.format(feature_extractor_type))
ValueError: ssd_mobilenet_v2 is not supported. See `model_builder.py` for features extractors compatible with different versions of Tensorflow

## 6. System information

- OS Platform and Distribution : Ubuntu 18.04
- TensorFlow installed from (source or binary): With CONDA, object_detection_tutorial.ipynb is working
- TensorFlow version (use command below): 2.2.0 (but the file train.py is set to use **tensorflow.compat.v1**)
- Python version: 3.6.10
- CUDA/cuDNN version: CUDA 10.1/ cuDNN 7.6.5
- GPU model and memory: NVIDIA GeForce 710

!PLEASE don`t link me to another issue, some of those links are looped and opened, which don`t help at all
Thank You
",Kosta404,b'models:research stat:awaiting response type:bug',2020-08-19T08:59:01Z,2020-09-11T12:28:04Z,,,,,,,
9121,AttributeError: 'AutoTrackable' object has no attribute 'output_shapes',"versions:
tensorflow - 2.3.0
conda - 4.8.4
python - 3.8.3
pip - 20.2.2

I am having an issue with getting a tensorflow python model to work jupyter. I am running a tutorial.ipynb file and only get one error toward the end


```
# In [19]

masking_model.output_shapes
AttributeError                            Traceback (most recent call last)
<ipython-input-19-31bf89ff98cf> in <module>
----> 1 masking_model.output_shapes

AttributeError: 'AutoTrackable' object has no attribute 'output_shapes'
```

I do not know how to get past this and seeing as this is the second to last code segment to execute it is rather frustrating",NFeruch,b'models:official stat:awaiting response type:bug',2020-08-18T02:24:53Z,2020-09-10T06:54:26Z,,,,,,,
9117,ValueError: Could not find matching function to call loaded from the SavedModel,"# Prerequisites

Please answer the following questions for yourself before submitting an issue.

- [ 1 ] I am using the latest TensorFlow Model Garden release and TensorFlow 2.
- [ 1 ] I am reporting the issue to the correct repository. (Model Garden official or research directory)
- [ 1 ] I checked to make sure that this issue has not been filed already.

## 1. The entire URL of the file you are using

https://github.com/tensorflow/models/tree/master/official/...

## 2. Describe the bug

I was using BERT to do text classification task. I have already trained the model. I used to use the ckpt to reload which is totally ok in code:
`
classifier_model = bert_models.classifier_model(
          bert_config, input_meta_data['num_labels'])[0]
checkpoint = tf.train.Checkpoint(model=classifier_model)
latest_checkpoint_file = (
          FLAGS.predict_checkpoint_path or
          tf.train.latest_checkpoint(FLAGS.model_dir))
assert latest_checkpoint_file
logging.info('Checkpoint file %s found and restoring from '
                   'checkpoint', latest_checkpoint_file)
checkpoint.restore(
          latest_checkpoint_file).assert_existing_objects_matched()
preds, _ = get_predictions_and_labels(
          strategy, classifier_model, eval_input_fn, return_probs=True)
`

When I want to use savedModel in the way of colab mentioned before:

`
reloaded_model = tf.saved_model.load(MODEL_PATH)
`

I get this error:
`
ValueError: Could not find matching function to call loaded from the SavedModel. Got:

      Positional arguments (3 total):
        * {'input_word_ids': <tf.Tensor 'inputs_2:0' shape=(None, 128) dtype=int32>, 'input_mask': <tf.Tensor 'inputs:0' shape=(None, 128) dtype=int32>, 'input_type_ids': <tf.Tensor 'inputs_1:0' shape=(None, 128) dtype=int32>}
        * False
        * None
      Keyword arguments: {}
 
    Expected these arguments to match one of the following 4 option(s):
    
    Option 1:
      Positional arguments (3 total):
        * [TensorSpec(shape=(None, 128), dtype=tf.int32, name='inputs/0'), TensorSpec(shape=(None, 128), dtype=tf.int32, name='inputs/1'), TensorSpec(shape=(None, 128), dtype=tf.int32, name='inputs/2')]
        * True
        * None
      Keyword arguments: {}
    
    Option 2:
      Positional arguments (3 total):
        * [TensorSpec(shape=(None, 128), dtype=tf.int32, name='inputs/0'), TensorSpec(shape=(None, 128), dtype=tf.int32, name='inputs/1'), TensorSpec(shape=(None, 128), dtype=tf.int32, name='inputs/2')]
        * False
        * None
      Keyword arguments: {}
    
    Option 3:
      Positional arguments (3 total):
        * [TensorSpec(shape=(None, 128), dtype=tf.int32, name='input_word_ids'), TensorSpec(shape=(None, 128), dtype=tf.int32, name='input_mask'), TensorSpec(shape=(None, 128), dtype=tf.int32, name='input_type_ids')]
        * True
        * None
      Keyword arguments: {}
    
    Option 4:
      Positional arguments (3 total):
        * [TensorSpec(shape=(None, 128), dtype=tf.int32, name='input_word_ids'), TensorSpec(shape=(None, 128), dtype=tf.int32, name='input_mask'), TensorSpec(shape=(None, 128), dtype=tf.int32, name='input_type_ids')]
        * False
        * None
      Keyword arguments: {}
`

## 3. Steps to reproduce

Steps to reproduce the behavior.

## 4. Expected behavior

A clear and concise description of what you expected to happen.

## 5. Additional context

Include any logs that would be helpful to diagnose the problem.

## 6. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):CentOs7
- Mobile device name if the issue happens on a mobile device:
- TensorFlow installed from (source or binary):tf-nightly
- TensorFlow version (use command below):
- Python version:py3.6
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:10.1
- GPU model and memory:GTX 1080

<!-- 
Collect system information using our environment capture script.
https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can also obtain the TensorFlow version with:

1. TensorFlow 1.0
`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

2. TensorFlow 2.0
`python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`
-->
",monologue1107,b'models:official type:bug',2020-08-17T06:52:43Z,2020-09-06T06:54:53Z,,,,,,,
9100,"Mean, std normalization inconsistent","# Prerequisites

Please answer the following questions for yourself before submitting an issue.

- [y] I am using the latest TensorFlow Model Garden release and TensorFlow 2.
- [y] I am reporting the issue to the correct repository. (Model Garden official or research directory)
- [y] I checked to make sure that this issue has not been filed already.

## 1. The entire URL of the file to debug:
https://github.com/tensorflow/models/blob/master/research/object_detection/model_lib_v2.py

## 2. Describe the bug:
The mean and std normalization of COCO images after preprocessing is still not in normal range in CenterNet. On `efficientdet_d0_coco17_tpu-32` behaviour is normal and preprocessing is giving close to 0 mean and 1 std. 
I have tried two ways to experiment with CenterNet by using `centernet_resnet_v1_50_fpn_512x512_coco17` config from the model zoo (without any checkpoint):

**1. By mentioning means and std in config:**
Means and stds taken as is from pre-trained model config file in the model zoo:
```
channel_means: [104.01362025, 114.03422265, 119.9165958 ]
channel_stds: [73.6027665 , 69.89082075, 70.9150767 ]
```
The mean and std of images _after_ normalization are computed from: https://github.com/tensorflow/models/blob/3f6fe2aa410d901aae8829597a65d084bffc20d3/research/object_detection/model_lib_v2.py#L598

```
features['image'].numpy().mean()
-115.607056
features['image'].numpy().std()
8.1939125
```
Notice the very negative value of mean and large value of std (batch size: 64).

**2. By mean:0, std:1 or not mentioning mean, std in config:**
```
channel_means: [0, 0, 0]
channel_stds: [1, 1, 1]
```

```
features['image'].numpy().mean()
-54.237076
features['image'].numpy().std()
80.218575
```

**3. If using `efficientdet_d0_coco17_tpu-32` not containing any mean, std info:**

```
features['image'].numpy().mean()
-0.9214938
features['image'].numpy().std()
1.362439
```

## 3. Steps to reproduce

Run https://github.com/tensorflow/models/blob/master/research/object_detection/model_main_tf2.py on config file of `centernet_resnet_v1_50_fpn_512x512_coco17` from TF model zoo and coco dataset. 

## 4. Expected behavior

Mean and std normalization should be consistent and inner workings documented. After standardization mean and std should be 0 and 1 respectively.

## 6. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 18.04): 18.04
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.3.0
- Python version: 3.7
",aabbas90,b'models:research type:bug',2020-08-13T19:29:36Z,2020-08-14T10:09:15Z,,,,,,,
9076,Unable to install python3-tk. Exiting.,"While installing delf - !bash install_delf.sh

getting the below error.

What could be the issue?



Traceback is as below - 

Downloading Protobuf compiler from https://github.com/google/protobuf/releases/download/v3.3.0/protoc-3.3.0-linux-x86_64.zip
Archive:  protoc-3.3.0-linux-x86_64.zip
   creating: protoc/include/
   creating: protoc/include/google/
   creating: protoc/include/google/protobuf/
  inflating: protoc/include/google/protobuf/any.proto  
  inflating: protoc/include/google/protobuf/api.proto  
   creating: protoc/include/google/protobuf/compiler/
  inflating: protoc/include/google/protobuf/compiler/plugin.proto  
  inflating: protoc/include/google/protobuf/descriptor.proto  
  inflating: protoc/include/google/protobuf/duration.proto  
  inflating: protoc/include/google/protobuf/empty.proto  
  inflating: protoc/include/google/protobuf/field_mask.proto  
  inflating: protoc/include/google/protobuf/source_context.proto  
  inflating: protoc/include/google/protobuf/struct.proto  
  inflating: protoc/include/google/protobuf/timestamp.proto  
  inflating: protoc/include/google/protobuf/type.proto  
  inflating: protoc/include/google/protobuf/wrappers.proto  
   creating: protoc/bin/
  inflating: protoc/bin/protoc       
  inflating: protoc/readme.txt       
Compiling DELF Protobufs
Cleaning up Protobuf compiler download
Installing matplotlib, numpy, scikit-image, scipy and python3-tk
Requirement already satisfied: matplotlib in /opt/conda/lib/python3.7/site-packages (3.2.1)
Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (1.18.5)
Requirement already satisfied: scikit-image in /opt/conda/lib/python3.7/site-packages (0.16.2)
Requirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (1.4.1)
Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib) (0.10.0)
Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib) (2.8.1)
Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib) (2.4.7)
Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib) (1.2.0)
Requirement already satisfied: networkx>=2.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image) (2.4)
Requirement already satisfied: pillow>=4.3.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image) (7.2.0)
Requirement already satisfied: imageio>=2.3.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image) (2.8.0)
Requirement already satisfied: PyWavelets>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image) (1.1.1)
Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from cycler>=0.10->matplotlib) (1.14.0)
Requirement already satisfied: decorator>=4.3.0 in /opt/conda/lib/python3.7/site-packages (from networkx>=2.0->scikit-image) (4.4.2)
WARNING: You are using pip version 20.1.1; however, version 20.2.1 is available.
You should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.
install_delf.sh: line 101: sudo: command not found
Unable to install python3-tk. Exiting.





",pn12,b'models:research stat:awaiting response type:bug',2020-08-08T07:47:57Z,2020-08-10T14:41:02Z,,,,,,,
9065,“No such layer” error,"Hi,

I am trying to train a network for object detection (a pre-trained network from the research folder), starting from the main python file:
[https://github.com/tensorflow/models/tree/master/research/object_detection/model_main_tf2](https://github.com/tensorflow/models/tree/master/research/object_detection/model_main_tf2)

I am executing it with this command:
`python model_main_tf2.py --model_dir=../models_tf2/my_faster_rcnn_resnet50 --pipeline_config_path=../models_tf2/my_faster_rcnn_resnet50/pipeline.config`

And I obtain this weird error:
`ValueError: No such layer: conv4_block6_out`
(and obtain the same error when I try to do it with another network architecture)

The complete traceback is:

```
    (…)/models/tf2/research/object_detection/model_lib_v2.py:355 _dummy_computation_fn
        labels)
    (…)/models/tf2/research/object_detection/model_lib_v2.py:122 _compute_losses_and_predictions_dicts
        **model.get_side_inputs(features))
    (…)/models/tf2/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py:824 predict
        prediction_dict = self._predict_first_stage(preprocessed_inputs)
    (…)/models/tf2/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py:877 _predict_first_stage
        image_shape) = self._extract_rpn_feature_maps(preprocessed_inputs)
    (…)/models/tf2/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py:1318 _extract_rpn_feature_maps
        preprocessed_inputs)
    (…)/models/tf2/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py:1334 _extract_proposal_features
        name=self.first_stage_feature_extractor_scope))
    (…)/models/tf2/research/object_detection/models/faster_rcnn_resnet_keras_feature_extractor.py:125 get_proposal_feature_extractor_model
        name=conv4_last_layer).output
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/network.py:569 get_layer
        raise ValueError('No such layer: ' + name)

    ValueError: No such layer: conv4_block6_out
```

",Mengant29,b'models:research stat:awaiting response type:bug',2020-08-07T07:37:38Z,2020-09-10T06:52:32Z,,,,,,,
9063,Checkpoint reading error during training!,"# Prerequisites

Please answer the following questions for yourself before submitting an issue.

- [x] I am using the latest TensorFlow Model Garden release and TensorFlow 2.
- [x] I am reporting the issue to the correct repository. (Model Garden official or research directory)
- [x] I checked to make sure that this issue has not been filed already.


Please help! I am following the tutorial at 
https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_training_and_evaluation.md

and keep getting this error during training
```
tensorflow.python.framework.errors_impl.DataLossError: Unable to open table file TRAIN/models/my_model_dir: 
Failed precondition: TRAIN/models/my_model_dir;
 Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?
```

i am following the object detection tutorial exactly and formatted my file tree as shown. Is the tuorial provided file structure correct ? After checking the config file, it seemed like the fine_tune_checkpoint parameter was looking for a single .ckpt file. I just input the entire directory instead. Currently, the checkpoint link provided downloads a folder with multiple checkpoint files (checkpoint/ckpt-0.data-00000-of-00001/ckpt-0.index). I don't know if this makes any difference or if this is just the same thing in a different format, but trying to figure out why I'm getting this error!
",jrash33,b'models:research type:bug',2020-08-06T22:55:17Z,2020-08-08T07:00:49Z,,,,,,,
9062,"Error indices[0] = 0 is not in [0, 0) with mask-rcnn object-detection model with tensorflow 2","# Prerequisites

Please answer the following questions for yourself before submitting an issue.

- [ x] I am using the latest TensorFlow Model Garden release and TensorFlow 2.
- [ x] I am reporting the issue to the correct repository. (Model Garden official or research directory)
- [ x] I checked to make sure that this issue has not already been filed.

## 2. Describe the bug
Please help! I am following the tutorial at https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_training_and_evaluation.md

everything has went smoothly until training. I keep getting this error below. I have seen forums with this error before but none as recently as now and using tensorflow 2
```
  File ""/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/executor.py"", line 67, in wait
    pywrap_tfe.TFE_ExecutorWaitForAllPendingNodes(self._handle)
tensorflow.python.framework.errors_impl.InvalidArgumentError: indices[0] = 0 is not in [0, 0)
	 [[{{node GatherV2_4}}]]
	 [[MultiDeviceIteratorGetNextFromShard]]
	 [[RemoteCall]]
```

## 3. Steps to reproduce
Here is my config file:
```
# Mask R-CNN with Inception Resnet v2 (no atrous)
# Sync-trained on COCO (with 8 GPUs) with batch size 16 (1024x1024 resolution)
# Initialized from Imagenet classification checkpoint
#
# Train on GPU-8
#
# Achieves 40.4 box mAP and 35.5 mask mAP on COCO17 val

model {
  faster_rcnn {
    number_of_stages: 3
    num_classes: 90
    image_resizer {
      fixed_shape_resizer {
        height: 1024
        width: 1024
      }
    }
    feature_extractor {
      type: 'faster_rcnn_inception_resnet_v2_keras'
    }
    first_stage_anchor_generator {
      grid_anchor_generator {
        scales: [0.25, 0.5, 1.0, 2.0]
        aspect_ratios: [0.5, 1.0, 2.0]
        height_stride: 16
        width_stride: 16
      }
    }
    first_stage_box_predictor_conv_hyperparams {
      op: CONV
      regularizer {
        l2_regularizer {
          weight: 0.0
        }
      }
      initializer {
        truncated_normal_initializer {
          stddev: 0.01
        }
      }
    }
    first_stage_nms_score_threshold: 0.0
    first_stage_nms_iou_threshold: 0.7
    first_stage_max_proposals: 300
    first_stage_localization_loss_weight: 2.0
    first_stage_objectness_loss_weight: 1.0
    initial_crop_size: 17
    maxpool_kernel_size: 1
    maxpool_stride: 1
    second_stage_box_predictor {
      mask_rcnn_box_predictor {
        use_dropout: false
        dropout_keep_probability: 1.0
        fc_hyperparams {
          op: FC
          regularizer {
            l2_regularizer {
              weight: 0.0
            }
          }
          initializer {
            variance_scaling_initializer {
              factor: 1.0
              uniform: true
              mode: FAN_AVG
            }
          }
        }
        mask_height: 33
        mask_width: 33
        mask_prediction_conv_depth: 0
        mask_prediction_num_conv_layers: 4
        conv_hyperparams {
          op: CONV
          regularizer {
            l2_regularizer {
              weight: 0.0
            }
          }
          initializer {
            truncated_normal_initializer {
              stddev: 0.01
            }
          }
        }
        predict_instance_masks: true
      }
    }
    second_stage_post_processing {
      batch_non_max_suppression {
        score_threshold: 0.0
        iou_threshold: 0.6
        max_detections_per_class: 100
        max_total_detections: 100
      }
      score_converter: SOFTMAX
    }
    second_stage_localization_loss_weight: 2.0
    second_stage_classification_loss_weight: 1.0
    second_stage_mask_prediction_loss_weight: 4.0
    resize_masks: false
  }
}

train_config: {
  batch_size: 16
  num_steps: 200000
  optimizer {
    momentum_optimizer: {
      learning_rate: {
        cosine_decay_learning_rate {
          learning_rate_base: 0.008
          total_steps: 200000
          warmup_learning_rate: 0.0
          warmup_steps: 5000
        }
      }
      momentum_optimizer_value: 0.9
    }
    use_moving_average: false
  }
  gradient_clipping_by_norm: 10.0
  fine_tune_checkpoint_version: V2
  fine_tune_checkpoint: ""TRAIN/models/my_model_dir/mask_rcnn_checkpoints""
  fine_tune_checkpoint_type: ""detection""
  data_augmentation_options {
    random_horizontal_flip {
    }
  }
}

train_input_reader: {
  label_map_path: ""TRAIN/data/pet_label_map.pbtxt""
  tf_record_input_reader {
    input_path: ""TRAIN/data/train_dataset/pet_faces_train.record-?????-of-00010""
  }
  load_instance_masks: true
  mask_type: PNG_MASKS
}

eval_config: {
  metrics_set: ""coco_detection_metrics""
  metrics_set: ""coco_mask_metrics""
  eval_instance_masks: true
  use_moving_averages: false
  batch_size: 1
  include_metrics_per_category: true
}

eval_input_reader: {
  label_map_path: ""TRAIN/data/pet_label_map.pbtxt""
  shuffle: false
  num_epochs: 1
  tf_record_input_reader {
    input_path: ""TRAIN/data/eval_dataset/pet_faces_val.record-?????-of-00010""
  }
  load_instance_masks: true
  mask_type: PNG_MASKS
}
```

I have created the pets data set tf records as indicated in the tutorial and running the below code, everything goes well until i get this error a couple times: 

```
python object_detection/model_main_tf2.py    
 --pipeline_config_path=TRAIN/models/my_model_dir/mask_rcnn_inception_resnet_v2_1024x1024_coco17_gpu-8.config     
--model_dir=TRAIN/models/my_model_dir     
--alsologtostderr
```


Any direction at all would be a huge help as I have been stuck on this for quite awhile!

",jrash33,b'models:research type:bug',2020-08-06T21:15:49Z,2020-08-06T22:46:13Z,,,,,,,
9061,ValueError: Tensor's shape is not compatible with supplied shape custom dataset using ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8,"# Prerequisites

Please answer the following questions for yourself before submitting an issue.

- [x] I am using the latest TensorFlow Model Garden release and TensorFlow 2.
- [x] I am reporting the issue to the correct repository. (Model Garden official or research directory)
- [x] I checked to make sure that this issue has not already been filed.

## 1. The entire URL of the file you are using

https://github.com/tensorflow/models/blob/master/research/object_detection/configs/tf2/ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8.config
https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md

## 2. Describe the bug

When attempting to train a custom model using the config file and the corresponding model from the model zoo I receive the following error:   ValueError: Tensor's shape (3, 3, 256, 546) is not compatible with supplied shape (3, 3, 256, 12). Full output listed below. I am having difficult identifying what the source of this error is.

## 3. Steps to reproduce

Add custom dataset into the object_detection directory, download the config file and model from the links above, move the model to the object_detection directory, config gets placed into a object_detection/training directory, and edit the config file as shown below. Then run the command: 

MEG:object_detection meg$ python model_main_tf2.py --pipeline_config_path ./trainingpython model_main_tf2.py --pipeline_config_path=training/ssd_mobilenet_v1_fpn_shared_box_predictor_640x64


## 4. Expected behavior

I expect when I run the following command that I will begin to train an object detection model:

MEG:object_detection meg$ python model_main_tf2.py --pipeline_config_path ./trainingpython model_main_tf2.py --pipeline_config_path=training/ssd_mobilenet_v1_fpn_shared_box_predictor_640x64




## 5. Additional context
 SSD with Mobilenet v1 FPN feature extractor, shared box predictor and focal
 loss (a.k.a Retinanet).
 See Lin et al, https://arxiv.org/abs/1708.02002
 Trained on COCO, initialized from Imagenet classification checkpoint

 Achieves 29.7 mAP on COCO14 minival dataset.


--------config file --------------
 This config is TPU compatible

model {
  ssd {
    inplace_batchnorm_update: true
    freeze_batchnorm: false
    num_classes: 1
    box_coder {
      faster_rcnn_box_coder {
        y_scale: 10.0
        x_scale: 10.0
        height_scale: 5.0
        width_scale: 5.0
      }
    }
    matcher {
      argmax_matcher {
        matched_threshold: 0.5
        unmatched_threshold: 0.5
        ignore_thresholds: false
        negatives_lower_than_unmatched: true
        force_match_for_each_row: true
        use_matmul_gather: true
      }
    }
    similarity_calculator {
      iou_similarity {
      }
    }
    encode_background_as_zeros: true
    anchor_generator {
      multiscale_anchor_generator {
        min_level: 3
        max_level: 7
        anchor_scale: 4.0
        aspect_ratios: [1.0, 2.0, 0.5]
        scales_per_octave: 2
      }
    }
    image_resizer {
      fixed_shape_resizer {
        height: 640
        width: 640
      }
    }
    box_predictor {
      weight_shared_convolutional_box_predictor {
        depth: 256
        class_prediction_bias_init: -4.6
        conv_hyperparams {
          activation: RELU_6,
          regularizer {
            l2_regularizer {
              weight: 0.00004
            }
          }
          initializer {
            random_normal_initializer {
              stddev: 0.01
              mean: 0.0
            }
          }
          batch_norm {
            scale: true,
            decay: 0.997,
            epsilon: 0.001,
          }
        }
        num_layers_before_predictor: 4
        kernel_size: 3
      }
    }
    feature_extractor {
      type: 'ssd_mobilenet_v1_fpn_keras'
      fpn {
        min_level: 3
        max_level: 7
      }
      min_depth: 16
      depth_multiplier: 1.0
      conv_hyperparams {
        activation: RELU_6,
        regularizer {
          l2_regularizer {
            weight: 0.00004
          }
        }
        initializer {
          random_normal_initializer {
            stddev: 0.01
            mean: 0.0
          }
        }
        batch_norm {
          scale: true,
          decay: 0.997,
          epsilon: 0.001,
        }
      }
      override_base_feature_extractor_hyperparams: true
    }
    loss {
      classification_loss {
        weighted_sigmoid_focal {
          alpha: 0.25
          gamma: 2.0
        }
      }
      localization_loss {
        weighted_smooth_l1 {
        }
      }
      classification_weight: 1.0
      localization_weight: 1.0
    }
    normalize_loss_by_num_matches: true
    normalize_loc_loss_by_codesize: true
    post_processing {
      batch_non_max_suppression {
        score_threshold: 1e-8
        iou_threshold: 0.6
        max_detections_per_class: 100
        max_total_detections: 100
      }
      score_converter: SIGMOID
    }
  }
}

train_config: {
  fine_tune_checkpoint: ""ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8/checkpoint/model.ckpt""
  batch_size: 20
  sync_replicas: true
  startup_delay_steps: 0
  replicas_to_aggregate: 8
  num_steps: 25000
  data_augmentation_options {
    random_horizontal_flip {
    }
  }
  data_augmentation_options {
    random_crop_image {
      min_object_covered: 0.0
      min_aspect_ratio: 0.75
      max_aspect_ratio: 3.0
      min_area: 0.75
      max_area: 1.0
      overlap_thresh: 0.0
    }
  }
  optimizer {
    momentum_optimizer: {
      learning_rate: {
        cosine_decay_learning_rate {
          learning_rate_base: .04
          total_steps: 25000
          warmup_learning_rate: .013333
          warmup_steps: 2000
        }
      }
      momentum_optimizer_value: 0.9
    }
    use_moving_average: false
  }
  max_number_of_boxes: 100
  unpad_groundtruth_tensors: false
}

train_input_reader: {
  tf_record_input_reader {
    input_path: ""data/train.record""
  }
  label_map_path: ""data/object-detection.pbtxt""
}

eval_config: {
  metrics_set: ""coco_detection_metrics""
  use_moving_averages: false
  num_examples: 8000
}

eval_input_reader: {
  tf_record_input_reader {
    input_path: ""data/test.record""
  }
  label_map_path: ""training/object-detection.pbtxt""
  shuffle: false
  num_readers: 1
}

--------ERROR OUTPUT----------

(SSD) MEG:object_detection meg$ python model_main_tf2.py --pipeline_config_path ./trainingpython model_main_tf2.py --pipeline_config_path=training/ssd_mobilenet_v1_fpn_shared_box_predictor_640x640_coco14_sync.config  --model_dir results --checkpoint_dir ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8/checkpoint/
WARNING:tensorflow:Forced number of epochs for all eval validations to be 1.
W0806 10:46:35.252889 4634940864 model_lib_v2.py:905] Forced number of epochs for all eval validations to be 1.
INFO:tensorflow:Maybe overwriting sample_1_of_n_eval_examples: None
I0806 10:46:35.253049 4634940864 config_util.py:552] Maybe overwriting sample_1_of_n_eval_examples: None
INFO:tensorflow:Maybe overwriting use_bfloat16: False
I0806 10:46:35.253113 4634940864 config_util.py:552] Maybe overwriting use_bfloat16: False
INFO:tensorflow:Maybe overwriting eval_num_epochs: 1
I0806 10:46:35.253171 4634940864 config_util.py:552] Maybe overwriting eval_num_epochs: 1
WARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.
W0806 10:46:35.253251 4634940864 model_lib_v2.py:920] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.
2020-08-06 10:46:35.342232: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-08-06 10:46:35.360943: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fae5731f580 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-08-06 10:46:35.360963: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
WARNING:tensorflow:From /Users/meg/opt/anaconda3/envs/SSD/lib/python3.6/site-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_deterministic`.
W0806 10:46:35.394832 4634940864 deprecation.py:323] From /Users/meg/opt/anaconda3/envs/SSD/lib/python3.6/site-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_deterministic`.
WARNING:tensorflow:From /Users/meg/opt/anaconda3/envs/SSD/lib/python3.6/site-packages/object_detection/builders/dataset_builder.py:175: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.map()
W0806 10:46:35.418838 4634940864 deprecation.py:323] From /Users/meg/opt/anaconda3/envs/SSD/lib/python3.6/site-packages/object_detection/builders/dataset_builder.py:175: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.map()
WARNING:tensorflow:From /Users/meg/opt/anaconda3/envs/SSD/lib/python3.6/site-packages/object_detection/inputs.py:79: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.
W0806 10:46:40.934005 4634940864 deprecation.py:323] From /Users/meg/opt/anaconda3/envs/SSD/lib/python3.6/site-packages/object_detection/inputs.py:79: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.
WARNING:tensorflow:From /Users/meg/opt/anaconda3/envs/SSD/lib/python3.6/site-packages/object_detection/inputs.py:259: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
W0806 10:46:42.502683 4634940864 deprecation.py:323] From /Users/meg/opt/anaconda3/envs/SSD/lib/python3.6/site-packages/object_detection/inputs.py:259: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
INFO:tensorflow:Waiting for new checkpoint at ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8/checkpoint/
I0806 10:46:46.062254 4634940864 checkpoint_utils.py:125] Waiting for new checkpoint at ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8/checkpoint/
INFO:tensorflow:Found new checkpoint at ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8/checkpoint/ckpt-0
I0806 10:46:46.079427 4634940864 checkpoint_utils.py:134] Found new checkpoint at ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8/checkpoint/ckpt-0
Traceback (most recent call last):
  File ""model_main_tf2.py"", line 106, in <module>
    tf.compat.v1.app.run()
  File ""/Users/meg/opt/anaconda3/envs/SSD/lib/python3.6/site-packages/tensorflow/python/platform/app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""/Users/meg/opt/anaconda3/envs/SSD/lib/python3.6/site-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/Users/meg/opt/anaconda3/envs/SSD/lib/python3.6/site-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""model_main_tf2.py"", line 83, in main
    wait_interval=300, timeout=FLAGS.eval_timeout)
  File ""/Users/meg/opt/anaconda3/envs/SSD/lib/python3.6/site-packages/object_detection/model_lib_v2.py"", line 959, in eval_continuously
    global_step=global_step)
  File ""/Users/meg/opt/anaconda3/envs/SSD/lib/python3.6/site-packages/object_detection/model_lib_v2.py"", line 774, in eager_eval_loop
    eval_dict, losses_dict, class_agnostic = compute_eval_dict(features, labels)
  File ""/Users/meg/opt/anaconda3/envs/SSD/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py"", line 580, in __call__
    result = self._call(*args, **kwds)
  File ""/Users/meg/opt/anaconda3/envs/SSD/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py"", line 627, in _call
    self._initialize(args, kwds, add_initializers_to=initializers)
  File ""/Users/meg/opt/anaconda3/envs/SSD/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py"", line 506, in _initialize
    *args, **kwds))
  File ""/Users/meg/opt/anaconda3/envs/SSD/lib/python3.6/site-packages/tensorflow/python/eager/function.py"", line 2446, in _get_concrete_function_internal_garbage_collected
    graph_function, _, _ = self._maybe_define_function(args, kwargs)
  File ""/Users/meg/opt/anaconda3/envs/SSD/lib/python3.6/site-packages/tensorflow/python/eager/function.py"", line 2777, in _maybe_define_function
    graph_function = self._create_graph_function(args, kwargs)
  File ""/Users/meg/opt/anaconda3/envs/SSD/lib/python3.6/site-packages/tensorflow/python/eager/function.py"", line 2667, in _create_graph_function
    capture_by_value=self._capture_by_value),
  File ""/Users/meg/opt/anaconda3/envs/SSD/lib/python3.6/site-packages/tensorflow/python/framework/func_graph.py"", line 981, in func_graph_from_py_func
    func_outputs = python_func(*func_args, **func_kwargs)
  File ""/Users/meg/opt/anaconda3/envs/SSD/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py"", line 441, in wrapped_fn
    return weak_wrapped_fn().__wrapped__(*args, **kwds)
  File ""/Users/meg/opt/anaconda3/envs/SSD/lib/python3.6/site-packages/tensorflow/python/framework/func_graph.py"", line 968, in wrapper
    raise e.ag_error_metadata.to_exception(e)
ValueError: in user code:

    /Users/meg/opt/anaconda3/envs/SSD/lib/python3.6/site-packages/object_detection/model_lib_v2.py:721 compute_eval_dict  *
        losses_dict, prediction_dict = _compute_losses_and_predictions_dicts(
    /Users/meg/opt/anaconda3/envs/SSD/lib/python3.6/site-packages/object_detection/model_lib_v2.py:118 _compute_losses_and_predictions_dicts  *
        prediction_dict = model.predict(
    /Users/meg/opt/anaconda3/envs/SSD/lib/python3.6/site-packages/object_detection/meta_architectures/ssd_meta_arch.py:591 predict  *
        predictor_results_dict = self._box_predictor(feature_maps)
    /Users/meg/opt/anaconda3/envs/SSD/lib/python3.6/site-packages/object_detection/core/box_predictor.py:202 call  *
        return self._predict(image_features, **kwargs)
    /Users/meg/opt/anaconda3/envs/SSD/lib/python3.6/site-packages/object_detection/predictors/convolutional_keras_box_predictor.py:484 _predict  *
        prediction = head_obj(head_tower_feature)
    /Users/meg/opt/anaconda3/envs/SSD/lib/python3.6/site-packages/object_detection/predictors/heads/head.py:69 call  *
        return self._predict(features)
    /Users/meg/opt/anaconda3/envs/SSD/lib/python3.6/site-packages/object_detection/predictors/heads/keras_class_head.py:340 _predict  *
        class_predictions_with_background = layer(
    /Users/meg/opt/anaconda3/envs/SSD/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py:897 __call__  **
        self._maybe_build(inputs)
    /Users/meg/opt/anaconda3/envs/SSD/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py:2416 _maybe_build
        self.build(input_shapes)  # pylint:disable=not-callable
    /Users/meg/opt/anaconda3/envs/SSD/lib/python3.6/site-packages/tensorflow/python/keras/layers/convolutional.py:163 build
        dtype=self.dtype)
    /Users/meg/opt/anaconda3/envs/SSD/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py:577 add_weight
        caching_device=caching_device)
    /Users/meg/opt/anaconda3/envs/SSD/lib/python3.6/site-packages/tensorflow/python/training/tracking/base.py:724 _add_variable_with_custom_getter
        name=name, shape=shape)
    /Users/meg/opt/anaconda3/envs/SSD/lib/python3.6/site-packages/tensorflow/python/training/tracking/base.py:791 _preload_simple_restoration
        checkpoint_position=checkpoint_position, shape=shape)
    /Users/meg/opt/anaconda3/envs/SSD/lib/python3.6/site-packages/tensorflow/python/training/tracking/base.py:75 __init__
        self.wrapped_value.set_shape(shape)
    /Users/meg/opt/anaconda3/envs/SSD/lib/python3.6/site-packages/tensorflow/python/framework/ops.py:1107 set_shape
        (self.shape, shape))

    ValueError: Tensor's shape (3, 3, 256, 546) is not compatible with supplied shape (3, 3, 256, 12)




## 6. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS Mojave 10.14.6
- Mobile device name if the issue happens on a mobile device:
- TensorFlow installed from (source or binary): command line? I used the setup file
- TensorFlow version (use command below): 2.2.0
- Python version: 3.6.10
- Bazel version (if compiling from source): n/a
- GCC/Compiler version (if compiling from source): n/a
- CUDA/cuDNN version: n/a
- GPU model and memory: n/a

<!-- 
Collect system information using our environment capture script.
https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can also obtain the TensorFlow version with:

1. TensorFlow 1.0
`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

2. TensorFlow 2.0
`python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`
-->
",mgon5170,b'models:research type:bug',2020-08-06T20:39:31Z,2020-08-20T15:55:29Z,,,,,,,
9057,Converting tf2 ssd_mobilenet-v1 object detection model to tflite model,"I am using Google Colab to run the training and conversion.

When I run the script 

!python /content/models/research/object_detection/export_tflite_ssd_graph.py \
--pipeline_config=/content/workspace/training/pipeline.config \
--trained_checkpoint=/content/workspace/training/model.ckpt \
--output_dir=/content/workspace/hands_detection \
--add_postprocessing_op=true

I get this error:

Traceback (most recent call last):
  File ""/content/models/research/object_detection/export_tflite_ssd_graph.py"", line 144, in <module>
    tf.app.run(main)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""/content/models/research/object_detection/export_tflite_ssd_graph.py"", line 135, in main
    text_format.Merge(f.read(), pipeline_config)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/lib/io/file_io.py"", line 116, in read
    self._preread_check()
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/lib/io/file_io.py"", line 79, in _preread_check
    self.__name, 1024 * 512)
TypeError: __init__(): incompatible constructor arguments. The following argument types are supported:
    1. tensorflow.python._pywrap_file_io.BufferedInputStream(arg0: str, arg1: int)

Invoked with: None, 524288

I traced the error to a pre_reading check for pipeline.config file. But it doesn't seem to be changed at all and all paths are correct.",Raphaeal19,b'models:research type:bug',2020-08-06T07:34:58Z,2020-08-31T11:51:38Z,,,,,,,
9054,Pre-trained model for Efficient net B0 implementation,"# Prerequisites

Please answer the following questions for yourself before submitting an issue.

- [X] I am using the latest TensorFlow Model Garden release and TensorFlow 2.
- [X] I am reporting the issue to the correct repository. (Model Garden official or research directory)
- [X] I checked to make sure that this issue has not been filed already.

## 1. The entire URL of the file you are using

https://github.com/tensorflow/models/tree/master/official/vision/image_classification

## 2. Describe the bug

For efficient net implementation (classifier_trainer.py), is the [TFHUB](https://tfhub.dev/tensorflow/efficientnet/b0/classification/1 ) saved model or pretrained weights expected to work ? I'm a bit confused as the [README.md](https://github.com/tensorflow/models/tree/master/official/vision/image_classification#efficientnet) says efficient net is work in progress.

I'm evaluating the saved_model.pb provided in the tfhub for B0 model and my accuracy on Imagenet is close to zero. 

The way I'm evaluating is as follows:
In the classifer_trainer.py, I add `model = tf.keras.models.load_model('eff_b0_checkpoint/')` (directory which has saved_model.pb)
and comment out the training part and skip to 

> validation_output = model.evaluate(validation_dataset, steps=validation_steps, verbose=2)

Can you please let me know if this is right ? Thank you !! 
",peri044,b'models:official type:bug',2020-08-05T19:17:47Z,2020-08-24T22:59:20Z,,,,,,,
9050,vision >> classifier_trainer.py >> dataset,"# Prerequisites

Please answer the following questions for yourself before submitting an issue.

I am using the latest TensorFlow Model Garden release2.3.0 and TensorFlow 2.3.0
I am reporting the issue to the correct repository. (Model Garden official or research directory
I checked to make sure that this issue has not been filed already.

## 1. The entire URL of the file you are using

https://github.com/tensorflow/models/blob/r2.3.0/official/vision/image_classification/classifier_trainer.py

## 2. Describe the bug

When I run classifier_trainer.py to training resnet50, it always stopping at:
```shell
dataset_factory >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>tfds.builder()
2020-08-05 11:52:32.953550: W tensorflow/core/platform/cloud/google_auth_provider.cc:184] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with ""Not found: Could not locate the credentials file."". Retrieving token from GCE failed with ""Failed precondition: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Couldn't resolve host 'metadata'"".
2020-08-05 11:53:48.123025: E tensorflow/core/platform/cloud/curl_http_request.cc:611] The transmission  of request 0x55c74a5687f0 (URI: https://www.googleapis.com/storage/v1/b/tfds-data/o/dataset_info%2Fimagenet2012%2F5.0.0?fields=size%2Cgeneration%2Cupdated) has been stuck at 0 of 0 bytes for 61 seconds and will be aborted. CURL timing information: lookup time: 0.010172 (No error), connect time: 0.066656 (No error), pre-transfer time: 0 (No error), start-transfer time: 0 (No error)
```

and I find this url is 404 :
https://www.googleapis.com/storage/v1/b/tfds-data/o/dataset_info%2Fimagenet2012%2F5.0.0?fields=size%2Cgeneration%2Cupdated

So tfds.builder() will not work (in dataset_factory.py )
## 3. Steps to reproduce

training script:
```shell
export CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
MODEL_DIR=../output
DATA_DIR=/datasets/ImageNet/tfrecord

python3 classifier_trainer.py \
  --mode=train_and_eval \
  --model_type=resnet \
  --dataset=imagenet \
  --model_dir=$MODEL_DIR \
  --data_dir=$DATA_DIR \
  --config_file=configs/examples/resnet/imagenet/gpu.yaml \
  --params_override='runtime.num_gpus=8'
```

## 4. Expected behavior

A clear and concise description of what you expected to happen.

## 5. Additional context

Include any logs that would be helpful to diagnose the problem.

## 6. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device name if the issue happens on a mobile device:
- TensorFlow installed from pip install tensorflow):
- TensorFlow version (use command below): 2.3.0
- Python version: 3.7.7
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source): gcc (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609
- CUDA/cuDNN version: 10.2
- GPU model and memory: 8× v100(16GB)

<!-- 
Collect system information using our environment capture script.
https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can also obtain the TensorFlow version with:

1. TensorFlow 1.0
`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

2. TensorFlow 2.0
`python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`
-->
",Flowingsun007,b'models:official type:bug',2020-08-05T04:36:56Z,2020-08-06T06:52:21Z,,,,,,,
9039,"Invoked with: <tensorflow.python._pywrap_tfe.TFE_MonitoringIntGaugeCell object at 0x00000199C670A6C0>, None","TypeError: TFE_MonitoringIntGaugeCellSet(): incompatible function arguments. The following argument types are supported:
    1. (arg0: tensorflow.python._pywrap_tfe.TFE_MonitoringIntGaugeCell, arg1: int) -> None

I'm using transformer on translation(zh-en) task, but got this error,   i'm using tensorflow==2.3.0 ",barton-wa,b'models:official stat:awaiting response type:bug',2020-08-04T09:39:18Z,2020-08-05T07:33:40Z,,,,,,,
9031,Converting TF 2 Object Detection Model to TFLite,"# Prerequisites

Please answer the following questions for yourself before submitting an issue.

- [X] I am using the latest TensorFlow Model Garden release and TensorFlow 2.
- [X] I am reporting the issue to the correct repository. (Model Garden official or research directory)
- [X] I checked to make sure that this issue has not already been filed.

## 1. The entire URL of the file you are using

https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md

## 2. Describe the bug

I am trying to Convert the SSD ResNet50 V1 FPN 640x640 (RetinaNet50) of the TF 2 Object Detection Zoo to TFLite. My Code is the following: 
```python
converter = tf.lite.TFLiteConverter.from_saved_model('ssd_resnet50_v1_fpn_640x640_coco17_tpu-8/saved_model/',signature_keys=['serving_default'])
converter.optimizations = [tf.lite.Optimize.DEFAULT]
converter.experimental_new_converter = True
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]

tflite_model = converter.convert()

with tf.io.gfile.GFile('model.tflite', 'wb') as f:
  f.write(tflite_model)

```

The Convertion is running without any Errors, but when I try to use the TFLite Model with the following Code

```python
interpreter = tf.lite.Interpreter(model_path=""./model.tflite"")
interpreter.allocate_tensors()

input_details = interpreter.get_input_details()
output_details = interpreter.get_output_details()

input_shape = input_details[0]['shape']
input_data = np.array(np.random.random_sample((1,640,640,3)), dtype=np.uint8)
interpreter.set_tensor(input_details[0]['index'], input_data)

interpreter.invoke()
output_data = interpreter.get_tensor(output_details[0]['index'])
print(output_data)
```

I am getting this Error: 
```
ValueError                                Traceback (most recent call last)
<ipython-input-17-44fd9cb644ae> in <module>
     20 rdm_img = np.array(np.random.random_sample((1,640,640,3)), dtype=np.uint8)
     21 # input_data = np.array(np.random.random_sample(input_shape), dtype=np.uint8)
---> 22 interpreter.set_tensor(input_details[0]['index'], rdm_img)
     23 
     24 interpreter.invoke()

/usr/lib/python3.6/site-packages/tensorflow/lite/python/interpreter.py in set_tensor(self, tensor_index, value)
    406       ValueError: If the interpreter could not set the tensor.
    407     """"""
--> 408     self._interpreter.SetTensor(tensor_index, value)
    409 
    410   def resize_tensor_input(self, input_index, tensor_size, strict=False):

ValueError: Cannot set tensor: Dimension mismatch. Got 640 but expected 1 for dimension 1 of input 0.
```

It seems that there are some Problems with the Dimensions of the converted Model. 
Thanks for your help!


## 6. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- TensorFlow version (use command below): 2.4.0
- Python version: 3.7
",Snixells,b'models:research type:bug',2020-08-03T15:49:31Z,2020-08-28T11:27:42Z,,,,,,,
9023,Error with shape mismatch when changing `num_scales` for mask rcnn,"## 1. The entire URL of the file you are using

https://github.com/tensorflow/models/tree/master/official/vision/detection/ops/roi_ops.py

## 2. Describe the bug

In the `multilevel_propose_rois` function, the returned `selected_rois` should have shape [batch_size, rpn_post_nms_top_k, 4]. However, if the `params.anchor.num_scales` argument is anything other that 1, the `batch_size` of the returned `selected_rois` is actually `batch_size` * `num_scales`. The reason for this is because when calculating ""this_level_anchors"", a -1 is used to fill in the shape: 

```
        this_level_anchors = tf.cast(
            tf.reshape(anchor_boxes[level], [-1, num_boxes, 4]),
            dtype=this_level_scores.dtype)
```

I assume this should instead be something like ...
```        
        this_level_anchors = tf.cast(
            tf.reshape(anchor_boxes[level], [-1, num_boxes*num_scales, 4]),
            dtype=this_level_scores.dtype)
``` 

but this introduces shape mismatch errors in other parts of the code as well. For example, after making the above changes, I see a new error:

```
ValueError: Dimensions must be equal, but are 49152 and 147456 for '{{node multilevel_propose_rois/level_2/decode_boxes/mul_2}} = Mul[T=DT_FLOAT](multilevel_propose_rois/level_2/decode_boxes/strided_slice, multilevel_propose_rois/level_2/decode_boxes/add)' with input shapes: [1,49152,1], [1,147456,1].
```

This is referring to a size mismatch in the `official/vision/detection/utils/box_utils.py` script, for the line `decoded_boxes_yc = dy * anchor_h + anchor_yc`, in which `dy` has shape (1, 49152, 1), while `anchor_h` has shape (1, 147456, 1). Here, we see the same factor of three that comes from the `num_scales` value.

## 3. Steps to reproduce

Set the `params.anchors.num_scales` to something larger than 1. I was trying this with 3.

## 4. Expected behavior

I expect the returned `selected_rois` to have shape [batch_size, rpn_post_nms_top_k, 4], but it actually has shape  [batch_size*num_scales, rpn_post_nms_top_k, 4].

## 5. Additional context
-- 

## 6. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Debian GNU/Linux 9.11
- Mobile device name if the issue happens on a mobile device: N/A
- TensorFlow installed from (source or binary): binary (pip)
- TensorFlow version (use command below): 2.3.0
- Python version: 3.7.3
- CUDA/cuDNN version: 10.1/7.6.4
- GPU model and memory: NVIDIA Tesla K80
",roserustowicz,b'models:official type:bug',2020-08-01T06:19:04Z,2020-08-13T21:39:33Z,,,,,,,
9021,Bugfix in context r-cnn scripts,"# Description

> :memo: Please include a summary of the change. 
>  
> * Please also include relevant motivation and context.  
> * List any dependencies that are required for this change.  

## Type of change

For a new feature or function, please create an issue first to discuss it
with us before submitting a pull request.

Note: Please delete options that are not relevant.

- [x] Bug fix (non-breaking change which fixes an issue)
- [ ] Documentation update
- [ ] TensorFlow 2 migration
- [ ] New feature (non-breaking change which adds functionality)
- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)
- [ ] A new research paper code implementation
- [ ] Other (Specify)

## Tests

> :memo: Please describe the tests that you ran to verify your changes.
>  
> * Provide instructions so we can reproduce.  
> * Please also list any relevant details for your test configuration.  

**Test Configuration**:

## Checklist

- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).
- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).
- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).
- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.
- [ ] I have commented my code, particularly in hard-to-understand areas.
- [ ] I have made corresponding changes to the documentation.
- [ ] My changes generate no new warnings.
- [ ] I have added tests that prove my fix is effective or that my feature works.
",kmindspark,b'cla: yes ready to pull',2020-07-31T19:00:33Z,2020-08-01T06:24:09Z,,,,,,,
9015,Bugfix: keep highest N candidates instead of removing,"# Description

The comment says ""select the last self.beam_size"", but `[:-self.beam_size]` actually means the opposite, i.e., removing the last self.beam_size.

## Type of change

- [x] Bug fix (non-breaking change which fixes an issue)

## Tests

Before the bugfix, the output was not a sentence:

```
Captions for image COCO_val2014_000000224477.jpg:
  0)  (p=0.000001)
  1) surfer (p=0.000000)
  2) two (p=0.000000)
```

After the bugfix, the output looks good:

```
Captions for image COCO_val2014_000000224477.jpg:
  0) a man riding a wave on top of a surfboard . (p=0.035869)
  1) a person riding a surf board on a wave (p=0.018637)
  2) a man riding a wave on a surfboard in the ocean . (p=0.004625)
```

**Test Configuration**:

* Python 3.6
* TensorFlow 1.0
* Pretrained model from [KranthiGV/Pretrained-Show-and-Tell-model](https://github.com/KranthiGV/Pretrained-Show-and-Tell-model)

## Checklist

- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).
- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).
- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).
- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.
- [x] I have commented my code, particularly in hard-to-understand areas.
- [x] I have made corresponding changes to the documentation.
- [x] My changes generate no new warnings.
- [x] I have added tests that prove my fix is effective or that my feature works.
",abcdabcd987,b'cla: yes',2020-07-30T22:40:54Z,2020-08-14T20:39:32Z,,,,,,,
9001,convert pb to tflite,"i trained ssd_mobilenet_v3_large_coco_2020_01_14 model. and it worked.
then i convert (saved_model.pb | saved_model.pbtxt) to tflite file.
using 3 ways: 
```
toco --saved_model_dir=saved_model --output_file=tflite/tflite_mobile.tflite --input_shapes=1,320,320,3 --output_arrays='TFLite_Detection_PostProcess','TFLite_Detection_PostProcess:1','TFLite_Detection_PostProcess:2','TFLite_Detection_PostProcess:3' --inference_type=FLOAT --allow_custom_ops
```

```
!tflite_convert --saved_model_dir=inference_graph/saved_model --output_file=detect.tflite --output_format=TFLITE --input_shapes=1,320,320,3 --input_arrays=normalized_input_image_tensor output_arrays='TFLite_Detection_PostProcess','TFLite_Detection_PostProcess:1','TFLite_Detection_PostProcess:2','TFLite_Detection_PostProcess:3' --inference_type=QUANTIZED_UINT8 --enable_v1_converter --mean_values=128 --std_dev_values=127 --change_concat_input_ranges=false --allow_custom_ops
```
```
converter = tf.lite.TFLiteConverter.from_saved_model(""saved_model"")
tflite_model = converter.convert()
open(""converted_model.tflite"", ""wb"").write(tflite_model)
```

but get errors:
```
RuntimeError: MetaGraphDef associated with tags {'serve'} could not be found in SavedModel. To inspect available tag-sets in the SavedModel, please use the SavedModel CLI: `saved_model_cli`
available_tags: [set()]
```
```
ValueError: Invalid tensors 'normalized_input_image_tensor' were found
```
```
None is only supported in the 1st dimension. Tensor 'image_tensor' has invalid shape '[None, None, None, 3]'.
```

please help",sajjadaemmi,b'models:research type:bug',2020-07-29T12:31:12Z,2020-08-10T09:48:36Z,,,,,,,
8994,'tensorflow.keras.activations' has no attribute 'gelu',"I set up a new clean conda environment with python 3.6. 

I installed tf-nightly, tensorflow-addons and tensorflow_hup as requested. But I cannot run the examples (but with a external trained BERT model for my language) and get the following:

```

Traceback (most recent call last):
  File ""run_classifier.py"", line 506, in <module>
    app.run(main)
  File ""C:\Users\\Anaconda3\envs\tf-nightly\lib\site-packages\absl\app.py"", line 299, in run
    _run_main(main, args)
  File ""C:\Users\\Anaconda3\envs\tf-nightly\lib\site-packages\absl\app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""run_classifier.py"", line 499, in main
    custom_main(custom_callbacks=None, custom_metrics=None)
  File ""run_classifier.py"", line 495, in custom_main
    custom_metrics=custom_metrics)
  File ""run_classifier.py"", line 410, in run_bert
    custom_metrics=custom_metrics)
  File ""run_classifier.py"", line 199, in run_bert_classifier
    custom_callbacks=custom_callbacks)
  File ""run_classifier.py"", line 221, in run_keras_compile_fit
    bert_model, sub_model = model_fn()
  File ""run_classifier.py"", line 149, in _get_classifier_model
    hub_module_trainable=FLAGS.hub_module_trainable))
  File ""C:\Users\\Corona_Bot\models-master\official\nlp\bert\bert_models.py"", line 344, in classifier_model
    bert_config, max_seq_length, output_range=1)
  File ""C:\Users\\Anaconda3\envs\tf-nightly\lib\site-packages\gin\config.py"", line 1078, in gin_wrapper
    utils.augment_exception_message_and_reraise(e, err_str)
  File ""C:\Users\\Anaconda3\envs\tf-nightly\lib\site-packages\gin\utils.py"", line 49, in augment_exception_message_and_reraise
    six.raise_from(proxy.with_traceback(exception.__traceback__), None)
  File ""<string>"", line 3, in raise_from
  File ""C:\Users\\Anaconda3\envs\tf-nightly\lib\site-packages\gin\config.py"", line 1055, in gin_wrapper
    return fn(*new_args, **new_kwargs)
  File ""C:\Users\\Corona_Bot\models-master\official\nlp\bert\bert_models.py"", line 175, in get_transformer_encoder
    return networks.TransformerEncoder(**kwargs)
  File ""C:\Users\\Corona_Bot\models-master\official\nlp\modeling\networks\transformer_encoder.py"", line 199, in __init__
    data = layer([data, attention_mask])
  File ""C:\Users\\Anaconda3\envs\tf-nightly\lib\site-packages\tensorflow\python\keras\engine\base_layer.py"", line 926, in __call__
    input_list)
  File ""C:\Users\\Anaconda3\envs\tf-nightly\lib\site-packages\tensorflow\python\keras\engine\base_layer.py"", line 1117, in _functional_construction_call
    outputs = call_fn(cast_inputs, *args, **kwargs)
  File ""C:\Users\\Anaconda3\envs\tf-nightly\lib\site-packages\tensorflow\python\autograph\impl\api.py"", line 667, in wrapper
    raise e.ag_error_metadata.to_exception(e)
AttributeError: in user code:

    C:\Users\\Corona_Bot\models-master\official\nlp\modeling\layers\transformer.py:214 call  *
        intermediate_output = self._intermediate_activation_layer(
    C:\Users\\Anaconda3\envs\tf-nightly\lib\site-packages\tensorflow\python\keras\engine\base_layer.py:926 __call__  **
        input_list)
    C:\Users\\Anaconda3\envs\tf-nightly\lib\site-packages\tensorflow\python\keras\engine\base_layer.py:1117 _functional_construction_call
        outputs = call_fn(cast_inputs, *args, **kwargs)
    C:\Users\\Anaconda3\envs\tf-nightly\lib\site-packages\tensorflow\python\keras\layers\core.py:427 call
        return self.activation(inputs)
    C:\Users\\Corona_Bot\models-master\official\modeling\activations\gelu.py:32 gelu
        return tf.keras.activations.gelu(x, approximate=True)

    AttributeError: module 'tensorflow.keras.activations' has no attribute 'gelu'

  In call to configurable 'get_transformer_encoder' (<function get_transformer_encoder at 0x00000274B249BB70>)
```",datistiquo,b'models:official type:bug',2020-07-29T07:57:44Z,2020-07-31T03:50:32Z,,,,,,,
8975,NotFoundError: /content/train/cells_label_map.pbtxt; No such file or directory,"# Prerequisites

Please answer the following questions for yourself before submitting an issue.

- [x] I am using the latest TensorFlow Model Garden release and TensorFlow 2.
- [x] I am reporting the issue to the correct repository. (Model Garden official or research directory)
- [x] I checked to make sure that this issue has not been filed already.

## 1. The entire URL of the file you are using

https://github.com/tensorflow/models/tree/master/official/...

## 2. Describe the bug

A clear and concise description of what the bug is.

## 3. Steps to reproduce

Steps to reproduce the behavior.

## 4. Expected behavior

A clear and concise description of what you expected to happen.

## 5. Additional context

Include any logs that would be helpful to diagnose the problem.

## 6. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device name if the issue happens on a mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below):
- Python version:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

<!-- 
Collect system information using our environment capture script.
https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can also obtain the TensorFlow version with:

1. TensorFlow 1.0
`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

2. TensorFlow 2.0
`python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`
-->
",haivamsieee,b'models:official stat:awaiting response type:bug',2020-07-27T17:41:29Z,2020-09-08T07:24:34Z,,,,,,,
8970,deeplab tflite model can not run a long time,"# Prerequisites

Please answer the following questions for yourself before submitting an issue.

- [ ] I am using the tensorflow-lite-1.15.0.aar for Android Device
- [ ] I am reporting the issue to the correct repository. (Model Garden official or research directory)
- [ ] I checked to make sure that this issue has not been filed already.

## 1. The entire URL of the file you are using

http://download.tensorflow.org/models/object_detection/ssdlite_mobilenet_v2_coco_2018_05_09.tar.gz

## 2. Describe the bug

A clear and concise description of what the bug is.

## 3. Steps to reproduce

Steps to reproduce the behavior.

## 4. Expected behavior

A clear and concise description of what you expected to happen.

## 5. Additional context

Include any logs that would be helpful to diagnose the problem.

## 6. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device name if the issue happens on a mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below):
- Python version:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

<!-- 
Collect system information using our environment capture script.
https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can also obtain the TensorFlow version with:

1. TensorFlow 1.0
`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

2. TensorFlow 2.0
`python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`
-->
",WindowsDriver,b'models:official type:bug',2020-07-27T05:23:58Z,2020-07-27T05:25:24Z,,,,,,,
8967,TF2 Object Detect API with CenterNet Resnet101 V1 FPN 512x512 ,"# Prerequisites

Please answer the following questions for yourself before submitting an issue.

- [Y] I am using the latest TensorFlow Model Garden release and TensorFlow 2.
- [Y] I am reporting the issue to the correct repository. (Model Garden official or research directory)
- [Y] I checked to make sure that this issue has not been filed already.

## 1. The entire URL of the file you are using

https://github.com/tensorflow/models/tree/master/official/...

## 2. Describe the bug

Training on a custom dataset using CenterNet Resnet101 V1 FPN 512x512 model has issues.  The checkpoint and pipeline.config were downloaded from the zoo and slightly modified to suit the custom dataset (e.g. number of classes changed).  The outcome depends on the fine_tune_checkpoint_type setting in the pipeline.config file:

fine_tune_checkpoint: ""centernet_resnet101_v1_fpn_512x512_coco17_tpu-8/checkpoint/ckpt-0

i. fine_tune_checkpoint_type: ""fine_tune""
   -runs successfully


ii. fine_tune_checkpoint_type: ""detection""
   -fails with the following error:

File ""tf2odapi/models/research/object_detection/meta_architectures/center_net_meta_arch.py"", line 2769, in restore_from_objects
    return {'feature_extractor': self._feature_extractor.get_model()}
AttributeError: 'CenterNetResnetV1FpnFeatureExtractor' object has no attribute 'get_model'


iii. fine_tune_checkpoint_type: ""classification""
   -gives a long string of warning saying it can't resolve model objects, then stops without giving an error:

...
WARNING:tensorflow:Unresolved object in checkpoint: (root).model._prediction_head_dict.box/offset.0.layer_with_weights-1.kernel
W0725 09:28:17.464377 140311093167936 util.py:143] Unresolved object in checkpoint: (root).model._prediction_head_dict.box/offset.0.layer_with_weights-1.kernel
WARNING:tensorflow:Unresolved object in checkpoint: (root).model._prediction_head_dict.box/offset.0.layer_with_weights-1.bias
W0725 09:28:17.464425 140311093167936 util.py:143] Unresolved object in checkpoint: (root).model._prediction_head_dict.box/offset.0.layer_with_weights-1.bias
WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.
W0725 09:28:17.464480 140311093167936 util.py:151] A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.


## 3. Steps to reproduce

Involves a custom dataset, so it can't be replicated here.

## 4. Expected behavior

Training should run smoothly for all three settings of fine_tune_checkpoint_type.

## 5. Additional context

Include any logs that would be helpful to diagnose the problem.

## 6. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- Mobile device name if the issue happens on a mobile device: 
- TensorFlow installed from (source or binary): pip
- TensorFlow version (use command below): 2.2.0
- Python version: 3.8
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 10.1, 7.6.5
- GPU model and memory: GE Force RTX 2080 11GB

<!-- 
Collect system information using our environment capture script.
https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can also obtain the TensorFlow version with:

1. TensorFlow 1.0
`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

2. TensorFlow 2.0
`python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`
-->
",mm7721,b'models:research type:bug',2020-07-25T16:32:06Z,2020-08-11T12:22:36Z,,,,,,,
8965,AttributeError: module 'tensorflow_core.compat.v1' has no attribute 'contrib',"# Prerequisites

Please answer the following questions for yourself before submitting an issue.

- [ ] I am using the latest TensorFlow Model Garden release and TensorFlow 2.
- [ ] I am reporting the issue to the correct repository. (Model Garden official or research directory)
- [ ] I checked to make sure that this issue has not been filed already.

## 1. The entire URL of the file you are using

https://github.com/tensorflow/models/tree/master/official/...

## 2. Describe the bug

2020-07-25 10:07:11.122491: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll
WARNING:tensorflow:From C:\Users\dw\Anaconda3\envs\TF2.2\lib\site-packages\tensorflow_core\python\compat\v2_compat.py:88: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.
Instructions for updating:
non-resource variables are not supported in the long term
Traceback (most recent call last):
  File ""model_main_tf2.py"", line 31, in <module>
    from object_detection import model_lib_v2
  File ""D:\tf_train\models\research\object_detection\model_lib_v2.py"", line 27, in <module>
    from object_detection import eval_util
  File ""D:\tf_train\models\research\object_detection\eval_util.py"", line 36, in <module>
    slim = tf.contrib.slim
AttributeError: module 'tensorflow_core.compat.v1' has no attribute 'contrib'

## 3. Steps to reproduce

python model_main_tf2.py --model_dir=training --pipeline_config_path=training/center_net_hourglass104_1024x1024_coco17_tpu-32.config --alsologtostderr

## 4. Expected behavior

Start training the model

## 5. Additional context

(TF2.1) D:\tf_train\workspaces\my_training_demo1>python model_main_tf2.py --model_dir=training --pipeline_config_path=training/center_net_hourglass104_1024x1024_coco17_tpu-32.config --alsologtostderr
2020-07-25 10:13:58.091313: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll
WARNING:tensorflow:From C:\Users\dw\Anaconda3\envs\TF2.2\lib\site-packages\tensorflow_core\python\compat\v2_compat.py:88: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.
Instructions for updating:
non-resource variables are not supported in the long term
Traceback (most recent call last):
  File ""model_main_tf2.py"", line 31, in <module>
    from object_detection import model_lib_v2
  File ""D:\tf_train\models\research\object_detection\model_lib_v2.py"", line 27, in <module>
    from object_detection import eval_util
  File ""D:\tf_train\models\research\object_detection\eval_util.py"", line 36, in <module>
    slim = tf.contrib.slim
AttributeError: module 'tensorflow_core.compat.v1' has no attribute 'contrib'

## 6. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Windows 10 professional workstation
- TensorFlow installed from (source or binary)：anaconda
- TensorFlow version (use command below):tensorflow-gpu=2.1
- Python version:3.6.10
- CUDA/cuDNN version: cudatoolkit=10.1  cudnn=7.6.5
- GPU model and memory: GTX2070,  39.8G

<!-- 
Collect system information using our environment capture script.
https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can also obtain the TensorFlow version with:

1. TensorFlow 1.0
`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

2. TensorFlow 2.0
`python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`
-->unknown 2.1.0
",dreamitpossible1,b'models:research stat:awaiting response type:bug',2020-07-25T02:26:07Z,2020-09-19T20:41:48Z,,,,,,,
8956,Some Error in models/official/nlp/transformer/,"# Prerequisites

Please answer the following questions for yourself before submitting an issue.

- [YES ] I am using the latest TensorFlow Model Garden release and TensorFlow 2.
- [YES ] I am reporting the issue to the correct repository. (Model Garden official or research directory)
- [YES] I checked to make sure that this issue has not been filed already.

## 1. The entire URL of the file you are using

https://github.com/tensorflow/models/tree/master/official/nlp/transformer/data_download.py

## 2. Describe the bug

**When !python3 data_download.py --data_dir=$DATA_DIR in Colab.
I get a Error:**

2020-07-24 01:51:24.447754: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
I0724 01:51:26.636575 140448915650432 data_download.py:375] Creating directory /tmp/translate_ende_raw
I0724 01:51:26.636913 140448915650432 data_download.py:375] Creating directory 
I0724 01:51:26.637027 140448915650432 data_download.py:385] Step 1/5: Downloading test data
I0724 01:51:26.637138 140448915650432 data_download.py:170] Downloading from https://storage.googleapis.com/tf-perf-public/official_transformer/test_data/newstest2014.tgz to newstest2014.tgz.
101% completed
I0724 01:51:27.189940 140448915650432 data_download.py:209] Extracting newstest2014.tgz.
Traceback (most recent call last):
  File ""data_download.py"", line 439, in <module>
    absl_app.run(main)
  File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""data_download.py"", line 386, in main
    get_raw_files(FLAGS.data_dir, _TEST_DATA_SOURCES)
  File ""data_download.py"", line 138, in get_raw_files
    raw_dir, d[""url""], d[""input""], d[""target""])
  File ""data_download.py"", line 221, in download_and_extract
    (url, path))
OSError: Download/extraction failed for url https://storage.googleapis.com/tf-perf-public/official_transformer/test_data/newstest2014.tgz to path 

## 3. Steps to reproduce

Steps to reproduce the behavior.
**Also in Colab:**
```
!git clone https://github.com/tensorflow/models.git
cd /content/models/
!pip3 install tf-nightly
!pip install tf-models-nightly
!pip3 install --user -r official/requirements.txt
import os
os.environ['PYTHONPATH'] += "":/content/models""
cd /content/models/official/nlp/transformer
# Export variables
!PARAM_SET=big
!DATA_DIR=$HOME/transformer/data
!MODEL_DIR=$HOME/transformer/model_$PARAM_SET
!VOCAB_FILE=$DATA_DIR/vocab.ende.32768
!python3 data_download.py --data_dir=$DATA_DIR
```

## 4. Expected behavior

I just want to normally run a Transormer example.

## 5. Additional context

No.

## 6. System information

Colab GPU environment.

",iimlearning,b'models:official stat:awaiting response type:bug',2020-07-24T02:09:59Z,2020-10-07T18:19:42Z,,,,,,,
8952,download_dataset.sh doesn't unpack the .tar files when downloading the GLDv2 Dataset.,"# Prerequisites
- [x] I am using the latest TensorFlow Model Garden release and TensorFlow 2.2.
- [x] I am reporting the issue to the correct repository. (Model Garden official or research directory)
- [x] I checked to make sure that this issue has not already been filed.

## 1. The entire URL of the file you are using

https://github.com/tensorflow/models/tree/master/research/delf/delf/python/training#prepare-the-data-for-training/download_dataset.sh

## 2. Describe the bug

I have downloaded the model exactly as the documentation and for some reason whenever the file tries to check the md5 checksums it says that they don't match and the files just stay there as .tar files instead of unpacking into neat little folders.  The only thing that I can think of that I have done differently is that I have installed the files to an external drive. (Maybe I need to give my computer certain permissions?)

I am using linux 20.04 with a Seagate external USB hard drive.
",Fateh-Aliyev,b'models:research type:bug',2020-07-23T22:00:47Z,2020-07-27T16:18:32Z,,,,,,,
8947,Not possible to train Object Detection 2.0 in Colab using TPU,"# Prerequisites

Please answer the following questions for yourself before submitting an issue.

- [x] I am using the latest TensorFlow Model Garden release and TensorFlow 2.
- [x] I am reporting the issue to the correct repository. (Model Garden official or research directory)
- [x] I checked to make sure that this issue has not already been filed.

## 1. The entire URL of the file you are using

https://github.com/tensorflow/models/tree/master/research/object_detection

## 2. Describe the bug

I'm familiar with the need to use gcs buckets for training data for colab TPUs. I have buckets setup to do this.
I'm trying to port my OD colab notebooks to tf2.0. I thought I'd try and use the TPUs available in Colab.

The issue is that the fine tuned checkpoint files in the config need to be on the local VM for the OD scripts to run - otherwise model_main_tf2.py will error almost immediately if a gs:// url is used. Changing the config location to a local VM drive will prevent this. However, soon afterwards, tensorflow will error when trying to access the checkpoint, saying that 'local storage' isn't implemented, which is the correct behavior since TPUs must use GCS buckets.

So I don't know how to have the config file point at both a local checkpoint and a gs:// resource. I'm assuming the same error will occur for the training/validation data tf records as well

## 3. Steps to reproduce
Create a colab
upload config files pointing to either local (colab drive) or gs:// locations for the fine tuning checkpoint.
run model_main_tf2.py with --use_tpu set to True

## 4. Expected behavior

TPU training should be possible somehow from colab?

## 5. Additional context

Error for gs:// content is 
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/py_checkpoint_reader.py"", line 95, in NewCheckpointReader
    return CheckpointReader(compat.as_bytes(filepattern))
RuntimeError: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for gs://MYBUCKET/checkpoint/ckpt-0
During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/content/models/research/object_detection/model_main_tf2.py"", line 106, in <module>
    tf.compat.v1.app.run()
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""/content/models/research/object_detection/model_main_tf2.py"", line 103, in main
    use_tpu=FLAGS.use_tpu)
  File ""/content/models/research/object_detection/model_lib_v2.py"", line 554, in train_loop
    unpad_groundtruth_tensors)
  File ""/content/models/research/object_detection/model_lib_v2.py"", line 335, in load_fine_tune_checkpoint
    if not is_object_based_checkpoint(checkpoint_path):
  File ""/content/models/research/object_detection/model_lib_v2.py"", line 298, in is_object_based_checkpoint
    var_names = [var[0] for var in tf.train.list_variables(checkpoint_path)]
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/checkpoint_utils.py"", line 98, in list_variables
    reader = load_checkpoint(ckpt_dir_or_file)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/checkpoint_utils.py"", line 67, in load_checkpoint
    return py_checkpoint_reader.NewCheckpointReader(filename)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/py_checkpoint_reader.py"", line 99, in NewCheckpointReader
    error_translator(e)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/py_checkpoint_reader.py"", line 35, in error_translator
    raise errors_impl.NotFoundError(None, None, error_message)

## 6. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Google Colab
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below): 2.2
- Python version: 3.6
",martinlyons,b'models:research stat:awaiting response type:bug',2020-07-23T05:38:04Z,2020-07-23T16:53:25Z,,,,,,,
8942,"running model/research/object_detection/builders/model_builder_tf2_test.py yields error "" tensorflow has not attribute contrib""","# Prerequisites

Please answer the following questions for yourself before submitting an issue.

- [ x] I am using the latest TensorFlow Model Garden release and TensorFlow 2.
- [ x] I am reporting the issue to the correct repository. (Model Garden official or research directory)
- [ x] I checked to make sure that this issue has not already been filed.

## 1. The entire URL of the file you are using

https://github.com/tensorflow/models/tree/master/research/object_detection/builders/model_builder_tf2_test.py

## 2. Describe the bug

trying to run model_builder.py file using 
`python model_builder_tf2_test.py`

and get the following error:
`Traceback (most recent call last):
  File ""model_builder_tf2_test.py"", line 24, in <module>
    from object_detection.builders import model_builder
  File ""C:\tensorflow\models\research\object_detection\builders\model_builder.py"", line 19, in <module>
    from object_detection.builders import box_predictor_builder
  File ""C:\tensorflow\models\research\object_detection\builders\box_predictor_builder.py"", line 18, in <module>
    from object_detection.core import box_predictor
  File ""C:\tensorflow\models\research\object_detection\core\box_predictor.py"", line 36, in <module>
    slim = tf.contrib.slim
AttributeError: module 'tensorflow' has no attribute 'contrib'`

## 3. Steps to reproduce

run from command line the \models\research\object_detection\builders\model_builder.py   script and get the error reported above

## 4. Expected behavior

Expect no error.  This error was previously reported when Object Detection API was not supported in TF2 but, it is now.

## 5. Additional context

Include any logs that would be helpful to diagnose the problem.

## 6. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- Mobile device name if the issue happens on a mobile device:
- TensorFlow installed from (source or binary): pip install
- TensorFlow version (use command below): 2.3.0-rc
- Python version: 3.7.4
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

<!-- 
Collect system information using our environment capture script.
https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.shrunn

You can also obtain the TensorFlow version with:

1. TensorFlow 1.0
`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

2. TensorFlow 2.0
`python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`
-->
",grewe,b'models:research stat:awaiting response type:bug',2020-07-22T21:45:11Z,2020-09-08T07:20:04Z,,,,,,,
8940,DELF GLDv2 training error: `Fatal Python error: Segmentation fault.`,"I might be interrupting. @andrefaraujo 

## 1. The entire URL of the file you are using
https://github.com/tensorflow/models/tree/master/research/delf/delf/python/training

## 2. Describe the bug
I run the train.py followed the instruction and an error occurs.
`Fatal Python error: Segmentation fault.`

Details are below. The problem may between [363](https://github.com/tensorflow/models/blob/567bd18d4e6c1e31e4e58d3ffee0127f81bc1ab8/research/delf/delf/python/training/train.py#L362)-[367](https://github.com/tensorflow/models/blob/567bd18d4e6c1e31e4e58d3ffee0127f81bc1ab8/research/delf/delf/python/training/train.py#L366) in train.py by following the output of `logging.info()`.


I0722 08:21:29.993298 140327930558272 train.py:120] Running training script with

I0722 08:21:29.993462 140327930558272 train.py:121] logdir= gldv2_training
I0722 08:21:29.993936 140327930558272 train.py:122] initial_lr= 0.010000
I0722 08:21:29.994389 140327930558272 train.py:123] block3_strides= True
2020-07-22 08:21:29.995690: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-07-22 08:21:30.064180: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties:
pciBusID: 0000:04:00.0 name: Tesla P40 computeCapability: 6.1
coreClock: 1.531GHz coreCount: 30 deviceMemorySize: 23.88GiB deviceMemoryBandwidth: 323.21GiB/s
2020-07-22 08:21:30.066700: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 1 with properties:
pciBusID: 0000:06:00.0 name: Tesla P40 computeCapability: 6.1
coreClock: 1.531GHz coreCount: 30 deviceMemorySize: 23.88GiB deviceMemoryBandwidth: 323.21GiB/s
2020-07-22 08:21:30.069208: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 2 with properties:
pciBusID: 0000:07:00.0 name: Tesla P40 computeCapability: 6.1
coreClock: 1.531GHz coreCount: 30 deviceMemorySize: 23.88GiB deviceMemoryBandwidth: 323.21GiB/s
2020-07-22 08:21:30.071704: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 3 with properties:
pciBusID: 0000:08:00.0 name: Tesla P40 computeCapability: 6.1
coreClock: 1.531GHz coreCount: 30 deviceMemorySize: 23.88GiB deviceMemoryBandwidth: 323.21GiB/s
2020-07-22 08:21:30.074091: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 4 with properties:
pciBusID: 0000:0c:00.0 name: Tesla P40 computeCapability: 6.1
coreClock: 1.531GHz coreCount: 30 deviceMemorySize: 23.88GiB deviceMemoryBandwidth: 323.21GiB/s
2020-07-22 08:21:30.076454: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 5 with properties:
pciBusID: 0000:0d:00.0 name: Tesla P40 computeCapability: 6.1
coreClock: 1.531GHz coreCount: 30 deviceMemorySize: 23.88GiB deviceMemoryBandwidth: 323.21GiB/s
2020-07-22 08:21:30.078852: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 6 with properties:
pciBusID: 0000:0e:00.0 name: Tesla P40 computeCapability: 6.1
coreClock: 1.531GHz coreCount: 30 deviceMemorySize: 23.88GiB deviceMemoryBandwidth: 323.21GiB/s
2020-07-22 08:21:30.081129: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 7 with properties:
pciBusID: 0000:0f:00.0 name: Tesla P40 computeCapability: 6.1
coreClock: 1.531GHz coreCount: 30 deviceMemorySize: 23.88GiB deviceMemoryBandwidth: 323.21GiB/s
2020-07-22 08:21:30.081347: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-07-22 08:21:30.083051: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-07-22 08:21:30.084738: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-07-22 08:21:30.085027: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-07-22 08:21:30.086848: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-07-22 08:21:30.087870: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-07-22 08:21:30.091821: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-07-22 08:21:30.130943: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0, 1, 2, 3, 4, 5, 6, 7
2020-07-22 08:21:30.131306: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-07-22 08:21:30.146241: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 2199885000 Hz
2020-07-22 08:21:30.150533: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56131c7b91b0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-07-22 08:21:30.150559: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-07-22 08:21:31.578771: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56131c0f1340 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-07-22 08:21:31.578812: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla P40, Compute Capability 6.1
2020-07-22 08:21:31.578822: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (1): Tesla P40, Compute Capability 6.1
2020-07-22 08:21:31.578830: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (2): Tesla P40, Compute Capability 6.1
2020-07-22 08:21:31.578837: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (3): Tesla P40, Compute Capability 6.1
2020-07-22 08:21:31.578844: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (4): Tesla P40, Compute Capability 6.1
2020-07-22 08:21:31.578851: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (5): Tesla P40, Compute Capability 6.1
2020-07-22 08:21:31.578859: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (6): Tesla P40, Compute Capability 6.1
2020-07-22 08:21:31.578866: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (7): Tesla P40, Compute Capability 6.1
2020-07-22 08:21:31.622038: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties:
pciBusID: 0000:04:00.0 name: Tesla P40 computeCapability: 6.1
coreClock: 1.531GHz coreCount: 30 deviceMemorySize: 23.88GiB deviceMemoryBandwidth: 323.21GiB/s
2020-07-22 08:21:31.624129: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 1 with properties:
pciBusID: 0000:06:00.0 name: Tesla P40 computeCapability: 6.1
coreClock: 1.531GHz coreCount: 30 deviceMemorySize: 23.88GiB deviceMemoryBandwidth: 323.21GiB/s
2020-07-22 08:21:31.626215: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 2 with properties:
pciBusID: 0000:07:00.0 name: Tesla P40 computeCapability: 6.1
coreClock: 1.531GHz coreCount: 30 deviceMemorySize: 23.88GiB deviceMemoryBandwidth: 323.21GiB/s
2020-07-22 08:21:31.628316: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 3 with properties:
pciBusID: 0000:08:00.0 name: Tesla P40 computeCapability: 6.1
coreClock: 1.531GHz coreCount: 30 deviceMemorySize: 23.88GiB deviceMemoryBandwidth: 323.21GiB/s
2020-07-22 08:21:31.630404: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 4 with properties:
pciBusID: 0000:0c:00.0 name: Tesla P40 computeCapability: 6.1
coreClock: 1.531GHz coreCount: 30 deviceMemorySize: 23.88GiB deviceMemoryBandwidth: 323.21GiB/s
2020-07-22 08:21:31.632471: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 5 with properties:
pciBusID: 0000:0d:00.0 name: Tesla P40 computeCapability: 6.1
coreClock: 1.531GHz coreCount: 30 deviceMemorySize: 23.88GiB deviceMemoryBandwidth: 323.21GiB/s
2020-07-22 08:21:31.634446: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 6 with properties:
pciBusID: 0000:0e:00.0 name: Tesla P40 computeCapability: 6.1
coreClock: 1.531GHz coreCount: 30 deviceMemorySize: 23.88GiB deviceMemoryBandwidth: 323.21GiB/s
2020-07-22 08:21:31.636402: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 7 with properties:
pciBusID: 0000:0f:00.0 name: Tesla P40 computeCapability: 6.1
coreClock: 1.531GHz coreCount: 30 deviceMemorySize: 23.88GiB deviceMemoryBandwidth: 323.21GiB/s
2020-07-22 08:21:31.636453: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-07-22 08:21:31.636473: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-07-22 08:21:31.636489: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-07-22 08:21:31.636506: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-07-22 08:21:31.636522: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-07-22 08:21:31.636537: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-07-22 08:21:31.636554: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-07-22 08:21:31.668968: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0, 1, 2, 3, 4, 5, 6, 7
2020-07-22 08:21:31.669017: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-07-22 08:21:31.686490: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-07-22 08:21:31.686513: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 1 2 3 4 5 6 7
2020-07-22 08:21:31.686525: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N Y Y Y Y Y Y Y
2020-07-22 08:21:31.686533: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 1:   Y N Y Y Y Y Y Y
2020-07-22 08:21:31.686541: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 2:   Y Y N Y Y Y Y Y
2020-07-22 08:21:31.686548: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 3:   Y Y Y N Y Y Y Y
2020-07-22 08:21:31.686563: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 4:   Y Y Y Y N Y Y Y
2020-07-22 08:21:31.686571: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 5:   Y Y Y Y Y N Y Y
2020-07-22 08:21:31.686578: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 6:   Y Y Y Y Y Y N Y
2020-07-22 08:21:31.686586: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 7:   Y Y Y Y Y Y Y N
2020-07-22 08:21:31.710870: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 22837 MB memory) -> physical GPU (device: 0, name: Tesla P40, pci
bus id: 0000:04:00.0, compute capability: 6.1)
2020-07-22 08:21:31.713223: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 22837 MB memory) -> physical GPU (device: 1, name: Tesla P40, pci
bus id: 0000:06:00.0, compute capability: 6.1)
2020-07-22 08:21:31.715586: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 22837 MB memory) -> physical GPU (device: 2, name: Tesla P40, pci
bus id: 0000:07:00.0, compute capability: 6.1)
2020-07-22 08:21:31.717907: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:3 with 22837 MB memory) -> physical GPU (device: 3, name: Tesla P40, pci
bus id: 0000:08:00.0, compute capability: 6.1)
2020-07-22 08:21:31.720255: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:4 with 22837 MB memory) -> physical GPU (device: 4, name: Tesla P40, pci
bus id: 0000:0c:00.0, compute capability: 6.1)
2020-07-22 08:21:31.722603: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:5 with 22837 MB memory) -> physical GPU (device: 5, name: Tesla P40, pci
bus id: 0000:0d:00.0, compute capability: 6.1)
2020-07-22 08:21:31.724940: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:6 with 22837 MB memory) -> physical GPU (device: 6, name: Tesla P40, pci
bus id: 0000:0e:00.0, compute capability: 6.1)
2020-07-22 08:21:31.727318: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:7 with 22837 MB memory) -> physical GPU (device: 7, name: Tesla P40, pci
bus id: 0000:0f:00.0, compute capability: 6.1)
INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3', '/job:localhost/replica:0/task:0/device:GPU:4', '/job:localhost/replica:0/task:0/device:GPU:5', '/job:localhost/replica:0/task:0/device:GPU:6', '/job:localhost/replica:0/task:0/device:GPU:7')
I0722 08:21:31.735625 140327930558272 mirrored_strategy.py:500] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3', '/job:localhost/replica:0/task:0/device:GPU:4', '/job:localhost/replica:0/task:0/device:GPU:5', '/job:localhost/replica:0/task:0/device:GPU:6', '/job:localhost/replica:0/task:0/device:GPU:7')
I0722 08:21:31.735947 140327930558272 train.py:128] Number of devices: 8
WARNING:tensorflow:From /home/xinkong/.local/lib/python3.6/site-packages/tensorflow/python/ops/image_ops_impl.py:2827: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.
Instructions for updating:
`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.
W0722 08:21:33.257451 140327930558272 deprecation.py:323] From /home/xinkong/.local/lib/python3.6/site-packages/tensorflow/python/ops/image_ops_impl.py:2827: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.
Instructions for updating:
`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.
I0722 08:21:41.587657 140327930558272 train.py:210] Model, datasets loaded.
num_classes= 81313
I0722 08:21:41.596926 140327930558272 train.py:363] Attempting to load ImageNet pretrained weights.
INFO:tensorflow:batch_all_reduce: 214 all-reduces with algorithm = nccl, num_packs = 1
I0722 08:22:10.150980 140327930558272 cross_device_ops.py:698] batch_all_reduce: 214 all-reduces with algorithm = nccl, num_packs = 1
INFO:tensorflow:batch_all_reduce: 8 all-reduces with algorithm = nccl, num_packs = 1
I0722 08:22:20.667220 140327930558272 cross_device_ops.py:698] batch_all_reduce: 8 all-reduces with algorithm = nccl, num_packs = 1
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
I0722 08:22:22.086211 140327930558272 cross_device_ops.py:440] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
I0722 08:22:22.087918 140327930558272 cross_device_ops.py:440] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:batch_all_reduce: 214 all-reduces with algorithm = nccl, num_packs = 1
I0722 08:22:47.857083 140327930558272 cross_device_ops.py:698] batch_all_reduce: 214 all-reduces with algorithm = nccl, num_packs = 1
INFO:tensorflow:batch_all_reduce: 8 all-reduces with algorithm = nccl, num_packs = 1
I0722 08:22:57.193145 140327930558272 cross_device_ops.py:698] batch_all_reduce: 8 all-reduces with algorithm = nccl, num_packs = 1
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
I0722 08:22:58.614024 140327930558272 cross_device_ops.py:440] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
I0722 08:22:58.616227 140327930558272 cross_device_ops.py:440] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
2020-07-22 08:23:27.528045: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-07-22 08:23:27.791325: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
Fatal Python error: Segmentation fault

Thread 0x00007fa0a473f740 (most recent call first):
  File ""/home/xinkong/.local/lib/python3.6/site-packages/tensorflow/python/eager/execute.py"", line 60 in quick_execute
  File ""/home/xinkong/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py"", line 598 in call
  File ""/home/xinkong/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py"", line 1746 in _call_flat
  File ""/home/xinkong/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py"", line 1665 in _filtered_call
  File ""/home/xinkong/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py"", line 2420 in __call__
  File ""/home/xinkong/.local/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py"", line 644 in _call
  File ""/home/xinkong/.local/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py"", line 580 in __call__
  File ""train.py"", line 365 in main
  File ""/home/xinkong/.local/lib/python3.6/site-packages/absl/app.py"", line 250 in _run_main
  File ""/home/xinkong/.local/lib/python3.6/site-packages/absl/app.py"", line 299 in run
  File ""train.py"", line 472 in <module>
Segmentation fault (core dumped)

## 6. System information

- OS Platform and Distribution: gcc version 4.8.2 20140120 (Red Hat 4.8.2-16)
- TensorFlow installed from (source or binary): pip install tensorflow-gpu
- TensorFlow version (use command below):  the latest version
- Python version: 3.6
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 10
- GPU model and memory: P40, 24G, 8 in total

Could anyone help me? Thanks! ",kxhit,b'models:research type:bug',2020-07-22T08:43:37Z,2020-07-27T16:59:18Z,,,,,,,
8933,ERROR: No matching distribution found for opencv-python-headless,"# Prerequisites

Please answer the following questions for yourself before submitting an issue.

- [x ] I am using the latest TensorFlow Model Garden release and TensorFlow 2.
- [x ] I am reporting the issue to the correct repository. (Model Garden official or research directory)
- [x ] I checked to make sure that this issue has not been filed already.

## 1. The entire URL of the file you are using

git clone https://github.com/tensorflow/models.git

## 2. Describe the bug

""ERROR: Could not find a version that satisfies the requirement opencv-python-headless (from tf-models-official->object-detection==0.1) (from versions: none)
ERROR: No matching distribution found for opencv-python-headless (from tf-models-official->object-detection==0.1)""

## 3. Steps to reproduce

Followed the Object Detection API with Tensorflow 2 instructions [here](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2.md)

After a successful ""Compile protos."" I began the ""Install TensorFlow Object Detection API."" 
The python pip install ran smoothly until I encountered the ""Error"" described above.

## 4. Expected behavior

Did not expect the ""No matching distribution found for opencv-python-headless""
I am presently running opencv-python 4.1.2 and did not see a requirement to be running opencv-python-headless in the requirements list.

## 5. Additional context

Include any logs that would be helpful to diagnose the problem.

## 6. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): NVIDIA Jetpack 4.3 (Ubuntu 18.04 Desktop) 
- Mobile device name if the issue happens on a mobile device:
- TensorFlow installed from (source or binary): pip
- TensorFlow version (use command below): 2.1.0 (NVIDIA Tensorflow package install)
- Python version: 3.6.9
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 10.0.326/7.6
- GPU model and memory: Jetson Nano 4GB
",TCIII,b'models:research stat:awaiting response type:bug',2020-07-21T23:03:04Z,2020-07-24T11:26:32Z,,,,,,,
8931,Mask RCNN with Distributed Strategy,"Having the following issue on MaskRCNN with Distributed Strategy. 

tensorflow.python.framework.errors_impl.InvalidArgumentError:  indices[0] = 0 is not in [0, 0)
         [[{{node parser/GatherV2_2}}]]
         [[MultiDeviceIteratorGetNextFromShard]]
         [[RemoteCall]]
         [[IteratorGetNext]] [Op:__inference_train_step_234790]
",ashiqimranintel,b'models:official stat:awaiting model gardener type:bug',2020-07-21T16:55:56Z,2020-08-05T16:42:55Z,,,,,,,
8925,Module in util not found ,"When i try to install util there are error pop up even i already install the util

----> 8 from utils import plot_bbs
      9 
     10 

ImportError: cannot import name 'plot_bbs'

I already install utils by
pip install utils",archy44,b'stat:awaiting response type:bug',2020-07-21T08:37:22Z,2020-09-01T13:33:20Z,,,,,,,
8922,the lenet not right,"# Prerequisites

Please answer the following questions for yourself before submitting an issue.

- [ ] I am using the latest TensorFlow Model Garden release and TensorFlow 2.
1.13
- [ ] I am reporting the issue to the correct repository. (Model Garden official or research directory)
models/research/slim/nets/lenet.py 
- [ ] I checked to make sure that this issue has not already been filed.
yes

## 1. The entire URL of the file you are using

https://github.com/tensorflow/models/tree/master/research/slim/nets/lenet.py 

## 2. Describe the bug
the lenet out of line with the original doc 《Gradient-Based Learning Applied to Document Recognition》


",djh123,b'models:research type:bug',2020-07-21T02:01:42Z,2020-07-21T02:26:35Z,,,,,,,
8919,object_detection_tutorial.ipynb not found,"Dear all,
I am using Tensorflow latest version for the Object Detection API. I followed all installation steps and explanations on Github and Youtube and everything worked fine with only one problem. There should be a file named object_detection_tutorial.ipynb in Tensorflow1\models\research\object_detection, but I cant find it I dont know why. I have looked almost every where to solve this issue but I didnt solve it. 
Is there a place where I can download the file separately? or I missed something ?",mohammed-ab99,b'models:official type:bug',2020-07-20T16:16:17Z,2020-07-20T19:20:14Z,,,,,,,
8916,Is tensorflow usable in a thread (C++) ?," Hi everyone, I'm using tensorflow in my own C++ object detection script and since I decided to use thread to maximize the performance of it, my ""session-> run"" command is not working anymore even if the argument are exactly the same. I'm using my own object detection model so i cannot provide any link of it.


   Have I written custom code (as opposed to using a stock example script provided in TensorFlow):yes
    OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Ubuntu 18.04
    Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
    TensorFlow installed from (source or binary):source
    TensorFlow version (use command below):1.15.2
    Python version:3.8
    Bazel version (if compiling from source):0.26.1
    GCC/Compiler version (if compiling from source):5.5
    CUDA/cuDNN version:10.1/7.5
    GPU model and memory:Jetson Xavier

Describe the current behavior
I'm working on creating an object detection script using Tensorflow in C++. For this, I've used https://github.com/lysukhin/tensorflow-object-detection-cpp as a start and after some changes to make it faster, I'm able to run it at a very good speed on the Jetson Xavier. But today, I would like to separate the capture and inference task to let them run by themself as threads. The problem is that my ""session ->run"" instruction is not giving me any information about what is going on. The only thing that I know is that my session->run is not working properly because it should output a tensorflow::Status and I'm getting nothing (neither an error). Since there is no error, It is pretty hard for me to find why my run instruction is not doing anything.

Thanks for the futur help !
",Kmarconi,b'models:research type:bug',2020-07-20T08:51:32Z,2020-07-29T13:34:58Z,,,,,,,
8914,AssertionError: Some Python objects were not bound to checkpointed values when trying to save models from checkpoints,"# Prerequisites

Please answer the following questions for yourself before submitting an issue.

- [ ] I am using the latest TensorFlow Model Garden release and TensorFlow 2.
- [ ] I am reporting the issue to the correct repository. (Model Garden official or research directory)
- [ ] I checked to make sure that this issue has not been filed already.

## 1. The entire URL of the file you are using

https://github.com/tensorflow/models/tree/master/official/...

## 2. Describe the bug

I have trained the classification and have some checkpoints in 'train and eval' model. In order to get the saved model in tf2, I start the run_classification.py in 'export_only' mode which are aimed to transfer my checkpoints to model.
I run the code
'''''''''''
python run_classifier.py \
  --mode='export_only' \
  --input_meta_data_path=${GLUE_DIR}/${TASK}_meta_data \
  --bert_config_file=${BERT_DIR}/bert_config.json \
  --model_dir=${MODEL_DIR} \
  --model_export_path=${SAVED_MODEL_DIR}
''''''''''''
with the error: 
AssertionError: Some Python objects were not bound to checkpointed values, likely due to changes in the Python program: [<tf.Variable 'transformer/layer_2/output_layer_norm/gamma:0' shape=(768,) dtype=float32, numpy

## 3. Steps to reproduce



## 4. Expected behavior

model exported.

## 5. Additional context

None

## 6. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):CentOS 7
- Mobile device name if the issue happens on a mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below): tf-nightly(tf2.0)
- Python version:3.6
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:10.1
- GPU model and memory:GTX 1080Ti 16GB
",monologue1107,b'models:official stat:awaiting response type:bug',2020-07-20T08:42:48Z,2020-07-31T06:58:16Z,,,,,,,
8908,"CenterNet ValueError: Dimensions must be equal, but are 90601 and 92416 for '{{node Loss/mul_1}} = Mul[T=DT_FLOAT](Loss/Pow_1, Loss/Pow_2)' with input shapes: [1,90601,1], [1,92416,1].","I was trying to use CenterNet for my dataset. Upon changing the dimensions in `image_resizer`, I'm getting following error:

```
Traceback (most recent call last):
  File ""object_detection/model_main_tf2.py"", line 106, in <module>
    tf.compat.v1.app.run()
  File ""/home/deploy/.local/lib/python3.6/site-packages/tensorflow/python/platform/app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""/usr/local/lib/python3.6/site-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/usr/local/lib/python3.6/site-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""object_detection/model_main_tf2.py"", line 103, in main
    use_tpu=FLAGS.use_tpu)
  File ""/home/deploy/.local/lib/python3.6/site-packages/object_detection/model_lib_v2.py"", line 622, in train_loop
    loss = _dist_train_step(train_input_iter)
  File ""/home/deploy/.local/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py"", line 580, in __call__
    result = self._call(*args, **kwds)
  File ""/home/deploy/.local/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py"", line 627, in _call
    self._initialize(args, kwds, add_initializers_to=initializers)
  File ""/home/deploy/.local/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py"", line 506, in _initialize
    *args, **kwds))
  File ""/home/deploy/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py"", line 2446, in _get_concrete_function_internal_garbage_collected
    graph_function, _, _ = self._maybe_define_function(args, kwargs)
  File ""/home/deploy/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py"", line 2777, in _maybe_define_function
    graph_function = self._create_graph_function(args, kwargs)
  File ""/home/deploy/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py"", line 2667, in _create_graph_function
    capture_by_value=self._capture_by_value),
  File ""/home/deploy/.local/lib/python3.6/site-packages/tensorflow/python/framework/func_graph.py"", line 981, in func_graph_from_py_func
    func_outputs = python_func(*func_args, **func_kwargs)
  File ""/home/deploy/.local/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py"", line 441, in wrapped_fn
    return weak_wrapped_fn().__wrapped__(*args, **kwds)
  File ""/home/deploy/.local/lib/python3.6/site-packages/tensorflow/python/framework/func_graph.py"", line 968, in wrapper
    raise e.ag_error_metadata.to_exception(e)
ValueError: in user code:

    /home/deploy/.local/lib/python3.6/site-packages/object_detection/model_lib_v2.py:608 _dist_train_step  *
        return _sample_and_train(strategy, train_step_fn, data_iterator)
    /home/deploy/.local/lib/python3.6/site-packages/object_detection/model_lib_v2.py:590 _sample_and_train  *
        per_replica_losses = strategy.run(
    /home/deploy/.local/lib/python3.6/site-packages/object_detection/model_lib_v2.py:573 train_step_fn  *
        loss = eager_train_step(
    /home/deploy/.local/lib/python3.6/site-packages/object_detection/model_lib_v2.py:246 eager_train_step  *
        losses_dict, _ = _compute_losses_and_predictions_dicts(
    /home/deploy/.local/lib/python3.6/site-packages/object_detection/model_lib_v2.py:123 _compute_losses_and_predictions_dicts  *
        losses_dict = model.loss(
    /home/deploy/.local/lib/python3.6/site-packages/object_detection/meta_architectures/center_net_meta_arch.py:2325 loss  *
        object_center_loss = self._compute_object_center_loss(
    /home/deploy/.local/lib/python3.6/site-packages/object_detection/meta_architectures/center_net_meta_arch.py:1745 _compute_object_center_loss  *
        loss += object_center_loss(
    /home/deploy/.local/lib/python3.6/site-packages/object_detection/core/losses.py:92 __call__  *
        return self._compute_loss(prediction_tensor, target_tensor, **params)
    /home/deploy/.local/lib/python3.6/site-packages/object_detection/core/losses.py:741 _compute_loss  *
        negative_loss = (tf.math.pow((1 - target_tensor), self._beta)*
    /home/deploy/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:984 binary_op_wrapper
        return func(x, y, name=name)
    /home/deploy/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:1283 _mul_dispatch
        return gen_math_ops.mul(x, y, name=name)
    /home/deploy/.local/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py:6092 mul
        ""Mul"", x=x, y=y, name=name)
    /home/deploy/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:744 _apply_op_helper
        attrs=attr_protos, op_def=op_def)
    /home/deploy/.local/lib/python3.6/site-packages/tensorflow/python/framework/func_graph.py:595 _create_op_internal
        compute_device)
    /home/deploy/.local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py:3327 _create_op_internal
        op_def=op_def)
    /home/deploy/.local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py:1817 __init__
        control_input_ops, op_def)
    /home/deploy/.local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py:1657 _create_c_op
        raise ValueError(str(e))

    ValueError: Dimensions must be equal, but are 90601 and 92416 for '{{node Loss/mul_1}} = Mul[T=DT_FLOAT](Loss/Pow_1, Loss/Pow_2)' with input shapes: [1,90601,1], [1,92416,1].
```

Here, is my config I used for training:

```
# CenterNet meta-architecture from the ""Objects as Points"" [1] paper
# with the ResNet-v2-101 backbone. The ResNet backbone has a few differences
# as compared to the one mentioned in the paper, hence the performance is
# slightly worse. This config is TPU comptatible.
# [1]: https://arxiv.org/abs/1904.07850

model {
  center_net {
    num_classes: 1
    feature_extractor {
      type: ""resnet_v2_50""
    }
    image_resizer {
      keep_aspect_ratio_resizer {
        min_dimension: 360
        max_dimension: 1205
        pad_to_max_dimension: true
      }
    }
    object_detection_task {
      task_loss_weight: 1.0
      offset_loss_weight: 1.0
      scale_loss_weight: 0.1
      localization_loss {
        l1_localization_loss {
        }
      }
    }
    object_center_params {
      object_center_loss_weight: 1.0
      min_box_overlap_iou: 0.7
      max_box_predictions: 100
      classification_loss {
        penalty_reduced_logistic_focal_loss {
          alpha: 2.0
          beta: 4.0
        }
      }
    }
    # mask_estimation_task{
    #   task_loss_weight: 4.0
    #   classification_loss {
    #     penalty_reduced_logistic_focal_loss {
    #       alpha: 2.0
    #       beta: 4.0
    #     }
    #   }
    # }
  }
}

train_config: {
  batch_size: 1
  num_steps: 150000

  data_augmentation_options {
    random_horizontal_flip {
    }
  }
  data_augmentation_options {
    random_crop_image {
      min_object_covered: 0.0
      min_aspect_ratio: 0.75
      max_aspect_ratio: 3.0
      min_area: 0.75
      max_area: 1.0
      overlap_thresh: 0.0
    }
  }

  optimizer {
    adam_optimizer: {
      epsilon: 1e-7  # Match tf.keras.optimizers.Adam's default.
      learning_rate: {
        cosine_decay_learning_rate {
          learning_rate_base: 1e-3
          total_steps: 150000
          warmup_learning_rate: 2.5e-4
          warmup_steps: 5000
        }
      }
    }
    use_moving_average: false
  }
  max_number_of_boxes: 100
  unpad_groundtruth_tensors: false

  fine_tune_checkpoint_version: V2
  #fine_tune_checkpoint: ""/home/deploy/ved/centernet_resnet101_v1_fpn_512x512_coco17_tpu-8/checkpoint/ckpt-0""
  fine_tune_checkpoint_type: ""detection""
}

train_input_reader: {
  label_map_path: ""/home/deploy/ved/label_map_potato_l1.pbtxt""
  tf_record_input_reader {
    input_path: ""/home/deploy/ved/potato_l1_3x1_11_train.record""
  }
  load_instance_masks: true
  mask_type: PNG_MASKS
}

eval_config: {
  metrics_set: ""coco_detection_metrics""
  use_moving_averages: false
  num_visualizations: 100
  batch_size: 1
}

eval_input_reader: {
  label_map_path: ""/home/deploy/ved/label_map_potato_l1.pbtxt""
  shuffle: false
  num_epochs: 1
  tf_record_input_reader {
    input_path: ""/home/deploy/ved/potato_l1_3x1_11_val.record""
  }
  mask_type: PNG_MASKS
  load_instance_masks: true
}
```

I was expecting to train the model with different input size.

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Debian 4.9.144-3.1
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): v2.2.0-rc4-8-g2b96f3662b
- Python version: 3.6.3
- CUDA/cuDNN version: 10.1
- GPU model and memory: 11441MiB",anshkumar,b'models:research type:bug',2020-07-19T14:19:18Z,2020-08-03T16:31:01Z,,,,,,,
8907,object detection api train label error,"# Prerequisites

Please answer the following questions for yourself before submitting an issue.

- [ NO] I am using the latest TensorFlow Model Garden release and TensorFlow 2.
- [YES ] I am reporting the issue to the correct repository. (Model Garden official or research directory)
- [YES ] I checked to make sure that this issue has not already been filed.

## 1. The entire URL of the file you are using

https://github.com/tensorflow/models/tree/master/research/...

## 2. Describe the bug

I found out during the object detection api training
The label on some pictures does not match the data I wrote to tfrecord. Even the right picture in the images of TensorBoard is the wrong label. But I used the tfrecord tool to detect and found no wrong label.
The error looks like this:
I have 3 kinds of pictures, the first kind of picture has 3 labels, and the second kind of picture also has three labels, but these three are different from the first kind of label. But when I went to check the images of TensorBoard, I found that the word displayed on the label of the second picture is the word of the label of the first picture, but the position of the box is the correct position of the label of the second picture. the thrid kind  picture still has this problem.

## 3. Steps to reproduce

I again confirmed the tfrecord generation script and regenerated tfrecord, and then deleted all the checkpoints for retraining.
There is still a problem with the picture displayed by TensorBoard.
Then I saved the model from the last checkpoint and directly performed object detection. Like the result of TensorBoard, only the object recognition of the first picture is normal, and only one label of the second picture is normal. The remaining two The label is not displayed, and the third image does not display the label. The results are the same as those displayed by TensorBoard.

## 4. Expected behavior

the data of object detection api receive should is which is the data I store in tfrecord

## 5. Additional context

Include any logs that would be helpful to diagnose the problem.

## 6. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows10
- Mobile device name if the issue happens on a mobile device: None
- TensorFlow installed from (source or binary): pip
- TensorFlow version (use command below): 1.15.0
- Python version: 3.7.7
- Bazel version (if compiling from source): None
- GCC/Compiler version (if compiling from source): None
- CUDA/cuDNN version: CUDA v10.0
- GPU model and memory: 8G

<!-- 
Collect system information using our environment capture script.
https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can also obtain the TensorFlow version with:

1. TensorFlow 1.0
`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

2. TensorFlow 2.0
`python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`
-->
",JiXiaoYao,b'models:research type:bug',2020-07-18T17:57:04Z,2020-07-22T13:55:05Z,,,,,,,
8892,"Object Detection API 2.0, error with load checkpoints:  A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used.","# Prerequisites

Please answer the following questions for yourself before submitting an issue.

- [ ] I am using the latest TensorFlow Model Garden release and TensorFlow 2.
- [ ] I am reporting the issue to the correct repository. (Model Garden official or research directory)
- [ ] I checked to make sure that this issue has not already been filed.

## 1. The entire URL of the file you are using

https://github.com/tensorflow/models/tree/master/research/object_detection

## 2. Describe the bug

Thanks for releasing the Object Detection API 2.0. I am trying to build the model on my own dataset. I downloaded the trained file from model zoo [CenterNet HourGlass104 512x512](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md). Then changed the configure file and test the code. A bug comes.
```
WARNING:tensorflow:Unresolved object in checkpoint: (root).model._feature_extractor._network.hourglass_network.1.inner_block.0.inner_block.0.inner_block.0.inner_block.0.decoder_block.1.conv_block.norm.moving_variance
W0716 19:56:53.424076 140587994642240 util.py:144] Unresolved object in checkpoint: (root).model._feature_extractor._network.hourglass_network.1.inner_block.0.inner_block.0.inner_block.0.inner_block.0.decoder_block.1.conv_block.norm.moving_variance
WARNING:tensorflow:Unresolved object in checkpoint: (root).model._feature_extractor._network.hourglass_network.1.inner_block.0.inner_block.0.inner_block.0.inner_block.0.decoder_block.1.skip.conv.kernel
W0716 19:56:53.424108 140587994642240 util.py:144] Unresolved object in checkpoint: (root).model._feature_extractor._network.hourglass_network.1.inner_block.0.inner_block.0.inner_block.0.inner_block.0.decoder_block.1.skip.conv.kernel
WARNING:tensorflow:Unresolved object in checkpoint: (root).model._feature_extractor._network.hourglass_network.1.inner_block.0.inner_block.0.inner_block.0.inner_block.0.decoder_block.1.skip.norm.axis
W0716 19:56:53.424140 140587994642240 util.py:144] Unresolved object in checkpoint: (root).model._feature_extractor._network.hourglass_network.1.inner_block.0.inner_block.0.inner_block.0.inner_block.0.decoder_block.1.skip.norm.axis
WARNING:tensorflow:Unresolved object in checkpoint: (root).model._feature_extractor._network.hourglass_network.1.inner_block.0.inner_block.0.inner_block.0.inner_block.0.decoder_block.1.skip.norm.gamma
W0716 19:56:53.424172 140587994642240 util.py:144] Unresolved object in checkpoint: (root).model._feature_extractor._network.hourglass_network.1.inner_block.0.inner_block.0.inner_block.0.inner_block.0.decoder_block.1.skip.norm.gamma
WARNING:tensorflow:Unresolved object in checkpoint: (root).model._feature_extractor._network.hourglass_network.1.inner_block.0.inner_block.0.inner_block.0.inner_block.0.decoder_block.1.skip.norm.beta
W0716 19:56:53.424204 140587994642240 util.py:144] Unresolved object in checkpoint: (root).model._feature_extractor._network.hourglass_network.1.inner_block.0.inner_block.0.inner_block.0.inner_block.0.decoder_block.1.skip.norm.beta
WARNING:tensorflow:Unresolved object in checkpoint: (root).model._feature_extractor._network.hourglass_network.1.inner_block.0.inner_block.0.inner_block.0.inner_block.0.decoder_block.1.skip.norm.moving_mean
W0716 19:56:53.424236 140587994642240 util.py:144] Unresolved object in checkpoint: (root).model._feature_extractor._network.hourglass_network.1.inner_block.0.inner_block.0.inner_block.0.inner_block.0.decoder_block.1.skip.norm.moving_mean
WARNING:tensorflow:Unresolved object in checkpoint: (root).model._feature_extractor._network.hourglass_network.1.inner_block.0.inner_block.0.inner_block.0.inner_block.0.decoder_block.1.skip.norm.moving_variance
W0716 19:56:53.424268 140587994642240 util.py:144] Unresolved object in checkpoint: (root).model._feature_extractor._network.hourglass_network.1.inner_block.0.inner_block.0.inner_block.0.inner_block.0.decoder_block.1.skip.norm.moving_variance
WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.
W0716 19:56:53.424301 140587994642240 util.py:152] **A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.**
```
**A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.**

I do not know how to resolve this issue!


## 6. System information

- OS Platform and Distribution: Linux Ubuntu 18.04
- TensorFlow installed from (source or binary): installed as the official guide and no error occurs.
- TensorFlow version (use command below): tensorflow 2.2.0
- Python version: 3.6
- CUDA/cuDNN version: CUDA 10.2, CuDNN 7.6
- GPU model and memory: 2x 2080 Ti

",Derekabc,b'models:research type:bug',2020-07-17T00:49:44Z,2020-09-29T02:01:22Z,,,,,,,
8888,Object Detection API Demo: Instance Segmentation example doesn't work,"# Prerequisites

Please answer the following questions for yourself before submitting an issue.

- [x] I am using the latest TensorFlow Model Garden release and TensorFlow 2.
- [x] I am reporting the issue to the correct repository. (Model Garden official or research directory)
- [x] I checked to make sure that this issue has not already been filed.

## 1. The entire URL of the file you are using

https://github.com/tensorflow/models/blob/master/research/object_detection/colab_tutorials/object_detection_tutorial.ipynb

## 2. Describe the bug

The last section of the colab notebook is supposed to show inference using a pretrained Mask-RCNN. However, it throws the following errors:

 ---------------------------------------------------------------------------
> AttributeError                            Traceback (most recent call last)
> <ipython-input-20-31bf89ff98cf> in <module>()
> ----> 1 masking_model.output_shapes

>AttributeError: 'AutoTrackable' object has no attribute 'output_shapes'

and,

 ---------------------------------------------------------------------------

> TypeError                                 Traceback (most recent call last)
> <ipython-input-21-25f0f9a75087> in <module>()
>      1 for image_path in TEST_IMAGE_PATHS:
> ----> 2   show_inference(masking_model, image_path)

> 2 frames
> /usr/local/lib/python3.6/dist-packages/object_detection/utils/ops.py in reframe_box_masks_to_image_masks(box_masks, >boxes, image_height, image_width, resize_method)
>    823     as `box_masks`.
>    824   """"""
>--> 825   resize_method = 'nearest' if box_masks.dtype == tf.uint8 else resize_method
>    826   # TODO(rathodv): Make this a public function.
>    827   def reframe_box_masks_to_image_masks_default():

>TypeError: data type not understood

## 3. Steps to reproduce

Run the colab.

",khanx169,b'models:research stat:awaiting response type:bug',2020-07-16T18:43:02Z,2020-07-28T04:32:06Z,,,,,,,
8883,TF2 Object Detection API training script model_main_t2 not working - Stuck on Waiting for new checkpoint - Timed-out waiting for a checkpoint,"# Prerequisites

Please answer the following questions for yourself before submitting an issue.

- [Y ] I am using the latest TensorFlow Model Garden release and TensorFlow 2.
- [Y ] I am reporting the issue to the correct repository. (Model Garden official or research directory)
- [ Y] I checked to make sure that this issue has not been filed already.

## 1. The entire URL of the file you are using

https://github.com/tensorflow/models/tree/master/research/object_detection/model_main_tf2.py

## 2. Describe the bug

After running for a while, model_main_t2 get stuck on ""Waiting for new checkpoint"". Then ends with error: ""Timed-out waiting for a checkpoint""

## 3. Steps to reproduce

https://github.com/IvanBrasilico/ajna_bbox
The steps of tf2 installation are on the project README. Basically the steps described in the documentation (generate tf_records for training, download a model definition and check-point, edit pipeline.config with paths of tfrecord, run model_main_tf2.

## 4. Expected behavior

The expected behavior was to do the training procedure or at least pop an error message.

## 5. Additional context

The complete model_main_tf2.py console output is on the end of report

## 6. System information

Important to register that the example colab repository eager_few_shot_od_training_tf2.ipynb is running and training the same model, in the same virtualenv of the same machine.

- Linux Ubuntu 16.04:
- Python 3.6 ven
- Tensorlow 2.2 installed by pip
- CUDA/cuDNN version: Cuda 11 installed by apt
- GPU model and memory: 1050ti 4GB

Complete environment information:

https://github.com/IvanBrasilico/ajna_bbox/blob/master/tf_env.txt


**Complete model_main_tf2 output:**

(venv) ivan@ivan-G7-7588:~/PycharmProjects/ajna_bbox$ python models/research/object_detection/model_main_tf2.py --model_dir=/home/ivan/PycharmProjects/ajna_bbox/bases/models/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8/ --checkpoint_dir=/home/ivan/PycharmProjects/ajna_bbox/bases/models/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8/checkpoint --alsologtostderr  --pipeline_config_path=bases/models/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8/pipeline.config --use-tpu=true
WARNING:tensorflow:Forced number of epochs for all eval validations to be 1.
W0715 23:32:23.856509 140079432734464 model_lib_v2.py:905] Forced number of epochs for all eval validations to be 1.
INFO:tensorflow:Maybe overwriting sample_1_of_n_eval_examples: None
I0715 23:32:23.856632 140079432734464 config_util.py:552] Maybe overwriting sample_1_of_n_eval_examples: None
INFO:tensorflow:Maybe overwriting use_bfloat16: False
I0715 23:32:23.856686 140079432734464 config_util.py:552] Maybe overwriting use_bfloat16: False
INFO:tensorflow:Maybe overwriting eval_num_epochs: 1
I0715 23:32:23.856735 140079432734464 config_util.py:552] Maybe overwriting eval_num_epochs: 1
WARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.
W0715 23:32:23.856801 140079432734464 model_lib_v2.py:920] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.
2020-07-15 23:32:23.881471: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-07-15 23:32:23.923686: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-15 23:32:23.924041: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce GTX 1050 Ti computeCapability: 6.1
coreClock: 1.62GHz coreCount: 6 deviceMemorySize: 3.95GiB deviceMemoryBandwidth: 104.43GiB/s
2020-07-15 23:32:23.924195: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/cuda-9.0/lib64:/usr/local/cuda/extras/CUPTI/lib64
2020-07-15 23:32:23.924305: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcublas.so.10'; dlerror: libcublas.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/cuda-9.0/lib64:/usr/local/cuda/extras/CUPTI/lib64
2020-07-15 23:32:23.925568: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-07-15 23:32:23.925901: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-07-15 23:32:23.928778: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-07-15 23:32:23.928903: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusparse.so.10'; dlerror: libcusparse.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/cuda-9.0/lib64:/usr/local/cuda/extras/CUPTI/lib64
2020-07-15 23:32:23.932572: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-07-15 23:32:23.932610: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1598] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2020-07-15 23:32:23.932881: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-07-15 23:32:23.939320: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 2299965000 Hz
2020-07-15 23:32:23.939775: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x657f610 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-07-15 23:32:23.939791: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-07-15 23:32:23.941028: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-07-15 23:32:23.941041: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      
WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.
W0715 23:32:23.947229 140079432734464 dataset_builder.py:83] num_readers has been reduced to 1 to match input file shards.
WARNING:tensorflow:From /home/ivan/PycharmProjects/ajna_bbox/venv/lib/python3.6/site-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_deterministic`.
W0715 23:32:23.949348 140079432734464 deprecation.py:323] From /home/ivan/PycharmProjects/ajna_bbox/venv/lib/python3.6/site-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_deterministic`.
WARNING:tensorflow:From /home/ivan/PycharmProjects/ajna_bbox/venv/lib/python3.6/site-packages/object_detection/builders/dataset_builder.py:175: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.map()
W0715 23:32:23.965300 140079432734464 deprecation.py:323] From /home/ivan/PycharmProjects/ajna_bbox/venv/lib/python3.6/site-packages/object_detection/builders/dataset_builder.py:175: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.map()
WARNING:tensorflow:From /home/ivan/PycharmProjects/ajna_bbox/venv/lib/python3.6/site-packages/object_detection/inputs.py:79: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.
W0715 23:32:29.178085 140079432734464 deprecation.py:323] From /home/ivan/PycharmProjects/ajna_bbox/venv/lib/python3.6/site-packages/object_detection/inputs.py:79: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.
WARNING:tensorflow:From /home/ivan/PycharmProjects/ajna_bbox/venv/lib/python3.6/site-packages/object_detection/inputs.py:259: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
W0715 23:32:30.630500 140079432734464 deprecation.py:323] From /home/ivan/PycharmProjects/ajna_bbox/venv/lib/python3.6/site-packages/object_detection/inputs.py:259: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
INFO:tensorflow:Waiting for new checkpoint at /home/ivan/PycharmProjects/ajna_bbox/bases/models/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8/checkpoint
I0715 23:32:33.767113 140079432734464 checkpoint_utils.py:125] Waiting for new checkpoint at /home/ivan/PycharmProjects/ajna_bbox/bases/models/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8/checkpoint
INFO:tensorflow:Found new checkpoint at /home/ivan/PycharmProjects/ajna_bbox/bases/models/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8/checkpoint/ckpt-0
I0715 23:32:33.767870 140079432734464 checkpoint_utils.py:134] Found new checkpoint at /home/ivan/PycharmProjects/ajna_bbox/bases/models/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8/checkpoint/ckpt-0
WARNING:tensorflow:From /home/ivan/PycharmProjects/ajna_bbox/venv/lib/python3.6/site-packages/object_detection/eval_util.py:854: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
W0715 23:33:02.120177 140079432734464 deprecation.py:323] From /home/ivan/PycharmProjects/ajna_bbox/venv/lib/python3.6/site-packages/object_detection/eval_util.py:854: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
INFO:tensorflow:Finished eval step 0
I0715 23:33:11.245014 140079432734464 model_lib_v2.py:782] Finished eval step 0
WARNING:tensorflow:From /home/ivan/PycharmProjects/ajna_bbox/venv/lib/python3.6/site-packages/object_detection/utils/visualization_utils.py:618: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0715 23:33:11.261951 140079432734464 deprecation.py:323] From /home/ivan/PycharmProjects/ajna_bbox/venv/lib/python3.6/site-packages/object_detection/utils/visualization_utils.py:618: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
INFO:tensorflow:Performing evaluation on 21 images.
I0715 23:33:30.778897 140079432734464 coco_evaluation.py:237] Performing evaluation on 21 images.
creating index...
index created!
INFO:tensorflow:Loading and preparing annotation results...
I0715 23:33:30.779220 140079432734464 coco_tools.py:116] Loading and preparing annotation results...
INFO:tensorflow:DONE (t=0.00s)
I0715 23:33:30.780228 140079432734464 coco_tools.py:138] DONE (t=0.00s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=0.03s).
Accumulating evaluation results...
DONE (t=0.00s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.024
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.024
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.024
INFO:tensorflow:Eval metrics at step 0
I0715 23:33:30.815683 140079432734464 model_lib_v2.py:836] Eval metrics at step 0
INFO:tensorflow:        + DetectionBoxes_Precision/mAP: 0.000143
I0715 23:33:30.818211 140079432734464 model_lib_v2.py:839]      + DetectionBoxes_Precision/mAP: 0.000143
INFO:tensorflow:        + DetectionBoxes_Precision/mAP@.50IOU: 0.000286
I0715 23:33:30.818874 140079432734464 model_lib_v2.py:839]      + DetectionBoxes_Precision/mAP@.50IOU: 0.000286
INFO:tensorflow:        + DetectionBoxes_Precision/mAP@.75IOU: 0.000000
I0715 23:33:30.819247 140079432734464 model_lib_v2.py:839]      + DetectionBoxes_Precision/mAP@.75IOU: 0.000000
INFO:tensorflow:        + DetectionBoxes_Precision/mAP (small): -1.000000
I0715 23:33:30.819588 140079432734464 model_lib_v2.py:839]      + DetectionBoxes_Precision/mAP (small): -1.000000
INFO:tensorflow:        + DetectionBoxes_Precision/mAP (medium): -1.000000
I0715 23:33:30.819919 140079432734464 model_lib_v2.py:839]      + DetectionBoxes_Precision/mAP (medium): -1.000000
INFO:tensorflow:        + DetectionBoxes_Precision/mAP (large): 0.000215
I0715 23:33:30.820254 140079432734464 model_lib_v2.py:839]      + DetectionBoxes_Precision/mAP (large): 0.000215
INFO:tensorflow:        + DetectionBoxes_Recall/AR@1: 0.000000
I0715 23:33:30.820581 140079432734464 model_lib_v2.py:839]      + DetectionBoxes_Recall/AR@1: 0.000000
INFO:tensorflow:        + DetectionBoxes_Recall/AR@10: 0.023810
I0715 23:33:30.820914 140079432734464 model_lib_v2.py:839]      + DetectionBoxes_Recall/AR@10: 0.023810
INFO:tensorflow:        + DetectionBoxes_Recall/AR@100: 0.023810
I0715 23:33:30.821241 140079432734464 model_lib_v2.py:839]      + DetectionBoxes_Recall/AR@100: 0.023810
INFO:tensorflow:        + DetectionBoxes_Recall/AR@100 (small): -1.000000
I0715 23:33:30.821578 140079432734464 model_lib_v2.py:839]      + DetectionBoxes_Recall/AR@100 (small): -1.000000
INFO:tensorflow:        + DetectionBoxes_Recall/AR@100 (medium): -1.000000
I0715 23:33:30.821907 140079432734464 model_lib_v2.py:839]      + DetectionBoxes_Recall/AR@100 (medium): -1.000000
INFO:tensorflow:        + DetectionBoxes_Recall/AR@100 (large): 0.023810
I0715 23:33:30.822265 140079432734464 model_lib_v2.py:839]      + DetectionBoxes_Recall/AR@100 (large): 0.023810
INFO:tensorflow:        + Loss/localization_loss: 0.189787
I0715 23:33:30.822557 140079432734464 model_lib_v2.py:839]      + Loss/localization_loss: 0.189787
INFO:tensorflow:        + Loss/classification_loss: 1.298645
I0715 23:33:30.822857 140079432734464 model_lib_v2.py:839]      + Loss/classification_loss: 1.298645
INFO:tensorflow:        + Loss/regularization_loss: 0.176113
I0715 23:33:30.823152 140079432734464 model_lib_v2.py:839]      + Loss/regularization_loss: 0.176113
INFO:tensorflow:        + Loss/total_loss: 1.664544
I0715 23:33:30.823446 140079432734464 model_lib_v2.py:839]      + Loss/total_loss: 1.664544
INFO:tensorflow:Waiting for new checkpoint at /home/ivan/PycharmProjects/ajna_bbox/bases/models/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8/checkpoint
I0715 23:37:33.829480 140079432734464 checkpoint_utils.py:125] Waiting for new checkpoint at /home/ivan/PycharmProjects/ajna_bbox/bases/models/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8/checkpoint
INFO:tensorflow:Timed-out waiting for a checkpoint.
I0716 00:37:33.181403 140079432734464 checkpoint_utils.py:188] Timed-out waiting for a checkpoint.
",IvanBrasilico,b'models:research type:bug',2020-07-16T12:13:23Z,2020-07-30T11:03:32Z,,,,,,,
8877,ModuleNotFoundError: No module named 'tensorflow.compat.v1',"# Prerequisites

Please answer the following questions for yourself before submitting an issue.

- [ ] I am using the latest TensorFlow Model Garden release and TensorFlow 2.
- [x] I am reporting the issue to the correct repository. (Model Garden official or research directory)
- [x] I checked to make sure that this issue has not already been filed.

## 1. The entire URL of the file you are using

https://github.com/tensorflow/models/tree/master/research/feelvos

## 2. Describe the bug

I got the following error when running `bash train.sh`.
The README doesn't tell us which TF to use.

The backward compatibility of TF **is REALLY AWFUL**.

```
Traceback (most recent call last):
  File ""/mnt/lustre/xiehaozhe/Development/feelvos/train.py"", line 24, in <module>
    from feelvos import model
  File ""/mnt/lustre/xiehaozhe/Development/feelvos/model.py"", line 58, in <module>
    from deeplab import model
  File ""/mnt/lustre/xiehaozhe/Development/feelvos/deeplab/model.py"", line 58, in <module>
    from deeplab.core import feature_extractor
  File ""/mnt/lustre/xiehaozhe/Development/feelvos/deeplab/core/feature_extractor.py"", line 21, in <module>
    import tensorflow.compat.v1 as tf
ModuleNotFoundError: No module named 'tensorflow.compat.v1'
```

## 3. Steps to reproduce

```bash
bash train.sh
```

## 4. Expected behavior

The program runs normally without raising `ModuleNotFoundError: No module named 'tensorflow.compat.v1'`.

## 5. Additional context

None

## 6. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Cent OS 7.3
- Mobile device name if the issue happens on a mobile device: N/a
- TensorFlow installed from (source or binary): Binary
- TensorFlow version (use command below): 1.12.3
- Python version: 3.6.5
- Bazel version (if compiling from source): N/a
- GCC/Compiler version (if compiling from source): 5.4.0
- CUDA/cuDNN version: 9.0
- GPU model and memory: NVIDIA TITAN Xp / 12GB

<!-- 
Collect system information using our environment capture script.
https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can also obtain the TensorFlow version with:

1. TensorFlow 1.0
`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

2. TensorFlow 2.0
`python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`
-->
",hzxie,b'models:research type:bug',2020-07-16T08:05:40Z,2020-07-17T02:46:20Z,,,,,,,
8868,Issues with models/official/nlp/bert/run_pretraining.py,"Hello,

I'm using 
https://github.com/tensorflow/models/blob/master/official/nlp/bert/run_pretraining.py
to pre-train bert on my custom data. I'm using tf-nightly and training the model on cloud TPU. 

The code uses model_training_utils.run_customized_training_loop(), which has been deprecated and I get ""Unable to destroy remote tensor handles. If you are running a tf.function, it usually indicates some op in the graph gets an error"" from a line in that function.

Here is the error log:

```
***** Number of cores used :  32
I0715 00:59:07.309198 140290240782464 run_pretraining.py:178] Training using customized training loop TF 2.0 with distributedstrategy.
WARNING:tensorflow:From research/bert/pretraining/training/run_pretraining.py:165: run_customized_training_loop (from official.nlp.bert.model_training_utils) is deprecated and will be removed in a future version.
Instructions for updating:
This function is deprecated and we do not expect adding new functionalities. Please do not have your code depending on this library.
W0715 00:59:07.309652 140290240782464 deprecation.py:323] From research/bert/pretraining/training/run_pretraining.py:165: run_customized_training_loop (from official.nlp.bert.model_training_utils) is deprecated and will be removed in a future version.
Instructions for updating:
This function is deprecated and we do not expect adding new functionalities. Please do not have your code depending on this library.
I0715 00:59:36.497698 140290240782464 optimization.py:89] using Adamw optimizer
2020-07-15 00:59:37.604910: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'steps' with dtype int32
	 [[{{node steps}}]]
2020-07-15 01:00:20.527288: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'steps' with dtype int32
	 [[{{node steps}}]]
Traceback (most recent call last):
  File ""research/bert/pretraining/training/run_pretraining.py"", line 219, in <module>
    app.run(main)
  File ""/opt/virtualenv/pretrain/lib/python3.6/site-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/opt/virtualenv/pretrain/lib/python3.6/site-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""research/bert/pretraining/training/run_pretraining.py"", line 215, in main
    run_bert_pretrain(strategy)
  File ""research/bert/pretraining/training/run_pretraining.py"", line 201, in run_bert_pretrain
    custom_callbacks=custom_callbacks)
  File ""research/bert/pretraining/training/run_pretraining.py"", line 165, in run_customized_training
    custom_callbacks=custom_callbacks)
  File ""/opt/virtualenv/pretrain/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py"", line 324, in new_func
    return func(*args, **kwargs)
  File ""/opt/virtualenv/pretrain/lib/python3.6/site-packages/official/nlp/bert/model_training_utils.py"", line 482, in run_customized_training_loop
    train_loss = _float_metric_value(train_loss_metric)
  File ""/opt/virtualenv/pretrain/lib/python3.6/site-packages/official/nlp/bert/model_training_utils.py"", line 75, in _float_metric_value
    return metric.result().numpy().astype(float)
  File ""/opt/virtualenv/pretrain/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 1064, in numpy
    maybe_arr = self._numpy()  # pylint: disable=protected-access
  File ""/opt/virtualenv/pretrain/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 1032, in _numpy
2020-07-15 01:02:01.903083: W tensorflow/core/distributed_runtime/eager/remote_tensor_handle_data.cc:76] Unable to destroy remote tensor handles. If you are running a tf.function, it usually indicates some op in the graph gets an error: 3 root error(s) found.
  (0) Out of range: {{function_node __inference_train_steps_217694}} {{function_node __inference_train_steps_217694_15939018961085879472_10}} End of sequence
	 [[{{node while/body/_1/while/IteratorGetNext_18}}]]
	 [[while/cluster_while_body_198928/_execute_22_0/_964]]
	 [[while/LoopCond/_1251/_244]]
Additional GRPC error information from remote target /job:worker/replica:0/task:2/device:TPU:5:
:{""created"":""@1594774842.995987202"",""description"":""Error received from peer ipv4:10.240.1.5:8470"",""file"":""third_party/grpc/src/core/lib/surface/call.cc"",""file_line"":1062,""grpc_message"":""{{function_node __inference_train_steps_217694_15939018961085879472_10}} End of sequence\n\t [[{{node while/body/_1/while/IteratorGetNext_18}}]]\n\t [[while/cluster_while_body_198928/_execute_22_0/_964]]\n\t [[while/LoopCond/_1251/_244]]"",""grpc_status"":11}
  (1) Out of range: {{function_node __inference_train_steps_217694}} End of sequence
	 [[{{node while/body/_1/while/IteratorGetNext_18}}]]
Additional GRPC error information from remote target /job:worker/replica:0/task:2:
:{""created"":""@1594774842.994945378"",""description"":""Error received from peer ipv4:10.240.1.5:8470"",""file"":""third_party/grpc/src/core/lib/surface/call.cc"",""file_line"":1062,""grpc_message"":""End of sequence\n\t [[{{node while/body/_1/while/IteratorGetNext_18}}]]"",""grpc_status"":11}
	 [[GroupCrossDeviceControlEdges_0/TPUVariableReshard/last_iteration/_16617246711369326259/_7/_796]]
	 [[tpu_compile_succeeded_assert/_6992992333505467331/_3/_832]]
  (2) Out of range: {{function_node __inference_train_steps_217694}} End of sequence
	 [[{{node while/body/_1/while/IteratorGetNext_18}}]]
Additional GRPC error information from remote target /job:worker/replica:0/task:2:
:{""created"":""@1594774842.994945378"",""description"":""Error received from peer ipv4:10.240.1.5:8470"",""file"":""third_party/grpc/src/core/lib/surface/call.cc"",""file_line"":1062,""grpc_message"":""End of sequence\n\t [[{{node while/body/_1/while/IteratorGetNext_18}}]]"",""grpc_status"":11}
	 [[GroupCrossDeviceControlEdges_0/TPUVariableReshard/last_iteration/_16617246711369326259/_7/_796]]
0 successful operations.
30 derived errors ignored.
    six.raise_from(core._status_to_exception(e.code, e.message), None)  # pylint: disable=protected-access
  File ""<string>"", line 3, in raise_from
tensorflow.python.framework.errors_impl.OutOfRangeError: 3 root error(s) found.
  (0) Out of range: {{function_node __inference_train_steps_217694}} {{function_node __inference_train_steps_217694_15939018961085879472_10}} End of sequence
	 [[{{node while/body/_1/while/IteratorGetNext_18}}]]
	 [[while/cluster_while_body_198928/_execute_22_0/_964]]
	 [[while/LoopCond/_1251/_244]]
Additional GRPC error information from remote target /job:worker/replica:0/task:2/device:TPU:5:
:{""created"":""@1594774842.995987202"",""description"":""Error received from peer ipv4:10.240.1.5:8470"",""file"":""third_party/grpc/src/core/lib/surface/call.cc"",""file_line"":1062,""grpc_message"":""{{function_node __inference_train_steps_217694_15939018961085879472_10}} End of sequence\n\t [[{{node while/body/_1/while/IteratorGetNext_18}}]]\n\t [[while/cluster_while_body_198928/_execute_22_0/_964]]\n\t [[while/LoopCond/_1251/_244]]"",""grpc_status"":11}
  (1) Out of range: {{function_node __inference_train_steps_217694}} End of sequence
	 [[{{node while/body/_1/while/IteratorGetNext_18}}]]
Additional GRPC error information from remote target /job:worker/replica:0/task:2:
:{""created"":""@1594774842.994945378"",""description"":""Error received from peer ipv4:10.240.1.5:8470"",""file"":""third_party/grpc/src/core/lib/surface/call.cc"",""file_line"":1062,""grpc_message"":""End of sequence\n\t [[{{node while/body/_1/while/IteratorGetNext_18}}]]"",""grpc_status"":11}
	 [[GroupCrossDeviceControlEdges_0/TPUVariableReshard/last_iteration/_16617246711369326259/_7/_796]]
	 [[tpu_compile_succeeded_assert/_6992992333505467331/_3/_832]]
  (2) Out of range: {{function_node __inference_train_steps_217694}} End of sequence
	 [[{{node while/body/_1/while/IteratorGetNext_18}}]]
Additional GRPC error information from remote target /job:worker/replica:0/task:2:
:{""created"":""@1594774842.994945378"",""description"":""Error received from peer ipv4:10.240.1.5:8470"",""file"":""third_party/grpc/src/core/lib/surface/call.cc"",""file_line"":1062,""grpc_message"":""End of sequence\n\t [[{{node while/body/_1/while/IteratorGetNext_18}}]]"",""grpc_status"":11}
	 [[GroupCrossDeviceControlEdges_0/TPUVariableReshard/last_iteration/_16617246711369326259/_7/_796]]
0 successful operations.

```

I've also tried using Tensorflow 2.2.0 and the r 2.2.0 branch codes, I get a similar error. 

I didn't have this issue when running the run_classifer.py and that did run ok. 

Any thoughts are appreciated. Thank you.",aidad,b'models:official type:bug',2020-07-15T01:55:12Z,2020-07-24T19:44:30Z,,,,,,,
8863,Model Zoo Not found,"# Prerequisites

Please answer the following questions for yourself before submitting an issue.

- [No] I am using the latest TensorFlow Model Garden release and TensorFlow 2.
- [Yes] I am reporting the issue to the correct repository. (Model Garden official or research directory)
- [Yes] I checked to make sure that this issue has not already been filed.

## 1. The entire URL of the file you are using

https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md

## 2. Describe the bug

I tried to download a checkpoint from the detection model zoo but it is showing Error 404 now. The model zoo was available a few days ago.

## 3. Steps to reproduce

1. Copy the following URL in your browser:
https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md

## 4. Expected behavior

I expected a model zoo there where I would find a model for fine-tuning my network.

## 5. Additional context

Include any logs that would be helpful to diagnose the problem.

## 6. System information

- OS Platform and Distribution: (Linux Ubuntu 16.04
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): 1.14
- Python version: 3.5.2
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 10.0.130
- GPU model and memory: RTX 2080Ti 12 GB

<!-- 
Collect system information using our environment capture script.
https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can also obtain the TensorFlow version with:

1. TensorFlow 1.0
`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

2. TensorFlow 2.0
`python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`
-->


",mnbrshd,b'models:research type:bug',2020-07-14T09:35:18Z,2020-07-14T11:59:39Z,,,,,,,
8855,AttributeError: 'SSDResNet50V1FpnKerasFeatureExtractor' object has no attribute 'restore_from_classification_checkpoint_fn',"# Prerequisites

Please answer the following questions for yourself before submitting an issue.

- [x] I am using the latest TensorFlow Model Garden release and TensorFlow 2.
- [x] I am reporting the issue to the correct repository. (Model Garden official or research directory)
- [x] I checked to make sure that this issue has not been filed already.

## 1. The entire URL of the file you are using

https://github.com/tensorflow/models/tree/master/official/...

## 2. Describe the bug

I followed this official documentation:
https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/training.html#training-the-model

I am using training/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8, have edited its config file and all as  per the docs.
When I run train.py I get the error
```I0713 11:22:44.929779 139813510887232 sync_replicas_optimizer.py:187] SyncReplicasV2: replicas_to_aggregate=8; total_num_replicas=1
Traceback (most recent call last):
  File ""train.py"", line 186, in <module>
    tf.app.run()
  File ""/opt/anaconda3/envs/cdsl/lib/python3.6/site-packages/tensorflow/python/platform/app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""/opt/anaconda3/envs/cdsl/lib/python3.6/site-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/opt/anaconda3/envs/cdsl/lib/python3.6/site-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""/opt/anaconda3/envs/cdsl/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py"", line 324, in new_func
    return func(*args, **kwargs)
  File ""train.py"", line 182, in main
    graph_hook_fn=graph_rewriter_fn)
  File ""/home/yaser.sakkaf/Object_Detection/TensorFlow/models/research/object_detection/legacy/trainer.py"", line 392, in train
    train_config.load_all_detection_checkpoint_vars))
  File ""/home/yaser.sakkaf/Object_Detection/TensorFlow/models/research/object_detection/meta_architectures/ssd_meta_arch.py"", line 1277, in restore_map
    return self._feature_extractor.restore_from_classification_checkpoint_fn(
AttributeError: 'SSDResNet50V1FpnKerasFeatureExtractor' object has no attribute 'restore_from_classification_checkpoint_fn'
ERROR:tensorflow:==================================
Object was never used (type <class 'tensorflow.python.framework.ops.Tensor'>):
<tf.Tensor 'report_uninitialized_variables/boolean_mask/GatherV2:0' shape=(None,) dtype=string>
If you want to mark it as used call its ""mark_used()"" method.
It was originally created here:
  File ""/opt/anaconda3/envs/cdsl/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py"", line 324, in new_func
    return func(*args, **kwargs)  File ""train.py"", line 182, in main
    graph_hook_fn=graph_rewriter_fn)  File ""/home/yaser.sakkaf/Object_Detection/TensorFlow/models/research/object_detection/legacy/trainer.py"", line 415, in train
    saver=saver)  File ""/opt/anaconda3/envs/cdsl/lib/python3.6/site-packages/tensorflow/python/training/sync_replicas_optimizer.py"", line 358, in apply_gradients
    return train_op  File ""/opt/anaconda3/envs/cdsl/lib/python3.6/site-packages/tensorflow/python/util/tf_should_use.py"", line 237, in wrapped
    error_in_function=error_in_function)
==================================
E0713 11:22:55.322450 139813510887232 tf_should_use.py:92] ==================================
Object was never used (type <class 'tensorflow.python.framework.ops.Tensor'>):
<tf.Tensor 'report_uninitialized_variables/boolean_mask/GatherV2:0' shape=(None,) dtype=string>
If you want to mark it as used call its ""mark_used()"" method.
It was originally created here:
  File ""/opt/anaconda3/envs/cdsl/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py"", line 324, in new_func
    return func(*args, **kwargs)  File ""train.py"", line 182, in main
    graph_hook_fn=graph_rewriter_fn)  File ""/home/yaser.sakkaf/Object_Detection/TensorFlow/models/research/object_detection/legacy/trainer.py"", line 415, in train
    saver=saver)  File ""/opt/anaconda3/envs/cdsl/lib/python3.6/site-packages/tensorflow/python/training/sync_replicas_optimizer.py"", line 358, in apply_gradients
    return train_op  File ""/opt/anaconda3/envs/cdsl/lib/python3.6/site-packages/tensorflow/python/util/tf_should_use.py"", line 237, in wrapped
    error_in_function=error_in_function)
==================================
```

## 3. Steps to reproduce

python train.py --logtostderr --train_dir=training/ --pipeline_config_path=training/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8.config

## 4. Expected behavior

The training should start

## 5. Additional context

Have a look at my config file: **ssd_resnet50_v1_fpn_640x640_coco17_tpu-8.config**

```
# SSD with Resnet 50 v1 FPN feature extractor, shared box predictor and focal
# loss (a.k.a Retinanet).
# See Lin et al, https://arxiv.org/abs/1708.02002
# Trained on COCO, initialized from Imagenet classification checkpoint
# Train on TPU-8
#
# Achieves 34.3 mAP on COCO17 Val

model {
  ssd {
    inplace_batchnorm_update: true
    freeze_batchnorm: false
    num_classes: 8
    box_coder {
      faster_rcnn_box_coder {
        y_scale: 10.0
        x_scale: 10.0
        height_scale: 5.0
        width_scale: 5.0
      }
    }
    matcher {
      argmax_matcher {
        matched_threshold: 0.5
        unmatched_threshold: 0.5
        ignore_thresholds: false
        negatives_lower_than_unmatched: true
        force_match_for_each_row: true
        use_matmul_gather: true
      }
    }
    similarity_calculator {
      iou_similarity {
      }
    }
    encode_background_as_zeros: true
    anchor_generator {
      multiscale_anchor_generator {
        min_level: 3
        max_level: 7
        anchor_scale: 4.0
        aspect_ratios: [1.0, 2.0, 0.5]
        scales_per_octave: 2
      }
    }
    image_resizer {
      fixed_shape_resizer {
        height: 640
        width: 640
      }
    }
    box_predictor {
      weight_shared_convolutional_box_predictor {
        depth: 256
        class_prediction_bias_init: -4.6
        conv_hyperparams {
          activation: RELU_6,
          regularizer {
            l2_regularizer {
              weight: 0.0004
            }
          }
          initializer {
            random_normal_initializer {
              stddev: 0.01
              mean: 0.0
            }
          }
          batch_norm {
            scale: true,
            decay: 0.997,
            epsilon: 0.001,
          }
        }
        num_layers_before_predictor: 4
        kernel_size: 3
      }
    }
    feature_extractor {
      type: 'ssd_resnet50_v1_fpn_keras'
      fpn {
        min_level: 3
        max_level: 7
      }
      min_depth: 16
      depth_multiplier: 1.0
      conv_hyperparams {
        activation: RELU_6,
        regularizer {
          l2_regularizer {
            weight: 0.0004
          }
        }
        initializer {
          truncated_normal_initializer {
            stddev: 0.03
            mean: 0.0
          }
        }
        batch_norm {
          scale: true,
          decay: 0.997,
          epsilon: 0.001,
        }
      }
      override_base_feature_extractor_hyperparams: true
    }
    loss {
      classification_loss {
        weighted_sigmoid_focal {
          alpha: 0.25
          gamma: 2.0
        }
      }
      localization_loss {
        weighted_smooth_l1 {
        }
      }
      classification_weight: 1.0
      localization_weight: 1.0
    }
    normalize_loss_by_num_matches: true
    normalize_loc_loss_by_codesize: true
    post_processing {
      batch_non_max_suppression {
        score_threshold: 1e-8
        iou_threshold: 0.6
        max_detections_per_class: 100
        max_total_detections: 100
      }
      score_converter: SIGMOID
    }
  }
}

train_config: {
  fine_tune_checkpoint_version: V2
  fine_tune_checkpoint: ""/home/yaser.sakkaf/Object_Detection/TensorFlow/workspace/training_demo/pre-trained-model/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8/resnet50.ckpt-1""
  fine_tune_checkpoint_type: ""classification""
  batch_size: 64
  sync_replicas: true
  startup_delay_steps: 0
  replicas_to_aggregate: 8
  use_bfloat16: true
  num_steps: 25000
  data_augmentation_options {
    random_horizontal_flip {
    }
  }
  data_augmentation_options {
    random_crop_image {
      min_object_covered: 0.0
      min_aspect_ratio: 0.75
      max_aspect_ratio: 3.0
      min_area: 0.75
      max_area: 1.0
      overlap_thresh: 0.0
    }
  }
  optimizer {
    momentum_optimizer: {
      learning_rate: {
        cosine_decay_learning_rate {
          learning_rate_base: .04
          total_steps: 25000
          warmup_learning_rate: .013333
          warmup_steps: 2000
        }
      }
      momentum_optimizer_value: 0.9
    }
    use_moving_average: false
  }
  max_number_of_boxes: 100
  unpad_groundtruth_tensors: false
}

train_input_reader: {
  label_map_path: ""/home/yaser.sakkaf/Object_Detection/TensorFlow/workspace/training_demo/training/kyc_label_map.pbtxt""
  tf_record_input_reader {
    input_path: ""/home/yaser.sakkaf/Object_Detection/TensorFlow/workspace/training_demo/annotations/train.tfrecord-00000-of-00001""
  }
}

eval_config: {
  metrics_set: ""coco_detection_metrics""
  use_moving_averages: false
}

eval_input_reader: {
  label_map_path: ""/home/yaser.sakkaf/Object_Detection/TensorFlow/workspace/training_demo/training/kyc_label_map.pbtxt""
  shuffle: false
  num_epochs: 1
  tf_record_input_reader {
    input_path: ""/home/yaser.sakkaf/Object_Detection/TensorFlow/workspace/training_demo/annotations/test.tfrecord-00000-of-00001""
  }
}
```
## 6. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
NAME=""Red Hat Enterprise Linux""
VERSION=""8.2 (Ootpa)""

- Mobile device name if the issue happens on a mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): '2.2.0'
- Python version: Python 3.6.10
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: V10.1.243/ MAJOR 7
- GPU model and memory: Tesla P100 16 GB

<!-- 
Collect system information using our environment capture script.
https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can also obtain the TensorFlow version with:

1. TensorFlow 1.0
`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

2. TensorFlow 2.0
`python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`
-->
",yasersakkaf,b'models:research type:bug',2020-07-13T11:34:24Z,2020-07-31T16:55:23Z,,,,,,,
8854,"object_detection Shape mismatch after adjusting the pipeline config, anything missing?","# Prerequisites

Please answer the following questions for yourself before submitting an issue.

- [x] I am using the latest TensorFlow Model Garden release and TensorFlow 2.
- [x] I am reporting the issue to the correct repository. (Model Garden official or research directory)
- [x] I checked to make sure that this issue has not already been filed.

## 1. The entire URL of the file you are using

Base config file: https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/configs/tf2/faster_rcnn_resnet101_v1_640x640_coco17_tpu-8.config

Base checkpoints: http://download.tensorflow.org/models/object_detection/tf2/20200711/faster_rcnn_resnet101_v1_640x640_coco17_tpu-8.tar.gz

## 2. Describe the bug

This is related to fine-tuning a detection model, in my case, it is based on Faster R-CNN. I have changed all the necessary parameters in the configuration file with respect to the dataset I have. The config file can be found [here](https://gist.github.com/sayakpaul/0171f5647219e8d41df63f3b1a6b2374#file-faster_rcnn_resnet101_v1_640x640_coco17_tpu-8-config). 

I am launching the training locally with the following command:

```
python ~/models/research/object_detection/model_main_tf2.py \
    --pipeline_config_path=${PIPELINE_CONFIG_PATH} \
    --model_dir=${MODEL_DIR} \
    --alsologtostderrv
```

Where, `PIPELINE_CONFIG_PATH` is defined as `home/jupyter/ssds_and_rcnn/lisa/experiments/training/faster_rcnn_resnet101_v1_640x640_coco17_tpu-8.config` and `MODEL_DIR` is defined as `/home/jupyter/ssds_and_rcnn/lisa/experiments/training/faster_rcnn_resnet101_v1_640x640_coco17_tpu-8/checkpoint`. 

Contents of `faster_rcnn_resnet101_v1_640x640_coco17_tpu-8/checkpoint`:

```
total 182M
-rw-r----- 1 jupyter jupyter  166 Jul 10 03:56 checkpoint
-rw-r----- 1 jupyter jupyter 182M Jul 10 03:58 ckpt-0.data-00000-of-00001
-rw-r----- 1 jupyter jupyter 8.7K Jul 10 03:56 ckpt-0.index
```

Now, upon launching the training I am getting:

```
Traceback (most recent call last):
  File ""/home/jupyter/models/research/object_detection/model_main_tf2.py"", line 106, in <module>
    tf.compat.v1.app.run()
  File ""/home/jupyter/.local/bin/.virtualenvs/tfod_api/lib/python3.7/site-packages/tensorflow/python/platform/app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""/home/jupyter/.local/bin/.virtualenvs/tfod_api/lib/python3.7/site-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/home/jupyter/.local/bin/.virtualenvs/tfod_api/lib/python3.7/site-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""/home/jupyter/models/research/object_detection/model_main_tf2.py"", line 103, in main
    use_tpu=FLAGS.use_tpu)
  File ""/home/jupyter/.local/bin/.virtualenvs/tfod_api/lib/python3.7/site-packages/object_detection/model_lib_v2.py"", line 569, in train_loop
    ckpt.restore(latest_checkpoint)
  File ""/home/jupyter/.local/bin/.virtualenvs/tfod_api/lib/python3.7/site-packages/tensorflow/python/training/tracking/util.py"", line 2009, in restore
    status = self._saver.restore(save_path=save_path)
  File ""/home/jupyter/.local/bin/.virtualenvs/tfod_api/lib/python3.7/site-packages/tensorflow/python/training/tracking/util.py"", line 1304, in restore
    checkpoint=checkpoint, proto_id=0).restore(self._graph_view.root)
  File ""/home/jupyter/.local/bin/.virtualenvs/tfod_api/lib/python3.7/site-packages/tensorflow/python/training/tracking/base.py"", line 209, in restore
    restore_ops = trackable._restore_from_checkpoint_position(self)  # pylint: disable=protected-access
  File ""/home/jupyter/.local/bin/.virtualenvs/tfod_api/lib/python3.7/site-packages/tensorflow/python/training/tracking/base.py"", line 907, in _restore_from_checkpoint_position
    tensor_saveables, python_saveables))
  File ""/home/jupyter/.local/bin/.virtualenvs/tfod_api/lib/python3.7/site-packages/tensorflow/python/training/tracking/util.py"", line 289, in restore_saveables
    validated_saveables).restore(self.save_path_tensor)
  File ""/home/jupyter/.local/bin/.virtualenvs/tfod_api/lib/python3.7/site-packages/tensorflow/python/training/saving/functional_saver.py"", line 281, in restore
    restore_ops.update(saver.restore(file_prefix))
  File ""/home/jupyter/.local/bin/.virtualenvs/tfod_api/lib/python3.7/site-packages/tensorflow/python/training/saving/functional_saver.py"", line 103, in restore
    restored_tensors, restored_shapes=None)
  File ""/home/jupyter/.local/bin/.virtualenvs/tfod_api/lib/python3.7/site-packages/tensorflow/python/distribute/values.py"", line 647, in restore
    for v in self._mirrored_variable.values))
  File ""/home/jupyter/.local/bin/.virtualenvs/tfod_api/lib/python3.7/site-packages/tensorflow/python/distribute/values.py"", line 647, in <genexpr>
    for v in self._mirrored_variable.values))
  File ""/home/jupyter/.local/bin/.virtualenvs/tfod_api/lib/python3.7/site-packages/tensorflow/python/distribute/values.py"", line 392, in _assign_on_device
    return variable.assign(tensor)
  File ""/home/jupyter/.local/bin/.virtualenvs/tfod_api/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py"", line 846, in assign
    self._shape.assert_is_compatible_with(value_tensor.shape)
  File ""/home/jupyter/.local/bin/.virtualenvs/tfod_api/lib/python3.7/site-packages/tensorflow/python/framework/tensor_shape.py"", line 1117, in assert_is_compatible_with
    raise ValueError(""Shapes %s and %s are incompatible"" % (self, other))
**ValueError: Shapes (4,) and (91,) are incompatible**
```

Am I missing something? 

## 3. Steps to reproduce

If needed I can supply the tfrecords files. 

## 4. Expected behavior

The training should not raise the shape mismatch error given I have done everything correctly before launching the training. 

## 5. Additional context

None

## 6. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- Mobile device name if the issue happens on a mobile device:
- TensorFlow installed from (source or binary): Binary
- TensorFlow version (use command below): 2.2.0
- Python version: Python 3.7
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 10.1 
- GPU model and memory: Tesla T4
",sayakpaul,b'models:research type:bug',2020-07-13T11:03:21Z,2020-07-14T06:54:19Z,,,,,,,
8838,loss is increasing??,"# Prerequisites

Please answer the following questions for yourself before submitting an issue.

- [ ] I am using the latest TensorFlow Model Garden release and TensorFlow 2.
- [ ] I am reporting the issue to the correct repository. (Model Garden official or research directory)
- [ ] I checked to make sure that this issue has not already been filed.

## 1. The entire URL of the file you are using

https://github.com/tensorflow/models/tree/master/research/...

## 2. Describe the bug

A clear and concise description of what the bug is.

## 3. Steps to reproduce

Steps to reproduce the behavior.

## 4. Expected behavior

A clear and concise description of what you expected to happen.

## 5. Additional context

Include any logs that would be helpful to diagnose the problem.

## 6. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device name if the issue happens on a mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below):
- Python version:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

<!-- 
Collect system information using our environment capture script.
https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can also obtain the TensorFlow version with:

1. TensorFlow 1.0
`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

2. TensorFlow 2.0
`python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`
-->
",erolgerceker,b'models:research stat:awaiting review type:bug',2020-07-11T10:50:44Z,2020-07-13T05:32:17Z,,,,,,,
8825,"ValueError: Tensor-typed variable initializers must either be wrapped in an init_scope or callable (e.g., `tf.Variable(lambda : tf.truncated_normal([10, 40]))`) when building functions. ","### Version ###
- OS Platform
Python 3.7.6
tensorflow 2.2.0
keras 2.3.0-tf
mem 64247.95703125
cpu 16

### Try to reproduce this work ###
https://www.kaggle.com/devang/transfer-learning-with-keras-and-mobilenet-v2

### Bug description ### 
The error occurs when I try to define layers and compile model using:

epochs = 100
batch_size = 150
testsplit = .2
targetx = 224
targety = 224
learning_rate = 0.0001
classes = 120
seed = random.randint(1, 1000)

shape=(targetx, targety, 3))

x = base_model.output
x = GlobalAveragePooling2D()(x)
# x = Dropout(rate = .2)(x)
x = BatchNormalization()(x)
x = Dense(1280, activation='relu',  kernel_initializer=glorot_uniform(seed), bias_initializer='zeros')(x)
# x = Dropout(rate = .2)(x)
x = BatchNormalization()(x)
predictions = Dense(classes, activation='softmax', kernel_initializer='random_uniform', bias_initializer='zeros')(x)

model = Model(inputs=base_model.input, outputs=predictions)


### Error report ###
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
<ipython-input-64-19962c4ddb53> in <module>
     12 """"""
     13 
---> **_14 x = Dense(1280, activation='relu',  kernel_initializer=glorot_uniform(seed), bias_initializer='zeros')(x)_**
     15 x = Dropout(rate = .2)(x)
     16 x = BatchNormalization()(x)

/apps/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py in symbolic_fn_wrapper(*args, **kwargs)
     73         if _SYMBOLIC_SCOPE.value:
     74             with get_graph().as_default():
---> 75                 return func(*args, **kwargs)
     76         else:
     77             return func(*args, **kwargs)

/apps/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/keras/engine/base_layer.py in __call__(self, inputs, **kwargs)
    461                                          'You can build it manually via: '
    462                                          '`layer.build(batch_input_shape)`')
--> 463                 self.build(unpack_singleton(input_shapes))
    464                 self.built = True
    465 

/apps/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/keras/layers/core.py in build(self, input_shape)
    893                                       name='kernel',
    894                                       regularizer=self.kernel_regularizer,
--> 895                                       constraint=self.kernel_constraint)
    896         if self.use_bias:
    897             self.bias = self.add_weight(shape=(self.units,),

/apps/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/keras/engine/base_layer.py in add_weight(self, name, shape, dtype, initializer, regularizer, trainable, constraint)
    280                             dtype=dtype,
    281                             name=name,
--> 282                             constraint=constraint)
    283         if regularizer is not None:
    284             with K.name_scope('weight_regularizer'):

/apps/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py in variable(value, dtype, name, constraint)
    618     """"""
    619     v = tf_keras_backend.variable(
--> 620         value, dtype=dtype, name=name, constraint=constraint)
    621     if hasattr(value, 'tocoo'):
    622         v._keras_shape = value.tocoo().shape

/apps/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/keras/backend.py in variable(value, dtype, name, constraint)
    843       dtype=dtypes_module.as_dtype(dtype),
    844       name=name,
--> 845       constraint=constraint)
    846   if isinstance(value, np.ndarray):
    847     v._keras_shape = value.shape

/apps/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/ops/variables.py in __call__(cls, *args, **kwargs)
    259       return cls._variable_v1_call(*args, **kwargs)
    260     elif cls is Variable:
--> 261       return cls._variable_v2_call(*args, **kwargs)
    262     else:
    263       return super(VariableMetaclass, cls).__call__(*args, **kwargs)

/apps/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/ops/variables.py in _variable_v2_call(cls, initial_value, trainable, validate_shape, caching_device, name, variable_def, dtype, import_scope, constraint, synchronization, aggregation, shape)
    253         synchronization=synchronization,
    254         aggregation=aggregation,
--> 255         shape=shape)
    256 
    257   def __call__(cls, *args, **kwargs):

/apps/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/ops/variables.py in <lambda>(**kws)
    234                         shape=None):
    235     """"""Call on Variable class. Useful to force the signature.""""""
--> 236     previous_getter = lambda **kws: default_variable_creator_v2(None, **kws)
    237     for _, getter in ops.get_default_graph()._variable_creator_stack:  # pylint: disable=protected-access
    238       previous_getter = _make_getter(getter, previous_getter)

/apps/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/ops/variable_scope.py in default_variable_creator_v2(next_creator, **kwargs)
   2645       synchronization=synchronization,
   2646       aggregation=aggregation,
-> 2647       shape=shape)
   2648 
   2649 

/apps/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/ops/variables.py in __call__(cls, *args, **kwargs)
    261       return cls._variable_v2_call(*args, **kwargs)
    262     else:
--> 263       return super(VariableMetaclass, cls).__call__(*args, **kwargs)
    264 
    265 

/apps/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py in __init__(self, initial_value, trainable, collections, validate_shape, caching_device, name, dtype, variable_def, import_scope, constraint, distribute_strategy, synchronization, aggregation, shape)
   1432           aggregation=aggregation,
   1433           shape=shape,
-> 1434           distribute_strategy=distribute_strategy)
   1435 
   1436   def _init_from_args(self,

/apps/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py in _init_from_args(self, initial_value, trainable, collections, caching_device, name, dtype, constraint, synchronization, aggregation, distribute_strategy, shape)
   1515     if isinstance(initial_value, ops.Tensor) and hasattr(
   1516         initial_value, ""graph"") and initial_value.graph.building_function:
-> 1517       raise ValueError(""Tensor-typed variable initializers must either be ""
   1518                        ""wrapped in an init_scope or callable ""
   1519                        ""(e.g., `tf.Variable(lambda : ""

ValueError: Tensor-typed variable initializers must either be wrapped in an init_scope or callable (e.g., `tf.Variable(lambda : tf.truncated_normal([10, 40]))`) when building functions. Please file a feature request if this restriction inconveniences you.

---------------------------------------------------------------------------
I had a few go on changing the 'seed' to the following:

* [1, seed]
* tf.constant(np.random.rand(2, 2)) 
* tf.keras.Variable(lambda : tf.truncated_normal([1, seed]))

However, I still can't manage to convert 'seed' to a tensor. 

Can anyone help me please ?

Any suggestions/feedback will be much appreiciated!

",Isabellaleesln,b'models:official stat:awaiting response type:bug',2020-07-10T14:14:07Z,2020-07-13T11:33:49Z,,,,,,,
8813,DEEPLAB TF2.1  compatibility,"# Prerequisites

Please answer the following questions for yourself before submitting an issue.

- [yes ] I am using the latest TensorFlow Model Garden release and TensorFlow 2.
- [yes ] I am reporting the issue to the correct repository. (Model Garden official or research directory)
- [yes ] I checked to make sure that this issue has not already been filed.

## 1. The entire URL of the file you are using

https://github.com/tensorflow/models/blob/master/research/deeplab/datasets/build_voc2012_data.py

## 2. Describe the bug

tf 2.1|2.0 does not support ""tf.app.flags"". maybe using tf.compat.v1 can resolve the problem
 
## 3. Steps to reproduce

when I wanted to execute the build_voc2012_data.py file to produce the ""tfrecord"" data

## 4. Expected behavior

trouble-free code execution

## 5. Additional context

**

> Traceback (most recent call last):
>   File ""build_voc2012_data.py"", line 60, in <module>
>     import build_data
>   File "".../deeplab/datasets/build_data.py"", line 36, in <module>
>     FLAGS = tf.app.flags.FLAGS
> AttributeError: module 'tensorflow' has no attribute 'app'

**

## 6. System information

- OS Platform and Distribution : Linux Ubuntu 18.04
- TensorFlow 2.1 installed from conda cloud 
- Python version: 3.7.7 



",hxfdanger,b'models:research type:bug',2020-07-09T09:18:15Z,2020-07-17T09:18:47Z,,,,,,,
8806,object_detection_tutorial -- ModuleNotFoundError: No module named 'tensorflow.contrib',"# Prerequisites

Please answer the following questions for yourself before submitting an issue.

- [x] I am using the latest TensorFlow Model Garden release and TensorFlow 2.
- [x] I am reporting the issue to the correct repository. (Model Garden official or research directory)
- [x] I checked to make sure that this issue has not already been filed.

## 1. The entire URL of the file you are using

https://github.com/tensorflow/models/blob/master/research/object_detection/colab_tutorials/object_detection_tutorial.ipynb

## 2. Describe the bug

The object_detection_tutorial is set to use tensorflow 2 but relies on tensorflow.contrib which has been removed from tensorflow 2.

## 3. Steps to reproduce

1. Pull the recent version of the tensorflow models
2. install all dependencies
3. run the object detection tutorial line by line
4. Error will occur in the ""Import the object detection module"" section.

## 4. Expected behavior

https://github.com/tensorflow/tensorflow/issues/30794 indicates that this code does not exist in tensorflow 2. The tutorial is set up to run on tensorflow 2. I would expect this to either be set to use tensorflow 1 or to be modified to work with tensorflow 2.

## 5. Additional context

I---------------------------------------------------------------------------
ModuleNotFoundError                       Traceback (most recent call last)
<ipython-input-5-7035655b948a> in <module>
----> 1 from object_detection.utils import ops as utils_ops
      2 from object_detection.utils import label_map_util
      3 from object_detection.utils import visualization_utils as vis_util

~/opt/anaconda3/envs/SSD/lib/python3.6/site-packages/object_detection/utils/ops.py in <module>
     26 from six.moves import zip
     27 import tensorflow.compat.v1 as tf
---> 28 import tf_slim as slim
     29 from object_detection.core import standard_fields as fields
     30 from object_detection.utils import shape_utils

~/opt/anaconda3/envs/SSD/lib/python3.6/site-packages/tf_slim/__init__.py in <module>
     21 
     22 # pylint: disable=unused-import,line-too-long,g-importing-member,wildcard-import
---> 23 from tf_slim import evaluation
     24 from tf_slim import learning
     25 from tf_slim import model_analyzer

~/opt/anaconda3/envs/SSD/lib/python3.6/site-packages/tf_slim/evaluation.py in <module>
    129 from __future__ import print_function
    130 
--> 131 from tensorflow.contrib.training.python.training import evaluation
    132 # pylint:disable=g-direct-tensorflow-import
    133 from tensorflow.python.summary import summary

ModuleNotFoundError: No module named 'tensorflow.contrib'

## 6. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS Mojave 10.14.6
- TensorFlow version (use command below): 2.0.0
- Python version: 3.6.10
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source): 
- CUDA/cuDNN version: n/a
- GPU model and memory: n/a

# Name                    Version                   Build  Channel
_tflow_select             2.3.0                       mkl  
absl-py                   0.9.0                    py36_0    conda-forge
appnope                   0.1.0           py36h9f0ad1d_1001    conda-forge
astor                     0.8.1              pyh9f0ad1d_0    conda-forge
attrs                     19.3.0                     py_0    conda-forge
backcall                  0.2.0              pyh9f0ad1d_0    conda-forge
bleach                    3.1.5              pyh9f0ad1d_0    conda-forge
brotlipy                  0.7.0           py36h37b9a7d_1000    conda-forge
c-ares                    1.15.0            h01d97ff_1001    conda-forge
ca-certificates           2020.6.20            hecda079_0    conda-forge
certifi                   2020.6.20        py36h9f0ad1d_0    conda-forge
cffi                      1.14.0           py36h356ff06_0    conda-forge
chardet                   3.0.4           py36h9f0ad1d_1006    conda-forge
contextlib2               0.6.0.post1                py_0    conda-forge
cryptography              2.9.2            py36hc9d8292_0    conda-forge
cycler                    0.10.0                     py_2    conda-forge
cython                    0.29.20          py36h0130604_0    conda-forge
dbus                      1.13.6               h2f22bb5_0    conda-forge
decorator                 4.4.2                      py_0    conda-forge
defusedxml                0.6.0                      py_0    conda-forge
entrypoints               0.3             py36h9f0ad1d_1001    conda-forge
expat                     2.2.9                h4a8c4bd_2    conda-forge
freetype                  2.10.2               h8da9a1a_0    conda-forge
gast                      0.2.2                      py_0    conda-forge
gettext                   0.19.8.1          h46ab8bc_1002    conda-forge
glib                      2.65.0               h577aef8_0    conda-forge
google-pasta              0.2.0              pyh8c360ce_0    conda-forge
grpcio                    1.27.2           py36h7c1f37e_0    conda-forge
h5py                      2.10.0          nompi_py36hdec09d9_103    conda-forge
hdf5                      1.10.6          nompi_h3e39495_100    conda-forge
icu                       64.2                 h6de7cb9_1    conda-forge
idna                      2.10               pyh9f0ad1d_0    conda-forge
importlib-metadata        1.7.0            py36h9f0ad1d_0    conda-forge
importlib_metadata        1.7.0                         0    conda-forge
ipykernel                 5.3.1            py36h95af2a2_0    conda-forge
ipython                   7.16.1           py36h95af2a2_0    conda-forge
ipython_genutils          0.2.0                      py_1    conda-forge
ipywidgets                7.5.1                      py_0    conda-forge
jedi                      0.17.1           py36h9f0ad1d_0    conda-forge
jinja2                    2.11.2             pyh9f0ad1d_0    conda-forge
jpeg                      9d                   h0b31af3_0    conda-forge
json5                     0.9.4              pyh9f0ad1d_0    conda-forge
jsonschema                3.2.0            py36h9f0ad1d_1    conda-forge
jupyter                   1.0.0                      py_2    conda-forge
jupyter_client            6.1.5                      py_0    conda-forge
jupyter_console           6.1.0                      py_1    conda-forge
jupyter_core              4.6.3            py36h9f0ad1d_1    conda-forge
jupyterlab                2.1.5                      py_0    conda-forge
jupyterlab_server         1.2.0                      py_0    conda-forge
keras-applications        1.0.8                      py_1    conda-forge
keras-preprocessing       1.1.0                      py_0    conda-forge
kiwisolver                1.2.0            py36h863e41a_0    conda-forge
krb5                      1.17.1               h14dd6a4_1    conda-forge
libblas                   3.8.0               17_openblas    conda-forge
libcblas                  3.8.0               17_openblas    conda-forge
libclang                  9.0.1           default_hf57f61e_0    conda-forge
libcxx                    10.0.0               h1af66ff_2    conda-forge
libedit                   3.1.20191231         hed1e85f_0    conda-forge
libffi                    3.2.1             h4a8c4bd_1007    conda-forge
libgfortran               4.0.0                         2    conda-forge
libiconv                  1.15              h0b31af3_1006    conda-forge
liblapack                 3.8.0               17_openblas    conda-forge
libllvm9                  9.0.1                h7475705_1    conda-forge
libopenblas               0.3.10               h3d69b6c_0    conda-forge
libpng                    1.6.37               hbbe82c9_1    conda-forge
libpq                     12.2                 h489d428_1    conda-forge
libprotobuf               3.12.3               hd174df1_0    conda-forge
libsodium                 1.0.17               h01d97ff_0    conda-forge
libtiff                   4.1.0                h2ae36a8_6    conda-forge
libwebp-base              1.1.0                h0b31af3_3    conda-forge
libxml2                   2.9.10               h53d96d6_0    conda-forge
libxslt                   1.1.33               h320ff13_0    conda-forge
llvm-openmp               10.0.0               h28b9765_0    conda-forge
lxml                      4.5.1            py36h2ab0afd_0    conda-forge
lz4-c                     1.9.2                h4a8c4bd_1    conda-forge
markdown                  3.2.2                      py_0    conda-forge
markupsafe                1.1.1            py36h37b9a7d_1    conda-forge
matplotlib                3.2.2                         1    conda-forge
matplotlib-base           3.2.2            py36h83d3ec1_1    conda-forge
mistune                   0.8.4           py36h37b9a7d_1001    conda-forge
nbconvert                 5.6.1            py36h9f0ad1d_1    conda-forge
nbformat                  5.0.7                      py_0    conda-forge
ncurses                   6.1               h0a44026_1002    conda-forge
notebook                  6.0.3            py36h9f0ad1d_1    conda-forge
nspr                      4.20              h0a44026_1000    conda-forge
nss                       3.47                 hc0980d9_0    conda-forge
numpy                     1.18.5           py36hdc5ca10_0    conda-forge
object-detection          0.1                      pypi_0    pypi
olefile                   0.46                       py_0    conda-forge
openssl                   1.1.1g               h0b31af3_0    conda-forge
opt_einsum                3.2.1                      py_0    conda-forge
packaging                 20.4               pyh9f0ad1d_0    conda-forge
pandoc                    2.10                          0    conda-forge
pandocfilters             1.4.2                      py_1    conda-forge
parso                     0.7.0              pyh9f0ad1d_0    conda-forge
pcre                      8.44                 h4a8c4bd_0    conda-forge
pexpect                   4.8.0            py36h9f0ad1d_1    conda-forge
pickleshare               0.7.5           py36h9f0ad1d_1001    conda-forge
pillow                    7.2.0            py36h2ae5dfa_0    conda-forge
pip                       20.1.1                     py_1    conda-forge
prometheus_client         0.8.0              pyh9f0ad1d_0    conda-forge
prompt-toolkit            3.0.5                      py_1    conda-forge
prompt_toolkit            3.0.5                         1    conda-forge
protobuf                  3.12.3           py36h0130604_0    conda-forge
ptyprocess                0.6.0                   py_1001    conda-forge
pycocotools               2.0.1            py36h37b9a7d_1    conda-forge
pycparser                 2.20               pyh9f0ad1d_2    conda-forge
pygments                  2.6.1                      py_0    conda-forge
pyopenssl                 19.1.0                     py_1    conda-forge
pyparsing                 2.4.7              pyh9f0ad1d_0    conda-forge
pyqt                      5.12.3           py36haa9e2f4_3    conda-forge
pyqt5-sip                 4.19.18                  pypi_0    pypi
pyqtchart                 5.12                     pypi_0    pypi
pyqtwebengine             5.12.1                   pypi_0    pypi
pyrsistent                0.16.0           py36h37b9a7d_0    conda-forge
pysocks                   1.7.1            py36h9f0ad1d_1    conda-forge
python                    3.6.10          h4334963_1011_cpython    conda-forge
python-dateutil           2.8.1                      py_0    conda-forge
python_abi                3.6                     1_cp36m    conda-forge
pyzmq                     19.0.1           py36h820b253_0    conda-forge
qt                        5.12.5               h514805e_3    conda-forge
qtconsole                 4.7.5              pyh9f0ad1d_0    conda-forge
qtpy                      1.9.0                      py_0    conda-forge
readline                  8.0                  hcfe32e1_0    conda-forge
requests                  2.24.0             pyh9f0ad1d_0    conda-forge
scipy                     1.5.0            py36h1dac7e4_0    conda-forge
send2trash                1.5.0                      py_0    conda-forge
setuptools                47.3.1           py36h9f0ad1d_0    conda-forge
six                       1.15.0             pyh9f0ad1d_0    conda-forge
sqlite                    3.32.3               h93121df_0    conda-forge
tensorboard               2.0.0              pyhb38c66f_1  
tensorflow                2.0.0           mkl_py36ha38f243_0  
tensorflow-base           2.0.0           mkl_py36h66b1bf0_0  
tensorflow-estimator      2.0.0              pyh2649769_0  
termcolor                 1.1.0                      py_2    conda-forge
terminado                 0.8.3            py36h9f0ad1d_1    conda-forge
testpath                  0.4.4                      py_0    conda-forge
tf_slim                   1.0                        py_1    conda-forge
tk                        8.6.10               hbbe82c9_0    conda-forge
tornado                   6.0.4            py36h37b9a7d_1    conda-forge
traitlets                 4.3.3            py36h9f0ad1d_1    conda-forge
urllib3                   1.25.9                     py_0    conda-forge
wcwidth                   0.2.5              pyh9f0ad1d_0    conda-forge
webencodings              0.5.1                      py_1    conda-forge
werkzeug                  1.0.1              pyh9f0ad1d_0    conda-forge
wheel                     0.34.2                     py_1    conda-forge
widgetsnbextension        3.5.1                    py36_0    conda-forge
wrapt                     1.12.1           py36h37b9a7d_1    conda-forge
xz                        5.2.5                h0b31af3_0    conda-forge
zeromq                    4.3.2                h6de7cb9_2    conda-forge
zipp                      3.1.0                      py_0    conda-forge
zlib                      1.2.11            h0b31af3_1006    conda-forge
zstd                      1.4.4                h4b3e974_3    conda-forge


",mgon5170,b'models:research stat:awaiting response type:bug',2020-07-08T15:45:13Z,2020-09-10T13:59:51Z,,,,,,,
8792,[Deeplab] eval.py/vis.py not working for custom dataset,"# Prerequisites

## 1. The entire URL of the file you are using

https://github.com/tensorflow/models/tree/master/research/deeplab

## 2. Describe the bug

I am training deeplab with my custom dataset that has 25 images for training and 11 for testing. It has only one class to detect, so num_classes=2. Image size is 720x2000. Training works fine and I've also set the crop_size to 721x2001. When running eval.py, I get the following error: (0) Invalid argument: assertion failed: [`labels` out of bound] [Condition x < y did not hold element-wise:] [x (mean_iou/confusion_matrix/control_dependency:0) = ] [0 0 0...] [y (mean_iou/Cast_1:0) = ] [2]
         [[node mean_iou/confusion_matrix/assert_less/Assert/AssertGuard/Assert (defined at /mnt/abandrei/anaconda3/envs/deeplab_tf/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:1748) ]]
         [[mean_iou/confusion_matrix/stack_1/_4491]]
  (1) Invalid argument: assertion failed: [`labels` out of bound] [Condition x < y did not hold element-wise:] [x (mean_iou/confusion_matrix/control_dependency:0) = ] [0 0 0...] [y (mean_iou/Cast_1:0) = ] [2]
         [[node mean_iou/confusion_matrix/assert_less/Assert/AssertGuard/Assert (defined at /mnt/abandrei/anaconda3/envs/deeplab_tf/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:1748) ]]

I've also tried to do the changes in https://github.com/tensorflow/models/issues/4203#issuecomment-407952737, but then I get the following error: (0) Invalid argument: Incompatible shapes: [1442721] vs. [1442684]
         [[{{node false_negatives_1/Mul}}]]
         [[mean_iou/AssignAdd/_4507]]
  (1) Invalid argument: Incompatible shapes: [1442721] vs. [1442684]
         [[{{node false_negatives_1/Mul}}]]

In this case, I understand that 1442721 is actually 721x2001, but I am not sure about the second shape and what causes it. 

## 3. Steps to reproduce

python3 eval.py   --logtostderr   --eval_split=""val""   --model_variant=""xception_65""   --atrous_rates=6   --atrous_rates=12   --atrous_rates=18   --output_stride=16   --decoder_output_stride=4   --eval_crop_size=""721,2001"" --eval_logdir=datasets/mydataset/exp/train_on_trainval_set/eval --checkpoint_dir=datasets/mydataset/exp/train_on_trainval_set/train  --dataset_dir=datasets/mydataset/tfrecord --eval_batch_size=1 --max_number_of_evaluations=1 --dataset=""mydataset""

_mydataset_INFORMATION = DatasetDescriptor(
    splits_to_sizes={
        'train': 25,  # num of samples in images/training
        'val': 11,  # num of samples in images/validation
    },
    num_classes=2,
    ignore_label=255,
)

## 4. Expected behavior

The evaluation should be performed.

## 6. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04
- TensorFlow installed from (source or binary): binary (pip)
- TensorFlow version (use command below): v1.15.0-rc3-22-g590d6ee 1.15.0
- Python version: 3.7.7
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:10.0/ no cudnn
- GPU model and memory: Tesla P4
",AndreiBaraian,b'models:research type:bug',2020-07-06T17:46:23Z,2020-08-24T15:23:13Z,,,,,,,
8777,DELF: absl.flags._exceptions.DuplicateFlagError: The flag 'seed' is defined twice,"# Prerequisites
- I am using the latest TensorFlow Model Garden release and TensorFlow 2.
- I am reporting the issue to the correct repository. ( research directory)
- I checked to make sure that this issue has not already been filed.

I followed the instructuins for Delf instalaltion from the link:
https://github.com/tensorflow/models/blob/master/research/delf/INSTALL_INSTRUCTIONS.md 

Then used the follwing instruction to train the model
https://github.com/tensorflow/models/blob/master/research/delf/delf/python/training/README.md

## 2. Describe the bug
Traceback (most recent call last):
  File ""models/research/delf/delf/python/training/train.py"", line 50, in <module>
    flags.DEFINE_integer('seed', 0, 'Seed to training dataset.')
  File ""/opt/conda/lib/python3.7/site-packages/absl/flags/_defines.py"", line 315, in DEFINE_integer
    DEFINE(parser, name, default, help, flag_values, serializer, **args)
  File ""/opt/conda/lib/python3.7/site-packages/absl/flags/_defines.py"", line 82, in DEFINE
    flag_values, module_name)
  File ""/opt/conda/lib/python3.7/site-packages/absl/flags/_defines.py"", line 104, in DEFINE_flag
    fv[flag.name] = flag
  File ""/opt/conda/lib/python3.7/site-packages/absl/flags/_flagvalues.py"", line 430, in __setitem__
    raise _exceptions.DuplicateFlagError.from_flag(name, self)
absl.flags._exceptions.DuplicateFlagError: The flag 'seed' is defined twice. First from delf.python.training.build_image_dataset, Second from models/research/delf/delf/python/training/train.py.  Description from first occurrence: (Optional) The seed to be used while shuffling the traindataset when generating the TRAIN and VALIDATION splits.Recommended for splits reproducibility purposes.

A clear and concise description of what the bug is.
first I executed the script python3 delf/python/training/build_image_dataset.py 
then python3 delf/python/training/train.py
I think the flag is redefined  in the second script and for that, there is flag duplicate 
",waelkht,b'models:research type:bug',2020-07-03T10:31:48Z,2020-08-15T21:15:20Z,,,,,,,
8776,"Message type ""object_detection.protos.DetectionModel"" has no field named ""loss""","I am training model ssd_mobilenet_v2_quantized_coco
tensorflow = 1.15.0
protobuf = 3.12.3
Can you fix me this error? thank you


WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py:125: main (from main) is deprecated and will be removed in a future version.
Instructions for updating:
Use object_detection/model_main.py.
Traceback (most recent call last):
File ""train.py"", line 184, in 
tf.app.run()
File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 125, in run
_sys.exit(main(argv))
File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py"", line 324, in new_func
return func(*args, **kwargs)
File ""train.py"", line 93, in main
FLAGS.pipeline_config_path)
File ""/content/tensorflow1/models/research/object_detection/utils/config_util.py"", line 96, in get_configs_from_pipeline_file
text_format.Merge(proto_str, pipeline_config)
File ""/usr/local/lib/python3.6/dist-packages/google/protobuf/text_format.py"", line 693, in Merge
allow_unknown_field=allow_unknown_field)
File ""/usr/local/lib/python3.6/dist-packages/google/protobuf/text_format.py"", line 760, in MergeLines
return parser.MergeLines(lines, message)
File ""/usr/local/lib/python3.6/dist-packages/google/protobuf/text_format.py"", line 785, in MergeLines
self._ParseOrMerge(lines, message)
File ""/usr/local/lib/python3.6/dist-packages/google/protobuf/text_format.py"", line 807, in _ParseOrMerge
self._MergeField(tokenizer, message)
File ""/usr/local/lib/python3.6/dist-packages/google/protobuf/text_format.py"", line 932, in _MergeField
merger(tokenizer, message, field)
File ""/usr/local/lib/python3.6/dist-packages/google/protobuf/text_format.py"", line 1006, in _MergeMessageField
self._MergeField(tokenizer, sub_message)
File ""/usr/local/lib/python3.6/dist-packages/google/protobuf/text_format.py"", line 899, in _MergeField
(message_descriptor.full_name, name))
google.protobuf.text_format.ParseError: 109:5 : Message type ""object_detection.protos.DetectionModel"" has no field named ""loss""
",sirvnvu98,b'models:research type:bug',2020-07-03T10:26:44Z,2020-07-24T08:51:46Z,,,,,,,
8765,Protos for object detection contain errors,"- I am using the latest TensorFlow Model Garden release and TensorFlow 2.
- I am reporting the issue to the correct repository. (Model Garden official or research directory)
- I checked to make sure that this issue has not already been filed.

## 1. The entire URL of the file you are using

https://github.com/tensorflow/models/tree/master/research/object_detection/protos

## 2. Describe the bug

I couldn't solve an error in a previous version of the object detection directory where a link seems to be broken. So I attempted to create a clean instance.

Following the install instructions found here:
https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/installation.md

I ran the following from models/research/: 
protoc object_detection/protos/*.proto --python_out=.


I received the following messages:
object_detection/protos/flexible_grid_anchor_generator.proto: File not found.
object_detection/protos/grid_anchor_generator.proto: File not found.
object_detection/protos/multiscale_anchor_generator.proto: File not found.
object_detection/protos/ssd_anchor_generator.proto: File not found.
research/object_detection/protos/anchor_generator.proto:5:1: Import ""object_detection/protos/flexible_grid_anchor_generator.proto"" was not found or had errors.
research/object_detection/protos/anchor_generator.proto:6:1: Import ""object_detection/protos/grid_anchor_generator.proto"" was not found or had errors.
research/object_detection/protos/anchor_generator.proto:7:1: Import ""object_detection/protos/multiscale_anchor_generator.proto"" was not found or had errors.
research/object_detection/protos/anchor_generator.proto:8:1: Import ""object_detection/protos/ssd_anchor_generator.proto"" was not found or had errors.
research/object_detection/protos/anchor_generator.proto:14:5: ""GridAnchorGenerator"" is not defined.
research/object_detection/protos/anchor_generator.proto:15:5: ""SsdAnchorGenerator"" is not defined.
research/object_detection/protos/anchor_generator.proto:16:5: ""MultiscaleAnchorGenerator"" is not defined.
research/object_detection/protos/anchor_generator.proto:17:5: ""FlexibleGridAnchorGenerator"" is not defined.

I verified flexible_grid_anchor_generator.proto, grid_anchor_generator.proto, multiscale_anchor_generator.proto, and ssd_anchor_generator.proto are in the proto directory. 

## 3. Steps to reproduce

1. Clone from https://github.com/tensorflow/models
2. run protoc object_detection/protos/*.proto --python_out=. from models/research
3. Receive errors.

## 4. Expected behavior

When running protoc object_detection/protos/*.proto --python_out=. I expected for all files to be processed and .py files to be generated.

## 5. Additional context

Include any logs that would be helpful to diagnose the problem.

## 6. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS Mojave 10.14.6
- TensorFlow installed from (source or binary): 2.3.0
- TensorFlow version (use command below):
- Python version: 3.6.10
-conda version: 4.8.3


<!-- 
Collect system information using our environment capture script.
https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can also obtain the TensorFlow version with:

1. TensorFlow 1.0
`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

2. TensorFlow 2.0
`python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`
-->
",mgon5170,b'models:research type:bug',2020-07-01T16:34:23Z,2020-07-10T18:53:24Z,,,,,,,
8758,object_detection not supported in TF 2,"# Prerequisites

Please answer the following questions for yourself before submitting an issue.

- [X] I am using the latest TensorFlow Model Garden release and TensorFlow 2.
- [X] I am reporting the issue to the correct repository. (Model Garden official or research directory)
- [X] I checked to make sure that this issue has not already been filed.

## 1. The entire URL of the file you are using

https://github.com/tensorflow/models/tree/master/research/object_detection

## 2. Describe the bug

The `object_detection` API isn't supported under TensorFlow 2, which is a problem in general. In my specific case, I'm trying to create an object detection model and use `tflite` to deploy it on mobile, but due to [this bug in tflite](https://github.com/tensorflow/tensorflow/issues/38558) I'm stuck using `tf-nightly`. However, I also depend on the `object_detection` API, which is stuck on TF 1.x.

## 3. Steps to reproduce

1. Create a model using the `object_detection` API (TensorFlow 1.15).
1. Try to convert that model to a mobile format using `tflite` (TensorFlow 2). It will fail to convert (presumably due to mismatched TF versions).

## 4. Expected behavior

I should be able to use the `object_detection` API with the latest TensorFlow releases.

## 5. Additional context

N/A

## 6. System information

N/A",mgalgs,b'models:research type:bug',2020-06-30T21:38:44Z,2020-07-10T18:14:18Z,,,,,,,
8752,"COCO-trained models for tf2,where can download?","# Prerequisites

Please answer the following questions for yourself before submitting an issue.

- [ X] I am using the latest TensorFlow Model Garden release and TensorFlow 2.

## 1. The entire URL of the file you are using

https://github.com/tensorflow/models/tree/master/research/...

## 2. Describe the bug
python3 legacy/train.py --logtostderr --train_dir=voc --pipeline_config_path=voc_lib/faster_rcnn_resnet101_pets.config

ValueError: faster_rcnn_resnet101 is not supported. See `model_builder.py` for features extractors compatible with different versions of Tensorflow


## 3. Steps to reproduce

WARNING:tensorflow:From /home/c/.local/lib/python3.6/site-packages/absl/app.py:250: main (from __main__) is deprecated and will be removed in a future version.
Instructions for updating:
Use object_detection/model_main.py.
W0630 14:38:04.062839 140272845739840 deprecation.py:323] From /home/c/.local/lib/python3.6/site-packages/absl/app.py:250: main (from __main__) is deprecated and will be removed in a future version.
Instructions for updating:
Use object_detection/model_main.py.
Traceback (most recent call last):
  File ""legacy/train.py"", line 186, in <module>
    tf.app.run()
  File ""/home/c/.local/lib/python3.6/site-packages/tensorflow/python/platform/app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""/home/c/.local/lib/python3.6/site-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/home/c/.local/lib/python3.6/site-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""/home/c/.local/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py"", line 324, in new_func
    return func(*args, **kwargs)
  File ""legacy/train.py"", line 182, in main
    graph_hook_fn=graph_rewriter_fn)
  File ""/usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/legacy/trainer.py"", line 248, in train
    detection_model = create_model_fn()
  File ""/usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/builders/model_builder.py"", line 950, in build
    add_summaries)
  File ""/usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/builders/model_builder.py"", line 510, in _build_faster_rcnn_model
    _check_feature_extractor_exists(frcnn_config.feature_extractor.type)
  File ""/usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/builders/model_builder.py"", line 208, in _check_feature_extractor_exists
    'Tensorflow'.format(feature_extractor_type))


## 4. Expected behavior



## 5. Additional context


## 6. System information

<!-- 
Collect system information using our environment capture script.
https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can also obtain the TensorFlow version with:

1. TensorFlow 1.0
`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

2. TensorFlow 2.0
`python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`
-->
>>> import tensorflow as tf
>>> print(tf.version.GIT_VERSION, tf.version.VERSION)
v2.2.0-rc4-8-g2b96f3662b 2.2.0

##according to model_builder.py, where is pretraining model for tf2?
",xpdrycry,b'models:research type:bug',2020-06-30T06:48:14Z,2020-07-14T23:30:54Z,,,,,,,
8721,"Error: cannot import name ""center_net_pb2""","# Prerequisites

Please answer the following questions for yourself before submitting an issue.

Traceback (most recent call last):
  File ""export_inference_graph.py"", line 109, in <module>
    from object_detection import exporter
  File ""/content/models/research/object_detection/exporter.py"", line 24, in <module>
    from object_detection.builders import model_builder
  File ""/content/models/research/object_detection/builders/model_builder.py"", line 38, in <module>
    from object_detection.protos import model_pb2
  File ""/content/models/research/object_detection/protos/model_pb2.py"", line 16, in <module>
    from object_detection.protos import center_net_pb2 as object__detection_dot_protos_dot_center__net__pb2
ImportError: cannot import name 'center_net_pb2'

-I am using tensorflow 1
- I am reporting this for the models research
- I checked to make sure that this issue has not already been filed.

## 1. The entire URL of the file you are using

https://github.com/EdjeElectronics/TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10

## 2. Describe the bug

For this repository, I copied train.py from tensorflow models' legacy directory to the object_detection directory.  When I run that command, it searches the protos folder for center_net_pb2.py, which does not exist.  It asks for 2 other _pb2.py files, which do exist and are imported perfectly.

## 3. Steps to reproduce

1.  Clone tensorflow models
2.  Pull object_detection/legacy/train.py into the object_detection folder and run with parameters
3.  Script attempts to import one proto that does not exist. 

## 4. Expected behavior

I expected the training script to run and train a model based on my generated tf records.  I did this just a few days ago and it worked perfectly.

## 5. Additional context

Include any logs that would be helpful to diagnose the problem.

## 6. System information

-Google Colab
- TensorFlow version 1:
-GPU instance
",Tylersuard,b'models:research type:bug',2020-06-22T23:43:50Z,2020-08-25T19:48:52Z,,,,,,,
8719,'MovingAverage' object has no attribute '_average_weights',"# Prerequisites

Please answer the following questions for yourself before submitting an issue.

- [x] I am using the latest TensorFlow Model Garden release and TensorFlow 2.
- [x] I am reporting the issue to the correct repository. (Model Garden official or research directory)
- [x] I checked to make sure that this issue has not been filed already.

## 1. The entire URL of the file you are using

https://github.com/tensorflow/models/tree/master/official/...

## 2. Describe the bug

A clear and concise description of what the bug is.

## 3. Steps to reproduce

Steps to reproduce the behavior.

## 4. Expected behavior

A clear and concise description of what you expected to happen.

## 5. Additional context

Include any logs that would be helpful to diagnose the problem.

## 6. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device name if the issue happens on a mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below):
- Python version:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

<!-- 
Collect system information using our environment capture script.
https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can also obtain the TensorFlow version with:

1. TensorFlow 1.0
`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

2. TensorFlow 2.0
`python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`
-->
",dipendra009,b'models:official type:bug',2020-06-22T18:46:59Z,2020-06-30T18:19:29Z,,,,,,,
8698,Tensorflow 2.0 object detection API colab tutorial not working,"# Prerequisites

Please answer the following questions for yourself before submitting an issue.

- [x] I am using the latest TensorFlow Model Garden release and TensorFlow 2.
- [x] I am reporting the issue to the correct repository. (Model Garden official or research directory)
- [x] I checked to make sure that this issue has not been filed already.

## 1. The entire URL of the file you are using

https://github.com/tensorflow/models/blob/master/research/object_detection/object_detection_tutorial.ipynb

## 2. Describe the bug

The object detection API in tensorflow 2.0  colab notebook is redirecting to page not found github page

## 3. Steps to reproduce

1.https://www.tensorflow.org/tutorials/
2. Advanced-> Images-> object detection API
3.https://github.com/tensorflow/models/blob/master/research/object_detection/object_detection_tutorial.ipynb
## 4. Expected behavior

I was expecting a colab notebook tutorial of object detection API in tensorflow 2.0

## 5. Additional context

Few days back it was working fine .Now I observed this problem

## 6. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): windows 7 chrome
- Mobile device name if the issue happens on a mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below):
- Python version:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

<!-- 
Collect system information using our environment capture script.
https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can also obtain the TensorFlow version with:

1. TensorFlow 1.0
`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

2. TensorFlow 2.0
`python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`
-->
",jyothiRamilla,b'models:research type:bug',2020-06-19T07:52:31Z,2020-07-28T14:22:13Z,,,,,,,
8672,Error when trying to use protoc compiler,"Hi, I'm using a MacBook OS for installing the latest version of the library and protoc.
Whenever I try running the command 
protoc object_detection/protos/*.proto --python_out=. 

in th /research directory, I ALWAYS get the error:
warning: Import object_detection/protos/image_resizer.proto is unused

I've tried looking online for answers but couldn't find any. Would appreciate any help, thanks!",shahriyarhabib,b'models:research type:bug',2020-06-14T07:19:59Z,2020-07-31T16:51:06Z,,,,,,,
8671,transformer_main.py - Low TPU usage V3-8,"# Prerequisites

Please answer the following questions for yourself before submitting an issue.

- [X] I am using the latest TensorFlow Model Garden release and TensorFlow 2.
- [X] I am reporting the issue to the correct repository. (Model Garden official or research directory)
- [X] I checked to make sure that this issue has not been filed already.

## 1. The entire URL of the file you are using

https://github.com/tensorflow/models/blob/master/official/nlp/transformer/transformer_main.py

## 2. Describe the bug

I followed the instructions to use TPUs to train a transformer model, but I only get around 12% of TPU utilization when running the code.

## 3. Steps to reproduce

```
export PYTHONPATH=""$PYTHONPATH:/path/to/models""

cd /path/to/models/official/nlp/transformer

# Export variables
PARAM_SET=big
DATA_DIR=$HOME/transformer/data
MODEL_DIR=$HOME/transformer/model_$PARAM_SET
VOCAB_FILE=$DATA_DIR/vocab.ende.32768

# Download training/evaluation/test datasets
python3 data_download.py --data_dir=$DATA_DIR

# Train the model for 100000 steps and evaluate every 5000 steps on a single GPU.
# Each train step, takes 4096 tokens as a batch budget with 64 as sequence
# maximal length.

python transformer_main.py \
--tpu=$TPU_NAME \
--model_dir=$MODEL_DIR \
--data_dir=$DATA_DIR \
--vocab_file=$DATA_DIR/vocab.ende.32768 \
--batch_size=10048 \
--train_steps=200000 \
--static_batch=true \
--use_ctl=true \
--param_set=big \
--steps_between_evals=30000 \
--max_length=64 \
--decode_batch_size=1024 \
--decode_max_length=97 \
--padded_decode=true \
--distribution_strategy=tpu \
--enable_metrics_in_training=true \
--enable_tensorboard=true 

capture_tpu_profile --tpu=$TPU_NAME  --monitoring_level=2
```

   TPU type: TPU v3
  Number of TPU cores: 8 (Replica count = 8, num cores per replica = 1)
  TPU idle time (lower is better): 0.058%
  Utilization of TPU Matrix Units (higher is better): 11.9%
  Step time: 209ms (avg), 209ms (min), 209ms (max)
  Infeed percentage: 0.048% (avg), 0.048% (min), 0.048% (max)

## 4. Expected behavior

I would expect TPU usage to be higher, it does seem to be using only 1 TPU core.

## 5. Additional context

Memory usage is also low, around 12GB, which again seems to be using just 1 TPU core.

## 6. System information


== check python ===================================================
python version: 3.7.3
python branch: 
python build version: ('default', 'Dec 20 2019 18:57:59')
python compiler version: GCC 8.3.0
python implementation: CPython
== check os platform ===============================================
os: Linux
os kernel version: #1 SMP Debian 4.19.118-2+deb10u1 (2020-06-07)
os release version: 4.19.0-9-cloud-amd64
os platform: Linux-4.19.0-9-cloud-amd64-x86_64-with-debian-10.4
linux distribution: ('debian', '10.4', '')
linux os distribution: ('debian', '10.4', '')
mac version: ('', ('', '', ''), '')
uname: uname_result(system='Linux', node='garden', release='4.19.0-9-cloud-amd64', version='#1 SMP Debian 4.19.11
8-2+deb10u1 (2020-06-07)', machine='x86_64', processor='')
architecture: ('64bit', 'ELF')
machine: x86_64
== are we in docker =============================================
No
== compiler =====================================================
c++ (Debian 8.3.0-6) 8.3.0
Copyright (C) 2018 Free Software Foundation, Inc.

",soares-f,b'models:official type:bug',2020-06-13T14:54:33Z,2020-08-28T05:22:22Z,,,,,,,
8665,type object 'Config' has no attribute 'resize'. I am using data generator,"At yesterday, when I run the coding below, there was no problem:

```
def preprocessing(img,label):

    img = cv2.resize(img,(Config.resize,Config.resize))
    img = img/255
    label = np_utils.to_categorical(label, Config.num_classes)
    num_classes=7
    labels_to_class = {0:'alif',1:'ba',2:'ta',3:'tsa',4:'jim',5:'hha',6:'kha'}
    class_to_labels = {'alif':0,'ba':1,'ta':2,'tsa':3,'jim':4,'hha':5,'kha':6}
    resize = 224	
    num_epochs =10
    batch_size =10
    return img,label
```
```
train_datagen = data_generator(samples,batch_size=8)

x,y = next(train_datagen)
print ('x_shape: ', x.shape)
print ('labels shape: ', y.shape)
print ('labels: ', y)
```
but then today when I run again with the coding below, this error happened:
AttributeError: type object 'Config' has no attribute 'resize'

 can someone tell me what happened to this? is there any bug???",xueqing311,b'models:research stat:awaiting response type:bug',2020-06-12T08:59:10Z,2020-08-08T02:23:39Z,,,,,,,
8658,Loading a pretrained checkpoint of a QAT model (Resnet 50),"# Prerequisites

Please answer the following questions for yourself before submitting an issue.

- [x] I am using the latest TensorFlow Model Garden release and TensorFlow 2.
- [x] I am reporting the issue to the correct repository. (Model Garden official or research directory)
- [x] I checked to make sure that this issue has not been filed already.

I'm using TF 2.2.0-dev20200506

## 1. The entire URL of the file you are using

https://github.com/tensorflow/models/tree/master/official/vision/image_classification/resnet

## 2. Describe the bug

I trained a Resnet-50 model with quantization aware training. However when I try to load the final checkpoint to export to a saved model, I see ""Unresolved object in checkpoint"" issues.  Please check the complete log [here ](https://gist.github.com/peri044/d78c6ff6f96db1ac0e899738a97b293b)
I perform QAT on the resnet by adding the following snippet of code in resnet_runnable.py [here](https://github.com/tensorflow/models/blob/master/official/vision/image_classification/resnet/resnet_runnable.py#L76)

`import tensorflow_model_optimization as tfmot` 
` quantize_model = tfmot.quantization.keras.quantize_model`
` self.model = quantize_model(self.model)`

I'm trying to export the saved model and face the above unresolved object in checkpoint error when loading weights https://gist.github.com/peri044/6decce75fb94c3ae3a2dee20eb5dd7a2#file-load-py-L47

Is there something obvious that I'm missing here ? Please advise. Thank you !!

## 3. Additional context

My checkpoint has the variable names under layer_with_weights and I see the kernel_min and kernel_max values for the quantization nodes. But the variables TF is looking for are `quant_bn2a_branch1` etc. Is this the right way for topological loading? 


",peri044,b'models:official type:bug',2020-06-10T07:20:25Z,2020-09-18T16:53:02Z,,,,,,,
8648, Context feature 'id' is required but could not be found,"Hi,

I try to use the YouTube-8M Starter Code to train the google audioset. But I met the problem.

python3 train.py --frame_features --model=FrameLevelLogisticModel \
--feature_names='rgb,audio' --feature_sizes='1024,128' \
--train_data_pattern=/home/yt8m/audioset_v1_embeddings/bal_train/*.tfrecord \
--train_dir=/home/yt8m/train_model \
--start_new_model

` File ""/usr/local/lib/python3.6/site-packages/tensorflow_core/python/platform/app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""/usr/local/lib/python3.6/site-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/usr/local/lib/python3.6/site-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""train.py"", line 706, in main
    FLAGS.export_model_steps).run(start_new_model=FLAGS.start_new_model)
  File ""train.py"", line 520, in run
    task_as_string(self.task))
  File ""/usr/local/lib/python3.6/contextlib.py"", line 88, in __exit__
    next(self.gen)
  File ""/usr/local/lib/python3.6/site-packages/tensorflow_core/python/training/supervisor.py"", line 1014, in managed_session
    self.stop(close_summary_writer=close_summary_writer)
  File ""/usr/local/lib/python3.6/site-packages/tensorflow_core/python/training/supervisor.py"", line 839, in stop
    ignore_live_threads=ignore_live_threads)
  File ""/usr/local/lib/python3.6/site-packages/tensorflow_core/python/training/coordinator.py"", line 389, in join
    six.reraise(*self._exc_info_to_raise)
  File ""/usr/local/lib/python3.6/site-packages/six.py"", line 703, in reraise
    raise value
  File ""/usr/local/lib/python3.6/site-packages/tensorflow_core/python/training/queue_runner_impl.py"", line 257, in _run
    enqueue_callable()
  File ""/usr/local/lib/python3.6/site-packages/tensorflow_core/python/client/session.py"", line 1287, in _single_operation_run
    self._call_tf_sessionrun(None, {}, [], target_list, None)
  File ""/usr/local/lib/python3.6/site-packages/tensorflow_core/python/client/session.py"", line 1443, in _call_tf_sessionrun
    run_metadata)
tensorflow.python.framework.errors_impl.InvalidArgumentError: Name: , Context feature 'id' is required but could not be found.
         [[{{node train_input/ParseSingleSequenceExample/ParseSingleSequenceExample}}]]`

I would really appreciate your help.
Best wishes",xiaoluobu,b'models:research type:bug',2020-06-08T19:22:10Z,2020-06-10T01:06:26Z,,,,,,,
8634,Quantization of LeNET model using MNIST dataset breaks during model freeze,"I'm trying to train Lenet-net using the MNIST dataset from [here](http://yann.lecun.com/exdb/mnist/ ) and to quantize its float model. My steps are the following:

Firstly, I have applied MNIST dataset to train the classifier which works fines. 

```
python3 train_image_classifier.py --dataset_dir=tmp/mnist --dataset_name=mnist --train_dir=train/mnist --model_name=lenet --clone_on_cpu=true --max_number_of_steps=50000 --quantize_delay=40000
```

Secondly, I have exported the trained model to the pb format and it works well.

```
python3 export_inference_graph.py --dataset_dir=tmp/mnist --dataset_name=mnist --train_dir=train/mnist --model_name=lenet --checkpoint=train/mnist/model.ckpt-50000 --quantize --output_file=mnist.pb 
```

Finally, I try to freeze graph using 
```
freeze_graph --input_graph=mnist.pb --input_checkpoint=train/mnist/model.ckpt-50000 --output_graph=mnist_frozen.pb --input_binary=true --output_node_names=Predictions/Reshape_1 
``` 

but the following error occurred

```
InvalidArgumentError: Restoring from checkpoint failed. This is most likely due to a mismatch between the current graph and the graph from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:

Assign requires shapes of both tensors to match. lhs shape= [5,5,3,32] rhs shape= [5,5,1,32] 
```

Please can you advise how to freeze it correctly?


BTW, I have tried other models like CIFAR10 and all process works fine.
",peter197321,b'models:research type:bug',2020-06-05T21:28:37Z,2020-06-08T13:35:14Z,,,,,,,
8632,model detects only 1 class,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution : Linux Ubuntu 18.04

- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 1.15.0
- Python version: 3.7.4 

- CUDA/cuDNN version: 10.2 
- GPU model and memory: GeForce GTX 1050



**Describe the current behavior**
Hello, i ran a 3 classes object detection model on cloud but it only detects 1 classes
it's return a good loss and mAP but only for one
since i ran it on model_main so the evaluation is included, checked tensorboard everything(GT and detections) looks good but only for one class
i tried swapping classes in the label map it detects only the last one, 

**Dataset**
3 classes dataset with around 100 images per class
20 for evaluation

**Data prep**
Annotation : using labelImg
**Generating csv**
```
 import os
import glob
import pandas as pd
import xml.etree.ElementTree as ET


def xml_to_csv(path):
    xml_list = []
    for xml_file in glob.glob(path + '/*.xml'):
        tree = ET.parse(xml_file)
        root = tree.getroot()
        for member in root.findall('object'):
            value = (root.find('filename').text,
                     int(root.find('size')[0].text),
                     int(root.find('size')[1].text),
                     member[0].text,
                     int(member[4][0].text),
                     int(member[4][1].text),
                     int(member[4][2].text),
                     int(member[4][3].text)
                     )
            xml_list.append(value)
    column_name = ['filename', 'width', 'height', 'class', 'xmin', 'ymin', 'xmax', 'ymax']
    xml_df = pd.DataFrame(xml_list, columns=column_name)
    return xml_df


def main():
  for directory in ['train','test'] :
    image_path = os.path.join(os.getcwd(), 'images/{}'.format(directory))
    xml_df = xml_to_csv(image_path)
    xml_df.to_csv('data/{}_labels.csv'.format(directory), index=None)
    print('Successfully converted xml to csv.')


main()
```
**Generating TFRecords**

```
from __future__ import division
from __future__ import print_function
from __future__ import absolute_import
from random import shuffle
import os
import io
import pandas as pd
import tensorflow as tf

from PIL import Image
from object_detection.utils import dataset_util
from collections import namedtuple, OrderedDict

flags = tf.app.flags
flags.DEFINE_string('csv_input', '', 'Path to the CSV input')
flags.DEFINE_string('output_path', '', 'Path to output TFRecord')
flags.DEFINE_string('image_dir', '', 'Path to images')
FLAGS = flags.FLAGS


# TO-DO replace this with label map
def class_text_to_int(row_label):
    if row_label == 'orange':
        return 1
    elif row_label == 'tunisie_telecom' :
        return 2
    elif row_label == 'ooredoo' :
        return 3
    else:
        None


def split(df, group):
    data = namedtuple('data', ['filename', 'object'])
    gb = df.groupby(group)
    return [data(filename, gb.get_group(x)) for filename, x in zip(gb.groups.keys(), gb.groups)]


def create_tf_example(group, path):
    with tf.gfile.GFile(os.path.join(path, '{}'.format(group.filename)), 'rb') as fid:
        encoded_jpg = fid.read()
    encoded_jpg_io = io.BytesIO(encoded_jpg)
    image = Image.open(encoded_jpg_io)
    width, height = image.size

    filename = group.filename.encode('utf8')
    image_format = b'jpg'
    xmins = []
    xmaxs = []
    ymins = []
    ymaxs = []
    classes_text = []
    classes = []

    for index, row in group.object.iterrows():
        xmins.append(row['xmin'] / width)
        xmaxs.append(row['xmax'] / width)
        ymins.append(row['ymin'] / height)
        ymaxs.append(row['ymax'] / height)
        classes_text.append(row['class'].encode('utf8'))
        classes.append(class_text_to_int(row['class']))

    tf_example = tf.train.Example(features=tf.train.Features(feature={
        'image/height': dataset_util.int64_feature(height),
        'image/width': dataset_util.int64_feature(width),
        'image/filename': dataset_util.bytes_feature(filename),
        'image/source_id': dataset_util.bytes_feature(filename),
        'image/encoded': dataset_util.bytes_feature(encoded_jpg),
        'image/format': dataset_util.bytes_feature(image_format),
        'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),
        'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),
        'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),
        'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),
        'image/object/class/text': dataset_util.bytes_list_feature(classes_text),
        'image/object/class/label': dataset_util.int64_list_feature(classes),
    }))
    return tf_example


def main(_):
    writer = tf.python_io.TFRecordWriter(FLAGS.output_path)
    path = os.path.join(FLAGS.image_dir)
    examples = pd.read_csv(FLAGS.csv_input)
    grouped = split(examples, 'filename')
    shuffle(grouped)
    for group in grouped:
        tf_example = create_tf_example(group, path)
        writer.write(tf_example.SerializeToString())

    writer.close()
    output_path = os.path.join(os.getcwd(), FLAGS.output_path)
    print('Successfully created the TFRecords: {}'.format(output_path))


if __name__ == '__main__':
    tf.app.run()
```
**Label map**
```
item {
  id: 1
  name: 'orange'

  id: 2

  name: 'tunisie_telecom'

  id: 3

  name: 'ooredoo'
}
```
**Config file**
```

# R-FCN with Resnet-101 (v1),  configuration for MSCOCO Dataset.
# Users should configure the fine_tune_checkpoint field in the train config as
# well as the label_map_path and input_path fields in the train_input_reader and
# eval_input_reader. Search for ""PATH_TO_BE_CONFIGURED"" to find the fields that
# should be configured.

model {
  faster_rcnn {
    num_classes: 3
    image_resizer {
      keep_aspect_ratio_resizer {
        min_dimension: 600
        max_dimension: 1024
      }
    }
    feature_extractor {
      type: 'faster_rcnn_resnet101'
      first_stage_features_stride: 16
    }
    first_stage_anchor_generator {
      grid_anchor_generator {
        scales: [0.25, 0.5, 1.0, 2.0]
        aspect_ratios: [0.5, 1.0, 2.0]
        height_stride: 16
        width_stride: 16
      }
    }
    first_stage_box_predictor_conv_hyperparams {
      op: CONV
      regularizer {
        l2_regularizer {
          weight: 0.0
        }
      }
      initializer {
        truncated_normal_initializer {
          stddev: 0.01
        }
      }
    }
    first_stage_nms_score_threshold: 0.0
    first_stage_nms_iou_threshold: 0.7
    first_stage_max_proposals: 300
    first_stage_localization_loss_weight: 2.0
    first_stage_objectness_loss_weight: 1.0
    second_stage_box_predictor {
      rfcn_box_predictor {
        conv_hyperparams {
          op: CONV
          regularizer {
            l2_regularizer {
              weight: 0.0
            }
          }
          initializer {
            truncated_normal_initializer {
              stddev: 0.01
            }
          }
        }
        crop_height: 18
        crop_width: 18
        num_spatial_bins_height: 3
        num_spatial_bins_width: 3
      }
    }
    second_stage_post_processing {
      batch_non_max_suppression {
        score_threshold: 0.0
        iou_threshold: 0.6
        max_detections_per_class: 100
        max_total_detections: 300
      }
      score_converter: SOFTMAX
    }
    second_stage_localization_loss_weight: 2.0
    second_stage_classification_loss_weight: 1.0
  }
}

train_config: {
  batch_size: 1
  optimizer {
    adam_optimizer: {
      learning_rate: {
        manual_step_learning_rate {
          initial_learning_rate: 0.0001
          schedule {
            step: 1
            learning_rate: .00001
          }
          schedule {
            step: 4000
            learning_rate: .000001
          }
          schedule {
            step: 8000
            learning_rate: .0000001
          }
          schedule {
            step: 12000
            learning_rate: .00000001
          }
          schedule {
            step: 16000
            learning_rate: .000000001
          }
          schedule {
            step: 18000
            learning_rate: .0000000001
          }

        }
      }
      #momentum_optimizer_value: 0.9
    }
    use_moving_average: false
  }
  gradient_clipping_by_norm: 10.0
  fine_tune_checkpoint: ""gs://nidham3/pfe/backbone/rfcn/model.ckpt""
  from_detection_checkpoint: true
  fine_tune_checkpoint_type:'detection'
  # Note: The below line limits the training process to 200K steps, which we
  # empirically found to be sufficient enough to train the pets dataset. This
  # effectively bypasses the learning rate schedule (the learning rate will
  # never decay). Remove the below line to train indefinitely.
  num_steps: 20000
  data_augmentation_options {
    random_horizontal_flip {
    }
  }
  data_augmentation_options {
    random_image_scale {
      min_scale_ratio: 0.3
      max_scale_ratio: 1.5
    }
  }
  data_augmentation_options {
    random_adjust_saturation {
    }
  }
  data_augmentation_options {
    random_adjust_contrast {
    }
  }
  data_augmentation_options {
    random_adjust_hue {
    }
  }
  data_augmentation_options {
    random_pixel_value_scale {
    }
  }
  data_augmentation_options {
    random_crop_image {
    }
  }
}

train_input_reader: {
  tf_record_input_reader {
    input_path: ""gs://nidham3/pfe/data/train.record""
  }
  label_map_path: ""gs://nidham3/pfe/data/logos.pbtxt""
}

eval_config: {
  num_examples: 20
  # Note: The below line limits the evaluation process to 10 evaluations.
  # Remove the below line to evaluate indefinitely.
  max_evals: 20
}

eval_input_reader: {
  tf_record_input_reader {
    input_path: ""gs://nidham3/pfe/data/test.record""
  }
  label_map_path: ""gs://nidham3/pfe/data/logos.pbtxt""
  shuffle: false
  num_readers: 1
}
```
** from models/research i ran :**
```
gcloud ml-engine jobs submit training pfe_train_`date +%m_%d_%Y_%H_%M_%S` \
    --runtime-version 1.15 \
    --job-dir=gs://nidham3/pfe/job_dir/pfe_train_`date +%m_%d_%Y_%H` \
    --packages dist/object_detection-0.1.tar.gz,slim/dist/slim-0.1.tar.gz,/tmp/pycocotools/pycocotools-2.0.tar.gz \
    --module-name object_detection.model_main \
    --region us-central1 \
    --config /home/milos/Desktop/cloud_train/gcp_train.yaml \
    -- \
    --model_dir=gs://nidham3/pfe/model/resnet101_training \
    --pipeline_config_path=gs://nidham3/pfe/pipeline/rfcn.config
```
**with gcp_train.yaml:**
```
trainingInput:
  scaleTier: BASIC_GPU
  pythonVersion: ""3.5""
```
I doubled check  every configurable num classes i know it's all set to 3 ",TekayaNidham,b'models:research type:bug',2020-06-05T13:06:49Z,2020-06-06T01:51:41Z,,,,,,,
8614,Pack node (RandomCropToAspectRatio/stack) axis attribute is out of bounds,"Hello

Using tf 1.13.rc0, python 2.7.12 on docker image, 16GB ram 4 core.

Im trying to recompile facessd_mobilenet_v2_quantized_320x320_open_image_v4 model but im having problems with the config file https://github.com/tensorflow/models/blob/master/research/object_detection/samples/configs/facessd_mobilenet_v2_quantized_320x320_open_image_v4.config

`./tensorflow/core/grappler/optimizers/graph_optimizer_stage.h:241 Faield to run ArithmetricOptimizer, stage RemoveStackStrideSliceSameAxis node RandomCropToAspectRatio/ChangeCoordinateFrame/strided_slice. Pack node (RandomCropToAspectRatio/stack) axis attribute is out of bounds`

",natxopedreira,b'models:official type:bug',2020-06-03T07:52:33Z,2020-06-03T07:53:21Z,,,,,,,
8613,assertion failed: [max value is lower than 1.01: ] [0],"## 1. The entire URL of the file you are using

git clone https://github.com/tensorflow/models --single-branch --branch r1.13.0

## 2. Describe the bug

It always crashes after step 800 with the following message
tensorflow.python.framework.errors_impl.InvalidArgumentError: 2 root error(s) found.
  (0) Invalid argument: assertion failed: [max value is lower than 1.01: ] [0]
	 [[node Loss/BoxClassifierLoss/ToNormalizedCoordinates/Assert/AssertGuard/Assert (defined at /home/asgtech/anaconda3/envs/training/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py:1748) ]]
	 [[control_dependency/_5517]]
  (1) Invalid argument: assertion failed: [max value is lower than 1.01: ] [0]
	 [[node Loss/BoxClassifierLoss/ToNormalizedCoordinates/Assert/AssertGuard/Assert (defined at /home/asgtech/anaconda3/envs/training/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py:1748) ]]
0 successful operations.
0 derived errors ignored.


## 3. Steps to reproduce

Installed models/research following this
https://gilberttanner.com/blog/installing-the-tensorflow-object-detection-api

Have been trying to reproduce this
https://gilberttanner.com/blog/train-a-mask-r-cnn-model-with-the-tensorflow-object-detection-api

## 4. Expected behavior

It should train for 2000 steps

## 5. Additional context

Attached log and config
[log file.txt](https://github.com/tensorflow/models/files/4721380/log.file.txt)

[mask_rcnn_inception_v2_coco.config.txt](https://github.com/tensorflow/models/files/4721386/mask_rcnn_inception_v2_coco.config.txt)

## 6. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 1.15
- Python version: 3.6.9
- CUDA/cuDNN version: cuda-command-line-tools-10-0/unknown,now 10.0.130-1 amd64 [installed,automatic]
                                       libcudnn7/now 7.6.5.32-1+cuda10.0 amd64 [installed,local]
- GPU model and memory: RTX 2070 8GB

<!-- 
Collect system information using our environment capture script.
https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can also obtain the TensorFlow version with:

1. TensorFlow 1.0
`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

2. TensorFlow 2.0
`python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`
-->
",asgtech,b'models:research type:bug',2020-06-03T06:40:45Z,2020-08-28T21:04:03Z,,,,,,,
8611,appear 160 ops no flops stats due to incomplete  shape  when convert ckpt to pd,"the model is ssd-mobilenet-v2 that trained by my own dataset  .when run  export_inference_graph.py ,  appear 160 ops no flops stats due to incomplete  shape，and the pd of produce is only 19M . the tensorflow's vesion is 1.13.   how to solve it?",DENESTY,b'models:research type:bug',2020-06-02T20:38:45Z,2020-06-05T09:23:41Z,,,,,,,
8598,ModuleNotFoundError: No module named 'tf_slim',"# Prerequisites

Please answer the following questions for yourself before submitting an issue.

- [ ] I am using the latest TensorFlow Model Garden release and TensorFlow 2.
- [x] I am reporting the issue to the correct repository. (Model Garden official or research directory)
- [x] I checked to make sure that this issue has not already been filed.

## 1. The entire URL of the file you are using

https://github.com/tensorflow/models/blob/master/research/object_detection/utils/ops.py

## 2. Describe the bug

Well, I was using the same code as from the object_detection_tutorial.ipynb on Monday (May 25 2020) and it was working fine. Today (May 31 2020) when I am running the code again I am getting **ModuleNotFoundError: No module named 'tf_slim'**

## 3. Steps to reproduce

Steps to reproduce the behavior.

1. Run object_detection_tutorial.ipynb
2. Run the cell with the line: from object_detection.utils import ops as utils_ops

## 4. Expected behavior

A clean run of that specific cell with no issues.

## 5. Additional context

No logs. Easy to reproduce.

## 6. System information

- OS Platform and Distribution (Windows 10):
- Run in Coolab the tutorial, nbno changes to the tutorial

<!-- 
Collect system information using our environment capture script.
https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can also obtain the TensorFlow version with:

1. TensorFlow 1.0
`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

2. TensorFlow 2.0
`python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`
-->
",ISimion,b'models:research type:bug',2020-05-31T07:36:49Z,2020-06-18T17:51:40Z,,,,,,,
8595,tensorflow.python.framework.errors_impl.InvalidArgumentError: Invalid argument: assertion failed:,"# Prerequisites

Please answer the following questions for yourself before submitting an issue.

- [Yes, Research Directory. No, TF1.x ] I am using the latest TensorFlow Model Garden release and TensorFlow 2.
- [Yes, research directory. ] I am reporting the issue to the correct repository. (Model Garden official or research directory)
- [Yes ] I checked to make sure that this issue has not already been filed.

## 1. The entire URL of the file you are using

https://github.com/tensorflow/models/tree/master/research/object_detection/model_main.py

## 2. Describe the bug
While training a custom object detector using TensorFlow Object Detection API on Colab I got this error. I was using `tensorflow-gpu==1.15.0`  and for fine tuning I was using `ssd_mobilenet_v2_coco` . Following is the verbose along with the error I got:
```

WARNING:tensorflow:Forced number of epochs for all eval validations to be 1.
W0528 21:13:21.113062 140292083513216 model_lib.py:717] Forced number of epochs for all eval validations to be 1.
INFO:tensorflow:Maybe overwriting train_steps: 200000
I0528 21:13:21.113316 140292083513216 config_util.py:523] Maybe overwriting train_steps: 200000
INFO:tensorflow:Maybe overwriting use_bfloat16: False
I0528 21:13:21.113430 140292083513216 config_util.py:523] Maybe overwriting use_bfloat16: False
INFO:tensorflow:Maybe overwriting sample_1_of_n_eval_examples: 1
I0528 21:13:21.113519 140292083513216 config_util.py:523] Maybe overwriting sample_1_of_n_eval_examples: 1
INFO:tensorflow:Maybe overwriting eval_num_epochs: 1
I0528 21:13:21.113614 140292083513216 config_util.py:523] Maybe overwriting eval_num_epochs: 1
INFO:tensorflow:Maybe overwriting load_pretrained: True
I0528 21:13:21.113696 140292083513216 config_util.py:523] Maybe overwriting load_pretrained: True
INFO:tensorflow:Ignoring config override key: load_pretrained
I0528 21:13:21.113776 140292083513216 config_util.py:533] Ignoring config override key: load_pretrained
WARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.
W0528 21:13:21.114626 140292083513216 model_lib.py:733] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.
INFO:tensorflow:create_estimator_and_inputs: use_tpu False, export_to_tpu False
I0528 21:13:21.114744 140292083513216 model_lib.py:768] create_estimator_and_inputs: use_tpu False, export_to_tpu False
INFO:tensorflow:Using config: {'_model_dir': 'training/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true
graph_options {
  rewrite_options {
    meta_optimizer_iterations: ONE
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f97ed4dd128>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0528 21:13:21.115245 140292083513216 estimator.py:212] Using config: {'_model_dir': 'training/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true
graph_options {
  rewrite_options {
    meta_optimizer_iterations: ONE
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f97ed4dd128>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
WARNING:tensorflow:Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7f97d328dbf8>) includes params argument, but params are not passed to Estimator.
W0528 21:13:21.115487 140292083513216 model_fn.py:630] Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7f97d328dbf8>) includes params argument, but params are not passed to Estimator.
INFO:tensorflow:Not using Distribute Coordinator.
I0528 21:13:21.116259 140292083513216 estimator_training.py:186] Not using Distribute Coordinator.
INFO:tensorflow:Running training and evaluation locally (non-distributed).
I0528 21:13:21.116456 140292083513216 training.py:612] Running training and evaluation locally (non-distributed).
INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.
I0528 21:13:21.116694 140292083513216 training.py:700] Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0528 21:13:21.124795 140292083513216 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.
W0528 21:13:21.162153 140292083513216 dataset_builder.py:84] num_readers has been reduced to 1 to match input file shards.
WARNING:tensorflow:From /content/models/research/object_detection/builders/dataset_builder.py:101: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.experimental.parallel_interleave(...)`.
W0528 21:13:21.167545 140292083513216 deprecation.py:323] From /content/models/research/object_detection/builders/dataset_builder.py:101: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.experimental.parallel_interleave(...)`.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/data/python/ops/interleave_ops.py:77: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0528 21:13:21.167754 140292083513216 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/data/python/ops/interleave_ops.py:77: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
2020-05-28 21:13:22.910301: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-05-28 21:13:22.953259: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-28 21:13:22.953875: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59
pciBusID: 0000:00:04.0
2020-05-28 21:13:22.960996: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2020-05-28 21:13:22.967688: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2020-05-28 21:13:22.977811: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2020-05-28 21:13:22.985131: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2020-05-28 21:13:22.995549: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2020-05-28 21:13:23.004617: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2020-05-28 21:13:23.025234: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-05-28 21:13:23.025382: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-28 21:13:23.026101: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-28 21:13:23.026693: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
WARNING:tensorflow:From /content/models/research/object_detection/inputs.py:77: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.
W0528 21:13:33.109247 140292083513216 deprecation.py:323] From /content/models/research/object_detection/inputs.py:77: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.
WARNING:tensorflow:From /content/models/research/object_detection/utils/ops.py:493: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
W0528 21:13:33.221111 140292083513216 deprecation.py:323] From /content/models/research/object_detection/utils/ops.py:493: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/operators/control_flow.py:1004: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.
Instructions for updating:
`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.
W0528 21:13:39.145547 140292083513216 api.py:332] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/operators/control_flow.py:1004: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.
Instructions for updating:
`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.
WARNING:tensorflow:From /content/models/research/object_detection/inputs.py:259: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
W0528 21:13:42.865469 140292083513216 deprecation.py:323] From /content/models/research/object_detection/inputs.py:259: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
WARNING:tensorflow:From /content/models/research/object_detection/builders/dataset_builder.py:174: batch_and_drop_remainder (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.batch(..., drop_remainder=True)`.
W0528 21:13:46.217640 140292083513216 deprecation.py:323] From /content/models/research/object_detection/builders/dataset_builder.py:174: batch_and_drop_remainder (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.batch(..., drop_remainder=True)`.
INFO:tensorflow:Calling model_fn.
I0528 21:13:46.233859 140292083513216 estimator.py:1148] Calling model_fn.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
Please use `layer.__call__` method instead.
W0528 21:13:46.430602 140292083513216 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
Please use `layer.__call__` method instead.
INFO:tensorflow:depth of additional conv before box predictor: 0
I0528 21:13:49.101978 140292083513216 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0
INFO:tensorflow:depth of additional conv before box predictor: 0
I0528 21:13:49.133970 140292083513216 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0
INFO:tensorflow:depth of additional conv before box predictor: 0
I0528 21:13:49.165436 140292083513216 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0
INFO:tensorflow:depth of additional conv before box predictor: 0
I0528 21:13:49.343221 140292083513216 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0
INFO:tensorflow:depth of additional conv before box predictor: 0
I0528 21:13:49.377842 140292083513216 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0
INFO:tensorflow:depth of additional conv before box predictor: 0
I0528 21:13:49.414346 140292083513216 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0
W0528 21:13:49.456603 140292083513216 variables_helper.py:161] Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/weights] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[1, 1, 256, 512]], model variable shape: [[3, 3, 256, 512]]. This variable will not be initialized from the checkpoint.
W0528 21:13:49.456816 140292083513216 variables_helper.py:161] Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/weights] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[1, 1, 128, 256]], model variable shape: [[3, 3, 128, 256]]. This variable will not be initialized from the checkpoint.
W0528 21:13:49.456997 140292083513216 variables_helper.py:161] Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/weights] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[1, 1, 128, 256]], model variable shape: [[3, 3, 128, 256]]. This variable will not be initialized from the checkpoint.
W0528 21:13:49.457174 140292083513216 variables_helper.py:161] Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/weights] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[1, 1, 64, 128]], model variable shape: [[3, 3, 64, 128]]. This variable will not be initialized from the checkpoint.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0528 21:13:54.449208 140292083513216 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
INFO:tensorflow:Done calling model_fn.
I0528 21:14:00.871218 140292083513216 estimator.py:1150] Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
I0528 21:14:00.872715 140292083513216 basic_session_run_hooks.py:541] Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
I0528 21:14:04.557027 140292083513216 monitored_session.py:240] Graph was finalized.
2020-05-28 21:14:04.557485: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2020-05-28 21:14:04.562729: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2000165000 Hz
2020-05-28 21:14:04.563012: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1771800 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-05-28 21:14:04.563048: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-05-28 21:14:04.666903: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-28 21:14:04.667672: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1770d80 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-05-28 21:14:04.667705: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5
2020-05-28 21:14:04.668018: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-28 21:14:04.668594: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59
pciBusID: 0000:00:04.0
2020-05-28 21:14:04.668682: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2020-05-28 21:14:04.668724: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2020-05-28 21:14:04.668747: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2020-05-28 21:14:04.668769: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2020-05-28 21:14:04.668796: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2020-05-28 21:14:04.668819: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2020-05-28 21:14:04.668842: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-05-28 21:14:04.668951: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-28 21:14:04.669555: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-28 21:14:04.670109: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
2020-05-28 21:14:04.670229: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2020-05-28 21:14:04.671546: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-05-28 21:14:04.671575: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 
2020-05-28 21:14:04.671585: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N 
2020-05-28 21:14:04.671747: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-28 21:14:04.672416: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-28 21:14:04.672994: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2020-05-28 21:14:04.673037: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14221 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)
INFO:tensorflow:Running local_init_op.
I0528 21:14:09.605103 140292083513216 session_manager.py:500] Running local_init_op.
INFO:tensorflow:Done running local_init_op.
I0528 21:14:09.941666 140292083513216 session_manager.py:502] Done running local_init_op.
INFO:tensorflow:Saving checkpoints for 0 into training/model.ckpt.
I0528 21:14:18.960145 140292083513216 basic_session_run_hooks.py:606] Saving checkpoints for 0 into training/model.ckpt.
2020-05-28 21:14:36.916392: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:145] Filling up shuffle buffer (this may take a while): 1074 of 2048
2020-05-28 21:14:46.905139: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:145] Filling up shuffle buffer (this may take a while): 2026 of 2048
2020-05-28 21:14:46.910085: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:195] Shuffle buffer filled.
2020-05-28 21:14:47.284742: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-05-28 21:14:53.420068: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
INFO:tensorflow:loss = 12.133639, step = 0
I0528 21:14:56.692664 140292083513216 basic_session_run_hooks.py:262] loss = 12.133639, step = 0
Traceback (most recent call last):
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1365, in _do_call
    return fn(*args)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1350, in _run_fn
    target_list, run_metadata)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1443, in _call_tf_sessionrun
    run_metadata)
tensorflow.python.framework.errors_impl.InvalidArgumentError: 2 root error(s) found.
  (0) Invalid argument: {{function_node __inference_Dataset_map_transform_and_pad_input_data_fn_3047}} assertion failed: [[0.748][0.758]] [[0.67][0.67]]
     [[{{node Assert/AssertGuard/else/_123/Assert}}]]
     [[IteratorGetNext]]
  (1) Invalid argument: {{function_node __inference_Dataset_map_transform_and_pad_input_data_fn_3047}} assertion failed: [[0.748][0.758]] [[0.67][0.67]]
     [[{{node Assert/AssertGuard/else/_123/Assert}}]]
     [[IteratorGetNext]]
     [[IteratorGetNext/_8451]]
0 successful operations.
0 derived errors ignored.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/content/models/research/object_detection/model_main.py"", line 114, in <module>
    tf.app.run()
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""/content/models/research/object_detection/model_main.py"", line 110, in main
    tf.estimator.train_and_evaluate(estimator, train_spec, eval_specs[0])
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py"", line 473, in train_and_evaluate
    return executor.run()
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py"", line 613, in run
    return self.run_local()
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py"", line 714, in run_local
    saving_listeners=saving_listeners)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 370, in train
    loss = self._train_model(input_fn, hooks, saving_listeners)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1161, in _train_model
    return self._train_model_default(input_fn, hooks, saving_listeners)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1195, in _train_model_default
    saving_listeners)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1494, in _train_with_estimator_spec
    _, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 754, in run
    run_metadata=run_metadata)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1259, in run
    run_metadata=run_metadata)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1360, in run
    raise six.reraise(*original_exc_info)
  File ""/usr/local/lib/python3.6/dist-packages/six.py"", line 693, in reraise
    raise value
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1345, in run
    return self._sess.run(*args, **kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1418, in run
    run_metadata=run_metadata)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1176, in run
    return self._sess.run(*args, **kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 956, in run
    run_metadata_ptr)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1180, in _run
    feed_dict_tensor, options, run_metadata)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1359, in _do_run
    run_metadata)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1384, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.InvalidArgumentError: 2 root error(s) found.
  (0) Invalid argument:  assertion failed: [[0.748][0.758]] [[0.67][0.67]]
     [[{{node Assert/AssertGuard/else/_123/Assert}}]]
     [[IteratorGetNext]]
  (1) Invalid argument:  assertion failed: [[0.748][0.758]] [[0.67][0.67]]
     [[{{node Assert/AssertGuard/else/_123/Assert}}]]
     [[IteratorGetNext]]
     [[IteratorGetNext/_8451]]
0 successful operations.
0 derived errors ignored.
```

## 3. Steps to reproduce

Training using `model_main.py` file while using `tensorflow-gpu==1.15.0` along with `ssd_mobilenet_v2_coco` produces this.

**EDIT:** I have tried both `tensorflow-gpu==1.15.0` (with pip installation) and version `1.15.2` (by specifying  `%tensorflow_version 1.x` Colab automatically installed version `1.15.2`). While working with both of them I got this error. I also encountered the no module found error for `tf-slim` which I fixed by installing `!pip install git+https://github.com/google-research/tf-slim` during my work. Finally, before I began training I executed `model_builder_test.py` to make sure everything is okay. And `model_builder_test.py` also didn't report any problem. But still I am getting this error.
I also asked the question on `Stack Overflow` and there I got comments like: "".......I uninstalled tensorflow-gpu 1.15, and installed 1.14, and it started the training. Sometimes after steps 200, sometimes after steps 1900, I still get the same error"". Here is the [link](https://stackoverflow.com/questions/62075321/tensorflow-python-framework-errors-impl-invalidargumenterror-invalid-argument).

## 4. Expected behavior

A clear and concise description of what you expected to happen.

## 5. Additional context

Include any logs that would be helpful to diagnose the problem.

## 6. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device name if the issue happens on a mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below):
- Python version:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

<!-- 
Collect system information using our environment capture script.
https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can also obtain the TensorFlow version with:

1. TensorFlow 1.0
`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

2. TensorFlow 2.0
`python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`
-->
",hafiz031,b'models:research type:bug',2020-05-30T19:04:08Z,2020-09-28T19:51:04Z,,,,,,,
8575,The following classes have no ground truth,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution : Linux Ubuntu 18.04

- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 1.15.0
- Python version: 3.7.4 

- CUDA/cuDNN version: 10.2 
- GPU model and memory: GeForce GTX 1050



**Describe the current behavior**
hey guys, i'm trying to train an object detection 3 classes model using resnet101 faster rcnn using train.py from legacy folder from object detection api,
the losses looks very good but when running eval.py i get a very low mAP of the 3rd one only
with this warning : 
object_detection_evaluation.py:1279] The following classes have no ground truth examples: [1 2]

label map : 

```
item {
  id: 1
  name: 'ooredoo'
  id: 2
  name: 'tt'
  id: 3
  name: 'orange'
}
```


config file  : 

```
# Faster R-CNN with Resnet-101 (v1), configuration for MSCOCO Dataset.
# Users should configure the fine_tune_checkpoint field in the train config as
# well as the label_map_path and input_path fields in the train_input_reader and
# eval_input_reader. Search for ""PATH_TO_BE_CONFIGURED"" to find the fields that
# should be configured.

model {
  faster_rcnn {
    num_classes: 3
    image_resizer {
      keep_aspect_ratio_resizer {
        min_dimension: 600
        max_dimension: 1024
      }
    }
    feature_extractor {
      type: 'faster_rcnn_resnet101'
      first_stage_features_stride: 16
    }
    first_stage_anchor_generator {
      grid_anchor_generator {
        scales: [0.25, 0.5, 1.0, 2.0]
        aspect_ratios: [0.5, 1.0, 2.0]
        height_stride: 16
        width_stride: 16
      }
    }
    first_stage_box_predictor_conv_hyperparams {
      op: CONV
      regularizer {
        l2_regularizer {
          weight: 0.0
        }
      }
      initializer {
        truncated_normal_initializer {
          stddev: 0.01
        }
      }
    }
    first_stage_nms_score_threshold: 0.0
    first_stage_nms_iou_threshold: 0.7
    first_stage_max_proposals: 300
    first_stage_localization_loss_weight: 2.0
    first_stage_objectness_loss_weight: 1.0
    initial_crop_size: 14
    maxpool_kernel_size: 2
    maxpool_stride: 2
    second_stage_box_predictor {
      mask_rcnn_box_predictor {
        use_dropout: false
        dropout_keep_probability: 1.0
        fc_hyperparams {
          op: FC
          regularizer {
            l2_regularizer {
              weight: 0.0
            }
          }
          initializer {
            variance_scaling_initializer {
              factor: 1.0
              uniform: true
              mode: FAN_AVG
            }
          }
        }
      }
    }
    second_stage_post_processing {
      batch_non_max_suppression {
        score_threshold: 0.0
        iou_threshold: 0.6
        max_detections_per_class: 100
        max_total_detections: 300
      }
      score_converter: SOFTMAX
    }
    second_stage_localization_loss_weight: 2.0
    second_stage_classification_loss_weight: 1.0
  }
}

train_config: {
  batch_size: 1
  optimizer {
    momentum_optimizer: {
      learning_rate: {
        manual_step_learning_rate {
          initial_learning_rate: 0.0003
          schedule {
            step: 300
            learning_rate: .00003
          }
          schedule {
            step: 600
            learning_rate: .000003
          }
        }
      }
      momentum_optimizer_value: 0.9
    }
    use_moving_average: false
  }
  gradient_clipping_by_norm: 10.0
  fine_tune_checkpoint: ""faster_rcnn_resnet101_coco_2018_01_28/model.ckpt""
  from_detection_checkpoint: true
  data_augmentation_options {
    random_horizontal_flip {
    }
  }
}

train_input_reader: {
  tf_record_input_reader {
    input_path: ""data/train.record""
  }
  label_map_path: ""data/comm.pbtxt""
}

eval_config: {
  num_examples: 22
  # Note: The below line limits the evaluation process to 10 evaluations.
  # Remove the below line to evaluate indefinitely.
  max_evals: 10
}

eval_input_reader: {
  tf_record_input_reader {
    input_path: ""data/test.record""
  }
  label_map_path: ""data/comm.pbtxt""
  shuffle: false
  num_readers: 1
}

```

already checked https://github.com/tensorflow/models/issues/1936 and https://github.com/tensorflow/models/issues/1696 
 ",TekayaNidham,b'models:research type:bug',2020-05-26T17:52:05Z,2020-06-19T00:04:39Z,,,,,,,
8572,"""ImportError: cannot import name tf2"" when doing Object Detection Model Training in Google Cloud","# Prerequisites

Please answer the following questions for yourself before submitting an issue.

- [no] I am using the latest TensorFlow Model Garden release and TensorFlow 2.
- [yes] I am reporting the issue to the correct repository. (Model Garden official or research directory)
- [yes] I checked to make sure that this issue has not been filed already.

## 1. The entire URL of the file you are using

https://github.com/tensorflow/models

## 2. Describe the bug

Starting a training job on google cloud for my object detection dataset. Job stops after ~7 minutes giving this error:
```
Traceback (most recent call last): File ""/usr/lib/python2.7/runpy.py"", line 174, in _run_module_as_main ""__main__"", fname, loader, pkg_name) 
File ""/usr/lib/python2.7/runpy.py"", line 72, in _run_code exec code in run_globals 
File ""/root/.local/lib/python2.7/site-packages/object_detection/model_main.py"", line 26, in <module> from object_detection import model_lib 
File ""/root/.local/lib/python2.7/site-packages/object_detection/model_lib.py"", line 28, in <module> from object_detection import exporter as exporter_lib 
File ""/root/.local/lib/python2.7/site-packages/object_detection/exporter.py"", line 23, in <module> from object_detection.builders import model_builder 
File ""/root/.local/lib/python2.7/site-packages/object_detection/builders/model_builder.py"", line 39, in <module> from object_detection.utils import tf_version
 File ""/root/.local/lib/python2.7/site-packages/object_detection/utils/tf_version.py"", line 17, in <module> from tensorflow.python import tf2 # pylint: disable=import-outside-toplevel ImportError: cannot import name tf2
```
Local training however works fine, but is really slow and will take at least a week.

## 3. Steps to reproduce

Install Tensorflow 1.14 with pip, all other libraries for the API, model repository, pycocotools, protobuf 3.11.4 -> testing the API installation works fine.
Create dataset including tfrecord files, training pipeline, googlecloud yaml file, ...
Run google cloud training job with:
# in models/research
```
gcloud ai-platform jobs submit training balls200_training_260520a     --runtime-version 1.12     --job-dir=gs://200balls_model/train     --packages dist/object_detection-0.1.tar.gz,slim/dist/slim-0.1.tar.gz,tmp/pycocotools/pycocotools-2.0.tar.gz     --module-name object_detection.model_main     --region us-central1     --config /home/ubuntu/Documents/200balls_modeltraining/cloud.yml     --     --model_dir=gs://200balls_model/train     --pipeline_config_path=gs://200balls_model/pipeline.config
```
getting the error
uninstalling tensorflow 1.14 and installing 1.15 as it is required for the API

## 4. Expected behavior

training job should run without any errors as I'm using tf 1.15 which is required for the object detection API

## 5. Additional context

## 6. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):ubuntu 16
- Mobile device name if the issue happens on a mobile device:-
- TensorFlow installed from (source or binary):pip install
- TensorFlow version (use command below):('v1.15.0-rc3-22-g590d6ee', '1.15.0')
- Python version:2.7.12
- Bazel version (if compiling from source):-
- GCC/Compiler version (if compiling from source):gcc (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 
- CUDA/cuDNN version:
- GPU model and memory:
",sohartma,b'models:research type:bug',2020-05-26T13:19:15Z,2020-05-27T15:01:08Z,,,,,,,
8569,[DeepLab] ImageNet pre-trained checkpoints are missing variables,"## 1. The entire URL of the file you are using

https://github.com/tensorflow/models/blob/master/research/deeplab/train.py

## 2. Describe the bug

When trying to train from ImageNet pretrained weights, most (all?) variables are reported missing:
```
INFO:tensorflow:Initializing model from path: deeplab/download/xception/model.ckpt
I0525 10:58:58.676074 140291237205824 train_utils.py:207] Initializing model from path: deeplab/download/xception/model.ckpt
WARNING:tensorflow:Checkpoint is missing variable [image_pooling/weights]
W0525 10:59:00.488656 140291237205824 variables.py:676] Checkpoint is missing variable [image_pooling/weights]
WARNING:tensorflow:Checkpoint is missing variable [image_pooling/BatchNorm/gamma]
W0525 10:59:00.488829 140291237205824 variables.py:676] Checkpoint is missing variable [image_pooling/BatchNorm/gamma]
WARNING:tensorflow:Checkpoint is missing variable [image_pooling/BatchNorm/beta]
W0525 10:59:00.488880 140291237205824 variables.py:676] Checkpoint is missing variable [image_pooling/BatchNorm/beta]
WARNING:tensorflow:Checkpoint is missing variable [image_pooling/BatchNorm/moving_mean]
W0525 10:59:00.488926 140291237205824 variables.py:676] Checkpoint is missing variable [image_pooling/BatchNorm/moving_mean]
WARNING:tensorflow:Checkpoint is missing variable [image_pooling/BatchNorm/moving_variance]
W0525 10:59:00.488965 140291237205824 variables.py:676] Checkpoint is missing variable [image_pooling/BatchNorm/moving_variance]
WARNING:tensorflow:Checkpoint is missing variable [aspp0/weights]
....
```
## 3. Steps to reproduce
I'm running the following command:
```bash
 python deeplab/train.py --logtostderr --training_number_of_steps=30000 --train_split=""train_aug""     --model_variant=""xception_65"" --atrous_rates=6 --atrous_rates=12 --atrous_rates=18 --output_stride=16 --decoder_output_stride=4 --train_crop_size=""513,513"" --train_batch_size=16     --dataset=""pascal_voc_seg""     --tf_initial_checkpoint=deeplab/download/xception/model.ckpt    --train_logdir=train_deeplab     --dataset_dir=deeplab/datasets/pascal_voc_seg/tfrecord/     --fine_tune_batch_norm=True     --num_clones=2     --base_learning_rate=0.007
```
which is almost identical to the example provided in the docs.
The only things I have changed are the train_split (I added tf-records for the SBD dataset to create the ""train_aug"" split) and the base_learning_rate. The file in the tf_initial_checkpoint argument is the extracted model checkpoint from [here](http://download.tensorflow.org/models/deeplabv3_xception_2018_01_04.tar.gz)

If I change the model_variant to ResNet or another version of xception I run into the same issue.

## 4. Expected behavior

I expect the model to load the weights from the pre-trained ImageNet model.

## 5. Additional context

The full output log until training starts is:
```
/home/stammes/development/envs/tf-deeplabv3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([(""qint8"", np.int8, 1)])
/home/stammes/development/envs/tf-deeplabv3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([(""quint8"", np.uint8, 1)])
/home/stammes/development/envs/tf-deeplabv3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([(""qint16"", np.int16, 1)])
/home/stammes/development/envs/tf-deeplabv3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([(""quint16"", np.uint16, 1)])
/home/stammes/development/envs/tf-deeplabv3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([(""qint32"", np.int32, 1)])
/home/stammes/development/envs/tf-deeplabv3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([(""resource"", np.ubyte, 1)])
/home/stammes/development/envs/tf-deeplabv3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([(""qint8"", np.int8, 1)])
/home/stammes/development/envs/tf-deeplabv3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([(""quint8"", np.uint8, 1)])
/home/stammes/development/envs/tf-deeplabv3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([(""qint16"", np.int16, 1)])
/home/stammes/development/envs/tf-deeplabv3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([(""quint16"", np.uint16, 1)])
/home/stammes/development/envs/tf-deeplabv3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([(""qint32"", np.int32, 1)])
/home/stammes/development/envs/tf-deeplabv3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([(""resource"", np.ubyte, 1)])
WARNING:tensorflow:From /home/stammes/development/models/research/deeplab/core/conv2d_ws.py:40: The name tf.layers.Layer is deprecated. Please use tf.compat.v1.layers.Layer instead.

WARNING:tensorflow:From deeplab/train.py:464: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.

WARNING:tensorflow:From deeplab/train.py:274: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.

W0525 11:08:29.822635 140689338758976 deprecation_wrapper.py:119] From deeplab/train.py:274: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.

WARNING:tensorflow:From deeplab/train.py:274: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.

W0525 11:08:29.822928 140689338758976 deprecation_wrapper.py:119] From deeplab/train.py:274: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.

WARNING:tensorflow:From deeplab/train.py:289: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.

W0525 11:08:29.823206 140689338758976 deprecation_wrapper.py:119] From deeplab/train.py:289: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.

WARNING:tensorflow:From deeplab/train.py:290: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.

W0525 11:08:29.823446 140689338758976 deprecation_wrapper.py:119] From deeplab/train.py:290: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.

INFO:tensorflow:Training on train_aug set
I0525 11:08:29.823647 140689338758976 train.py:290] Training on train_aug set
WARNING:tensorflow:From deeplab/train.py:314: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.

W0525 11:08:29.825254 140689338758976 deprecation_wrapper.py:119] From deeplab/train.py:314: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.

WARNING:tensorflow:From /home/stammes/development/models/research/deeplab/datasets/data_generator.py:350: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.

W0525 11:08:29.831180 140689338758976 deprecation_wrapper.py:119] From /home/stammes/development/models/research/deeplab/datasets/data_generator.py:350: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.

WARNING:tensorflow:From /home/stammes/development/models/research/deeplab/datasets/data_generator.py:221: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.

W0525 11:08:29.857454 140689338758976 deprecation_wrapper.py:119] From /home/stammes/development/models/research/deeplab/datasets/data_generator.py:221: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.

WARNING:tensorflow:From /home/stammes/development/models/research/deeplab/datasets/data_generator.py:236: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

W0525 11:08:29.857678 140689338758976 deprecation_wrapper.py:119] From /home/stammes/development/models/research/deeplab/datasets/data_generator.py:236: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

2020-05-25 11:08:29.886698: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2020-05-25 11:08:30.100392: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: Tesla V100-SXM2-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:1a:00.0
2020-05-25 11:08:30.102558: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 1 with properties: 
name: Tesla V100-SXM2-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:1b:00.0
2020-05-25 11:08:30.104418: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2020-05-25 11:08:30.107183: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2020-05-25 11:08:30.109918: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2020-05-25 11:08:30.115403: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2020-05-25 11:08:30.119125: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2020-05-25 11:08:30.122577: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2020-05-25 11:08:30.132241: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2020-05-25 11:08:30.140754: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0, 1
WARNING:tensorflow:From /home/stammes/development/models/research/deeplab/core/preprocess_utils.py:351: The name tf.lin_space is deprecated. Please use tf.linspace instead.

W0525 11:08:30.168017 140689338758976 deprecation_wrapper.py:119] From /home/stammes/development/models/research/deeplab/core/preprocess_utils.py:351: The name tf.lin_space is deprecated. Please use tf.linspace instead.

WARNING:tensorflow:From /home/stammes/development/models/research/deeplab/core/preprocess_utils.py:352: The name tf.random_shuffle is deprecated. Please use tf.random.shuffle instead.

W0525 11:08:30.170604 140689338758976 deprecation_wrapper.py:119] From /home/stammes/development/models/research/deeplab/core/preprocess_utils.py:352: The name tf.random_shuffle is deprecated. Please use tf.random.shuffle instead.

WARNING:tensorflow:From /home/stammes/development/models/research/deeplab/core/preprocess_utils.py:377: The name tf.image.resize_bilinear is deprecated. Please use tf.compat.v1.image.resize_bilinear instead.

W0525 11:08:30.184353 140689338758976 deprecation_wrapper.py:119] From /home/stammes/development/models/research/deeplab/core/preprocess_utils.py:377: The name tf.image.resize_bilinear is deprecated. Please use tf.compat.v1.image.resize_bilinear instead.

WARNING:tensorflow:From /home/stammes/development/models/research/deeplab/core/preprocess_utils.py:314: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.

W0525 11:08:30.310308 140689338758976 deprecation_wrapper.py:119] From /home/stammes/development/models/research/deeplab/core/preprocess_utils.py:314: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.

WARNING:tensorflow:From /home/stammes/development/models/research/deeplab/datasets/data_generator.py:339: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.
W0525 11:08:30.395894 140689338758976 deprecation.py:323] From /home/stammes/development/models/research/deeplab/datasets/data_generator.py:339: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.
WARNING:tensorflow:From /home/stammes/development/models/research/deeplab/core/feature_extractor.py:490: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
W0525 11:08:30.411961 140689338758976 deprecation.py:323] From /home/stammes/development/models/research/deeplab/core/feature_extractor.py:490: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
WARNING:tensorflow:From /home/stammes/development/models/research/deeplab/utils/train_utils.py:158: The name tf.losses.add_loss is deprecated. Please use tf.compat.v1.losses.add_loss instead.

W0525 11:08:35.227229 140689338758976 deprecation_wrapper.py:119] From /home/stammes/development/models/research/deeplab/utils/train_utils.py:158: The name tf.losses.add_loss is deprecated. Please use tf.compat.v1.losses.add_loss instead.

WARNING:tensorflow:From deeplab/train.py:333: The name tf.summary.histogram is deprecated. Please use tf.compat.v1.summary.histogram instead.

W0525 11:08:37.335386 140689338758976 deprecation_wrapper.py:119] From deeplab/train.py:333: The name tf.summary.histogram is deprecated. Please use tf.compat.v1.summary.histogram instead.

WARNING:tensorflow:From deeplab/train.py:361: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.

W0525 11:08:37.994565 140689338758976 deprecation_wrapper.py:119] From deeplab/train.py:361: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.

INFO:tensorflow:Setting decay_steps to total training steps.
I0525 11:08:37.997147 140689338758976 train_utils.py:327] Setting decay_steps to total training steps.
WARNING:tensorflow:From /home/stammes/development/models/research/deeplab/utils/train_utils.py:337: The name tf.train.polynomial_decay is deprecated. Please use tf.compat.v1.train.polynomial_decay instead.

W0525 11:08:37.997281 140689338758976 deprecation_wrapper.py:119] From /home/stammes/development/models/research/deeplab/utils/train_utils.py:337: The name tf.train.polynomial_decay is deprecated. Please use tf.compat.v1.train.polynomial_decay instead.

WARNING:tensorflow:From /home/stammes/development/envs/tf-deeplabv3/lib/python3.7/site-packages/tensorflow/python/keras/optimizer_v2/learning_rate_schedule.py:409: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Deprecated in favor of operator or tf.math.divide.
W0525 11:08:38.000476 140689338758976 deprecation.py:323] From /home/stammes/development/envs/tf-deeplabv3/lib/python3.7/site-packages/tensorflow/python/keras/optimizer_v2/learning_rate_schedule.py:409: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Deprecated in favor of operator or tf.math.divide.
WARNING:tensorflow:From /home/stammes/development/models/research/deeplab/utils/train_utils.py:372: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
W0525 11:08:38.004090 140689338758976 deprecation.py:323] From /home/stammes/development/models/research/deeplab/utils/train_utils.py:372: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
WARNING:tensorflow:From deeplab/train.py:380: The name tf.train.MomentumOptimizer is deprecated. Please use tf.compat.v1.train.MomentumOptimizer instead.

W0525 11:08:38.005710 140689338758976 deprecation_wrapper.py:119] From deeplab/train.py:380: The name tf.train.MomentumOptimizer is deprecated. Please use tf.compat.v1.train.MomentumOptimizer instead.

WARNING:tensorflow:From deeplab/train.py:424: The name tf.summary.merge is deprecated. Please use tf.compat.v1.summary.merge instead.

W0525 11:08:43.557871 140689338758976 deprecation_wrapper.py:119] From deeplab/train.py:424: The name tf.summary.merge is deprecated. Please use tf.compat.v1.summary.merge instead.

INFO:tensorflow:Ignoring initialization; other checkpoint exists
I0525 11:08:43.580271 140689338758976 train_utils.py:204] Ignoring initialization; other checkpoint exists
WARNING:tensorflow:From /home/stammes/development/envs/tf-deeplabv3/lib/python3.7/site-packages/tensorflow/contrib/slim/python/slim/learning.py:742: Supervisor.__init__ (from tensorflow.python.training.supervisor) is deprecated and will be removed in a future version.
Instructions for updating:
Please switch to tf.train.MonitoredTrainingSession
W0525 11:08:44.982430 140689338758976 deprecation.py:323] From /home/stammes/development/envs/tf-deeplabv3/lib/python3.7/site-packages/tensorflow/contrib/slim/python/slim/learning.py:742: Supervisor.__init__ (from tensorflow.python.training.supervisor) is deprecated and will be removed in a future version.
Instructions for updating:
Please switch to tf.train.MonitoredTrainingSession
2020-05-25 11:08:45.925250: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2020-05-25 11:08:45.967727: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
2020-05-25 11:08:45.967964: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0xfe943a0 executing computations on platform Host. Devices:
2020-05-25 11:08:45.967992: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2020-05-25 11:08:46.248227: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: Tesla V100-SXM2-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:1a:00.0
2020-05-25 11:08:46.249768: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 1 with properties: 
name: Tesla V100-SXM2-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:1b:00.0
2020-05-25 11:08:46.249842: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2020-05-25 11:08:46.249857: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2020-05-25 11:08:46.249888: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2020-05-25 11:08:46.249901: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2020-05-25 11:08:46.249913: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2020-05-25 11:08:46.249925: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2020-05-25 11:08:46.249938: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2020-05-25 11:08:46.255653: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0, 1
2020-05-25 11:08:46.255709: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2020-05-25 11:08:46.259229: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-05-25 11:08:46.259243: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 1 
2020-05-25 11:08:46.259248: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N Y 
2020-05-25 11:08:46.259252: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 1:   Y N 
2020-05-25 11:08:46.265176: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 30583 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:1a:00.0, compute capability: 7.0)
2020-05-25 11:08:46.268464: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 30583 MB memory) -> physical GPU (device: 1, name: Tesla V100-SXM2-32GB, pci bus id: 0000:1b:00.0, compute capability: 7.0)
2020-05-25 11:08:46.270905: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0xdbd5460 executing computations on platform CUDA. Devices:
2020-05-25 11:08:46.270923: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2020-05-25 11:08:46.270928: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (1): Tesla V100-SXM2-32GB, Compute Capability 7.0
WARNING:tensorflow:From /home/stammes/development/envs/tf-deeplabv3/lib/python3.7/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to check for files with this prefix.
W0525 11:08:46.272718 140689338758976 deprecation.py:323] From /home/stammes/development/envs/tf-deeplabv3/lib/python3.7/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to check for files with this prefix.
INFO:tensorflow:Restoring parameters from train_deeplab_test_15/model.ckpt-0
I0525 11:08:46.273993 140689338758976 saver.py:1280] Restoring parameters from train_deeplab_test_15/model.ckpt-0
2020-05-25 11:08:48.614744: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
WARNING:tensorflow:From /home/stammes/development/envs/tf-deeplabv3/lib/python3.7/site-packages/tensorflow/python/training/saver.py:1066: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file utilities to get mtimes.
W0525 11:08:49.853774 140689338758976 deprecation.py:323] From /home/stammes/development/envs/tf-deeplabv3/lib/python3.7/site-packages/tensorflow/python/training/saver.py:1066: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file utilities to get mtimes.
INFO:tensorflow:Running local_init_op.
I0525 11:08:49.856222 140689338758976 session_manager.py:500] Running local_init_op.
INFO:tensorflow:Done running local_init_op.
I0525 11:08:50.772156 140689338758976 session_manager.py:502] Done running local_init_op.
INFO:tensorflow:Starting Session.
I0525 11:08:58.693684 140689338758976 learning.py:754] Starting Session.
INFO:tensorflow:Saving checkpoint to path train_deeplab_test_15/model.ckpt
I0525 11:08:59.046062 140684354885376 supervisor.py:1117] Saving checkpoint to path train_deeplab_test_15/model.ckpt
INFO:tensorflow:Starting Queues.
I0525 11:08:59.046199 140689338758976 learning.py:768] Starting Queues.
2020-05-25 11:09:08.968793: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
INFO:tensorflow:Recording summary at step 0.
I0525 11:09:13.616672 140683927086848 supervisor.py:1050] Recording summary at step 0.
INFO:tensorflow:global_step/sec: 0
I0525 11:09:16.224447 140683935479552 supervisor.py:1099] global_step/sec: 0
INFO:tensorflow:global step 10: loss = 2.7641 (1.359 sec/step)
I0525 11:09:32.953874 140689338758976 learning.py:507] global step 10: loss = 2.7641 (1.359 sec/step)
```

## 6. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- Mobile device name if the issue happens on a mobile device: n.a.
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 1.14
- Python version: 3.7.3
- Bazel version (if compiling from source): n.a.
- GCC/Compiler version (if compiling from source): n.a.
- CUDA/cuDNN version: CUDA 10.0/cuDNN 7
- GPU model and memory: 2x Tesla V100 32GB

<!-- 
Collect system information using our environment capture script.
https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can also obtain the TensorFlow version with:

1. TensorFlow 1.0
`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

2. TensorFlow 2.0
`python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`
-->
",ErikStammes,b'models:research type:bug',2020-05-25T09:13:21Z,2020-06-05T13:55:08Z,,,,,,,
8566,Cant export frozen inference graph ValueError: The passed save_path is not a valid checkpoint: training/model.ckpt-4347,"Whenever I try to export the frozen inference graph it produces an error ""ValueError: The passed save_path is not a valid checkpoint: training/model.ckpt-4347"" even though I am currently in object detection directory and there is a training folder which contains model.ckpt.4347

Logs

Traceback (most recent call last):
  File ""export_inference_graph.py"", line 162, in <module>
    tf.app.run()
  File ""C:\Users\Rahul\Anaconda3\envs\tf1.13.1\lib\site-packages\tensorflow\python\platform\app.py"", line 125, in run
    _sys.exit(main(argv))
  File ""export_inference_graph.py"", line 158, in main
    write_inference_graph=FLAGS.write_inference_graph)
  File ""D:\ExtraWork\models\research\object_detection\exporter.py"", line 489, in export_inference_graph
    write_inference_graph=write_inference_graph)
  File ""D:\ExtraWork\models\research\object_detection\exporter.py"", line 418, in _export_inference_graph
    trained_checkpoint_prefix=checkpoint_to_use)
  File ""D:\ExtraWork\models\research\object_detection\exporter.py"", line 327, in write_graph_and_checkpoint
    saver.restore(sess, trained_checkpoint_prefix)
  File ""C:\Users\Rahul\Anaconda3\envs\tf1.13.1\lib\site-packages\tensorflow\python\training\saver.py"", line 1268, in restore
    + compat.as_text(save_path))
ValueError: The passed save_path is not a valid checkpoint: training/model.ckpt-4347.


6. System information

- OS Platform :windows10
- TensorFlow version 1.13.1
- Python version 3.7
-Both my cuda and cudann are compatible with TensorFlow
- GPU model and memory: GTX 1050 4gb

![Screenshot (97)](https://user-images.githubusercontent.com/38246396/82751010-ea215480-9dd1-11ea-867e-ced490c6f5bf.png)

",bloodgreed99,b'models:research type:bug',2020-05-24T09:49:18Z,2020-05-24T09:52:18Z,,,,,,,
8564,"incompatible with both tensroflow v1 and v2, this project is absolutely unusable","I ran the code with tf 2 and it gave **tf.contrib** error. I searched the internet and found I should use version 1, and with version 1 it'll give **tf.python.tf2** error",aliamiri1380,b'models:research type:bug',2020-05-23T02:14:59Z,2020-05-28T05:03:13Z,,,,,,,
8560,No OpKernel was registered to support Op 'NcclAllReduce' used by ,"# Prerequisites

Please answer the following questions for yourself before submitting an issue.

- [x] I am using the latest TensorFlow Model Garden release and TensorFlow 2.2.0
- [ ] I am reporting the issue to the correct repository. (Model Garden official or research directory)
- [ ] I checked to make sure that this issue has not been filed already.

## 1. The entire URL of the file you are using

https://github.com/tensorflow/models/tree/master/official/nlp/transformer

## 2. Describe the bug

tensorflow.python.framework.errors_impl.InvalidArgumentError: No OpKernel was registered to support Op 'NcclAllReduce' used by {{node div_no_nan/NcclAllReduce}} with these attrs: [T=DT_FLOAT, num_devices=4, reduction=""sum"", shared_name=""c2""]
Registered devices: [CPU, XLA_CPU]

## 3. Steps to reproduce

!python3 transformer_main.py --data_dir=data --model_dir=model \
    --vocab_file=data/vocab.ende.32768 --param_set=big \
    --train_steps=100000 --steps_between_evals=5000 \
    --batch_size=4096 --max_length=64 \
    --bleu_source=data/newstest2014.en \
    --bleu_ref=data/newstest2014.de \
    --num_gpus=4\
    --enable_time_history=false

## 4. Expected behavior

A clear and concise description of what you expected to happen.

## 5. Additional context

Include any logs that would be helpful to diagnose the problem.

## 6. System information

- OS Platform and Distribution (centos 7.5):
- Mobile device name if the issue happens on a mobile device:
- TensorFlow installed from (source):
- TensorFlow version (2.2.0):
- Python version:3.6
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:10.2.0
- GPU model and memory: v100 *4    11G/per

<!-- 
Collect system information using our environment capture script.
https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can also obtain the TensorFlow version with:

2. TensorFlow 2.2.0
`python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`
-->
",paulrich1234,b'models:official type:bug',2020-05-22T02:50:43Z,2020-05-27T02:53:45Z,,,,,,,
8559,AttributeError: change_coordinate_frame ,"## The entire URL of the file you are using

https://github.com/tensorflow/models/tree/master/research/model_main.py

## Describe the bug

When running `model_main.py` after pulling the latest from master, I'm getting the error: `AttributeError: change_coordinate_frame` from `https://github.com/tensorflow/models/tree/master/research/model_lib.py`:

```
WARNING: Logging before flag parsing goes to stderr.
W0522 01:48:09.645347 140098740733760 deprecation_wrapper.py:119] From /tf/models/research/object_detection/model_main.py:111: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.

W0522 01:48:09.647595 140098740733760 deprecation_wrapper.py:119] From /tf/models/research/object_detection/utils/config_util.py:137: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.

W0522 01:48:09.653165 140098740733760 deprecation_wrapper.py:119] From /tf/models/research/object_detection/model_lib.py:685: The name tf.logging.warning is deprecated. Please use tf.compat.v1.logging.warning instead.

W0522 01:48:09.653301 140098740733760 model_lib.py:686] Forced number of epochs for all eval validations to be 1.
W0522 01:48:09.653435 140098740733760 deprecation_wrapper.py:119] From /tf/models/research/object_detection/utils/config_util.py:523: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.

I0522 01:48:09.653532 140098740733760 config_util.py:523] Maybe overwriting train_steps: None
I0522 01:48:09.653616 140098740733760 config_util.py:523] Maybe overwriting use_bfloat16: False
I0522 01:48:09.653701 140098740733760 config_util.py:523] Maybe overwriting sample_1_of_n_eval_examples: 1
I0522 01:48:09.653797 140098740733760 config_util.py:523] Maybe overwriting eval_num_epochs: 1
I0522 01:48:09.653898 140098740733760 config_util.py:523] Maybe overwriting load_pretrained: True
I0522 01:48:09.653985 140098740733760 config_util.py:533] Ignoring config override key: load_pretrained
W0522 01:48:09.654740 140098740733760 model_lib.py:702] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.
I0522 01:48:09.654871 140098740733760 model_lib.py:737] create_estimator_and_inputs: use_tpu False, export_to_tpu False
I0522 01:48:09.655415 140098740733760 estimator.py:209] Using config: {'_model_dir': 'v2_fpn-dwise_BOX_AR1.0__AUG_0.15-1.0//train', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true
graph_options {
  rewrite_options {
    meta_optimizer_iterations: ONE
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f6b10801f60>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0522 01:48:09.655672 140098740733760 model_fn.py:630] Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7f6b0de8d488>) includes params argument, but params are not passed to Estimator.
I0522 01:48:09.656445 140098740733760 estimator_training.py:186] Not using Distribute Coordinator.
I0522 01:48:09.656667 140098740733760 training.py:612] Running training and evaluation locally (non-distributed).
I0522 01:48:09.656970 140098740733760 training.py:700] Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.
W0522 01:48:09.668902 140098740733760 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
Traceback (most recent call last):
  File ""/tf/models/research/object_detection/model_main.py"", line 111, in <module>
    tf.app.run()
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 300, in run
    _run_main(main, args)
  File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 251, in _run_main
    sys.exit(main(argv))
  File ""/tf/models/research/object_detection/model_main.py"", line 107, in main
    tf.estimator.train_and_evaluate(estimator, train_spec, eval_specs[0])
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py"", line 473, in train_and_evaluate
    return executor.run()
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py"", line 613, in run
    return self.run_local()
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py"", line 714, in run_local
    saving_listeners=saving_listeners)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 367, in train
    loss = self._train_model(input_fn, hooks, saving_listeners)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1158, in _train_model
    return self._train_model_default(input_fn, hooks, saving_listeners)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1185, in _train_model_default
    input_fn, ModeKeys.TRAIN))
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1022, in _get_features_and_labels_from_input_fn
    self._call_input_fn(input_fn, mode))
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1113, in _call_input_fn
    return input_fn(**kwargs)
  File ""/tf/models/research/object_detection/inputs.py"", line 645, in _train_input_fn
    params=params)
  File ""/tf/models/research/object_detection/inputs.py"", line 720, in train_input
    model_config, is_training=True).preprocess
  File ""/tf/models/research/object_detection/builders/model_builder.py"", line 905, in build
    add_summaries)
  File ""/tf/models/research/object_detection/builders/model_builder.py"", line 340, in _build_ssd_model
    ssd_config.post_processing)
  File ""/tf/models/research/object_detection/builders/post_processing_builder.py"", line 59, in build
    post_processing_config.batch_non_max_suppression)
  File ""/tf/models/research/object_detection/builders/post_processing_builder.py"", line 105, in _build_non_max_suppressor
    change_coordinate_frame=nms_config.change_coordinate_frame)
AttributeError: change_coordinate_frame
```

## Steps to reproduce

`python models/tree/master/research/model_main.py`

## System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 1.14
- Python version: 3.6.8",alexdwu13,b'models:research type:bug',2020-05-22T02:06:08Z,2020-05-22T22:52:36Z,,,,,,,
8542,bugfix: unused and incorrect variable name,"# Description
there is a bug that assigns test data files to `train_files` variable. Also, currently, test data are downloaded only (unprocessed and unused), so there is no need for a variable to keep track of those files.

## Type of change

- [x] Bug fix (non-breaking change which fixes an issue)

## Checklist

- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).
- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).
- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).
- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.
- [x] I have commented my code, particularly in hard-to-understand areas.
- [x] I have made corresponding changes to the documentation.
- [x] My changes generate no new warnings.
- [x] I have added tests that prove my fix is effective or that my feature works.
",howl-anderson,b'cla: yes ready to pull',2020-05-20T07:53:15Z,2020-05-25T06:50:03Z,,,,,,,
8537,Model failed to serialize as JSON. Ignoring... Layer MetricLayer has arguments in `__init__` and therefore must override `get_config`.,"# Prerequisites

Please answer the following questions for yourself before submitting an issue.

- [Y ] I am using the latest TensorFlow Model Garden release and TensorFlow 2.
- [Y ] I am reporting the issue to the correct repository. (Model Garden official or research directory)
- [ Y] I checked to make sure that this issue has not been filed already.

## 1. The entire URL of the file you are using

https://github.com/tensorflow/models/blob/master/official/recommendation/ncf_keras_main.py

## 2. Describe the bug

Running ncf_keras_main.py gives an output with warning:
summary_ops_v2.py:1139] Model failed to serialize as JSON. Ignoring... Layer MetricLayer has arguments in `__init__` and therefore must override `get_config`.

## 3. Steps to reproduce

python ncf_keras_main.py --model_dir=""..."" --data_dir=""...""

## 4. Expected behavior

No warning. What could I do in order to save model and test with tensorflow.js?

## 5. Additional context

Include any logs that would be helpful to diagnose the problem.

## 6. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): CentOS 7
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): v2.2.0-rc4-8-g2b96f3662b 2.2.0
- Python version: 3.6.8
",n0ego,b'models:official stalled stat:awaiting response type:bug',2020-05-19T18:04:36Z,2020-09-18T18:17:54Z,,,,,,,
8532,i think it is because the eval process the source language and it concat target language output errors .,"# Prerequisites

Please answer the following questions for yourself before submitting an issue.

- [1 ] I am using the latest TensorFlow Model Garden release and TensorFlow 2.2.0
- [ 2] I am reporting the issue to the correct repository. (Model Garden official or research directory)
- [ 3] I checked to make sure that this issue has not been filed already.

## 1. The entire URL of the file you are using

https://github.com/tensorflow/models/tree/master/official/nlp/transformer

## 2. Describe the bug
i use the follow command to run the translation ,
 it training is ok ,and during training it eval a newstest2014.en file and it cannot concat the eval translation results and errors as following 

 
!python3 transformer_main.py --data_dir=data_v2 \
    --model_dir=model\
    --vocab_file=data_v2/vocab.ende.32768 \
    --param_set=big \
    --train_steps=100000 \
    --steps_between_evals=5000\
    --batch_size=4096 --max_length=64 \
    --bleu_source=data_v2/newstest2014.en \
    --bleu_ref=data_v2/newstest2014.de \
    --num_gpus=4 \
    --enable_time_history=False



64/64 [==============================] - 432s 7s/step
Traceback (most recent call last):
  File ""transformer_main.py"", line 510, in <module>
    app.run(main)
  File ""/home/dell/anaconda3/envs/tf2.2/lib/python3.6/site-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/home/dell/anaconda3/envs/tf2.2/lib/python3.6/site-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""transformer_main.py"", line 498, in main
    task.train()
  File ""transformer_main.py"", line 371, in train
    uncased_score, cased_score = self.eval()
  File ""transformer_main.py"", line 404, in eval
    distribution_strategy)
  File ""transformer_main.py"", line 122, in evaluate_and_log_bleu
    model, params, subtokenizer, bleu_source, bleu_ref, distribution_strategy)
  File ""transformer_main.py"", line 89, in translate_and_compute_bleu
    distribution_strategy=distribution_strategy)
  File ""/home/dell/workspace/cps_seq/models-master_origin_20200427/official/nlp/transformer/translate.py"", line 174, in translate_file
    val_outputs, _ = model.predict(text,verbose=1)
  File ""/home/dell/anaconda3/envs/tf2.2/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py"", line 94, in _method_wrapper
    return method(self, *args, **kwargs)
  File ""/home/dell/anaconda3/envs/tf2.2/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py"", line 1396, in predict
    all_outputs = nest.map_structure_up_to(batch_outputs, concat, outputs)
  File ""/home/dell/anaconda3/envs/tf2.2/lib/python3.6/site-packages/tensorflow/python/util/nest.py"", line 1131, in map_structure_up_to
    **kwargs)
  File ""/home/dell/anaconda3/envs/tf2.2/lib/python3.6/site-packages/tensorflow/python/util/nest.py"", line 1227, in map_structure_with_tuple_paths_up_to
    *flat_value_lists)]
  File ""/home/dell/anaconda3/envs/tf2.2/lib/python3.6/site-packages/tensorflow/python/util/nest.py"", line 1226, in <listcomp>
    results = [func(*args, **kwargs) for args in zip(flat_path_list,
  File ""/home/dell/anaconda3/envs/tf2.2/lib/python3.6/site-packages/tensorflow/python/util/nest.py"", line 1129, in <lambda>
    lambda _, *values: func(*values),  # Discards the path arg.
  File ""/home/dell/anaconda3/envs/tf2.2/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py"", line 1884, in concat
    return array_ops.concat(tensors, axis=axis)
  File ""/home/dell/anaconda3/envs/tf2.2/lib/python3.6/site-packages/tensorflow/python/util/dispatch.py"", line 180, in wrapper
    return target(*args, **kwargs)
  File ""/home/dell/anaconda3/envs/tf2.2/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py"", line 1630, in concat
    return gen_array_ops.concat_v2(values=values, axis=axis, name=name)
  File ""/home/dell/anaconda3/envs/tf2.2/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py"", line 1198, in concat_v2
    _ops.raise_from_not_ok_status(e, name)
  File ""/home/dell/anaconda3/envs/tf2.2/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 6816, in raise_from_not_ok_status
    six.raise_from(core._status_to_exception(e.code, message), None)
  File ""<string>"", line 3, in raise_from
tensorflow.python.framework.errors_impl.InvalidArgumentError: ConcatOp : Dimensions of inputs should match: shape[0] = [32,178] vs. shape[1] = [32,175] [Op:ConcatV2] name: concat

## 3. Steps to reproduce

!python3 transformer_main.py --data_dir=data_v2 \
    --model_dir=model\
    --vocab_file=data_v2/vocab.ende.32768 \
    --param_set=big \
    --train_steps=100000 \
    --steps_between_evals=5000\
    --batch_size=4096 --max_length=64 \
    --bleu_source=data_v2/newstest2014.en \
    --bleu_ref=data_v2/newstest2014.de \
    --num_gpus=4 \
    --enable_time_history=False

## 4. Expected behavior

when training ,it eval the translation file ,but it's eval process outputs concats errors 

## 5. Additional context

i think it is because the eval process the source language and it concat target language batch results shape doesnt match errors
but i donot know how to fix it .

## 6. System information

- Linux Ubuntu 16.04):
- TensorFlow installed from source 
- TensorFlow version 2.2.0:
- Python version:3.6
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:10.2.1
- GPU model and memory: 2080TI  *4   

<!-- 
Collect system information using our environment capture script.
https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can also obtain the TensorFlow version with:

1. TensorFlow 1.0
`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

2. TensorFlow 2.0
`python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`
-->
",paulrich1234,b'models:official type:bug',2020-05-19T03:11:29Z,2020-05-22T07:43:28Z,,,,,,,
8529,Evaluation/Fine-tuning of Resnet 50 in TF 2.X,"# Prerequisites

Please answer the following questions for yourself before submitting an issue.

- [x] I am using the latest TensorFlow Model Garden release and TensorFlow 2.
- [x] I am reporting the issue to the correct repository. (Model Garden official or research directory)
- [x] I checked to make sure that this issue has not been filed already.

## 1. The entire URL of the file you are using

https://github.com/tensorflow/models/tree/master/official/vision/image_classification/resnet
For pretrained checkpoints, I used the ones linked in the README (https://github.com/tensorflow/models/tree/master/official/vision/image_classification/resnet#pretrained-models)

## 2. Describe the bug

1) I'm trying to evaluate and finetune the Resnet 50 model available at the URL(mentioned above). However I get near zero accuracy when I evaluate. I would like to know how to evaluate and finetune using the existing RN50 checkpoint. 

The command I use for evaluating the existing model 
`python3 resnet_ctl_imagenet_main.py --model_dir=checkpoints/ --num_gpus=1 --batch_size=32 --train_epochs=1 --train_steps=1 --use_synthetic_data=false --data_dir imagenet_tfr_data/ `

The `model_dir` is set to checkpoints directory which has the downloaded checkpoint (from the README link). The checkpoint manager picks up this checkpoint, however does not seem to load as I get many unresolved object issues where the layer names mismatch.

> W0518 15:35:57.377599 139869265008448 util.py:144] Unresolved object in checkpoint: (root).layer_with_weights-4.kernel
WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-5.axis


2) Currently I seem to get this resnet model running for Tensorflow 2.2. There were multiple errors for 2.0 and 2.1. One such error is `from tensorflow.python.keras.layers.preprocessing import image_preprocessing as image_ops. ImportError: cannot import name 'image_preprocessing'`
This may not be relevant to the actual issue but for me TF 2,0 and TF 2.1 seem to give import and not found attribute errors which drove me to try TF 2.2.

3) Evaluation works when I do the following

In the resnet_runnable.py, I use keras way of loading the checkpoint
`self.model.load_weights(flags_obj.pretrained_filepath)`

This probably loads the checkpoint according to network topology rather than names (used by tf.train.CheckpointManager. (Is this correct way of loading ? ) 
I disable training manually and run the `self._evaluate_once(current_step)` to get `76.476`. Just wanted to confirm if this is same accuracy that you obtained? 

The questions are

* Is there a plan to add standalone eval script to this repo ? 
* If the way of evaluation described in 3) is recommended, can it be added to the repo as well as update the documentation as well on eval/finetuning steps? 
I would be happy to make some PR if required :)

Thank you !!
",peri044,b'models:official type:bug',2020-05-18T22:40:50Z,2020-05-18T22:45:24Z,,,,,,,
8491,I am facing the same error while doing transfer learning on retinenet,"<!--
Please make sure that this is a bug. 

As per our GitHub Policy (https://github.com/tensorflow/models/blob/master/ISSUES.md), we only address code bugs, documentation issues, and feature requests on GitHub.

Please go to Stack Overflow (http://stackoverflow.com/questions/tagged/tensorflow-model-garden) for help and support.

The research models (https://github.com/tensorflow/models/tree/master/research) are a large collection of models implemented in TensorFlow by researchers. They are not officially supported. It is up to the individual researchers to maintain the models and/or provide support on issues and pull requests.
-->

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g., Pixel 4, Samsung Galaxy 10) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below):
- Python version:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

<!-- 
You can collect some of this information using our environment capture (https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 

1. TensorFlow 1.0
`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 

2. TensorFlow 2.0
`python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`
-->

**Please provide the entire URL of the model you are using?**
<!-- (e.g., https://github.com/tensorflow/models/tree/master/official/nlp/bert) -->

**Describe the current behavior**

**Describe the expected behavior**

**Code to reproduce the issue**
<!-- Provide a reproducible test case that is the bare minimum necessary to generate the problem. -->

**Other info / logs**
<!-- Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. -->
",bundelesneha05,b'models:research type:bug',2020-05-11T22:00:37Z,2020-06-05T07:21:04Z,,,,,,,
8488,tensorflow.python.framework.errors_impl.FailedPreconditionError: 2 root error(s) found.   (0) Failed precondition:  data/training; Is a directory,"running     on tensorflow-gpu=2.2.0  

!python3 transformer_main.py --data_dir=data \
    --model_dir=model\
    --vocab_file=data/vocab.ende.32768 \
    --param_set=big \
    --train_steps=100000 \
    --steps_between_evals=5000\
    --batch_size=4096 --max_length=64 \
    --bleu_source=data/newstest2014.en \
    --bleu_ref=data/newstest2014.de \
    --num_gpus=2 \
    --enable_time_history=false



the following error occors

INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')
I0511 16:00:08.782238 140326923654976 mirrored_strategy.py:341] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')
I0511 16:00:08.783418 140326923654976 transformer_main.py:186] Running transformer with num_gpus = 2
I0511 16:00:08.784826 140326923654976 transformer_main.py:190] For training, using distribution strategy: <tensorflow.python.distribute.mirrored_strategy.MirroredStrategy object at 0x7fa0207a48d0>
Model: ""model""

Total params: 210,804,736
Trainable params: 210,804,736
Non-trainable params: 0
__________________________________________________________________________________________________
I0511 16:00:16.170870 140326923654976 transformer_main.py:312] Start train iteration at global step:0
INFO:tensorflow:batch_all_reduce: 185 all-reduces with algorithm = nccl, num_packs = 1
I0511 16:00:23.557520 140326923654976 cross_device_ops.py:697] batch_all_reduce: 185 all-reduces with algorithm = nccl, num_packs = 1
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
I0511 16:00:26.764555 140326923654976 cross_device_ops.py:439] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
I0511 16:00:26.767467 140326923654976 cross_device_ops.py:439] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:batch_all_reduce: 185 all-reduces with algorithm = nccl, num_packs = 1
I0511 16:00:36.671541 140326923654976 cross_device_ops.py:697] batch_all_reduce: 185 all-reduces with algorithm = nccl, num_packs = 1
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
I0511 16:00:38.748556 140326923654976 cross_device_ops.py:439] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
I0511 16:00:38.750910 140326923654976 cross_device_ops.py:439] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
Traceback (most recent call last):
  File ""transformer_main.py"", line 509, in <module>
    app.run(main)
  File ""/home/dell/anaconda3/envs/tf2.2/lib/python3.6/site-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/home/dell/anaconda3/envs/tf2.2/lib/python3.6/site-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""transformer_main.py"", line 497, in main
    task.train()
  File ""transformer_main.py"", line 364, in train
    verbose=(2 if flags_obj.enable_time_history else 1))
  File ""/home/dell/anaconda3/envs/tf2.2/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py"", line 72, in _method_wrapper
    return method(self, *args, **kwargs)
  File ""/home/dell/anaconda3/envs/tf2.2/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py"", line 907, in fit
    tmp_logs = train_function(iterator)
  File ""/home/dell/anaconda3/envs/tf2.2/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py"", line 766, in __call__
    result = self._call(*args, **kwds)
  File ""/home/dell/anaconda3/envs/tf2.2/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py"", line 826, in _call
    return self._stateless_fn(*args, **kwds)
  File ""/home/dell/anaconda3/envs/tf2.2/lib/python3.6/site-packages/tensorflow/python/eager/function.py"", line 2812, in __call__
    return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access
  File ""/home/dell/anaconda3/envs/tf2.2/lib/python3.6/site-packages/tensorflow/python/eager/function.py"", line 1838, in _filtered_call
    cancellation_manager=cancellation_manager)
  File ""/home/dell/anaconda3/envs/tf2.2/lib/python3.6/site-packages/tensorflow/python/eager/function.py"", line 1915, in _call_flat
    ctx, args, cancellation_manager=cancellation_manager))
  File ""/home/dell/anaconda3/envs/tf2.2/lib/python3.6/site-packages/tensorflow/python/eager/function.py"", line 549, in call
    ctx=ctx)
  File ""/home/dell/anaconda3/envs/tf2.2/lib/python3.6/site-packages/tensorflow/python/eager/execute.py"", line 60, in quick_execute
    inputs, attrs, num_outputs)
tensorflow.python.framework.errors_impl.FailedPreconditionError: 2 root error(s) found.
  (0) Failed precondition:  data/training; Is a directory
	 [[{{node MultiDeviceIteratorGetNextFromShard}}]]
	 [[RemoteCall]]
	 [[IteratorGetNextAsOptional_1]]
  (1) Cancelled:  Function was cancelled before it was started
0 successful operations.
1 derived errors ignored. [Op:__inference_train_function_45467]

Function call stack:
train_function -> train_function",paulrich1234,b'models:official type:bug',2020-05-11T08:03:48Z,2020-05-11T08:28:36Z,,,,,,,
8475,Using YAMNet  in android,"<!--
Please make sure that this is a bug. 

As per our GitHub Policy (https://github.com/tensorflow/models/blob/master/ISSUES.md), we only address code bugs, documentation issues, and feature requests on GitHub.

Please go to Stack Overflow (http://stackoverflow.com/questions/tagged/tensorflow-model-garden) for help and support.

The research models (https://github.com/tensorflow/models/tree/master/research) are a large collection of models implemented in TensorFlow by researchers. They are not officially supported. It is up to the individual researchers to maintain the models and/or provide support on issues and pull requests.
-->

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
N/A
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
N/A
- Mobile device (e.g., Pixel 4, Samsung Galaxy 10) if the issue happens on mobile device:
Android 9
- TensorFlow installed from (source or binary):
source 
- TensorFlow version (use command below):
1.13.1
- Python version:
3.6
- Bazel version (if compiling from source):
0.19.1
- GCC/Compiler version (if compiling from source):
N/A
- CUDA/cuDNN version:
N/A
- GPU model and memory:
N/A
- NDK:
r18b

<!-- 
You can collect some of this information using our environment capture (https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 

1. TensorFlow 1.0
`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 

2. TensorFlow 2.0
`python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`
-->

**Please provide the entire URL of the model you are using?**
<!-- (e.g., https://github.com/tensorflow/models/tree/master/official/nlp/bert) -->
https://github.com/tensorflow/models/tree/master/research/audioset/yamnet
**Describe the current behavior**
I'm using YAMNet in android, I compiled Tensorflow 1.13 from source in Ubuntu 16.04 for android platform, so I can use native c++ to do inference in android. But now I get no output of YAMNet. 
This is the logcat in android studio, seems the 'RFFT' op is not supported?
```
D/Mudra: Graph /data/user/0/com.example.sd/cache/yamnet.pb read successfully! 
I/Mudra: Create TensorFlow Session: Invalid argument: No OpKernel was registered to support Op 'RFFT' used by {{node log_mel_features/stft/rfft}}with these attrs: []
    Registered devices: [CPU]
    Registered kernels:
      <no registered kernels>
    
    	 [[{{node log_mel_features/stft/rfft}}]]
```
**Describe the expected behavior**
I test the pb model in windows, tensorflow 1.14, it works fine.
**Code to reproduce the issue**
<!-- Provide a reproducible test case that is the bare minimum necessary to generate the problem. -->
N/A
**Other info / logs**
<!-- Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. -->
N/A",paleomoon,b'models:research type:bug',2020-05-07T07:39:13Z,2020-05-07T10:45:21Z,,,,,,,
8474,model_main.py: Windows fatal exception: (No any Valid information),"<!--
Please make sure that this is a bug. 

As per our GitHub Policy (https://github.com/tensorflow/models/blob/master/ISSUES.md), we only address code bugs, documentation issues, and feature requests on GitHub.

Please go to Stack Overflow (http://stackoverflow.com/questions/tagged/tensorflow-model-garden) for help and support.
-->

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Windows 10 1941.207
- Mobile device (e.g., Pixel 4, Samsung Galaxy 10) if the issue happens on mobile device:
no
- TensorFlow installed from (source or binary):
pip
- TensorFlow version (use command below):
-gpu(1.13.1,1.14,1.15)
- Python version:
3.7.7
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
CUDA:10.0 cuDNN:7.6.5.32
- GPU model and memory:
RTX 2080
<!-- 
You can collect some of this information using our environment capture (https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 

1. TensorFlow 1.0
`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 

2. TensorFlow 2.0
`python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`
-->

**Please provide the entire URL of the model you are using?**
<!-- (e.g., https://github.com/tensorflow/models/tree/master/official/nlp/bert) -->

**Describe the current behavior**
Training model
**Describe the expected behavior**
Training sucessful
**Code to reproduce the issue**
<!-- Provide a reproducible test case that is the bare minimum necessary to generate the problem. -->

**Other info / logs**
<!-- Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. -->

tensorflow: I try 1.13-1.15 all is don't work.



Command: python model_main.py --alsologtostderr --model_dir=training/ --pipeline_config_path=training/ssd_inception_v2_coco.config

complite running log:


`WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:From C:\Users\16668\source\repos\Arknights-Auto\TensorFlowObjectDetectionAPI\TensorFlow\models\research\slim\nets\inception_resnet_v2.py:373: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.

WARNING:tensorflow:From C:\Users\16668\source\repos\Arknights-Auto\TensorFlowObjectDetectionAPI\TensorFlow\models\research\slim\nets\mobilenet\mobilenet.py:389: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.

WARNING:tensorflow:From model_main.py:109: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.

WARNING:tensorflow:From C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python37_64\lib\site-packages\object_detection\utils\config_util.py:94: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.

W0507 00:49:51.139271  8860 module_wrapper.py:139] From C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python37_64\lib\site-packages\object_detection\utils\config_util.py:94: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.

WARNING:tensorflow:From C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python37_64\lib\site-packages\object_detection\model_lib.py:573: The name tf.logging.warning is deprecated. Please use tf.compat.v1.logging.warning instead.

W0507 00:49:51.143266  8860 module_wrapper.py:139] From C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python37_64\lib\site-packages\object_detection\model_lib.py:573: The name tf.logging.warning is deprecated. Please use tf.compat.v1.logging.warning instead.

WARNING:tensorflow:Forced number of epochs for all eval validations to be 1.
W0507 00:49:51.144263  8860 model_lib.py:574] Forced number of epochs for all eval validations to be 1.
WARNING:tensorflow:From C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python37_64\lib\site-packages\object_detection\utils\config_util.py:480: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.

W0507 00:49:51.144263  8860 module_wrapper.py:139] From C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python37_64\lib\site-packages\object_detection\utils\config_util.py:480: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.

INFO:tensorflow:Maybe overwriting train_steps: None
I0507 00:49:51.145691  8860 config_util.py:480] Maybe overwriting train_steps: None
INFO:tensorflow:Maybe overwriting sample_1_of_n_eval_examples: 1
I0507 00:49:51.145691  8860 config_util.py:480] Maybe overwriting sample_1_of_n_eval_examples: 1
INFO:tensorflow:Maybe overwriting eval_num_epochs: 1
I0507 00:49:51.146691  8860 config_util.py:480] Maybe overwriting eval_num_epochs: 1
INFO:tensorflow:Maybe overwriting load_pretrained: True
I0507 00:49:51.146691  8860 config_util.py:480] Maybe overwriting load_pretrained: True
INFO:tensorflow:Ignoring config override key: load_pretrained
I0507 00:49:51.146691  8860 config_util.py:490] Ignoring config override key: load_pretrained
WARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.
W0507 00:49:51.147687  8860 model_lib.py:590] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.
INFO:tensorflow:create_estimator_and_inputs: use_tpu False, export_to_tpu False
I0507 00:49:51.147687  8860 model_lib.py:623] create_estimator_and_inputs: use_tpu False, export_to_tpu False
INFO:tensorflow:Using config: {'_model_dir': 'training/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true
graph_options {
  rewrite_options {
    meta_optimizer_iterations: ONE
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000002115590BE08>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0507 00:49:51.148684  8860 estimator.py:212] Using config: {'_model_dir': 'training/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true
graph_options {
  rewrite_options {
    meta_optimizer_iterations: ONE
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000002115590BE08>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
WARNING:tensorflow:Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x000002115590D708>) includes params argument, but params are not passed to Estimator.
W0507 00:49:51.150257  8860 model_fn.py:630] Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x000002115590D708>) includes params argument, but params are not passed to Estimator.
INFO:tensorflow:Not using Distribute Coordinator.
I0507 00:49:51.151252  8860 estimator_training.py:186] Not using Distribute Coordinator.
INFO:tensorflow:Running training and evaluation locally (non-distributed).
I0507 00:49:51.151252  8860 training.py:612] Running training and evaluation locally (non-distributed).
INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.
I0507 00:49:51.151252  8860 training.py:700] Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.
WARNING:tensorflow:From C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python37_64\lib\site-packages\tensorflow_core\python\training\training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0507 00:49:51.157238  8860 deprecation.py:323] From C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python37_64\lib\site-packages\tensorflow_core\python\training\training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
Windows fatal exception: access violation

Current thread 0x0000229c (most recent call first):
  File ""C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python37_64\lib\site-packages\tensorflow_core\python\lib\io\file_io.py"", line 84 in _preread_check
  File ""C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python37_64\lib\site-packages\tensorflow_core\python\lib\io\file_io.py"", line 122 in read
  File ""C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python37_64\lib\site-packages\object_detection\utils\label_map_util.py"", line 133 in load_labelmap
  File ""C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python37_64\lib\site-packages\object_detection\utils\label_map_util.py"", line 164 in get_label_map_dict
  File ""C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python37_64\lib\site-packages\object_detection\data_decoders\tf_example_decoder.py"", line 59 in __init__
  File ""C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python37_64\lib\site-packages\object_detection\data_decoders\tf_example_decoder.py"", line 297 in __init__
  File ""C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python37_64\lib\site-packages\object_detection\builders\dataset_builder.py"", line 123 in build
  File ""C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python37_64\lib\site-packages\object_detection\inputs.py"", line 488 in _train_input_fn
  File ""C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python37_64\lib\site-packages\tensorflow_estimator\python\estimator\estimator.py"", line 1116 in _call_input_fn
  File ""C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python37_64\lib\site-packages\tensorflow_estimator\python\estimator\estimator.py"", line 1025 in _get_features_and_labels_from_input_fn
  File ""C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python37_64\lib\site-packages\tensorflow_estimator\python\estimator\estimator.py"", line 1188 in _train_model_default
  File ""C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python37_64\lib\site-packages\tensorflow_estimator\python\estimator\estimator.py"", line 1161 in _train_model
  File ""C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python37_64\lib\site-packages\tensorflow_estimator\python\estimator\estimator.py"", line 370 in train
  File ""C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python37_64\lib\site-packages\tensorflow_estimator\python\estimator\training.py"", line 714 in run_local
  File ""C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python37_64\lib\site-packages\tensorflow_estimator\python\estimator\training.py"", line 613 in run
  File ""C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python37_64\lib\site-packages\tensorflow_estimator\python\estimator\training.py"", line 473 in train_and_evaluate
  File ""model_main.py"", line 105 in main
  File ""C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python37_64\lib\site-packages\absl\app.py"", line 250 in _run_main
  File ""C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python37_64\lib\site-packages\absl\app.py"", line 299 in run
  File ""C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python37_64\lib\site-packages\tensorflow_core\python\platform\app.py"", line 40 in run
  File ""model_main.py"", line 109 in <module>`

",JiXiaoYao,b'models:research type:bug',2020-05-07T04:56:20Z,2020-08-18T08:40:26Z,,,,,,,
8457,TPU distribution strategy fail: NodeDef expected inputs 'string' do not match 0 inputs specified,"I'm trying to initialize a TPU distribution strategy and I have the following error:

```
tensorflow.python.framework.errors_impl.InvalidArgumentError: NodeDef expected inputs 'string' do not match 0 inputs specified; Op<name=_Send; signature=tensor:T -> ; attr=T:type; attr=tensor_name:string; 
attr=send_device:string; attr=send_device_incarnation:int; attr=recv_device:string; attr=client_terminated:bool,default=false; is_stateful=true>; NodeDef: {{node _Send}}
```

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): `Yes`
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): `Debian 10`
- TensorFlow installed from (source or binary): `binary (pip3)`
- TensorFlow version (use command below): `2.2.0-dev20200501`
- Python version: `Python 3.7.3`
- CUDA/cuDNN version: `none (GCP TPU)`
- GPU model and memory: `none (GCP TPU)`

**Code to reproduce the issue**

`tpu_strategy.py`

```python
# -*- coding: utf-8 -*-
import os

from official.utils.misc import distribution_utils

tpu_name=os.getenv('TPU_NAME')

strategy = distribution_utils.get_distribution_strategy(
    distribution_strategy=""tpu"",
    tpu_address=tpu_name)

strategy_scope = distribution_utils.get_strategy_scope(strategy)
```

**How to run this code**

Follow the guide to run a TPU vm: https://cloud.google.com/tpu/docs/quickstart)

Then when you have a shell session on it, execute the following commands instead of running the MNIST example:
 
```bash
$ pip3 install tf-models-nightly
$ TPU_NAME=tpu-quickstart python3 tpu_strategy.py
```

**Other info / logs**

<details><summary>Complete log + stacktrace</summary>

```
2020-05-02 06:30:09.091314: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: N
o such file or directory
2020-05-02 06:30:09.091362: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
Get strategy tpu
on TPU ichimia
2020-05-02 06:30:10.718866: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such fil
e or directory
2020-05-02 06:30:10.718920: E tensorflow/stream_executor/cuda/cuda_driver.cc:313] failed call to cuInit: UNKNOWN ERROR (303)
2020-05-02 06:30:10.718950: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ichimia): /proc/driver/nvidia/version does not exist
2020-05-02 06:30:10.886804: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance-critical oper
ations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-05-02 06:30:10.894306: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 2300000000 Hz
2020-05-02 06:30:10.894601: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5a05920 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-05-02 06:30:10.894631: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-05-02 06:30:10.903492: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job worker -> {0 -> 10.240.1.2:8470}
2020-05-02 06:30:10.903537: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job localhost -> {0 -> localhost:40985}
2020-05-02 06:30:10.919176: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job worker -> {0 -> 10.240.1.2:8470}
2020-05-02 06:30:10.919227: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job localhost -> {0 -> localhost:40985}
2020-05-02 06:30:10.919829: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:390] Started server with target: grpc://localhost:40985
Traceback (most recent call last):
  File ""src/tpu.py"", line 15, in <module>
    tpu_address=tpu_name)
  File ""/home/amaret93/.local/lib/python3.7/site-packages/official/utils/misc/distribution_utils.py"", line 129, in get_distribution_strategy
    cluster_resolver = tpu_lib.tpu_initialize(tpu_address)
  File ""/home/amaret93/.local/lib/python3.7/site-packages/official/utils/misc/tpu_lib.py"", line 33, in tpu_initialize
    tf.tpu.experimental.initialize_tpu_system(cluster_resolver)
  File ""/home/amaret93/.local/lib/python3.7/site-packages/tensorflow/python/tpu/tpu_strategy_util.py"", line 103, in initialize_tpu_system
    serialized_topology = output.numpy()
  File ""/home/amaret93/.local/lib/python3.7/site-packages/tensorflow/python/framework/ops.py"", line 1110, in numpy
    maybe_arr = self._numpy()  # pylint: disable=protected-access
  File ""/home/amaret93/.local/lib/python3.7/site-packages/tensorflow/python/framework/ops.py"", line 1078, in _numpy
    six.raise_from(core._status_to_exception(e.code, e.message), None)
  File ""<string>"", line 3, in raise_from
tensorflow.python.framework.errors_impl.InvalidArgumentError: NodeDef expected inputs 'string' do not match 0 inputs specified; Op<name=_Send; signature=tensor:T -> ; attr=T:type; attr=tensor_name:string; 
attr=send_device:string; attr=send_device_incarnation:int; attr=recv_device:string; attr=client_terminated:bool,default=false; is_stateful=true>; NodeDef: {{node _Send}}
2020-05-02 06:30:21.913994: W tensorflow/core/distributed_runtime/eager/remote_tensor_handle_data.cc:76] Unable to destroy remote tensor handles. If you are running a tf.function, it usually indicates some
 op in the graph gets an error: NodeDef expected inputs 'string' do not match 0 inputs specified; Op<name=_Send; signature=tensor:T -> ; attr=T:type; attr=tensor_name:string; attr=send_device:string; attr=
send_device_incarnation:int; attr=recv_device:string; attr=client_terminated:bool,default=false; is_stateful=true>; NodeDef: {{node _Send}}
```

</details>",Aschen,b'models:official type:bug',2020-05-02T06:44:14Z,2020-07-31T03:40:13Z,,,,,,,
8456,export_tflite_ssd_graph crash in TF 2,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Windows 10
- Mobile device (e.g., Pixel 4, Samsung Galaxy 10) if the issue happens on mobile device:
N/A
- TensorFlow installed from (source or binary):
Binary (pip)
- TensorFlow version (use command below):
v2.1.0-rc2-17-ge5bf8de410 2.1.0
- Python version:
3.6.3
- Bazel version (if compiling from source):
N/A
- GCC/Compiler version (if compiling from source):
N/A
- CUDA/cuDNN version:
N/A
- GPU model and memory:
N/A

**Describe the current behavior**
Running `export_tflite_ssd_graph.py` crashes due to `ModuleNotFoundError: No module named 'tensorflow.tools.graph_transforms'`.

Full stacktrace:
```
Traceback (most recent call last):
  File ""C:\MyProjects\tensorflow-models\research\object_detection\export_tflite_ssd_graph.py"", line 96, in <module>
    from object_detection import export_tflite_ssd_graph_lib
  File ""C:\MyProjects\tensorflow-models\research\object_detection\export_tflite_ssd_graph_lib.py"", line 26, in <module>
    from tensorflow.tools.graph_transforms import TransformGraph
ModuleNotFoundError: No module named 'tensorflow.tools.graph_transforms'
```

As per [this](https://github.com/tensorflow/tensorflow/issues/33352#issuecomment-556245567), graph_transforms no longer exposed intentionally in TF 2.0

Anytime I need to convert I use some VM with TF 1.14.0 is there any fix/workaround for this issue on TF2?
Thx.",ValYouW,b'models:research type:bug',2020-04-30T23:52:30Z,2020-05-29T05:54:22Z,,,,,,,
8450,Error: cannot import name 'export_saved_model,"<!--


**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g., Pixel 4, Samsung Galaxy 10) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below):
- Python version:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

<!-- 
You can collect some of this information using our environment capture (https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 

1. TensorFlow 1.0
`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 

2. TensorFlow 2.0
`python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`
-->

**Please provide the entire URL of the model you are using?**
<!-- (e.g., https://github.com/tensorflow/models/tree/master/official/nlp/bert) -->

**Describe the current behavior**
Getting Error  while import from tensorflow.python.keras.saving.save import export_saved_model
Error 👍 cannot import name 'export_saved_model
 Tensorflow 2.2 version

**Describe the expected behavior**

**Code to reproduce the issue**
<!-- Provide a reproducible test case that is the bare minimum necessary to generate the problem. -->from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

from tensorflow.python.keras.saving.hdf5_format import load_attributes_from_hdf5_group
from tensorflow.python.keras.saving.hdf5_format import load_model_from_hdf5
from tensorflow.python.keras.saving.hdf5_format import load_weights_from_hdf5_group
from tensorflow.python.keras.saving.hdf5_format import load_weights_from_hdf5_group_by_name
from tensorflow.python.keras.saving.hdf5_format import preprocess_weights_for_loading
from tensorflow.python.keras.saving.hdf5_format import save_attributes_to_hdf5_group
from tensorflow.python.keras.saving.hdf5_format import save_model_to_hdf5
from tensorflow.python.keras.saving.hdf5_format import save_weights_to_hdf5_group
from tensorflow.python.keras.saving.model_config import model_from_config
from tensorflow.python.keras.saving.model_config import model_from_json
from tensorflow.python.keras.saving.model_config import model_from_yaml
from tensorflow.python.keras.saving.save import load_model
from tensorflow.python.keras.saving.save import save_model
from tensorflow.python.keras.saving.save import export_saved_model
from tensorflow.python.keras.saving.saved_model import load_from_saved_model
from tensorflow.python.keras.saving.saving_utils import trace_model_call

**Other info / logs**
<!-- Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. -->
",abhishekray2010,b'models:official type:bug',2020-04-28T14:25:26Z,2020-09-19T22:13:49Z,,,,,,,
8449,Inference hangs on GPU only when Eager is enabled,"<!--
Please make sure that this is a bug. 

As per our GitHub Policy (https://github.com/tensorflow/models/blob/master/ISSUES.md), we only address code bugs, documentation issues, and feature requests on GitHub.

Please go to Stack Overflow (http://stackoverflow.com/questions/tagged/tensorflow-model-garden) for help and support.

The research models (https://github.com/tensorflow/models/tree/master/research) are a large collection of models implemented in TensorFlow by researchers. They are not officially supported. It is up to the individual researchers to maintain the models and/or provide support on issues and pull requests.
-->

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
I made small changes (use of opencv to capture images) to the object_detection_tutorial file.
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- TensorFlow installed from (source or binary): python -m pip install tensorflow
- TensorFlow version (use command below): v2.1.0-rc2-17-ge5bf8de410 2.1.0
- Python version: 3.7
- CUDA/cuDNN version: 10.1 / 7.6.5.32
- GPU model and memory: GTX 960M 2GB or RTX2070 Super 8 GB

<!-- 
You can collect some of this information using our environment capture (https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 

1. TensorFlow 1.0
`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 

2. TensorFlow 2.0
`python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`
-->

**Describe the current behavior**
With GPU and Eager mode enabled, running inference hangs indefinitely after processing a few frames (<15).  
If I then disable Eager mode, it runs fine.

**Describe the expected behavior**
Being able to run inference without hangs with Eager mode enabled. 

**Code to reproduce the issue**

```
import os
import pathlib
import cv2
import numpy as np
import tensorflow as tf

from object_detection.utils import ops as utils_ops

def load_model(model_name):
    base_url = 'http://download.tensorflow.org/models/object_detection/'
    model_file = model_name + '.tar.gz'
    model_dir = tf.keras.utils.get_file(
        fname=model_name,
        origin=base_url + model_file,
        untar=True)
    model_dir = pathlib.Path(model_dir)/""saved_model""
    model = tf.saved_model.load(str(model_dir))
    model = model.signatures['serving_default']
    return model

def run_inference_for_single_image(model, image):
    image = np.asarray(image)
    input_tensor = tf.convert_to_tensor(image)
    input_tensor = input_tensor[tf.newaxis, ...]
    # Run inference
    print(""Inference start"")
    model(input_tensor)
    print(""Inference end"")

if ""models"" in pathlib.Path.cwd().parts:
    while ""models"" in pathlib.Path.cwd().parts:
        os.chdir('..')

#disable eager mode
#tf.compat.v1.disable_eager_execution()

MODELNAME = 'ssd_mobilenet_v1_coco_2017_11_17'
DETECTION_MODEL = load_model(MODELNAME)

utils_ops.tf = tf.compat.v1
tf.gfile = tf.io.gfile

IMGPATH = PATH_TO_IMAGE
IMAGE = cv2.cv2.imread(IMGPATH)

while True:
    run_inference_for_single_image(DETECTION_MODEL, IMAGE)
```
I ran this from the research\object_detection folder

**Other info / logs**
I am not sure how to support the claim of it being a bug. I tried it on different machines and the code is based on an example. I thought it was because there are no error or warning messages before hanging, it works fine when just using the CPU (with or without Eager mode), it works on GPU without Eager mode and it hangs in a library function.

I never did anything like this before. If i did something wrong or more information is required, please let me know. 
",McSlay,b'models:research type:bug',2020-04-28T13:39:44Z,2020-05-11T07:24:38Z,,,,,,,
8448,the pretrained model in multiprocessing,"hi,dear,
I have the problem in multiprocessing ,codes 
```
from multiprocessing.pool import ThreadPool
modelV3=tf.keras.applications.InceptionV3(include_top=False, pooling='avg')

def process(inputs):
    x_pred=modelV3.predict(inputs)
    return x_pred

x=np.random.randn(1,299,299,3)
y=np.random.randn(1,299,299,3)
z=np.random.randn(1,299,299,3)

pool=ThreadPool(2)
pool.map(process,[x,y,z])
```

**Error**:
```
Traceback (most recent call last):
  File ""D:\python36\new\xception_load_.py"", line 26, in <module>
    pool.map(process,[x,y,z])
  File ""D:\python36\lib\multiprocessing\pool.py"", line 266, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File ""D:\python36\lib\multiprocessing\pool.py"", line 644, in get
    raise self._value
  File ""D:\python36\lib\multiprocessing\pool.py"", line 119, in worker
    result = (True, func(*args, **kwds))
  File ""D:\python36\lib\multiprocessing\pool.py"", line 44, in mapstar
    return list(map(*args))
  File ""D:\python36\new\xception_load_.py"", line 18, in process
    x_pred=modelV3.predict(inputs)
  File ""D:\python36\lib\site-packages\tensorflow_core\python\keras\engine\training.py"", line 908, in predict
    use_multiprocessing=use_multiprocessing)
  File ""D:\python36\lib\site-packages\tensorflow_core\python\keras\engine\training_arrays.py"", line 723, in predict
    callbacks=callbacks)
  File ""D:\python36\lib\site-packages\tensorflow_core\python\keras\engine\training_arrays.py"", line 189, in model_iteration
    f = _make_execution_function(model, mode)
  File ""D:\python36\lib\site-packages\tensorflow_core\python\keras\engine\training_arrays.py"", line 566, in _make_execution_function
    return model._make_execution_function(mode)
  File ""D:\python36\lib\site-packages\tensorflow_core\python\keras\engine\training.py"", line 2189, in _make_execution_function
    self._make_predict_function()
  File ""D:\python36\lib\site-packages\tensorflow_core\python\keras\engine\training.py"", line 2179, in _make_predict_function
    **kwargs)
  File ""D:\python36\lib\site-packages\tensorflow_core\python\keras\backend.py"", line 3678, in function
    return GraphExecutionFunction(inputs, outputs, updates=updates, **kwargs)
  File ""D:\python36\lib\site-packages\tensorflow_core\python\keras\backend.py"", line 3330, in __init__
    with ops.control_dependencies([self.outputs[0]]):
  File ""D:\python36\lib\site-packages\tensorflow_core\python\framework\ops.py"", line 5254, in control_dependencies
    return get_default_graph().control_dependencies(control_inputs)
  File ""D:\python36\lib\site-packages\tensorflow_core\python\framework\ops.py"", line 4688, in control_dependencies
    c = self.as_graph_element(c)
  File ""D:\python36\lib\site-packages\tensorflow_core\python\framework\ops.py"", line 3607, in as_graph_element
    return self._as_graph_element_locked(obj, allow_tensor, allow_operation)
  File ""D:\python36\lib\site-packages\tensorflow_core\python\framework\ops.py"", line 3686, in _as_graph_element_locked
    raise ValueError(""Tensor %s is not an element of this graph."" % obj)
ValueError: Tensor Tensor(""global_average_pooling2d_1/Mean:0"", shape=(?, 2048), dtype=float32) is not an element of this graph.
```

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):win10 64
- TensorFlow installed from (source or binary):pip
- TensorFlow version (use command below):1.14
- Python version: 3.6.8
- CUDA/cuDNN version: NO
- GPU model and memory: No GPU


Could you pls help me ?
thx",ucas010,b'models:research type:bug',2020-04-28T04:12:07Z,2020-05-12T01:49:02Z,,,,,,,
8441,KeyError: 'leonberger' in create_pet_tf_record.py with pets dataset,"Hello everybody.
i want to train the mask-rcnn on the oxford pets dataset.
i downloaded the pets dataset from this official link :[https://www.robots.ox.ac.uk/~vgg/data/pets/](url)
now it is required to convert raw dataset to tfrecord files with  **create_pet_tf_record.py** script.
but when i run this script , i face an issue like this :

> File ""/home/eagle-soft/anaconda3/lib/python3.7/site-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""new_create_pet_tf_record.py"", line 308, in main
    mask_type=FLAGS.mask_type)
  File ""new_create_pet_tf_record.py"", line 263, in create_tf_record
    mask_type=mask_type)
  File ""new_create_pet_tf_record.py"", line 169, in dict_to_tf_example
    classes.append(label_map_dict[class_name])
KeyError: 'leonberger'

it seems that the label_map_util.get_label_map_dict method returns an empty dictionary.
but i don't know how to solve this issue.
does anybody can help me ?
thank you ",naserpiltan,b'models:research type:bug',2020-04-26T10:00:55Z,2020-05-11T18:05:43Z,,,,,,,
8429,FIFOQueue '_1_prefetch_queue/fifo_queue' is closed and has insufficient elements,"I run slim/train_image_classifier.py and used mobilenet_v2 fine-turning
I set up the relevant configuration according to the documentation， when i run .py, I got the bug:

`INFO:tensorflow:Caught OutOfRangeError. Stopping Training. FIFOQueue '_1_prefetch_queue/fifo_queue' is closed and has insufficient elements (requested 1, current size 0)
	 [[node fifo_queue_Dequeue (defined at E:/sence-classification/models/research/slim/train_image_classifier.py:488) ]]`

`tensorflow.python.framework.errors_impl.DataLossError: corrupted record at 0
	 [[{{node parallel_read/ReaderReadV2_1}}]]`

How can i solve it？

Thanks！",Ijustakid,b'models:research type:bug',2020-04-24T06:29:01Z,2020-04-24T06:57:39Z,,,,,,,
8404,Object detection API: Training stuck at step=0 for ssd mobilenetv2,"**System information**
- Didn't change the code but used my own data:
- Windows 10 + conda
- TensorFlow installed from binary
- TensorFlow version: v1.15.0-rc3-22-g590d6eef7e 1.15.0
- Python version: 3.7.6
- CUDA/cuDNN version: 10.0
- GPU model and memory: GeForce GTX 1080 Ti

<!-- 
You can collect some of this information using our environment capture (https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 

1. TensorFlow 1.0
`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 

2. TensorFlow 2.0
`python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`
-->

**Please provide the entire URL of the model you are using?**
http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v2_oid_v4_2018_12_12.tar.gz

**Describe the current behavior**
The training stops at step = 0.

I wanted to do transfer learning using a ssd + mobilenetv2 model with my own images. I have only one class. The images were downloaded from OpenImageDataSet. I verified that the TFRecord was correctly created as I can use the same data to train faster_rcnn with object detetion APIs. I created my own config file using the one in the repos: ssd_mobilenet_v2_oid_v4.config. 

I also tried to start with ssd_mobilenet_v2_coco_2018_03_29.tar.gz using corresponding config file. The behavior is the same -- it also stuck at the same place.

**Describe the expected behavior**
I would expect I can train the ssd + mobilenetv2 with the my data as what I did for faster_rcnn. 

**Code to reproduce the issue**
Images of one class and train with a config file like below. 
Thank you!

**Other info / logs**

####################
ssd_mobilenet_v2_oid_v4.config. 

model {
  ssd {
    num_classes: 1
    box_coder {
      faster_rcnn_box_coder {
        y_scale: 10.0
        x_scale: 10.0
        height_scale: 5.0
        width_scale: 5.0
      }
    }
    matcher {
      argmax_matcher {
        matched_threshold: 0.5
        unmatched_threshold: 0.5
        ignore_thresholds: false
        negatives_lower_than_unmatched: true
        force_match_for_each_row: true
      }
    }
    similarity_calculator {
      iou_similarity {
      }
    }
    anchor_generator {
      ssd_anchor_generator {
        num_layers: 6
        min_scale: 0.2
        max_scale: 0.95
        aspect_ratios: 1.0
        aspect_ratios: 2.0
        aspect_ratios: 0.5
        aspect_ratios: 3.0
        aspect_ratios: 0.3333
      }
    }
    image_resizer {
      fixed_shape_resizer {
        height: 300
        width: 300
      }
    }
    box_predictor {
      convolutional_box_predictor {
        min_depth: 0
        max_depth: 0
        num_layers_before_predictor: 0
        use_dropout: false
        dropout_keep_probability: 0.8
        kernel_size: 1
        box_code_size: 4
        apply_sigmoid_to_scores: false
        conv_hyperparams {
          activation: RELU_6,
          regularizer {
            l2_regularizer {
              weight: 0.00004
            }
          }
          initializer {
            truncated_normal_initializer {
              stddev: 0.03
              mean: 0.0
            }
          }
          batch_norm {
            train: true,
            scale: true,
            center: true,
            decay: 0.9997,
            epsilon: 0.001,
          }
        }
      }
    }
    feature_extractor {
      type: 'ssd_mobilenet_v2'
      min_depth: 16
      depth_multiplier: 1.0
      conv_hyperparams {
        activation: RELU_6,
        regularizer {
          l2_regularizer {
            weight: 0.00004
          }
        }
        initializer {
          truncated_normal_initializer {
            stddev: 0.03
            mean: 0.0
          }
        }
        batch_norm {
          train: true,
          scale: true,
          center: true,
          decay: 0.9997,
          epsilon: 0.001,
        }
      }
    }
    loss {
      classification_loss {
        weighted_sigmoid {
        }
      }
      localization_loss {
        weighted_smooth_l1 {
        }
      }
      hard_example_miner {
        num_hard_examples: 3000
        iou_threshold: 0.99
        loss_type: CLASSIFICATION
        max_negatives_per_positive: 3
        min_negatives_per_image: 3
      }
      classification_weight: 1.0
      localization_weight: 1.0
    }
    normalize_loss_by_num_matches: true
    post_processing {
      batch_non_max_suppression {
        score_threshold: 1e-8
        iou_threshold: 0.6
        max_detections_per_class: 100
        max_total_detections: 100
      }
      score_converter: SIGMOID
    }
  }
}

train_config: {
  batch_size: 24
  optimizer {
    rms_prop_optimizer: {
      learning_rate: {
        exponential_decay_learning_rate {
          initial_learning_rate: 0.0008
          decay_steps: 800720
          decay_factor: 0.95
        }
      }
      momentum_optimizer_value: 0.9
      decay: 0.9
      epsilon: 1.0
    }
  }

  gradient_clipping_by_norm: 10.0
  keep_checkpoint_every_n_hours: 24
  fine_tune_checkpoint: ""D:/work/cv/others/my-tf2-od-transfer-ssd-mobilenet-v2/ssd_mobilenet_v2_oid_v4_2018_12_12/model.ckpt""




  num_steps: 100
  data_augmentation_options {
    random_horizontal_flip {
    }
  }
  data_augmentation_options {
    ssd_random_crop {
    }
  }
}

train_input_reader: {
  tf_record_input_reader {

    input_path: ""D:/work/cv/others/my-tf2-od-transfer-ssd-mobilenet-v2/data/oid_glasses_train.tfrecord""
  }

  label_map_path: ""D:/work/cv/others/my-tf2-od-transfer-ssd-mobilenet-v2/labelmap.pbtxt""
}

eval_config: {





  metrics_set: ""open_images_V2_detection_metrics""
}

eval_input_reader: {
  sample_1_of_n_examples: 10
  tf_record_input_reader {

    input_path: ""D:/work/cv/others/my-tf2-od-transfer-ssd-mobilenet-v2/data/oid_glasses_validation.tfrecord""
  }

  label_map_path: ""D:/work/cv/others/my-tf2-od-transfer-ssd-mobilenet-v2/labelmap.pbtxt""
  shuffle: false
  num_readers: 1
}





####################
CONSOLE LOG:
Instructions for updating:
Use standard file utilities to get mtimes.
INFO:tensorflow:Running local_init_op.
I0416 16:30:39.198738 19792 session_manager.py:500] Running local_init_op.
INFO:tensorflow:Done running local_init_op.
I0416 16:30:39.632495 19792 session_manager.py:502] Done running local_init_op.
INFO:tensorflow:Saving checkpoints for 0 into D:\work\cv\others\my-tf2-od-transfer-ssd-mobilenet-v2\model.ckpt.
I0416 16:30:48.724722 19792 basic_session_run_hooks.py:606] Saving checkpoints for 0 into D:\work\cv\others\my-tf2-od-transfer-ssd-mobilenet-v2\model.ckpt.
2020-04-16 16:30:59.919297: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll
2020-04-16 16:31:00.964680: W tensorflow/stream_executor/cuda/redzone_allocator.cc:312] Internal: Invoking ptxas not supported on Windows
Relying on driver to perform ptx compilation. This message will be only logged once.
2020-04-16 16:31:00.986098: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_100.dll
INFO:tensorflow:loss = 12.512502, step = 0
I0416 16:31:02.740392 19792 basic_session_run_hooks.py:262] loss = 12.512502, step = 0  [STUCK HERE]
",jackyvr,b'models:research type:bug',2020-04-17T00:20:02Z,2020-04-24T04:07:45Z,,,,,,,
8399,Some Python objects were not bound to checkpointed values,"<!--
Please make sure that this is a bug. 

As per our GitHub Policy (https://github.com/tensorflow/models/blob/master/ISSUES.md), we only address code bugs, documentation issues, and feature requests on GitHub.

Please go to Stack Overflow (http://stackoverflow.com/questions/tagged/tensorflow-model-garden) for help and support.
-->

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04
- Mobile device (e.g., Pixel 4, Samsung Galaxy 10) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): v1.12.1-29517-g242129341e 2.2.0-dev20200414
- Python version: 3.7.4
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: CUDA Version 10.1.243
- GPU model and memory: GeForce GTX 970

<!-- 
You can collect some of this information using our environment capture (https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 

1. TensorFlow 1.0
`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 

2. TensorFlow 2.0
`python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`
-->

**Please provide the entire URL of the model you are using?**
<!-- (e.g., https://github.com/tensorflow/models/tree/master/official/nlp/bert) -->

https://github.com/tensorflow/models/tree/master/official/nlp/bert

**Describe the current behavior**

I am fine-tuning a bert-based model and saving checkpoints. At prediction time, restoring the checkpoints fails with the errors similar to:
```
Traceback (most recent call last):
  File ""/home/david/github/bert-checkpoints-bug/predict.py"", line 12, in <module>
    checkpoint.restore(tf.train.latest_checkpoint('checkpoints')).assert_existing_objects_matched()
  File ""/home/david/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/tracking/util.py"", line 783, in assert_existing_objects_matched
    (list(unused_python_objects),))
AssertionError: Some Python objects were not bound to checkpointed values, likely due to changes in the Python program: [<tf.Variable 'save_counter:0' shape=() dtype=int64, numpy=0>, <tf.Variable 'transformer/layer_2/self_attention_output/kernel:0' shape=(12, 64, 768) dtype=float32, numpy=
...
```
**Describe the expected behavior**
Should work without errors

**Code to reproduce the issue**
<!-- Provide a reproducible test case that is the bare minimum necessary to generate the problem. -->

reproduce.py:
```
import os

import tensorflow as tf
from official.nlp.bert.bert_models import get_transformer_encoder
from official.nlp.bert.configs import BertConfig
from tensorflow.keras.layers import Dense
from tensorflow.keras.models import Model


def build_model(bert_dir):
    max_seq_len = 384

    bert_config = BertConfig.from_json_file(os.path.join(bert_dir, 'bert_config.json'))
    bert_encoder = get_transformer_encoder(bert_config, max_seq_len)

    input_ids = tf.keras.layers.Input(shape=(max_seq_len,), dtype=tf.int32, name='input_ids')
    input_mask = tf.keras.layers.Input(shape=(max_seq_len,), dtype=tf.int32, name='input_mask')
    segment_ids = tf.keras.layers.Input(shape=(max_seq_len,), dtype=tf.int32, name='segment_ids')

    bert_inputs = [input_ids, input_mask, segment_ids]
    bert_sequence_output, bert_pooled_output = bert_encoder(bert_inputs)

    out = Dense(1, activation='sigmoid', name='out')(bert_pooled_output)
    return Model(inputs=bert_inputs, outputs=[out])


dir_path = os.path.dirname(os.path.realpath(__file__))
bert_dir = os.path.join(dir_path, 'uncased_L-12_H-768_A-12')

# TRAIN

model = build_model(bert_dir)
checkpoint = tf.train.Checkpoint(model=model)
checkpoint.restore(os.path.join(bert_dir, 'bert_model.ckpt')).expect_partial()

optimizer = tf.optimizers.Adam()
model.compile(optimizer=optimizer, loss=[tf.losses.BinaryCrossentropy()])

input_ids = tf.zeros((1, 384))
input_mask = tf.zeros((1, 384))
segment_ids = tf.zeros((1, 384))

y = tf.zeros((1, 1))

checkpoint_path = ""checkpoints/model.ckpt""
checkpoint_dir = os.path.dirname(checkpoint_path)
cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,
                                                 save_weights_only=True,
                                                 verbose=1)
model.fit(x=[input_ids, input_mask, segment_ids], y=y, epochs=3, callbacks=[cp_callback])

# PREDICT

model = build_model(bert_dir)
checkpoint = tf.train.Checkpoint(model=model)
checkpoint.restore(tf.train.latest_checkpoint('checkpoints')).assert_existing_objects_matched()  # <-- ERROR

input_ids = tf.zeros((1, 384))
input_mask = tf.zeros((1, 384))
segment_ids = tf.zeros((1, 384))

model.predict([input_ids, input_mask, segment_ids])
```

To reproduce, first download and extract the pre-trained model https://storage.googleapis.com/cloud-tpu-checkpoints/bert/keras_bert/uncased_L-12_H-768_A-12.tar.gz

Then run
```
python reproduce.py
```

I also have a repo with the same code as above: https://github.com/david-wb/bert-checkpoints-bug
**Other info / logs**
<!-- Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. -->
",david-wb,b'models:official type:bug',2020-04-14T23:18:09Z,2020-08-24T14:02:29Z,,,,,,,
8394,Matrix of confusion in tensor flow 1.4,"hello, I am using the script ( https://www.shiftedup.com/2018/10/10/confusion-matrix-in-object-detection-api-with-tensorflow ), I generated the confuction matrix, only I have two classes and the matrix has a size of 3x3, which is wrong. someone could explain me. Thank you

![matriz](https://user-images.githubusercontent.com/62752094/79141415-1fc52d80-7d90-11ea-9504-6a663b34f85d.PNG)


matriz

Matriz de confusión:
[[1. 1. 7.]
[0. 3. 3.]
[2. 1. 0.]]

categoría ... recordar_@0.5IOU
0 Gafas ... 0.111111
1 Bolígrafo ... 0.500000

[2 filas x 3 columnas]
",jhonjam,b'models:official type:bug',2020-04-13T17:08:01Z,2020-08-07T18:22:56Z,,,,,,,
8392,RuntimeError when using TransformerXLModel layers ,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Windows 10 (10.0, Build 18362)
- Mobile device (e.g., Pixel 4, Samsung Galaxy 10) if the issue happens on mobile device:None
- TensorFlow installed from (source or binary):binary
- TensorFlow version (use command below):2.1.0
- Python version:3.7.6
Describe the problem
I want to use transformer xl in my keras model and  I use xlnet_modeling.py provided in official models to test, when testing models I met a RuntimeError.
Source code / logs
the code here is mainly from xlnet_modeling.py in official models and I rewrite some part of input.
[code.txt](https://github.com/tensorflow/models/files/4470425/code.txt)
and here's the wrong information:
Traceback (most recent call last):

  File ""<ipython-input-3-049aa757e999>"", line 1, in <module>
    model_use = model_test1(True)

  File ""D:\bug_fixing.py"", line 800, in model_test1
    a,b = user_hist_item_transformerxl([input1, input3, input4, None, None, None, None])

  File ""C:\Users\win\Anaconda3\lib\site-packages\tensorflow_core\python\keras\engine\base_layer.py"", line 822, in __call__
    outputs = self.call(cast_inputs, *args, **kwargs)

  File ""D:\bug_fixing.py"", line 637, in call
    non_tgt_mask = -tf.eye(qlen, dtype=self.tf_float)

  File ""C:\Users\win\Anaconda3\lib\site-packages\tensorflow_core\python\ops\linalg_ops.py"", line 169, in eye
    name=name)

  File ""C:\Users\win\Anaconda3\lib\site-packages\tensorflow_core\python\ops\linalg_ops_impl.py"", line 65, in eye
    diag_shape = array_ops.concat((batch_shape, [diag_size]), axis=0)

  File ""C:\Users\win\Anaconda3\lib\site-packages\tensorflow_core\python\util\dispatch.py"", line 180, in wrapper
    return target(*args, **kwargs)

  File ""C:\Users\win\Anaconda3\lib\site-packages\tensorflow_core\python\ops\array_ops.py"", line 1517, in concat
    return gen_array_ops.concat_v2(values=values, axis=axis, name=name)

  File ""C:\Users\win\Anaconda3\lib\site-packages\tensorflow_core\python\ops\gen_array_ops.py"", line 1334, in concat_v2
    ""ConcatV2"", values=values, axis=axis, name=name)

  File ""C:\Users\win\Anaconda3\lib\site-packages\tensorflow_core\python\framework\op_def_library.py"", line 412, in _apply_op_helper
    as_ref=input_arg.is_ref)

  File ""C:\Users\win\Anaconda3\lib\site-packages\tensorflow_core\python\framework\ops.py"", line 1382, in internal_convert_n_to_tensor
    ctx=ctx))

  File ""C:\Users\win\Anaconda3\lib\site-packages\tensorflow_core\python\framework\ops.py"", line 1280, in convert_to_tensor
    raise RuntimeError(""Attempting to capture an EagerTensor without ""

RuntimeError: Attempting to capture an EagerTensor without building a function.

As for me, I think it may because tf.eye EagerTensor part is not attached to the graph,but I haven't come up with any idea to solve the problem above",shidaide2019,b'models:official stalled stat:awaiting response type:bug',2020-04-13T16:21:07Z,2020-09-18T19:17:29Z,,,,,,,
8388,ValueError: Eval batch size 256 is not divisible by 1000,"<!--
Please make sure that this is a bug. 

As per our GitHub Policy (https://github.com/tensorflow/models/blob/master/ISSUES.md), we only address code bugs, documentation issues, and feature requests on GitHub.

Please go to Stack Overflow (http://stackoverflow.com/questions/tagged/tensorflow-model-garden) for help and support.
-->

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS Catalina Version 10.15.4 (19E287)d
- Mobile device (e.g., Pixel 4, Samsung Galaxy 10) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below): 2.2.0-dev20200411
- Python version: 3.6
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

<!-- 
You can collect some of this information using our environment capture (https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 

1. TensorFlow 1.0
`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 

2. TensorFlow 2.0
`python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`
-->

**Please provide the entire URL of the model you are using?** 
https://github.com/tensorflow/models/blob/master/official/recommendation/ncf_keras_main.py
<!-- (e.g., https://github.com/tensorflow/models/tree/master/official/nlp/bert) -->

**Describe the current behavior**
Got the following error message when running command `python official/recommendation/ncf_keras_main.py --model_dir ../XXXX/model --data_dir ../XXXX/data`:
```
ValueError: Eval batch size 256 is not divisible by 1000
```
Full log is like below:
```sh
$ python official/recommendation/ncf_keras_main.py --model_dir ../ncf_tensorflow_sample/model --data_dir ../ncf_tensorflow_sample/data
2020-04-11 11:03:52.325168: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-04-11 11:03:52.343370: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f8d359bcbd0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-04-11 11:03:52.343389: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
WARNING:tensorflow:Some requested devices in `tf.distribute.Strategy` are not visible to TensorFlow: /job:localhost/replica:0/task:0/device:GPU:0
W0411 11:03:52.343887 4374371776 cross_device_ops.py:1172] Some requested devices in `tf.distribute.Strategy` are not visible to TensorFlow: /job:localhost/replica:0/task:0/device:GPU:0
INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)
I0411 11:03:52.345362 4374371776 mirrored_strategy.py:341] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)
I0411 11:03:52.345715 4374371776 movielens.py:108] Dataset ml-1m has already been downloaded
I0411 11:03:52.345789 4374371776 data_preprocessing.py:201] Beginning data preprocessing.
I0411 11:03:53.482697 4374371776 data_preprocessing.py:117] Generating user_map and item_map...
I0411 11:03:54.415248 4374371776 data_preprocessing.py:139] Sorting by user, timestamp...
I0411 11:03:57.333374 4374371776 data_preprocessing.py:172] Writing raw data cache.
Traceback (most recent call last):
  File ""official/recommendation/ncf_keras_main.py"", line 562, in <module>
    app.run(main)
  File ""/Users/xyin/anaconda3/envs/py36/lib/python3.6/site-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/Users/xyin/anaconda3/envs/py36/lib/python3.6/site-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""official/recommendation/ncf_keras_main.py"", line 557, in main
    run_ncf(FLAGS)
  File ""official/recommendation/ncf_keras_main.py"", line 246, in run_ncf
    num_users, num_items, _, _, producer = ncf_common.get_inputs(params)
  File ""/Users/xyin/Documents/self/models/official/recommendation/ncf_common.py"", line 61, in get_inputs
    deterministic=FLAGS.seed is not None)
  File ""/Users/xyin/Documents/self/models/official/recommendation/data_preprocessing.py"", line 236, in instantiate_pipeline
    create_data_offline=generate_data_offline)
  File ""/Users/xyin/Documents/self/models/official/recommendation/data_pipeline.py"", line 852, in __init__
    super(BisectionDataConstructor, self).__init__(*args, **kwargs)
  File ""/Users/xyin/Documents/self/models/official/recommendation/data_pipeline.py"", line 414, in __init__
    eval_batch_size, 1 + rconst.NUM_EVAL_NEGATIVES))
ValueError: Eval batch size 256 is not divisible by 1000
```


**Describe the expected behavior**

**Code to reproduce the issue**
https://github.com/tensorflow/models/blob/master/official/recommendation/ncf_keras_main.py
<!-- Provide a reproducible test case that is the bare minimum necessary to generate the problem. -->

**Other info / logs**
<!-- Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. -->
",xiangshiyin,b'models:official type:bug',2020-04-11T19:51:23Z,2020-04-16T04:30:08Z,,,,,,,
8380,ValueError: Unknown ssd feature_extractor: ssd_mobilenet_v3_large,"Ubuntu 18.04 
TensorFlow 1.15.0 (Because of workaround: [link](https://stackoverflow.com/questions/59825444/modulenotfounderror-no-module-named-tensorflow-tools-graph-transforms-when-us))
Python = 3.6
I want to place ssd_mobilenet_v3_large into android code, to do so Im following [link](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/running_on_mobile_tensorflowlite.md)

and when I run command: 

`python object_detection/export_tflite_ssd_graph.py \
--pipeline_config_path=/home/n/Downloads/ssd_mobilenet_v3_large_coco_2019_08_14/pipeline.config \
--trained_checkpoint_prefix=/home/n/Downloads/ssd_mobilenet_v3_large_coco_2019_08_14/model.ckpt.data-00000-of-00001 \
--output_directory=/tmp/tflite \
--add_postprocessing_op=true`

I got:
`Traceback (most recent call last):
  File ""object_detection/export_tflite_ssd_graph.py"", line 143, in <module>
    tf.app.run(main)
  File ""/home/n/.conda/envs/car_detection/lib/python3.6/site-packages/tensorflow_core/python/platform/app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""/home/n/.conda/envs/car_detection/lib/python3.6/site-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/home/n/.conda/envs/car_detection/lib/python3.6/site-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""object_detection/export_tflite_ssd_graph.py"", line 139, in main
    FLAGS.max_classes_per_detection, use_regular_nms=FLAGS.use_regular_nms)
  File ""/home/n/.conda/envs/car_detection/lib/python3.6/site-packages/object_detection/export_tflite_ssd_graph_lib.py"", line 234, in export_tflite_graph
    pipeline_config.model, is_training=False)
  File ""/home/n/.conda/envs/car_detection/lib/python3.6/site-packages/object_detection/builders/model_builder.py"", line 121, in build
    return _build_ssd_model(model_config.ssd, is_training, add_summaries)
  File ""/home/n/.conda/envs/car_detection/lib/python3.6/site-packages/object_detection/builders/model_builder.py"", line 244, in _build_ssd_model
    is_training=is_training)
  File ""/home/n/.conda/envs/car_detection/lib/python3.6/site-packages/object_detection/builders/model_builder.py"", line 168, in _build_ssd_feature_extractor
    raise ValueError('Unknown ssd feature_extractor: {}'.format(feature_type))
ValueError: Unknown ssd feature_extractor: ssd_mobilenet_v3_large
`


However that's weird, because in file  /home/n/.conda/envs/car_detection/lib/python3.6/site-packages/object_detection/builders/model_builder.py

there is what they looking for: 
`    'ssd_mobilenet_v3_large': SSDMobileNetV3LargeFeatureExtractor,
`
in SSD_FEATURE_EXTRACTOR_CLASS_MAP

What is going on ?
",Adblu,b'models:research type:bug',2020-04-10T09:53:12Z,2020-08-06T07:14:23Z,,,,,,,
8377,Error while running deep_speech.py,"<!--
Please make sure that this is a bug. 

As per our GitHub Policy (https://github.com/tensorflow/models/blob/master/ISSUES.md), we only address code bugs, documentation issues, and feature requests on GitHub.

Please go to Stack Overflow (http://stackoverflow.com/questions/tagged/tensorflow-model-garden) for help and support.
-->

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- Mobile device (e.g., Pixel 4, Samsung Galaxy 10) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below): 1.15
- Python version: 3.6.9
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

<!-- 
You can collect some of this information using our environment capture (https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 

1. TensorFlow 1.0
`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 

2. TensorFlow 2.0
`python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`
-->

**Please provide the entire URL of the model you are using?**
<!-- (e.g., https://github.com/tensorflow/models/tree/master/official/nlp/bert) -->

**Describe the current behavior**
per_replica_batch_size is missing in distribution_utils of official.utils.misc
**Describe the expected behavior**
per_replica_batch_size is called in deep_speech.py. So, it should be in distribution_utils. The function definition exists in official/r1/transformer/transformer_main.py

**Code to reproduce the issue**
<!-- Provide a reproducible test case that is the bare minimum necessary to generate the problem. -->

**Other info / logs**
<!-- Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. -->
",Rafi99769,b'models:official type:bug',2020-04-09T12:00:06Z,2020-04-21T16:58:58Z,,,,,,,
8368,Seq2Species failes tests in run_training_test.py,"<!--
Please make sure that this is a bug. 

As per our GitHub Policy (https://github.com/tensorflow/models/blob/master/ISSUES.md), we only address code bugs, documentation issues, and feature requests on GitHub.

Please go to Stack Overflow (http://stackoverflow.com/questions/tagged/tensorflow-model-garden) for help and support.

The research models (https://github.com/tensorflow/models/tree/master/research) are a large collection of models implemented in TensorFlow by researchers. They are not officially supported. It is up to the individual researchers to maintain the models and/or provide support on issues and pull requests.
-->

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Latest Debian and Ubuntu
- TensorFlow installed from (source or binary): Binary (pip)
- TensorFlow version (use command below):  ('v1.15.0-rc3-22-g590d6ee', '1.15.0')
- Python version: 2.7.16

**Please provide the entire URL of the model you are using?**
https://github.com/tensorflow/models/tree/master/research/seq2species/

**Describe the current behavior**
2 tests fail
**Describe the expected behavior**
No tests fail
**Code to reproduce the issue**
First copy seq2species dir and cd into it
```
virtualenv -p /usr/bin/python2 venv
source venv/bin/activate
pip2 install tensorflow==1.15
python2 -B run_training_test.py
```
**Other info / logs**
See attached [log file](https://github.com/tensorflow/models/files/4443664/output.log)
The real training script seems to work fine using the provided preprocessed data (for the 60 seconds I let it run), so there might be something wrong with the test code. @apbusia and @depristo tagging maintainers.
",Bartvelp,b'models:archived models:research type:bug',2020-04-07T10:49:24Z,2020-04-28T16:46:09Z,,,,,,,
8363,Transformer: training failed at 3k steps on TPU,"I followed the official Transformer-2.x tutorial to train a Transformer Translation model on WMT, but training failed after 3k steps.
Tutorial: https://cloud.google.com/tpu/docs/tutorials/transformer-2.x

I checked that the instructions are up-to-date with transformer README here, and the code provided by the tutorial is the same as the 2.1.0 release of this repository: https://github.com/tensorflow/models/archive/v2.1.0.tar.gz


**System information**

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Google Cloud TPU v3-8
- TensorFlow version (use command below): 2.1
- Python version: 3.7.3

I followed exact instructions from Transformer-2.x tutorial to create my VM/TPU:  https://cloud.google.com/tpu/docs/tutorials/transformer-2.x

**Please provide the entire URL of the model you are using?**
official/transformer models in: 
https://github.com/tensorflow/models/archive/v2.1.0.tar.gz

OR

/usr/share/models/official/transformer on Cloud TPU

**Describe the current behavior**
Training failed after 3k steps during evaluation. 

It seems that different runs will fail at different # of steps. Previously, it failed at 6k steps.

**Describe the expected behavior**
The model is able to train 200k steps with full convergence.

**Code to reproduce the issue**
The codebase in the tutorial is the same as https://github.com/tensorflow/models/archive/v2.1.0.tar.gz

I followed the steps here: https://cloud.google.com/tpu/docs/tutorials/transformer-2.x

Training command is: python3 transformer_main.py --tpu=$TPU_NAME --model_dir=$MODEL_DIR --data_dir=$GCS_DATA_DIR --vocab_file=$GCS_DATA_DIR/vocab.ende.32768 --bleu_source=$GCS_DATA_DIR/newstest2014.en --bleu_ref=$GCS_DATA_DIR/newstest2014.de --batch_size=6144 --train_steps=200000 --static_batch=true --use_ctl=true --param_set=big --max_length=64 --decode_batch_size=32 --decode_max_length=97 --padded_decode=true --distribution_strategy=tpu

**Other info / logs**



  File ""transformer_main.py"", line 383, in eval
    distribution_strategy)
  File ""transformer_main.py"", line 118, in evaluate_and_log_bleu
    model, params, subtokenizer, bleu_source, bleu_ref, distribution_strategy)
  File ""transformer_main.py"", line 88, in translate_and_compute_bleu
    uncased_score = compute_bleu.bleu_wrapper(bleu_ref, tmp_filename, False)
  File ""/usr/share/models/official/transformer/compute_bleu.py"", line 96, in bleu_wrapper
    raise ValueError(""Reference and translation files have different number of ""
ValueError: Reference and translation files have different number of lines. If training only a few steps (100-200), the translation may be empty.

2020-04-05 20:40:41.852968: W ./tensorflow/core/distributed_runtime/eager/destroy_tensor_handle_node.h:79] Ignoring an error encountered when deleting remote tensors handles: Invalid argument: Unable to find a context_id matching the specified one (16973409415646534521). Perhaps the worker was restarted, or the context was GC'd?
Additional GRPC error information:
{""created"":""@1586119241.852831589"",""description"":""Error received from peer"",""file"":""external/grpc/src/core/lib/surface/call.cc"",""file_line"":1039,""grpc_message"":""Unable to find a context_id matching the specified one (16973409415646534521). Perhaps the worker was restarted, or the context was GC'd?"",""grpc_status"":3}
",dguo98,b'models:official stat:awaiting response type:bug',2020-04-05T22:10:22Z,2020-04-28T02:57:00Z,,,,,,,
8362,Tensorflow graph nodes are exchange  ,"I have trained a model with fine-tuning pre-trained model ` ssd_mobilenet_v2_coco_2018`. Here, i have used the exactly same `pipeline.config` file for training which is available inside `ssd_mobilenet_v2_coco_2018` pre-trained folder. 
I have only removed the `batch_norm_trainable: true` flag and changed the number of classes (4).
After training the model with my custom datasets with 4 classes, i found concat and concat_1 nodes gets exchange with each others. 
Pre-trained model has
| concat       | 1x1917x1x4  |
after-training it becomes
| concat       | 1x1917x5   |             
I have attached both tensorboard graph visualisation images. First image is pre-trained graph `ssd_mobilenet_v2_coco_2018`.
![pre-trained](https://user-images.githubusercontent.com/25616511/78499856-db72d580-7770-11ea-86ee-aacf49e29112.png)
![aftertraining](https://user-images.githubusercontent.com/25616511/78499862-e594d400-7770-11ea-9ba9-334b8780a08f.png)
          
The node exchanges can be seen on the right most corner of image. As in pre-trained graph, `Postprocess layer` connect with `concat_1` and `Squeeeze` connect with `concat`. But after the training, the graph shows completely reverse. Like `Prosprocess layer` connect with `concat` and `Squeeeze` connect with `concat_1`.
Further, i also found in pre-trained model graph that the `Preprocessor` takes input `ToFloat` while after training the  graph shows `Cast` as an input to `Preprocessor`.
I have fed the input to the model as `tfrecords`.

OS: Ubuntu 18.04
Framework: Tensorflow 1.14.0",sainisanjay,b'models:research type:bug',2020-04-05T13:41:08Z,2020-05-09T23:56:13Z,,,,,,,
8349,Transfer Learning with Inceptionv3 - flag directory error,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Ubuntu 16.04 running via VMware on Macbook Pro - External HDD
- TensorFlow installed from (source or binary): Source
- TensorFlow version (use command below): 1.14.0
- Python version: 3
- Bazel version (if compiling from source): 2.2.0
- GCC/Compiler version (if compiling from source):5.4.0

**Describe the current behavior**

Using a custom dataset of grocery store items to retrain InceptionV3. The dataset is hosted on an external hard drive and is accessible by cd'ing into it. The `noexec` option is not tagged.
I can edit and modify the external hard drive data via terminal.


Running an unmodified retrain.py fails with the following error: `AttributeError: 'NoneType' object has no attribute 'keys`

Tracing back, I can see the dir_path is prepended incorrectly: `E0401 14:27:30.038295 140710347978496 retrain.py:141] Image directory '/home/XXX/media/XXX/book/dataset/train_img' not found.`

The pertinent output is:
`E0401 14:27:30.038295 140710347978496 retrain.py:141] Image directory '/home/XXX/media/XXX/book/dataset/train_img' not found.
Traceback (most recent call last):
  File ""retrain.py"", line 1285, in <module>
    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)
  File ""/home/XXX/MIDI/lib/python3.6/site-packages/tensorflow/python/platform/app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""/home/XXX/MIDI/lib/python3.6/site-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/home/XXX/MIDI/lib/python3.6/site-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""retrain.py"", line 943, in main
    class_count = len(image_lists.keys())
AttributeError: 'NoneType' object has no attribute 'keys'
`

**Describe the expected behavior**
I expected the dir_path, in this case the image_dir, to be as I flagged it: `--image_dir ~/media/XXX/book/dataset/train_img`

and not what is seen in the output, above: `'/home/XXX/media/XXX/book/dataset/train_img' not found.`

**Code to reproduce the issue**

`python3 retrain.py --model_dir ./media/XXX/book/tmp/checkpoints --image_dir ~/media/XXX/book/dataset/train_img --output_graph ./media/XXX/book/tmp --how_many_training_steps 1000`


I ask if anyone knows why the dir_path is prepended with `home` directory, then the user `XXX`, and then follows the flagged directive?
I cannot find where in [retrain.py](https://github.com/tensorflow/hub/blob/master/examples/image_retraining/retrain.py) the germane changes should be made.
Line 141 assigns the `dir_name = os.path.basename()` and not a `os.path.dirname(path)`.

So I am trying to ascertain why the dir_path is prepended with the local `home` directory and then the user `/home/XXX/`.

If anyone can assist it would be a great help.
",CapitalZe,b'models:research type:bug',2020-04-01T14:28:48Z,2020-04-08T15:54:57Z,,,,,,,
8348,Dependency addition in BUILD file for /research/tcn,"I kept running into _ImportError_ when running _videos_to_tfrecords_ with _bazel_.
'_util_' should be added to the dependency for _videos_to_tfrecords_

**Correction**
py_binary(
    name = ""videos_to_tfrecords"",
    srcs = [
        ""dataset/videos_to_tfrecords.py"",
    ],
    main = ""dataset/videos_to_tfrecords.py"",
    deps = [
        "":preprocessing"",
        "":util"",
    ],
)
",Vignesh-Nswamy,b'models:archived models:research type:bug',2020-04-01T00:35:46Z,2020-04-26T20:12:00Z,,,,,,,
8343,"[object detection] when train ssd add random_image_scale and some other Photometric Distortions augment, cost a lot gpu memory?","
**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (linux):
- TensorFlow installed from (source or binary): pip install tensorflow 1.14
- TensorFlow version (use command below):
- Python version: python 3.7
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 10
- GPU model and memory: 24G

i use object detection package to train ssd detector (use coco predefine config), i add follow augment to data process pipeline (random_horizontal_flip **random_vertical_flip random_rotation90 random_adjust_brightness random_adjust_contrast random_adjust_saturation random_image_scale** ssd_random_crop), expect model will be more balance to Photometric change and scale change. 
but when i trained the model, the batch size on 4 gpu can only 128 as if not add augment the batch size can be 512, and the 4 gpu is not all used all the time , but some time some gpu use rate is 0 but next time is 100%, why these happen, as augment only processed before model!",mlinxiang,b'models:research type:bug',2020-03-31T12:11:51Z,2020-05-12T17:33:05Z,,,,,,,
8332,model_main.py tries to import unavailable libraries in tensorflow v2,"I'm trying to run models/research/objection_detection/model_main.py. It calls eval_utils.py which contains this line:

slim = tf.contrib.slim

Currently **tensorflow v2 does not have the tf.contrib library** anymore. This is the error I get:

`Traceback (most recent call last):
  File ""model_main.py"", line 26, in <module>
    from object_detection import model_lib
  File ""C:\Users\Me\Documents\Project 2018\07_imagerec\Tensorflow\models\research\object_detection\model_lib.py"", line 27, in <module>
    from object_detection import eval_util
  File ""C:\Users\Me\Documents\Project 2018\07_imagerec\Tensorflow\models\research\object_detection\eval_util.py"", line 35, in <module>
    slim = tf.contrib.slim
AttributeError: module 'tensorflow' has no attribute `'contrib'`

I did however find someone with a similar issue and the solution proposed is to use ""tf_slim"" package. This solve the particular error above but further in hits another error which is also due to calling from tensorflow.contrib

`2020-03-26 22:47:22.437429: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_100.dll
Traceback (most recent call last):
  File ""model_main.py"", line 26, in <module>
    from object_detection import model_lib
  File ""C:\Users\Me\Documents\Project 2018\07_imagerec\Tensorflow\models\research\object_detection\model_lib.py"", line 27, in <module>
    from object_detection import eval_util
  File ""C:\Users\Me\Documents\Project 2018\07_imagerec\Tensorflow\models\research\object_detection\eval_util.py"", line 34, in <module>
    import tf_slim as slim
  File ""C:\Users\Me\AppData\Local\Programs\Python\Python36\lib\site-packages\tf_slim\__init__.py"", line 23, in <module>
    from tf_slim import evaluation
  File ""C:\Users\Me\AppData\Local\Programs\Python\Python36\lib\site-packages\tf_slim\evaluation.py"", line 131, in <module>
    from tensorflow.contrib.training.python.training import evaluation
  File ""C:\Users\Me\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\contrib\training\__init__.py"", line 58, in <module>
    from tensorflow.contrib.training.python.training.hparam import *
  File ""C:\Users\Me\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\contrib\training\python\training\hparam.py"", line 26, in <module>
    from tensorflow.contrib.training.python.training import hparam_pb2
ImportError: cannot import name 'hparam_pb2'`

Is there a workaround or does the model_main.py need to be updated?",john-khgoh,b'models:research type:bug',2020-03-26T14:53:07Z,2020-05-28T04:47:58Z,,,,,,,
8320,"""ncf_test.py"" failed.","<!--
Please make sure that this is a bug. 

As per our GitHub Policy (https://github.com/tensorflow/models/blob/master/ISSUES.md), we only address code bugs, documentation issues, and feature requests on GitHub.

Please go to Stack Overflow (http://stackoverflow.com/questions/tagged/tensorflow-model-garden) for help and support.
-->

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g., Pixel 4, Samsung Galaxy 10) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):pip3
- TensorFlow version (use command below): Tensorflow 2.2.0rc
- Python version: 3.6
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

<!-- 
You can collect some of this information using our environment capture (https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 

1. TensorFlow 1.0
`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 

2. TensorFlow 2.0
`python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`
-->

**Please provide the entire URL of the model you are using?**
<!-- (e.g., https://github.com/tensorflow/models/tree/master/official/nlp/bert) -->
https://github.com/tensorflow/models/blob/master/official/recommendation/ncf_test.py
**Describe the current behavior**
![Screenshot from 2020-03-20 19-19-03](https://user-images.githubusercontent.com/41910134/77169598-c09d3180-6adf-11ea-9661-593b19760e2d.png)

**Describe the expected behavior**
![Screenshot from 2020-03-20 19-17-20](https://user-images.githubusercontent.com/41910134/77169601-c3982200-6adf-11ea-880a-de6ecc5ae72c.png)

**Code to reproduce the issue**
<!-- Provide a reproducible test case that is the bare minimum necessary to generate the problem. -->
python3 official/recommendation/ncf_test.py
**Other info / logs**
<!-- Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. -->
",ayushmankumar7,b'models:official type:bug',2020-03-20T13:50:14Z,2020-04-27T04:43:14Z,,,,,,,
8319,ValueError: Eval batch size 256 is not divisible by 1000,"<!--
Please make sure that this is a bug. 

As per our GitHub Policy (https://github.com/tensorflow/models/blob/master/ISSUES.md), we only address code bugs, documentation issues, and feature requests on GitHub.

Please go to Stack Overflow (http://stackoverflow.com/questions/tagged/tensorflow-model-garden) for help and support.
-->

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04 LTS
- Mobile device (e.g., Pixel 4, Samsung Galaxy 10) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): pip3
- TensorFlow version (use command below): 2.2.0rc
- Python version: 3.6
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

<!-- 
You can collect some of this information using our environment capture (https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 

1. TensorFlow 1.0
`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 

2. TensorFlow 2.0
`python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`
-->

**Please provide the entire URL of the model you are using?**
<!-- (e.g., https://github.com/tensorflow/models/tree/master/official/nlp/bert) -->
https://github.com/tensorflow/models/blob/master/official/recommendation/ncf_keras_main.py
**Describe the current behavior**


**Describe the expected behavior**

**Code to reproduce the issue**
<!-- Provide a reproducible test case that is the bare minimum necessary to generate the problem. -->
python3 official/recommendation/ncf_keras_main.py 

**Other info / logs**
<!-- Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. -->

Traceback (most recent call last):
  File ""official/recommendation/ncf_keras_main.py"", line 562, in <module>
    app.run(main)
  File ""/home/ayushman/.local/lib/python3.6/site-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/home/ayushman/.local/lib/python3.6/site-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""official/recommendation/ncf_keras_main.py"", line 557, in main
    run_ncf(FLAGS)
  File ""official/recommendation/ncf_keras_main.py"", line 246, in run_ncf
    num_users, num_items, _, _, producer = ncf_common.get_inputs(params)
  File ""/home/ayushman/Documents/github/models/official/recommendation/ncf_common.py"", line 61, in get_inputs
    deterministic=FLAGS.seed is not None)
  File ""/home/ayushman/Documents/github/models/official/recommendation/data_preprocessing.py"", line 236, in instantiate_pipeline
    create_data_offline=generate_data_offline)
  File ""/home/ayushman/Documents/github/models/official/recommendation/data_pipeline.py"", line 852, in __init__
    super(BisectionDataConstructor, self).__init__(*args, **kwargs)
  File ""/home/ayushman/Documents/github/models/official/recommendation/data_pipeline.py"", line 414, in __init__
    eval_batch_size, 1 + rconst.NUM_EVAL_NEGATIVES))
ValueError: Eval batch size 256 is not divisible by 1000

",ayushmankumar7,b'models:official type:bug',2020-03-20T13:28:32Z,2020-05-07T07:14:19Z,,,,,,,
8310,Attention OCR does not converge.,"<!--
Please make sure that this is a bug. 

As per our GitHub Policy (https://github.com/tensorflow/models/blob/master/ISSUES.md), we only address code bugs, documentation issues, and feature requests on GitHub.

Please go to Stack Overflow (http://stackoverflow.com/questions/tagged/tensorflow-model-garden) for help and support.

The research models (https://github.com/tensorflow/models/tree/master/research) are a large collection of models implemented in TensorFlow by researchers. They are not officially supported. It is up to the individual researchers to maintain the models and/or provide support on issues and pull requests.
-->

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 19.04
- Mobile device (e.g., Pixel 4, Samsung Galaxy 10) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below):
- Python version: python 3.7
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

<!-- 
You can collect some of this information using our environment capture (https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 

1. TensorFlow 1.0
`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 

2. TensorFlow 2.0
`python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`
-->

**Please provide the entire URL of the model you are using?**
<!-- (e.g., https://github.com/tensorflow/models/tree/master/official/nlp/bert) -->

**Describe the current behavior**

**Describe the expected behavior**

**Code to reproduce the issue**
<!-- Provide a reproducible test case that is the bare minimum necessary to generate the problem. -->

**Other info / logs**
<!-- Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. -->


When I train attention OCR on fsns data, my loss is not going below 30. How does one use fine-tuning and hyperparameter optimization to reduce training loss?

Also, when the same model is trained on my custom num plate images, nearly 8k images, my loss increases and fails to converge. Any inputs on how to overcome this challenge.
",Guneetkaur03,b'models:research type:bug',2020-03-19T12:30:05Z,2020-05-13T23:53:11Z,,,,,,,
8305,tf.contrib related issue with main TF API. Object detection trainining and inference export from checkpoint not working.,"Since yesterday morning 9 AM CEST I was not able to proceed training from checkpoint or even export current checkpoint via export_inference_graph.py. Tested on both TF 1.15 and 2.1.0 and it worked flawlessly up until yesterday. Is there any workaround currently?


**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes.
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux (Colab)
- Mobile device (e.g., Pixel 4, Samsung Galaxy 10) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): 
- TensorFlow version (use command below): 1.15 and 2.1.0
- Python version: 3.6.9
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 
- GPU model and memory:  depends on which one Colab assigns to me

<!-- 
You can collect some of this information using our environment capture (https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 

1. TensorFlow 1.0
`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 

2. TensorFlow 2.0
`python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`
-->

**Please provide the entire URL of the model you are using?**
https://github.com/tensorflow/models/blob/master/research/object_detection/samples/configs/faster_rcnn_inception_v2_pets.config

**Describe the current behavior**
Using /usr/local/lib/python3.6/dist-packages
Finished processing dependencies for object-detection==0.1
env: PYTHONPATH=/content/models/research:/content/models/research/slim
Traceback (most recent call last):
  File ""object_detection/builders/model_builder_test.py"", line 23, in <module>
    from object_detection.builders import model_builder
  File ""/content/models/research/object_detection/builders/model_builder.py"", line 22, in <module>
    from object_detection.builders import box_predictor_builder
  File ""/content/models/research/object_detection/builders/box_predictor_builder.py"", line 20, in <module>
    from object_detection.predictors import convolutional_box_predictor
  File ""/content/models/research/object_detection/predictors/convolutional_box_predictor.py"", line 23, in <module>
    slim = tf.contrib.slim
AttributeError: module 'tensorflow' has no attribute 'contrib'

same with train.py:

Traceback (most recent call last):
  File ""object_detection/legacy/train.py"", line 48, in <module>
    from tensorflow.contrib import framework as contrib_framework
ModuleNotFoundError: No module named 'tensorflow.contrib'

and model_main.py:
Traceback (most recent call last):
  File ""object_detection/model_main.py"", line 26, in <module>
    from object_detection import model_lib
  File ""/content/models/research/object_detection/model_lib.py"", line 27, in <module>
    from object_detection import eval_util
  File ""/content/models/research/object_detection/eval_util.py"", line 40, in <module>
    slim = tf.contrib.slim
AttributeError: module 'tensorflow' has no attribute 'contrib'

and even export_inference_graph.py:

Traceback (most recent call last):
  File ""object_detection/export_inference_graph.py"", line 108, in <module>
    from object_detection import exporter
  File ""/content/models/research/object_detection/exporter.py"", line 20, in <module>
    from tensorflow.contrib.quantize.python import graph_matcher
ModuleNotFoundError: No module named 'tensorflow.contrib'


**Describe the expected behavior**

test the model builder:

object_detection/builders/model_builder_test.py    outputs 17 in TF1(10 in TF2) successful tests


**Code to reproduce the issue**

!python object_detection/builders/model_builder_test.py

**Other info / logs**

",synergy178,b'models:research type:bug',2020-03-18T15:07:31Z,2020-04-14T15:20:41Z,,,,,,,
8300,"When trying to train attention_ocr, I am facing the following issue","In train.py at app.run(), I get the following issue:
/content/python/datasets/data/fsns/train; No such file or directory

![image](https://user-images.githubusercontent.com/43083412/76865558-e7155f80-6888-11ea-9f42-f9ad908d300d.png)
",rajphani,b'models:official type:bug',2020-03-17T14:23:22Z,2020-04-24T18:41:37Z,,,,,,,
8291,ModuleNotFoundError: No module named 'official',"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 (64 bit)
- Mobile device (e.g., Pixel 4, Samsung Galaxy 10) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below): 2.1.0
- Python version: 3.7
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 10.1
- GPU model and memory: GTX 1050ti and 4 GB

I am running below script mentioned [here](https://github.com/tensorflow/models/tree/master/official/vision/image_classification) and it gives me  ModuleNotFoundError: No module named 'official'. 

> python mnist_main.py \
  --model_dir=$MODEL_DIR \
  --data_dir=$DATA_DIR \
  --train_epochs=10 \
  --distribution_strategy=one_device \
  --num_gpus=$NUM_GPUS \
  --download",Eshan-Agarwal,b'models:official type:bug',2020-03-13T15:24:05Z,2020-08-23T12:57:01Z,,,,,,,
8283,transpose does not suppport  quant,"<!--
Please make sure that this is a bug. 

As per our GitHub Policy (https://github.com/tensorflow/models/blob/master/ISSUES.md), we only address code bugs, documentation issues, and feature requests on GitHub.

Please go to Stack Overflow (http://stackoverflow.com/questions/tagged/tensorflow-model-garden) for help and support.

The research models (https://github.com/tensorflow/models/tree/master/research) are a large collection of models implemented in TensorFlow by researchers. They are not officially supported. It is up to the individual researchers to maintain the models and/or provide support on issues and pull requests.
-->

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):16.04
- Mobile device (e.g., Pixel 4, Samsung Galaxy 10) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below):1.14.0
- Python version:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

<!-- 
You can collect some of this information using our environment capture (https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 

1. TensorFlow 1.0
`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 

2. TensorFlow 2.0
`python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`
-->

**Please provide the entire URL of the model you are using?**
<!-- (e.g., https://github.com/tensorflow/models/tree/master/official/nlp/bert) -->

**Describe the current behavior**
toco run failed,axis is much big or negative number
**Describe the expected behavior**
the axis should be (0,3)
**Code to reproduce the issue**
<!-- Provide a reproducible test case that is the bare minimum necessary to generate the problem. -->
tf.squeeze()+tf.transpose() will occur the bug.
if I use tf.squeeze()+tf.reshape() it pass


**Other info / logs**
<!-- Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. -->
2020-03-13 11:19:52.146016: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 2359 operators, 3524 arrays (0 quantized)
2020-03-13 11:19:52.372475: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 2359 operators, 3524 arrays (0 quantized)
2020-03-13 11:19:52.982458: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 342 operators, 672 arrays (1 quantized)
2020-03-13 11:19:52.984716: F tensorflow/lite/toco/graph_transformations/propagate_fixed_sizes.cc:1813] Check failed: axis < input_shape.dimensions_count() (1696750784 vs. 4)
Fatal Python error: Aborted

",sunzhe09,b'models:research type:bug',2020-03-13T11:22:38Z,2020-07-02T09:40:23Z,,,,,,,
8260,All segmentation images are completely black,"I am executing the pascal example.
I can execute all steps, but in visual step, all segmentation images are completely black.

I am processing with GPU, Python 3.5 and Tensorflow-gpu 1.14.0.

I executed:

- ./download_and_convert_voc2012.sh
- ./local_test_mobilenetv2.sh

The image result example:

![000008_image](https://user-images.githubusercontent.com/18166522/76171979-e0436a00-616f-11ea-8f57-20e025cb0625.png)
![000008_prediction](https://user-images.githubusercontent.com/18166522/76171981-e20d2d80-616f-11ea-9d49-5ea935312661.png)

What is the problem?

Thanks
",rafaelmarconiramos,b'models:research stat:awaiting response type:bug',2020-03-08T22:06:38Z,2020-07-02T09:46:23Z,,,,,,,
8246,ImportError: cannot import name 'profiler_v2',"<!--
Please make sure that this is a bug. 

As per our GitHub Policy (https://github.com/tensorflow/models/blob/master/ISSUES.md), we only address code bugs, documentation issues, and feature requests on GitHub.

Please go to Stack Overflow (http://stackoverflow.com/questions/tagged/tensorflow-model-garden) for help and support.
-->

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g., Pixel 4, Samsung Galaxy 10) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): pip3
- TensorFlow version (use command below): 2.1.0
- Python version: 3.6
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

<!-- 
You can collect some of this information using our environment capture (https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 

1. TensorFlow 1.0
`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 

2. TensorFlow 2.0
`python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`
-->

**Please provide the entire URL of the model you are using?**
<!-- (e.g., https://github.com/tensorflow/models/tree/master/official/nlp/bert) -->

**Describe the current behavior**
![Screenshot from 2020-03-05 18-05-22](https://user-images.githubusercontent.com/41910134/75982396-9444bb00-5f0c-11ea-9f7d-6ba878e63723.png)

**Describe the expected behavior**
![Screenshot from 2020-03-05 18-07-15](https://user-images.githubusercontent.com/41910134/75982424-a45c9a80-5f0c-11ea-8315-ead552c513de.png)


**Code to reproduce the issue**
<!-- Provide a reproducible test case that is the bare minimum necessary to generate the problem. -->

**Other info / logs**
<!-- Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. -->
",ayushmankumar7,b'models:official type:bug',2020-03-05T12:41:10Z,2020-05-14T06:13:35Z,,,,,,,
8244,tf.contrib not available in Tensorflow 2.0,"<!--
Please make sure that this is a bug. 

As per our GitHub Policy (https://github.com/tensorflow/models/blob/master/ISSUES.md), we only address code bugs, documentation issues, and feature requests on GitHub.

Please go to Stack Overflow (http://stackoverflow.com/questions/tagged/tensorflow-model-garden) for help and support.

The research models (https://github.com/tensorflow/models/tree/master/research) are a large collection of models implemented in TensorFlow by researchers. They are not officially supported. It is up to the individual researchers to maintain the models and/or provide support on issues and pull requests.
-->

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04
- Mobile device (e.g., Pixel 4, Samsung Galaxy 10) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): Binary
- TensorFlow version (use command below): 2.0 / 2.1.0
- Python version: 3.7.6
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory: No GPU

<!-- 
You can collect some of this information using our environment capture (https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 

1. TensorFlow 1.0
`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 

2. TensorFlow 2.0
`python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`
-->

**Please provide the entire URL of the model you are using?**
<!-- (e.g., https://github.com/tensorflow/models/tree/master/official/nlp/bert) -->
https://github.com/tensorflow/models/blob/master/research/object_detection/predictors/convolutional_box_predictor.py

**Describe the current behavior**
Training SSD Mobilenet with Tensorflow 2.0 breaks due to missing `tf.contrib` API

**Describe the expected behavior**

**Code to reproduce the issue**
<!-- Provide a reproducible test case that is the bare minimum necessary to generate the problem. -->

**Other info / logs**
<!-- Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. -->
",bornhardt,b'models:research type:bug',2020-03-05T08:23:44Z,2020-03-17T20:00:54Z,,,,,,,
8243,ImportError: cannot import name 'profiler_v2' from 'tensorflow.python.profiler' ,"When I Using official/recommendation/ncf_keras_main.py, I got:

Traceback (most recent call last):
  File ""ncf_keras_main.py"", line 37, in <module>
    from official.recommendation import ncf_common
  File ""/home/ruyin/Projects/models/official/recommendation/ncf_common.py"", line 38, in <module>
    from official.utils.misc import keras_utils
  File ""/home/ruyin/Projects/models/official/utils/misc/keras_utils.py"", line 28, in <module>
    from tensorflow.python.profiler import profiler_v2 as profiler
ImportError: cannot import name 'profiler_v2' from 'tensorflow.python.profiler' (/home/ruyin/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/profiler/__init__.py)

what's the reason?

**System information**
Linux Ubuntu 18.04
TensorFlow version: 2.1, installed from binary
Python version: 3.7
CUDA: 10.1
GPU model: 1080Ti
",ruipingyin,b'models:official type:bug',2020-03-05T07:53:22Z,2020-03-06T07:16:15Z,,,,,,,
8237,SSD mobilenet v3 converted to tflite with postprocessing does not work correctly on the device,"The problem is that: I export the [ssd_mobilenet_v3_large_coco](http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v3_large_coco_2019_08_14.tar.gz) model to a graph along with postprocessing.

```
python object_detection/export_tflite_ssd_graph.py \
--pipeline_config_path ssd_mobilenet_v3_large_coco_2019_08_14/pipeline.config \
--trained_checkpoint_prefix ssd_mobilenet_v3_large_coco_2019_08_14/model.ckpt \
--output_directory ssd_mobilenet_v3_large_coco_2019_08_14/tflite \
--add_postprocessing_op=true
```

Next, I get a graph such as a .pb file with post-processing

Then I convert the previously obtained graph into a float tflite model using the following script: 
```
tflite_convert \
--graph_def_file=tflite/tflite_graph.pb \
--output_file=tflite/frozen_inference_graph_test.tflite \
--output_format=TFLITE \
--input_arrays=normalized_input_image_tensor \
--input_shapes=1,320,320,3 \
--output_arrays=""TFLite_Detection_PostProcess,TFLite_Detection_PostProcess:1,TFLite_Detection_PostProcess:2,TFLite_Detection_PostProcess:3"" \
--allow_custom_ops
```
I use the converted model in my Android application, but I don’t get the correct results, always at the output I get strange results:

```
D/DEBUGMODELANSWEAR:  
     SCORES: 0.116135836 CLASS: 14.0
     SCORES: 0.046395004 CLASS: 0.0
     SCORES: 0.045846403 CLASS: 0.0
     SCORES: 0.045446068 CLASS: 0.0
     SCORES: 0.04536411 CLASS: 0.0
     SCORES: 0.04513964 CLASS: 0.0
     SCORES: 0.045139074 CLASS: 0.0
     SCORES: 0.04456976 CLASS: 14.0
     SCORES: 0.044314265 CLASS: 0.0
     SCORES: 0.044303298 CLASS: 0.0
```

Interestingly, I do the same actions with [ssd_mobilenet_v3_small_coco](http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v3_small_coco_2019_08_14.tar.gz), but this model works fine. Can someone tell me what I'm doing wrong and how can I fix this situation


**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Mac
- Mobile device (e.g., Pixel 4, Samsung Galaxy 10) if the issue happens on mobile device: Xiaomi mi 9
- TensorFlow installed from (source or binary):  pip
- TensorFlow version (use command below): v1.14.0-rc1-22-gaf24dc91b5 1.14.0
- Tflite mobile: 'org.tensorflow:tensorflow-lite:0.0.0-nightly'
- Python version: 3
- Bazel version (if compiling from source):  not applicable
- GCC/Compiler version (if compiling from source): not applicable
- CUDA/cuDNN version: not applicable
- GPU model and memory: not applicable

1. TensorFlow 1.0
v1.14.0-rc1-22-gaf24dc91b5 1.14.0
",AndrzejKRK,b'models:research type:bug',2020-03-04T10:35:55Z,2020-03-04T11:03:27Z,,,,,,,
8230,ImportError: No module named absl,"<!--
Please make sure that this is a bug. 

As per our GitHub Policy (https://github.com/tensorflow/models/blob/master/ISSUES.md), we only address code bugs, documentation issues, and feature requests on GitHub.

Please go to Stack Overflow (http://stackoverflow.com/questions/tagged/tensorflow-model-garden) for help and support.
-->

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g., Pixel 4, Samsung Galaxy 10) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below):
- Python version:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

<!-- 
You can collect some of this information using our environment capture (https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 

1. TensorFlow 1.0
`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 

2. TensorFlow 2.0
`python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`
-->

**Please provide the entire URL of the model you are using?**
<!-- (e.g., https://github.com/tensorflow/models/tree/master/official/nlp/bert) -->
https://github.com/tensorflow/models/blob/master/official/recommendation/run.sh

**Describe the current behavior**
![Screenshot from 2020-03-03 20-20-24](https://user-images.githubusercontent.com/41910134/75787376-a4359100-5d8c-11ea-8779-f70d9d5d11e5.png)



**Describe the expected behavior**

**Code to reproduce the issue**
<!-- Provide a reproducible test case that is the bare minimum necessary to generate the problem. -->

**Other info / logs**
<!-- Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. -->
",ayushmankumar7,b'models:official type:bug',2020-03-03T14:52:09Z,2020-03-08T08:39:13Z,,,,,,,
8201,ModuleNotFoundError: No module named 'official',"<!--
Please make sure that this is a bug. 

As per our GitHub Policy (https://github.com/tensorflow/models/blob/master/ISSUES.md), we only address code bugs, documentation issues, and feature requests on GitHub.

Please go to Stack Overflow (http://stackoverflow.com/questions/tagged/tensorflow) for help and support.
-->

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g., Pixel 4, Samsung Galaxy 10) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): pip3
- TensorFlow version (use command below): 2.1.0
- Python version: 3.6
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

<!-- 
You can collect some of this information using our environment capture (https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 

1. TensorFlow 1.0
`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 

2. TensorFlow 2.0
`python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`
-->

**Please provide the entire URL of the model you are using?**
<!-- (e.g., https://github.com/tensorflow/models/tree/master/official/nlp/bert) -->

**Describe the current behavior**
![Screenshot from 2020-02-24 22-25-56](https://user-images.githubusercontent.com/41910134/75345417-b4e49380-58c2-11ea-8ade-c8be6ecbe8f5.png)


**Describe the expected behavior**

**Code to reproduce the issue**
<!-- Provide a reproducible test case that is the bare minimum necessary to generate the problem. -->

**Other info / logs**
<!-- Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. -->
",ayushmankumar7,b'models:official type:bug',2020-02-26T12:36:42Z,2020-02-27T11:30:44Z,,,,,,,
8196,official/benchmark/models/resnet_cifar_main.py name 'absl_app' is not defined,"It caused by this commit https://github.com/tensorflow/models/commit/02af9bb524030d1a133d7380207fbe6776865289 

`from absl import app as absl_app` has been removed, so the test can't run.",chuanqi129,b'models:official type:bug',2020-02-26T07:25:23Z,2020-02-26T16:53:56Z,,,,,,,
8188,Graph After Training is Different Than Pretrained Model's Graph (MobileNetV2),"I have trained an image classification model (MobileNetV2) using train_image_classifier.py and the resulting model's graph is different than the pretrained model given at:

https://github.com/tensorflow/models/tree/master/research/slim/nets/mobilenet

My model has extra nodes such as `Logits/Dropout/dropout_1/Cast`. I have asked this as a question at stackoverflow. See below for graph outputs from tensorboard and list of extra nodes :

Pretrained MobileNetV2's graph:
https://i.stack.imgur.com/CozaP.jpg

My model's graph after training:
https://i.stack.imgur.com/ilJbp.jpg

https://stackoverflow.com/questions/60378750/tf-slim-image-classification-model-nodes-are-different-from-given-pretrained-net

But this seems more like a bug or version mismatch to me. How can I make sure, after training I have the same graph structure as the pretrained model (MobileNetV2)?",menessahin,b'models:research type:bug',2020-02-24T18:33:46Z,2020-05-28T04:56:00Z,,,,,,,
8186,ModuleNotFoundError: No module named 'mock',"<!--
Please make sure that this is a bug. 

As per our GitHub Policy (https://github.com/tensorflow/models/blob/master/ISSUES.md), we only address code bugs, documentation issues, and feature requests on GitHub.

Please go to Stack Overflow (http://stackoverflow.com/questions/tagged/tensorflow) for help and support.
-->

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04 LTS
- Mobile device (e.g., Pixel 4, Samsung Galaxy 10) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): pip3
- TensorFlow version (use command below): 2.1.0
- Python version: 3.6
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 
- GPU model and memory:

<!-- 
You can collect some of this information using our environment capture (https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 

1. TensorFlow 1.0
`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 

2. TensorFlow 2.0
`python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`
-->

**Please provide the entire URL of the model you are using?**
<!-- (https://github.com/tensorflow/models/blob/master/official/recommendation/ncf_test.py) -->

**Describe the current behavior**
![Screenshot from 2020-02-24 22-25-56](https://user-images.githubusercontent.com/41910134/75173550-10910e80-5755-11ea-9239-9e7f41efb333.png)

**Describe the expected behavior**
mock should be included in requirements.txt
**Code to reproduce the issue**
<!-- Provide a reproducible test case that is the bare minimum necessary to generate the problem. -->

**Other info / logs**
<!-- Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. -->
",ayushmankumar7,b'models:official type:bug',2020-02-24T16:59:44Z,2020-02-24T20:09:57Z,,,,,,,
8078,[BUGS] The recent update(1 hr ago) on reserch/slim/net has some problems,"there are some files with 
`from tensorflow.contrib import slim as contrib_slim`
which suggest the tensorflow version used must be < 2.0 since tf2.0 doesnt have the contrib attribute.

and then in the same file compat.v1 is present.
eg:
```
with tf.compat.v1.variable_scope(scope, 'Block17', [net], reuse=reuse):
    with tf.compat.v1.variable_scope('Branch_0'):
```

and there is no compat.v1 for tf versions < 2.0

i came across this in reserch/slim/nets/inception_resnet_v2.py",richardjoy530,b'models:research type:bug',2020-01-22T03:18:28Z,2020-05-15T10:48:56Z,,,,,,,
7975,Possible mismatch between the provided ResNet V1 50 pre-trained ckpt and pb,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: no
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: win10
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.15
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

### Describe the problem

I found that maybe there's a mismatch between the provided ResNet V1 50 pre-trained model ckpt and generated resnet_v1_50.pb.

There's how to reproduce:

```
python .\models\research\slim\export_inference_graph.py --model_name=resnet_v1_50 --output_file=./resnet_v1_50_var.pb
# download ckpt from http://download.tensorflow.org/models/resnet_v1_50_2016_08_28.tar.gz and extract to the working directory
python ~\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow_core\python\tools\freeze_graph.py --input_graph=.\resnet_v1_50_var.pb --input_checkpoint=.\resnet_v1_50.ckpt --input_binary=true --output_graph=.\resnet_v1_50.pb --output_node_names=resnet_v1_50/predictions/Reshape_1
```

### Source code / logs
```
WARNING:tensorflow:From C:\\Users\\v-xiat\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\tools\\freeze_graph.py:127: checkpoint_exists (from 
tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to check for files with this prefix.
W1221 17:41:38.434148 19332 deprecation.py:323] From C:\\Users\\v-xiat\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\tools\\freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to check for files with this prefix.
2019-12-21 17:41:39.003578: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations:  AVX AVX2
To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags.
2019-12-21 17:41:39.022982: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 12. Tune using inter_op_parallelism_threads for best performance.
INFO:tensorflow:Restoring parameters from .\resnet_v1_50.ckpt
I1221 17:41:39.283333 19332 saver.py:1284] Restoring parameters from .\resnet_v1_50.ckpt
Traceback (most recent call last):
  File ""C:\Users\v-xiat\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow_core\python\client\session.py"", line 1365, in _do_call
    return fn(*args)
  File ""C:\Users\v-xiat\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow_core\python\client\session.py"", line 1350, in _run_fn
    target_list, run_metadata)
  File ""C:\Users\v-xiat\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow_core\python\client\session.py"", line 1443, in _call_tf_sessionrun
    run_metadata)
tensorflow.python.framework.errors_impl.InvalidArgumentError: Assign requires shapes of both tensors to match. lhs shape= [1001] rhs shape= [1000]
         [[{{node save/Assign_265}}]]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Users\v-xiat\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow_core\python\training\saver.py"", line 1290, in restore
    {self.saver_def.filename_tensor_name: save_path})
  File ""C:\Users\v-xiat\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow_core\python\client\session.py"", line 956, in run
    run_metadata_ptr)
  File ""C:\Users\v-xiat\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow_core\python\client\session.py"", line 1180, in _run
    feed_dict_tensor, options, run_metadata)
  File ""C:\Users\v-xiat\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow_core\python\client\session.py"", line 1359, in _do_run
    run_metadata)
  File ""C:\Users\v-xiat\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow_core\python\client\session.py"", line 1384, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.InvalidArgumentError: Assign requires shapes of both tensors to match. lhs shape= [1001] rhs shape= [1000]
         [[node save/Assign_265 (defined at Users\v-xiat\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow_core\python\framework\ops.py:1748) ]]

Original stack trace for 'save/Assign_265':
  File ""\Users\\v-xiat\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\tools\\freeze_graph.py"", line 491, in <module>
    run_main()
  File ""\Users\\v-xiat\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\tools\\freeze_graph.py"", line 487, in run_main
    app.run(main=my_main, argv=[sys.argv[0]] + unparsed)
  File ""Users\v-xiat\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow_core\python\platform\app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""Users\v-xiat\AppData\Local\Continuum\anaconda3\lib\site-packages\absl\app.py"", line 299, in run
    _run_main(main, args)
  File ""Users\v-xiat\AppData\Local\Continuum\anaconda3\lib\site-packages\absl\app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""\Users\\v-xiat\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\tools\\freeze_graph.py"", line 486, in <lambda>
    my_main = lambda unused_args: main(unused_args, flags)
  File ""\Users\\v-xiat\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\tools\\freeze_graph.py"", line 378, in main
    flags.saved_model_tags, checkpoint_version)
  File ""\Users\\v-xiat\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\tools\\freeze_graph.py"", line 361, in freeze_graph
    checkpoint_version=checkpoint_version)
  File ""\Users\\v-xiat\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\tools\\freeze_graph.py"", line 190, in freeze_graph_with_def_protos     
    var_list=var_list, write_version=checkpoint_version)
  File ""Users\v-xiat\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow_core\python\training\saver.py"", line 828, in __init__
    self.build()
  File ""Users\v-xiat\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow_core\python\training\saver.py"", line 840, in build
    self._build(self._filename, build_save=True, build_restore=True)
  File ""Users\v-xiat\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow_core\python\training\saver.py"", line 878, in _build
    build_restore=build_restore)
  File ""Users\v-xiat\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow_core\python\training\saver.py"", line 508, in _build_internal
    restore_sequentially, reshape)
  File ""Users\v-xiat\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow_core\python\training\saver.py"", line 350, in _AddRestoreOps
    assign_ops.append(saveable.restore(saveable_tensors, shapes))
  File ""Users\v-xiat\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow_core\python\training\saving\saveable_object_util.py"", line 73, in restore
    self.op.get_shape().is_fully_defined())
  File ""Users\v-xiat\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow_core\python\ops\state_ops.py"", line 227, in assign
    validate_shape=validate_shape)
  File ""Users\v-xiat\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow_core\python\ops\gen_state_ops.py"", line 65, in assign
    use_locking=use_locking, name=name)
  File ""Users\v-xiat\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow_core\python\framework\op_def_library.py"", line 794, in _apply_op_helper
    op_def=op_def)
  File ""Users\v-xiat\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow_core\python\util\deprecation.py"", line 507, in new_func
    return func(*args, **kwargs)
  File ""Users\v-xiat\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow_core\python\framework\ops.py"", line 3357, in create_op
    attrs, op_def, compute_device)
  File ""Users\v-xiat\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow_core\python\framework\ops.py"", line 3426, in _create_op_internal
    op_def=op_def)
  File ""Users\v-xiat\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow_core\python\framework\ops.py"", line 1748, in __init__
    self._traceback = tf_stack.extract_stack()


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\\Users\\v-xiat\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\tools\\freeze_graph.py"", line 491, in <module>
    run_main()
  File ""C:\\Users\\v-xiat\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\tools\\freeze_graph.py"", line 487, in run_main
    app.run(main=my_main, argv=[sys.argv[0]] + unparsed)
  File ""C:\Users\v-xiat\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow_core\python\platform\app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""C:\Users\v-xiat\AppData\Local\Continuum\anaconda3\lib\site-packages\absl\app.py"", line 299, in run
    _run_main(main, args)
  File ""C:\Users\v-xiat\AppData\Local\Continuum\anaconda3\lib\site-packages\absl\app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""C:\\Users\\v-xiat\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\tools\\freeze_graph.py"", line 486, in <lambda>
    my_main = lambda unused_args: main(unused_args, flags)
  File ""C:\\Users\\v-xiat\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\tools\\freeze_graph.py"", line 378, in main
    flags.saved_model_tags, checkpoint_version)
  File ""C:\\Users\\v-xiat\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\tools\\freeze_graph.py"", line 361, in freeze_graph
    checkpoint_version=checkpoint_version)
  File ""C:\\Users\\v-xiat\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\tools\\freeze_graph.py"", line 209, in freeze_graph_with_def_protos  
    saver.restore(sess, input_checkpoint)
  File ""C:\Users\v-xiat\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow_core\python\training\saver.py"", line 1326, in restore
    err, ""a mismatch between the current graph and the graph"")
tensorflow.python.framework.errors_impl.InvalidArgumentError: Restoring from checkpoint failed. This is most likely due to a mismatch between the current graph and the graph from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:

Assign requires shapes of both tensors to match. lhs shape= [1001] rhs shape= [1000]
         [[node save/Assign_265 (defined at Users\v-xiat\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow_core\python\framework\ops.py:1748) ]]

Original stack trace for 'save/Assign_265':
  File ""\Users\\v-xiat\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\tools\\freeze_graph.py"", line 491, in <module>
    run_main()
  File ""\Users\\v-xiat\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\tools\\freeze_graph.py"", line 487, in run_main
    app.run(main=my_main, argv=[sys.argv[0]] + unparsed)
  File ""Users\v-xiat\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow_core\python\platform\app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""Users\v-xiat\AppData\Local\Continuum\anaconda3\lib\site-packages\absl\app.py"", line 299, in run
    _run_main(main, args)
  File ""Users\v-xiat\AppData\Local\Continuum\anaconda3\lib\site-packages\absl\app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""\Users\\v-xiat\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\tools\\freeze_graph.py"", line 486, in <lambda>
    my_main = lambda unused_args: main(unused_args, flags)
  File ""\Users\\v-xiat\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\tools\\freeze_graph.py"", line 378, in main
    flags.saved_model_tags, checkpoint_version)
  File ""\Users\\v-xiat\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\tools\\freeze_graph.py"", line 361, in freeze_graph
    checkpoint_version=checkpoint_version)
  File ""\Users\\v-xiat\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\tools\\freeze_graph.py"", line 190, in freeze_graph_with_def_protos     
    var_list=var_list, write_version=checkpoint_version)
  File ""Users\v-xiat\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow_core\python\training\saver.py"", line 828, in __init__
    self.build()
  File ""Users\v-xiat\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow_core\python\training\saver.py"", line 840, in build
    self._build(self._filename, build_save=True, build_restore=True)
  File ""Users\v-xiat\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow_core\python\training\saver.py"", line 878, in _build
    build_restore=build_restore)
  File ""Users\v-xiat\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow_core\python\training\saver.py"", line 508, in _build_internal
    restore_sequentially, reshape)
  File ""Users\v-xiat\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow_core\python\training\saver.py"", line 350, in _AddRestoreOps
    assign_ops.append(saveable.restore(saveable_tensors, shapes))
  File ""Users\v-xiat\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow_core\python\training\saving\saveable_object_util.py"", line 73, in restore
    self.op.get_shape().is_fully_defined())
  File ""Users\v-xiat\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow_core\python\ops\state_ops.py"", line 227, in assign
    validate_shape=validate_shape)
  File ""Users\v-xiat\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow_core\python\ops\gen_state_ops.py"", line 65, in assign
    use_locking=use_locking, name=name)
  File ""Users\v-xiat\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow_core\python\framework\op_def_library.py"", line 794, in _apply_op_helper
    op_def=op_def)
  File ""Users\v-xiat\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow_core\python\util\deprecation.py"", line 507, in new_func
    return func(*args, **kwargs)
  File ""Users\v-xiat\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow_core\python\framework\ops.py"", line 3357, in create_op
    attrs, op_def, compute_device)
  File ""Users\v-xiat\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow_core\python\framework\ops.py"", line 3426, in _create_op_internal
    op_def=op_def)
  File ""Users\v-xiat\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow_core\python\framework\ops.py"", line 1748, in __init__
    self._traceback = tf_stack.extract_stack()
```
",tigert1998,b'models:research type:bug',2019-12-21T09:44:17Z,2020-06-04T16:59:14Z,,,,,,,
7920,TF Object Detection API incompatible with TF 2.1.X,"### System information
- **What is the top-level directory of the model you are using**: object_detection
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: no
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: MacOS 10.15.1
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: tf-nightly==2.1.0.dev20191203
- **Bazel version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**:

`from object_detection import model_lib_v2`

### Describe the problem
Model training fails in versions of TensorFlow greater than 2.0 due to the removal of the contrib library. The evaluation utils still depend on this module which has officially been deprecated in 2.1.X.

### Source code / logs
```
from object_detection import model_lib_v2
```
```
---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
<ipython-input-2-fe4a9e95a33f> in <module>
----> 1 from object_detection import model_lib_v2

~/.pyenv/versions/3.7.5/envs/fritzml-tf2/lib/python3.7/site-packages/object_detection/model_lib_v2.py in <module>
     24 import tensorflow as tf
     25 
---> 26 from object_detection import eval_util
     27 from object_detection import inputs
     28 from object_detection import model_lib

~/.pyenv/versions/3.7.5/envs/fritzml-tf2/lib/python3.7/site-packages/object_detection/eval_util.py in <module>
     38 from object_detection.utils import visualization_utils as vis_utils
     39 
---> 40 slim = tf.contrib.slim
     41 
     42 # A dictionary of metric names to classes that implement the metric. The classes

AttributeError: module 'tensorflow' has no attribute 'contrib'
```",jamesonthecrow,b'models:research type:bug',2019-12-06T16:22:09Z,2020-07-10T18:15:19Z,,,,,,,
7917,RuntimeError when trying to use the functional API.,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 18.04
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 2.0.0
- **Exact command to reproduce**:

### Describe the problem
I implemented transformer xl using tf.keras.layers with the subclassing api and it works. I also checked the trainable variables and their names are the same as in original implementation. If i want to use my model with the Functional api, i get a RuntimeError. 

### Source code / logs
My code for the Functional api follows the same structure as the code in bert [here](https://github.com/tensorflow/models/blob/master/official/nlp/modeling/networks/transformer_encoder.py). In my transformer xl code i have custom layers and a final big keras layer which connects all the other layers in the call function.

My code for the functional api is shown below:
```
class TransformerXLModel(network.Network):
    def __init__(self, n_token, init_method, init_std, init_range, n_layer, d_model, n_head, d_head, d_inner,
                 ff_activation, untie_r, dropout, dropout_att, mem_len, reuse_len, bi_data, clamp_len,
                 same_length, tf_float, residual, **kwargs):
        initializer = _get_initializer(init_method, init_std, init_range)
        attn_type = 'bi'
        self._self_setattr_tracking = False
        self._config_dict = {
            'n_token': n_token,
            'init_method': init_method,
            'init_std': init_std,
            'init_range': init_range,
            'n_layer': n_layer,
            'd_model': d_model,
            'n_head': n_head,
            'd_head': d_head,
            'd_inner': d_inner,
            'ff_activation': ff_activation,
            'untie_r': untie_r,
            'dropout': dropout,
            'dropout_att': dropout_att,
            'mem_len': mem_len,
            'reuse_len': reuse_len,
            'bi_data': bi_data,
            'clamp_len': clamp_len,
            'same_length': same_length,
            'tf_float': tf_float,
            'residual': residual
        }

        input_word_ids = tf.keras.layers.Input(
            shape=(FLAGS.seq_length,), dtype=tf.int32, name='input_ids')
        segment_ids = tf.keras.layers.Input(
            shape=(FLAGS.seq_length,), dtype=tf.int32, name='segment_ids')
        input_mask = tf.keras.layers.Input(
            shape=(FLAGS.seq_length,), dtype=tf.float32, name='input_mask')
        mems = None
        perm_mask = None
        inps = pack_inputs([input_word_ids, segment_ids, input_mask, mems, perm_mask])

        self.transformerxl_model = TransformerXlLayer(n_layer, d_model, n_head, d_head, d_inner, ff_activation, untie_r,
                                                      n_token, dropout, dropout_att, attn_type, mem_len, reuse_len,
                                                      bi_data, clamp_len, same_length, initializer, tf_float,
                                                      residual, name='transformer')
        output, new_mems, lookup_table = self.transformerxl_model(inps)

        super(TransformerXLModel, self).__init__(
            inputs=[input_word_ids, segment_ids, input_mask, mems, perm_mask],
            outputs=[output],
            **kwargs)

    def get_config(self):
        return self._config_dict

    @classmethod
    def from_config(cls, config, custom_objects=None):
        return cls(**config)
```


```
Traceback (most recent call last):
  File ""checkpoint_converter/checkpoint_conv_tool.py"", line 179, in <module>
    app.run(main=main)
  File ""/home/chris/miniconda3/envs/tensorflow_cpu/lib/python3.7/site-packages/tensorflow_core/python/platform/app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""/home/chris/miniconda3/envs/tensorflow_cpu/lib/python3.7/site-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/home/chris/miniconda3/envs/tensorflow_cpu/lib/python3.7/site-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""checkpoint_converter/checkpoint_conv_tool.py"", line 173, in main
    FLAGS.target_checkpoint,
  File ""checkpoint_converter/checkpoint_conv_tool.py"", line 159, in convert_checkpoint
    model = get_XLnet()
  File ""checkpoint_converter/checkpoint_conv_tool.py"", line 146, in get_XLnet
    FLAGS.same_length, tf_float, FLAGS.residual)
  File ""checkpoint_converter/checkpoint_conv_tool.py"", line 90, in __init__
    output, new_mems, lookup_table = self.transformerxl_model(inps)
  File ""/home/chris/miniconda3/envs/tensorflow_cpu/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py"", line 891, in __call__
    outputs = self.call(cast_inputs, *args, **kwargs)
  File ""/home/chris/PycharmProjects/My_xlnet/modeling.py"", line 664, in call
    non_tgt_mask = -tf.eye(qlen, dtype=self.tf_float)
  File ""/home/chris/miniconda3/envs/tensorflow_cpu/lib/python3.7/site-packages/tensorflow_core/python/ops/linalg_ops.py"", line 169, in eye
    name=name)
  File ""/home/chris/miniconda3/envs/tensorflow_cpu/lib/python3.7/site-packages/tensorflow_core/python/ops/linalg_ops_impl.py"", line 65, in eye
    diag_shape = array_ops.concat((batch_shape, [diag_size]), axis=0)
  File ""/home/chris/miniconda3/envs/tensorflow_cpu/lib/python3.7/site-packages/tensorflow_core/python/util/dispatch.py"", line 180, in wrapper
    return target(*args, **kwargs)
  File ""/home/chris/miniconda3/envs/tensorflow_cpu/lib/python3.7/site-packages/tensorflow_core/python/ops/array_ops.py"", line 1431, in concat
    return gen_array_ops.concat_v2(values=values, axis=axis, name=name)
  File ""/home/chris/miniconda3/envs/tensorflow_cpu/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_array_ops.py"", line 1257, in concat_v2
    ""ConcatV2"", values=values, axis=axis, name=name)
  File ""/home/chris/miniconda3/envs/tensorflow_cpu/lib/python3.7/site-packages/tensorflow_core/python/framework/op_def_library.py"", line 471, in _apply_op_helper
    as_ref=input_arg.is_ref)
  File ""/home/chris/miniconda3/envs/tensorflow_cpu/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py"", line 1365, in internal_convert_n_to_tensor
    ctx=ctx))
  File ""/home/chris/miniconda3/envs/tensorflow_cpu/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py"", line 1264, in internal_convert_to_tensor
    raise RuntimeError(""Attempting to capture an EagerTensor without ""
RuntimeError: Attempting to capture an EagerTensor without building a function.
```
Please help!!! i cant find a solution. It seems that functional api requires graph and not eager tensors. I used the @tf.function decorator without success. I also tried using functional api with the tf.keras.model.Model and the result is exactly the same.

**EDIT**
By watching a tensor when executing both functional and subclassing api i found that the names differ.
Subclassing API: Tensor(""model/transformer/Cast:0"", shape=(1, 128, 1, 1), dtype=float32)
Functional API: Tensor(""Cast:0"", shape=(1, 128, 1, 1), dtype=float32)",christk1,b'models:official type:bug',2019-12-06T13:17:25Z,2020-06-13T04:46:22Z,,,,,,,
7823,Error polling for event status: failed to query event: CUDA_ERROR_ILLEGAL_ADDRESS: an illegal memory access was encountered,"trying to run trasformer in v2 with TF-2.0 stable and branch in models : tf_2_0_rc1(https://github.com/tensorflow/models/tree/tf_2_0_rc1) as per ticket
#7644
with below command:
python transformer_main.py --data_dir=$DATA_DIR --model_dir=$MODEL_DIR --vocab_file=$VOCAB_FILE --param_set=big --bleu_source=$DATA_DIR/newstest2014.en --bleu_ref=$DATA_DIR/newstest2014.de

Got error with below Stack trace:

W1118 07:34:57.648332 140172354287360 util.py:144] Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.decoder_stack.layers.5.2.layer.filter_dense_layer.bias
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.decoder_stack.layers.5.2.layer.output_dense_layer.kernel
W1118 07:34:57.648442 140172354287360 util.py:144] Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.decoder_stack.layers.5.2.layer.output_dense_layer.kernel
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.decoder_stack.layers.5.2.layer.output_dense_layer.bias
W1118 07:34:57.648550 140172354287360 util.py:144] Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.decoder_stack.layers.5.2.layer.output_dense_layer.bias
WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/alpha/guide/checkpoints#loading_mechanics for details.
W1118 07:34:57.648662 140172354287360 util.py:152] A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/alpha/guide/checkpoints#loading_mechanics for details.
2019-11-18 07:34:57.650464: E tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:750] failed to record completion event; therefore, failed to create inter-stream dependency
2019-11-18 07:34:57.650537: I tensorflow/stream_executor/stream.cc:4816] [stream=0x5401120,impl=0x53ffe90] did not memcpy host-to-device; source: 0x7f7b6c055f00
2019-11-18 07:34:57.650560: E tensorflow/stream_executor/stream.cc:332] Error recording event in stream: error recording CUDA event on stream 0x5400b10: CUDA_ERROR_ILLEGAL_ADDRESS: an illegal memory access was encountered; not marking stream as bad, as the Event object may be at fault. Monitor for further errors.
2019-11-18 07:34:57.650586: E tensorflow/stream_executor/cuda/cuda_event.cc:29] Error polling for event status: failed to query event: CUDA_ERROR_ILLEGAL_ADDRESS: an illegal memory access was encountered
2019-11-18 07:34:57.650613: F tensorflow/core/common_runtime/gpu/gpu_event_mgr.cc:273] Unexpected Event status: 1
Fatal Python error: Aborted

Thread 0x00007f7c6b627700 (most recent call first):
  File ""/home/ubuntu/tf2py/lib/python3.5/site-packages/tensorflow_core/python/ops/gen_dataset_ops.py"", line 1141 in delete_iterator
  File ""/home/ubuntu/tf2py/lib/python3.5/site-packages/tensorflow_core/python/data/ops/iterator_ops.py"", line 537 in __del__
Aborted




",tkngoutham,b'models:official stat:awaiting response type:bug',2019-11-18T07:55:06Z,2020-05-10T06:24:34Z,,,,,,,
7822,TypeError: unsupported operand type(s) for *: 'NoneType' and 'int' in keras_utils.py,"trying to run trasformer in v2 with  TF-2.0 stable and branch in models : tf_2_0_rc1(https://github.com/tensorflow/models/tree/tf_2_0_rc1)  as per ticket 
 https://github.com/tensorflow/models/issues/7644 
with below command:
python transformer_main.py --data_dir=$DATA_DIR --model_dir=$MODEL_DIR     --vocab_file=$VOCAB_FILE --param_set=base     --bleu_source=$DATA_DIR/newstest2014.en --bleu_ref=$DATA_DIR/newstest2014.de


Got error with below Stack trace:

Total params: 61,362,176
Trainable params: 61,362,176
Non-trainable params: 0
__________________________________________________________________________________________________
I1118 07:25:13.213394 139963829905152 transformer_main.py:298] Start train iteration at global step:0
Train for 1000 steps
/home/ubuntu/tf2py/lib/python3.5/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  ""Converting sparse IndexedSlices to a dense Tensor of unknown shape. ""
/home/ubuntu/tf2py/lib/python3.5/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  ""Converting sparse IndexedSlices to a dense Tensor of unknown shape. ""
2019-11-18 07:25:42.524686: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
INFO:tensorflow:BenchmarkMetric: {'epoch':0, 'time_taken': 91.634508}
I1118 07:26:44.871305 139963829905152 keras_utils.py:93] BenchmarkMetric: {'epoch':0, 'time_taken': 91.634508}
Traceback (most recent call last):
  File ""official/transformer/v2/transformer_main.py"", line 474, in <module>
    app.run(main)
  File ""/usr/local/lib/python3.5/dist-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/usr/local/lib/python3.5/dist-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""official/transformer/v2/transformer_main.py"", line 463, in main
    _run_task(task)
  File ""official/transformer/v2/transformer_main.py"", line 454, in _run_task
    task.train()
  File ""official/transformer/v2/transformer_main.py"", line 329, in train
    verbose=(2 if flags_obj.enable_time_history else 1))
  File ""/home/ubuntu/tf2py/lib/python3.5/site-packages/tensorflow_core/python/keras/engine/training.py"", line 728, in fit
    use_multiprocessing=use_multiprocessing)
  File ""/home/ubuntu/tf2py/lib/python3.5/site-packages/tensorflow_core/python/keras/engine/training_v2.py"", line 324, in fit
    total_epochs=epochs)
  File ""/home/ubuntu/tf2py/lib/python3.5/site-packages/tensorflow_core/python/keras/engine/training_v2.py"", line 174, in run_one_epoch
    step += 1
  File ""/usr/lib/python3.5/contextlib.py"", line 66, in __exit__
    next(self.gen)
  File ""/home/ubuntu/tf2py/lib/python3.5/site-packages/tensorflow_core/python/keras/engine/training_v2.py"", line 700, in on_batch
    mode, 'end', step, batch_logs)
  File ""/home/ubuntu/tf2py/lib/python3.5/site-packages/tensorflow_core/python/keras/callbacks.py"", line 235, in _call_batch_hook
    batch_hook(batch, logs)
  File ""/home/ubuntu/tf2py/lib/python3.5/site-packages/tensorflow_core/python/keras/callbacks.py"", line 518, in on_train_batch_end
    self.on_batch_end(batch, logs=logs)
  File ""/mnt/data/models/official/utils/misc/keras_utils.py"", line 80, in on_batch_end
    examples_per_second = (self.batch_size * self.log_steps) / elapsed_time
TypeError: unsupported operand type(s) for *: 'NoneType' and 'int'



Note:PARAM_SET is base

",tkngoutham,b'models:official type:bug',2019-11-18T07:49:41Z,2020-05-15T17:33:28Z,,,,,,,
7821,Tensorflow GPU trained .PB file,"Hi Team,

I trained Faster RCNN deep learning model on GCP with GPU and generated the .pb file. Am trying to use trained .pb file in CPU. I am getting errors while reading the .pb file in CPU without gpu. Pls. find the attached error.

![image](https://user-images.githubusercontent.com/9213878/69027700-d3024400-09f5-11ea-8bbf-4979e989c318.png)

Regards
Mohan
",mohanrajmit,b'models:research stalled stat:awaiting response type:bug',2019-11-18T05:53:32Z,2020-09-18T17:17:40Z,,,,,,,
7643,[TF2]'Tensor' object has no attribute '_keras_history'   ,"### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:Linux Ubuntu 16.04)
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**:2.0-GPU
- **CUDA/cuDNN version**:9.6
- **GPU model and memory**:
- **Exact command to reproduce**:





### Problem
in TF2.0 use Keras to save model.h5 ,then load model.h5.

I have saved **model.h5** from **official.nlp.bert_models.py** by use model.save(""model.h5"") .
everything is ok , but when I load the **model.h5** there have some problems.
```python

model =tf.keras.models.load_model('./my_model1.h5', custom_objects={'BertModel':bert_modeling.BertModel})
```

emmmmm, how to solve this problem???? 


### Traceback 
Traceback (most recent call last):
  File ""/Users/lollipop/Documents/tf2g/false_news/test.py"", line 30, in <module>
    model =tf.keras.models.load_model('./my_model1.h5', custom_objects={'BertModel':bert_modeling.BertModel})
  File ""/Users/lollipop/.conda/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/save.py"", line 146, in load_model
    return hdf5_format.load_model_from_hdf5(filepath, custom_objects, compile)
  File ""/Users/lollipop/.conda/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py"", line 168, in load_model_from_hdf5
    custom_objects=custom_objects)
  File ""/Users/lollipop/.conda/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/model_config.py"", line 55, in model_from_config
    return deserialize(config, custom_objects=custom_objects)
  File ""/Users/lollipop/.conda/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/keras/layers/serialization.py"", line 102, in deserialize
    printable_module_name='layer')
  File ""/Users/lollipop/.conda/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/keras/utils/generic_utils.py"", line 191, in deserialize_keras_object
    list(custom_objects.items())))
  File ""/Users/lollipop/.conda/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py"", line 906, in from_config
    config, custom_objects)
  File ""/Users/lollipop/.conda/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py"", line 1852, in reconstruct_from_config
    process_node(layer, node_data)
  File ""/Users/lollipop/.conda/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py"", line 1802, in process_node
    output_index = nest.flatten(output_tensors)[0]._keras_history.node_index
AttributeError: 'Tensor' object has no attribute '_keras_history'

Process finished with exit code 1

",SmileTM,b'models:official type:bug',2019-10-10T10:25:42Z,2020-06-21T18:26:07Z,,,,,,,
7024,Object detection training is not starting as given for coral edge tpu,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",avinash00721,b'comp:lite models:research stat:awaiting model gardener type:bug',2019-06-15T17:38:07Z,2020-03-25T23:02:48Z,,,,,,,
6928,Bug fix of cifar10_eval.py,"line 120: changed from eval_data = FLAGS.eval_data == 'test'
to: eval_data = FLAGS.eval_data
comment: the original code assigns 'true' to eval_data, when the script is being used to evaluate networks on the evaluation set, it DOES NOT load the evaluation set as intended, but actually loads the trainning set (line 105 of cifar10_input.py).",youngleox,b'cla: yes',2019-05-30T20:10:36Z,2019-07-08T20:28:45Z,,,,,,,
6819,Getting an optimized model with TOCO failed,"### System information
- **What is the top-level directory of the model you are using**: tensorflow
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: 1.12.0 (CPU only)
- **Bazel version (if compiling from source)**: 0.19.0
- **CUDA/cuDNN version**: 9.0/7.4
- **GPU model and memory**: GeForce 660M/8 GB RAM
- **Exact command to reproduce**: 

```
bazel run -c opt tensorflow/contrib/lite/toco:toco -- --input_file=D:\tensor\output\tflite_graph.pb --output_file=D:\tensor\output\flutter_model.tflite --inference_type=QUANTIZED_UINT8 --input_format=TENSORFLOW_GRAPHDEF --output_format=TFLITE --input_shapes=1,300,300,3 --input_arrays=normalized_input_image_tensor --output_arrays='TFLite_Detection_PostProcess','TFLite_Detection_PostProcess:1','TFLite_Detection_PostProcess:2','TFLite_Detection_PostProcess:3' --mean_values=128 --std_values=128 --change_concat_input_ranges=false --allow_custom_ops
```

### Describe the problem
My goal is to run a Mobilenet pretrained model on a mobile. I went step by step through the following tutorial, starting from building TF from source:
https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/running_on_mobile_tensorflowlite.md

Everything went quite smoothly or I managed to find some already solved issues. Yet, I have a problem with the last step that is getting the optimized model with TOCO.

### Source code / logs

When I ran the command:

```
bazel run -c opt tensorflow/contrib/lite/toco:toco -- --input_file=D:\tensor\output\tflite_graph.pb --output_file=D:\tensor\output\flutter_model.tflite --inference_type=QUANTIZED_UINT8 --input_format=TENSORFLOW_GRAPHDEF --output_format=TFLITE --input_shapes=1,300,300,3 --input_arrays=normalized_input_image_tensor --output_arrays='TFLite_Detection_PostProcess','TFLite_Detection_PostProcess:1','TFLite_Detection_PostProcess:2','TFLite_Detection_PostProcess:3' --mean_values=128 --std_values=128 --change_concat_input_ranges=false --allow_custom_ops
```

I got the following error:
```
2019-05-18 13:50:34.792006: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1080] Converting unsupported operation: TFLite_Detection_PostProcess
2019-05-18 13:50:34.870333: F tensorflow/contrib/lite/toco/tooling_util.cc:854] Check failed: model.HasArray(output_array) Output array not found: 'TFLite_Detection_PostProcess'
```",abiela,b'comp:lite models:research stat:awaiting response type:bug',2019-05-20T06:02:56Z,2019-07-08T17:44:59Z,,,,,,,
6695,bug fix,,seemuch,b'cla: yes',2019-04-29T20:37:16Z,2019-04-29T20:53:13Z,,,,,,,
6341,Are the object detection evaluation scripts still working for coco dataset?,"Are the evaluation scripts still working for coco dataset, say on model ssd_inception_v2?
https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/oid_inference_and_evaluation.md

I tried the flow above with tfrecord generated by create_coco_tf_record. But it looks like it's quite bumpy, that I have to fix several typo-looking issues in the source code to make it through.

```
object_detection/inference/detection_inference.py:65
-  with tf.gfile.Open(inference_graph_path, 'r') as graph_def_file:
+  with tf.gfile.Open(inference_graph_path, 'rb') as graph_def_file:

object_detection/metrics/offline_eval_map_corloc.py:159
-  input_config = configs['eval_input_config']
+  input_config = configs['eval_input_configs'][0]
```

Finally all image got skipped when computing evaluation measures from tfrecord, because some 'groundtruth_classes' can't be found in annotations.

So how can I evaluate ssd_inception_v2 in model zoo on coco dataset exactly? Do I need to try on Python2? Do I need to try object_detection/legacy/eval.py?",lbingbing,b'models:research type:bug',2019-03-11T13:18:57Z,2020-03-25T23:05:24Z,,,,,,,
6207,[Object detection TFlite] PPN tflite show total wrong result on mobile,"**System information**
* Have I written custom code (as opposed to using a stock example script provided in TensorFlow):N
* OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
* Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: HUAWEI MATE20
* TensorFlow installed from (source or binary):binary
* TensorFlow version (use command below):1.10
* Python version:3.6
* Bazel version (if compiling from source):1.15
* GCC/Compiler version (if compiling from source):1.9
* CUDA/cuDNN version:8.0
* GPU model and memory:16GB

I used object detection API, the ssd_mobilenetV2 is working well including the train, eval ,inference on pc ,and .tflite on phone.
Recently, i try ppn_mobilenetv1, the train and eval is well. The frozen_inference_graph.pb also work well on pc and the results are right. When i convert it to tflite_graph.pb, then convert it to detect.tflite. No errors occur. But when it runs on the mobile, it shows totally wrong results. I Look through the export_tflite_ssd_graph.py and export_inference_graph.py . I wonder how it works well for ssd_mobilenetV2 and wrong for ppn_mobilenetv1 on mobile, and how it works well for ppn_mobilenetv1 on pc and wrong on the mobile. Looking forward to your help.

To reproduce the bug as following:
1.Download the ppn_mobilnetV1 http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v1_ppn_shared_box_predictor_300x300_coco14_sync_2018_07_03.tar.gz
2.Conver it to tflite, no errors occur
```
CONFIG_PATH=../pipeline.config 
CHECKPOINT_PATH=../model.ckpt 
OUTPUT_DIR=../results/	
```
```
python object_detection/export_tflite_ssd_graph.py \ 
--pipeline_config_path $CONFIG_PATH \ 
--trained_checkpoint_prefix $CHECKPOINT_PATH \ 
--output_directory $OUTPUT_DIR \ 
--add_postprocessing_op=true
```
```
bazel-bin/tensorflow/contrib/lite/toco/toco \ 
--input_file=$OUTPUT_DIR/tflite_graph.pb \
--output_file=$OUTPUT_DIR/detect.tflite \ 
--input_shapes=1,300,300,3 \ 
--input_arrays=normalized_input_image_tensor \ 
--output_arrays='TFLite_Detection_PostProcess','TFLite_Detection_PostProcess:1','TFLite_Detection_PostProcess:2','TFLite_Detection_PostProcess:3' \ 
--inference_type=FLOAT \
--allow_custom_ops
```
3. Run it on mobile, i use the tensorflow-lite from tensoflow 1.10",holyhao,b'comp:lite models:research stat:awaiting model gardener type:bug',2019-02-15T06:51:56Z,2020-03-25T23:06:07Z,,,,,,,
5979,object detection predict error ,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
can't show the image 

### Source code / logs

QObject::moveToThread: Current thread (0x7f3a44ba2800) is not the object's thread (0x7f3a4dd7a900).
Cannot move to target thread (0x7f3a44ba2800)

QPixmap: Must construct a QApplication before a QPaintDevice
Aborted (core dumped)

",xxllp,b'models:research stat:awaiting response type:bug',2019-01-02T04:23:08Z,2019-06-10T22:04:31Z,,,,,,,
5920,ssd_mobilenetv2_oidv4 download link not working,"The download link of the ssd_mobilenetv2_oidv4 model (from the Tensorflow detection model zoo page) trained on open images is not working.

Page where the link can be found: https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md

Link: http://download.tensorflow.org/models/object_detection/ssd_mobilenetv2_oidv4_2018_10_30.tar.gz

Error message: 

```
<Error>
<Code>AccessDenied</Code>
<Message>Access denied.</Message>
<Details>
Anonymous caller does not have storage.objects.get access to download.tensorflow.org/models/object_detection/ssd_mobilenetv2_oidv4_2018_10_30.tar.gz.
</Details>
</Error>
```",bocsiboti,b'type:bug',2018-12-17T08:21:53Z,2020-02-19T19:20:21Z,,,,,,,
5914,"interactive_text_analyzer notebook error: ""Key lookahead/cell/cell_0/layer_norm_basic_lstm_cell/kernel not found""","### System information
- **What is the top-level directory of the model you are using**: models/research/syntaxnet/examples/dragnn
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: stock example below
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 18.04
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: ('v1.11.0-0-gc19e29306c', '1.11.0')
- **Bazel version (if compiling from source)**: 0.15.2
- **CUDA/cuDNN version**: 10.0 / 7.3.1.20
- **GPU model and memory**: RTX 2080 ti 11GB
- **Exact command to reproduce**: run 1st cell in: models/research/syntaxnet/examples/dragnn/interactive_text_analyzer.ipynb

### Describe the problem
I am unable to run jupyter notebook ""interactive_text_analyzer.ipynb"", located in models/research/syntaxnet/examples/dragnn. 
It returns the error shown below. can someone advise on how to get the interactive_text_analyzer notebook to run?
`NotFoundError: Key lookahead/cell/cell_0/layer_norm_basic_lstm_cell/kernel not found in checkpoint
	 [[Node: save/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, ..., DT_FLOAT, DT_FLOAT, DT_INT32, DT_INT32, DT_FLOAT], _device=""/job:localhost/replica:0/task:0/device:CPU:0""](_arg_save/Const_0_0, save/RestoreV2/tensor_names, save/RestoreV2/shape_and_slices)]]`
`	 [[Node: save/RestoreV2/_17 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device_incarnation=1, tensor_name=""edge_24_save/RestoreV2"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:GPU:0""]()]`

I saw a reference to using a checkpoint converter ([here](https://github.com/KranthiGV/Pretrained-Show-and-Tell-model/issues/9#issuecomment-366816238)), and ran converter like this:
```
anatolii@ubun:~/models/research/syntaxnet/examples/dragnn$ python2 ~/models/research/syntaxnet/tensorflow/tensorflow/contrib/rnn/python/tools/checkpoint_convert.py ./data/en/segmenter/checkpoint ./data-new/en/segmenter/
2018-12-15 16:54:22.748978: I external/org_tensorflow/tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2018-12-15 16:54:22.930786: I external/org_tensorflow/tensorflow/core/common_runtime/gpu/gpu_device.cc:1356] Found device 0 with properties: 
name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.665
pciBusID: 0000:05:00.0
totalMemory: 10.73GiB freeMemory: 10.03GiB
2018-12-15 16:54:22.930811: I external/org_tensorflow/tensorflow/core/common_runtime/gpu/gpu_device.cc:1435] Adding visible gpu devices: 0
2018-12-15 16:54:23.143174: I external/org_tensorflow/tensorflow/core/common_runtime/gpu/gpu_device.cc:923] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-12-15 16:54:23.143205: I external/org_tensorflow/tensorflow/core/common_runtime/gpu/gpu_device.cc:929]      0 
2018-12-15 16:54:23.143212: I external/org_tensorflow/tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 0:   N 
2018-12-15 16:54:23.143415: I external/org_tensorflow/tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9689 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:05:00.0, compute capability: 7.5)
```
but it results in a small `checkpoint` file 59 bytes long with this content:
```
model_checkpoint_path: "".""
all_model_checkpoint_paths: "".""
```

### Source Code of the notebook cell that's failing:
```
import os
import ipywidgets as widgets
import tensorflow as tf
from IPython import display
from dragnn.protos import spec_pb2
from dragnn.python import graph_builder
from dragnn.python import spec_builder
from dragnn.python import load_dragnn_cc_impl  # This loads the actual op definitions
from dragnn.python import render_parse_tree_graphviz
from dragnn.python import visualization
from google.protobuf import text_format
from syntaxnet import load_parser_ops  # This loads the actual op definitions
from syntaxnet import sentence_pb2
from syntaxnet.ops import gen_parser_ops
from tensorflow.python.platform import tf_logging as logging

def load_model(base_dir, master_spec_name, checkpoint_name):
    # Read the master spec
    master_spec = spec_pb2.MasterSpec()
    with open(os.path.join(base_dir, master_spec_name), ""r"") as f:
        text_format.Merge(f.read(), master_spec)
    spec_builder.complete_master_spec(master_spec, None, base_dir)
    logging.set_verbosity(logging.WARN)  # Turn off TensorFlow spam.

    # Initialize a graph
    graph = tf.Graph()
    with graph.as_default():
        hyperparam_config = spec_pb2.GridPoint()
        builder = graph_builder.MasterBuilder(master_spec, hyperparam_config)
        # This is the component that will annotate test sentences.
        annotator = builder.add_annotation(enable_tracing=True)
        builder.add_saver()  # ""Savers"" can save and load models; here, we're only going to load.

    sess = tf.Session(graph=graph)
    with graph.as_default():
        #sess.run(tf.global_variables_initializer())
        #sess.run('save/restore_all', {'save/Const:0': os.path.join(base_dir, checkpoint_name)})
        checkpointPath = os.path.join(base_dir, checkpoint_name)
        print (""calling saver.restore on"",checkpointPath)
        builder.saver.restore(sess, checkpointPath)
        
    def annotate_sentence(sentence):
        with graph.as_default():
            return sess.run([annotator['annotations'], annotator['traces']],
                            feed_dict={annotator['input_batch']: [sentence]})
    return annotate_sentence

segmenter_model = load_model(""data/en/segmenter"", ""spec.textproto"", ""checkpoint"")
parser_model = load_model(""data/en"", ""parser_spec.textproto"", ""checkpoint"")
```
### Output of the cell:
```
WARNING:tensorflow:tf.op_scope(values, name, default_name) is deprecated, use tf.name_scope(name, default_name, values)
WARNING:tensorflow:tf.op_scope(values, name, default_name) is deprecated, use tf.name_scope(name, default_name, values)
('calling saver.restore on', 'data/en/segmenter/checkpoint')
---------------------------------------------------------------------------
NotFoundError                             Traceback (most recent call last)
<ipython-input-1-6469534a5d58> in <module>()
     48     return annotate_sentence
     49 
---> 50 segmenter_model = load_model(""data/en/segmenter"", ""spec.textproto"", ""checkpoint"")
     51 parser_model = load_model(""data/en"", ""parser_spec.textproto"", ""checkpoint"")

<ipython-input-1-6469534a5d58> in load_model(base_dir, master_spec_name, checkpoint_name)
     40         checkpointPath = os.path.join(base_dir, checkpoint_name)
     41         print (""calling saver.restore on"",checkpointPath)
---> 42         builder.saver.restore(sess, checkpointPath)
     43 
     44     def annotate_sentence(sentence):

/home/anatolii/models/research/syntaxnet/bazel-bin/dragnn/tools/oss_notebook_launcher.runfiles/org_tensorflow/tensorflow/python/training/saver.pyc in restore(self, sess, save_path)
   1800     else:
   1801       sess.run(self.saver_def.restore_op_name,
-> 1802                {self.saver_def.filename_tensor_name: save_path})
   1803 
   1804   @staticmethod

/home/anatolii/models/research/syntaxnet/bazel-bin/dragnn/tools/oss_notebook_launcher.runfiles/org_tensorflow/tensorflow/python/client/session.pyc in run(self, fetches, feed_dict, options, run_metadata)
    898     try:
    899       result = self._run(None, fetches, feed_dict, options_ptr,
--> 900                          run_metadata_ptr)
    901       if run_metadata:
    902         proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)

/home/anatolii/models/research/syntaxnet/bazel-bin/dragnn/tools/oss_notebook_launcher.runfiles/org_tensorflow/tensorflow/python/client/session.pyc in _run(self, handle, fetches, feed_dict, options, run_metadata)
   1133     if final_fetches or final_targets or (handle and feed_dict_tensor):
   1134       results = self._do_run(handle, final_targets, final_fetches,
-> 1135                              feed_dict_tensor, options, run_metadata)
   1136     else:
   1137       results = []

/home/anatolii/models/research/syntaxnet/bazel-bin/dragnn/tools/oss_notebook_launcher.runfiles/org_tensorflow/tensorflow/python/client/session.pyc in _do_run(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)
   1314     if handle is None:
   1315       return self._do_call(_run_fn, feeds, fetches, targets, options,
-> 1316                            run_metadata)
   1317     else:
   1318       return self._do_call(_prun_fn, handle, feeds, fetches)

/home/anatolii/models/research/syntaxnet/bazel-bin/dragnn/tools/oss_notebook_launcher.runfiles/org_tensorflow/tensorflow/python/client/session.pyc in _do_call(self, fn, *args)
   1333         except KeyError:
   1334           pass
-> 1335       raise type(e)(node_def, op, message)
   1336 
   1337   def _extend_graph(self):

NotFoundError: Key lookahead/cell/cell_0/layer_norm_basic_lstm_cell/kernel not found in checkpoint
	 [[Node: save/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, ..., DT_FLOAT, DT_FLOAT, DT_INT32, DT_INT32, DT_FLOAT], _device=""/job:localhost/replica:0/task:0/device:CPU:0""](_arg_save/Const_0_0, save/RestoreV2/tensor_names, save/RestoreV2/shape_and_slices)]]
	 [[Node: save/RestoreV2/_17 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device_incarnation=1, tensor_name=""edge_24_save/RestoreV2"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:GPU:0""]()]]

Caused by op u'save/RestoreV2', defined at:
  File ""/usr/lib/python2.7/runpy.py"", line 174, in _run_module_as_main
    ""__main__"", fname, loader, pkg_name)
  File ""/usr/lib/python2.7/runpy.py"", line 72, in _run_code
    exec code in run_globals
  File ""/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py"", line 16, in <module>
    app.launch_new_instance()
  File ""/usr/local/lib/python2.7/dist-packages/traitlets/config/application.py"", line 658, in launch_instance
    app.start()
  File ""/usr/local/lib/python2.7/dist-packages/ipykernel/kernelapp.py"", line 499, in start
    self.io_loop.start()
  File ""/usr/local/lib/python2.7/dist-packages/tornado/ioloop.py"", line 1073, in start
    handler_func(fd_obj, events)
  File ""/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py"", line 300, in null_wrapper
    return fn(*args, **kwargs)
  File ""/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py"", line 450, in _handle_events
    self._handle_recv()
  File ""/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py"", line 480, in _handle_recv
    self._run_callback(callback, msg)
  File ""/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py"", line 432, in _run_callback
    callback(*args, **kwargs)
  File ""/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py"", line 300, in null_wrapper
    return fn(*args, **kwargs)
  File ""/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py"", line 283, in dispatcher
    return self.dispatch_shell(stream, msg)
  File ""/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py"", line 233, in dispatch_shell
    handler(stream, idents, msg)
  File ""/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py"", line 399, in execute_request
    user_expressions, allow_stdin)
  File ""/usr/local/lib/python2.7/dist-packages/ipykernel/ipkernel.py"", line 208, in do_execute
    res = shell.run_cell(code, store_history=store_history, silent=silent)
  File ""/usr/local/lib/python2.7/dist-packages/ipykernel/zmqshell.py"", line 537, in run_cell
    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)
  File ""/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py"", line 2714, in run_cell
    interactivity=interactivity, compiler=compiler, result=result)
  File ""/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py"", line 2818, in run_ast_nodes
    if self.run_code(code, result):
  File ""/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py"", line 2878, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File ""<ipython-input-1-6469534a5d58>"", line 50, in <module>
    segmenter_model = load_model(""data/en/segmenter"", ""spec.textproto"", ""checkpoint"")
  File ""<ipython-input-1-6469534a5d58>"", line 32, in load_model
    builder.add_saver()  # ""Savers"" can save and load models; here, we're only going to load.
  File ""/home/anatolii/models/research/syntaxnet/bazel-bin/dragnn/tools/oss_notebook_launcher.runfiles/__main__/dragnn/python/graph_builder.py"", line 720, in add_saver
    write_version=saver_pb2.SaverDef.V1)
  File ""/home/anatolii/models/research/syntaxnet/bazel-bin/dragnn/tools/oss_notebook_launcher.runfiles/org_tensorflow/tensorflow/python/training/saver.py"", line 1338, in __init__
    self.build()
  File ""/home/anatolii/models/research/syntaxnet/bazel-bin/dragnn/tools/oss_notebook_launcher.runfiles/org_tensorflow/tensorflow/python/training/saver.py"", line 1347, in build
    self._build(self._filename, build_save=True, build_restore=True)
  File ""/home/anatolii/models/research/syntaxnet/bazel-bin/dragnn/tools/oss_notebook_launcher.runfiles/org_tensorflow/tensorflow/python/training/saver.py"", line 1384, in _build
    build_save=build_save, build_restore=build_restore)
  File ""/home/anatolii/models/research/syntaxnet/bazel-bin/dragnn/tools/oss_notebook_launcher.runfiles/org_tensorflow/tensorflow/python/training/saver.py"", line 835, in _build_internal
    restore_sequentially, reshape)
  File ""/home/anatolii/models/research/syntaxnet/bazel-bin/dragnn/tools/oss_notebook_launcher.runfiles/org_tensorflow/tensorflow/python/training/saver.py"", line 472, in _AddRestoreOps
    restore_sequentially)
  File ""/home/anatolii/models/research/syntaxnet/bazel-bin/dragnn/tools/oss_notebook_launcher.runfiles/org_tensorflow/tensorflow/python/training/saver.py"", line 886, in bulk_restore
    return io_ops.restore_v2(filename_tensor, names, slices, dtypes)
  File ""/home/anatolii/models/research/syntaxnet/bazel-bin/dragnn/tools/oss_notebook_launcher.runfiles/org_tensorflow/tensorflow/python/ops/gen_io_ops.py"", line 1463, in restore_v2
    shape_and_slices=shape_and_slices, dtypes=dtypes, name=name)
  File ""/home/anatolii/models/research/syntaxnet/bazel-bin/dragnn/tools/oss_notebook_launcher.runfiles/org_tensorflow/tensorflow/python/framework/op_def_library.py"", line 787, in _apply_op_helper
    op_def=op_def)
  File ""/home/anatolii/models/research/syntaxnet/bazel-bin/dragnn/tools/oss_notebook_launcher.runfiles/org_tensorflow/tensorflow/python/framework/ops.py"", line 3392, in create_op
    op_def=op_def)
  File ""/home/anatolii/models/research/syntaxnet/bazel-bin/dragnn/tools/oss_notebook_launcher.runfiles/org_tensorflow/tensorflow/python/framework/ops.py"", line 1718, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access

NotFoundError (see above for traceback): Key lookahead/cell/cell_0/layer_norm_basic_lstm_cell/kernel not found in checkpoint
	 [[Node: save/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, ..., DT_FLOAT, DT_FLOAT, DT_INT32, DT_INT32, DT_FLOAT], _device=""/job:localhost/replica:0/task:0/device:CPU:0""](_arg_save/Const_0_0, save/RestoreV2/tensor_names, save/RestoreV2/shape_and_slices)]]
	 [[Node: save/RestoreV2/_17 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device_incarnation=1, tensor_name=""edge_24_save/RestoreV2"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:GPU:0""]()]]
```
",toli-belo,b'type:bug',2018-12-16T01:04:14Z,2020-02-07T18:50:56Z,,,,,,,
5901,Can Not Replicate Transformer Base Bleu Scores,"### System information
- **What is the top-level directory of the model you are using**: /models/official/transformer
- **Have I written custom code** : No
- **OS Platform and Distribution** :Ubuntu 16.04.5 LTS
- **TensorFlow installed from (source or binary)**: Binary
- **TensorFlow version** : v1.12.0-0-ga6d8ffae09 1.12.0
- **CUDA/cuDNN version**: release 9.0, V9.0.176
- **GPU model and memory**: Tesla K40m/12GB
- **Exact command to reproduce**: Official Instructions
- **Bazel version**: N/A

### Describe the problem
I have been trying to replicate models/offical/tensorflow/ **Base**. I followed the official instructions  yet I was faced with two problems:
1- The size of the generated vocabulary was bigger than the one defined in /models/offical/tranformer/model/model_params.py. The program would not work, I fixed it by changing the value in model_params.py to the actual vocabulary size of 33945.
2- The second problem, and the one I could not solve,  is that Blue scores after **10 epochs** are not consistent with what is reported in models/official/tensorflow.  Running, as instructed,  compute_bleu.py gives **case-insensitive** Bleu scores of **26.04** far bellow the ""promised"" **27.7** Bleu for **Base** Transformer.

I have trained **3** models and even though there are fluctuation in Bleu scores these are minimal being the biggest difference **0,1 Bleu**.   

### Source code / logs
python compute_bleu.py --translation=translation.en --reference=test_data/newstest2014.de                                                          
I1212 11:03:35.484694 140343540246272 tf_logging.py:115] Case-insensitive results: 26.038009
I1212 11:03:40.145630 140343540246272 tf_logging.py:115] Case-sensitive results: 25.506699

",rodasoares,b'type:bug',2018-12-12T13:31:14Z,2020-06-21T22:42:20Z,,,,,,,
5899,Unicode error when building ADE20K dataset tf record for deeplab.,"### System information
- **What is the top-level directory of the model you are using**:deeplab
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:Ubuntu16.04
- **TensorFlow installed from (source or binary)**:pip
- **TensorFlow version (use command below)**:1.90 gpu
- **Bazel version (if compiling from source)**:None
- **CUDA/cuDNN version**:9.0,7.1
- **GPU model and memory**:TITAN,1080ti
- **Exact command to reproduce**:bash download_and_convert_ade20k.sh

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
```
>> Converting image 1/20210 shard 0Traceback (most recent call last):
  File ""./build_ade20k_data.py"", line 118, in <module>
    tf.app.run()
  File ""/home/re01/anaconda3/lib/python3.5/site-packages/tensorflow/python/platform/app.py"", line 125, in run
    _sys.exit(main(argv))
  File ""./build_ade20k_data.py"", line 113, in main
    'train', FLAGS.train_image_folder, FLAGS.train_image_label_folder)
  File ""./build_ade20k_data.py"", line 94, in _convert_dataset
    image_data = tf.gfile.FastGFile(image_filename, 'r').read()
  File ""/home/re01/anaconda3/lib/python3.5/site-packages/tensorflow/python/lib/io/file_io.py"", line 132, in read
    pywrap_tensorflow.ReadFromStream(self._read_buf, length, status))
  File ""/home/re01/anaconda3/lib/python3.5/site-packages/tensorflow/python/lib/io/file_io.py"", line 100, in _prepare_value
    return compat.as_str_any(val)
  File ""/home/re01/anaconda3/lib/python3.5/site-packages/tensorflow/python/util/compat.py"", line 107, in as_str_any
    return as_str(value)
  File ""/home/re01/anaconda3/lib/python3.5/site-packages/tensorflow/python/util/compat.py"", line 80, in as_text
    return bytes_or_text.decode(encoding)
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte

```",QuantumLiu,b'type:bug',2018-12-12T06:14:33Z,2019-03-06T13:18:06Z,,,,,,,
5876,"Tensorflow-TensorRT ""Engine buffer is full""","------------------------

### System information
- **What is the top-level directory of the model you are using**: object_detection
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 18.04
- **TensorFlow installed from (source or binary)**: Binary
- **TensorFlow version (use command below)**: 1.12
- **Bazel version (if compiling from source)**: n/a
- **CUDA/cuDNN version**: 10/7
- **GPU model and memory**: Jetson Xavier 16GB shared w/ RAM
- **Exact command to reproduce**: sess.run()

### Describe the problem

I'm trying to convert the frozen weights from faster_rcnn_resnet50_coco to TensorRT and I'm getting the following error when I call session.run():

`2018-12-06 12:21:53.405304: W tensorflow/contrib/tensorrt/kernels/trt_engine_op.cc:260] Engine buffer is full. buffer limit=1, current entries=1, requested batch=100
2018-12-06 12:21:53.405458: W tensorflow/contrib/tensorrt/kernels/trt_engine_op.cc:277] Failed to get engine batch, running native segment for my_trt_op_1`

Is this a bug? If not, what is the cause of this error?

### Source code / logs

Here is a minimal example of the code:

    trt_graph = trt.create_inference_graph(
        input_graph_def=frozen_graph,
        outputs=output_names,
        max_batch_size=1,
        max_workspace_size_bytes=4000000000,
        precision_mode='FP16',
        minimum_segment_size=50
    )
    
    tf_config = tf.ConfigProto()
    tf_config.gpu_options.allow_growth = True
    tf_sess = tf.Session(config=tf_config)
    tf.import_graph_def(trt_graph, name='')\
    scores, boxes, classes, num_detections = tf_sess.run([tf_scores, tf_boxes, tf_classes, tf_num_detections], feed_dict={
        tf_input: image_resized[None, ...]
    })

I'm following [this](https://github.com/NVIDIA-AI-IOT/tf_trt_models/blob/master/examples/classification/classification.ipynb) guide in an NVIDIA repo if you want to see the complete code. Supposedly someone else got the same faster-rcnn working so it should work.",atyshka,b'stat:awaiting model gardener type:bug',2018-12-06T19:04:29Z,2020-01-29T23:00:36Z,,,,,,,
5869,from google3.pyglib import logging,"lstm_object_detection 

error:

  File ""/root/Desktop/models/research/lstm_object_detection/trainer.py"", line 24, in <module>
    from google3.pyglib import logging
ModuleNotFoundError: No module named 'google3'

run:

models/research/lstm_object_detection#     python train.py \
>         --logtostderr \
>         --train_dir=/root/Desktop/models/research/lstm_object_detection/configs \
>         --pipeline_config_path=/root/Desktop/models/research/lstm_object_detection/configs/lstm_ssd_mobilenet_v1_imagenet.config

",zyxcambridge,b'type:bug',2018-12-05T13:59:55Z,2019-07-23T02:35:56Z,,,,,,,
5472,bug fix and python3 compatability,"fixed bug and introduced python3 compatability.
describtion: The automated marco did not account for the output of the tensorflow model enumerated the dictionary keys in the order of the scores. 

Additionally removed the conversion to % ",JonathanJuhl,b'cla: yes',2018-10-11T06:31:02Z,2018-10-11T15:35:58Z,,,,,,,
5264,from object_detection.protos import input_reader_pb2 ImportError: cannot import name 'input_reader_pb2',"Hey. I'm trying to run train.py from _models/research/object_detection/legacy_ but it's throwing this error

`from object_detection.protos import input_reader_pb2
ImportError: cannot import name 'input_reader_pb2'`
 
I did the following as well but no luck

From tensorflow/models/research/
protoc object_detection/protos/*.proto --python_out=.

From tensorflow/models/research/
export PYTHONPATH=$PYTHONPATH:`pwd`:`pwd`/slim

PS: I also run the model_main.py from _models/research/object_detection_ but the same error.",hammadullah125,b'type:bug',2018-09-07T09:51:48Z,2020-08-20T08:24:17Z,,,,,,,
5198,Bug residual bottleneck unit implementation in slim. ,"### System information
- **What is the top-level directory of the model you are using**: N/A
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: N/A
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: N/A
- **TensorFlow installed from (source or binary)**: N/A
- **TensorFlow version (use command below)**: N/A
- **Bazel version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**: N/A

------------------------
### Problem Description
In the documentation of the `bottleneck()` function here: https://github.com/tensorflow/models/blob/master/research/slim/nets/resnet_v2.py

It says the bottleneck unit is a direct adaptation of figure 1)(b) here: https://arxiv.org/pdf/1603.05027.pdf

However, there are differences, for instance, the code has only one batch norm layer whereas the figure has two. ",zeyademam,None,2018-08-28T22:34:54Z,2020-02-07T18:52:32Z,,,,,,,
4987,Bug fix: change dict.iteritems() to dict.items(),`iteritems()` was removed from python3. `items()` does the same functionality so changing it will work in both python2 and python3. The only difference as far as I know is `iteritems()` returns a generator where `items` returns a list. But for this this code it will not make any difference where we are just changing the key of the dict to a string.,TwistedHardware,b'cla: yes',2018-08-02T15:07:12Z,2018-08-03T20:42:57Z,,,,,,,
4927,Fix a couple of bugs and edit spacing,"Bugs fixed:
 * replaced the fizzbuzz call whose signature no longer matched
 * remove the Flatter layer which seems to be buggy

Note: is there a way to include external colabs into tests?",mdanatg,b'cla: yes',2018-07-28T12:42:47Z,2018-07-30T14:02:48Z,,,,,,,
4863,[object_detection] image summary 'Detections_Left_Groundtruth_Right' in eval_metric_ops caused OutOfRangeError,"### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: binary 
- **TensorFlow version (use command below)**: 1.10.0-dev20180721
- **Bazel version (if compiling from source)**: 
- **CUDA/cuDNN version**: 9.0/7
- **GPU model and memory**: Tesla K80
- **Exact command to reproduce**: 

Set `eval_input_reader.num_epochs` of `${PIPELINE_CONFIG}` to `1`, and set `eval_config.num_examples` of `${PIPELINE_CONFIG}` to some value greater than the number of examples in `eval_input_reader`. 

Run
`python3 object_detection/model_main.py --pipeline_config_path=${PIPELINE_CONFIG} --checkpoint_dir=${MODEL_DIR}`

---

After [evaluating all the examples](https://github.com/tensorflow/tensorflow/blob/fa9d8aab41249cfc901338dfcb38cedb7ed1e603/tensorflow/python/training/evaluation.py#L211) in the input source, `Estimator` will [run](https://github.com/tensorflow/tensorflow/blob/fa9d8aab41249cfc901338dfcb38cedb7ed1e603/tensorflow/python/training/evaluation.py#L211) `value_op`s of `eval_metric_ops` to get the `eval_results`.

The `value_op` of `eval_metric_ops['Detections_Left_Groundtruth_Right']` is [`img_summary`](https://github.com/tensorflow/models/blob/85dd5fa4ba406b953550f20269cadddac5303241/research/object_detection/model_lib.py#L390), which is a tensor depending on the input source. Running `img_summary` will cause `OutOfRangeError` if the input source has been exhausted.

[Removing `Detections_Left_Groundtruth_Right` from `eval_metric_ops`](https://github.com/tensorflow/models/blob/85dd5fa4ba406b953550f20269cadddac5303241/research/object_detection/model_lib.py#L388-L390) or save the summary to a `Variable` may be temporary workarounds.",manipopopo,b'stat:awaiting maintainer type:bug',2018-07-22T06:21:01Z,2020-01-30T01:07:11Z,,,,,,,
4662,[vid2depth] tiny readme typos,"Hi Reza and thank you very much for the code. 
2 typos you might want to update in the readme:
- for running the inference, parameter is written ""--video"" instead of ""--kitti_video
- for the wget of the kitti_archives_to_download.txt, link is to the git page. The raw file address instead is 
https://raw.githubusercontent.com/mrharicot/monodepth/master/utils/kitti_archives_to_download.txt

Thank you again.
K. 
",kalanityL,b'type:bug type:docs',2018-07-01T09:36:14Z,2020-02-07T18:52:30Z,,,,,,,
4477,BugFix: python3 compatability,"Wrapped range() with a list, for python3 compatability.

See: https://github.com/tensorflow/models/issues/4455",dori-reichmann,b'cla: yes',2018-06-07T07:30:12Z,2019-12-03T07:09:27Z,,,,,,,
4392,bug report: DEFINE_boolean not work fot tensorflow 1.8,"from tensorflow.python.platform.flags import DEFINE_float, DEFINE_string, DEFINE_integer, DEFINE_boolean, DEFINE_bool

this two functions DEFINE_boolean, DEFINE_bool is not working， when i try to run my code 
in a cmd windows. i can not set boolean parameters by function  DEFINE_boolean or DEFINE_bool.

python XXXX.py --stringTest hello --integerTest 500 --booleanTest False --floatTest 0.95

my code here:
DEFINE_string(""stringTest"", 'StringTest的测试数据', '默认测试数据是 StringTest的测试数据')
DEFINE_integer('integerTest', 20, '默认测试数据是20')
DEFINE_boolean('booleanTest', True, ""默认测试数据是True"")
DEFINE_float('floatTest', 0.65, ""默认测试数据是0.65"")

Flags = tf.app.flags.FLAGS

def main(_):
    str1 = Flags.stringTest
    print(str1, type(str1))
    integer1 = Flags.integerTest
    print(integer1, type(integer1))
    bool1 = Flags.booleanTest
    print(bool1, type(bool1))
    float1 = Flags.floatTest
    print(float1, type(float1))

if __name__ == '__main__':
    tf.app.run()",tnkong,b'stat:awaiting response',2018-05-29T06:18:29Z,2020-02-07T18:45:47Z,,,,,,,
3777,Bug fix on flag name in wide_deep.py,PR #3650 renamed FLAGS.epochs_per_eval to flags.epochs_between_evals; it missed this one,nkconnor,b'cla: yes',2018-03-27T19:14:25Z,2018-03-27T22:03:48Z,,,,,,,
3715,bug？ImportError: No module named mobilenet,"When I try to test the installation of object detection API with commond:
python object_detection/builders/model_builder_test.py
It reports the error: 
    from nets.mobilenet import mobilenet
ImportError: No module named mobilenet

But If I use the same code like:
from nets.nasnet import nasnet
It never report any error.

In my opinion, the mobilenet and nasnet have the same role, can you explain this?

",liu09114,None,2018-03-23T09:06:08Z,2018-03-26T07:08:26Z,,,,,,,
3508,retrained tfslim mobilenet_v1 model does not have input node?,"### System information
- **What is the top-level directory of the model you are using**:
/tensorflow/models/research/slim
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**:
Binary. It's a tensorflow docker image so all below questions are fixed
- **TensorFlow version (use command below)**:
3.5
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**: 9(? not sure, part of the standard docker image)
- **GPU model and memory**: nVidia 1080T
- **Exact command to reproduce**:

nvidia-docker run -v ~/DataSets:/DataSets -v ~/tensorflow:/tensorflow -it gcr.io/tensorflow/tensorflow:latest-gpu-py3 bash
Here DataSets are tfrecords formatted images, tensorflow is the tensorflow

Then within the docker image:
1. train:
DATASET_DIR=/DataSets/
mkdir /tmp/logs
TRAIN_DIR=/tmp/logs
cd /tensorflow/models/research/slim 
python train_image_classifier.py --train_dir=${TRAIN_DIR} --dataset_name=imagenet --dataset_split_name=train --dataset_dir=${DATASET_DIR} --model_name=mobilenet_v1
2. frozen pb:
cd /usr/local/lib/python3.5/dist-packages/tensorflow/python/tools
python freeze_graph.py --input_graph=/tmp/logs/graph.pbtxt --input_checkpoint=/tmp/logs/model.ckpt-102638  --output_graph=/tmp/mobilenet_v1_224_frozen_trained.pb --output_node_names=MobilenetV1/Predictions/Reshape_1

### Describe the problem
This frozen pb does not have input node.
I tried with summary_graph.py, it says ""No inputs spotted."" (the summary_graph.py is on another desktop with python 2.7, but I assume the model once frozen should be portable)
Also tried another tool, it complains the same thing.

",springishere,b'type:bug',2018-03-02T18:30:24Z,2018-11-17T20:10:26Z,,,,,,,
3489,Bug in Tensorflow object detection evaluation,"I want  evaluate my object detection model with mAP (mean average precision). In https://github.com/tensorflow/models/tree/master/research/object_detection/utils/ there is object_detection_evaluation.py that I want to use. 

The Bug is when i change the order of the prediction Boxes, I get a different result.

I am using the example in https://github.com/tensorflow/models/blob/master/research/object_detection/utils/object_detection_evaluation_test.py

I use following for the groundtruth boxes:

pascal_evaluator = object_detection_evaluation.PascalDetectionEvaluator( categories, matching_iou_threshold=0.1)
groundtruth_boxes = np.array([[10, 10, 11, 11]], dtype=float)
groundtruth_class_labels = np.array([1], dtype=int)

groundtruth_is_difficult_list = np.array([False], dtype=bool)
pascal_evaluator.add_single_ground_truth_image_info(
    'img2',
    {
        standard_fields.InputDataFields.groundtruth_boxes: groundtruth_boxes,
        standard_fields.InputDataFields.groundtruth_classes: groundtruth_class_labels,
        standard_fields.InputDataFields.groundtruth_difficult: groundtruth_is_difficult_list
    }
)

and this for the prediction Boxes:

image_key = 'img2'
detected_boxes = np.array(
    [ [100, 100, 220, 220], [10, 10, 11, 11]],
    dtype=float)
detected_class_labels = np.array([1,1], dtype=int)
detected_scores = np.array([0.8, 0.9], dtype=float)
pascal_evaluator.add_single_detected_image_info(image_key, {
    standard_fields.DetectionResultFields.detection_boxes:
        detected_boxes,
    standard_fields.DetectionResultFields.detection_scores:
        detected_scores,
    standard_fields.DetectionResultFields.detection_classes:
        detected_class_labels
})
I print the results with metrics = pascal_evaluator.evaluate() print(metrics)
if I use this prediction Boxes [100, 100, 220, 220], [10, 10, 11, 11] the result is:

{'PASCAL/Precision/mAP@0.1IOU': 1.0, 'PASCAL/PerformanceByCategory/AP@0.1IOU/face': 1.0}

If I use [10, 10, 11, 11], [100, 100, 220, 220] (other Box sequence)

I get following result:

{'PASCAL/Precision/mAP@0.1IOU': 0.5, 'PASCAL/PerformanceByCategory/AP@0.1IOU/face': 0.5}

The results are different, so in my view it is a bug. 

Cheers
Michael 

",mkrech,None,2018-02-28T07:43:12Z,2018-11-17T20:24:03Z,,,,,,,
3477,autoencoder: bugfix in initialization,"Bugfix for initialization in autoencoder, thanks to @cclauss for raising the issue in #1052 
Verified it runs.",swaroopgj,b'cla: yes',2018-02-27T03:43:56Z,2018-04-17T16:11:46Z,,,,,,,
3389,bug correction for dataset import,The iterator to generate batches for imported dataset is missed. ,jind11,b'cla: no',2018-02-16T01:24:25Z,2018-02-16T17:12:53Z,,,,,,,
3356,bugs in faster_rcnn_meta_arch_test_lib.py,"When I was runing the module faster_rcnn_meta_arch_test_lib.py in ubuntu16.04:

#From object_detection/meta_architectures
$ python3 faster_rcnn_meta_arch_test_lib.py

I got 3 errors listed as following:

======================================================================
ERROR: test_loss_with_hard_mining (__main__.FasterRCNNMetaArchTestBase)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""faster_rcnn_meta_arch_test_lib.py"", line 1095, in test_loss_with_hard_mining
    hard_mining=True)
  File ""faster_rcnn_meta_arch_test_lib.py"", line 236, in _build_model
    num_classes=num_classes, is_training=is_training), **common_kwargs)
  File ""faster_rcnn_meta_arch_test_lib.py"", line 108, in _get_model
    **common_kwargs)
  File ""/home/shirhe-lyh/models/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py"", line 325, in __init__
    if is_training and second_stage_batch_size > first_stage_max_proposals:
TypeError: unorderable types: NoneType() > int()

======================================================================
ERROR: test_predict_correct_shapes_in_inference_mode_both_stages (__main__.FasterRCNNMetaArchTestBase)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""faster_rcnn_meta_arch_test_lib.py"", line 375, in test_predict_correct_shapes_in_inference_mode_both_stages
    self._get_box_classifier_features_shape(image_size,
AttributeError: 'FasterRCNNMetaArchTestBase' object has no attribute '_get_box_classifier_features_shape'

======================================================================
ERROR: test_predict_gives_correct_shapes_in_train_mode_both_stages (__main__.FasterRCNNMetaArchTestBase)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""faster_rcnn_meta_arch_test_lib.py"", line 438, in test_predict_gives_correct_shapes_in_train_mode_both_stages
    self._get_box_classifier_features_shape(image_size,
AttributeError: 'FasterRCNNMetaArchTestBase' object has no attribute '_get_box_classifier_features_shape'

----------------------------------------------------------------------
Ran 17 tests in 26.742s

FAILED (errors=3)
",Shirhe-Lyh,None,2018-02-10T02:50:15Z,2018-02-13T17:05:27Z,,,,,,,
3355,Bug in finding smallest side when preprocessing,"### System information
- **What is the top-level directory of the model you are using**: `models/research/slim/preprocessing`
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 14.04.5, Windows 10 x64
- **TensorFlow installed from (source or binary)**: Binary
- **TensorFlow version (use command below)**: `v1.4.0-19-ga52c8d9 1.4.1` (On Ubuntu), `unknown 1.4.0` (On Windows)
- **Bazel version (if compiling from source)**: NA
- **CUDA/cuDNN version**: 8.0.61/6.0.21 (On Ubuntu), No GPU on Windows
- **GPU model and memory**: Titan X (Pascal), 12GB
- **Exact command to reproduce**: 
```python
>>> sess.run(vgg_preprocessing._smallest_size_at_least(height, width, smallest_side),
             feed_dict={height: 1080, width: 1920, smallest_side: 224})
223, 398
```

### Describe the problem
When using the `vgg_preprocessing.preprocess_for_eval`, and by giving the image height value mentioned above, the given output is actually smaller than the `smallest_side` which happens due to precision loss when storing the result of dividing `smallest_side` by `height` in a `float32`.

This bug can also be easily reproduced using Numpy
```python
>>> a = np.float32(224.0 / 1080.0)
>>> (a * 1080.0).astype(np.int32)
223
```
I fixed this by changing [these lines](https://github.com/tensorflow/models/blob/master/research/slim/preprocessing/vgg_preprocessing.py#L249-L251) to all use `to_double`.",erfannoury,b'stat:awaiting model gardener',2018-02-09T22:05:14Z,2020-02-07T18:44:04Z,,,,,,,
3345,Bug in beginners tutorial using premade_estimator.py,"### System information
- **What is the top-level directory of the model you are using**:
 C:\Python3\Lib\site-packages\tensorflow\models\samples\core\get_started
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Windows 10
- **TensorFlow installed from (source or binary)**:
Binary
- **TensorFlow version (use command below)**:
1.5.0
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
V8.0.60
- **GPU model and memory**:
GT635m 4GB
- **Exact command to reproduce**:
python3 premade_estimator.py

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
When parsing the host variable in client.py the variable returned conatins a trailing semi-colon resulting in the port number reasiing an error since it's taken as a literal:
 "" ValueError: invalid literal for int() with base 10: '3128;' ""
### Source code / logs
```
   C:\Python3\Lib\site-packages\tensorflow\models\samples\core\get_started>py premade_estimator.py
    Downloading data from http://download.tensorflow.org/data/iris_training.csv
    Traceback (most recent call last):
      File ""C:\Python3\lib\http\client.py"", line 798, in _get_hostport
        port = int(host[i+1:])
    ValueError: invalid literal for int() with base 10: '3128;'
    
    During handling of the above exception, another exception occurred:
    
    Traceback (most recent call last):
      File ""premade_estimator.py"", line 88, in <module>
        tf.app.run(main)
      File ""C:\Python3\lib\site-packages\tensorflow\python\platform\app.py"", line 124, in run
        _sys.exit(main(argv))
      File ""premade_estimator.py"", line 34, in main
        (train_x, train_y), (test_x, test_y) = iris_data.load_data()
      File ""C:\Python3\Lib\site-packages\tensorflow\models\samples\core\get_started\iris_data.py"", line 19, in load_data
        train_path, test_path = maybe_download()
      File ""C:\Python3\Lib\site-packages\tensorflow\models\samples\core\get_started\iris_data.py"", line 12, in maybe_download
        train_path = tf.keras.utils.get_file(TRAIN_URL.split('/')[-1], TRAIN_URL)
      File ""C:\Python3\lib\site-packages\tensorflow\python\keras\_impl\keras\utils\data_utils.py"", line 238, in get_file
        urlretrieve(origin, fpath, dl_progress)
      File ""C:\Python3\lib\urllib\request.py"", line 188, in urlretrieve
        with contextlib.closing(urlopen(url, data)) as fp:
      File ""C:\Python3\lib\urllib\request.py"", line 163, in urlopen
        return opener.open(url, data, timeout)
      File ""C:\Python3\lib\urllib\request.py"", line 466, in open
        response = self._open(req, data)
      File ""C:\Python3\lib\urllib\request.py"", line 484, in _open
        '_open', req)
      File ""C:\Python3\lib\urllib\request.py"", line 444, in _call_chain
        result = func(*args)
      File ""C:\Python3\lib\urllib\request.py"", line 1282, in http_open
        return self.do_open(http.client.HTTPConnection, req)
      File ""C:\Python3\lib\urllib\request.py"", line 1223, in do_open
        h = http_class(host, timeout=req.timeout, **http_conn_args)
      File ""C:\Python3\lib\http\client.py"", line 762, in __init__
        (self.host, self.port) = self._get_hostport(host, port)
      File ""C:\Python3\lib\http\client.py"", line 803, in _get_hostport
        raise InvalidURL(""nonnumeric port: '%s'"" % host[i+1:])
    http.client.InvalidURL: nonnumeric port: '3128;'

```",muhammedchand,b'stat:awaiting model gardener',2018-02-08T17:22:38Z,2018-02-20T19:52:37Z,,,,,,,
3302,bugs while decoding,"Description about the System

1. OS: Windows 10
2. Ram: 4GB DDR3
3. GPU: AMD Radeon 8 series(2GB)
4. Tensorflow Version :1.0.0
5. python version: 3.5


Description about the issue:

While decoding the files cloned from the tensorflow/models (eng-french) it get successfully cloned as well as the WMT files also gets downloaded.
After training when i am decoding the same it says..
![new](https://user-images.githubusercontent.com/29627340/35717129-451134b2-0803-11e8-94ef-1b2728128ed8.PNG)
Giving a wrong output with some bugs in it.
Please, Do describe me what actually the problem is and the solution to the same.",Sammyreus,b'stat:awaiting response',2018-02-02T04:56:18Z,2018-09-29T04:30:46Z,,,,,,,
3218,bugfix type mismatch tf.float32 != tf.int32 (fixes #2774),This fixes the bug described in https://github.com/tensorflow/models/issues/2774,davidenitti,b'cla: yes',2018-01-22T18:26:21Z,2019-11-24T23:44:10Z,,,,,,,
3217,bugfix type mismatch tf.float32 != tf.int32 (fixes #2774),"it fixes the bug discussed at https://github.com/tensorflow/models/issues/2774
TypeError: x and y must have the same dtype, got tf.float32 != tf.int32",davidenitti,b'cla: no',2018-01-22T17:23:16Z,2018-01-22T18:17:40Z,,,,,,,
3186,Bugs in the usage of i ?,"https://github.com/tensorflow/models/blob/9325ea8feb5458d0ba2046a0134c305fd92e82a5/tutorials/rnn/ptb/reader.py#L124

i  in line 124 does not equal to i in line 120. 
Actually,  i(line 124) = i (line 120) + 1 , thus , i think,  it's not longer  "" a **word-level prediction** experiments "" with lstm.",morning-wind,None,2018-01-18T05:31:19Z,2018-01-21T23:11:07Z,,,,,,,
3179,KeyError for groundtruth_classes running eval.py,"### System information
- **What is the top-level directory of the model you are using**: ssd_mobilenet_v1 latest
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: ubuntu 16.04
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: 1.4.0
- **Bazel version (if compiling from source)**: 0.9.0
- **CUDA/cuDNN version**: 9.0 / 7
- **GPU model and memory**: NVIDIA GTX 1050 4GB (6.1 capability) 
- **Exact command to reproduce**:

i got a pascal-voc based dataset for hands. From that i  successfully created the csv and tfrecord files.
I got around 5000 training images with 10000 labels and around 800 testing images with 2000 labels.
The csv looks like this (so should be alright):
```
filename,width,height,class,xmin,ymin,xmax,ymax
VOC2007_518.jpg,375,500,hand,299,274,333,309
VOC2007_518.jpg,375,500,hand,337,198,376,236
```

My only class is ""hand"", therefore my label map looks like:
```
item {
  id: 1
  name: 'hand'
}
```
in eval.py i added:
`os.environ['CUDA_VISIBLE_DEVICES'] = '-1'`
to run it on CPU, but deleting this line does not solve the problem

parallel to training (which seems to run successful) i try to run the evaluation job like:
```
python object_detection/eval.py \
--logtostderr \
--pipeline_config_path= /home/gustav/workspace/training_hands/model/ssd_mobilehandsnet.config \
--checkpoint_dir=/home/gustav/workspace/training_hands/model/train \   
--eval_dir=/home/gustav/workspace/training_hands/model/eval
```

and got following error right in the beginning:
```
WARNING:root:image 0 does not have groundtruth difficult flag specified
Traceback (most recent call last):
  File ""object_detection/eval.py"", line 135, in <module>
    tf.app.run()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 48, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""object_detection/eval.py"", line 131, in main
    FLAGS.checkpoint_dir, FLAGS.eval_dir)
  File ""/home/gustav/workspace/tensorflow/models/research/object_detection/evaluator.py"", line 210, in evaluate
    save_graph_dir=(eval_dir if eval_config.save_graph else ''))
  File ""/home/gustav/workspace/tensorflow/models/research/object_detection/eval_util.py"", line 381, in repeated_checkpoint_run
    save_graph_dir)
  File ""/home/gustav/workspace/tensorflow/models/research/object_detection/eval_util.py"", line 269, in _run_checkpoint_once
    image_id=batch, groundtruth_dict=result_dict)
  File ""/home/gustav/workspace/tensorflow/models/research/object_detection/utils/object_detection_evaluation.py"", line 167, in add_single_ground_truth_image_info
    standard_fields.InputDataFields.groundtruth_classes]
KeyError: 'groundtruth_classes'
```

So i printed out the groundtruth_dict which causes the problem, and it looks like this:
```
('groundtruth_dict= ', {'original_image': array([[[[64, 68, 80],
         [66, 70, 82],
         [62, 66, 78],
         ...,
         [12, 16, 15],
         [12, 16, 15],
         [17, 21, 20]],

        [[63, 67, 79],
         [66, 70, 82],
         [61, 65, 77],
         ...,
         [13, 17, 16],
         [13, 17, 16],
         [17, 21, 20]],

        [[62, 66, 78],
         [66, 70, 82],
         [62, 66, 78],
         ...,
         [15, 19, 18],
         [14, 18, 17],
         [18, 22, 21]],

        ...,

        [[97, 83, 82],
         [85, 71, 70],
         [84, 70, 67],
         ...,
         [32, 36, 37],
         [26, 30, 31],
         [27, 31, 32]],

        [[94, 80, 79],
         [86, 72, 71],
         [90, 76, 73],
         ...,
         [30, 34, 35],
         [22, 26, 27],
         [27, 31, 32]],

        [[87, 73, 72],
         [85, 71, 70],
         [97, 83, 80],
         ...,
         [28, 32, 33],
         [18, 22, 23],
         [23, 27, 28]]]], dtype=uint8), 'groundtruth_is_crowd': array([], dtype=bool), 'groundtruth_area': array([], dtype=float32), 'detection_boxes': array([[  3.7222574, 243.85812  , 107.565025 , 424.56796  ],
       [ 11.711642 , 323.64343  , 105.015625 , 500.       ],
       [278.89868  , 458.30972  , 342.8926   , 497.58078  ],
       [  3.8873253,  29.537014 ,  97.22421  , 239.43376  ],
       [ 35.484375 , 428.64963  , 166.29593  , 499.3997   ],
       [252.70572  , 315.68005  , 361.17697  , 437.46945  ],
       [199.74017  , 268.7957   , 218.25183  , 287.99872  ],
       [ 27.835133 , 323.57385  ,  42.138878 , 341.12427  ],
       [262.94836  , 459.0676   , 324.5173   , 497.0951   ],
       [ 30.12121  , 352.18933  ,  42.691647 , 366.9404   ],
       [195.73451  , 346.0745   , 222.67781  , 369.47473  ],
       [182.75648  , 349.4227   , 203.51555  , 368.03787  ],
       [216.14795  , 268.55164  , 239.84476  , 289.22177  ],
       [213.16508  , 347.17734  , 239.56981  , 369.95773  ],
       [196.84222  , 321.86615  , 222.91957  , 343.78122  ],
       [198.60518  , 296.3402   , 221.77362  , 317.35907  ],
       [182.73792  , 323.54163  , 204.73431  , 343.42215  ],
       [212.7839   , 319.90427  , 240.82404  , 343.36578  ],
       [180.62373  , 296.06586  , 200.99411  , 315.83798  ],
       [338.9445   , 348.37943  , 359.15344  , 367.71082  ],
       [234.88895  , 349.16602  , 259.0071   , 370.33292  ],
       [303.46356  , 457.30545  , 364.08194  , 497.49954  ],
       [215.08684  , 240.73073  , 238.43745  , 261.50558  ],
       [145.5085   , 326.44092  , 157.93738  , 338.1567   ],
       [ 83.43828  , 271.63446  ,  98.896355 , 286.15344  ],
       [199.06071  , 241.57281  , 217.82936  , 260.41003  ],
       [140.45529  , 295.98352  , 157.77802  , 310.67267  ],
       [233.60094  , 320.17004  , 260.29773  , 343.26422  ],
       [182.35611  , 269.01178  , 198.91292  , 287.86884  ],
       [181.20068  , 372.96698  , 201.5161   , 393.46417  ],
       [300.68942  , 407.16644  , 359.04584  , 464.96985  ],
       [139.66115  , 444.37216  , 159.07675  , 479.99152  ],
       [ 23.430836 , 397.88272  ,  44.162247 , 422.06415  ],
       [ 21.100252 , 294.047    ,  42.38389  , 314.4236   ],
       [236.31688  , 243.0964   , 258.58383  , 261.66235  ],
       [280.3447   , 407.4605   , 292.8006   , 420.21317  ],
       [299.36264  , 378.95526  , 314.73883  , 393.8552   ],
       [215.91156  , 295.24384  , 241.68756  , 317.32587  ],
       [160.2216   , 293.39374  , 180.43195  , 310.80597  ],
       [104.38906  , 423.31558  , 119.70608  , 449.4095   ],
       [ 28.486263 , 373.89478  ,  45.667873 , 392.93118  ],
       [218.15582  , 216.69876  , 238.20929  , 235.54846  ],
       [ 83.59404  , 397.43365  ,  98.18858  , 419.92328  ],
       [234.9742   , 294.39795  , 259.99747  , 315.69208  ],
       [ 40.300983 , 420.2927   ,  60.01407  , 446.76932  ],
       [ 83.4634   , 300.71408  ,  98.52754  , 313.43674  ],
       [299.78403  , 351.60342  , 317.20264  , 366.65198  ],
       [338.4315   , 373.68985  , 359.32492  , 394.76834  ],
       [166.14731  , 325.57693  , 184.81743  , 340.32037  ],
       [ 44.711205 , 397.67593  ,  61.83229  , 420.33655  ],
       [257.01343  , 350.76517  , 278.36444  , 369.43997  ],
       [158.12172  , 445.21902  , 178.86504  , 480.0696   ],
       [262.4441   , 433.15714  , 275.50058  , 447.81937  ],
       [235.62439  , 269.40042  , 260.34317  , 289.5497   ],
       [216.74083  , 372.85437  , 239.18875  , 395.69507  ],
       [104.77659  , 272.44052  , 120.63016  , 287.7762   ],
       [320.54465  , 352.04922  , 339.21588  , 368.14398  ],
       [335.92252  , 398.19324  , 358.44922  , 421.3909   ],
       [ 58.603916 , 358.8482   ,  70.879425 , 371.98077  ],
       [141.1541   , 271.51678  , 160.22408  , 288.35416  ],
       [165.6901   , 377.2134   , 182.83548  , 393.69647  ],
       [297.67566  , 322.5592   , 319.34927  , 341.68277  ],
       [219.46007  , 191.31029  , 236.61574  , 210.29526  ],
       [261.85358  , 406.24994  , 275.86523  , 420.3969   ],
       [201.52548  , 218.10652  , 218.98857  , 235.7868   ],
       [ 61.601517 , 419.59647  ,  81.58215  , 449.02356  ],
       [259.13358  , 191.19864  , 275.70117  , 210.28836  ],
       [196.6504   , 370.98364  , 219.95567  , 395.11862  ],
       [ 37.326405 , 444.67273  ,  60.239902 , 478.10492  ],
       [ 64.34091  , 272.268    ,  81.0081   , 286.43555  ],
       [239.10269  , 190.63756  , 256.7139   , 209.62975  ],
       [ 84.614586 , 219.65251  , 100.4486   , 234.34676  ],
       [164.96635  , 400.28537  , 179.88608  , 420.6667   ],
       [236.52635  , 449.33408  , 259.5564   , 475.5281   ],
       [276.8998   , 356.08392  , 338.37222  , 413.64206  ],
       [104.9978   , 399.731    , 116.69384  , 418.34628  ],
       [320.3317   , 111.434006 , 338.71234  , 131.7356   ],
       [ 81.85569  , 420.5974   ,  99.61256  , 449.95294  ],
       [237.63846  , 217.76233  , 258.50333  , 235.64027  ],
       [150.84442  , 381.60397  , 163.33492  , 394.88397  ],
       [336.49493  , 293.7339   , 358.86316  , 315.8196   ],
       [316.99408  , 322.72513  , 339.50522  , 341.49857  ],
       [147.58536  , 403.13043  , 160.26057  , 421.39246  ],
       [ 59.55451  , 445.28403  ,  82.34845  , 480.91904  ],
       [124.00205  , 246.3231   , 143.39198  , 263.2262   ],
       [259.49414  , 163.86137  , 276.08868  , 184.64775  ],
       [338.4011   , 107.287674 , 356.83478  , 129.8463   ],
       [ 64.310234 , 398.55325  ,  81.488144 , 421.8755   ],
       [ 81.583664 , 444.8386   , 101.344795 , 482.3399   ],
       [105.01828  , 194.82852  , 119.77269  , 210.081    ],
       [ 36.95982  , 213.85706  ,  63.16913  , 236.14496  ],
       [337.48508  , 322.28442  , 359.05057  , 341.78952  ],
       [ 25.420755 , 164.07928  ,  40.073856 , 183.27313  ],
       [279.17184  , 379.42944  , 294.5789   , 393.39044  ],
       [316.2293   , 295.75665  , 341.90454  , 317.5249   ],
       [104.77272  , 167.66571  , 119.54046  , 183.84103  ],
       [254.92526  , 319.55164  , 280.5428   , 343.57095  ],
       [240.45943  , 163.13182  , 257.80908  , 185.5624   ],
       [ 86.57174  , 194.65358  , 101.57887  , 209.33946  ],
       [201.43233  , 191.00928  , 217.96552  , 209.88242  ]],
      dtype=float32), 'groundtruth_classes': array([1, 1]), 'groundtruth_group_of': array([], dtype=int64), 'detection_classes': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'groundtruth_boxes': array([[329.     , 185.     , 364.     , 222.     ],
       [228.00002, 142.     , 255.     , 169.     ]], dtype=float32), 'detection_scores': array([0.28857195, 0.27300978, 0.26126269, 0.26062793, 0.2579368 ,
       0.2562737 , 0.25593358, 0.25527725, 0.25475922, 0.25462022,
       0.25362423, 0.25343668, 0.25324154, 0.25309741, 0.25304952,
       0.2525339 , 0.25238705, 0.25216657, 0.25213185, 0.25187644,
       0.25182185, 0.25181577, 0.25178105, 0.25142857, 0.2514179 ,
       0.25129703, 0.2512553 , 0.25114852, 0.25109357, 0.25099254,
       0.25076938, 0.25071684, 0.25066367, 0.25060827, 0.2504932 ,
       0.25044683, 0.25038907, 0.2503281 , 0.25016046, 0.25004968,
       0.25001392, 0.24997473, 0.2499705 , 0.24986933, 0.24985579,
       0.24971655, 0.24966986, 0.24957949, 0.24955411, 0.2495341 ,
       0.24944127, 0.24943528, 0.24927019, 0.24923873, 0.24902871,
       0.24901138, 0.2489826 , 0.248974  , 0.24894503, 0.24888656,
       0.24886039, 0.24881014, 0.24875696, 0.2486437 , 0.248637  ,
       0.24848294, 0.24847926, 0.2484746 , 0.2484148 , 0.2483988 ,
       0.24838823, 0.24836443, 0.24826829, 0.2482202 , 0.24818836,
       0.24814872, 0.24807507, 0.24805978, 0.24801467, 0.24799332,
       0.24793899, 0.24792199, 0.24777597, 0.24773791, 0.2475662 ,
       0.24744678, 0.24743527, 0.24741969, 0.24732958, 0.24732772,
       0.24732672, 0.24732575, 0.24726531, 0.24718814, 0.24705447,
       0.24699058, 0.24694735, 0.24692817, 0.24681918, 0.24681872],
      dtype=float32), 'key': 'VOC2007_348.jpg', 'groundtruth_difficult': array([], dtype=int64)})
('standard_fields.InputDataFields.groundtruth_classes= ', 'groundtruth_classes')
WARNING:root:image 0 does not have groundtruth difficult flag specified
('groundtruth_dict= ', {})
```

Could it be that there is something wrong with the Int / Float formating of my data?",gustavz,b'stat:awaiting model gardener type:bug',2018-01-17T14:03:01Z,2019-09-03T15:33:15Z,,,,,,,
3161,"TypeError: x and y must have the same dtype, got tf.float32 != tf.int32","i am learning the tensorflow object detection api.i can train model normally using the train.py script,but when i use the eval.py script to evaluate it,some wrong happend.
python eval.py --logtostderr \
> --checkpoint_dir=train_log \
> --eval_dir=eval_log \
> --pipeline_config_path=ssd_mobilenet_v1_coco.config 
INFO:tensorflow:depth of additional conv before box predictor: 0
INFO:tensorflow:depth of additional conv before box predictor: 0
INFO:tensorflow:depth of additional conv before box predictor: 0
INFO:tensorflow:depth of additional conv before box predictor: 0
INFO:tensorflow:depth of additional conv before box predictor: 0
INFO:tensorflow:depth of additional conv before box predictor: 0
Traceback (most recent call last):
  File ""eval.py"", line 168, in <module>
    tf.app.run()
  File ""/usr/local/lib/python3.4/dist-packages/tensorflow/python/platform/app.py"", line 48, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""eval.py"", line 164, in main
    FLAGS.checkpoint_dir, FLAGS.eval_dir)
  File ""/home/yj/tensorflow3/models/research/object_detection/evaluator.py"", line 142, in evaluate
    ignore_groundtruth=eval_config.ignore_groundtruth)
  File ""/home/yj/tensorflow3/models/research/object_detection/evaluator.py"", line 61, in _extract_prediction_tensors
    detections = model.postprocess(prediction_dict)
  File ""/home/yj/tensorflow3/models/research/object_detection/meta_architectures/ssd_meta_arch.py"", line 405, in postprocess
    class_predictions_without_background)
  File ""/home/yj/tensorflow3/models/research/object_detection/builders/post_processing_builder.py"", line 94, in score_converter_fn
    scaled_logits = tf.divide(logits, logit_scale, name='scale_logits')
  File ""/usr/local/lib/python3.4/dist-packages/tensorflow/python/ops/math_ops.py"", line 309, in divide
    return DivideDelegateWithName(x, name) / y
  File ""/usr/local/lib/python3.4/dist-packages/tensorflow/python/ops/math_ops.py"", line 294, in __truediv__
    return _truediv_python3(self.x, y, self.name)
  File ""/usr/local/lib/python3.4/dist-packages/tensorflow/python/ops/math_ops.py"", line 981, in _truediv_python3
    (x_dtype, y_dtype))
TypeError: x and y must have the same dtype, got tf.float32 != tf.int32

my tf version is 1.4.0,python3.4,cpu,thanks",jimo123,b'type:bug',2018-01-14T02:04:28Z,2020-04-10T18:38:17Z,,,,,,,
3155,"Performance issues : Speed is very slow, around .8 seconds per frame on pre-trained model","I am using the pre-trained model ""ssd_mobilenet_v1_coco_2017_11_17"" and the results for object detection for vehicles is pretty good. However, the performance is extremely slow and hence I am unable to use it for my purpose. I resized the image to a smaller one and even chopped the horizon from the image so that the detection is faster, but it doesnt seem to help. Is this a known issue? Any suggestions here",MeghaMaheshwari,b'type:bug',2018-01-12T19:22:46Z,2020-02-07T18:43:51Z,,,,,,,
3143,Feature Request: Freeze capability NasNet-A-Large Checkpoint on a CPU,"### System information
- **What is the top-level directory of the model you are using**:
https://storage.googleapis.com/download.tensorflow.org/models/nasnet-a_large_04_10_2017.tar.gz

- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
Yes (see below)

- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
== cat /etc/issue ===============================================
Linux steelers.steelersnet 4.14.11-200.fc26.x86_64 #1 SMP Wed Jan 3 13:58:53 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux
VERSION=""26 (Workstation Edition)""
VERSION_ID=26
REDHAT_BUGZILLA_PRODUCT_VERSION=26
REDHAT_SUPPORT_PRODUCT_VERSION=26
- **TensorFlow installed from (source or binary)**:
source
- **TensorFlow version (use command below)**:
== tensorflow import ============================================
tf.VERSION = 1.4.0
tf.GIT_VERSION = v1.3.0-rc1-5312-g8a4d849691
tf.COMPILER_VERSION = v1.3.0-rc1-5312-g8a4d849691
Sanity check: array([1], dtype=int32)

$ python3 -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""
2018-01-10 22:56:18.576633: I tensorflow/core/platform/s3/aws_logging.cc:53] Initializing Curl library
/usr/lib64/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
v1.3.0-rc1-6922-ga77096897f 1.5.0-rc0

- **Bazel version (if compiling from source)**:
$ bazel version
Build label: 0.8.1- (@non-git)
Build target: bazel-out/k8-opt/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Wed Dec 6 22:56:54 2017 (1512601014)
Build timestamp: 1512601014
Build timestamp as int: 1512601014

- **CUDA/cuDNN version**:
Not Applicable
- **GPU model and memory**:
Not Applicable
- **Exact command to reproduce**:
See below

### Describe the problem

The NasNet-A-Large trained checkpoint advertised [here](https://github.com/tensorflow/models/tree/master/research/slim#pre-trained-models) and downloadable from [here](https://storage.googleapis.com/download.tensorflow.org/models/nasnet-a_large_04_10_2017.tar.gz) appears to be only freezeable for a GPU.  Attempts to freeze it with a CPU generates errors.  There is an apparent incapatibility here between NHWC and NCHW data formats.

Using pretrained models on a CPU is expected and should be a usable feature.

### Source code / logs

```python
$ ipython3
Python 3.6.3 (default, Oct  9 2017, 12:11:29) 
Type 'copyright', 'credits' or 'license' for more information
IPython 6.2.1 -- An enhanced Interactive Python. Type '?' for help.

In [1]: import tensorflow as tf
   ...: import tensorflow.contrib.slim as slim
   ...: import numpy as np
   ...: 
   ...: import sys
   ...: sys.path.append(""/usr/local/src/tensorflow/models/research/slim"")
   ...: from nets.nasnet.nasnet import build_nasnet_large, nasnet_large_arg_scop
   ...: e
   ...: height = 299
   ...: width = 299
   ...: channels = 3
   ...: FREEZE_DIR = ""./models/build_freeze_graphs""
   ...: # Create graph
   ...: X = tf.placeholder(tf.float32, shape=[None, height, width, channels])
   ...: with slim.arg_scope(nasnet_large_arg_scope()):
   ...:     logits, end_points = build_nasnet_large(X, num_classes=1001,is_train
   ...: ing=False)
   ...: softmax = end_points[""Predictions""]
   ...: saver = tf.train.Saver()
   ...: X_test = np.ones((1,299,299,3))  # a fake image
   ...: 
   ...: # Execute graph
   ...: with tf.Session() as sess:
   ...:     saver.restore(sess, FREEZE_DIR + ""/nasnet-a_large_04_10_2017-model.c
   ...: kpt"")
   ...:     tf.train.write_graph(sess.graph_def, FREEZE_DIR, 'nasnet-a_large.pbt
   ...: xt')
   ...:     
2018-01-10 23:15:42.496988: I tensorflow/core/platform/s3/aws_logging.cc:53] Initializing Curl library
/usr/lib64/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
INFO:tensorflow:Restoring parameters from ./models/build_freeze_graphs/nasnet-a_large_04_10_2017-model.ckpt

In [2]: 

```

```bash
$ python3 /usr/local/src/tensorflow/tensorflow/tensorflow/python/tools/freeze_graph.py --input_graph ./nasnet-a_large.pbtxt --input_checkpoint ./nasnet-a_large_04_10_2017-model.ckpt --output_node_names final_layer/predictions --output_graph ./frozen_nasnet-a_large.pb
2018-01-11 03:48:11.933436: I tensorflow/core/platform/s3/aws_logging.cc:53] Initializing Curl library
/usr/lib64/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Converted 1546 variables to const ops.
```


```python

$ ipython3
Python 3.6.3 (default, Oct  9 2017, 12:11:29) 
Type 'copyright', 'credits' or 'license' for more information
IPython 6.2.1 -- An enhanced Interactive Python. Type '?' for help.

In [1]: TF_SRC_DIR = ""/usr/local/src/tensorflow""
   ...: TF_TF_SRC_DIR = TF_SRC_DIR + ""/tensorflow""
   ...: TF_MODELS_SRC_DIR = TF_SRC_DIR + ""/models""
   ...: TF_EXAMPLES_DIR = TF_TF_SRC_DIR + ""/tensorflow/examples""
   ...: 

In [2]: import importlib.util
   ...: import sys
   ...: 
   ...: # Load TF retrain module
   ...: spec = importlib.util.spec_from_file_location(""retrain"", TF_EXAMPLES_DIR
   ...:  + ""/image_retraining/retrain.py"")
   ...: retrain = importlib.util.module_from_spec(spec)
   ...: spec.loader.exec_module(retrain)
   ...: 
2018-01-11 04:11:22.152580: I tensorflow/core/platform/s3/aws_logging.cc:53] Initializing Curl library
/usr/lib64/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters

In [3]: DATA_DIR = ""./data/processed""
   ...: IMAGE_DIR = DATA_DIR + ""/JPG/Train""
   ...: ARCHITECTURE = ""nasnet-a_large""
   ...: 

In [4]: class C:
   ...:     pass
   ...: 
   ...: retrain.FLAGS = C()
   ...: 
   ...: retrain.FLAGS.architecture = ARCHITECTURE
   ...: retrain.FLAGS.bottleneck_dir = DATA_DIR + '/' + ARCHITECTURE + ""/bottlen
   ...: ecks""
   ...: retrain.FLAGS.eval_step_interval = 200
   ...: retrain.FLAGS.final_tensor_name = ""final_result""
   ...: retrain.FLAGS.flip_left_right = False
   ...: retrain.FLAGS.how_many_training_steps = 20000
   ...: retrain.FLAGS.image_dir = IMAGE_DIR
   ...: retrain.FLAGS.intermediate_output_graphs_dir = DATA_DIR + '/' + ARCHITEC
   ...: TURE + ""/intermed_output_graphs""
   ...: retrain.FLAGS.intermediate_store_frequency = 0
   ...: retrain.FLAGS.learning_rate = 0.005
   ...: retrain.FLAGS.model_dir = DATA_DIR + ""/models""
   ...: retrain.FLAGS.output_graph = DATA_DIR + '/' + ARCHITECTURE + ""/output_gr
   ...: aph.pb""
   ...: retrain.FLAGS.output_labels = DATA_DIR + '/' + ARCHITECTURE + ""/output_l
   ...: abels.txt""
   ...: retrain.FLAGS.print_misclassified_test_images = False
   ...: retrain.FLAGS.random_brightness = 0
   ...: retrain.FLAGS.random_crop = 0
   ...: retrain.FLAGS.random_scale = 0
   ...: retrain.FLAGS.summaries_dir = DATA_DIR + '/' + ARCHITECTURE + ""/retrain_
   ...: logs""
   ...: retrain.FLAGS.test_batch_size = -1
   ...: retrain.FLAGS.testing_percentage = 10
   ...: retrain.FLAGS.train_batch_size = 100
   ...: retrain.FLAGS.validation_batch_size = 100
   ...: retrain.FLAGS.validation_percentage = 10
   ...: 
   ...: 

In [5]: def create_model_info(architecture):
   ...:     return {
   ...:       'data_url': ""localhost:12345/fake/path/frozen_nasnet-a_large.pb"",
   ...:       'bottleneck_tensor_name': ""final_layer/dropout/Identity:0"",
   ...:       'bottleneck_tensor_size': 4032,
   ...:       'input_width': 299,
   ...:       'input_height': 299,
   ...:       'input_depth': 3,
   ...:       'resized_input_tensor_name': ""Placeholder:0"",
   ...:       'model_file_name': ""frozen_nasnet-a_large.pb"",
   ...:       'input_mean': 128,
   ...:       'input_std': 128,
   ...:       'quantize_layer': False,
   ...:   }
   ...: 
   ...: retrain.create_model_info = create_model_info
   ...: 

In [6]: retrain.main(None)
Not extracting or downloading files, model already present in disk
Model path:  ./data/processed/models/frozen_nasnet-a_large.pb
INFO:tensorflow:Looking for images in 'Iceberg'
INFO:tensorflow:Looking for images in 'NotIceberg'
INFO:tensorflow:Creating bottleneck at ./data/processed/nasnet-a_large/bottlenecks/Iceberg/1475-e8b76fb7.jpg_nasnet-a_large.txt
---------------------------------------------------------------------------
InvalidArgumentError                      Traceback (most recent call last)
~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py in _do_call(self, fn, *args)
   1349     try:
-> 1350       return fn(*args)
   1351     except errors.OpError as e:

~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py in _run_fn(session, feed_dict, fetch_list, target_list, options, run_metadata)
   1328                                    feed_dict, fetch_list, target_list,
-> 1329                                    status, run_metadata)
   1330 

~/.local/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py in __exit__(self, type_arg, value_arg, traceback_arg)
    472             compat.as_text(c_api.TF_Message(self.status.status)),
--> 473             c_api.TF_GetCode(self.status.status))
    474     # Delete the underlying status object from memory otherwise it stays alive

InvalidArgumentError: ConcatOp : Dimensions of inputs should match: shape[0] = [1,75,75,42] vs. shape[2] = [1,42,75,75]
	 [[Node: cell_stem_0/cell_output/concat = _MklConcatV2[N=4, T=DT_FLOAT, Tidx=DT_INT32, _kernel=""MklOp"", _device=""/job:localhost/replica:0/task:0/device:CPU:0""](cell_stem_0/comb_iter_1/combine/add, cell_stem_0/comb_iter_2/combine/add, cell_stem_0/comb_iter_3/combine/add, cell_stem_0/comb_iter_4/combine/add, cell_17/split/split_dim, DMT/_121, DMT/_122, cell_stem_0/comb_iter_3/combine/add:1, DMT/_123, DMT/_124)]]

During handling of the above exception, another exception occurred:

InvalidArgumentError                      Traceback (most recent call last)
/usr/local/src/tensorflow/tensorflow/tensorflow/examples/image_retraining/retrain.py in create_bottleneck_file(bottleneck_path, image_lists, label_name, index, image_dir, category, sess, jpeg_data_tensor, decoded_image_tensor, resized_input_tensor, bottleneck_tensor)
    381         sess, image_data, jpeg_data_tensor, decoded_image_tensor,
--> 382         resized_input_tensor, bottleneck_tensor)
    383   except Exception as e:

/usr/local/src/tensorflow/tensorflow/tensorflow/examples/image_retraining/retrain.py in run_bottleneck_on_image(sess, image_data, image_data_tensor, decoded_image_tensor, resized_input_tensor, bottleneck_tensor)
    316   bottleneck_values = sess.run(bottleneck_tensor,
--> 317                                {resized_input_tensor: resized_input_values})
    318   bottleneck_values = np.squeeze(bottleneck_values)

~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py in run(self, fetches, feed_dict, options, run_metadata)
    894       result = self._run(None, fetches, feed_dict, options_ptr,
--> 895                          run_metadata_ptr)
    896       if run_metadata:

~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py in _run(self, handle, fetches, feed_dict, options, run_metadata)
   1127       results = self._do_run(handle, final_targets, final_fetches,
-> 1128                              feed_dict_tensor, options, run_metadata)
   1129     else:

~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py in _do_run(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)
   1343       return self._do_call(_run_fn, self._session, feeds, fetches, targets,
-> 1344                            options, run_metadata)
   1345     else:

~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py in _do_call(self, fn, *args)
   1362           pass
-> 1363       raise type(e)(node_def, op, message)
   1364 

InvalidArgumentError: ConcatOp : Dimensions of inputs should match: shape[0] = [1,75,75,42] vs. shape[2] = [1,42,75,75]
	 [[Node: cell_stem_0/cell_output/concat = _MklConcatV2[N=4, T=DT_FLOAT, Tidx=DT_INT32, _kernel=""MklOp"", _device=""/job:localhost/replica:0/task:0/device:CPU:0""](cell_stem_0/comb_iter_1/combine/add, cell_stem_0/comb_iter_2/combine/add, cell_stem_0/comb_iter_3/combine/add, cell_stem_0/comb_iter_4/combine/add, cell_17/split/split_dim, DMT/_121, DMT/_122, cell_stem_0/comb_iter_3/combine/add:1, DMT/_123, DMT/_124)]]

Caused by op 'cell_stem_0/cell_output/concat', defined at:
  File ""/usr/bin/ipython3"", line 11, in <module>
    sys.exit(start_ipython())
  File ""/usr/lib/python3.6/site-packages/IPython/__init__.py"", line 125, in start_ipython
    return launch_new_instance(argv=argv, **kwargs)
  File ""/usr/lib/python3.6/site-packages/traitlets/config/application.py"", line 658, in launch_instance
    app.start()
  File ""/usr/lib/python3.6/site-packages/IPython/terminal/ipapp.py"", line 356, in start
    self.shell.mainloop()
  File ""/usr/lib/python3.6/site-packages/IPython/terminal/interactiveshell.py"", line 480, in mainloop
    self.interact()
  File ""/usr/lib/python3.6/site-packages/IPython/terminal/interactiveshell.py"", line 471, in interact
    self.run_cell(code, store_history=True)
  File ""/usr/lib/python3.6/site-packages/IPython/core/interactiveshell.py"", line 2728, in run_cell
    interactivity=interactivity, compiler=compiler, result=result)
  File ""/usr/lib/python3.6/site-packages/IPython/core/interactiveshell.py"", line 2856, in run_ast_nodes
    if self.run_code(code, result):
  File ""/usr/lib/python3.6/site-packages/IPython/core/interactiveshell.py"", line 2910, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File ""<ipython-input-6-c66df78b6d6a>"", line 1, in <module>
    retrain.main(None)
  File ""/usr/local/src/tensorflow/tensorflow/tensorflow/examples/image_retraining/retrain.py"", line 1024, in main
    create_model_graph(model_info))
  File ""/usr/local/src/tensorflow/tensorflow/tensorflow/examples/image_retraining/retrain.py"", line 291, in create_model_graph
    model_info['resized_input_tensor_name'],
  File ""/home/rick/.local/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py"", line 316, in new_func
    return func(*args, **kwargs)
  File ""/home/rick/.local/lib/python3.6/site-packages/tensorflow/python/framework/importer.py"", line 548, in import_graph_def
    op_def=op_def)
  File ""/home/rick/.local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 3160, in create_op
    op_def=op_def)
  File ""/home/rick/.local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 1617, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access

InvalidArgumentError (see above for traceback): ConcatOp : Dimensions of inputs should match: shape[0] = [1,75,75,42] vs. shape[2] = [1,42,75,75]
	 [[Node: cell_stem_0/cell_output/concat = _MklConcatV2[N=4, T=DT_FLOAT, Tidx=DT_INT32, _kernel=""MklOp"", _device=""/job:localhost/replica:0/task:0/device:CPU:0""](cell_stem_0/comb_iter_1/combine/add, cell_stem_0/comb_iter_2/combine/add, cell_stem_0/comb_iter_3/combine/add, cell_stem_0/comb_iter_4/combine/add, cell_17/split/split_dim, DMT/_121, DMT/_122, cell_stem_0/comb_iter_3/combine/add:1, DMT/_123, DMT/_124)]]


During handling of the above exception, another exception occurred:

RuntimeError                              Traceback (most recent call last)
<ipython-input-6-c66df78b6d6a> in <module>()
----> 1 retrain.main(None)

/usr/local/src/tensorflow/tensorflow/tensorflow/examples/image_retraining/retrain.py in main(_)
   1063                         FLAGS.bottleneck_dir, jpeg_data_tensor,
   1064                         decoded_image_tensor, resized_image_tensor,
-> 1065                         bottleneck_tensor, FLAGS.architecture)
   1066 
   1067     # Add the new layer that we'll be training.

/usr/local/src/tensorflow/tensorflow/tensorflow/examples/image_retraining/retrain.py in cache_bottlenecks(sess, image_lists, image_dir, bottleneck_dir, jpeg_data_tensor, decoded_image_tensor, resized_input_tensor, bottleneck_tensor, architecture)
    486             sess, image_lists, label_name, index, image_dir, category,
    487             bottleneck_dir, jpeg_data_tensor, decoded_image_tensor,
--> 488             resized_input_tensor, bottleneck_tensor, architecture)
    489 
    490         how_many_bottlenecks += 1

/usr/local/src/tensorflow/tensorflow/tensorflow/examples/image_retraining/retrain.py in get_or_create_bottleneck(sess, image_lists, label_name, index, image_dir, category, bottleneck_dir, jpeg_data_tensor, decoded_image_tensor, resized_input_tensor, bottleneck_tensor, architecture)
    428                            image_dir, category, sess, jpeg_data_tensor,
    429                            decoded_image_tensor, resized_input_tensor,
--> 430                            bottleneck_tensor)
    431   with open(bottleneck_path, 'r') as bottleneck_file:
    432     bottleneck_string = bottleneck_file.read()

/usr/local/src/tensorflow/tensorflow/tensorflow/examples/image_retraining/retrain.py in create_bottleneck_file(bottleneck_path, image_lists, label_name, index, image_dir, category, sess, jpeg_data_tensor, decoded_image_tensor, resized_input_tensor, bottleneck_tensor)
    383   except Exception as e:
    384     raise RuntimeError('Error during processing file %s (%s)' % (image_path,
--> 385                                                                  str(e)))
    386   bottleneck_string = ','.join(str(x) for x in bottleneck_values)
    387   with open(bottleneck_path, 'w') as bottleneck_file:

RuntimeError: Error during processing file ./data/processed/JPG/Train/Iceberg/1475-e8b76fb7.jpg (ConcatOp : Dimensions of inputs should match: shape[0] = [1,75,75,42] vs. shape[2] = [1,42,75,75]
	 [[Node: cell_stem_0/cell_output/concat = _MklConcatV2[N=4, T=DT_FLOAT, Tidx=DT_INT32, _kernel=""MklOp"", _device=""/job:localhost/replica:0/task:0/device:CPU:0""](cell_stem_0/comb_iter_1/combine/add, cell_stem_0/comb_iter_2/combine/add, cell_stem_0/comb_iter_3/combine/add, cell_stem_0/comb_iter_4/combine/add, cell_17/split/split_dim, DMT/_121, DMT/_122, cell_stem_0/comb_iter_3/combine/add:1, DMT/_123, DMT/_124)]]

Caused by op 'cell_stem_0/cell_output/concat', defined at:
  File ""/usr/bin/ipython3"", line 11, in <module>
    sys.exit(start_ipython())
  File ""/usr/lib/python3.6/site-packages/IPython/__init__.py"", line 125, in start_ipython
    return launch_new_instance(argv=argv, **kwargs)
  File ""/usr/lib/python3.6/site-packages/traitlets/config/application.py"", line 658, in launch_instance
    app.start()
  File ""/usr/lib/python3.6/site-packages/IPython/terminal/ipapp.py"", line 356, in start
    self.shell.mainloop()
  File ""/usr/lib/python3.6/site-packages/IPython/terminal/interactiveshell.py"", line 480, in mainloop
    self.interact()
  File ""/usr/lib/python3.6/site-packages/IPython/terminal/interactiveshell.py"", line 471, in interact
    self.run_cell(code, store_history=True)
  File ""/usr/lib/python3.6/site-packages/IPython/core/interactiveshell.py"", line 2728, in run_cell
    interactivity=interactivity, compiler=compiler, result=result)
  File ""/usr/lib/python3.6/site-packages/IPython/core/interactiveshell.py"", line 2856, in run_ast_nodes
    if self.run_code(code, result):
  File ""/usr/lib/python3.6/site-packages/IPython/core/interactiveshell.py"", line 2910, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File ""<ipython-input-6-c66df78b6d6a>"", line 1, in <module>
    retrain.main(None)
  File ""/usr/local/src/tensorflow/tensorflow/tensorflow/examples/image_retraining/retrain.py"", line 1024, in main
    create_model_graph(model_info))
  File ""/usr/local/src/tensorflow/tensorflow/tensorflow/examples/image_retraining/retrain.py"", line 291, in create_model_graph
    model_info['resized_input_tensor_name'],
  File ""/home/rick/.local/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py"", line 316, in new_func
    return func(*args, **kwargs)
  File ""/home/rick/.local/lib/python3.6/site-packages/tensorflow/python/framework/importer.py"", line 548, in import_graph_def
    op_def=op_def)
  File ""/home/rick/.local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 3160, in create_op
    op_def=op_def)
  File ""/home/rick/.local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 1617, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access

InvalidArgumentError (see above for traceback): ConcatOp : Dimensions of inputs should match: shape[0] = [1,75,75,42] vs. shape[2] = [1,42,75,75]
	 [[Node: cell_stem_0/cell_output/concat = _MklConcatV2[N=4, T=DT_FLOAT, Tidx=DT_INT32, _kernel=""MklOp"", _device=""/job:localhost/replica:0/task:0/device:CPU:0""](cell_stem_0/comb_iter_1/combine/add, cell_stem_0/comb_iter_2/combine/add, cell_stem_0/comb_iter_3/combine/add, cell_stem_0/comb_iter_4/combine/add, cell_17/split/split_dim, DMT/_121, DMT/_122, cell_stem_0/comb_iter_3/combine/add:1, DMT/_123, DMT/_124)]]
)

```
",rickhg12hs,b'stat:awaiting model gardener type:bug',2018-01-11T03:24:24Z,2020-06-12T02:41:45Z,,,,,,,
3103,from six.moves import xrange,"The following files are incompatible with Python 3 at least in part because they use xrange() yet they lack the import:
* __from six.moves import xrange__
```
./research/compression/entropy_coder/dataset/gen_synthetic_dataset.py
./research/compression/entropy_coder/dataset/synthetic_model.py
./research/compression/entropy_coder/lib/blocks_masked_conv2d.py
./research/compression/entropy_coder/lib/blocks_masked_conv2d_test.py
./research/compression/entropy_coder/lib/blocks_std_test.py
./research/delf/delf/python/feature_io.py
./research/differential_privacy/dp_sgd/dp_mnist/dp_mnist.py
./research/differential_privacy/dp_sgd/per_example_gradients/per_example_gradients.py
./research/differential_privacy/multiple_teachers/aggregation.py
./research/differential_privacy/multiple_teachers/deep_cnn.py
./research/differential_privacy/multiple_teachers/input.py
./research/differential_privacy/multiple_teachers/train_student.py
./research/domain_adaptation/domain_separation/dsn_eval.py
./research/gan/cifar/util.py
./research/gan/image_compression/networks_test.py
./research/gan/mnist/util.py
./research/gan/mnist_estimator/train.py
./research/im2txt/im2txt/data/build_mscoco_data.py
./research/learned_optimizer/metaopt.py
./research/learning_to_remember_rare_events/data_utils.py
./research/learning_to_remember_rare_events/memory.py
./research/learning_to_remember_rare_events/train.py
./research/lfads/synth_data/generate_itb_data.py
./research/lfads/synth_data/generate_labeled_rnn_data.py
./research/neural_gpu/data_utils.py
./research/next_frame_prediction/cross_conv/eval.py
./research/next_frame_prediction/cross_conv/example_gen.py
./research/next_frame_prediction/cross_conv/model.py
./research/next_frame_prediction/cross_conv/reader.py
./research/next_frame_prediction/cross_conv/sprites_gen.py
./research/object_detection/dataset_tools/oid_tfrecord_creation.py
./research/object_detection/utils/np_box_list_ops.py
./research/pcl_rl/baseline.py
./research/pcl_rl/controller.py
./research/pcl_rl/env_spec.py
./research/pcl_rl/expert_paths.py
./research/pcl_rl/gym_wrapper.py
./research/pcl_rl/optimizers.py
./research/pcl_rl/replay_buffer.py
./research/pcl_rl/trainer.py
./research/pcl_rl/trust_region.py
./research/ptn/metrics.py
./research/ptn/model_ptn.py
./research/ptn/model_rotator.py
./research/ptn/model_voxel_generation.py
./research/ptn/pretrain_rotator.py
./research/ptn/utils.py
./research/real_nvp/real_nvp_utils.py
./research/slim/datasets/build_imagenet_data.py
./research/slim/datasets/preprocess_imagenet_validation_data.py
./research/slim/datasets/process_bounding_boxes.py
./research/slim/nets/cyclegan.py
./research/slim/nets/dcgan.py
./research/slim/nets/dcgan_test.py
./research/street/python/decoder.py
./research/street/python/shapes.py
./research/street/python/vgslspecs.py
./research/syntaxnet/dragnn/python/graph_builder_test.py
./research/syntaxnet/dragnn/python/network_units.py
./research/syntaxnet/dragnn/python/spec_builder.py
./research/syntaxnet/dragnn/python/trainer_lib.py
./research/tcn/labeled_eval.py
```
  
  ",cclauss,b'help wanted type:bug',2018-01-04T10:55:43Z,2018-08-14T20:37:28Z,,,,,,,
3068,Object detection. No cropping in evaluation config results in wrong validation,"### System information
- **What is the top-level directory of the model you are using**: object_detection
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: binary for anaconda python
- **TensorFlow version (use command below)**: v1.4.0-rc1-11-g130a514 1.4.0
- **Bazel version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: 6.0
- **GPU model and memory**: gtx1060 6gb
- **Exact command to reproduce**:

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

I train the ssd mobilenet v1 model on the kitti dataset.
I want the model input to be 640x360 (aspect ratio 16:9 ~ 1.7778)
```
    image_resizer {
      fixed_shape_resizer {
        height: 360
        width: 640
      }
    }
```
Kitti dataset image resolution is 1242x375 (aspect ratio 3.312)

I use a following preprocessing in train_config to use subimage with standard aspect ratio.
```
  data_augmentation_options {
    random_crop_to_aspect_ratio {
      aspect_ratio: 1.7778
      overlap_thresh: 0.8
    }
  }
```

So the training images are first cropped to 667x375 and are then resized to 640x360, resulting in normal training picture.

But there is no such preprocessing during the evaluation step, which means that validation images 1242x375 are just resized to 640x360, which results in images with squeezed road objects.

Because of that I get poor accuracy on the validation accuracy chart in tensorboard, but the model actually performs well during the manual testing, when I feed it with 16:9 aspect ratio images.

Is there a way to reproduce the same cropping during the validation step?",SergeyBykov1,b'stat:awaiting model gardener type:bug',2017-12-27T12:31:18Z,2020-02-07T18:43:48Z,,,,,,,
2936,precision vs accuracy in cifar10_eval.py,"### System information
- **What is the top-level directory of the model you are using**: /tensorflow/models/tree/master/tutorials/image/cifar10
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:NO
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:Linux Ubuntu 16.04.3
- **TensorFlow installed from (source or binary)**:binary
- **TensorFlow version (use command below)**:1.1.0
- **Bazel version (if compiling from source)**:NA
- **CUDA/cuDNN version**:7
- **GPU model and memory**:nvidia geforce 1080Ti /11172 MiB
- **Exact command to reproduce**: python cifar10_eval.py

**error:**
The output of the script is ""precision"", however the correct term should be ""accuracy""
""2017-11-30 19:55:56.608454: precision @ 1 = 0.866""


**solution:**
change ""precision"" to ""accuracy"" in cifar10_eval.py also remove ""@1"" (whatever that means)
add epochs and time that went by  to calculate the accuracy.

**additional comments:**
the script itself talks about ""accuracy"" in the comment section, so the coder was aware about that fact,
later the term was confused with precision.
See: [accuracy vs precision](https://www.google.com/search?q=accuracy+vs+precision)




",tobigithub,b'stat:awaiting model gardener type:bug',2017-12-01T04:03:04Z,2017-12-02T03:05:16Z,,,,,,,
2930,object_detection/protos/*.proto: No such file or directory,"As mentioned above the error takes place in while executing the command in the windows cmd prompt.

>D:/BB/bin/protoc object_detection/protos/*.proto --python_out=.

as for the reference in the installation process of object detection in this model.

in protobuf compilation.",Hemanth2396,b'stat:awaiting response type:bug',2017-11-30T06:09:54Z,2020-09-27T13:32:30Z,,,,,,,
2926,The faster rcnn module does not support batch_size > 1 for each clone,"https://github.com/tensorflow/models/blob/b63a73df70656ecfcd2d50bfc98b09b3ce06f635/research/object_detection/trainer.py#L155

The above line has a concat operation which only works for single image or images with the same width/height ratio, i.e., the same size after resize. 

This seems to be a bug; because in 
https://github.com/tensorflow/models/blob/01aa7a4a6190bf021f448dee26fc649f4b47753e/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py#L101, the comments show ""When training with a relative large batch size (e.g. 8), it could be desirable to enable batch norm update."" This indicates the authors plan to support more batch sizes. Also, I believe that this comment is misleading. Set batch norm parameters not trainable is OK for fine tuning, but NOT acceptable for training from scratch. If training from scratch, even if the batch size is 1, the batch norm still need to be set trainable.",ybsave,b'stat:awaiting model gardener type:bug',2017-11-29T21:19:09Z,2020-02-07T18:43:28Z,,,,,,,
2906,"3D reconstruction using tensorflow implementation of ptn, error in  pretraining rotator ","
Hi,
When I tried to pretrain the rotator model with the dataset provided in the webpage, I'm getting the following Value error and I guess the problem is with the inp_dir path for the dataset on the system.

Tried providing both absolute and relative path but still the problem persist, any help would be great since I'm completely new to tensorflow .

ERROR:
INFO: Analysed target //:pretrain_rotator (0 packages loaded).
INFO: Found 1 target...
Target //:pretrain_rotator up-to-date:
  bazel-bin/pretrain_rotator
INFO: Elapsed time: 0.174s, Critical Path: 0.01s
INFO: Build completed successfully, 1 total action

INFO: Running command line: bazel-bin/pretrain_rotator '--step_size=1' '--init_model=/tmp/ptn_train/'
/.shapenet_tf
Traceback (most recent call last):
  File ""/home/sbasavaraju/.cache/bazel/_bazel_sbasavaraju/b31d182e049bda91baa4373c1dc1e3ce/execroot/__main__/bazel-out/local-opt/bin/pretrain_rotator.runfiles/__main__/pretrain_rotator.py"", line 236, in <module>
    app.run()
  File ""/home/sbasavaraju/anaconda3/lib/python3.6/site-packages/tensorflow/python/platform/app.py"", line 48, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""/home/sbasavaraju/.cache/bazel/_bazel_sbasavaraju/b31d182e049bda91baa4373c1dc1e3ce/execroot/__main__/bazel-out/local-opt/bin/pretrain_rotator.runfiles/__main__/pretrain_rotator.py"", line 119, in main
    ['encoder', 'rotator', 'decoder'], FLAGS)
  File ""/media/sbasavaraju/DATA/ptn/model_rotator.py"", line 151, in get_regularization_loss
    return losses.regularization_loss(scopes, params)
  File ""/media/sbasavaraju/DATA/ptn/losses.py"", line 173, in regularization_loss
    reg_loss += tf.add_n([tf.nn.l2_loss(var) for var in scope_vars])
  File ""/home/sbasavaraju/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py"", line 1942, in add_n
    raise ValueError(""inputs must be a list of at least one Tensor with the ""
ValueError: inputs must be a list of at least one Tensor with the same dtype and shape
ERROR: Non-zero return code '1' from command: Process exited with status 1


------------------------

System information
-  top-level directory of the model you are using: ptn
- OS Platform and Distribution : Ubuntu 16.04
- TensorFlow version : 1.3.0
- Bazel version: 0.70


",Santubasa,b'stat:awaiting model gardener type:bug',2017-11-27T10:45:24Z,2017-11-30T12:32:14Z,,,,,,,
2884,Tensorflow[attention_ocr] eval.py Freezes ,"when I run the example that is wrote in the [link](https://github.com/tensorflow/models/blob/master/research/attention_ocr/python/eval.py)
 which is: `A simple usage example:
python eval.py`

the server freezes with the outputs:
```
(tensorflow)ubuntu@ip-172-31-31-92:/nsfs/tensor_models/models/research/attention_ocr/python$ python eval.py
INFO 2017-11-23 14:53:36.000674: fsns.py: 130 Using FSNS dataset split_name=train dataset_dir=/nsfs/tensor_models/models/research/attention_ocr/python/datasets/data/fsns
DEBUG 2017-11-23 14:53:36.000805: model.py: 354 images: Tensor(""shuffle_batch:0"", shape=(32, 150, 600, 3), dtype=float32)
DEBUG 2017-11-23 14:53:36.000838: model.py: 359 Views=4 single view: Tensor(""AttentionOcr_v1/split:0"", shape=(32, 150, 150, 3), dtype=float32)
DEBUG 2017-11-23 14:53:36.000838: model.py: 200 Using final_endpoint=Mixed_5d
DEBUG 2017-11-23 14:53:37.000284: model.py: 200 Using final_endpoint=Mixed_5d
DEBUG 2017-11-23 14:53:37.000419: model.py: 200 Using final_endpoint=Mixed_5d
DEBUG 2017-11-23 14:53:37.000553: model.py: 200 Using final_endpoint=Mixed_5d
DEBUG 2017-11-23 14:53:37.000688: model.py: 365 Conv tower: Tensor(""AttentionOcr_v1/conv_tower_fn/INCE/InceptionV3/Mixed_5d/concat:0"", shape=(32, 16, 16, 288), dtype=float32)
DEBUG 2017-11-23 14:53:37.000688: model.py: 368 Conv tower w/ encoded coordinates: Tensor(""AttentionOcr_v1/conv_tower_fn/INCE/InceptionV3/Mixed_5d/concat:0"", shape=(32, 16, 16, 288), dtype=float32)
DEBUG 2017-11-23 14:53:37.000690: model.py: 371 Pooled views: Tensor(""AttentionOcr_v1/pool_views_fn/STCK/Reshape:0"", shape=(32, 1024, 288), dtype=float32)
DEBUG 2017-11-23 14:53:37.000690: sequence_layers.py: 421 Use AttentionWithAutoregression as a layer class
DEBUG 2017-11-23 14:53:39.000137: model.py: 374 chars_logit: Tensor(""AttentionOcr_v1/sequence_logit_fn/SQLR/concat:0"", shape=(32, 37, 134), dtype=float32)
WARNING:tensorflow:From /nsfs/tensor_models/models/research/attention_ocr/python/model.py:406: get_total_loss (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.
Instructions for updating:
Use tf.losses.get_total_loss instead.
WARNING 2017-11-23 14:53:39.000864: tf_logging.py: 90 From /nsfs/tensor_models/models/research/attention_ocr/python/model.py:406: get_total_loss (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.
Instructions for updating:
Use tf.losses.get_total_loss instead.
WARNING:tensorflow:From /home/ubuntu/tensorflow/local/lib/python2.7/site-packages/tensorflow/contrib/losses/python/losses/loss_ops.py:261: get_losses (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.
Instructions for updating:
Use tf.losses.get_losses instead.
WARNING 2017-11-23 14:53:39.000865: tf_logging.py: 90 From /home/ubuntu/tensorflow/local/lib/python2.7/site-packages/tensorflow/contrib/losses/python/losses/loss_ops.py:261: get_losses (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.
Instructions for updating:
Use tf.losses.get_losses instead.
WARNING:tensorflow:From /home/ubuntu/tensorflow/local/lib/python2.7/site-packages/tensorflow/contrib/losses/python/losses/loss_ops.py:263: get_regularization_losses (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.
Instructions for updating:
Use tf.losses.get_regularization_losses instead.
WARNING 2017-11-23 14:53:39.000865: tf_logging.py: 90 From /home/ubuntu/tensorflow/local/lib/python2.7/site-packages/tensorflow/contrib/losses/python/losses/loss_ops.py:263: get_regularization_losses (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.
Instructions for updating:
Use tf.losses.get_regularization_losses instead.
WARNING:tensorflow:From eval.py:64: get_or_create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Please switch to tf.train.get_or_create_global_step
WARNING 2017-11-23 14:53:39.000901: tf_logging.py: 90 From eval.py:64: get_or_create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Please switch to tf.train.get_or_create_global_step
INFO:tensorflow:Waiting for new checkpoint at /tmp/attention_ocr/train
INFO 2017-11-23 14:53:39.000907: tf_logging.py: 82 Waiting for new checkpoint at /tmp/attention_ocr/train
```",ibr123,b'stat:awaiting model gardener type:bug',2017-11-23T16:07:13Z,2019-11-13T11:46:16Z,,,,,,,
2882,Swivel: Force bufsz to be the square of shard_size? ,"Hey, I'm new to swivel and I tried it on my custom dataset. Since my vocabulary is quite large, I increased the shard_size and left everything unchanged. Then I found this will not throw any error during running prep.py, but will cause encoding error while running swivel.py. For example:

`UnicodeDecodeError: 'utf8' codec can't decode byte 0xc1 in position 40: invalid start byte`

Then I realized that I also need to change bufsz to be square of shard_size. After fixing this, everything is back on track. So I'm wondering if it would be better to force bufsz to be the square of shard_size instead of hard-coding it to be 16M? Please correct me if I'm wrong. Thanks. ",tomahawklin,b'type:bug',2017-11-23T15:21:38Z,2020-02-07T18:43:28Z,,,,,,,
2844,when training will complete,"Hello,

When I tried to tune a inception model to identify the flowers, I found that the program never end. 

I read and follow the step posted in the link: https://github.com/tensorflow/models/tree/master/research/inception

The command I used to run the training is:
/usr/bin/python /share_folder/220Proj/flower_demo/bazel-bin/inception/flowers_train.runfiles/inception/inception/flowers_train.py \
--train_dir=/share_folder/220Proj/flower_demo/flowers_train \
--data_dir=/share_folder/220Proj/flower_demo/flowers_data \
--pretrained_model_checkpoint_path=/usr/local/lib/python3.5/dist-packages/inception-v3/model.ckpt-157585 \
--fine_tune=True \
--initial_learning=0.001 \
--input_queue_memory_factor=1

Here is part of the log:
2017-11-21 01:23:16.037863: step 250070, loss = 0.98 (77.4 examples/sec; 0.413 sec/batch)
2017-11-21 01:23:20.213151: step 250080, loss = 0.91 (76.4 examples/sec; 0.419 sec/batch)
2017-11-21 01:23:24.387518: step 250090, loss = 0.95 (77.1 examples/sec; 0.415 sec/batch)
2017-11-21 01:23:28.536253: step 250100, loss = 1.12 (76.9 examples/sec; 0.416 sec/batch)
2017-11-21 01:23:34.435414: step 250110, loss = 0.92 (76.5 examples/sec; 0.418 sec/batch)
2017-11-21 01:23:38.599515: step 250120, loss = 1.07 (77.5 examples/sec; 0.413 sec/batch)
2017-11-21 01:23:42.764535: step 250130, loss = 0.95 (77.0 examples/sec; 0.415 sec/batch)
2017-11-21 01:23:46.922841: step 250140, loss = 0.92 (78.0 examples/sec; 0.410 sec/batch)
2017-11-21 01:23:51.092711: step 250150, loss = 0.96 (77.4 examples/sec; 0.414 sec/batch)

You can see the loss is around 0.98 to 1.07, and never decrease. 

So could you tell if there is max steps in inception or not?

What should I do next? End the program manually?

Thanks,

Shuai Hua
",huahandsome,b'type:bug',2017-11-21T01:27:50Z,2017-11-29T23:05:43Z,,,,,,,
2830,"Error from ""python object_detection/builders/model_builder_test.py"" command.","I have following error while doing the installation final step. 
I'm using tensorflow (1.4), cuda (8.0), cudnn (6.0), matplotlib (2.1.0) under anaconda virtual environment.

----------------------------------------------------------------------------------------------------------------------------
(tensorflow) chkim@chkim-PMTSB09D-Samsung-DeskTop:~/다운로드/models-master/research$ python object_detection/builders/model_builder_test.py

Traceback (most recent call last):
  File ""object_detection/builders/model_builder_test.py"", line 21, in <module>
    from object_detection.builders import model_builder
  File ""/home/chkim/다운로드/models-master/research/object_detection/builders/model_builder.py"", line 29, in <module>
    from object_detection.meta_architectures import ssd_meta_arch
  File ""/home/chkim/다운로드/models-master/research/object_detection/meta_architectures/ssd_meta_arch.py"", line 31, in <module>
    from object_detection.utils import visualization_utils
  File ""/home/chkim/다운로드/models-master/research/object_detection/utils/visualization_utils.py"", line 24, in <module>
    import matplotlib.pyplot as plt
  File ""/home/chkim/anaconda2/envs/tensorflow/lib/python2.7/site-packages/matplotlib/pyplot.py"", line 69, in <module>
    from matplotlib.backends import pylab_setup
  File ""/home/chkim/anaconda2/envs/tensorflow/lib/python2.7/site-packages/matplotlib/backends/__init__.py"", line 14, in <module>
    line for line in traceback.format_stack()
  File ""/home/chkim/anaconda2/envs/tensorflow/lib/python2.7/site-packages/matplotlib/backends/__init__.py"", line 16, in <genexpr>
    if not line.startswith('  File ""<frozen importlib._bootstrap'))
UnicodeDecodeError: 'ascii' codec can't decode byte 0xeb in position 20: ordinal not in range(128)
-------------------------------------------------------------------------------------------------------------------------


",flipflop98,b'stat:awaiting model gardener type:bug',2017-11-18T13:42:58Z,2020-02-07T18:43:26Z,,,,,,,
2818,Bug using 2 gpus,"### System information
- **What is the top-level directory of the model you are using**:
tensorflow/models/research/slim
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.4.0
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**: 8/6
- **GPU model and memory**: 1)GeForce GTX Titan, 2) GeForce GTX 1080
- **Exact command to reproduce**:
`python train_image_classifier.py \
  --train_dir=${TRAIN_DIR} \
  --dataset_name=DATASET_NAME \
  --dataset_split_name=train \
  --dataset_dir=${DATASET_DIR} \
  --clone_on_cpu=False \
  --num_clones=2 \
  --model_name=resnet_v2_101 \
  --max_number_of_steps=154526 \
  --batch_size=64 \
  --learning_rate=0.0001 \
  --learning_rate_decay_factor=0.1 \
  --end_learning_rate=0.00001 \
  --optimizer=momentum \
  --momentum=0.9 \
  --weight_decay=0.0001 \
  --train_image_size=180 \
  --save_interval_secs=60 \
  --save_summaries_secs=60 \
  --log_every_n_steps=100 \
  --checkpoint_path=${PRETRAINED_CHECKPOINT_DIR}/resnet_v2_101.ckpt \
  --checkpoint_exclude_scopes=resnet_v2_101/logits`



### Describe the problem
I am training resnet_v2_101 model on my custom data set. I composed the data set from the script for getting TFRecord shards, so the data are right and shuffled. The training process is really slow using 2 gpus and using the command **watch nvidia-smi** the gpus are not being utilized all the time. They can be at 80-100% both but suddenly they fall to 0% for a small amount of time. I think this is something that slows down the training. I spent a lot of time to check if the problem has to do with the reading process of the files but I cannot figure out the source.",chrisrn,b'type:support',2017-11-17T08:43:02Z,2020-05-08T21:05:56Z,,,,,,,
2778,Odd batch_size specific behaviour with nasnet_large on ImageNet validation,"I've been trying to reproduce the ImageNet validation accuracies posted with the pretrained weights.

I cannot reproduce the results with an image size of 331 and the default batch size of 100 used in the eval_image_classifer script. With defaults I get roughly 64% top-1 and 74% top-5 using the command:

`python eval_image_classifier.py --dataset_dir ~/imagenet/ --dataset_split_name validation --model_name nasnet_large --checkpoint_path ~/nasnet_large/model.ckpt  --dataset_name imagenet --moving_average_decay=0.9999`

However, if I change the batch size down to 50, I hit the posted results dead on, 82.7% top-1 and 92.6% top-5. This seems rather odd to me. I've never experienced that significant of a performance drop by changing the batch size by a factor of two at eval. 

I noticed that with the batch size of 100, I could improve performance by dropping the eval image size down. There is an optimal value somewhere in the 280-290 range before it starts to fall off. My best result with batch size of 100 was at 288x288 with a 80.8% top-1 and 95.2% top-5, it falls off quickly as the image size increases from there. 

Is this possibly some sort of overflow in batch norm or another op in the network?

Note, I'm using latest released pip install of Tensorflow 1.4 for GPU. CUDA 8.0, cuDNN 6.",rwightman,b'type:bug',2017-11-13T04:04:52Z,2020-01-30T04:20:33Z,,,,,,,
2770,Apparent incorrect behavior from resize_to_range() in object_detection/core/preprocessor.py,"From the comments for resize_to_range():

  The output size can be described by two cases:
  1. If the image can be rescaled so its minimum dimension is equal to the
     provided value without the other dimension exceeding max_dimension,
     then do so.
  2. Otherwise, resize so the largest dimension is equal to max_dimension.

This logic would yield the wrong behavior for images with an aspect ratio near 1. For instance, if we had a 1200x1200 image, and we had settings min_dimension = 600 and max_dimension = 1024, it seems that the desired behavior would be to rescale the image to 1024x1024. Instead, following the logic above, the image would be rescaled to 600x600.

Am I missing something?

@jch1 @tombstone @derekjchow @jesu9 @dreamdragon
",MisterMorden,b'help wanted type:bug',2017-11-10T23:40:19Z,2020-02-07T18:43:24Z,,,,,,,
2753,Object Detection: error when using random_crop_pad_image data augmentation,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**: object_detection
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: no
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: 'v1.4.0-1-g7f646a6' 1.4.0
- **Bazel version (if compiling from source)**: 0.7.0
- **CUDA/cuDNN version**: 8.0/6.0
- **GPU model and memory**: 1080Ti 11 GB
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

When I add 
```
  data_augmentation_options {
    random_crop_pad_image {
    }
  }
```
in the train_config section of my pipeline config, and then run train.py, I get the following error:

```
Traceback (most recent call last):
  File ""../gpu-env/lib/python3.5/site-packages/object_detection/train.py"", line 163, in <module>
    tf.app.run()
  File ""/home/dan/gpu-env/lib/python3.5/site-packages/tensorflow/python/platform/app.py"", line 48, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""../gpu-env/lib/python3.5/site-packages/object_detection/train.py"", line 159, in main
    worker_job_name, is_chief, FLAGS.train_dir)
  File ""/home/dan/gpu-env/lib/python3.5/site-packages/object_detection/trainer.py"", line 217, in train
    train_config.prefetch_queue_capacity, data_augmentation_options)
  File ""/home/dan/gpu-env/lib/python3.5/site-packages/object_detection/trainer.py"", line 77, in create_input_queue
    include_keypoints=include_keypoints))
  File ""/home/dan/gpu-env/lib/python3.5/site-packages/object_detection/core/preprocessor.py"", line 2547, in preprocess
    results = func(*args, **params)
  File ""/home/dan/gpu-env/lib/python3.5/site-packages/object_detection/core/preprocessor.py"", line 1272, in random_crop_pad_image
    min_padded_size_ratio)
  File ""/home/dan/gpu-env/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py"", line 885, in binary_op_wrapper
    y = ops.convert_to_tensor(y, dtype=x.dtype.base_dtype, name=""y"")
  File ""/home/dan/gpu-env/lib/python3.5/site-packages/tensorflow/python/framework/ops.py"", line 836, in convert_to_tensor
    as_ref=False)
  File ""/home/dan/gpu-env/lib/python3.5/site-packages/tensorflow/python/framework/ops.py"", line 926, in internal_convert_to_tensor
    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
  File ""/home/dan/gpu-env/lib/python3.5/site-packages/tensorflow/python/framework/constant_op.py"", line 229, in _constant_tensor_conversion_function
    return constant(v, dtype=dtype, name=name)
  File ""/home/dan/gpu-env/lib/python3.5/site-packages/tensorflow/python/framework/constant_op.py"", line 208, in constant
    value, dtype=dtype, shape=shape, verify_shape=verify_shape))
  File ""/home/dan/gpu-env/lib/python3.5/site-packages/tensorflow/python/framework/tensor_util.py"", line 371, in make_tensor_proto
    raise ValueError(""None values not supported."")
ValueError: None values not supported.
```

This appears to be a bug relating to RandomCropPadImage.{min_padded_size_ratio,max_padded_size_ratio} not being specified. In addition, if I do specify them, e.g.:

```
  data_augmentation_options {
    random_crop_pad_image {
      min_padded_size_ratio: [0.5, 0.5]
      max_padded_size_ratio: [2.0, 2.0]
    }
  }
```

I get the following error:

```
Traceback (most recent call last):
  File ""../gpu-env/lib/python3.5/site-packages/object_detection/train.py"", line 163, in <module>
    tf.app.run()
  File ""/home/dan/gpu-env/lib/python3.5/site-packages/tensorflow/python/platform/app.py"", line 48, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""../gpu-env/lib/python3.5/site-packages/object_detection/train.py"", line 159, in main
    worker_job_name, is_chief, FLAGS.train_dir)
  File ""/home/dan/gpu-env/lib/python3.5/site-packages/object_detection/trainer.py"", line 217, in train
    train_config.prefetch_queue_capacity, data_augmentation_options)
  File ""/home/dan/gpu-env/lib/python3.5/site-packages/object_detection/trainer.py"", line 77, in create_input_queue
    include_keypoints=include_keypoints))
  File ""/home/dan/gpu-env/lib/python3.5/site-packages/object_detection/core/preprocessor.py"", line 2547, in preprocess
    results = func(*args, **params)
  File ""/home/dan/gpu-env/lib/python3.5/site-packages/object_detection/core/preprocessor.py"", line 1272, in random_crop_pad_image
    min_padded_size_ratio)
  File ""/home/dan/gpu-env/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py"", line 885, in binary_op_wrapper
    y = ops.convert_to_tensor(y, dtype=x.dtype.base_dtype, name=""y"")
  File ""/home/dan/gpu-env/lib/python3.5/site-packages/tensorflow/python/framework/ops.py"", line 836, in convert_to_tensor
    as_ref=False)
  File ""/home/dan/gpu-env/lib/python3.5/site-packages/tensorflow/python/framework/ops.py"", line 926, in internal_convert_to_tensor
    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
  File ""/home/dan/gpu-env/lib/python3.5/site-packages/tensorflow/python/framework/constant_op.py"", line 229, in _constant_tensor_conversion_function
    return constant(v, dtype=dtype, name=name)
  File ""/home/dan/gpu-env/lib/python3.5/site-packages/tensorflow/python/framework/constant_op.py"", line 208, in constant
    value, dtype=dtype, shape=shape, verify_shape=verify_shape))
  File ""/home/dan/gpu-env/lib/python3.5/site-packages/tensorflow/python/framework/tensor_util.py"", line 383, in make_tensor_proto
    _AssertCompatible(values, dtype)
  File ""/home/dan/gpu-env/lib/python3.5/site-packages/tensorflow/python/framework/tensor_util.py"", line 303, in _AssertCompatible
    (dtype.name, repr(mismatch), type(mismatch).__name__))
TypeError: Expected float32, got [0.5, 0.5] of type 'RepeatedScalarContainer' instead.
```

It appears that the code isn't properly converting from protobuf to a tensor.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",dnuffer,b'stat:awaiting model gardener type:bug',2017-11-09T17:10:52Z,2017-11-16T23:31:52Z,,,,,,,
2713,"Object_Detection ValueError: operands could not be broadcast together with shapes (0,) (16,)","Dear all,
I am trying to train the API object detection model on my dataset with just one class. The training ended and i tried to run the evaluation (eval.py) but it gives me an error that I am not able to fully understand:

python eval.py
INFO:tensorflow:Scale of 0 disables regularizer.
INFO:tensorflow:Scale of 0 disables regularizer.
INFO:tensorflow:Scale of 0 disables regularizer.
INFO:tensorflow:depth of additional conv before box predictor: 0
INFO:tensorflow:Scale of 0 disables regularizer.
2017-11-06 11:24:50.514416: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2017-11-06 11:24:50.710928: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties:
name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.683
pciBusID: 0000:05:00.0
totalMemory: 10.91GiB freeMemory: 10.56GiB
2017-11-06 11:24:50.710953: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:05:00.0, compute capability: 6.1)
INFO:tensorflow:Restoring parameters from ./models/model/train/model.ckpt-200000
INFO:tensorflow:Restoring parameters from ./models/model/train/model.ckpt-200000
2017-11-06 11:24:57.255021: W tensorflow/core/framework/op_kernel.cc:1192] Out of range: FIFOQueue '_2_parallel_read/common_queue' is closed and has insufficient elements (requested 1, current size 0)
         [[Node: parallel_read/common_queue_Dequeue = QueueDequeueV2[component_types=[DT_STRING, DT_STRING], timeout_ms=-1, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](parallel_read/common_queue)]]
WARNING:root:The following classes have no ground truth examples: 1
/home/ucesfpa/ObjectDetection/TF_Models/models/research/object_detection/utils/metrics.py:144: RuntimeWarning: invalid value encountered in true_divide
  num_images_correctly_detected_per_class / num_gt_imgs_per_class)
/home/ucesfpa/ObjectDetection/TF_Models/models/research/object_detection/utils/object_detection_evaluation.py:585: RuntimeWarning: Mean of empty slice
  mean_ap = np.nanmean(self.average_precision_per_class)
/home/ucesfpa/ObjectDetection/TF_Models/models/research/object_detection/utils/object_detection_evaluation.py:586: RuntimeWarning: Mean of empty slice
  mean_corloc = np.nanmean(self.corloc_per_class)
Traceback (most recent call last):
  File ""eval.py"", line 130, in <module>
    tf.app.run()
  File ""/home/ucesfpa/ObjectDetection/lib/python3.5/site-packages/tensorflow/python/platform/app.py"", line 48, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""eval.py"", line 126, in main
    FLAGS.checkpoint_dir, FLAGS.eval_dir)
  File ""/home/ucesfpa/ObjectDetection/TF_Models/models/research/object_detection/evaluator.py"", line 210, in evaluate
    save_graph_dir=(eval_dir if eval_config.save_graph else ''))
  File ""/home/ucesfpa/ObjectDetection/TF_Models/models/research/object_detection/eval_util.py"", line 381, in repeated_checkpoint_run
    save_graph_dir)
  File ""/home/ucesfpa/ObjectDetection/TF_Models/models/research/object_detection/eval_util.py"", line 269, in _run_checkpoint_once
    image_id=batch, groundtruth_dict=result_dict)
  File ""/home/ucesfpa/ObjectDetection/TF_Models/models/research/object_detection/utils/object_detection_evaluation.py"", line 174, in add_single_ground_truth_image_info
    standard_fields.InputDataFields.groundtruth_difficult, None))
  File ""/home/ucesfpa/ObjectDetection/TF_Models/models/research/object_detection/utils/object_detection_evaluation.py"", line 447, in add_single_ground_truth_image_info
    groundtruth_is_group_of_list.astype(dtype=bool))
  File ""/home/ucesfpa/ObjectDetection/TF_Models/models/research/object_detection/utils/object_detection_evaluation.py"", line 527, in _update_ground_truth_statistics
    & ~groundtruth_is_group_of_list] == class_index)
ValueError: operands could not be broadcast together with shapes (0,) (16,)

Can anyone of you explain the problem?

Thank you,
Fabio",ucesfpa,b'stat:awaiting model gardener type:bug',2017-11-06T12:45:04Z,2018-07-04T11:58:52Z,,,,,,,
2634,[object detection] input_reader_builder_test failed,"### System information
- **OS Platform and Distribution**: Linux Ubuntu 16.04
- **TensorFlow version (use command below)**: 1.3.0
- **CUDA/cuDNN version**: 8.0
- **Exact command to reproduce**: python object_detection/builders/input_reader_builder_test.py
- **protobuf**: protobuf(2.6.1)/protobuf (3.4.0)


### Describe the problem
input reader builder test failed. It seems TfExampleDecoder in input_reader_builder.py does not take load_instance_masks as argument?

### Source code / logs

ERROR: test_build_tf_record_input_reader (__main__.InputReaderBuilderTest)

TypeError: __init__() got an unexpected keyword argument 'load_instance_masks'TypeError: __init__() got an unexpected keyword argument 'load_instance_masks'
",yimintsai,b'type:bug',2017-10-29T03:37:31Z,2017-10-30T05:10:48Z,,,,,,,
2489,Problems with official examples,"I'm playing with Tensorflow for a week now and I was able to hook up another database to the models in the official folder (https://github.com/tensorflow/models/blob/master/official/resnet/imagenet_main.py). I like this high-level API much and everything seems to work fine apart the following issues:

- when using a large database containing millions of images, the workstation just explodes. High RAM usage, events.out.tfevent on the order of several gigabytes. I realized that this problem is related to the fact that each time a checkpoint is saved or a summary, the entire list of images is saved to disk:) I could circumvent this problem by using placeholders for filenames and variables, feeding them using a hook on the train function. I don't know if this the recommended way. I've read somewhere that one might want to transfer the database into TFRecords. However, what's best there: a single file or multiple files?

- I had to add something like logits += tf.constant(1e-8) to avoid NaN at some point

- training proceeds nicely apart that something is destroyed each time a checkpoint is restored (after stop and restart or when the train function finishes in the cycle while loop).

![screenshot_2017-10-04_09-40-25](https://user-images.githubusercontent.com/2109115/31165885-04564040-a8ed-11e7-88e8-a9cf58070942.png)

Is this something expected? I suspect that some parameters are not well restored (batch norm moving mean or moving variance?). If I run the example on a smaller database with fewer classes, this does not seem that dramatic. But I guess it is because I haven't run it for long. Maybe the moving mean/variance is really well estimated, then destroyed, causing those curves.

I've posted this question at several places. Also, I've seen people having the same issue in different places. However, I found no convincing answer. Thanks for your help.


",jmaye,b'type:bug',2017-10-04T08:20:59Z,2018-07-13T07:35:45Z,,,,,,,
2462,Bug in models/official/resnet/cifar10_main.py when re-starting training,"In file models/official/resnet/cifar10_main.py, there is the running cycle defined as:

    for cycle in range(FLAGS.train_steps // FLAGS.steps_per_eval):

This cycle is not correct when training from an existing checkpoint but is only correct when training from scratch. I think the original intention for ""FLAGS.train_steps"" is the total number of training steps but not the steps needed for extra training; therefore, I believe that this is a bug.",ybsave,None,2017-09-26T18:17:06Z,2017-09-27T15:24:34Z,,,,,,,
2418,Bug in models/learning_to_remember_rare_events/,"
It seems like the per-shot accuracy calculation in `models/learning_to_remember_rare_events/train.py` is wrong: 
```correct_by_shot = dict((k, []) for k in xrange(self.episode_width + 1))```

Instead of `self.episode_width` , it should be something like `int(self.episode_length/self.episode_width*1.0)-1` since per shot means how many samples have been seen so far. 

The original code does not make sense when `episode_length` is 60 and `episode_width` is 10 in which case we should be seeing accuracies for 0-shot,1-shot,2-shot,3-shot,4-shot,5-shot. With the fix above, this seems to work fine. ",himani-arora,b'stat:awaiting model gardener type:bug',2017-09-19T18:39:47Z,2018-02-28T04:40:32Z,,,,,,,
2374,Frozen pretrained Faster RCNN/RFCN networks from model zoo yielding different outputs on different GPUs and runs,"### System information
- **What is the top-level directory of the model you are using**:
Using unmodified pretrained coco models: faster_rcnn_inception_resnet_v2_atrous_coco_11_06_2017, faster_rcnn_resnet101_coco_11_06_2017, rfcn_resnet101_coco_11_06_2017

- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
No

- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
UPDATE: tested on two machines now, both reproduce it:
Machine 1: Linux Ubuntu 14.04.4 LTS
Machine 2: Linux Ubuntu 16.04.2 LTS

- **TensorFlow installed from (source or binary)**:
official docker container, with last commit 58fb6d7e257f28cd7934316d6ae7a81ec42a533a
docker version from 2017-08-24T02:37:57.51182742Z

- **TensorFlow version (use command below)**:
('v1.2.0-5-g435cdfc', '1.2.1')

- **Bazel version (if compiling from source)**:
N/A

- **CUDA/cuDNN version**:
From official docker: CUDA 8., cuDNN 5.1.10

- **GPU model and memory**:
Machine 1: Three nVIDIA GeForce GTX 1080, 12 GB
Machine 2: Two nVIDIA GeForce GTX 1080, 12 GB

- **Exact command to reproduce**:
Running object_detection_tutorial.ipynb with different GPUs, either with export CUDA_VISIBLE_DEVICES=, or by setting it in the session config.  Version that runs through 3 GPUs several times and compares output is included.

### Describe the problem
Running on different GPUs yields different results, and GPUs 1 and 2 are not deterministic.  This is accomplished by making devices 1,2 invisible, and tensorflow runs on 0, and so forth.  This is using frozen pretrained networks from this repository's linked [model zoo](https://github.com/tensorflow/models/blob/master/object_detection/g3doc/detection_model_zoo.md) and the supplied object_detection_tutorial.ipynb with no modifications other than setting the cuda visible_device_list.  The SSD frozen models, however, give identical outputs on the 3 GPUs from what I have seen.

I have also run [cuda_memtest](https://sourceforge.net/projects/cudagpumemtest/) on all 3 GPUs, logs attached

UPDATE: I just tested on a second machine with 2 GPUs, and reproduced the issue.  GPU 0 is deterministic, GPU 1 is not (and often produces bad results).

### Source code / logs
I've attached the diff of the modified object_detection_tutorial.ipynb which loops over 3 GPUs 3 times and prints out the top box scores, which change depending on the run.  Also attached is a PDF of that ipynb with detections drawn on it.  Text output:

> Evaluating image 0
> 
> 	Running on GPU 0
> 		Top 4 box scores: 
> 		Iter 1: [ 0.99978215  0.99857557  0.95300484  0.91580492]
> 		Iter 2: [ 0.99978215  0.99857557  0.95300484  0.91580492]
> 		Iter 3: [ 0.99978215  0.99857557  0.95300484  0.91580492]
> 
> 	Running on GPU 1
> 		Top 4 box scores: 
> 		Iter 1: [ 0.68702352  0.16781448  0.13143283  0.12993629]
> 		Iter 2: [ 0.18502565  0.16854601  0.08074528  0.07859289]
> 		Iter 3: [ 0.18502565  0.16854601  0.05546702  0.05111229]
> 
> 	Running on GPU 2
> 		Top 4 box scores: 
> 		Iter 1: [ 0.68702352  0.16781448  0.13143283  0.12993629]
> 		Iter 2: [ 0.18941374  0.18502565  0.16854601  0.16230994]
> 		Iter 3: [ 0.18502565  0.16854601  0.05546702  0.05482833]
> 
> 
> Evaluating image 1
> 
> 	Running on GPU 0
> 		Top 4 box scores: 
> 		Iter 1: [ 0.99755412  0.99750346  0.99380219  0.99067008]
> 		Iter 2: [ 0.99755412  0.99750346  0.99380219  0.99067008]
> 		Iter 3: [ 0.99755412  0.99750346  0.99380219  0.99067008]
> 
> 	Running on GPU 1
> 		Top 4 box scores: 
> 		Iter 1: [ 0.96881998  0.96441168  0.96164131  0.96006596]
> 		Iter 2: [ 0.9377929   0.91686022  0.80374646  0.79758978]
> 		Iter 3: [ 0.90396696  0.89217037  0.85456908  0.85334581]
> 
> 	Running on GPU 2
> 		Top 4 box scores: 
> 		Iter 1: [ 0.9377929   0.91686022  0.80374646  0.79758978]
> 		Iter 2: [ 0.9377929   0.91686022  0.80374646  0.79758978]
> 		Iter 3: [ 0.9377929   0.91686022  0.80374646  0.79758978]

[object_detection_tutorial.diff.txt](https://github.com/tensorflow/models/files/1313430/object_detection_tutorial.diff.txt)

[gpu_output_differences.pdf](https://github.com/tensorflow/models/files/1313428/gpu_output_differences.pdf)

Updated with longer run:
[cuda_memtest.log.txt](https://github.com/tensorflow/models/files/1315285/cuda_memtest.log.txt)


",EpochalEngineer,b'type:bug',2017-09-13T01:39:20Z,2020-02-07T18:42:43Z,,,,,,,
2372,A bug in object detection?,"In [argmax_matcher.py](https://github.com/tensorflow/models/blob/master/object_detection/matchers/argmax_matcher.py#L158), the algorithm of `_force_match_for_each_row` is wrong?

It seems that use the maximum of row to force_match_for_each_row, but many rows can have  maximum  with the same column.

For example,  to use similarity
```
similarity = np.array([[0,1,2],
                        [1,2,3],
                        [2,3,4]], dtype=np.int32)
```
instead of similarity in [test_return_correct_matches_unmatched_row_while_using_force_match](https://github.com/tensorflow/models/blob/master/object_detection/matchers/argmax_matcher_test.py#L167). You will get matched_rows with length of 2.

Another question is [assertEmpty](https://github.com/tensorflow/models/blob/master/object_detection/matchers/argmax_matcher_test.py#L47), it will raise a error, because I can't find it is a member function of `tf.test.TestCase`.

",gauss-clb,b'stat:awaiting model gardener type:bug',2017-09-12T11:40:00Z,2020-02-07T18:42:43Z,,,,,,,
2299,BUG: Fix inception imagenet download script,"In [`download_imagenet.sh`](inception/inception/data/download_imagenet.sh), the path to the `$SYNSETS_FILE` resource (`imagenet_2012_validation_synset_labels.txt`) was not working due to a `cd` earlier in the script.

This is fixed by prepending the initial directory path to the path to the resource file (`$SYNSETS_FILE`) when we try to access it.

Fixes #682.",scottclowe,b'cla: yes',2017-08-28T12:17:10Z,2018-03-03T18:45:13Z,,,,,,,
2259,bugfix for rnn tutorial on Python3,"`str` object doesn't have `decode` method and so `tutorials/rnn/ptb/reader.py` doesn't work on Python3.

Actually we don't have to call `decode` method even if we use Python2 because the data used in the tutorial only include ascii characters.
I wrote the code which have `if` condition for `Py3` to apply this code to some texts include non-ascii characters.",skwbc,b'cla: yes',2017-08-19T12:35:17Z,2017-09-09T02:27:46Z,,,,,,,
2255,Huge RAM usage with LFADS model,"We observed that when we tried to run LFADS on continuous data (hence using gaussian cost function of LFADS) with 300 trials where the data dimensionality was 40 and the length of each trial was 900 time samples ( 300x40x900 matrix), LFADS takes a huge amount of RAM (CPU RAM) about 30+GB.
The RAM usage gradually ramps up to 30+GB, and most of the RAM growth occurs during the initial part of the training (or even before the training starts) and it becomes steady after that. The GPU RAM usage would be around 1GB.

We also observed that the length of the trials (time samples - in our case 900) is the critical variable that sets the RAM usage, the number of trials and data dimensionality do not lead to this huge memory usage. If we decrease the time samples for e.g. to 300, the RAM usage significantly decreases (to e.g. 2-4GB range). 

We are using LFADS model:
https://github.com/tensorflow/models/tree/master/lfads
Tensorflow ver: 1.2
Cuda Ver: 8.0
OS: Linux CentOS

This issue limits us from being able to use LFADS on data with a hundreds of time sample long due to this memory issue. 
",mrezak,b'stat:awaiting model gardener type:bug',2017-08-19T05:19:38Z,2020-02-07T18:42:41Z,,,,,,,
2251,Bugfix for missing function rotator_metrics in models/ptn,"This PR fixes the known bug when evaluating the rotator model in models/ptn. #2240 

Please check this out @arkanath @mees ",xcyan,b'cla: yes',2017-08-18T10:31:21Z,2017-08-18T18:06:53Z,,,,,,,
2243,Cost calculation in Variational Autoencoder model is wrong,"### System information
- **What is the top-level directory of the model you are using**: autoencoder
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: no
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 14.04
- **TensorFlow installed from (source or binary)**: not relevant
- **TensorFlow version (use command below)**: not relevant
- **Bazel version (if compiling from source)**:not relevant
- **CUDA/cuDNN version**: not relevant
- **GPU model and memory**: not relevant
- **Exact command to reproduce**: not relevant

### Describe the problem
The [reconstruction error](https://github.com/tensorflow/models/blob/master/autoencoder/autoencoder_models/VariationalAutoencoder.py#L24) in variational autoencoder is calculated without specifying the ""axis"" argument, resulting in calculating the sum of reconstruction error across the whole batch. However, the [latent error](https://github.com/tensorflow/models/blob/master/autoencoder/autoencoder_models/VariationalAutoencoder.py#L25) is calculated with axis=1, resulting in a 1D vector representing the latent error for each sample in the batch. When we add them up and take the average to get the [cost](https://github.com/tensorflow/models/blob/master/autoencoder/autoencoder_models/VariationalAutoencoder.py#L26), the 0-d reconstruction error will get broadcast to each element of the latent error, resulting in a larger cost than it should be. The right way should be either mean + mean, or mean(vector + vector).

### Source code / logs
N/A
",haoyangz,b'help wanted type:bug',2017-08-17T23:37:57Z,2020-02-07T18:42:40Z,,,,,,,
2169,Computation of quantized graph is slower than unquantized graph [Galaxy S8],"The performance result of the benchmark tool on S8 and also S7 shows that quantized computation is much slower than unquantized 32float computation! I saw previous issues on this but those are regarding mainly on intel CPU platform and I know that gemmlowp is not optimized for x86 CPU. Though gemmlowp is highly optimized for ARM NEON SIMD, it still lacks performance compared to 32float!

Platform: S8, compiled from source for arm64-v8a, Tensorflow  v1.0.1
Inception-v3 (optimized for inference, 32float) has 1.17x higher performance than Inception-v3 (optimized for inference & quantized, 8bit)

Inception-v1 (optimized for inference, 32float) has 3.65x higher performance than Inception-v1 (optimized for inference & quantized, 8bit)




",atrah22,b'type:bug',2017-08-09T08:30:16Z,2018-08-01T20:07:48Z,,,,,,,
2145,Bug: Change protobuf to list in Object Detection API,"
there is a 'subtract_channel_mean' preprocess op in Object Detection API.
https://github.com/tensorflow/models/blob/master/object_detection/core/preprocessor.py#L1462

Problem 1:
When I add this preprocessing op in the pipeline.config, and begin to train, it raises error:

    TypeError: Expected float32, got <google.protobuf.pyext._message.RepeatedScalarContainer object at 0x7f17df4fde30> of type 'RepeatedScalarContainer' instead.

Add 'means = list(means)' before Line 1474, and the problem solved(but this way is not elegant).

You need to fix it.

Problem 2:
This config is in the model config as a preprocessing config. However, it seems that if this operation be done in the training procedure, it also need to be done in the eval & test. But it seems not.
",irmowan,b'stat:awaiting model gardener',2017-08-07T09:59:53Z,2020-02-07T18:42:37Z,,,,,,,
2137,Couldn't restore attention_ocr variables from .index and .data checkpoints,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
MacOS Sierra 10.12.5
- **TensorFlow installed from (source or binary)**:
created environment in conda, then installed tf via pip
- **TensorFlow version (use command below)**:
('v1.2.0-rc2-21-g12f033d', '1.2.0')
- **Python version**: 
2.7
- **Bazel version (if compiling from source)**:
Not installed
- **CUDA/cuDNN version**:
No GPU supported
- **GPU model and memory**:
No
- **Exact command to reproduce**:
python test.py
You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

Hi, I am trying to use attention_ocr in my own data, a simple test is firstly implemented.
according to the instructions from [How to use a pre-trained model](https://github.com/tensorflow/models/tree/master/attention_ocr#how-to-use-a-pre-trained-model) but somehow failed in restoring the checkpoints without explicit error info.

The following condition has been checked:
1. checkpoint files are complete
2. right path to the checkpoint
3. graphs have been imported from .meta
4. Nothing changes after run saver.train.restore() (predictions remained the same)
5. No error or hints provided

The checkpoint was downloaded as suggested:
```
wget http://download.tensorflow.org/models/attention_ocr_2017_05_17.tar.gz
tar xf attention_ocr_2017_05_17.tar.gz
cd attention_ocr_2017_05_17
ls -lh
```
```
total 64216
-rw-r-----  1 liuhuichuan  staff    14M  5 18 04:07 model.ckpt-399731.data-00000-of-00001
-rw-r-----  1 liuhuichuan  staff   8.2K  5 18 04:07 model.ckpt-399731.index
-rw-r-----  1 liuhuichuan  staff    17M  5 18 04:07 model.ckpt-399731.meta
```

The graphs were successfully imported from .meta, but somehow saver couldn't recognize .index and .data files: 
```
print os.path.exists('../attention_ocr_2017_05_17/model.ckpt-399731.data-00000-of-00001')
print os.path.exists('../attention_ocr_2017_05_17/model.ckpt-399731.index')
print tf.train.get_checkpoint_state('../attention_ocr_2017_05_17/model.ckpt-399731')
```
returns:
```
Ture
Ture
None
```
A very simple test is attempted:
```
saver = tf.train.import_meta_graph('../attention_ocr_2017_05_17/model.ckpt-399731.meta')
with tf.Session() as sess:
    print os.path.exists('./attention_ocr_2017_05_17/model.ckpt-399731.meta')
    print tf.train.get_checkpoint_state('../attention_ocr_2017_05_17/model.ckpt-399731')
    saver.restore(sess,'../attention_ocr_2017_05_17/model.ckpt-399731')
```
returns no error, but still not restored:
```
2017-08-06 16:24:41.346086: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
True
2017-08-06 16:24:41.346124: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2017-08-06 16:24:41.346129: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2017-08-06 16:24:41.346133: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
None
INFO:tensorflow:Restoring parameters from ../attention_ocr_2017_05_17/model.ckpt-399731
INFO 2017-08-06 16:24:41.000354: tf_logging.py: 82 Restoring parameters from ../attention_ocr_2017_05_17/model.ckpt-399731

Process finished with exit code 0
```

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.

```
import tensorflow as tf
import os
from tensorflow.python.platform import flags
import matplotlib.image as mpimg
import common_flags

FLAGS = flags.FLAGS
common_flags.define()

# yapf: disable
flags.DEFINE_integer('num_batches', 100,
                     'Number of batches to run eval for.')

flags.DEFINE_string('eval_log_dir', '/tmp/attention_ocr/eval',
                    'Directory where the evaluation results are saved to.')

flags.DEFINE_integer('eval_interval_secs', 60,
                     'Frequency in seconds to run evaluations.')

flags.DEFINE_integer('number_of_steps', None,
                     'Number of times to run evaluation.')


# fake a simple test image

raw_image_data = mpimg.imread('A4A8A5910A355-cvt.jpg').reshape((1,150,600,3))
images_placeholder = tf.placeholder(tf.float32,shape = (1,150, 600, 3),name='img_data')

if not tf.gfile.Exists(FLAGS.eval_log_dir):
    tf.gfile.MakeDirs(FLAGS.eval_log_dir)
dataset = common_flags.create_dataset(split_name=FLAGS.split_name)
model = common_flags.create_model(dataset.num_char_classes,
                                    dataset.max_sequence_length,
                                    dataset.num_of_views, dataset.null_code)
endpoints = model.create_base(images_placeholder, labels_one_hot=None)

# start loading attention_ocr model

saver = tf.train.import_meta_graph('../attention_ocr_2017_05_17/model.ckpt-399731.meta')

with tf.Session() as sess:
    # init without checkpoint variables and predict
    init = tf.global_variables_initializer()
    sess.run(init)
    predictions = sess.run(endpoints.predicted_chars, feed_dict={images_placeholder: raw_image_data})
    print predictions

    # restore from checkpoint then predict
    print os.path.exists('./attention_ocr_2017_05_17/model.ckpt-399731.meta')
    print tf.train.get_checkpoint_state('../attention_ocr_2017_05_17/model.ckpt-399731')
    saver.restore(sess,'../attention_ocr_2017_05_17/model.ckpt-399731')
    predictions = sess.run(endpoints.predicted_chars, feed_dict={images_placeholder: raw_image_data})
    print predictions
```

```
INFO 2017-08-06 16:48:44.000554: fsns.py: 130 Using FSNS dataset split_name=train dataset_dir=/Users/liuhuichuan/PycharmProjects/models/attention_ocr/python/datasets/data/fsns
DEBUG 2017-08-06 16:48:44.000556: model.py: 343 images: Tensor(""img_data:0"", shape=(1, 150, 600, 3), dtype=float32)
DEBUG 2017-08-06 16:48:44.000561: model.py: 348 Views=4 single view: Tensor(""AttentionOcr_v1/split:0"", shape=(1, 150, 150, 3), dtype=float32)
DEBUG 2017-08-06 16:48:44.000561: model.py: 191 Using final_endpoint=Mixed_5d
DEBUG 2017-08-06 16:48:46.000492: model.py: 191 Using final_endpoint=Mixed_5d
DEBUG 2017-08-06 16:48:47.000546: model.py: 191 Using final_endpoint=Mixed_5d
DEBUG 2017-08-06 16:48:48.000684: model.py: 191 Using final_endpoint=Mixed_5d
DEBUG 2017-08-06 16:48:49.000862: model.py: 354 Conv tower: Tensor(""AttentionOcr_v1/conv_tower_fn/INCE/InceptionV3/Mixed_5d/concat:0"", shape=(1, 16, 16, 288), dtype=float32)
DEBUG 2017-08-06 16:48:49.000862: model.py: 357 Conv tower w/ encoded coordinates: Tensor(""AttentionOcr_v1/conv_tower_fn/INCE/InceptionV3/Mixed_5d/concat:0"", shape=(1, 16, 16, 288), dtype=float32)
DEBUG 2017-08-06 16:48:49.000869: model.py: 360 Pooled views: Tensor(""AttentionOcr_v1/pool_views_fn/STCK/Reshape:0"", shape=(1, 1024, 288), dtype=float32)
DEBUG 2017-08-06 16:48:49.000869: sequence_layers.py: 421 Use AttentionWithAutoregression as a layer class
DEBUG 2017-08-06 16:48:53.000099: model.py: 363 chars_logit: Tensor(""AttentionOcr_v1/sequence_logit_fn/SQLR/concat:0"", shape=(1, 37, 134), dtype=float32)
2017-08-06 16:50:05.943512: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2017-08-06 16:50:05.943528: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2017-08-06 16:50:05.943532: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2017-08-06 16:50:05.943537: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
INFO:tensorflow:Restoring parameters from ../attention_ocr_2017_05_17/model.ckpt-399731
INFO 2017-08-06 16:50:29.000024: tf_logging.py: 82 Restoring parameters from ../attention_ocr_2017_05_17/model.ckpt-399731
[[  0   0   0 123 123 123 123 123 123 123 123 123 123 123 123 123 123 123
  123 123 123 123 123 123 123 123 123 123 123 123 123 123 123 123 123 123
  123]]
True
None
[[  0   0   0 123 123 123 123 123 123 123 123 123 123 123 123 123 123 123
  123 123 123 123 123 123 123 123 123 123 123 123 123 123 123 123 123 123
  123]]

Process finished with exit code 0
```
",HuichuanLiu,b'stat:awaiting model gardener type:bug',2017-08-06T09:43:55Z,2017-11-30T06:33:37Z,,,,,,,
2133,Object Detection: Errors with Export/Import for inference,"## System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.2.1
- **Bazel version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: 6.0
- **GPU model and memory**: Tesla P100 16276 MiB
- **Exact command to reproduce**: See description

## Describe the problem
### Overview
Loading a frozen model created with export_inference_graph.py results in ""truncated message: errors.  As a result, I am unable to use the model for inference.  Model was generated at 10,820 iterations training the pet detector example locally.

### Details:
The tutorial given at https://github.com/tensorflow/models/blob/master/object_detection/g3doc/exporting_models.md has some incorrect input option names, however, a few minor changes to the suggested inputs gets export_inference_graph.py to run via:
`python object_detection/export_inference_graph.py --input_type image_tensor --pipeline_config_path /home/qzhrlc/models/object_detection/samples/configs/faster_rcnn_resnet101_pets.config --trained_checkpoint_prefix /path/to/checkpoint/model.ckpt-10820 --output_directory .`

This produces a .pb file, however, some log messages appear which may indicate some issue.  Then, when loading into python via 
`PATH_TO_CKPT = '/home/qzhrlc/models/saved_model/saved_model.pb'`
`detection_graph = tf.Graph()`
`with detection_graph.as_default():`
`  od_graph_def = tf.GraphDef()`
`  with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:`
`    serialized_graph = fid.read()`
`    od_graph_def.ParseFromString(serialized_graph)`
`    tf.import_graph_def(od_graph_def, name='')`
An error is generated on `od_graph_def.ParseFromString(serialized_graph)`  of DecodeError: Truncated message.  Output of export_inference_graph and error message included below.

## Source code / logs
### export_inference_graph output:
2017-08-04 12:00:13.624623: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2017-08-04 12:00:13.624652: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2017-08-04 12:00:13.624656: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2017-08-04 12:00:13.624678: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2017-08-04 12:00:13.624683: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
2017-08-04 12:00:14.054272: I tensorflow/core/common_runtime/gpu/gpu_device.cc:940] Found device 0 with properties: 
name: Tesla P100-SXM2-16GB
major: 6 minor: 0 memoryClockRate (GHz) 1.4805
pciBusID 0000:05:00.0
Total memory: 15.89GiB
Free memory: 514.25MiB
2017-08-04 12:00:14.452981: W tensorflow/stream_executor/cuda/cuda_driver.cc:523] A non-primary context 0x714e4f0 exists before initializing the StreamExecutor. We haven't verified StreamExecutor works with that.
2017-08-04 12:00:14.453690: I tensorflow/core/common_runtime/gpu/gpu_device.cc:940] Found device 1 with properties: 
name: Tesla P100-SXM2-16GB
major: 6 minor: 0 memoryClockRate (GHz) 1.4805
pciBusID 0000:06:00.0
Total memory: 15.89GiB
Free memory: 514.25MiB
2017-08-04 12:00:14.885142: W tensorflow/stream_executor/cuda/cuda_driver.cc:523] A non-primary context 0x7151e80 exists before initializing the StreamExecutor. We haven't verified StreamExecutor works with that.
2017-08-04 12:00:14.885995: I tensorflow/core/common_runtime/gpu/gpu_device.cc:940] Found device 2 with properties: 
name: Tesla P100-SXM2-16GB
major: 6 minor: 0 memoryClockRate (GHz) 1.4805
pciBusID 0000:84:00.0
Total memory: 15.89GiB
Free memory: 514.25MiB
2017-08-04 12:00:15.310494: W tensorflow/stream_executor/cuda/cuda_driver.cc:523] A non-primary context 0x7155810 exists before initializing the StreamExecutor. We haven't verified StreamExecutor works with that.
2017-08-04 12:00:15.311252: I tensorflow/core/common_runtime/gpu/gpu_device.cc:940] Found device 3 with properties: 
name: Tesla P100-SXM2-16GB
major: 6 minor: 0 memoryClockRate (GHz) 1.4805
pciBusID 0000:85:00.0
Total memory: 15.89GiB
Free memory: 514.25MiB
2017-08-04 12:00:15.312769: I tensorflow/core/common_runtime/gpu/gpu_device.cc:961] DMA: 0 1 2 3 
2017-08-04 12:00:15.312779: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   Y Y Y Y 
2017-08-04 12:00:15.312783: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 1:   Y Y Y Y 
2017-08-04 12:00:15.312786: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 2:   Y Y Y Y 
2017-08-04 12:00:15.312790: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 3:   Y Y Y Y 
2017-08-04 12:00:15.312798: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla P100-SXM2-16GB, pci bus id: 0000:05:00.0)
2017-08-04 12:00:15.312805: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:1) -> (device: 1, name: Tesla P100-SXM2-16GB, pci bus id: 0000:06:00.0)
2017-08-04 12:00:15.312810: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:2) -> (device: 2, name: Tesla P100-SXM2-16GB, pci bus id: 0000:84:00.0)
2017-08-04 12:00:15.312832: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:3) -> (device: 3, name: Tesla P100-SXM2-16GB, pci bus id: 0000:85:00.0)
2017-08-04 12:01:02.982605: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla P100-SXM2-16GB, pci bus id: 0000:05:00.0)
2017-08-04 12:01:02.982634: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:1) -> (device: 1, name: Tesla P100-SXM2-16GB, pci bus id: 0000:06:00.0)
2017-08-04 12:01:02.982656: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:2) -> (device: 2, name: Tesla P100-SXM2-16GB, pci bus id: 0000:84:00.0)
2017-08-04 12:01:02.982661: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:3) -> (device: 3, name: Tesla P100-SXM2-16GB, pci bus id: 0000:85:00.0)
Converted 530 variables to const ops.
2017-08-04 12:01:12.496242: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla P100-SXM2-16GB, pci bus id: 0000:05:00.0)
2017-08-04 12:01:12.496283: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:1) -> (device: 1, name: Tesla P100-SXM2-16GB, pci bus id: 0000:06:00.0)
2017-08-04 12:01:12.496288: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:2) -> (device: 2, name: Tesla P100-SXM2-16GB, pci bus id: 0000:84:00.0)
2017-08-04 12:01:12.496292: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:3) -> (device: 3, name: Tesla P100-SXM2-16GB, pci bus id: 0000:85:00.0)


### Import error message:
---------------------------------------------------------------------------
DecodeError                               Traceback (most recent call last)
<ipython-input-7-0e97fbc26e6d> in <module>()
      4   with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:
      5     serialized_graph = fid.read()
----> 6     od_graph_def.ParseFromString(serialized_graph)
      7     tf.import_graph_def(od_graph_def, name='')

/home/qzhrlc/miniconda2/envs/ajlBaseCaffe/lib/python2.7/site-packages/google/protobuf/message.pyc in ParseFromString(self, serialized)
    183     """"""
    184     self.Clear()
--> 185     self.MergeFromString(serialized)
    186 
    187   def SerializeToString(self):

/home/qzhrlc/miniconda2/envs/ajlBaseCaffe/lib/python2.7/site-packages/google/protobuf/internal/python_message.pyc in MergeFromString(self, serialized)
   1060     length = len(serialized)
   1061     try:
-> 1062       if self._InternalParse(serialized, 0, length) != length:
   1063         # The only reason _InternalParse would return early is if it
   1064         # encountered an end-group tag.

/home/qzhrlc/miniconda2/envs/ajlBaseCaffe/lib/python2.7/site-packages/google/protobuf/internal/python_message.pyc in InternalParse(self, buffer, pos, end)
   1096         pos = new_pos
   1097       else:
-> 1098         pos = field_decoder(buffer, new_pos, end, self, field_dict)
   1099         if field_desc:
   1100           self._UpdateOneofState(field_desc)

/home/qzhrlc/miniconda2/envs/ajlBaseCaffe/lib/python2.7/site-packages/google/protobuf/internal/decoder.pyc in DecodeField(buffer, pos, end, message, field_dict)
    631         raise _DecodeError('Truncated message.')
    632       # Read sub-message.
--> 633       if value._InternalParse(buffer, pos, new_pos) != new_pos:
    634         # The only reason _InternalParse would return early is if it encountered
    635         # an end-group tag.

/home/qzhrlc/miniconda2/envs/ajlBaseCaffe/lib/python2.7/site-packages/google/protobuf/internal/python_message.pyc in InternalParse(self, buffer, pos, end)
   1096         pos = new_pos
   1097       else:
-> 1098         pos = field_decoder(buffer, new_pos, end, self, field_dict)
   1099         if field_desc:
   1100           self._UpdateOneofState(field_desc)

/home/qzhrlc/miniconda2/envs/ajlBaseCaffe/lib/python2.7/site-packages/google/protobuf/internal/decoder.pyc in DecodeRepeatedField(buffer, pos, end, message, field_dict)
    610           raise _DecodeError('Truncated message.')
    611         # Read sub-message.
--> 612         if value.add()._InternalParse(buffer, pos, new_pos) != new_pos:
    613           # The only reason _InternalParse would return early is if it
    614           # encountered an end-group tag.

/home/qzhrlc/miniconda2/envs/ajlBaseCaffe/lib/python2.7/site-packages/google/protobuf/internal/python_message.pyc in InternalParse(self, buffer, pos, end)
   1096         pos = new_pos
   1097       else:
-> 1098         pos = field_decoder(buffer, new_pos, end, self, field_dict)
   1099         if field_desc:
   1100           self._UpdateOneofState(field_desc)

/home/qzhrlc/miniconda2/envs/ajlBaseCaffe/lib/python2.7/site-packages/google/protobuf/internal/decoder.pyc in DecodeMap(buffer, pos, end, message, field_dict)
    741       # Read sub-message.
    742       submsg.Clear()
--> 743       if submsg._InternalParse(buffer, pos, new_pos) != new_pos:
    744         # The only reason _InternalParse would return early is if it
    745         # encountered an end-group tag.

/home/qzhrlc/miniconda2/envs/ajlBaseCaffe/lib/python2.7/site-packages/google/protobuf/internal/python_message.pyc in InternalParse(self, buffer, pos, end)
   1086       if field_decoder is None:
   1087         value_start_pos = new_pos
-> 1088         new_pos = local_SkipField(buffer, new_pos, end, tag_bytes)
   1089         if new_pos == -1:
   1090           return pos

/home/qzhrlc/miniconda2/envs/ajlBaseCaffe/lib/python2.7/site-packages/google/protobuf/internal/decoder.pyc in SkipField(buffer, pos, end, tag_bytes)
    848     # The wire type is always in the first byte since varints are little-endian.
    849     wire_type = ord(tag_bytes[0:1]) & wiretype_mask
--> 850     return WIRETYPE_TO_SKIPPER[wire_type](buffer, pos, end)
    851 
    852   return SkipField

/home/qzhrlc/miniconda2/envs/ajlBaseCaffe/lib/python2.7/site-packages/google/protobuf/internal/decoder.pyc in _SkipGroup(buffer, pos, end)
    797   while 1:
    798     (tag_bytes, pos) = ReadTag(buffer, pos)
--> 799     new_pos = SkipField(buffer, pos, end, tag_bytes)
    800     if new_pos == -1:
    801       return pos

/home/qzhrlc/miniconda2/envs/ajlBaseCaffe/lib/python2.7/site-packages/google/protobuf/internal/decoder.pyc in SkipField(buffer, pos, end, tag_bytes)
    848     # The wire type is always in the first byte since varints are little-endian.
    849     wire_type = ord(tag_bytes[0:1]) & wiretype_mask
--> 850     return WIRETYPE_TO_SKIPPER[wire_type](buffer, pos, end)
    851 
    852   return SkipField

/home/qzhrlc/miniconda2/envs/ajlBaseCaffe/lib/python2.7/site-packages/google/protobuf/internal/decoder.pyc in _SkipFixed32(buffer, pos, end)
    812   pos += 4
    813   if pos > end:
--> 814     raise _DecodeError('Truncated message.')
    815   return pos
    816 

DecodeError: Truncated message.
",matlabninja,b'type:bug',2017-08-04T16:20:58Z,2018-04-09T14:39:22Z,,,,,,,
2038,[object detection] Dequeue placement issue,"### System information
- **What is the top-level directory of the model you are using**:
object_detection
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Windows Server 2012 R2
- **TensorFlow installed from (source or binary)**:
Binary
- **TensorFlow version (use command below)**:
1.3.0rc0
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
8.0 / 5.1.10
- **GPU model and memory**:
GTX 1080 Ti 11GB
- **Exact command to reproduce**:
```
python C:\Users\name\git-repos\models\object_detection\train.py --logtostderr --pipe
line_config_path=ssd_inception_v2.config --train_dir=.
```
### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

The output of the object_detection `train.py` file includes this line:

```
2017-07-25 12:39:37.289202: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\core\common_runtime\simple_placer.cc:697] Ignoring device specification /device:GPU:0 for node 'prefetch_queue_Dequeue' because the input edge from 'prefetch_queue' is a reference connection and already has a device field set to /device:CPU:0
```

This is related to issue #1390. Is this a performance problem? This problem existed in 1.2.x as well.
",MaxBareiss,b'models:research stat:awaiting response type:bug',2017-07-25T16:54:26Z,2020-02-07T18:42:26Z,,,,,,,
2020,Unable to run translate.py with tensorflow version 1.0 on windows  an Invalid argument error is thrown,"I get this error when trying to run seq-seq model in tensorflow version 1.0

Windows 10 (CPU)
Python 3.5


when i run the following command : python translate.py --decode, the following error is displayed:

"" InvalidArgumentError (see above for traceback): Assign requires shapes of both tensors to match. lhs shape= [1024] rhs shape= [256]
         [[Node: save/Assign_2 = Assign[T=DT_FLOAT, _class=[""loc:@embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/biases""], use_locking=true, validate_shape=true, _device=""/job:localhost/replica:0/task:0/cpu:0""](embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/biases, save/RestoreV2_2)]]"" ",soukira,b'stat:awaiting model gardener type:bug',2017-07-24T16:21:48Z,2018-10-20T02:09:36Z,,,,,,,
2016,Spatial Transformer Networks cuts off last row and column off input,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
models/transformer
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
Only the script attached below to reproduce the issue
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Tested on both MacOS Sierra and Linux Ubuntu 16.04.2 LTS
- **TensorFlow installed from (source or binary)**:
binary
- **TensorFlow version (use command below)**:
1.2.1
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
n/a
- **GPU model and memory**:
n/a
- **Exact command to reproduce**:

```python
import tensorflow as tf
import numpy as np
from spatial_transformer import transformer

def identity():

    original_theta = np.array([[1., 0., 0.],
                               [0., 1., 0.]])

    theta = tf.Variable(initial_value=np.expand_dims(original_theta.flatten(), 0))
    
    original_U = np.reshape(np.arange(25, dtype=""float32""), [5,5])
    reshaped_U = np.expand_dims(np.expand_dims(original_U, 2), 0)
    U = tf.Variable(initial_value=reshaped_U)

    assert(U.shape == (1,5,5,1))
    assert(theta.shape == (1,6))

    raw_output = transformer(U, theta, (5,5))
    
    sess = tf.Session()
    sess.run(tf.global_variables_initializer())
    output = np.array(sess.run(raw_output))
   
    assert(reshaped_U.shape == (1,5,5,1))
    assert(output.shape == (1,5,5,1))

    print(output)
    print(reshaped_U)

    assert((output == reshaped_U).all())
```

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

I cloned the models/transformer directory to generalize 2D spatial transformers to 3D. In the process, I found a few bugs that caused spatial transformers to not output the exact transformation specified. After investigating, I found that there are some indexing errors which cause the problem shown above. I'd be happy to make a PR for any or all of the following if it would be helpful:
1) The fixed 2D spatial transformer
2) Newly implemented 3D spatial transformer
3) Basic test cases for both of the above

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",hughbzhang,b'stat:community support type:bug',2017-07-24T03:18:20Z,2020-02-07T18:42:25Z,,,,,,,
1876,API ObjectDetection size of  input images issues ,"**GPU  : GeForce GTX 1080 Ti/PCIe/SSE2 (11 GB)**
**Tensorflow version: 1.1.0**
**Python version: 2.7.12**
**Model checkpoint : ssd_mobilenet_v1_coco_11_06_2017**

**Context** :After read the tutorial of ObjectDetection, I converted my own image data sets to tfRecord files by create the *.xml file to each image. As the sizes of images of my own data sets are very large : about **width=4000pixels** and **height=2000pixels** for each , the train.tfRecord is about **55G**.

**Issues**: When I began to train with **train.py** by using the lightest model  **ssd_mobilenet_v1_coco_11_06_2017**, after 4-5 steps, it crashed by error OOM.
The error message is below:
![125](https://user-images.githubusercontent.com/29950360/27914310-08056dd6-6263-11e7-83ca-8249a3ff0c9a.png)
Il seems like that the OOM error happened when allocating tensor with shape[1,2969,3546,3],
As the capacity of my GPU is 11GB, I didn't understand why it causes this problem..





",chenyuZha,b'stat:awaiting model gardener type:bug',2017-07-06T14:06:43Z,2020-07-07T14:37:25Z,,,,,,,
1598,Follow TF performance guide in models available here,"### System information
N/A

### Describe the problem
Currently, none of the models available here generally follow the TF performance guidelines. None of the models here support running in NCHW, and only the newest object detection models use the fused batch norm op.

As such, this makes the [published TF benchmarks](https://www.tensorflow.org/performance/benchmarks) somewhat misleading – while those benchmarks run at competitive speeds, the actual reference model code published here does not, and instead takes a very large performance hit.

Ideally the first-party example code here should all support NCHW and use fused batch norm where relevant, such that the performance obtained here is actually comparable with the claims made via the posted benchmarks.",taion,b'stat:awaiting response type:bug',2017-06-17T23:21:11Z,2017-06-20T20:12:21Z,,,,,,,
1587,"Mention of Python 3: AttributeError: 'dict' object has no attribute 'iteritems' for ""python ./object_detection/builders/model_builder_test.py""","When you meet this:

```
File ""./object_detection/builders/model_builder_test.py"", line 258, in test_create_faster_rcnn_resnet_v1_models_from_config

File ""./object_detection/builders/model_builder_test.py"", line 448, in test_create_rfcn_resnet_v1_model_from_config

```
This is a Python 2 to Python 3 of dict change.

Solution:
_change iteritems() to items()_

`for extractor_type, extractor_class in FEATURE_EXTRACTOR_MAPS.items():`

Then,
`python ./object_detection/builders/model_builder_test.py`

.......
----------------------------------------------------------------------
Ran 7 tests in 0.055s

OK

",zhouphd,b'help wanted type:bug',2017-06-16T21:28:50Z,2019-11-09T16:48:56Z,,,,,,,
1585,object_detection/models/faster_rcnn_resnet_v1_feature_extractor_test.py Broken !,"Looks like resnet_v1 feature extractors are broken. Here is the log of running the test - ` python models/faster_rcnn_resnet_v1_feature_extractor_test.py`

```======================================================================
ERROR: test_extract_proposal_features_stride_eight (__main__.FasterRcnnResnetV1FeatureExtractorTest)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""models/faster_rcnn_resnet_v1_feature_extractor_test.py"", line 65, in test_extract_proposal_features_stride_eight
    preprocessed_inputs, scope='TestScope')
  File ""/models/object_detection/meta_architectures/faster_rcnn_meta_arch.py"", line 131, in extract_proposal_features
    return self._extract_proposal_features(preprocessed_inputs, scope)
  File ""/models/object_detection/models/faster_rcnn_resnet_v1_feature_extractor.py"", line 125, in _extract_proposal_features
    scope=var_scope)
  File ""/models/slim/nets/resnet_v1.py"", line 280, in resnet_v1_101
    reuse=reuse, scope=scope)
  File ""/models/slim/nets/resnet_v1.py"", line 204, in resnet_v1
    logits = tf.squeeze(net, [1, 2], name='SpatialSqueeze')
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/array_ops.py"", line 2281, in squeeze
    return gen_array_ops._squeeze(input, axis, name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_array_ops.py"", line 3329, in _squeeze
    squeeze_dims=squeeze_dims, name=name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py"", line 767, in apply_op
    op_def=op_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 2508, in create_op
    set_shapes_for_outputs(ret)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 1873, in set_shapes_for_outputs
    shapes = shape_func(op)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 1823, in call_with_requiring
    return call_cpp_shape_fn(op, require_shape_fn=True)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/common_shapes.py"", line 610, in call_cpp_shape_fn
    debug_python_shape_fn, require_shape_fn)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/common_shapes.py"", line 676, in _call_cpp_shape_fn_impl
    raise ValueError(err.message)
ValueError: Can not squeeze dim[1], expected a dimension of 1, got 28 for 'TestScope/resnet_v1_101/resnet_v1_101/SpatialSqueeze' (op: 'Squeeze') with input shapes: [4,28,28,2048].

----------------------------------------------------------------------
```",darshanhegde,b'stat:awaiting response type:bug',2017-06-16T20:58:51Z,2017-06-16T21:51:09Z,,,,,,,
1576,no test_ckpt/ssd_inception_v2.pb file for /models/object_detection/object_detection_tutorial.ipynb,"Thanks for your new Great object detection model.

I'm trying to test  /models/object_detection/object_detection_tutorial.ipynb with jupyter notebook.

but there missing file , ""test_ckpt/ssd_inception_v2.pb""

this is sample code.

PATH_TO_CKPT = os.path.join('test_ckpt', 'ssd_inception_v2.pb')

and,

with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:
        serialized_graph = fid.read()
        od_graph_def.ParseFromString(serialized_graph)
        tf.import_graph_def(od_graph_def, name='')

So , PATH_TO_CKPT( = test_ckpt/ssd_inception_v2.pb) is need to run test code.

please check it and let me know how to down load this file please. :-)

Thanks for reading!",Jun-13,b'stat:awaiting response type:bug',2017-06-16T11:30:44Z,2017-10-27T07:48:58Z,,,,,,,
1541,rnn/ptb/ptb_word_lm.py cannot run with Python3 due to str.decode,"The example rnn/ptg/ptb_word_lm.py  cannot run with Python3. 
~/models/tutorials/rnn/ptb$ python3 ptb_word_lm.py --data_path=/tmp/simple-examples/data --model=small
Traceback (most recent call last):
  File ""ptb_word_lm.py"", line 385, in <module>
    tf.app.run()
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/platform/app.py"", line 48, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""ptb_word_lm.py"", line 332, in main
    raw_data = reader.ptb_raw_data(FLAGS.data_path)
  File ""/home/vanmao_ngo/models/tutorials/rnn/ptb/reader.py"", line 73, in ptb_raw_data
    word_to_id = _build_vocab(train_path)
  File ""/home/vanmao_ngo/models/tutorials/rnn/ptb/reader.py"", line 34, in _build_vocab
    data = _read_words(filename)
  File ""/home/vanmao_ngo/models/tutorials/rnn/ptb/reader.py"", line 30, in _read_words
    return f.read().decode(""utf-8"").replace(""\n"", ""<eos>"").split()
AttributeError: 'str' object has no attribute 'decode'

The problem is as clear as the message: str.decode is not necessary in Python3. 

# Solution: Change in the reader.py file, just remove decode(""utf-8""). 
The full solution should handle both Python 2 and Python 3. 
if sys.version_info[0] >= 3:
  return f.read().replace(""\n"", ""<eos>"").split()
else:
 return f.read().decode(""utf-8"").replace(""\n"", ""<eos>"").split()",ngovanmao,b'type:bug',2017-06-09T13:18:38Z,2017-06-13T15:59:30Z,,,,,,,
1476,Attention_OCR Model,"### System information
- What is the top-level directory of the model you are using: attention_ocr
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): stock code
- OS Platform and Distribution: Linux Ubuntu 16.04
- TensorFlow installed from (source or binary): installed via pip
- TensorFlow version (use command below): 1.0.1 [also tried it in 1.1.0]
- Bazel version (if compiling from source): N/A
- CUDA/cuDNN version: I'm using CPU

### Describe the problem
I'm trying to execute the code posted in the readme file:

> wget http://download.tensorflow.org/models/attention_ocr_2017_05_01.tar.gz
> tar xf attention_ocr_2017_05_01.tar.gz
> python train.py --checkpoint=model.ckpt-232572

1. I noticed the checkpoint number (232672) written in the readme is not the same as the one found in the tar.gz file (230849). 
2. I also placed the three files (model.ckpt-230849.data-00000-of-00001, model.ckpt-230849.index, model.ckpt-230849.meta) found in attention_ocr_2017_05_01.tar.gz in the same directory as the train.py and the script can't seem to find the model file. I also tried changing the checkpoint parameter to  --checkpoint=model.ckpt-230849 and the script can't still find it.
3. Also, is there a way for me to use my own images instead of the FSNS?

### Log
  File ""/opt/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/framework/python/ops/variables.py"", line 512, in assign_from_checkpoint
    reader = pywrap_tensorflow.NewCheckpointReader(model_path)
  File ""/opt/anaconda2/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 110, in NewCheckpointReader
    return CheckpointReader(compat.as_bytes(filepattern), status)
  File ""/opt/anaconda2/lib/python2.7/contextlib.py"", line 24, in __exit__
    self.gen.next()
  File ""/opt/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/errors_impl.py"", line 466, in raise_exception_on_not_ok_status
    pywrap_tensorflow.TF_GetCode(status))
tensorflow.python.framework.errors_impl.NotFoundError: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for model.ckpt-232572
",leifsyliongka,b'stat:awaiting response type:bug',2017-05-17T03:24:38Z,2017-05-31T03:17:27Z,,,,,,,
1436,[slim] Python 3 support,"### System information
- **What is the top-level directory of the model you are using**: slim
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: no
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: MacOS 10.12.3 (16D32)
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.1.0
- **Bazel version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**: `cd slim && python download_and_convert_data.py --dataset_name=flowers --dataset_dir=data`

Here's the output from the environment capture script:

```

== cat /etc/issue ===============================================
Darwin Brandons-MBP.connect 16.4.0 Darwin Kernel Version 16.4.0: Thu Dec 22 22:53:21 PST 2016; root:xnu-3789.41.3~3/RELEASE_X86_64 x86_64
Mac OS X 10.12.3

== are we in docker =============================================
No

== compiler =====================================================
Apple LLVM version 8.0.0 (clang-800.0.42.1)
Target: x86_64-apple-darwin16.4.0
Thread model: posix
InstalledDir: /Library/Developer/CommandLineTools/usr/bin

== uname -a =====================================================
Darwin Brandons-MBP.connect 16.4.0 Darwin Kernel Version 16.4.0: Thu Dec 22 22:53:21 PST 2016; root:xnu-3789.41.3~3/RELEASE_X86_64 x86_64

== check pips ===================================================
numpy (1.12.1)
protobuf (3.2.0)
tensorflow (1.1.0)

== check for virtualenv =========================================
False

== tensorflow import ============================================
tf.VERSION = 1.1.0
tf.GIT_VERSION = v1.1.0-rc0-61-g1ec6ed5
tf.COMPILER_VERSION = v1.1.0-rc0-61-g1ec6ed5
Sanity check: array([1], dtype=int32)

== env ==========================================================
LD_LIBRARY_PATH is unset
DYLD_LIBRARY_PATH is unset

== nvidia-smi ===================================================

== cuda libs  ===================================================
```

### Describe the problem
The slim/download_and_convert_data.py script doesn't work with Python 3.6.0.  It gives the following output:

```Python traceback
Traceback (most recent call last):
  File ""download_and_convert_data.py"", line 39, in <module>
    from datasets import download_and_convert_cifar10
  File ""/Users/pokey/src/deep-stats/models/slim/datasets/download_and_convert_cifar10.py"", line 29, in <module>
    import cPickle
ModuleNotFoundError: No module named 'cPickle'
```

To fix this, I patched as follows:

```diff
diff --git a/slim/datasets/download_and_convert_cifar10.py b/slim/datasets/download_and_convert_cifar10.py
index 2cb787d..ee8928b 100644
--- a/slim/datasets/download_and_convert_cifar10.py
+++ b/slim/datasets/download_and_convert_cifar10.py
@@ -26,7 +26,7 @@ from __future__ import absolute_import
 from __future__ import division
 from __future__ import print_function
 
-import cPickle
+import pickle
 import os
 import sys
 import tarfile
@@ -73,7 +73,7 @@ def _add_to_tfrecord(filename, tfrecord_writer, offset=0):
     The new offset.
   """"""
   with tf.gfile.Open(filename, 'r') as f:
-    data = cPickle.load(f)
+    data = pickle.load(f)
 
   images = data['data']
   num_images = images.shape[0]
```

However, I then get the following:

```Python traceback
>> Downloading flower_photos.tgz 100.0%
Successfully downloaded flower_photos.tgz 228813984 bytes.
>> Converting image 1/3320 shard 0Traceback (most recent call last):
  File ""download_and_convert_data.py"", line 73, in <module>
    tf.app.run()
  File ""/Users/pokey/.pyenv/versions/deep-stats/lib/python3.6/site-packages/tensorflow/python/platform/app.py"", line 48, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""download_and_convert_data.py"", line 65, in main
    download_and_convert_flowers.run(FLAGS.dataset_dir)
  File ""/Users/pokey/src/deep-stats/models/slim/datasets/download_and_convert_flowers.py"", line 202, in run
    dataset_dir)
  File ""/Users/pokey/src/deep-stats/models/slim/datasets/download_and_convert_flowers.py"", line 139, in _convert_dataset
    image_data = tf.gfile.FastGFile(filenames[i], 'r').read()
  File ""/Users/pokey/.pyenv/versions/deep-stats/lib/python3.6/site-packages/tensorflow/python/lib/io/file_io.py"", line 122, in read
    pywrap_tensorflow.ReadFromStream(self._read_buf, length, status))
  File ""/Users/pokey/.pyenv/versions/deep-stats/lib/python3.6/site-packages/tensorflow/python/lib/io/file_io.py"", line 90, in _prepare_value
    return compat.as_str_any(val)
  File ""/Users/pokey/.pyenv/versions/deep-stats/lib/python3.6/site-packages/tensorflow/python/util/compat.py"", line 106, in as_str_any
    return as_str(value)
  File ""/Users/pokey/.pyenv/versions/deep-stats/lib/python3.6/site-packages/tensorflow/python/util/compat.py"", line 84, in as_text
    return bytes_or_text.decode(encoding)
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte
```",pokey,b'type:bug',2017-05-03T11:42:01Z,2018-11-17T19:56:30Z,,,,,,,
1429,Im2Txt not working for other languages like hindi,"
------------------------

### System information
- **What is the top-level directory of the model you are using** models/Im2Txt:
- **OS Platform and Distribution : Linux CentOS 7**:
- **TensorFlow installed from Binary**:
- **TensorFlow version:('v1.0.0-rc1-102-g1536a84-dirty', '1.0.0-rc2')**:

I am trying to use im2txt model with MSCOCO dataset modified to use hindi caption. When I tried to pre-process dataset using bazel-bin/im2txt/download_and_preprocess_mscoco ""${MSCOCO_DIR}"" command, it will work until generating word_count file. In step of generating TFrecord it throws following error:

Exception in thread Thread-14:
Traceback (most recent call last):
  File ""/usr/lib64/python2.7/threading.py"", line 811, in __bootstrap_inner
    self.run()
  File ""/usr/lib64/python2.7/threading.py"", line 764, in run
    self.__target(*self.__args, **self.__kwargs)
  File ""/root/.cache/bazel/_bazel_root/5d96493270bd616258f6b3292edd375b/execroot/im2txt/bazel-out/local-fastbuild/bin/im2txt/build_mscoco_data.runfiles/im2txt/im2txt/data/build_mscoco_data.py"", line 281, in _process_image_files
    sequence_example = _to_sequence_example(image, decoder, vocab)
  File ""/root/.cache/bazel/_bazel_root/5d96493270bd616258f6b3292edd375b/execroot/im2txt/bazel-out/local-fastbuild/bin/im2txt/build_mscoco_data.runfiles/im2txt/im2txt/data/build_mscoco_data.py"", line 234, in _to_sequence_example
    ""image/caption"": _bytes_feature_list(caption),
  File ""/root/.cache/bazel/_bazel_root/5d96493270bd616258f6b3292edd375b/execroot/im2txt/bazel-out/local-fastbuild/bin/im2txt/build_mscoco_data.runfiles/im2txt/im2txt/data/build_mscoco_data.py"", line 202, in _bytes_feature_list
    return tf.train.FeatureList(feature=[_bytes_feature(v) for v in values])
  File ""/root/.cache/bazel/_bazel_root/5d96493270bd616258f6b3292edd375b/execroot/im2txt/bazel-out/local-fastbuild/bin/im2txt/build_mscoco_data.runfiles/im2txt/im2txt/data/build_mscoco_data.py"", line 192, in _bytes_feature
    return tf.train.Feature(bytes_list=tf.train.BytesList(value=str(value)))
UnicodeEncodeError: 'ascii' codec can't encode characters in position 0-2: ordinal not in range(128)


It seems error in encoding data to tfrecord. I have also tried to modify str(value) using unicode encode  function. 
Sample caption file is available at: https://drive.google.com/file/d/0B8Rng3ofk0uAbDBJekpPR3BXVzA/view?usp=sharing
",shahparth123,b'type:bug',2017-05-01T13:32:37Z,2018-10-08T00:17:18Z,,,,,,,
1428,[Slim] Imagenet training not utilizing multiple GPUs efficiently,"Hi,

I am running some tests on Slim's imagenet training using Inception Resnet V2. The training is done on AWS ec2 instances (p2.xlarge and p2.8xlarge): Here are the specs for both:

1) p2.xlarge: GPUs (1), vCPUs (4), Ram (61GB)
2) p2.8xlarge: GPUs (8), vCPUs (32), Ram (488GB)

The GPUs are all Nvidia Tesla K80

Tensorflow seems to detect and loads the training on all GPUs according to both the training output and nvidia-smi. However there does not seem to be much difference in execution times.


On the **p2.xlarge** instance, TF/Slim reported an average of **3.05 sec/step**. 
On the **p2.8xlarge**  instance it reported an average of **2.96 sec/step**

I was expecting the time to drop significantly but given the above results I do not see a huge benefit running the training on multiple GPUs. 

Both instances have a copy of the same exact training datasets and scripts. I am running the training using this command:

```
DATASET_DIR=/imagenet2
TRAIN_DIR=/imagenet2/train_logs
python train_image_classifier.py \
	--train_dir=${TRAIN_DIR} \
	--dataset_name=imagenet \
	--dataset_split_name=train \
	--dataset_dir=${DATASET_DIR} \
	--max_number_of_steps=20000 \
	--model_name=inception_resnet_v2
```

Both instances running Tensorflow 1.0.1 running from binary as VM
Both instances are running Ubuntu 14.04 x64


Regards

",redserpent7,b'type:bug',2017-05-01T11:46:42Z,2018-02-08T18:22:15Z,,,,,,,
1407,Out of bound error on Swivel.py model,"I was running swivel.py, and the only thing I changed was CPU instead of GPU, but still got an error message as below:

> InvalidArgumentError (see above for traceback): indices[3926] = [0,4096] is out of bounds: need 0 <= index < [4096,4096]
	 [[Node: SparseToDense = SparseToDense[T=DT_FLOAT, Tindices=DT_INT64, validate_indices=true, _device=""/job:localhost/replica:0/task:0/cpu:0""](concat, SparseToDense/output_shape, ParseSingleExample/ParseExample/ParseExample:5, SparseToDense/default_value)]]

How can I fix this? Also, why is index < [4096,4096]? shouldn't it be <= [4096,4096], since the number of shard was set to be 4096??

Below is the link to swivel.py
https://github.com/tensorflow/models/blob/dc135d79b8e5ec725e14a5fef050859ec57e83bb/swivel/swivel.py
",gahu1125,b'stat:awaiting model gardener type:bug',2017-04-25T17:35:55Z,2017-10-22T21:17:11Z,,,,,,,
1400,Neural_programmer bug,"Hi, 

I keep getting this error trying to run `python neural_programmer.py`,

```
(tf_py2_tf_1_0) ajay@ajay-h8-1170uk:~/PythonProjects/TF_models_v1/neural_programmer$ python neural_programmer.py
Annotated examples loaded  14152
Annotated examples loaded  4344
entry match token:  9133 9133
entry match token:  9134 9134
# train examples  10178
# dev examples  2546
# test examples  3913
running open source
forget gate bias
Traceback (most recent call last):
  File ""neural_programmer.py"", line 237, in <module>
    tf.app.run()
  File ""/home/ajay/anaconda3/envs/tf_py2_tf_1_0/lib/python2.7/site-packages/tensorflow/python/platform/app.py"", line 48, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""neural_programmer.py"", line 233, in main
    master(train_data, dev_data, utility)
  File ""neural_programmer.py"", line 160, in master
    graph.create_graph(params, global_step)
  File ""/home/ajay/PythonProjects/TF_models_v1/neural_programmer/model.py"", line 636, in create_graph
    self.total_cost = self.compute_error() 
  File ""/home/ajay/PythonProjects/TF_models_v1/neural_programmer/model.py"", line 582, in compute_error
    1, [self.batch_number_column_mask, self.batch_word_column_mask])
  File ""/home/ajay/anaconda3/envs/tf_py2_tf_1_0/lib/python2.7/site-packages/tensorflow/python/ops/array_ops.py"", line 1029, in concat
    dtype=dtypes.int32).get_shape(
  File ""/home/ajay/anaconda3/envs/tf_py2_tf_1_0/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 639, in convert_to_tensor
    as_ref=False)
  File ""/home/ajay/anaconda3/envs/tf_py2_tf_1_0/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 704, in internal_convert_to_tensor
    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
  File ""/home/ajay/anaconda3/envs/tf_py2_tf_1_0/lib/python2.7/site-packages/tensorflow/python/framework/constant_op.py"", line 113, in _constant_tensor_conversion_function
    return constant(v, dtype=dtype, name=name)
  File ""/home/ajay/anaconda3/envs/tf_py2_tf_1_0/lib/python2.7/site-packages/tensorflow/python/framework/constant_op.py"", line 102, in constant
    tensor_util.make_tensor_proto(value, dtype=dtype, shape=shape, verify_shape=verify_shape))
  File ""/home/ajay/anaconda3/envs/tf_py2_tf_1_0/lib/python2.7/site-packages/tensorflow/python/framework/tensor_util.py"", line 370, in make_tensor_proto
    _AssertCompatible(values, dtype)
  File ""/home/ajay/anaconda3/envs/tf_py2_tf_1_0/lib/python2.7/site-packages/tensorflow/python/framework/tensor_util.py"", line 302, in _AssertCompatible
    (dtype.name, repr(mismatch), type(mismatch).__name__))
TypeError: Expected int32, got list containing Tensors of type '_Message' instead.
```

- **What is the top-level directory of the model you are using**:
https://github.com/tensorflow/models/tree/master/neural_programmer

- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
No

- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Ubuntu 14.04

- **TensorFlow installed from (source or binary)**:
binary

- **TensorFlow version (use command below)**:

('v1.1.0-rc0-61-g1ec6ed5', '1.1.0')

- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:

CPU mode

- **Exact command to reproduce**:

python neural_programmer.py


You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",AjayTalati,b'help wanted type:bug',2017-04-25T10:12:20Z,2018-11-12T08:43:00Z,,,,,,,
1395,"""Found input thread dead"" and ""No attribute next""","When running 

     bazel-bin/textsum/seq2seq_attention \
     --mode=train \
     --article_key=article \
     --abstract_key=abstract \
     --data_path=data/bin_data_train\
     --vocab_path=data/vocab \
     --log_root=textsum/log_root \
     --train_dir=textsum/log_root/train

I get this error:

    ERROR:tensorflow:Found input thread dead.
    Exception in thread Thread-377:
    Traceback (most recent call last):
      File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/threading.py"", line 916,     in _bootstrap_inner
        self.run()
      File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/threading.py"", line 864,    in run
        self._target(*self._args, **self._kwargs)
      File ""/Users/johnjosephhiggins/PycharmProjects/prometheadj/models/textsum/batch_reader.py"",     line 136, in _FillInputQueue
        (article, abstract) = input_gen.next()
     AttributeError: 'generator' object has no attribute 'next'


I've done everything correctly, as far as I know. I'm running on CPU-- no CUDA. I have a pretty new Mac, OS Yosemite with 8GB free. Python 3.6.

I think the first error ""Input thread dead"" might be tied to the second ""no attribute next."" I opened a pull request changing 

    .next( )

to

    .__next__( )

in 'batch_reader.py'. That removes the ""no attribute 'next'"" and ""found thread dead"" errors, but causes training to stop after the first global step. I waited for ~3 hours and received no new messages from either tensorboard or terminal.

Any thoughts? Is my pull request worth a shot?
",Higgins2718,b'stat:awaiting model gardener type:bug',2017-04-24T22:35:20Z,2017-05-11T22:14:57Z,,,,,,,
1390,Slim multi-gpu performance problems,"I was using slim models with flower dataset in Ubuntu 16.04.

Tensorflow version:1.1.0rc2 from src

git version:
34c738cc6d3badcb22e3f72482536ada29bd0e65

Bazel version:
Build label: 0.4.5
Build target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Thu Mar 16 12:19:38 2017 (1489666778)
Build timestamp: 1489666778
Build timestamp as int: 1489666778

CUDA version: 8.0.44
cuDNN version:5.1.5
GPU: 3GPUs. All of them are GeForce GTX 1080Ti 11GB
Memory: 32GB

I didn't change source code.
with 1 GPU:

TRAIN_DIR=/tmp/train_logs
DATASET_DIR=/home/l/data/flowers
python train_image_classifier.py     --train_dir=${TRAIN_DIR}     --dataset_name=flowers     --dataset_split_name=train     --dataset_dir=${DATASET_DIR}     --model_name=inception_resnet_v2
…
(log here is same as running with 3 gpus)
…
INFO:tensorflow:global_step/sec: 0
INFO:tensorflow:Recording summary at step 0.
INFO:tensorflow:global step 10: loss = 3.2313 (0.96 sec/step)
INFO:tensorflow:global step 20: loss = 3.7792 (0.97 sec/step)
INFO:tensorflow:global step 30: loss = 2.9681 (0.96 sec/step)
INFO:tensorflow:global step 40: loss = 3.8321 (0.97 sec/step)
INFO:tensorflow:global step 50: loss = 3.2210 (0.96 sec/step)
...

when I use 3 gpus:
python train_image_classifier.py     --train_dir=${TRAIN_DIR}     --dataset_name=flowers     --dataset_split_name=train     --dataset_dir=${DATASET_DIR}     --model_name=inception_resnet_v2 --num_clones=3
2017-04-24 14:26:11.885411: I tensorflow/core/common_runtime/gpu/gpu_device.cc:887] Found device 0 with properties: 
name: Graphics Device
major: 6 minor: 1 memoryClockRate (GHz) 1.582
pciBusID 0000:05:00.0
Total memory: 10.91GiB
Free memory: 10.53GiB
2017-04-24 14:26:11.885472: W tensorflow/stream_executor/cuda/cuda_driver.cc:485] creating context when one is currently active; existing: 0x5b62c2c0
2017-04-24 14:26:12.131777: I tensorflow/core/common_runtime/gpu/gpu_device.cc:887] Found device 1 with properties: 
name: Graphics Device
major: 6 minor: 1 memoryClockRate (GHz) 1.582
pciBusID 0000:06:00.0
Total memory: 10.91GiB
Free memory: 10.75GiB
2017-04-24 14:26:12.131848: W tensorflow/stream_executor/cuda/cuda_driver.cc:485] creating context when one is currently active; existing: 0x5945f2d0
2017-04-24 14:26:12.369331: I tensorflow/core/common_runtime/gpu/gpu_device.cc:887] Found device 2 with properties: 
name: Graphics Device
major: 6 minor: 1 memoryClockRate (GHz) 1.582
pciBusID 0000:09:00.0
Total memory: 10.91GiB
Free memory: 10.75GiB
2017-04-24 14:26:12.371583: I tensorflow/core/common_runtime/gpu/gpu_device.cc:908] DMA: 0 1 2 
2017-04-24 14:26:12.371596: I tensorflow/core/common_runtime/gpu/gpu_device.cc:918] 0:   Y Y Y 
2017-04-24 14:26:12.371601: I tensorflow/core/common_runtime/gpu/gpu_device.cc:918] 1:   Y Y Y 
2017-04-24 14:26:12.371606: I tensorflow/core/common_runtime/gpu/gpu_device.cc:918] 2:   Y Y Y 
2017-04-24 14:26:12.371615: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Graphics Device, pci bus id: 0000:05:00.0)
2017-04-24 14:26:12.371622: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977] Creating TensorFlow device (/gpu:1) -> (device: 1, name: Graphics Device, pci bus id: 0000:06:00.0)
2017-04-24 14:26:12.371625: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977] Creating TensorFlow device (/gpu:2) -> (device: 2, name: Graphics Device, pci bus id: 0000:09:00.0)
INFO:tensorflow:Restoring parameters from /tmp/train_logs/model.ckpt-0
**2017-04-24 14:26:17.426353: I tensorflow/core/common_runtime/simple_placer.cc:669] Ignoring device specification /device:GPU:2 for node 'clone_2/fifo_queue_Dequeue' because the input edge from 'prefetch_queue/fifo_queue' is a reference connection and already has a device field set to /device:CPU:0
2017-04-24 14:26:17.427748: I tensorflow/core/common_runtime/simple_placer.cc:669] Ignoring device specification /device:GPU:1 for node 'clone_1/fifo_queue_Dequeue' because the input edge from 'prefetch_queue/fifo_queue' is a reference connection and already has a device field set to /device:CPU:0
2017-04-24 14:26:17.429099: I tensorflow/core/common_runtime/simple_placer.cc:669] Ignoring device specification /device:GPU:0 for node 'clone_0/fifo_queue_Dequeue' because the input edge from 'prefetch_queue/fifo_queue' is a reference connection and already has a device field set to /device:CPU:0**
INFO:tensorflow:Starting Session.
INFO:tensorflow:Saving checkpoint to path /tmp/train_logs/model.ckpt
INFO:tensorflow:Starting Queues.
INFO:tensorflow:global_step/sec: 0
INFO:tensorflow:Recording summary at step 0.
INFO:tensorflow:global step 10: loss = 2.9670 (0.98 sec/step)
INFO:tensorflow:global step 20: loss = 2.9945 (0.99 sec/step)
INFO:tensorflow:global step 30: loss = 3.0432 (0.99 sec/step)
INFO:tensorflow:global step 40: loss = 3.0007 (1.04 sec/step)
INFO:tensorflow:global step 50: loss = 2.8072 (1.03 sec/step)
...

I saw ""Ignoring device specification"" and the training speed didn't change.
This is nvidia-smi output with 3 gpus.

+-----------------------------------------------------------------------------+
| NVIDIA-SMI 378.13                 Driver Version: 378.13                    |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  Graphics Device     Off  | 0000:05:00.0      On |                  N/A |
| 49%   83C    P2   140W / 250W |  10754MiB / 11171MiB |     98%      Default |
+-------------------------------+----------------------+----------------------+
|   1  Graphics Device     Off  | 0000:06:00.0     Off |                  N/A |
| 47%   81C    P2   137W / 250W |  10744MiB / 11172MiB |     98%      Default |
+-------------------------------+----------------------+----------------------+
|   2  Graphics Device     Off  | 0000:09:00.0     Off |                  N/A |
| 43%   74C    P2   130W / 250W |  10744MiB / 11172MiB |     98%      Default |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID  Type  Process name                               Usage      |
|=============================================================================|
|    0      1065    G   /usr/lib/xorg/Xorg                             160MiB |
|    0      1757    G   compiz                                          81MiB |
|    0     14407    C   python                                       10497MiB |
|    1     14407    C   python                                       10729MiB |
|    2     14407    C   python                                       10729MiB |
+-----------------------------------------------------------------------------+

Something Else
  I tried inception model with 3 gpus and it worked well with speed boost. There was no ""Ignoring device specification"" in inception model logs. I'm not sure whether it is the problem.

  similar problem: 
  #1338 
  https://github.com/tensorflow/tensorflow/issues/8061 (I tried the script in TF1.1.0 and ""Ignoring device specification"" appeared too. If someone needs details,I will post logs.)
 

 I changed model to inception_v3. It seems nothing changed.
 I'm also considering if I can output batch content that may be helpful.",Ettard,b'stat:awaiting model gardener type:bug',2017-04-24T07:36:08Z,2018-01-19T06:15:03Z,,,,,,,
1389,python vgslspecs_test.py,"I get the following error while executing python vgslspecs_test.py
kindly help me to resolve the bug
Traceback (most recent call last):
  File ""vgslspecs_test.py"", line 19, in <module>
    import vgslspecs
  File ""/home/sarfraaz/Downloads/tensorflow-models-master/street/python/vgslspecs.py"", line 24, in <module>
    import nn_ops
  File ""/home/sarfraaz/Downloads/tensorflow-models-master/street/python/nn_ops.py"", line 22, in <module>
    rnn = tf.load_op_library(""../cc/rnn_ops.so"")
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/load_library.py"", line 64, in load_op_library
    None, None, error_msg, error_code)
tensorflow.python.framework.errors_impl.NotFoundError: ../cc/rnn_ops.so: undefined symbol: _ZN10tensorflow7strings8internal9CatPiecesB5cxx11ESt16initializer_listINS_11StringPieceEE



",SarfraazMsa,b'stat:awaiting maintainer type:bug',2017-04-24T06:35:58Z,2018-07-17T14:10:10Z,,,,,,,
1378,cannot convert dictionary update sequence element #0 to a sequence,"My system is windows 10, python 3.5, tensorflow 1.0,
the path is E:\PycharmProjects\models\slim\nets\resnet_v2_test.py

Here is the error:
Error
Traceback (most recent call last):
  File ""E:\PycharmProjects\models\slim\nets\resnet_v2_test.py"", line 172, in testEndPointsV2
    _, end_points = self._resnet_plain(inputs, blocks, scope='tiny')
  File ""E:\PycharmProjects\models\slim\nets\resnet_v2_test.py"", line 162, in _resnet_plain
    end_points = dict(tf.get_collection('end_points'))
TypeError: cannot convert dictionary update sequence element #0 to a sequence

And by the way , my file nets have the resnet_v2.py , why I just use ""import resnet_v2"" in resnet_v2_test.py , it show no module named resnet_v2 ? And I use ""from nets import resnet_v2"" , it
still show no module named nets and no module named resnet_v2 ?",paulzhhong,b'stat:awaiting model gardener type:bug',2017-04-21T09:03:34Z,2018-02-24T18:39:58Z,,,,,,,
1376,wrapped_units.LayerNormBasicLSTMNetwork,"No1.
http://stackoverflow.com/questions/43509103/typeerror-init-got-an-unexpected-keyword-argument-reuse

for No1,i modify the file dragnn/python/wrapped_units.py by del del the "", reuse=True"" in 
""return tf.contrib.rnn.LayerNormBasicLSTMCell(
          num_units, layer_norm=self._attrs['layer_norm'], reuse=True)""  to slove the problem.

No2. using in dragnn model as blow:
 tagger.set_network_unit(name='wrapped_units.LayerNormBasicLSTMNetwork', hidden_layer_sizes='256)
when i run 
""text = '他們 是 親朋 好友 .'
tokens = [sentence_pb2.Token(word=word, start=-1, end=-1) for word in text.split()]
sentence = sentence_pb2.Sentence()
sentence.token.extend(tokens)
with tf.Session(graph=graph) as sess:
    # Restore the model we just trained.
    builder.saver.restore(sess, CHECKPOINT_FILENAME
)
    annotations, traces = sess.run([annotator['annotations'], annotator['traces']],
                      feed_dict={annotator['input_batch']: [sentence.SerializeToString()]})
HTML(visualization.trace_html(traces[0]))""

jupyter notebook show log as blow
[W 11:51:42.335 NotebookApp] Saving untrusted notebook trainer_tutorial.ipynb
I dragnn/core/compute_session_pool.cc:55] Destroying pool: total number of sessions created = 1
*** Error in `/usr/bin/python2.7': double free or corruption (!prev): 0x000000000109e160 ***
[I 11:52:25.327 NotebookApp] KernelRestarter: restarting kernel (1/5)
WARNING:root:kernel ad3ac582-fb41-4ffe-9a4f-e7b41ca1eabf restarted
 
source:
IN[1]: 
import os.path
import time
import random
import tensorflow as tf
from IPython.display import HTML
from tensorflow.python.platform import gfile
from tensorflow.python.platform import tf_logging as logging
from google.protobuf import text_format
from syntaxnet.ops import gen_parser_ops
from syntaxnet import load_parser_ops
from syntaxnet import task_spec_pb2
from syntaxnet import sentence_pb2
from dragnn.protos import spec_pb2 
from dragnn.python.sentence_io import ConllSentenceReader
from dragnn.python import evaluation
from dragnn.python import graph_builder
from dragnn.python import lexicon
from dragnn.python import load_dragnn_cc_impl
from dragnn.python import render_parse_tree_graphviz
from dragnn.python import render_spec_with_graphviz
from dragnn.python import spec_builder
from dragnn.python import trainer_lib
from dragnn.python import visualization

DATA_DIR = '/usr/cep/nlp/np/data/zht'
TENSORBOARD_DIR = '/usr/local/models/syntaxnet/tensorflow/tensorflow/tensorboard'
CHECKPOINT_FILENAME = '{}/zht.checkpoint'.format(DATA_DIR)
TRAINING_CORPUS_PATH = '{}/zh-ud-train.conllu'.format(DATA_DIR)
DEV_CORPUS_PATH = '{}/zh-ud-dev.conllu'.format(DATA_DIR)

assert os.path.isfile(TRAINING_CORPUS_PATH), '训练语料库不存在'

logging.set_verbosity(logging.WARN)

lexicon.build_lexicon(DATA_DIR, TRAINING_CORPUS_PATH)

lookahead = spec_builder.ComponentSpecBuilder('lookahead')
lookahead.set_network_unit(
    name='FeedForwardNetwork', hidden_layer_sizes='256')
lookahead.set_transition_system(name='shift-only', left_to_right='true')
lookahead.add_fixed_feature(name='words', fml='input.word', embedding_dim=32)
lookahead.add_rnn_link(embedding_dim=-1)
lookahead.fill_from_resources(DATA_DIR)

tagger = spec_builder.ComponentSpecBuilder('tagger')
tagger.set_network_unit(name='wrapped_units.LayerNormBasicLSTMNetwork', hidden_layer_sizes='256')
tagger.set_transition_system(name='tagger')
tagger.add_rnn_link(embedding_dim=-1)
tagger.add_token_link(source=lookahead, fml='input.focus', embedding_dim=32)
tagger.fill_from_resources(DATA_DIR)

parser = spec_builder.ComponentSpecBuilder('parser')
parser.set_network_unit(name='FeedForwardNetwork', hidden_layer_sizes='256',
                        layer_norm_hidden='true')
parser.set_transition_system(name='arc-standard')
parser.add_token_link(source=lookahead, fml='input.focus', embedding_dim=32)
parser.add_token_link(
    source=tagger, fml='input.focus stack.focus stack(1).focus',
    embedding_dim=32)

parser.add_fixed_feature(name='labels', embedding_dim=16,
                         fml=' '.join([
                             'stack.child(1).label',
                             'stack.child(1).sibling(-1).label',
                             'stack.child(-1).label',
                             'stack.child(-1).sibling(1).label',
                             'stack(1).child(1).label',
                             'stack(1).child(1).sibling(-1).label',
                             'stack(1).child(-1).label',
                             'stack(1).child(-1).sibling(1).label',
                             'stack.child(2).label',
                             'stack.child(-2).label',
                             'stack(1).child(2).label',
                             'stack(1).child(-2).label']))

parser.add_link(
        source=parser,  # recurrent connection
        name='rnn-stack',  # unique identifier
        fml='stack.focus stack(1).focus',  # look for both stack tokens
        source_translator='shift-reduce-step',  # maps token indices -> step
        embedding_dim=32)  # project down to 64 dims

parser.fill_from_resources(DATA_DIR)

master_spec = spec_pb2.MasterSpec()
master_spec.component.extend([lookahead.spec, tagger.spec, parser.spec])
HTML(render_spec_with_graphviz.master_spec_graph(master_spec))

IN[2]:
graph = tf.Graph()
with graph.as_default():
    hyperparam_config = spec_pb2.GridPoint(
        learning_method='adam',
        learning_rate=0.0005, 
        adam_beta1=0.9, adam_beta2=0.9, adam_eps=0.001,
        decay_steps=128000,
        dropout_rate=0.8, gradient_clip_norm=1,
        use_moving_average=True,
        seed=1)    
    builder = graph_builder.MasterBuilder(master_spec, hyperparam_config)
    target = spec_pb2.TrainTarget(
        name='all',
        unroll_using_oracle=[False, True, True], # train tagger & parser on gold unrolling, skip lookahead
        component_weights=[0, 0.5, 0.5]) # tagger and parser losses have equal weights
    trainer = builder.add_training_from_config(target)
    annotator = builder.add_annotation(enable_tracing=True)
    builder.add_saver()

N_STEPS = 20
BATCH_SIZE = 64
with tf.Session(graph=graph) as sess:
    sess.run(tf.global_variables_initializer())
    training_corpus = ConllSentenceReader(
        TRAINING_CORPUS_PATH, projectivize=True).corpus()
    dev_corpus = ConllSentenceReader(DEV_CORPUS_PATH).corpus()[:200]
    for step in xrange(N_STEPS):
        trainer_lib.run_training_step(sess, trainer, training_corpus, batch_size=BATCH_SIZE)
        tf.logging.warning('Step %d/%d', step + 1, N_STEPS)
    parsed_dev_corpus = trainer_lib.annotate_dataset(sess, annotator, dev_corpus)
    pos, uas, las = evaluation.calculate_parse_metrics(dev_corpus, parsed_dev_corpus)
    tf.logging.warning('POS %.2f UAS %.2f LAS %.2f', pos, uas, las)
    builder.saver.save(sess, CHECKPOINT_FILENAME)

IN[3]:
text = '他們 是 親朋 好友 .'
tokens = [sentence_pb2.Token(word=word, start=-1, end=-1) for word in text.split()]
sentence = sentence_pb2.Sentence()
sentence.token.extend(tokens)

with tf.Session(graph=graph) as sess:
    builder.saver.restore(sess, CHECKPOINT_FILENAME)
    annotations, traces = sess.run([annotator['annotations'], annotator['traces']],
                      feed_dict={annotator['input_batch']: [sentence.SerializeToString()]})
HTML(visualization.trace_html(traces[0]))

",haoran8899,b'stat:awaiting model gardener type:bug',2017-04-21T05:42:35Z,2020-02-07T18:40:57Z,,,,,,,
1280,Unable to load bi skip thought model under Encoding Sentences ,"## Please let us know which model this issue is about (specify the top-level directory)
This is regarding the skip thoughts model. The uni model loads fine, the following error is thrown when loading the bi model:

```
VOCAB_FILE_BI = ""/home/icarus/skip_thoughts/pretrained/skip_thoughts_bi_2017_02_16/vocab.txt""
EMBEDDING_MATRIX_FILE_BI = ""/home/icarus/skip_thoughts/pretrained/skip_thoughts_bi_2017_02_16/embeddings.npy""
CHECKPOINT_PATH_BI = ""/home/icarus/skip_thoughts/pretrained/skip_thoughts_bi_2017_02_16/model.ckpt-500008""

```


```
---------------------------------------------------------------------------
NotFoundError                             Traceback (most recent call last)
<ipython-input-4-debbde01a7e3> in <module>()
      3                    vocabulary_file=VOCAB_FILE_BI,
      4                    embedding_matrix_file=EMBEDDING_MATRIX_FILE_BI,
----> 5                    checkpoint_path=CHECKPOINT_PATH_BI)

/home/icarus/skip_thoughts/skip_thoughts/encoder_manager.pyc in load_model(self, model_config, vocabulary_file, embedding_matrix_file, checkpoint_path)
     85 
     86     sess = tf.Session(graph=g)
---> 87     restore_model(sess)
     88 
     89     self.encoders.append(encoder)

/home/icarus/skip_thoughts/skip_thoughts/skip_thoughts_encoder.pyc in _restore_fn(sess)
    128     def _restore_fn(sess):
    129       tf.logging.info(""Loading model from checkpoint: %s"", checkpoint_path)
--> 130       saver.restore(sess, checkpoint_path)
    131       tf.logging.info(""Successfully loaded checkpoint: %s"",
    132                       os.path.basename(checkpoint_path))

/home/icarus/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/saver.pyc in restore(self, sess, save_path)
   1426       return
   1427     sess.run(self.saver_def.restore_op_name,
-> 1428              {self.saver_def.filename_tensor_name: save_path})
   1429 
   1430   @staticmethod

/home/icarus/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc in run(self, fetches, feed_dict, options, run_metadata)
    765     try:
    766       result = self._run(None, fetches, feed_dict, options_ptr,
--> 767                          run_metadata_ptr)
    768       if run_metadata:
    769         proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)

/home/icarus/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc in _run(self, handle, fetches, feed_dict, options, run_metadata)
    963     if final_fetches or final_targets:
    964       results = self._do_run(handle, final_targets, final_fetches,
--> 965                              feed_dict_string, options, run_metadata)
    966     else:
    967       results = []

/home/icarus/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc in _do_run(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)
   1013     if handle is None:
   1014       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,
-> 1015                            target_list, options, run_metadata)
   1016     else:
   1017       return self._do_call(_prun_fn, self._session, handle, feed_dict,

/home/icarus/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc in _do_call(self, fn, *args)
   1033         except KeyError:
   1034           pass
-> 1035       raise type(e)(node_def, op, message)
   1036 
   1037   def _extend_graph(self):

NotFoundError: Key encoder/gru_cell/candidate/layer_norm/w/beta not found in checkpoint
	 [[Node: save/RestoreV2_2 = RestoreV2[dtypes=[DT_FLOAT], _device=""/job:localhost/replica:0/task:0/cpu:0""](_recv_save/Const_0, save/RestoreV2_2/tensor_names, save/RestoreV2_2/shape_and_slices)]]

Caused by op u'save/RestoreV2_2', defined at:
  File ""/home/icarus/anaconda2/lib/python2.7/runpy.py"", line 174, in _run_module_as_main
    ""__main__"", fname, loader, pkg_name)
  File ""/home/icarus/anaconda2/lib/python2.7/runpy.py"", line 72, in _run_code
    exec code in run_globals
  File ""/home/icarus/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py"", line 3, in <module>
    app.launch_new_instance()
  File ""/home/icarus/anaconda2/lib/python2.7/site-packages/traitlets/config/application.py"", line 653, in launch_instance
    app.start()
  File ""/home/icarus/anaconda2/lib/python2.7/site-packages/ipykernel/kernelapp.py"", line 474, in start
    ioloop.IOLoop.instance().start()
  File ""/home/icarus/anaconda2/lib/python2.7/site-packages/zmq/eventloop/ioloop.py"", line 162, in start
    super(ZMQIOLoop, self).start()
  File ""/home/icarus/anaconda2/lib/python2.7/site-packages/tornado/ioloop.py"", line 887, in start
    handler_func(fd_obj, events)
  File ""/home/icarus/anaconda2/lib/python2.7/site-packages/tornado/stack_context.py"", line 275, in null_wrapper
    return fn(*args, **kwargs)
  File ""/home/icarus/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py"", line 440, in _handle_events
    self._handle_recv()
  File ""/home/icarus/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py"", line 472, in _handle_recv
    self._run_callback(callback, msg)
  File ""/home/icarus/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py"", line 414, in _run_callback
    callback(*args, **kwargs)
  File ""/home/icarus/anaconda2/lib/python2.7/site-packages/tornado/stack_context.py"", line 275, in null_wrapper
    return fn(*args, **kwargs)
  File ""/home/icarus/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py"", line 276, in dispatcher
    return self.dispatch_shell(stream, msg)
  File ""/home/icarus/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py"", line 228, in dispatch_shell
    handler(stream, idents, msg)
  File ""/home/icarus/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py"", line 390, in execute_request
    user_expressions, allow_stdin)
  File ""/home/icarus/anaconda2/lib/python2.7/site-packages/ipykernel/ipkernel.py"", line 196, in do_execute
    res = shell.run_cell(code, store_history=store_history, silent=silent)
  File ""/home/icarus/anaconda2/lib/python2.7/site-packages/ipykernel/zmqshell.py"", line 501, in run_cell
    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)
  File ""/home/icarus/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py"", line 2717, in run_cell
    interactivity=interactivity, compiler=compiler, result=result)
  File ""/home/icarus/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py"", line 2827, in run_ast_nodes
    if self.run_code(code, result):
  File ""/home/icarus/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py"", line 2881, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File ""<ipython-input-4-debbde01a7e3>"", line 5, in <module>
    checkpoint_path=CHECKPOINT_PATH_BI)
  File ""/home/icarus/skip_thoughts/skip_thoughts/encoder_manager.py"", line 84, in load_model
    checkpoint_path)
  File ""/home/icarus/skip_thoughts/skip_thoughts/skip_thoughts_encoder.py"", line 151, in build_graph_from_config
    saver = tf.train.Saver()
  File ""/home/icarus/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/saver.py"", line 1040, in __init__
    self.build()
  File ""/home/icarus/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/saver.py"", line 1070, in build
    restore_sequentially=self._restore_sequentially)
  File ""/home/icarus/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/saver.py"", line 675, in build
    restore_sequentially, reshape)
  File ""/home/icarus/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/saver.py"", line 402, in _AddRestoreOps
    tensors = self.restore_op(filename_tensor, saveable, preferred_shard)
  File ""/home/icarus/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/saver.py"", line 242, in restore_op
    [spec.tensor.dtype])[0])
  File ""/home/icarus/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/gen_io_ops.py"", line 668, in restore_v2
    dtypes=dtypes, name=name)
  File ""/home/icarus/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py"", line 763, in apply_op
    op_def=op_def)
  File ""/home/icarus/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 2327, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""/home/icarus/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 1226, in __init__
    self._traceback = _extract_stack()

NotFoundError (see above for traceback): Key encoder/gru_cell/candidate/layer_norm/w/beta not found in checkpoint
	 [[Node: save/RestoreV2_2 = RestoreV2[dtypes=[DT_FLOAT], _device=""/job:localhost/replica:0/task:0/cpu:0""](_recv_save/Const_0, save/RestoreV2_2/tensor_names, save/RestoreV2_2/shape_and_slices)]]

```",ankitarya10,b'stat:awaiting model gardener stat:awaiting response type:bug',2017-03-30T22:54:06Z,2017-04-03T17:04:39Z,,,,,,,
1264,Cifar10 underutilizing GPUs?,"I am running on four GPUs on a cloud server.

I am fairly certain I am underutiliing GPUs since I am running `watch nvidia-smi` and seeing lots of zeroes with periodic breif upticks to about 20-30% in one or two gpus. I sent `--num-gpus=4` as an argument.

Here is some detail:

`W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE3 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:910] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
I tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with properties:
name: Tesla K80
major: 3 minor: 7 memoryClockRate (GHz) 0.8235
pciBusID 0000:00:04.0
Total memory: 11.17GiB
Free memory: 11.11GiB
W tensorflow/stream_executor/cuda/cuda_driver.cc:590] creating context when one is currently active; existing: 0x2c26cc0
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:910] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
I tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 1 with properties:
name: Tesla K80
major: 3 minor: 7 memoryClockRate (GHz) 0.8235
pciBusID 0000:00:05.0
Total memory: 11.17GiB
Free memory: 11.11GiB
W tensorflow/stream_executor/cuda/cuda_driver.cc:590] creating context when one is currently active; existing: 0x2c2ab00
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:910] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
I tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 2 with properties:
name: Tesla K80
major: 3 minor: 7 memoryClockRate (GHz) 0.8235
pciBusID 0000:00:06.0
Total memory: 11.17GiB
Free memory: 11.11GiB
W tensorflow/stream_executor/cuda/cuda_driver.cc:590] creating context when one is currently active; existing: 0x2c4e9c0
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:910] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
I tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 3 with properties:
name: Tesla K80
major: 3 minor: 7 memoryClockRate (GHz) 0.8235
pciBusID 0000:00:07.0
Total memory: 11.17GiB
Free memory: 11.11GiB
I tensorflow/core/common_runtime/gpu/gpu_device.cc:777] Peer access not supported between device ordinals 0 and 1
I tensorflow/core/common_runtime/gpu/gpu_device.cc:777] Peer access not supported between device ordinals 0 and 2
I tensorflow/core/common_runtime/gpu/gpu_device.cc:777] Peer access not supported between device ordinals 0 and 3
I tensorflow/core/common_runtime/gpu/gpu_device.cc:777] Peer access not supported between device ordinals 1 and 0
I tensorflow/core/common_runtime/gpu/gpu_device.cc:777] Peer access not supported between device ordinals 1 and 2
I tensorflow/core/common_runtime/gpu/gpu_device.cc:777] Peer access not supported between device ordinals 1 and 3
I tensorflow/core/common_runtime/gpu/gpu_device.cc:777] Peer access not supported between device ordinals 2 and 0
I tensorflow/core/common_runtime/gpu/gpu_device.cc:777] Peer access not supported between device ordinals 2 and 1
I tensorflow/core/common_runtime/gpu/gpu_device.cc:777] Peer access not supported between device ordinals 2 and 3
I tensorflow/core/common_runtime/gpu/gpu_device.cc:777] Peer access not supported between device ordinals 3 and 0
I tensorflow/core/common_runtime/gpu/gpu_device.cc:777] Peer access not supported between device ordinals 3 and 1
I tensorflow/core/common_runtime/gpu/gpu_device.cc:777] Peer access not supported between device ordinals 3 and 2
I tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0 1 2 3
I tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0:   Y N N N
I tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 1:   N Y N N
I tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 2:   N N Y N
I tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 3:   N N N Y
I tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0)
I tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:1) -> (device: 1, name: Tesla K80, pci bus id: 0000:00:05.0)
I tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:2) -> (device: 2, name: Tesla K80, pci bus id: 0000:00:06.0)
I tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:3) -> (device: 3, name: Tesla K80, pci bus id: 0000:00:07.0)`


and then my steps are slower than the file claims should be... since I am running 4 K80s I would expect much faster. I have been running about 2 hours now...


`2017-03-27 19:26:46.990922: step 0, loss = 4.67 (1.3 examples/sec; 100.494 sec/batch)
2017-03-27 19:27:15.323066: step 10, loss = 4.63 (212.7 examples/sec; 0.602 sec/batch)
2017-03-27 19:27:42.953002: step 20, loss = 4.61 (194.4 examples/sec; 0.659 sec/batch)
2017-03-27 19:28:08.125142: step 30, loss = 4.39 (202.5 examples/sec; 0.632 sec/batch)
2017-03-27 19:28:34.616396: step 40, loss = 4.32 (197.4 examples/sec; 0.649 sec/batch)
2017-03-27 19:29:00.785607: step 50, loss = 4.33 (221.3 examples/sec; 0.578 sec/batch)
2017-03-27 19:29:28.233038: step 60, loss = 4.31 (205.7 examples/sec; 0.622 sec/batch)
2017-03-27 19:29:54.034672: step 70, loss = 4.07 (232.7 examples/sec; 0.550 sec/batch)
2017-03-27 19:30:20.986209: step 80, loss = 4.13 (216.5 examples/sec; 0.591 sec/batch)
2017-03-27 19:30:46.936150: step 90, loss = 4.02 (182.9 examples/sec; 0.700 sec/batch)
2017-03-27 19:31:10.537182: step 100, loss = 4.03 (208.4 examples/sec; 0.614 sec/batch)
2017-03-27 19:31:40.003347: step 110, loss = 3.93 (187.7 examples/sec; 0.682 sec/batch)
2017-03-27 19:32:06.837135: step 120, loss = 3.86 (225.1 examples/sec; 0.569 sec/batch)
2017-03-27 19:32:33.440906: step 130, loss = 4.01 (165.4 examples/sec; 0.774 sec/batch)
2017-03-27 19:32:59.915578: step 140, loss = 3.98 (176.0 examples/sec; 0.727 sec/batch)
2017-03-27 19:33:25.993545: step 150, loss = 3.96 (195.5 examples/sec; 0.655 sec/batch)
2017-03-27 19:33:53.430149: step 160, loss = 3.78 (170.8 examples/sec; 0.749 sec/batch)
2017-03-27 19:34:18.521821: step 170, loss = 3.75 (212.1 examples/sec; 0.604 sec/batch)
2017-03-27 19:34:43.483902: step 180, loss = 3.88 (220.9 examples/sec; 0.580 sec/batch)
2017-03-27 19:35:10.340536: step 190, loss = 3.65 (182.9 examples/sec; 0.700 sec/batch)
2017-03-27 19:35:37.155107: step 200, loss = 3.90 (181.9 examples/sec; 0.704 sec/batch)
2017-03-27 19:36:07.403705: step 210, loss = 3.80 (192.3 examples/sec; 0.666 sec/batch)
2017-03-27 19:36:33.683254: step 220, loss = 3.91 (201.4 examples/sec; 0.635 sec/batch)
2017-03-27 19:36:59.653552: step 230, loss = 3.57 (176.6 examples/sec; 0.725 sec/batch)
2017-03-27 19:37:26.459334: step 240, loss = 3.66 (195.9 examples/sec; 0.653 sec/batch)
2017-03-27 19:37:54.057299: step 250, loss = 3.50 (212.2 examples/sec; 0.603 sec/batch)
2017-03-27 19:38:20.363680: step 260, loss = 3.54 (169.5 examples/sec; 0.755 sec/batch)
2017-03-27 19:38:46.152019: step 270, loss = 3.65 (211.0 examples/sec; 0.607 sec/batch)
2017-03-27 19:39:13.269074: step 280, loss = 3.77 (164.5 examples/sec; 0.778 sec/batch)
2017-03-27 19:39:38.569408: step 290, loss = 3.52 (197.6 examples/sec; 0.648 sec/batch)
2017-03-27 19:40:06.769787: step 300, loss = 3.52 (234.1 examples/sec; 0.547 sec/batch)
2017-03-27 19:40:37.029889: step 310, loss = 3.47 (192.5 examples/sec; 0.665 sec/batch)
2017-03-27 19:41:03.169604: step 320, loss = 3.52 (204.1 examples/sec; 0.627 sec/batch)
2017-03-27 19:41:31.389978: step 330, loss = 3.44 (180.9 examples/sec; 0.708 sec/batch)
2017-03-27 19:41:57.252489: step 340, loss = 3.68 (215.6 examples/sec; 0.594 sec/batch)
2017-03-27 19:42:23.678016: step 350, loss = 3.31 (196.3 examples/sec; 0.652 sec/batch)
2017-03-27 19:42:51.908805: step 360, loss = 3.24 (218.5 examples/sec; 0.586 sec/batch)
2017-03-27 19:43:19.394081: step 370, loss = 3.25 (170.1 examples/sec; 0.752 sec/batch)
2017-03-27 19:43:44.038110: step 380, loss = 3.20 (208.9 examples/sec; 0.613 sec/batch)
2017-03-27 19:44:11.626015: step 390, loss = 3.25 (163.5 examples/sec; 0.783 sec/batch)
2017-03-27 19:44:38.404796: step 400, loss = 3.29 (203.4 examples/sec; 0.629 sec/batch)
2017-03-27 19:45:07.275305: step 410, loss = 3.36 (169.9 examples/sec; 0.753 sec/batch)
2017-03-27 19:45:34.380476: step 420, loss = 3.28 (194.0 examples/sec; 0.660 sec/batch)
2017-03-27 19:46:00.917443: step 430, loss = 3.09 (189.5 examples/sec; 0.676 sec/batch)
2017-03-27 19:46:28.402162: step 440, loss = 3.16 (170.2 examples/sec; 0.752 sec/batch)
2017-03-27 19:46:54.475613: step 450, loss = 3.23 (214.7 examples/sec; 0.596 sec/batch)
2017-03-27 19:47:20.203394: step 460, loss = 3.14 (197.6 examples/sec; 0.648 sec/batch)
2017-03-27 19:47:46.100768: step 470, loss = 3.15 (205.0 examples/sec; 0.624 sec/batch)
2017-03-27 19:48:12.108813: step 480, loss = 3.16 (182.7 examples/sec; 0.700 sec/batch)
2017-03-27 19:48:38.917580: step 490, loss = 3.03 (189.9 examples/sec; 0.674 sec/batch)
2017-03-27 19:49:06.275778: step 500, loss = 3.33 (217.0 examples/sec; 0.590 sec/batch)
2017-03-27 19:49:37.939371: step 510, loss = 3.00 (168.8 examples/sec; 0.758 sec/batch)
2017-03-27 19:50:05.918202: step 520, loss = 3.17 (203.2 examples/sec; 0.630 sec/batch)
2017-03-27 19:50:33.384825: step 530, loss = 3.06 (188.6 examples/sec; 0.679 sec/batch)
2017-03-27 19:50:58.220123: step 540, loss = 3.04 (189.3 examples/sec; 0.676 sec/batch)
2017-03-27 19:51:24.429506: step 550, loss = 3.10 (214.1 examples/sec; 0.598 sec/batch)
2017-03-27 19:51:50.033498: step 560, loss = 3.17 (197.8 examples/sec; 0.647 sec/batch)
2017-03-27 19:52:15.544901: step 570, loss = 2.89 (213.4 examples/sec; 0.600 sec/batch)
2017-03-27 19:52:41.645112: step 580, loss = 2.88 (182.8 examples/sec; 0.700 sec/batch)
2017-03-27 19:53:08.246384: step 590, loss = 2.85 (184.3 examples/sec; 0.695 sec/batch)
2017-03-27 19:53:34.648499: step 600, loss = 3.23 (159.7 examples/sec; 0.802 sec/batch)
2017-03-27 19:54:05.155759: step 610, loss = 2.97 (154.4 examples/sec; 0.829 sec/batch)
2017-03-27 19:54:32.427825: step 620, loss = 2.93 (191.4 examples/sec; 0.669 sec/batch)
2017-03-27 19:54:58.939925: step 630, loss = 2.85 (171.5 examples/sec; 0.746 sec/batch)
2017-03-27 19:55:25.750831: step 640, loss = 2.75 (177.0 examples/sec; 0.723 sec/batch)
2017-03-27 19:55:54.483247: step 650, loss = 3.01 (174.2 examples/sec; 0.735 sec/batch)
2017-03-27 19:56:20.648869: step 660, loss = 2.79 (198.0 examples/sec; 0.646 sec/batch)
2017-03-27 19:56:48.254483: step 670, loss = 2.94 (177.0 examples/sec; 0.723 sec/batch)
2017-03-27 19:57:14.791461: step 680, loss = 2.86 (220.6 examples/sec; 0.580 sec/batch)
2017-03-27 19:57:41.755795: step 690, loss = 2.60 (176.1 examples/sec; 0.727 sec/batch)
2017-03-27 19:58:07.782214: step 700, loss = 2.84 (181.8 examples/sec; 0.704 sec/batch)
2017-03-27 19:58:37.283130: step 710, loss = 2.72 (174.5 examples/sec; 0.733 sec/batch)
2017-03-27 19:59:02.973874: step 720, loss = 2.72 (212.3 examples/sec; 0.603 sec/batch)
2017-03-27 19:59:30.256519: step 730, loss = 2.58 (186.9 examples/sec; 0.685 sec/batch)
2017-03-27 19:59:58.869470: step 740, loss = 2.66 (199.2 examples/sec; 0.642 sec/batch)
2017-03-27 20:00:24.191095: step 750, loss = 2.60 (254.0 examples/sec; 0.504 sec/batch)
2017-03-27 20:00:49.456903: step 760, loss = 2.66 (183.1 examples/sec; 0.699 sec/batch)
2017-03-27 20:01:15.948954: step 770, loss = 2.75 (169.9 examples/sec; 0.753 sec/batch)
2017-03-27 20:01:43.432525: step 780, loss = 2.68 (185.4 examples/sec; 0.690 sec/batch)
2017-03-27 20:02:09.862770: step 790, loss = 2.52 (160.3 examples/sec; 0.798 sec/batch)
2017-03-27 20:02:37.205679: step 800, loss = 2.55 (221.0 examples/sec; 0.579 sec/batch)
2017-03-27 20:03:06.496276: step 810, loss = 2.84 (242.3 examples/sec; 0.528 sec/batch)
2017-03-27 20:03:33.060909: step 820, loss = 2.41 (203.1 examples/sec; 0.630 sec/batch)
2017-03-27 20:03:59.760558: step 830, loss = 2.65 (177.4 examples/sec; 0.722 sec/batch)
2017-03-27 20:04:25.873692: step 840, loss = 2.57 (196.4 examples/sec; 0.652 sec/batch)
2017-03-27 20:04:51.278986: step 850, loss = 2.40 (254.7 examples/sec; 0.503 sec/batch)
2017-03-27 20:05:18.219390: step 860, loss = 2.45 (231.0 examples/sec; 0.554 sec/batch)
2017-03-27 20:05:43.783941: step 870, loss = 2.54 (231.2 examples/sec; 0.554 sec/batch)
2017-03-27 20:06:10.881609: step 880, loss = 2.49 (194.2 examples/sec; 0.659 sec/batch)
2017-03-27 20:06:37.334819: step 890, loss = 2.57 (179.2 examples/sec; 0.714 sec/batch)
2017-03-27 20:07:04.405804: step 900, loss = 2.66 (194.2 examples/sec; 0.659 sec/batch)
2017-03-27 20:07:33.789852: step 910, loss = 2.41 (169.8 examples/sec; 0.754 sec/batch)
2017-03-27 20:08:00.781905: step 920, loss = 2.39 (188.1 examples/sec; 0.681 sec/batch)
2017-03-27 20:08:27.574612: step 930, loss = 2.47 (204.2 examples/sec; 0.627 sec/batch)
2017-03-27 20:08:53.584209: step 940, loss = 2.33 (203.6 examples/sec; 0.629 sec/batch)
2017-03-27 20:09:20.882582: step 950, loss = 2.74 (170.6 examples/sec; 0.750 sec/batch)
2017-03-27 20:09:46.787176: step 960, loss = 2.35 (226.8 examples/sec; 0.564 sec/batch)
2017-03-27 20:10:13.693611: step 970, loss = 2.23 (221.3 examples/sec; 0.578 sec/batch)
2017-03-27 20:10:39.787442: step 980, loss = 2.30 (189.5 examples/sec; 0.675 sec/batch)
2017-03-27 20:11:05.435047: step 990, loss = 2.46 (222.1 examples/sec; 0.576 sec/batch)
2017-03-27 20:11:31.995699: step 1000, loss = 2.42 (189.5 examples/sec; 0.676 sec/batch)
2017-03-27 20:12:02.392635: step 1010, loss = 2.41 (176.0 examples/sec; 0.727 sec/batch)
2017-03-27 20:12:28.601123: step 1020, loss = 2.28 (189.5 examples/sec; 0.675 sec/batch)
2017-03-27 20:12:57.962129: step 1030, loss = 2.07 (166.6 examples/sec; 0.768 sec/batch)
2017-03-27 20:13:23.711667: step 1040, loss = 2.40 (150.0 examples/sec; 0.853 sec/batch)
2017-03-27 20:13:50.391482: step 1050, loss = 2.16 (163.3 examples/sec; 0.784 sec/batch)
2017-03-27 20:14:17.150539: step 1060, loss = 2.18 (176.4 examples/sec; 0.725 sec/batch)
2017-03-27 20:14:43.821420: step 1070, loss = 2.23 (231.7 examples/sec; 0.552 sec/batch)
2017-03-27 20:15:11.304181: step 1080, loss = 2.38 (194.1 examples/sec; 0.659 sec/batch)
2017-03-27 20:15:37.173430: step 1090, loss = 2.05 (203.5 examples/sec; 0.629 sec/batch)
2017-03-27 20:16:04.255046: step 1100, loss = 2.23 (194.7 examples/sec; 0.657 sec/batch)
2017-03-27 20:16:34.813689: step 1110, loss = 2.28 (165.6 examples/sec; 0.773 sec/batch)
2017-03-27 20:17:01.100678: step 1120, loss = 2.14 (178.2 examples/sec; 0.718 sec/batch)
2017-03-27 20:17:28.586044: step 1130, loss = 2.11 (195.2 examples/sec; 0.656 sec/batch)
2017-03-27 20:17:55.360578: step 1140, loss = 2.04 (150.1 examples/sec; 0.853 sec/batch)
2017-03-27 20:18:22.455943: step 1150, loss = 2.24 (186.1 examples/sec; 0.688 sec/batch)
2017-03-27 20:18:50.903029: step 1160, loss = 1.96 (185.7 examples/sec; 0.689 sec/batch)
2017-03-27 20:19:18.376409: step 1170, loss = 2.09 (170.0 examples/sec; 0.753 sec/batch)
2017-03-27 20:19:45.204791: step 1180, loss = 2.04 (213.4 examples/sec; 0.600 sec/batch)
2017-03-27 20:20:11.020790: step 1190, loss = 2.19 (189.2 examples/sec; 0.676 sec/batch)
2017-03-27 20:20:37.598919: step 1200, loss = 2.10 (198.9 examples/sec; 0.644 sec/batch)
2017-03-27 20:21:08.177342: step 1210, loss = 2.31 (182.7 examples/sec; 0.701 sec/batch)
2017-03-27 20:21:35.569058: step 1220, loss = 2.14 (153.8 examples/sec; 0.832 sec/batch)
2017-03-27 20:22:02.416500: step 1230, loss = 2.10 (186.6 examples/sec; 0.686 sec/batch)
2017-03-27 20:22:30.671925: step 1240, loss = 1.93 (176.6 examples/sec; 0.725 sec/batch)
2017-03-27 20:22:56.999680: step 1250, loss = 2.17 (183.7 examples/sec; 0.697 sec/batch)
2017-03-27 20:23:25.414515: step 1260, loss = 2.00 (189.4 examples/sec; 0.676 sec/batch)
2017-03-27 20:23:52.737623: step 1270, loss = 2.07 (181.8 examples/sec; 0.704 sec/batch)
2017-03-27 20:24:20.142201: step 1280, loss = 1.95 (174.4 examples/sec; 0.734 sec/batch)
2017-03-27 20:24:47.854200: step 1290, loss = 1.81 (184.2 examples/sec; 0.695 sec/batch)
2017-03-27 20:25:14.885685: step 1300, loss = 1.94 (175.9 examples/sec; 0.728 sec/batch)
2017-03-27 20:25:43.580519: step 1310, loss = 2.08 (244.6 examples/sec; 0.523 sec/batch)
2017-03-27 20:26:10.291048: step 1320, loss = 2.09 (154.9 examples/sec; 0.826 sec/batch)
2017-03-27 20:26:36.991663: step 1330, loss = 2.06 (180.9 examples/sec; 0.708 sec/batch)
2017-03-27 20:27:04.117405: step 1340, loss = 2.12 (188.9 examples/sec; 0.678 sec/batch)
2017-03-27 20:27:30.031492: step 1350, loss = 1.96 (213.5 examples/sec; 0.600 sec/batch)
2017-03-27 20:27:56.745065: step 1360, loss = 1.83 (199.8 examples/sec; 0.641 sec/batch)
2017-03-27 20:28:23.977106: step 1370, loss = 1.98 (220.1 examples/sec; 0.581 sec/batch)
2017-03-27 20:28:51.653204: step 1380, loss = 1.90 (189.6 examples/sec; 0.675 sec/batch)
2017-03-27 20:29:18.689594: step 1390, loss = 2.08 (190.3 examples/sec; 0.673 sec/batch)
2017-03-27 20:29:46.789295: step 1400, loss = 2.07 (141.3 examples/sec; 0.906 sec/batch)
2017-03-27 20:30:15.382193: step 1410, loss = 1.87 (203.6 examples/sec; 0.629 sec/batch)
2017-03-27 20:30:40.716611: step 1420, loss = 2.02 (214.1 examples/sec; 0.598 sec/batch)
2017-03-27 20:31:07.416061: step 1430, loss = 1.73 (185.0 examples/sec; 0.692 sec/batch)
2017-03-27 20:31:35.051818: step 1440, loss = 1.89 (191.9 examples/sec; 0.667 sec/batch)
2017-03-27 20:32:01.469996: step 1450, loss = 2.10 (231.1 examples/sec; 0.554 sec/batch)
2017-03-27 20:32:28.600844: step 1460, loss = 1.70 (197.7 examples/sec; 0.647 sec/batch)
2017-03-27 20:32:56.324405: step 1470, loss = 1.76 (203.2 examples/sec; 0.630 sec/batch)
2017-03-27 20:33:23.486288: step 1480, loss = 2.25 (202.5 examples/sec; 0.632 sec/batch)
2017-03-27 20:33:49.776652: step 1490, loss = 1.77 (211.4 examples/sec; 0.606 sec/batch)
2017-03-27 20:34:16.973078: step 1500, loss = 1.75 (162.7 examples/sec; 0.786 sec/batch)
2017-03-27 20:34:47.797704: step 1510, loss = 1.78 (176.4 examples/sec; 0.726 sec/batch)
2017-03-27 20:35:14.206160: step 1520, loss = 1.79 (202.8 examples/sec; 0.631 sec/batch)
2017-03-27 20:35:40.812538: step 1530, loss = 1.95 (185.6 examples/sec; 0.689 sec/batch)
2017-03-27 20:36:08.044138: step 1540, loss = 1.83 (189.3 examples/sec; 0.676 sec/batch)
2017-03-27 20:36:35.161508: step 1550, loss = 1.78 (208.4 examples/sec; 0.614 sec/batch)
2017-03-27 20:37:01.680550: step 1560, loss = 1.81 (189.5 examples/sec; 0.676 sec/batch)
2017-03-27 20:37:29.050672: step 1570, loss = 1.78 (189.7 examples/sec; 0.675 sec/batch)
2017-03-27 20:37:56.332387: step 1580, loss = 1.73 (174.9 examples/sec; 0.732 sec/batch)
2017-03-27 20:38:22.492058: step 1590, loss = 1.62 (207.6 examples/sec; 0.617 sec/batch)
2017-03-27 20:36:35.161508: step 1550, loss = 1.78 (208.4 examples/sec; 0.614 sec/batch)
2017-03-27 20:37:01.680550: step 1560, loss = 1.81 (189.5 examples/sec; 0.676 sec/batch)
2017-03-27 20:37:29.050672: step 1570, loss = 1.78 (189.7 examples/sec; 0.675 sec/batch)
2017-03-27 20:37:56.332387: step 1580, loss = 1.73 (174.9 examples/sec; 0.732 sec/batch)
2017-03-27 20:38:22.492058: step 1590, loss = 1.62 (207.6 examples/sec; 0.617 sec/batch)
` 

Is this abnormal? Is something stopping the GPUs from running correctly?

Mon Mar 27 20:38:08 2017
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 375.39                 Driver Version: 375.39                    |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  Tesla K80           Off  | 0000:00:04.0     Off |                    0 |
| N/A   56C    P0    58W / 149W |  10943MiB / 11439MiB |      1%      Default |
+-------------------------------+----------------------+----------------------+
|   1  Tesla K80           Off  | 0000:00:05.0     Off |                    0 |
| N/A   72C    P0    71W / 149W |  10943MiB / 11439MiB |      1%      Default |
+-------------------------------+----------------------+----------------------+
|   2  Tesla K80           Off  | 0000:00:06.0     Off |                    0 |
| N/A   73C    P0    72W / 149W |  10943MiB / 11439MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   3  Tesla K80           Off  | 0000:00:07.0     Off |                    0 |
| N/A   56C    P0    63W / 149W |  10941MiB / 11439MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+

+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID  Type  Process name                               Usage      |",MikeTam1021,b'stat:awaiting model gardener type:bug',2017-03-27T20:39:00Z,2019-12-13T17:39:14Z,,,,,,,
1262,Loading Skip Thoughts Model in Python 3,"Model: skip_thoughts
Issue type: Update for Python 3.5+ support
Excellent job with the implementation of Skip-Thoughts in TF.
Just want to bring to your attention about loading the embedding matrix .npy file in Python 3.5.3.
These lines in encoder_manager.py:
```
with open(embedding_matrix_file, ""r"") as f:
      embedding_matrix = np.load(f)
```
need to be changed to the following:
`embedding_matrix = np.load(embedding_matrix_file)`
as Python 3 seems to have issues loading the file object but seems fine loading directly.
The original code raises an error as: _startswith first arg must be str or a tuple of str, not bytes_
when npyio.py file reads the file object at line 393: `magic.startswith(_ZIP_PREFIX)`

Thanks",karthikmswamy,b'stat:awaiting maintainer type:bug',2017-03-27T06:44:27Z,2018-02-28T03:33:24Z,,,,,,,
1257,[im2txt] Unable to preprocess mscoco dataset for show and tell,"I'm trying to preprocess mscoco dataset for use in im2txt model. 
I'm using tensorflow 1.0 for GPU on a GTX 1070 with 16 GB RAM.
Python version: 3.5.3
```
(tensorflow) timberners@galileo:/media/timberners/magicae/models/im2txt$ bazel-bin/im2txt/download_and_preprocess_mscoco ""${MSCOCO_DIR}""
/media/timberners/magicae/models/im2txt
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcudnn.so.5 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.so.8.0 locally
Loaded caption metadata for 82783 images from /media/timberners/magicae/models/im2txt/data/mscoco/raw-data/annotations/captions_train2014.json
Processing captions.
Finished processing 414113 captions for 82783 images in /media/timberners/magicae/models/im2txt/data/mscoco/raw-data/annotations/captions_train2014.json
Loaded caption metadata for 40504 images from /media/timberners/magicae/models/im2txt/data/mscoco/raw-data/annotations/captions_val2014.json
Processing captions.
Finished processing 202654 captions for 40504 images in /media/timberners/magicae/models/im2txt/data/mscoco/raw-data/annotations/captions_val2014.json
Creating vocabulary.
Total words: 29415
Words in vocabulary: 11519
Wrote vocabulary file: /media/timberners/magicae/models/im2txt/data/mscoco/word_counts.txt
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE3 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:910] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
I tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with properties: 
name: GeForce GTX 1070
major: 6 minor: 1 memoryClockRate (GHz) 1.7465
pciBusID 0000:01:00.0
Total memory: 7.92GiB
Free memory: 7.47GiB
I tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0:   Y 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0)
Launching 8 threads for spacings: [[0, 73296], [73296, 146592], [146592, 219888], [219888, 293184], [293184, 366480], [366480, 439776], [439776, 513072], [513072, 586368]]
Exception in thread Thread-3:
Traceback (most recent call last):
  File ""/home/timberners/anaconda3/envs/tensorflow/lib/python3.5/threading.py"", line 914, in _bootstrap_inner
    self.run()
  File ""/home/timberners/anaconda3/envs/tensorflow/lib/python3.5/threading.py"", line 862, in run
    self._target(*self._args, **self._kwargs)
  File ""/media/timberners/magicae/models/im2txt/bazel-bin/im2txt/download_and_preprocess_mscoco.runfiles/im2txt/im2txt/data/build_mscoco_data.py"", line 281, in _process_image_files
    sequence_example = _to_sequence_example(image, decoder, vocab)
  File ""/media/timberners/magicae/models/im2txt/bazel-bin/im2txt/download_and_preprocess_mscoco.runfiles/im2txt/im2txt/data/build_mscoco_data.py"", line 227, in _to_sequence_example
    ""image/data"": _bytes_feature(encoded_image),
  File ""/media/timberners/magicae/models/im2txt/bazel-bin/im2txt/download_and_preprocess_mscoco.runfiles/im2txt/im2txt/data/build_mscoco_data.py"", line 192, in _bytes_feature
    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[str(value)]))
TypeError: 'b\'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x01\\x00\\xb4\\x00\\xb4\\x00\\x00\\xff\\xe2\\ has type str, but expected one of: bytes

Exception in thread Thread-1:
Traceback (most recent call last):
  File ""/home/timberners/anaconda3/envs/tensorflow/lib/python3.5/threading.py"", line 914, in _bootstrap_inner
    self.run()
  File ""/home/timberners/anaconda3/envs/tensorflow/lib/python3.5/threading.py"", line 862, in run
    self._target(*self._args, **self._kwargs)
  File ""/media/timberners/magicae/models/im2txt/bazel-bin/im2txt/download_and_preprocess_mscoco.runfiles/im2txt/im2txt/data/build_mscoco_data.py"", line 281, in _process_image_files
    sequence_example = _to_sequence_example(image, decoder, vocab)
  File ""/media/timberners/magicae/models/im2txt/bazel-bin/im2txt/download_and_preprocess_mscoco.runfiles/im2txt/im2txt/data/build_mscoco_data.py"", line 227, in _to_sequence_example
    ""image/data"": _bytes_feature(encoded_image),
  File ""/media/timberners/magicae/models/im2txt/bazel-bin/im2txt/download_and_preprocess_mscoco.runfiles/im2txt/im2txt/data/build_mscoco_data.py"", line 192, in _bytes_feature
    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[str(value)]))
TypeError: 'b\'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x01\\x00H\\x00H\\x00\\x00\\xff\\xe2\\x0cXICC_ has type str, but expected one of: bytes

Exception in thread Thread-2:
Traceback (most recent call last):
  File ""/home/timberners/anaconda3/envs/tensorflow/lib/python3.5/threading.py"", line 914, in _bootstrap_inner
    self.run()
  File ""/home/timberners/anaconda3/envs/tensorflow/lib/python3.5/threading.py"", line 862, in run
    self._target(*self._args, **self._kwargs)
  File ""/media/timberners/magicae/models/im2txt/bazel-bin/im2txt/download_and_preprocess_mscoco.runfiles/im2txt/im2txt/data/build_mscoco_data.py"", line 281, in _process_image_files
    sequence_example = _to_sequence_example(image, decoder, vocab)
  File ""/media/timberners/magicae/models/im2txt/bazel-bin/im2txt/download_and_preprocess_mscoco.runfiles/im2txt/im2txt/data/build_mscoco_data.py"", line 227, in _to_sequence_example
    ""image/data"": _bytes_feature(encoded_image),
  File ""/media/timberners/magicae/models/im2txt/bazel-bin/im2txt/download_and_preprocess_mscoco.runfiles/im2txt/im2txt/data/build_mscoco_data.py"", line 192, in _bytes_feature
    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[str(value)]))
TypeError: 'b\'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x01\\x00H\\x00H\\x00\\x00\\xff\\xdb\\x00C\\x0 has type str, but expected one of: bytes

Exception in thread Thread-7:
Traceback (most recent call last):
  File ""/home/timberners/anaconda3/envs/tensorflow/lib/python3.5/threading.py"", line 914, in _bootstrap_inner
    self.run()
  File ""/home/timberners/anaconda3/envs/tensorflow/lib/python3.5/threading.py"", line 862, in run
    self._target(*self._args, **self._kwargs)
  File ""/media/timberners/magicae/models/im2txt/bazel-bin/im2txt/download_and_preprocess_mscoco.runfiles/im2txt/im2txt/data/build_mscoco_data.py"", line 281, in _process_image_files
    sequence_example = _to_sequence_example(image, decoder, vocab)
  File ""/media/timberners/magicae/models/im2txt/bazel-bin/im2txt/download_and_preprocess_mscoco.runfiles/im2txt/im2txt/data/build_mscoco_data.py"", line 227, in _to_sequence_example
    ""image/data"": _bytes_feature(encoded_image),
  File ""/media/timberners/magicae/models/im2txt/bazel-bin/im2txt/download_and_preprocess_mscoco.runfiles/im2txt/im2txt/data/build_mscoco_data.py"", line 192, in _bytes_feature
    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[str(value)]))
TypeError: 'b\'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x01\\x00H\\x00H\\x00\\x00\\xff\\xdb\\x00C\\x0 has type str, but expected one of: bytes
Exception in thread Thread-6:
Traceback (most recent call last):
  File ""/home/timberners/anaconda3/envs/tensorflow/lib/python3.5/threading.py"", line 914, in _bootstrap_inner
    self.run()
  File ""/home/timberners/anaconda3/envs/tensorflow/lib/python3.5/threading.py"", line 862, in run
    self._target(*self._args, **self._kwargs)
  File ""/media/timberners/magicae/models/im2txt/bazel-bin/im2txt/download_and_preprocess_mscoco.runfiles/im2txt/im2txt/data/build_mscoco_data.py"", line 281, in _process_image_files
    sequence_example = _to_sequence_example(image, decoder, vocab)
  File ""/media/timberners/magicae/models/im2txt/bazel-bin/im2txt/download_and_preprocess_mscoco.runfiles/im2txt/im2txt/data/build_mscoco_data.py"", line 227, in _to_sequence_example
    ""image/data"": _bytes_feature(encoded_image),
  File ""/media/timberners/magicae/models/im2txt/bazel-bin/im2txt/download_and_preprocess_mscoco.runfiles/im2txt/im2txt/data/build_mscoco_data.py"", line 192, in _bytes_feature
    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[str(value)]))
TypeError: 'b\'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x01\\x00H\\x00H\\x00\\x00\\xff\\xe2\\x0cXICC_ has type str, but expected one of: bytes
Exception in thread Thread-4:
Traceback (most recent call last):
  File ""/home/timberners/anaconda3/envs/tensorflow/lib/python3.5/threading.py"", line 914, in _bootstrap_inner
    self.run()
  File ""/home/timberners/anaconda3/envs/tensorflow/lib/python3.5/threading.py"", line 862, in run
    self._target(*self._args, **self._kwargs)
  File ""/media/timberners/magicae/models/im2txt/bazel-bin/im2txt/download_and_preprocess_mscoco.runfiles/im2txt/im2txt/data/build_mscoco_data.py"", line 281, in _process_image_files
    sequence_example = _to_sequence_example(image, decoder, vocab)
  File ""/media/timberners/magicae/models/im2txt/bazel-bin/im2txt/download_and_preprocess_mscoco.runfiles/im2txt/im2txt/data/build_mscoco_data.py"", line 227, in _to_sequence_example
    ""image/data"": _bytes_feature(encoded_image),
  File ""/media/timberners/magicae/models/im2txt/bazel-bin/im2txt/download_and_preprocess_mscoco.runfiles/im2txt/im2txt/data/build_mscoco_data.py"", line 192, in _bytes_feature
    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[str(value)]))
TypeError: 'b\'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x01\\x00H\\x00H\\x00\\x00\\xff\\xe2\\x0cTICC_ has type str, but expected one of: bytes


Exception in thread Thread-5:
Traceback (most recent call last):
  File ""/home/timberners/anaconda3/envs/tensorflow/lib/python3.5/threading.py"", line 914, in _bootstrap_inner
    self.run()
  File ""/home/timberners/anaconda3/envs/tensorflow/lib/python3.5/threading.py"", line 862, in run
    self._target(*self._args, **self._kwargs)
  File ""/media/timberners/magicae/models/im2txt/bazel-bin/im2txt/download_and_preprocess_mscoco.runfiles/im2txt/im2txt/data/build_mscoco_data.py"", line 281, in _process_image_files
    sequence_example = _to_sequence_example(image, decoder, vocab)
  File ""/media/timberners/magicae/models/im2txt/bazel-bin/im2txt/download_and_preprocess_mscoco.runfiles/im2txt/im2txt/data/build_mscoco_data.py"", line 227, in _to_sequence_example
    ""image/data"": _bytes_feature(encoded_image),
  File ""/media/timberners/magicae/models/im2txt/bazel-bin/im2txt/download_and_preprocess_mscoco.runfiles/im2txt/im2txt/data/build_mscoco_data.py"", line 192, in _bytes_feature
    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[str(value)]))
TypeError: 'b\'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x01\\x00H\\x00H\\x00\\x00\\xff\\xe1\\x0b\\x0e has type str, but expected one of: bytes


Exception in thread Thread-8:
Traceback (most recent call last):
  File ""/home/timberners/anaconda3/envs/tensorflow/lib/python3.5/threading.py"", line 914, in _bootstrap_inner
    self.run()
  File ""/home/timberners/anaconda3/envs/tensorflow/lib/python3.5/threading.py"", line 862, in run
    self._target(*self._args, **self._kwargs)
  File ""/media/timberners/magicae/models/im2txt/bazel-bin/im2txt/download_and_preprocess_mscoco.runfiles/im2txt/im2txt/data/build_mscoco_data.py"", line 281, in _process_image_files
    sequence_example = _to_sequence_example(image, decoder, vocab)
  File ""/media/timberners/magicae/models/im2txt/bazel-bin/im2txt/download_and_preprocess_mscoco.runfiles/im2txt/im2txt/data/build_mscoco_data.py"", line 227, in _to_sequence_example
    ""image/data"": _bytes_feature(encoded_image),
  File ""/media/timberners/magicae/models/im2txt/bazel-bin/im2txt/download_and_preprocess_mscoco.runfiles/im2txt/im2txt/data/build_mscoco_data.py"", line 192, in _bytes_feature
    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[str(value)]))
TypeError: 'b\'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x01\\x01\\xce\\x01\\xce\\x00\\x00\\xff\\xe2\\ has type str, but expected one of: bytes

2017-03-26 01:57:03.430551: Finished processing all 586368 image-caption pairs in data set 'train'.
I tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0)
Launching 4 threads for spacings: [[0, 2533], [2533, 5066], [5066, 7599], [7599, 10132]]
Exception in thread Thread-10:
Traceback (most recent call last):
  File ""/home/timberners/anaconda3/envs/tensorflow/lib/python3.5/threading.py"", line 914, in _bootstrap_inner
    self.run()
  File ""/home/timberners/anaconda3/envs/tensorflow/lib/python3.5/threading.py"", line 862, in run
    self._target(*self._args, **self._kwargs)
  File ""/media/timberners/magicae/models/im2txt/bazel-bin/im2txt/download_and_preprocess_mscoco.runfiles/im2txt/im2txt/data/build_mscoco_data.py"", line 281, in _process_image_files
    sequence_example = _to_sequence_example(image, decoder, vocab)
  File ""/media/timberners/magicae/models/im2txt/bazel-bin/im2txt/download_and_preprocess_mscoco.runfiles/im2txt/im2txt/data/build_mscoco_data.py"", line 227, in _to_sequence_example
    ""image/data"": _bytes_feature(encoded_image),
  File ""/media/timberners/magicae/models/im2txt/bazel-bin/im2txt/download_and_preprocess_mscoco.runfiles/im2txt/im2txt/data/build_mscoco_data.py"", line 192, in _bytes_feature
    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[str(value)]))
TypeError: 'b\'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x01\\x00H\\x00H\\x00\\x00\\xff\\xdb\\x00C\\x0 has type str, but expected one of: bytes

Exception in thread Thread-11:
Traceback (most recent call last):
  File ""/home/timberners/anaconda3/envs/tensorflow/lib/python3.5/threading.py"", line 914, in _bootstrap_inner
    self.run()
  File ""/home/timberners/anaconda3/envs/tensorflow/lib/python3.5/threading.py"", line 862, in run
    self._target(*self._args, **self._kwargs)
  File ""/media/timberners/magicae/models/im2txt/bazel-bin/im2txt/download_and_preprocess_mscoco.runfiles/im2txt/im2txt/data/build_mscoco_data.py"", line 281, in _process_image_files
    sequence_example = _to_sequence_example(image, decoder, vocab)
  File ""/media/timberners/magicae/models/im2txt/bazel-bin/im2txt/download_and_preprocess_mscoco.runfiles/im2txt/im2txt/data/build_mscoco_data.py"", line 227, in _to_sequence_example
    ""image/data"": _bytes_feature(encoded_image),
  File ""/media/timberners/magicae/models/im2txt/bazel-bin/im2txt/download_and_preprocess_mscoco.runfiles/im2txt/im2txt/data/build_mscoco_data.py"", line 192, in _bytes_feature
    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[str(value)]))
TypeError: 'b\'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x01\\x00H\\x00H\\x00\\x00\\xff\\xdb\\x00C\\x0 has type str, but expected one of: bytes

Exception in thread Thread-9:
Traceback (most recent call last):
  File ""/home/timberners/anaconda3/envs/tensorflow/lib/python3.5/threading.py"", line 914, in _bootstrap_inner
    self.run()
  File ""/home/timberners/anaconda3/envs/tensorflow/lib/python3.5/threading.py"", line 862, in run
    self._target(*self._args, **self._kwargs)
  File ""/media/timberners/magicae/models/im2txt/bazel-bin/im2txt/download_and_preprocess_mscoco.runfiles/im2txt/im2txt/data/build_mscoco_data.py"", line 281, in _process_image_files
    sequence_example = _to_sequence_example(image, decoder, vocab)
  File ""/media/timberners/magicae/models/im2txt/bazel-bin/im2txt/download_and_preprocess_mscoco.runfiles/im2txt/im2txt/data/build_mscoco_data.py"", line 227, in _to_sequence_example
    ""image/data"": _bytes_feature(encoded_image),
  File ""/media/timberners/magicae/models/im2txt/bazel-bin/im2txt/download_and_preprocess_mscoco.runfiles/im2txt/im2txt/data/build_mscoco_data.py"", line 192, in _bytes_feature
    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[str(value)]))
TypeError: 'b\'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x01\\x00H\\x00H\\x00\\x00\\xff\\xe2\\x0cXICC_ has type str, but expected one of: bytes

Exception in thread Thread-12:
Traceback (most recent call last):
  File ""/home/timberners/anaconda3/envs/tensorflow/lib/python3.5/threading.py"", line 914, in _bootstrap_inner
    self.run()
  File ""/home/timberners/anaconda3/envs/tensorflow/lib/python3.5/threading.py"", line 862, in run
    self._target(*self._args, **self._kwargs)
  File ""/media/timberners/magicae/models/im2txt/bazel-bin/im2txt/download_and_preprocess_mscoco.runfiles/im2txt/im2txt/data/build_mscoco_data.py"", line 281, in _process_image_files
    sequence_example = _to_sequence_example(image, decoder, vocab)
  File ""/media/timberners/magicae/models/im2txt/bazel-bin/im2txt/download_and_preprocess_mscoco.runfiles/im2txt/im2txt/data/build_mscoco_data.py"", line 227, in _to_sequence_example
    ""image/data"": _bytes_feature(encoded_image),
  File ""/media/timberners/magicae/models/im2txt/bazel-bin/im2txt/download_and_preprocess_mscoco.runfiles/im2txt/im2txt/data/build_mscoco_data.py"", line 192, in _bytes_feature
    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[str(value)]))
TypeError: 'b\'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x01\\x01,\\x01,\\x00\\x00\\xff\\xdb\\x00C\\x0 has type str, but expected one of: bytes

2017-03-26 01:57:04.812453: Finished processing all 10132 image-caption pairs in data set 'val'.
I tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0)
Launching 8 threads for spacings: [[0, 2533], [2533, 5066], [5066, 7600], [7600, 10133], [10133, 12666], [12666, 15200], [15200, 17733], [17733, 20267]]
Exception in thread Thread-16:
Traceback (most recent call last):
  File ""/home/timberners/anaconda3/envs/tensorflow/lib/python3.5/threading.py"", line 914, in _bootstrap_inner
    self.run()
  File ""/home/timberners/anaconda3/envs/tensorflow/lib/python3.5/threading.py"", line 862, in run
    self._target(*self._args, **self._kwargs)
  File ""/media/timberners/magicae/models/im2txt/bazel-bin/im2txt/download_and_preprocess_mscoco.runfiles/im2txt/im2txt/data/build_mscoco_data.py"", line 281, in _process_image_files
    sequence_example = _to_sequence_example(image, decoder, vocab)
  File ""/media/timberners/magicae/models/im2txt/bazel-bin/im2txt/download_and_preprocess_mscoco.runfiles/im2txt/im2txt/data/build_mscoco_data.py"", line 227, in _to_sequence_example
    ""image/data"": _bytes_feature(encoded_image),
  File ""/media/timberners/magicae/models/im2txt/bazel-bin/im2txt/download_and_preprocess_mscoco.runfiles/im2txt/im2txt/data/build_mscoco_data.py"", line 192, in _bytes_feature
    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[str(value)]))
TypeError: 'b\'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x01\\x00H\\x00H\\x00\\x00\\xff\\xfe\\x00\\x0c has type str, but expected one of: bytes

Exception in thread Thread-19:
Traceback (most recent call last):
  File ""/home/timberners/anaconda3/envs/tensorflow/lib/python3.5/threading.py"", line 914, in _bootstrap_inner
    self.run()
  File ""/home/timberners/anaconda3/envs/tensorflow/lib/python3.5/threading.py"", line 862, in run
    self._target(*self._args, **self._kwargs)
  File ""/media/timberners/magicae/models/im2txt/bazel-bin/im2txt/download_and_preprocess_mscoco.runfiles/im2txt/im2txt/data/build_mscoco_data.py"", line 281, in _process_image_files
    sequence_example = _to_sequence_example(image, decoder, vocab)
  File ""/media/timberners/magicae/models/im2txt/bazel-bin/im2txt/download_and_preprocess_mscoco.runfiles/im2txt/im2txt/data/build_mscoco_data.py"", line 227, in _to_sequence_example
    ""image/data"": _bytes_feature(encoded_image),
  File ""/media/timberners/magicae/models/im2txt/bazel-bin/im2txt/download_and_preprocess_mscoco.runfiles/im2txt/im2txt/data/build_mscoco_data.py"", line 192, in _bytes_feature
    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[str(value)]))
TypeError: 'b\'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x01\\x00H\\x00H\\x00\\x00\\xff\\xdb\\x00C\\x0 has type str, but expected one of: bytes

Exception in thread Thread-13:
Traceback (most recent call last):
  File ""/home/timberners/anaconda3/envs/tensorflow/lib/python3.5/threading.py"", line 914, in _bootstrap_inner
    self.run()
  File ""/home/timberners/anaconda3/envs/tensorflow/lib/python3.5/threading.py"", line 862, in run
    self._target(*self._args, **self._kwargs)
  File ""/media/timberners/magicae/models/im2txt/bazel-bin/im2txt/download_and_preprocess_mscoco.runfiles/im2txt/im2txt/data/build_mscoco_data.py"", line 281, in _process_image_files
    sequence_example = _to_sequence_example(image, decoder, vocab)
  File ""/media/timberners/magicae/models/im2txt/bazel-bin/im2txt/download_and_preprocess_mscoco.runfiles/im2txt/im2txt/data/build_mscoco_data.py"", line 227, in _to_sequence_example
    ""image/data"": _bytes_feature(encoded_image),
  File ""/media/timberners/magicae/models/im2txt/bazel-bin/im2txt/download_and_preprocess_mscoco.runfiles/im2txt/im2txt/data/build_mscoco_data.py"", line 192, in _bytes_feature
    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[str(value)]))
TypeError: 'b\'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x01\\x00H\\x00H\\x00\\x00\\xff\\xdb\\x00C\\x0 has type str, but expected one of: bytes

Exception in thread Thread-15:
Traceback (most recent call last):
  File ""/home/timberners/anaconda3/envs/tensorflow/lib/python3.5/threading.py"", line 914, in _bootstrap_inner
    self.run()
  File ""/home/timberners/anaconda3/envs/tensorflow/lib/python3.5/threading.py"", line 862, in run
    self._target(*self._args, **self._kwargs)
  File ""/media/timberners/magicae/models/im2txt/bazel-bin/im2txt/download_and_preprocess_mscoco.runfiles/im2txt/im2txt/data/build_mscoco_data.py"", line 281, in _process_image_files
    sequence_example = _to_sequence_example(image, decoder, vocab)
  File ""/media/timberners/magicae/models/im2txt/bazel-bin/im2txt/download_and_preprocess_mscoco.runfiles/im2txt/im2txt/data/build_mscoco_data.py"", line 227, in _to_sequence_example
    ""image/data"": _bytes_feature(encoded_image),
  File ""/media/timberners/magicae/models/im2txt/bazel-bin/im2txt/download_and_preprocess_mscoco.runfiles/im2txt/im2txt/data/build_mscoco_data.py"", line 192, in _bytes_feature
    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[str(value)]))
TypeError: 'b\'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x01\\x00`\\x00`\\x00\\x00\\xff\\xdb\\x00C\\x0 has type str, but expected one of: bytes

Exception in thread Thread-20:
Traceback (most recent call last):
  File ""/home/timberners/anaconda3/envs/tensorflow/lib/python3.5/threading.py"", line 914, in _bootstrap_inner
    self.run()
  File ""/home/timberners/anaconda3/envs/tensorflow/lib/python3.5/threading.py"", line 862, in run
    self._target(*self._args, **self._kwargs)
  File ""/media/timberners/magicae/models/im2txt/bazel-bin/im2txt/download_and_preprocess_mscoco.runfiles/im2txt/im2txt/data/build_mscoco_data.py"", line 281, in _process_image_files
    sequence_example = _to_sequence_example(image, decoder, vocab)
  File ""/media/timberners/magicae/models/im2txt/bazel-bin/im2txt/download_and_preprocess_mscoco.runfiles/im2txt/im2txt/data/build_mscoco_data.py"", line 227, in _to_sequence_example
    ""image/data"": _bytes_feature(encoded_image),
  File ""/media/timberners/magicae/models/im2txt/bazel-bin/im2txt/download_and_preprocess_mscoco.runfiles/im2txt/im2txt/data/build_mscoco_data.py"", line 192, in _bytes_feature
    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[str(value)]))
TypeError: 'b\'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x01\\x00H\\x00H\\x00\\x00\\xff\\xe1\\n\\x00XM has type str, but expected one of: bytes
Exception in thread Thread-18:
Traceback (most recent call last):
  File ""/home/timberners/anaconda3/envs/tensorflow/lib/python3.5/threading.py"", line 914, in _bootstrap_inner
    self.run()
  File ""/home/timberners/anaconda3/envs/tensorflow/lib/python3.5/threading.py"", line 862, in run
    self._target(*self._args, **self._kwargs)
  File ""/media/timberners/magicae/models/im2txt/bazel-bin/im2txt/download_and_preprocess_mscoco.runfiles/im2txt/im2txt/data/build_mscoco_data.py"", line 281, in _process_image_files
    sequence_example = _to_sequence_example(image, decoder, vocab)
  File ""/media/timberners/magicae/models/im2txt/bazel-bin/im2txt/download_and_preprocess_mscoco.runfiles/im2txt/im2txt/data/build_mscoco_data.py"", line 227, in _to_sequence_example
    ""image/data"": _bytes_feature(encoded_image),
  File ""/media/timberners/magicae/models/im2txt/bazel-bin/im2txt/download_and_preprocess_mscoco.runfiles/im2txt/im2txt/data/build_mscoco_data.py"", line 192, in _bytes_feature
    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[str(value)]))
TypeError: 'b\'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x01\\x00H\\x00H\\x00\\x00\\xff\\xe1\\x01\\xc7 has type str, but expected one of: bytes

Exception in thread Thread-14:
Traceback (most recent call last):
  File ""/home/timberners/anaconda3/envs/tensorflow/lib/python3.5/threading.py"", line 914, in _bootstrap_inner
    self.run()
  File ""/home/timberners/anaconda3/envs/tensorflow/lib/python3.5/threading.py"", line 862, in run
    self._target(*self._args, **self._kwargs)
  File ""/media/timberners/magicae/models/im2txt/bazel-bin/im2txt/download_and_preprocess_mscoco.runfiles/im2txt/im2txt/data/build_mscoco_data.py"", line 281, in _process_image_files
    sequence_example = _to_sequence_example(image, decoder, vocab)
  File ""/media/timberners/magicae/models/im2txt/bazel-bin/im2txt/download_and_preprocess_mscoco.runfiles/im2txt/im2txt/data/build_mscoco_data.py"", line 227, in _to_sequence_example
    ""image/data"": _bytes_feature(encoded_image),
  File ""/media/timberners/magicae/models/im2txt/bazel-bin/im2txt/download_and_preprocess_mscoco.runfiles/im2txt/im2txt/data/build_mscoco_data.py"", line 192, in _bytes_feature
    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[str(value)]))
TypeError: 'b\'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x01\\x01,\\x01,\\x00\\x00\\xff\\xdb\\x00C\\x0 has type str, but expected one of: bytes

Exception in thread Thread-17:
Traceback (most recent call last):
  File ""/home/timberners/anaconda3/envs/tensorflow/lib/python3.5/threading.py"", line 914, in _bootstrap_inner
    self.run()
  File ""/home/timberners/anaconda3/envs/tensorflow/lib/python3.5/threading.py"", line 862, in run
    self._target(*self._args, **self._kwargs)
  File ""/media/timberners/magicae/models/im2txt/bazel-bin/im2txt/download_and_preprocess_mscoco.runfiles/im2txt/im2txt/data/build_mscoco_data.py"", line 281, in _process_image_files
    sequence_example = _to_sequence_example(image, decoder, vocab)
  File ""/media/timberners/magicae/models/im2txt/bazel-bin/im2txt/download_and_preprocess_mscoco.runfiles/im2txt/im2txt/data/build_mscoco_data.py"", line 227, in _to_sequence_example
    ""image/data"": _bytes_feature(encoded_image),
  File ""/media/timberners/magicae/models/im2txt/bazel-bin/im2txt/download_and_preprocess_mscoco.runfiles/im2txt/im2txt/data/build_mscoco_data.py"", line 192, in _bytes_feature
    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[str(value)]))
TypeError: 'b\'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x01\\x00H\\x00H\\x00\\x00\\xff\\xe2\\x0cXICC_ has type str, but expected one of: bytes


2017-03-26 01:57:05.852854: Finished processing all 20267 image-caption pairs in data set 'test'.

```",KranthiGV,b'help wanted type:bug',2017-03-25T20:52:28Z,2020-05-02T05:25:51Z,,,,,,,
1222,[Inception] Resource Exhausted exception when generating TF-Records,"Hi,

I started generating TF records to start training Imagenet data from scratch. I keep getting this error and the process terminates:

````2017-03-20 08:51:14.244444 [thread 0]: Processed 19000 of 1077584 images in thread batch.
Exception in thread Thread-7:
Traceback (most recent call last):
  File ""/usr/lib/python2.7/threading.py"", line 810, in __bootstrap_inner
    self.run()
  File ""/usr/lib/python2.7/threading.py"", line 763, in run
    self.__target(*self.__args, **self.__kwargs)
  File ""/home/ubuntu/tensorflow_models/models-master/inception/bazel-bin/inception/download_and_preprocess_imagenet.runfiles/inception/inception/data/build_imagenet_data.py"", line 389, in _process_image_files_batch
    image_buffer, height, width = _process_image(filename, coder)
  File ""/home/ubuntu/tensorflow_models/models-master/inception/bazel-bin/inception/download_and_preprocess_imagenet.runfiles/inception/inception/data/build_imagenet_data.py"", line 317, in _process_image
    image_data = f.read()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/lib/io/file_io.py"", line 102, in read
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/lib/io/file_io.py"", line 72, in _preread_check
  File ""/usr/lib/python2.7/contextlib.py"", line 24, in __exit__
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/errors.py"", line 463, in raise_exception_on_not_ok_status
ResourceExhaustedError: /imagenet2/raw-data/train/n02055803/n02055803_8301.jpg

Exception in thread Thread-8:
Traceback (most recent call last):
  File ""/usr/lib/python2.7/threading.py"", line 810, in __bootstrap_inner
    self.run()
  File ""/usr/lib/python2.7/threading.py"", line 763, in run
    self.__target(*self.__args, **self.__kwargs)
  File ""/home/ubuntu/tensorflow_models/models-master/inception/bazel-bin/inception/download_and_preprocess_imagenet.runfiles/inception/inception/data/build_imagenet_data.py"", line 389, in _process_image_files_batch
    image_buffer, height, width = _process_image(filename, coder)
  File ""/home/ubuntu/tensorflow_models/models-master/inception/bazel-bin/inception/download_and_preprocess_imagenet.runfiles/inception/inception/data/build_imagenet_data.py"", line 317, in _process_image
    image_data = f.read()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/lib/io/file_io.py"", line 102, in read
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/lib/io/file_io.py"", line 72, in _preread_check
  File ""/usr/lib/python2.7/contextlib.py"", line 24, in __exit__
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/errors.py"", line 463, in raise_exception_on_not_ok_status
ResourceExhaustedError: /imagenet2/raw-data/train/n02382948/n02382948_22355.jpg

Exception in thread Thread-3:
Traceback (most recent call last):
  File ""/usr/lib/python2.7/threading.py"", line 810, in __bootstrap_inner
    self.run()
  File ""/usr/lib/python2.7/threading.py"", line 763, in run
    self.__target(*self.__args, **self.__kwargs)
  File ""/home/ubuntu/tensorflow_models/models-master/inception/bazel-bin/inception/download_and_preprocess_imagenet.runfiles/inception/inception/data/build_imagenet_data.py"", line 389, in _process_image_files_batch
    image_buffer, height, width = _process_image(filename, coder)
  File ""/home/ubuntu/tensorflow_models/models-master/inception/bazel-bin/inception/download_and_preprocess_imagenet.runfiles/inception/inception/data/build_imagenet_data.py"", line 317, in _process_image
    image_data = f.read()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/lib/io/file_io.py"", line 102, in read
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/lib/io/file_io.py"", line 72, in _preread_check
  File ""/usr/lib/python2.7/contextlib.py"", line 24, in __exit__
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/errors.py"", line 463, in raise_exception_on_not_ok_status
ResourceExhaustedError: /imagenet2/raw-data/train/n12409470/n12409470_12184.jpg

Exception in thread Thread-1:
Traceback (most recent call last):
  File ""/usr/lib/python2.7/threading.py"", line 810, in __bootstrap_inner
    self.run()
  File ""/usr/lib/python2.7/threading.py"", line 763, in run
    self.__target(*self.__args, **self.__kwargs)
  File ""/home/ubuntu/tensorflow_models/models-master/inception/bazel-bin/inception/download_and_preprocess_imagenet.runfiles/inception/inception/data/build_imagenet_data.py"", line 389, in _process_image_files_batch
    image_buffer, height, width = _process_image(filename, coder)
  File ""/home/ubuntu/tensorflow_models/models-master/inception/bazel-bin/inception/download_and_preprocess_imagenet.runfiles/inception/inception/data/build_imagenet_data.py"", line 317, in _process_image
    image_data = f.read()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/lib/io/file_io.py"", line 102, in read
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/lib/io/file_io.py"", line 72, in _preread_check
  File ""/usr/lib/python2.7/contextlib.py"", line 24, in __exit__
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/errors.py"", line 463, in raise_exception_on_not_ok_status
ResourceExhaustedError: /imagenet2/raw-data/train/n03978966/n03978966_12697.jpg

2017-03-20 08:51:17.086050: Finished writing all 8620676 images in data set.
Determining list of input files and labels from /imagenet2/raw-data/train/.
Traceback (most recent call last):
  File ""/home/ubuntu/tensorflow_models/models-master/inception/bazel-bin/inception/download_and_preprocess_imagenet.runfiles/inception/inception/data/build_imagenet_data.py"", line 704, in <module>
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 30, in run
  File ""/home/ubuntu/tensorflow_models/models-master/inception/bazel-bin/inception/download_and_preprocess_imagenet.runfiles/inception/inception/data/build_imagenet_data.py"", line 700, in main
  File ""/home/ubuntu/tensorflow_models/models-master/inception/bazel-bin/inception/download_and_preprocess_imagenet.runfiles/inception/inception/data/build_imagenet_data.py"", line 597, in _process_dataset
  File ""/home/ubuntu/tensorflow_models/models-master/inception/bazel-bin/inception/download_and_preprocess_imagenet.runfiles/inception/inception/data/build_imagenet_data.py"", line 513, in _find_image_files
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/lib/io/file_io.py"", line 251, in get_matching_files
  File ""/usr/lib/python2.7/contextlib.py"", line 24, in __exit__
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/errors.py"", line 463, in raise_exception_on_not_ok_status
tensorflow.python.framework.errors.ResourceExhaustedError: /imagenet2/raw-data/train/n00006484
````

I am not sure what resource its exhausting. I am running it on CPU with 8 cores and 30GB of RAM. I kept monitoring the process using top and both memory and CPU levels were low during the process until the crash.

Does generating TF-Records require GPU?

Regards
",redserpent7,b'type:bug',2017-03-20T11:57:32Z,2017-05-09T23:28:09Z,,,,,,,
1213,[Inception] 0-byte TF_Record files,"Hi,

I am trying to train imagenet from scratch. I have all original images available and I followed the documentation step-by-step. However, when I run download_and_preprocess_imagenet I get this output:

````
2017-03-19 14:47:32.641057 [thread 0]: Wrote 0 images to /imagenet2/train-00127-of-01024
2017-03-19 14:47:32.641226 [thread 6]: Wrote 0 images to /imagenet2/train-00892-of-01024
2017-03-19 14:47:32.641296 [thread 7]: Wrote 0 images to /imagenet2/train-00994-of-01024
2017-03-19 14:47:32.641428 [thread 5]: Wrote 0 images to /imagenet2/train-00766-of-01024
2017-03-19 14:47:32.641474 [thread 0]: Wrote 0 images to 0 shards.
2017-03-19 14:47:32.641542 [thread 4]: Wrote 0 images to /imagenet2/train-00634-of-01024
2017-03-19 14:47:32.641797 [thread 6]: Wrote 0 images to /imagenet2/train-00893-of-01024
2017-03-19 14:47:32.641883 [thread 4]: Wrote 0 images to /imagenet2/train-00635-of-01024
2017-03-19 14:47:32.641969 [thread 7]: Wrote 0 images to /imagenet2/train-00995-of-01024
2017-03-19 14:47:32.642150 [thread 5]: Wrote 0 images to /imagenet2/train-00767-of-01024
2017-03-19 14:47:32.642309 [thread 6]: Wrote 0 images to /imagenet2/train-00894-of-01024
2017-03-19 14:47:32.642365 [thread 4]: Wrote 0 images to /imagenet2/train-00636-of-01024
2017-03-19 14:47:32.642472 [thread 7]: Wrote 0 images to /imagenet2/train-00996-of-01024
2017-03-19 14:47:32.642543 [thread 5]: Wrote 0 images to 0 shards.
2017-03-19 14:47:32.642614 [thread 4]: Wrote 0 images to /imagenet2/train-00637-of-01024
2017-03-19 14:47:32.642821 [thread 4]: Wrote 0 images to /imagenet2/train-00638-of-01024
2017-03-19 14:47:32.642962 [thread 4]: Wrote 0 images to /imagenet2/train-00639-of-01024
2017-03-19 14:47:32.643050 [thread 6]: Wrote 0 images to /imagenet2/train-00895-of-01024
2017-03-19 14:47:32.643123 [thread 4]: Wrote 0 images to 0 shards.
2017-03-19 14:47:32.643188 [thread 7]: Wrote 0 images to /imagenet2/train-00997-of-01024
2017-03-19 14:47:32.643224 [thread 6]: Wrote 0 images to 0 shards.
2017-03-19 14:47:32.643409 [thread 7]: Wrote 0 images to /imagenet2/train-00998-of-01024
2017-03-19 14:47:32.643509 [thread 7]: Wrote 0 images to /imagenet2/train-00999-of-01024
2017-03-19 14:47:32.643602 [thread 7]: Wrote 0 images to /imagenet2/train-01000-of-01024
2017-03-19 14:47:32.643694 [thread 7]: Wrote 0 images to /imagenet2/train-01001-of-01024
2017-03-19 14:47:32.643788 [thread 7]: Wrote 0 images to /imagenet2/train-01002-of-01024
2017-03-19 14:47:32.643879 [thread 7]: Wrote 0 images to /imagenet2/train-01003-of-01024
2017-03-19 14:47:32.643969 [thread 7]: Wrote 0 images to /imagenet2/train-01004-of-01024
2017-03-19 14:47:32.644059 [thread 7]: Wrote 0 images to /imagenet2/train-01005-of-01024
2017-03-19 14:47:32.644148 [thread 7]: Wrote 0 images to /imagenet2/train-01006-of-01024
2017-03-19 14:47:32.644238 [thread 7]: Wrote 0 images to /imagenet2/train-01007-of-01024
2017-03-19 14:47:32.644338 [thread 7]: Wrote 0 images to /imagenet2/train-01008-of-01024
2017-03-19 14:47:32.644430 [thread 7]: Wrote 0 images to /imagenet2/train-01009-of-01024
2017-03-19 14:47:32.644519 [thread 7]: Wrote 0 images to /imagenet2/train-01010-of-01024
2017-03-19 14:47:32.644607 [thread 7]: Wrote 0 images to /imagenet2/train-01011-of-01024
2017-03-19 14:47:32.644694 [thread 7]: Wrote 0 images to /imagenet2/train-01012-of-01024
2017-03-19 14:47:32.644783 [thread 7]: Wrote 0 images to /imagenet2/train-01013-of-01024
2017-03-19 14:47:32.644871 [thread 7]: Wrote 0 images to /imagenet2/train-01014-of-01024
2017-03-19 14:47:32.644959 [thread 7]: Wrote 0 images to /imagenet2/train-01015-of-01024
2017-03-19 14:47:32.645049 [thread 7]: Wrote 0 images to /imagenet2/train-01016-of-01024
2017-03-19 14:47:32.645136 [thread 7]: Wrote 0 images to /imagenet2/train-01017-of-01024
2017-03-19 14:47:32.645225 [thread 7]: Wrote 0 images to /imagenet2/train-01018-of-01024
2017-03-19 14:47:32.645312 [thread 7]: Wrote 0 images to /imagenet2/train-01019-of-01024
2017-03-19 14:47:32.645402 [thread 7]: Wrote 0 images to /imagenet2/train-01020-of-01024
2017-03-19 14:47:32.645490 [thread 7]: Wrote 0 images to /imagenet2/train-01021-of-01024
2017-03-19 14:47:32.645578 [thread 7]: Wrote 0 images to /imagenet2/train-01022-of-01024
2017-03-19 14:47:32.645670 [thread 7]: Wrote 0 images to /imagenet2/train-01023-of-01024
````

And when I go and check my data directory I see all TF-Record files are 0-bytes.

No exceptions are thrown and no warnings. not sure what is wrong here.

I checked all classes folders and they all contain the jpg images.",redserpent7,b'stat:awaiting response type:bug type:build/install type:support',2017-03-19T14:51:10Z,2018-02-22T20:01:26Z,,,,,,,
1126,when i use tensorboard in tf1.0 there are SyntaxError: invalid syntax,"when i fine this inception3 model and use tensorboard in tf1.0 all have syntaxerror invalid syntax .

DATASET_DIR=/home/cy/data/flowers
TRAIN_DIR=./flowers-models/inception_v3
CHECKPOINT_PATH=./pretrainmodel/inception_v3.ckpt
python3 train_image_classifier.py \
    --train_dir=${TRAIN_DIR} \
    --dataset_dir=${DATASET_DIR} \
    --dataset_name=flowers \
    --dataset_split_name=train \
    --model_name=inception_v3 \
    --checkpoint_path=${CHECKPOINT_PATH} \
    --checkpoint_exclude_scopes=InceptionV3/Logits,InceptionV3/AuxLogits/Logits \
    --trainable_scopes=InceptionV3/Logits,InceptionV3/AuxLogits/Logits

cy@cy:~/PycharmProjects/models-master/slim/flowers-models$ tensorboard --logdir=./inception_v3
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcudnn.so.5 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.so.8.0 locally
Traceback (most recent call last):
  File ""/usr/local/bin/tensorboard"", line 7, in <module>
    from tensorflow.tensorboard.tensorboard import main
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/tensorboard/tensorboard.py"", line 34, in <module>
    from tensorflow.tensorboard.backend import server
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/tensorboard/backend/server.py"", line 38, in <module>
    from tensorflow.tensorboard.plugins.projector import plugin as projector_plugin
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/tensorboard/plugins/projector/plugin.py"", line 27, in <module>
    from tensorflow.contrib.tensorboard.plugins.projector import PROJECTOR_FILENAME
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/__init__.py"", line 29, in <module>
    from tensorflow.contrib import factorization
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/factorization/__init__.py"", line 24, in <module>
    from tensorflow.contrib.factorization.python.ops.gmm import *
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/factorization/python/ops/gmm.py"", line 32, in <module>
    from tensorflow.contrib.learn.python.learn import graph_actions
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/__init__.py"", line 83, in <module>
    from tensorflow.contrib.learn.python.learn import *
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/__init__.py"", line 23, in <module>
    from tensorflow.contrib.learn.python.learn import *
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/__init__.py"", line 25, in <module>
    from tensorflow.contrib.learn.python.learn import estimators
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/estimators/__init__.py"", line 310, in <module>
    from tensorflow.contrib.learn.python.learn.estimators.dnn import DNNClassifier
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/estimators/dnn.py"", line 29, in <module>
    from tensorflow.contrib.learn.python.learn.estimators import dnn_linear_combined
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/estimators/dnn_linear_combined.py"", line 33, in <module>
    from tensorflow.contrib.learn.python.learn.estimators import estimator
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py"", line 51, in <module>
    from tensorflow.contrib.learn.python.learn.learn_io import data_feeder
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/learn_io/__init__.py"", line 21, in <module>
    from tensorflow.contrib.learn.python.learn.learn_io.dask_io import extract_dask_data
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/learn_io/dask_io.py"", line 26, in <module>
    import dask.dataframe as dd
  File ""/home/cy/.local/lib/python3.5/site-packages/dask/dataframe/__init__.py"", line 3, in <module>
    from .core import (DataFrame, Series, Index, _Frame, map_partitions,
  File ""/home/cy/.local/lib/python3.5/site-packages/dask/dataframe/core.py"", line 11, in <module>
    import pandas as pd
  File ""/home/cy/.local/lib/python3.5/site-packages/pandas/__init__.py"", line 22, in <module>
    from pandas.compat.numpy import *
  File ""/home/cy/.local/lib/python3.5/site-packages/pandas/compat/__init__.py"", line 357, in <module>
    from dateutil import parser as _date_parser
  File ""/home/cy/.local/lib/python3.5/site-packages/dateutil/parser.py"", line 158
    l.append(""%s=%s"" % (attr, `value`))
                              ^
SyntaxError: invalid syntax
",andongchen,b'type:bug',2017-03-08T06:33:32Z,2017-07-18T03:20:03Z,,,,,,,
1072,Shape mismatch between predictions and labels in ResNet_v1_50,"## slim

I am trying to run the pretrained model for resnet_v1_50. 

It throws an error while defining metrics. Says there is shape mismatch between predictions and labels.

Here is the stack trace

INFO:tensorflow:Scale of 0 disables regularizer.
Traceback (most recent call last):
  File ""eval_image_classifier.py"", line 191, in <module>
    tf.app.run()
  File ""/home/sk6829/Work/TensorFlowCuda1/lib/python2.7/site-packages/tensorflow/python/platform/app.py"", line 44, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""eval_image_classifier.py"", line 155, in main
    'Accuracy': slim.metrics.streaming_accuracy(predictions, labels),
  File ""/home/sk6829/Work/TensorFlowCuda1/lib/python2.7/site-packages/tensorflow/contrib/metrics/python/ops/metric_ops.py"", line 490, in streaming_accuracy
    updates_collections=updates_collections, name=name)
  File ""/home/sk6829/Work/TensorFlowCuda1/lib/python2.7/site-packages/tensorflow/python/ops/metrics_impl.py"", line 326, in accuracy
    labels, predictions, weights=weights)
  File ""/home/sk6829/Work/TensorFlowCuda1/lib/python2.7/site-packages/tensorflow/python/ops/metrics_impl.py"", line 75, in _remove_squeezable_dimensions
    predictions.get_shape().assert_is_compatible_with(labels.get_shape())
  File ""/home/sk6829/Work/TensorFlowCuda1/lib/python2.7/site-packages/tensorflow/python/framework/tensor_shape.py"", line 756, in assert_is_compatible_with
    raise ValueError(""Shapes %s and %s are incompatible"" % (self, other))
ValueError: Shapes (100, 1, 10) and (100,) are incompatible


",salilkapur,b'type:bug',2017-02-25T23:07:04Z,2017-03-23T22:51:34Z,,,,,,,
1039,ptb example not working,"## models/tutorials/rnn/ptb/

When attempting to run the tut, there is the following error:

line 117, in ptb_producer
    [batch_size, (i + 1) * num_steps])
TypeError: strided_slice() missing 1 required positional argument: 'strides'

I'm running with python3, and adding strides=None does not help. Looks like this function cannot work without a stride specified.",nebgru,b'stat:awaiting response type:bug',2017-02-19T21:22:44Z,2017-02-20T11:54:48Z,,,,,,,
1038,inception_resnet_v2 fails to instantiate under Tensorflow 1.0,"The tf-slim implementation of inception-resnet-v2 (https://github.com/tensorflow/models/blob/master/slim/nets/inception_resnet_v2.py) fails to instantiate for me under TF 1.0.   I was able to fix this by installing TF 0.12.  I'm running tensorflow-gpu (both versions) under Ubuntu Server 16.04, using python3.

Apologies, since at the time I didn't think to save off the error message when I encountered it, and I've long since closed the SSH window and lost the buffer.  However, the last line of the error messages was identical to [this recent post](https://github.com/tensorflow/models/issues/987):

`TypeError: Expected int32, got list containing Tensors of type '_Message' instead.`

...which occurred in response to the following call:

`self.logits, self.end_points = inception_resnet_v2(scaled_input_tensor, is_training=False)`

If it can't be reproduced, I can install TF-1.0 again to catch the error trace.
",admcl,b'stat:awaiting response type:bug',2017-02-19T15:38:18Z,2017-02-21T17:07:36Z,,,,,,,
1037,im2txt: Why is the initial learning rate so high (2.0)?,Is it a bug or is it expected that high? https://github.com/tensorflow/models/blob/master/im2txt/im2txt/configuration.py#L93,danieljl,b'stat:awaiting model gardener type:bug',2017-02-19T03:56:24Z,2017-07-06T03:03:29Z,,,,,,,
1036,when i train resnet the program stuck,"python3.5 tf version 1.0 the program is stuck here
=========================Options=============================
-max_depth                  10000
-min_bytes                  0
-min_micros                 0
-min_params                 0
-min_float_ops              1
-device_regexes             .*
-order_by                   float_ops
-account_type_regexes       .*
-start_name_regexes         .*
-trim_name_regexes          
-show_name_regexes          .*
-hide_name_regexes          
-account_displayed_op_only  true
-select                     float_ops
-viz                        false
-dump_to_file               

==================Model Analysis Report======================
_TFProfRoot (0/17.63b flops)
  unit_2_1/sub2/conv2/Conv2D (603.98m/603.98m flops)
  unit_3_4/sub2/conv2/Conv2D (603.98m/603.98m flops)
  unit_3_4/sub1/conv1/Conv2D (603.98m/603.98m flops)
  unit_3_3/sub2/conv2/Conv2D (603.98m/603.98m flops)
  unit_3_3/sub1/conv1/Conv2D (603.98m/603.98m flops)
  unit_3_2/sub2/conv2/Conv2D (603.98m/603.98m flops)
  unit_3_2/sub1/conv1/Conv2D (603.98m/603.98m flops)
  unit_3_1/sub2/conv2/Conv2D (603.98m/603.98m flops)
  unit_3_1/sub1/conv1/Conv2D (603.98m/603.98m flops)
  unit_3_0/sub2/conv2/Conv2D (603.98m/603.98m flops)
  unit_2_4/sub2/conv2/Conv2D (603.98m/603.98m flops)
  unit_2_4/sub1/conv1/Conv2D (603.98m/603.98m flops)
  unit_2_3/sub2/conv2/Conv2D (603.98m/603.98m flops)
  unit_2_3/sub1/conv1/Conv2D (603.98m/603.98m flops)
  unit_2_2/sub2/conv2/Conv2D (603.98m/603.98m flops)
  unit_2_2/sub1/conv1/Conv2D (603.98m/603.98m flops)
  unit_2_1/sub1/conv1/Conv2D (603.98m/603.98m flops)
  unit_2_0/sub2/conv2/Conv2D (603.98m/603.98m flops)
  unit_1_0/sub1/conv1/Conv2D (603.98m/603.98m flops)
  unit_1_4/sub2/conv2/Conv2D (603.98m/603.98m flops)
  unit_1_4/sub1/conv1/Conv2D (603.98m/603.98m flops)
  unit_1_3/sub2/conv2/Conv2D (603.98m/603.98m flops)
  unit_1_3/sub1/conv1/Conv2D (603.98m/603.98m flops)
  unit_1_0/sub2/conv2/Conv2D (603.98m/603.98m flops)
  unit_1_2/sub2/conv2/Conv2D (603.98m/603.98m flops)
  unit_1_2/sub1/conv1/Conv2D (603.98m/603.98m flops)
  unit_1_1/sub2/conv2/Conv2D (603.98m/603.98m flops)
  unit_1_1/sub1/conv1/Conv2D (603.98m/603.98m flops)
  unit_3_0/sub1/conv1/Conv2D (301.99m/301.99m flops)
  unit_2_0/sub1/conv1/Conv2D (301.99m/301.99m flops)
  init/init_conv/Conv2D (113.25m/113.25m flops)
  logit/xw_plus_b (1.28k/165.12k flops)
    logit/xw_plus_b/MatMul (163.84k/163.84k flops)
  gradients/logit/xw_plus_b/MatMul_grad/MatMul_1 (163.84k/163.84k flops)
  gradients/logit/xw_plus_b/MatMul_grad/MatMul (163.84k/163.84k flops)

======================End of Report==========================
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE3 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:910] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
I tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with properties: 
name: GeForce GTX 1060 6GB
major: 6 minor: 1 memoryClockRate (GHz) 1.7845
pciBusID 0000:01:00.0
Total memory: 5.93GiB
Free memory: 5.12GiB
I tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0:   Y 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 6GB, pci bus id: 0000:01:00.0)


",andongchen,b'stat:awaiting response type:bug',2017-02-19T02:55:29Z,2017-03-11T02:43:56Z,,,,,,,
1030,No biases in inception_v4 checkpoint file,"Hi I'm trying to use the inception_v4 code and checkpoint file as a starting point for my model. I'm not using the slim scripts directly but am importing the inception network and using 

slim.assign_from_checkpoint_fn(
      model_path + ""inception_v4.ckpt"",
      weights,
      ignore_missing_vars=True)

Where weights are the network weights minus all the meta weights needed for adam optimizer. I'm getting a lot of:

WARNING:tensorflow:Variable InceptionV4/Mixed_6f/Branch_1/Conv2d_0a_1x1/biases missing in checkpoint

It's only for the biases. After inspecting the checkpoint file manually with tf.train.NewCheckpointReader I see that there aren't in fact any bias variables saved in the checkpoint file. Is this on purpose or am I missing something? Why would nets.inception_v4.inception_v4 create a network with biases that aren't saved in the checkpoint file. Any help appreciated!",lucaswiser,b'stat:community support type:bug',2017-02-17T23:04:07Z,2017-07-21T07:54:39Z,,,,,,,
1024,Computer Vision sample and tutorials don't work. These are official samples and need more attention.,"I'm trying to run tutorial sample and I get tons of errors

imagenet doesn't work, classify sample that uses pretrained imagenet doesn't work. 
mnist doesn't work

A lot of code outdated and not usable on current version of Tensorflow without adjustments.
The official samples are important for new users that are trying to learn Tensorflow It's bad that most of the code cannot be executed",AndreaFar,b'stat:awaiting response type:bug',2017-02-16T15:32:35Z,2017-03-03T23:41:05Z,,,,,,,
1022,TypeError: zeros_initializer() missing 1 required positional argument: 'shape' ,"inception model

What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?

None yet

Environment info

Operating System: ubuntu 14.04
python 3.4.3

If installed from binary pip package, provide:

A link to the pip package you installed: pip 7.1.2

The output from python -c ""import tensorflow; print(tensorflow.__version__)"".
0.12.1
If installed from source, provide

The commit hash (git rev-parse HEAD)

The output of bazel version
Build label: 0.4.3

If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)

What other attempted solutions have you tried?

Logs or other output that would be helpful

(If logs are large, please upload as attachment or provide link).


`Traceback (most recent call last): File ""/home/raj/FYP/FP4/models/inception/bazel-bin/inception/crops_train.runfiles/inception/inception/crops_train.py"", line 41, in <module> tf.app.run() File ""/home/raj/FYP/FP4/lib/python3.4/site-packages/tensorflow/python/platform/app.py"", line 43, in run sys.exit(main(sys.argv[:1] + flags_passthrough)) File ""/home/raj/FYP/FP4/models/inception/bazel-bin/inception/crops_train.runfiles/inception/inception/crops_train.py"", line 37, in main inception_train.train(dataset) File ""/home/raj/FYP/FP4/models/inception/bazel-bin/inception/crops_train.runfiles/inception/inception/inception_train.py"", line 241, in train scope, reuse_variables) File ""/home/raj/FYP/FP4/models/inception/bazel-bin/inception/crops_train.runfiles/inception/inception/inception_train.py"", line 109, in _tower_loss scope=scope) File ""/home/raj/FYP/FP4/models/inception/bazel-bin/inception/crops_train.runfiles/inception/inception/inception_model.py"", line 87, in inference scope=scope) File ""/home/raj/FYP/FP4/models/inception/bazel-bin/inception/crops_train.runfiles/inception/inception/slim/inception_model.py"", line 87, in inception_v3 scope='conv0') File ""/home/raj/FYP/FP4/models/inception/bazel-bin/inception/crops_train.runfiles/inception/inception/slim/scopes.py"", line 155, in func_with_args return func(*args, **current_args) File ""/home/raj/FYP/FP4/models/inception/bazel-bin/inception/crops_train.runfiles/inception/inception/slim/ops.py"", line 234, in conv2d outputs = batch_norm(conv, **batch_norm_params) File ""/home/raj/FYP/FP4/models/inception/bazel-bin/inception/crops_train.runfiles/inception/inception/slim/scopes.py"", line 155, in func_with_args return func(*args, **current_args) File ""/home/raj/FYP/FP4/models/inception/bazel-bin/inception/crops_train.runfiles/inception/inception/slim/ops.py"", line 88, in batch_norm initializer=tf.zeros_initializer(), TypeError: zeros_initializer() missing 1 required positional argument: 'shape'`

Working upon crops dataset with 38 classes , created tfrecords as asked of training and validation data. jpg files resized to 299x299. using flowers_train and flowers_data with edited num_examples and num_classes.Even the flowes dataset gave same error upon training.",rajmiglani,b'stat:awaiting response type:bug',2017-02-16T08:07:37Z,2017-03-19T06:16:08Z,,,,,,,
1021,Issue during debug of tensorflow,"
Hello,
I'm pretty new to tensorflow and python. If I try to run syntaxnet by command line it works well, but I have an issue when I try to debug it step by step with Eclipse or Spyder. I had same error: an issue on load a library (parser_ops.so). Someone should help me to understand what is the issue? 
I attach here the error log (generated by Spyder)

  File ""<ipython-input-2-c92123615836>"", line 1, in <module>
    debugfile('/home/erber/models/syntaxnet/bazel-bin/syntaxnet/parser_eval.runfiles/__main__/syntaxnet/parser_eval.py', wdir='/home/erber/models/syntaxnet/bazel-bin/syntaxnet/parser_eval.runfiles/__main__/syntaxnet')

  File ""/usr/lib/python2.7/dist-packages/spyderlib/widgets/externalshell/sitecustomize.py"", line 719, in debugfile
    debugger.run(""runfile(%r, args=%r, wdir=%r)"" % (filename, args, wdir))

  File ""/usr/lib/python2.7/bdb.py"", line 400, in run
    exec cmd in globals, locals

  File ""<string>"", line 1, in <module>

  File ""/usr/lib/python2.7/dist-packages/spyderlib/widgets/externalshell/sitecustomize.py"", line 699, in runfile
    execfile(filename, namespace)

  File ""/usr/lib/python2.7/dist-packages/spyderlib/widgets/externalshell/sitecustomize.py"", line 81, in execfile
    builtins.execfile(filename, *where)

  File ""/home/erber/models/syntaxnet/bazel-bin/syntaxnet/parser_eval.runfiles/__main__/syntaxnet/parser_eval.py"", line 31, in <module>
    import graph_builder

  File ""graph_builder.py"", line 22, in <module>
    import load_parser_ops

  File ""load_parser_ops.py"", line 25, in <module>
    'parser_ops.so'))

  File ""/home/erber/.local/lib/python2.7/site-packages/tensorflow/python/framework/load_library.py"", line 64, in load_op_library
    None, None, error_msg, error_code)

NotFoundError: parser_ops.so: cannot open shared object file: No such file or directory

thank you very much for any help!
",EnricoBeltramo,b'stat:awaiting model gardener type:bug',2017-02-15T23:29:26Z,2018-02-08T00:24:52Z,,,,,,,
1020,Slim.learning.train  error when model train too fast,"I follow step in slim_walkthoungh.ipynb and get error. I gess when train model too fast then elapsed_time equal zero

`Layers
name = deep_regression/fc2/Relu:0, shape = (?, 16)
name = deep_regression/fc1/Relu:0, shape = (?, 32)
name = deep_regression/prediction/BiasAdd:0, shape = (?, 1)


Parameters
name = deep_regression/fc1/weights:0, shape = (1, 32)
name = deep_regression/fc1/biases:0, shape = (32,)
name = deep_regression/fc2/weights:0, shape = (32, 16)
name = deep_regression/fc2/biases:0, shape = (16,)
name = deep_regression/prediction/weights:0, shape = (16, 1)
name = deep_regression/prediction/biases:0, shape = (1,)
WARNING:tensorflow:From D:\ML Learning\python_env\lib\site-packages\tensorflow\python\training\supervisor.py:344 in __init__.: SummaryWriter.__init__ (from tensorflow.python.training.summary_io) is deprecated and will be removed after 2016-11-30.
Instructions for updating:
Please switch to tf.summary.FileWriter. The interface and behavior is the same; this is just a rename.
INFO:tensorflow:Starting Session.
INFO:tensorflow:Starting Queues.
INFO:tensorflow:Error reported to Coordinator: <class 'ZeroDivisionError'>, float division by zero
INFO:tensorflow:Stopping Training.
INFO:tensorflow:Finished training! Saving model to disk.
Traceback (most recent call last):
  File ""D:/ML Learning/workspace/mnistclass/model.py"", line 117, in <module>
    log_every_n_steps=50)
  File ""D:\ML Learning\python_env\lib\site-packages\tensorflow\contrib\slim\python\slim\learning.py"", line 793, in train
    raise
  File ""D:\ML Learning\python_env\lib\contextlib.py"", line 66, in __exit__
    next(self.gen)
  File ""D:\ML Learning\python_env\lib\site-packages\tensorflow\python\training\supervisor.py"", line 974, in managed_session
    self.stop(close_summary_writer=close_summary_writer)
  File ""D:\ML Learning\python_env\lib\site-packages\tensorflow\python\training\supervisor.py"", line 802, in stop
    stop_grace_period_secs=self._stop_grace_secs)
  File ""D:\ML Learning\python_env\lib\site-packages\tensorflow\python\training\coordinator.py"", line 386, in join
    six.reraise(*self._exc_info_to_raise)
  File ""D:\ML Learning\python_env\lib\site-packages\six.py"", line 686, in reraise
    raise value
  File ""D:\ML Learning\python_env\lib\site-packages\tensorflow\python\training\coordinator.py"", line 296, in stop_on_exception
    yield
  File ""D:\ML Learning\python_env\lib\site-packages\tensorflow\python\training\coordinator.py"", line 487, in run
    self.run_loop()
  File ""D:\ML Learning\python_env\lib\site-packages\tensorflow\python\training\supervisor.py"", line 1044, in run_loop
    steps_per_sec = added_steps / elapsed_time
ZeroDivisionError: float division by zero`",nguyenvulebinh,b'type:bug',2017-02-15T08:11:20Z,2017-02-15T18:23:16Z,,,,,,,
1005,Suggestions for autoencoder,"## Please let us know which model this issue is about (specify the top-level directory) autoencoder

In _models/autoencoder/AdditiveGaussianNoiseAutoencoderRunner.py_ 
Changing 
```
    # Display logs per epoch step
    if epoch % display_step == 0:
        print ""Epoch:"", '%04d' % (epoch + 1), \
            ""cost="", ""{:.9f}"".format(avg_cost)

print ""Total cost: "" + str(autoencoder.calc_total_cost(X_test))
```
to 
```
    # Display logs per epoch step
    if epoch % display_step == 0:
        print(""Epoch:"", '%04d' % (epoch + 1), \
            ""cost="", ""{:.9f}"".format(avg_cost))

print(""Total cost: "" + str(autoencoder.calc_total_cost(X_test)))
```
Also for _models/autoencoder/AutoencoderRunner.py_ ,  _MaskingNoiseAutoencoderRunner.py_ and  _VariationalAutoencoderRunner.py_",linrio,b'help wanted type:bug',2017-02-10T13:44:57Z,2018-02-22T19:34:06Z,,,,,,,
987,"inception: ""TypeError: Expected int32, got list containing Tensors of type '_Message' instead.""","Steps to reproduce: follow the inception tutorial with TensorFlow 0.12.head installed.

When running training from scratch, I get:

```
$ bazel-bin/inception/imagenet_train --num_gpus=1 --batch_size=32 --train_dir=/tmp/imagenet_train --data_dir=/work/user/data/imagenet
I tensorflow/stream_executor/dso_loader.cc:125] successfully opened CUDA library libcublas.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:125] successfully opened CUDA library libcudnn.so.5 locally
I tensorflow/stream_executor/dso_loader.cc:125] successfully opened CUDA library libcufft.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:125] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:125] successfully opened CUDA library libcurand.so.8.0 locally
Traceback (most recent call last):
  File ""/usr/wiss/user/libs/tfmodels/inception/bazel-bin/inception/imagenet_train.runfiles/inception/inception/imagenet_train.py"", line 41, in <module>
    tf.app.run()
  File ""/usr/wiss/user/.local/lib/python2.7/site-packages/tensorflow/python/platform/app.py"", line 44, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""/usr/wiss/user/libs/tfmodels/inception/bazel-bin/inception/imagenet_train.runfiles/inception/inception/imagenet_train.py"", line 37, in main
    inception_train.train(dataset)
  File ""/usr/wiss/user/libs/tfmodels/inception/bazel-bin/inception/imagenet_train.runfiles/inception/inception/inception_train.py"", line 217, in train
    num_preprocess_threads=num_preprocess_threads)
  File ""/usr/wiss/user/libs/tfmodels/inception/bazel-bin/inception/imagenet_train.runfiles/inception/inception/image_processing.py"", line 136, in distorted_inputs
    num_readers=FLAGS.num_readers)
  File ""/usr/wiss/user/libs/tfmodels/inception/bazel-bin/inception/imagenet_train.runfiles/inception/inception/image_processing.py"", line 490, in batch_inputs
    example_serialized)
  File ""/usr/wiss/user/libs/tfmodels/inception/bazel-bin/inception/imagenet_train.runfiles/inception/inception/image_processing.py"", line 397, in parse_example_proto
    bbox = tf.concat(0, [ymin, xmin, ymax, xmax])
  File ""/usr/wiss/user/.local/lib/python2.7/site-packages/tensorflow/python/ops/array_ops.py"", line 1248, in concat
    dtype=dtypes.int32).get_shape(
  File ""/usr/wiss/user/.local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 651, in convert_to_tensor
    as_ref=False)
  File ""/usr/wiss/user/.local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 716, in internal_convert_to_tensor
    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
  File ""/usr/wiss/user/.local/lib/python2.7/site-packages/tensorflow/python/framework/constant_op.py"", line 176, in _constant_tensor_conversion_function
    return constant(v, dtype=dtype, name=name)
  File ""/usr/wiss/user/.local/lib/python2.7/site-packages/tensorflow/python/framework/constant_op.py"", line 165, in constant
    tensor_util.make_tensor_proto(value, dtype=dtype, shape=shape, verify_shape=verify_shape))
  File ""/usr/wiss/user/.local/lib/python2.7/site-packages/tensorflow/python/framework/tensor_util.py"", line 367, in make_tensor_proto
    _AssertCompatible(values, dtype)
  File ""/usr/wiss/user/.local/lib/python2.7/site-packages/tensorflow/python/framework/tensor_util.py"", line 302, in _AssertCompatible
    (dtype.name, repr(mismatch), type(mismatch).__name__))
TypeError: Expected int32, got list containing Tensors of type '_Message' instead.

```

The problem is that some examples don't provide bounding boxes. In that case, xmin etc are all `[]` in which case concat fails.",haeusser,b'type:bug',2017-02-06T15:13:01Z,2017-03-23T22:49:57Z,,,,,,,
952,Incpetion flowers fine-tune taking too long,"I know this is probably not the place to ask this but since I need the but I hope someone here has already tried fine-tuning the inception model.

I am running the inception fine-tuning flowers example. Its been well over 5 days now and I'm just went past the 150,000 step.

How many steps does it take to fine-tune the flowers model?",redserpent7,b'stat:community support type:bug type:support',2017-01-25T14:01:30Z,2018-02-08T00:19:56Z,,,,,,,
950,Fine-tune Inception V3 with Tensorflow 0.12.1 failed,"Fine-tune Inception V3 with Tensorflow 0.12.1 failed.
```
Traceback (most recent call last):
  File ""train_image_classifier.py"", line 585, in <module>
    tf.app.run()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 44, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""train_image_classifier.py"", line 448, in main
    image = image_preprocessing_fn(image, train_image_size, train_image_size)
  File ""/home/ylzhao/project/tensorflow-models/slim/preprocessing/preprocessing_factory.py"", line 70, in preprocessing_fn
    image, output_height, output_width, is_training=is_training, **kwargs)
  File ""/home/ylzhao/project/tensorflow-models/slim/preprocessing/inception_preprocessing.py"", line 302, in preprocess_image
    return preprocess_for_train(image, height, width, bbox, fast_mode)
  File ""/home/ylzhao/project/tensorflow-models/slim/preprocessing/inception_preprocessing.py"", line 195, in preprocess_for_train
    tf.image_summary('image_with_bounding_boxes', image_with_box)
AttributeError: 'module' object has no attribute 'image_summary'
```
```
Traceback (most recent call last):
  File ""eval_image_classifier.py"", line 191, in <module>
    tf.app.run()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 44, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""eval_image_classifier.py"", line 128, in main
    image = image_preprocessing_fn(image, eval_image_size, eval_image_size)
  File ""/home/ylzhao/project/tensorflow-models/slim/preprocessing/preprocessing_factory.py"", line 70, in preprocessing_fn
    image, output_height, output_width, is_training=is_training, **kwargs)
  File ""/home/ylzhao/project/tensorflow-models/slim/preprocessing/inception_preprocessing.py"", line 304, in preprocess_image
    return preprocess_for_eval(image, height, width)
  File ""/home/ylzhao/project/tensorflow-models/slim/preprocessing/inception_preprocessing.py"", line 273, in preprocess_for_eval
    image = tf.sub(image, 0.5)
AttributeError: 'module' object has no attribute 'sub'
```
```
Traceback (most recent call last):
  File ""eval_image_classifier.py"", line 191, in <module>
    tf.app.run()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 44, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""eval_image_classifier.py"", line 128, in main
    image = image_preprocessing_fn(image, eval_image_size, eval_image_size)
  File ""/home/ylzhao/project/tensorflow-models/slim/preprocessing/preprocessing_factory.py"", line 70, in preprocessing_fn
    image, output_height, output_width, is_training=is_training, **kwargs)
  File ""/home/ylzhao/project/tensorflow-models/slim/preprocessing/inception_preprocessing.py"", line 304, in preprocess_image
    return preprocess_for_eval(image, height, width)
  File ""/home/ylzhao/project/tensorflow-models/slim/preprocessing/inception_preprocessing.py"", line 274, in preprocess_for_eval
    image = tf.mul(image, 2.0)
AttributeError: 'module' object has no attribute 'mul'
```
```
Traceback (most recent call last):
  File ""eval_image_classifier.py"", line 191, in <module>
    tf.app.run()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 44, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""eval_image_classifier.py"", line 139, in main
    logits, _ = network_fn(images)
  File ""/home/ylzhao/project/models/slim/nets/nets_factory.py"", line 105, in network_fn
    return func(images, num_classes, is_training=is_training)
  File ""/home/ylzhao/project/models/slim/nets/inception_v3.py"", line 481, in inception_v3
    depth_multiplier=depth_multiplier)
  File ""/home/ylzhao/project/models/slim/nets/inception_v3.py"", line 161, in inception_v3_base
    net = tf.concat(3, [branch_0, branch_1, branch_2, branch_3])
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/array_ops.py"", line 1053, in concat
    dtype=dtypes.int32).get_shape(
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 651, in convert_to_tensor
    as_ref=False)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 716, in internal_convert_to_tensor
    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/constant_op.py"", line 176, in _constant_tensor_conversion_function
    return constant(v, dtype=dtype, name=name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/constant_op.py"", line 165, in constant
    tensor_util.make_tensor_proto(value, dtype=dtype, shape=shape, verify_shape=verify_shape))
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/tensor_util.py"", line 367, in make_tensor_proto
    _AssertCompatible(values, dtype)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/tensor_util.py"", line 302, in _AssertCompatible
    (dtype.name, repr(mismatch), type(mismatch).__name__))
TypeError: Expected int32, got list containing Tensors of type '_Message' instead.
```",panovr,b'type:bug',2017-01-25T03:05:00Z,2017-03-23T22:50:28Z,,,,,,,
923,Civar10_train & Cifar10_multi_gpu_train won't run: TypeError: strided_slice() missing 1 required positional argument: 'strides',"I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\stream_executor\dso_loader.cc:128] successfully opened CUDA library cublas64_80.dll locally
I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\stream_executor\dso_loader.cc:128] successfully opened CUDA library cudnn64_5.dll locally
I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\stream_executor\dso_loader.cc:128] successfully opened CUDA library cufft64_80.dll locally
I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\stream_executor\dso_loader.cc:128] successfully opened CUDA library nvcuda.dll locally
I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\stream_executor\dso_loader.cc:128] successfully opened CUDA library curand64_80.dll locally
Traceback (most recent call last):
  File ""C:/Users/TH/PycharmProjects/TensorflowTest/cifar10_3/cifar10_train.py"", line 120, in <module>
    tf.app.run()
  File ""C:\Program Files\Python35\lib\site-packages\tensorflow\python\platform\app.py"", line 43, in run
    sys.exit(main(sys.argv[:1] + flags_passthrough))
  File ""C:/Users/TH/PycharmProjects/TensorflowTest/cifar10_3/cifar10_train.py"", line 116, in main
    train()
  File ""C:/Users/TH/PycharmProjects/TensorflowTest/cifar10_3/cifar10_train.py"", line 63, in train
    images, labels = cifar10.distorted_inputs()
  File ""C:\Users\TH\PycharmProjects\TensorflowTest\cifar10_3\cifar10.py"", line 156, in distorted_inputs
    batch_size=FLAGS.batch_size)
  File ""C:\Users\TH\PycharmProjects\TensorflowTest\cifar10_3\cifar10_input.py"", line 161, in distorted_inputs
    read_input = read_cifar10(filename_queue)
  File ""C:\Users\TH\PycharmProjects\TensorflowTest\cifar10_3\cifar10_input.py"", line 87, in read_cifar10
    tf.strided_slice(record_bytes, [0], [label_bytes]), tf.int32)
TypeError: strided_slice() missing 1 required positional argument: 'strides'",ghost,b'type:bug',2017-01-19T08:58:29Z,2017-01-23T21:28:14Z,,,,,,,
910,seek() takes exactly 2 arguments (3 given),"## Please let us know which model this issue is about (specify the top-level directory)
In the models/differential_privacy/multiple_teachers I have run this line:

python train_teachers.py --nb_teachers=100 --teacher_id=10 --dataset=mnist --max_steps=300

It ran but when I try and run this line or rerun the previous line:

python train_student.py --nb_teachers=100 --dataset=mnist --stdnt_share=5000

I get the error in the subject line.  If I delete the /tmp files I can rerun the first line again but I can't run the second line.  The problem (I think) is that that in input.py this function is called for both commands:

def extract_mnist_data(filename, num_images, image_size, pixel_depth):
  """"""
  Extract the images into a 4D tensor [image index, y, x, channels].

  Values are rescaled from [0, 255] down to [-0.5, 0.5].
  """"""
  # if not os.path.exists(file):
  if not tf.gfile.Exists(filename+"".npy""):
    with gzip.open(filename) as bytestream:
      bytestream.read(16)
      buf = bytestream.read(image_size * image_size * num_images)
      data = np.frombuffer(buf, dtype=np.uint8).astype(np.float32)
      data = (data - (pixel_depth / 2.0)) / pixel_depth
      data = data.reshape(num_images, image_size, image_size, 1)
      np.save(filename, data)
      return data
  else:
    with tf.gfile.Open(filename+"".npy"", mode='r') as file_obj:
      return np.load(file_obj)

The first time I call train_teachers, the top part of the if runs.  When I call the train_students, the bottom part runs and blows up.  

",j2cunningham,b'stat:awaiting model gardener type:bug',2017-01-16T19:39:06Z,2017-04-13T00:56:09Z,,,,,,,
901,cifar10_multi_gpu_train.py,"I just used git to download the codes, and tensorflow was installed from nightly build. Then I compiled tensorflow from source.
```
# python cifar10_multi_gpu_train.py --num_gpus=4
I tensorflow/stream_executor/dso_loader.cc:125] successfully opened CUDA library libcublas.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:125] successfully opened CUDA library libcudnn.so.5 locally
I tensorflow/stream_executor/dso_loader.cc:125] successfully opened CUDA library libcufft.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:125] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:125] successfully opened CUDA library libcurand.so.8.0 locally
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
WARNING:tensorflow:From /home/***/Downloads/models/tutorials/image/cifar10/cifar10_input.py:135: image_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.
Instructions for updating:
Please switch to tf.summary.image. Note that tf.summary.image uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, the max_images argument was renamed to max_outputs.
Traceback (most recent call last):
  File ""cifar10_multi_gpu_train.py"", line 273, in <module>
    tf.app.run()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 44, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""cifar10_multi_gpu_train.py"", line 269, in main
    train()
  File ""cifar10_multi_gpu_train.py"", line 171, in train
    loss = tower_loss(scope)
  File ""cifar10_multi_gpu_train.py"", line 78, in tower_loss
    logits = cifar10.inference(images)
  File ""/home/***/Downloads/models/tutorials/image/cifar10/cifar10.py"", line 207, in inference
    wd=0.0)
  File ""/home/***/Downloads/models/tutorials/image/cifar10/cifar10.py"", line 137, in _variable_with_weight_decay
    weight_decay = tf.mul(tf.nn.l2_loss(var), wd, name='weight_loss')
AttributeError: 'module' object has no attribute 'mul'
```",weigei123,b'help wanted type:bug',2017-01-14T20:21:29Z,2017-01-17T14:39:16Z,,,,,,,
893,cifar10_eval.py issue: cannot infer Tensor's rank,"I ran a unmodified version of cifar10_eval.py, here is the error message

Traceback (most recent call last):
  File ""cifar10_eval.py"", line 157, in <module>
    tf.app.run()
  File ""/home/zhisong/tensorflow/tensorflow/python/platform/app.py"", line 44, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""cifar10_eval.py"", line 153, in main
    evaluate()
  File ""cifar10_eval.py"", line 121, in evaluate
    images, labels = cifar10.inputs(eval_data=eval_data)
  File ""/home/zhisong/tensorflow/models/tutorials/image/cifar10/cifar10.py"", line 183, in inputs
    batch_size=FLAGS.batch_size)
  File ""/home/zhisong/tensorflow/models/tutorials/image/cifar10/cifar10_input.py"", line 257, in inputs
    shuffle=False)
  File ""/home/zhisong/tensorflow/models/tutorials/image/cifar10/cifar10_input.py"", line 132, in _generate_image_and_label_batch
    capacity=min_queue_examples + 3 * batch_size)
  File ""/home/zhisong/tensorflow/tensorflow/python/training/input.py"", line 872, in batch
    name=name)
  File ""/home/zhisong/tensorflow/tensorflow/python/training/input.py"", line 655, in _batch
    shapes = _shapes([tensor_list], shapes, enqueue_many)
  File ""/home/zhisong/tensorflow/tensorflow/python/training/input.py"", line 598, in _shapes
    raise ValueError(""Cannot infer Tensor's rank: %s"" % tl[i])
ValueError: Cannot infer Tensor's rank: Tensor(""Cast:0"", dtype=int32)

By comparing to distorted_inputs() in cifar10_input.py, I suspect the following lines are missing in inputs()

float_image.set_shape([height, width, 3])
read_input.label.set_shape([1])

After adding the above two lines, the script works just fine",zhisong,b'type:bug',2017-01-13T04:17:31Z,2017-01-13T23:17:47Z,,,,,,,
892,cifar10_eval issues - tensorflow 0.12,"## tensorflow/models/tutorial/image/cifar10/cifar10_eval.py

When I run cifar10_eval.py alongside the cifar10_train.py script in tensorflow 0.12, it crashes the main training script with the error: 

Out of range: RandomShuffleQueue '_2_shuffle_batch/random_shuffle_queue' is closed and has insufficient elements (requested 128, current size 46)

It does this on both the gpu training code and the cpu code - but this doesn't happen using tensorflow 0.11.  Any ideas?

",al3xsh,b'type:bug',2017-01-12T12:58:27Z,2017-06-28T08:30:33Z,,,,,,,
859,setting max number of iterations in inception doesn't work!,"While training the inception model, I've set the maximum number of iterations to some small number. In some random runs, the fastest worker would break from the training loop, but the other workers suddenly stuck with no progression. As a result the parameter servers and some of the workers stalls and the training phase never finishes.

I'm training using TensorFlow r.012, using Nvidia K40 on a cluster of machines.

Here is the piece of code responsible for breaking out of loop after certain iterations(Code reside in inception_distributed_train.py):

```
      while not sv.should_stop():
        try:
          start_time = time.time()
          loss_value, step = sess.run([train_op, global_step])
          assert not np.isnan(loss_value), 'Model diverged with loss = NaN'
          if step > FLAGS.max_steps:
            break
          duration = time.time() - start_time

          if step % 30 == 0:
            examples_per_sec = FLAGS.batch_size / float(duration)
            format_str = ('Worker %d: %s: step %d, loss = %.2f'
                          '(%.1f examples/sec; %.3f  sec/batch)')
            tf.logging.info(format_str %
                            (FLAGS.task_id, datetime.now(), step, loss_value,
                             examples_per_sec, duration))

          # Determine if the summary_op should be run on the chief worker.
          if is_chief and next_summary_time < time.time():
            tf.logging.info('Running Summary operation on the chief.')
            summary_str = sess.run(summary_op)
            sv.summary_computed(sess, summary_str)
            tf.logging.info('Finished running Summary operation.')

            # Determine the next time for running the summary.
            next_summary_time += FLAGS.save_summaries_secs
        except:
          if is_chief:
            tf.logging.info('About to execute sync_clean_up_op!')
            sess.run(clean_up_op)
          raise

      # Stop the supervisor.  This also waits for service threads to finish.
      sv.stop()

```

Is it a normal behavior or an anomaly in the code?",saman-aghazadeh,b'type:bug',2017-01-06T23:23:54Z,2018-02-22T19:29:56Z,,,,,,,
857,Isuue with models/tutorials/image/mnist,"The MNIST example seems to have problem in running with Tensorflow:
Hi, I am completely new in TensorFlow. I just built TensorFlow and tried to run models/tutorials/image/imagenet/classify_image.py and it ran. But when I tried MNIST, I found the following error:

abhishek@phoebusdev:~/Documents/Works/models/tutorials/image/mnist$ python convolutional.py --self-test
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz
Traceback (most recent call last):
  File ""convolutional.py"", line 339, in <module>
    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 44, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""convolutional.py"", line 231, in main
    logits, train_labels_node))
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/nn_ops.py"", line 1685, in sparse_softmax_cross_entropy_with_logits
    labels, logits)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/nn_ops.py"", line 1534, in _ensure_xent_args
    ""named arguments (labels=..., logits=..., ...)"" % name)
ValueError: Only call `sparse_softmax_cross_entropy_with_logits` with named arguments (labels=..., logits=..., ...)

Am I doing anything wrong?
",abdasgupta,b'stat:awaiting response type:bug',2017-01-06T06:17:03Z,2019-06-30T03:34:53Z,,,,,,,
840,Inception / imagenet_train fails with python2.7,"I am trying to train Inception CNN using imagenet in python2.7 but it is failing.

Command run:
```
bazel-bin/inception/imagenet_train --num_gpus=4 --batch_size=32 --train_dir=/tmp/imagenet_train-yo/ --data_dir=/root/host_mount/datasets/imagenet/imagenet-data
```
Log:
```
Traceback (most recent call last):
  File ""/root/host_mount/code/models/inception/bazel-bin/inception/imagenet_train.runfiles/inception/inception/imagenet_train.py"", line 41, in <module>
    tf.app.run()
  File ""/root/tensorflow-py2/local/lib/python2.7/site-packages/tensorflow/python/platform/app.py"", line 43, in run
    sys.exit(main(sys.argv[:1] + flags_passthrough))
  File ""/root/host_mount/code/models/inception/bazel-bin/inception/imagenet_train.runfiles/inception/inception/imagenet_train.py"", line 37, in main
    inception_train.train(dataset)
  File ""/root/host_mount/code/models/inception/bazel-bin/inception/imagenet_train.runfiles/inception/inception/inception_train.py"", line 239, in train
    scope)
  File ""/root/host_mount/code/models/inception/bazel-bin/inception/imagenet_train.runfiles/inception/inception/inception_train.py"", line 124, in _tower_loss
    loss_averages_op = loss_averages.apply(losses + [total_loss])
  File ""/root/tensorflow-py2/local/lib/python2.7/site-packages/tensorflow/python/training/moving_averages.py"", line 391, in apply
    self._averages[var], var, decay, zero_debias=zero_debias))
  File ""/root/tensorflow-py2/local/lib/python2.7/site-packages/tensorflow/python/training/moving_averages.py"", line 70, in assign_moving_average
    update_delta = _zero_debias(variable, value, decay)
  File ""/root/tensorflow-py2/local/lib/python2.7/site-packages/tensorflow/python/training/moving_averages.py"", line 177, in _zero_debias
    trainable=False)
  File ""/root/tensorflow-py2/local/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py"", line 1024, in get_variable
    custom_getter=custom_getter)
  File ""/root/tensorflow-py2/local/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py"", line 850, in get_variable
    custom_getter=custom_getter)
  File ""/root/tensorflow-py2/local/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py"", line 346, in get_variable
    validate_shape=validate_shape)
  File ""/root/tensorflow-py2/local/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py"", line 331, in _true_getter
    caching_device=caching_device, validate_shape=validate_shape)
  File ""/root/tensorflow-py2/local/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py"", line 650, in _get_single_variable
    ""VarScope?"" % name)
ValueError: Variable tower_1/tower_1/CrossEntropyLoss/value/avg/biased does not exist, or was not created with tf.get_variable(). Did you mean to set reuse=None in VarScope?
```
Other Info:
```
python -c ""import tensorflow; print(tensorflow.__version__)""
0.12.1

git rev-parse HEAD
bfa1bb1bf52c4b8eabf7c1766e65dcb04164f778

bazel version
Build label: 0.3.2
Build target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Fri Oct 7 17:25:10 2016 (1475861110)
Build timestamp: 1475861110
Build timestamp as int: 1475861110
```",yogeshg,b'type:bug',2017-01-02T22:36:46Z,2017-03-23T22:50:51Z,,,,,,,
839,im2txt Caption class comparison fails in Python 3.5,"## models/im2txt 

### Caption class comparison fails in Python 3.5 because Python 2's __cmp__ is deprecated in 3+

@cshallue 

I was trying to run #466 on Python 3.5 and I was getting the following error:

> Traceback (most recent call last):
>   File ""test.py"", line 84, in <module>
>     tf.app.run()
>   File ""/data/venvs/tensorflow/lib/python3.5/site-packages/tensorflow/python/platform/app.py"", line 43, in run
>     sys.exit(main(sys.argv[:1] + flags_passthrough))
>   File ""test.py"", line 74, in main
>     captions = generator.beam_search(sess, image)
>   File ""/media/scott/BigHD/Code/tensorflow_ex/im2txt/inference_utils/caption_generator.py"", line 193, in beam_search
>     partial_captions.push(beam)
>   File ""/media/scott/BigHD/Code/tensorflow_ex/im2txt/inference_utils/caption_generator.py"", line 77, in push
>     heapq.heappush(self._data, x)
> TypeError: unorderable types: Caption() < Caption()

The Caption class only implements __cmp__, but needs __lt__ and __eq__ for Python 3. It's a simple addition that would help compatibility between the versions. I'm not sure if you're planning on supporting Python 3, but everything else worked out of the box except this when I ran the run_inference.py file from the repo.

",srome,b'type:bug',2017-01-02T18:46:11Z,2017-01-27T17:52:38Z,,,,,,,
836,tutorials/rnn/translate Matrix multiplication error,"**tensorflow/models/tutorials/rnn/translate/seq2seq_model.py**

Hello everyone, 

When I ran the translate model, I encountered the following issue:

File ""translate.py"", line 294, in main
    train()
  File ""translate.py"", line 153, in train
    model = create_model(sess, False)
  File ""translate.py"", line 132, in create_model
    dtype=dtype)
  File ""/Users/richard_xiong/Documents/DeepLearningMaster/RNN/seq2seq_model.py"", line 181, in __init__
    softmax_loss_function=softmax_loss_function)
  File ""/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/tensorflow/python/ops/seq2seq.py"", line 1130, in model_with_buckets
    softmax_loss_function=softmax_loss_function))
  File ""/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/tensorflow/python/ops/seq2seq.py"", line 1058, in sequence_loss
    softmax_loss_function=softmax_loss_function))
  File ""/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/tensorflow/python/ops/seq2seq.py"", line 1022, in sequence_loss_by_example
    crossent = softmax_loss_function(logit, target)
  File ""/Users/richard_xiong/Documents/DeepLearningMaster/RNN/seq2seq_model.py"", line 117, in sampled_loss
    num_classes=self.target_vocab_size),
  File ""/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/tensorflow/python/ops/nn.py"", line 1412, in sampled_softmax_loss
    name=name)
  File ""/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/tensorflow/python/ops/nn.py"", line 1219, in _compute_sampled_logits
    inputs, sampled_w, transpose_b=True) + sampled_b
  File ""/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/tensorflow/python/ops/math_ops.py"", line 1729, in matmul
    a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)
  File ""/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/tensorflow/python/ops/gen_math_ops.py"", line 1442, in _mat_mul
    transpose_b=transpose_b, name=name)
  File ""/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py"", line 759, in apply_op
    op_def=op_def)
  File ""/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 2242, in create_op
    set_shapes_for_outputs(ret)
  File ""/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 1617, in set_shapes_for_outputs
    shapes = shape_func(op)
  File ""/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 1568, in call_with_requiring
    return call_cpp_shape_fn(op, require_shape_fn=True)
  File ""/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/tensorflow/python/framework/common_shapes.py"", line 610, in call_cpp_shape_fn
    debug_python_shape_fn, require_shape_fn)
  File ""/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/tensorflow/python/framework/common_shapes.py"", line 675, in _call_cpp_shape_fn_impl
    raise ValueError(err.message)
**ValueError**: Shape must be rank 2 but is rank 1 for 'model_with_buckets/sequence_loss/sequence_loss_by_example/sampled_softmax_loss/MatMul_1' (op: 'MatMul') with input shapes: [?], [?,1024].

It seems it's the intrinsic matrix multiplication error in the function 'tf.nn.seq2seq.model_with_buckets()'

Does anyone have any ideas? Thank you!",richardxiong,b'type:bug',2017-01-01T22:33:27Z,2017-03-30T19:25:32Z,,,,,,,
828,Two root nodes for one sentence,"I trying to process next sentence: ""/ / Россия в глобальной политике ."" with model Russian-SynTagRus.

```
echo ""/ / Россия в глобальной политике ."" | syntaxnet/models/parsey_universal/parse.sh /home/tensor/tensorflow/Russian-SynTagRus
```

And I have in result two root nodes (see first and sixth word). I think it is not ok, because it is not tree:

```
1	/	_	PUNCT	/	fPOS=PUNCT++/	0	ROOT	_	_
2	/	_	PUNCT	/	fPOS=PUNCT++/	3	punct	_	_
3	Россия	_	NOUN	_	Animacy=Inan|Case=Nom|Gender=Fem|Number=Sing|fPOS=NOUN++	6	nsubj	_	_
4	в	_	ADP	_	fPOS=ADP++	6	case	_	_
5	глобальной	_	ADJ	_	Case=Loc|Degree=Pos|Gender=Fem|Number=Sing|fPOS=ADJ++	6	amod	_	_
6	политике	_	NOUN	_	Animacy=Inan|Case=Loc|Gender=Fem|Number=Sing|fPOS=NOUN++	0	ROOT	_	_
7	.	_	PUNCT	.	fPOS=PUNCT++.	6	punct	_	_
```",mnvx,b'type:bug',2016-12-29T09:00:31Z,2018-02-22T19:24:15Z,,,,,,,
827,_bytes_feature(encoded_image) will throw an exception,"## Please let us know which model this issue is about (specify the top-level directory)
When I using ptyhon3.5.2 to run script build_mscoco_data,there will throw an exception in line
```

 context = tf.train.Features(feature={
      ""image/image_id"": _int64_feature(image.image_id),
      ""image/data"": _bytes_feature(encoded_image),
  })
```

the debug info before this has no warning,error and exception 

```
Loaded caption metadata for 200 images from /Users/apple1/Desktop/im2txt_new/im2txt/im2txt/data/raw-data/annotations/captions_train2014.json
Proccessing captions.
Finished processing 1000 captions for 200 images in /Users/apple1/Desktop/im2txt_new/im2txt/im2txt/data/raw-data/annotations/captions_train2014.json
Loaded caption metadata for 50 images from /Users/apple1/Desktop/im2txt_new/im2txt/im2txt/data/raw-data/annotations/captions_val2014.json
Proccessing captions.
Finished processing 250 captions for 50 images in /Users/apple1/Desktop/im2txt_new/im2txt/im2txt/data/raw-data/annotations/captions_val2014.json
Creating vocabulary.
Total words: 1601
Words in vocabulary: 463
Wrote vocabulary file: /tmp/word_counts.txt
Launching 8 threads for spacings: [[0, 151], [151, 302], [302, 453], [453, 605], [605, 756], [756, 907], [907, 1058], [1058, 1210]]
```
I only use 200 train images and 50 val images to test, I have processed two json files, captions and images all paired.

when step on 

```
def _bytes_feature(value):
  """"""Wrapper for inserting a bytes Feature into a SequenceExample proto.""""""
  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[str(value)]))
```
there will throw an exception

```
Exception in thread Thread-6:
Traceback (most recent call last):
  File ""/opt/local/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/threading.py"", line 914, in _bootstrap_inner
    self.run()
  File ""/opt/local/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/threading.py"", line 862, in run
    self._target(*self._args, **self._kwargs)
  File ""/Users/apple1/Desktop/im2txt_new/im2txt/im2txt/data/build_mscoco_data.py"", line 278, in _process_image_files
    sequence_example = _to_sequence_example(image, decoder, vocab)
  File ""/Users/apple1/Desktop/im2txt_new/im2txt/im2txt/data/build_mscoco_data.py"", line 224, in _to_sequence_example
    ""image/data"": _bytes_feature(encoded_image),
  File ""/Users/apple1/Desktop/im2txt_new/im2txt/im2txt/data/build_mscoco_data.py"", line 189, in _bytes_feature
    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[str(value)]))
  File ""/opt/local/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/google/protobuf/internal/python_message.py"", line 517, in init
    copy.extend(field_value)
  File ""/opt/local/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/google/protobuf/internal/containers.py"", line 275, in extend
    new_values = [self._type_checker.CheckValue(elem) for elem in elem_seq_iter]
  File ""/opt/local/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/google/protobuf/internal/containers.py"", line 275, in <listcomp>
    new_values = [self._type_checker.CheckValue(elem) for elem in elem_seq_iter]
  File ""/opt/local/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/google/protobuf/internal/type_checkers.py"", line 108, in CheckValue
    raise TypeError(message)
TypeError: 'b\'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x01\\x00d\\x00d\\x00\\x00\\xff\\xe2\\x0cXICC_PROFILE\\x00\\x01\\x01\\x00\\x00\\x0cHLino\\x02\\x10\\x00\\x00mntrRGB XYZ \\x07\\xce\\x00\\x02\\x00\\t\\x00\\x06\\x001\\x00\\x00acspMSFT\\x00\\x00\\x00\\x00IEC sRGB\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\xf6\\xd6\\x00\\x01\\x00\\x00\\x00\\x00\\xd3-HP  \\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x11cprt\\x00\\x00\\x01P\\x00\\x00\\x003desc\\x00\\x00\\x01\\x84\\x00\\x00\\x00lwtpt\\x00\\x00\\x01\\xf0\\x00\\x00\\x00\\x14bkpt\\x00\\x00\\x02\\x04\\x00\\x00\\x00\\x14rXYZ\\x00\\x00\\x02\\x18\\x00\\x00\\x00\\x14gXYZ\\x00\\x00\\x02,\\x00\\x00\\x00\\x14bXYZ\\x00\\x00\\x02@\\x00\\x00\\x00\\x14dmnd\\x00\\x00\\x02T\\x00\\x00\\x00pdmdd\\x00\\x00\\x02\\xc4\\x00\\x00\\x00\\x88vued\\x00\\x00\\x03L\\x00\\x00\\ has type <class 'str'>, but expected one of: ((<class 'bytes'>,),)
```
",PowerAndSpeed,b'stat:awaiting maintainer type:bug',2016-12-29T07:39:24Z,2019-06-10T22:06:11Z,,,,,,,
817,"cifar10_input.py calls tf.strided_slice() with 3 arguments, 4 needed.","## Please let us know which model this issue is about (specify the top-level directory)

models/tutorials/image/cifar10/cifar10_input.py:87

  File ""/mnt/st12tb/models/tutorials/image/cifar10/cifar10_input.py"", line 87, in read_cifar10
    tf.strided_slice(record_bytes, [0], [label_bytes]), tf.int32)

models/tutorials/image/cifar10/cifar10_input.py:93

  File ""/mnt/st12tb/models/tutorials/image/cifar10/cifar10_input.py"", line 93, in read_cifar10
    [label_bytes + image_bytes]),

In both cases, running the script, e.g. with ""python cifar10_train.py"" on TensorFlow v0.12 yields

TypeError: strided_slice() takes at least 4 arguments (3 given)",dweekly,b'type:bug',2016-12-26T23:20:34Z,2017-01-16T02:51:25Z,,,,,,,
815,models.slim.deployment needs to have proper summary operations,"models.slim.deployment, all references to *_summary need to be changed to tf.summary as per latest TF master. 
",aazout,b'type:bug',2016-12-26T05:53:55Z,2017-03-23T22:51:15Z,,,,,,,
796,AttributeError in tutorials/embedding : skipgram_word2vec ,"I am getting the following AttributeError
```
$ python word2vec_optimized.py   --train_data=text8   --eval_data=questions-words.txt   --save_path=/tmp/

Traceback (most recent call last):
  File ""word2vec_optimized.py"", line 439, in <module>
    tf.app.run()
  File ""/Users/cremones/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/platform/app.py"", line 43, in run
    sys.exit(main(sys.argv[:1] + flags_passthrough))
  File ""word2vec_optimized.py"", line 423, in main
    model = Word2Vec(opts, session)
  File ""word2vec_optimized.py"", line 146, in __init__
    self.build_graph()
  File ""word2vec_optimized.py"", line 181, in build_graph
    examples, labels) = word2vec.skipgram_word2vec(filename=opts.train_data,
AttributeError: module 'tensorflow.models.embedding.gen_word2vec' has no attribute 'skipgram_word2vec'
```
using python 3.5.2, tensorflow 0.12.0 and latest master of the models repository ( commit 33bc8b14693d )

Thank you for your help!
",sharkovsky,b'type:bug',2016-12-22T15:57:02Z,2017-11-30T22:24:13Z,,,,,,,
784,tf.contrib.deprecated methods is eliminated in tf version 0.12,"As I mentioned in the title the tf.contrib.deprecated is eliminated in tensorflow version 0.12. So I suggest to edit the code. If it's ok you can make it contribute welcome for me to edit it myself.

## Please let us know which model this issue is about (specify the top-level directory)
image/cifar10
embedding
rnn/ptb",mrphoenix13,b'help wanted type:bug',2016-12-21T07:26:24Z,2018-02-08T00:55:23Z,,,,,,,
782,TF-Slim Walkthrough slim/slim_walkthough.ipynb Doesn't Work With TF 0.12,"The walkthrough has the user use the sum_of_squares() loss function which was removed after TF 0.10 and is no longer present in TF 0.12. Please update the walkthrough to work with TF 0.12.

loss = slim.losses.sum_of_squares(predictions, targets)",dweekly,b'type:bug',2016-12-21T04:44:46Z,2017-03-16T04:39:01Z,,,,,,,
771,Seq-to-Seq tutorial model predicts nothing except _UNK,"Model directory: `tutorials/rnn/translate`

I followed [this tutorial](https://www.tensorflow.org/tutorials/seq2seq/#what-next) with the suggested default parameters and let the network train for 3 days, doing 486800 steps and over 3 epochs. So to train the model, I ran:
```
python translate.py --data_dir /home/user/nn/seq-to-seq/data/en-to-fr --train_dir checkpoints/
```

But when I want to try out the resulting model by running
```
python translate.py --decode --data_dir /home/user/nn/seq-to-seq/data/en-to-fr --train_dir checkpoints/
```
then I get nothing but ""_UNK""s as translations (corresponding to the bucket sizes), e.g.:
```
Reading model parameters from checkpoints/translate.ckpt-486800
> cat
_UNK _UNK
> these are four words
_UNK _UNK _UNK _UNK _UNK _UNK
> There are three cats on the table
_UNK _UNK _UNK _UNK _UNK _UNK _UNK _UNK _UNK _UNK _UNK _UNK
```

I can see nothing wrong with either the data files, vocab files, or anything else created by the script. I made no changes to the code, except for changing the following to lines in `translate.py` and `seq2seq_model.py` so that the script uses the local libs. Without this change, the script [fails while looking for giga-fren.release2.fr.gz](http://lpaste.net/350155), which got renamed to giga-fren.release2.fixed.fr.gz as correctly referenced by the current version of the tutorial.
```
#from tensorflow.models.rnn.translate import data_utils
import data_utils
#from tensorflow.models.rnn.translate import seq2seq_model
import seq2seq_model
```
Can someone confirm the problem? Basically just have TF 0.12 installed, change the imports of data_utils and seq2seq_model to be local and run the commands mentioned higher up to train and try the model. I don't understand what's wrong.

PS: The perplexity during training is suspiciously low, too:
```
global step 400 learning rate 0.5000 step-time 0.51 perplexity 3.12
  eval: bucket 0 perplexity 7.41
  eval: bucket 1 perplexity 2.93
  eval: bucket 2 perplexity 1.63
  eval: bucket 3 perplexity 1.28
global step 600 learning rate 0.5000 step-time 0.45 perplexity 1.25
  eval: bucket 0 perplexity 1.51
  eval: bucket 1 perplexity 1.26
  eval: bucket 2 perplexity 1.19
  eval: bucket 3 perplexity 1.12
global step 800 learning rate 0.5000 step-time 0.48 perplexity 1.18
  eval: bucket 0 perplexity 1.51
  eval: bucket 1 perplexity 1.27
  eval: bucket 2 perplexity 1.19
  eval: bucket 3 perplexity 1.11
global step 1000 learning rate 0.5000 step-time 0.47 perplexity 1.17
  eval: bucket 0 perplexity 1.47
  eval: bucket 1 perplexity 1.28
  eval: bucket 2 perplexity 1.18
  eval: bucket 3 perplexity 1.11
```
...
```
global step 486400 learning rate 0.0011 step-time 0.48 perplexity 1.15
  eval: bucket 0 perplexity 1.47
  eval: bucket 1 perplexity 1.28
  eval: bucket 2 perplexity 1.15
  eval: bucket 3 perplexity 1.10
global step 486600 learning rate 0.0011 step-time 0.48 perplexity 1.15
  eval: bucket 0 perplexity 1.44
  eval: bucket 1 perplexity 1.25
  eval: bucket 2 perplexity 1.16
  eval: bucket 3 perplexity 1.11
```
I don't think it's learning anything.",cshapeshifter,b'stat:awaiting model gardener type:bug',2016-12-19T15:37:10Z,2017-01-09T09:27:23Z,,,,,,,
767,inception model training failing due to a ValueError,"## Please let us know which model this issue is about (specify the top-level directory)
Directory: tensorflow/models/inception

I have been trying to run the inception-net model following the instructions in the README.md.
`$ bazel-bin/inception/imagenet_train --num_gpus=2 --batch_size=128 --train_dir=/data-local/akshayc/imagenet_train --data_dir=""${DATA_DIR}""`
However, I get the following error:
```
Traceback (most recent call last):
  File ""/home/akshayc/tensorflow-source/tensorflow/models/inception/bazel-bin/inception/imagenet_train.runfiles/inception/inception/imagenet_train.py"", line 41, in <module>
    tf.app.run()
  File ""/home/akshayc/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/platform/app.py"", line 43, in run
    sys.exit(main(sys.argv[:1] + flags_passthrough))
  File ""/home/akshayc/tensorflow-source/tensorflow/models/inception/bazel-bin/inception/imagenet_train.runfiles/inception/inception/imagenet_train.py"", line 37, in main
    inception_train.train(dataset)
  File ""/home/akshayc/tensorflow-source/tensorflow/models/inception/bazel-bin/inception/imagenet_train.runfiles/inception/inception/inception_train.py"", line 239, in train
    scope)
  File ""/home/akshayc/tensorflow-source/tensorflow/models/inception/bazel-bin/inception/imagenet_train.runfiles/inception/inception/inception_train.py"", line 124, in _tower_loss
    loss_averages_op = loss_averages.apply(losses + [total_loss])
  File ""/home/akshayc/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/training/moving_averages.py"", line 391, in apply
    self._averages[var], var, decay, zero_debias=zero_debias))
  File ""/home/akshayc/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/training/moving_averages.py"", line 70, in assign_moving_average
    update_delta = _zero_debias(variable, value, decay)
  File ""/home/akshayc/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/training/moving_averages.py"", line 177, in _zero_debias
    trainable=False)
  File ""/home/akshayc/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py"", line 1024, in get_variable
    custom_getter=custom_getter)
  File ""/home/akshayc/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py"", line 850, in get_variable
    custom_getter=custom_getter)
  File ""/home/akshayc/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py"", line 346, in get_variable
    validate_shape=validate_shape)
  File ""/home/akshayc/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py"", line 331, in _true_getter
    caching_device=caching_device, validate_shape=validate_shape)
  File ""/home/akshayc/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py"", line 650, in _get_single_variable
    ""VarScope?"" % name)
ValueError: Variable tower_1/tower_1/CrossEntropyLoss/value/avg/biased does not exist, or was not created with tf.get_variable(). Did you mean to set reuse=None in VarScope?

```

Any idea what is happening here?

Thanks",akshayc11,b'stat:awaiting response type:bug',2016-12-16T23:22:31Z,2017-01-11T19:37:02Z,,,,,,,
764,TypeError: Parameter to MergeFrom() must be instance of same class,"I am trying to run models/resnet but I am getting type error:
TypeError: Parameter to MergeFrom() must be instance of same class: expected Summary got list. for field Event.summar

As I got few warnings about deprecated functions, I had updated them to suggested ones but same type error is still present. I am updated to latest tensorflow and protobuf (previous uninstall).


",frobrd,b'type:bug',2016-12-16T10:55:02Z,2017-01-16T02:42:35Z,,,,,,,
719,im2txt train error. (Attempting to use uninitialized value global_step) ,"I am trying to train the im2txt model in README.  Facing this issue:

INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.FailedPreconditionError'>, Attempting to use uninitialized value global_step
         [[Node: _send_global_step_0 = _Send[T=DT_INT32, client_terminated=true, recv_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device_incarnation=6453906879161278131, tensor_name=""global_step:0"", _device=""/job:localhost/replica:0/task:0/cpu:0""](global_step)]]
Traceback (most recent call last):
  File ""/im2txt/bazel-bin/im2txt/train.runfiles/im2txt/im2txt/train.py"", line 115, in <module>
    tf.app.run()
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/platform/app.py"", line 44, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""/im2txt/bazel-bin/im2txt/train.runfiles/im2txt/im2txt/train.py"", line 111, in main
    saver=saver)
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/contrib/slim/python/slim/learning.py"", line 770, in train
    sv.start_standard_services(sess)
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/training/supervisor.py"", line 666, in start_standard_services
    current_step = training_util.global_step(sess, self._global_step)
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/training/training_util.py"", line 54, in global_step
    return int(sess.run(global_step_tensor))
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 767, in run
    run_metadata_ptr)
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 965, in _run
    feed_dict_string, options, run_metadata)
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 1015, in _do_run
    target_list, options, run_metadata)
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 1035, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.FailedPreconditionError: Attempting to use uninitialized value global_step
         [[Node: _send_global_step_0 = _Send[T=DT_INT32, client_terminated=true, recv_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device_incarnation=6453906879161278131, tensor_name=""global_step:0"", _device=""/job:localhost/replica:0/task:0/cpu:0""](global_step)]]

before the error, according to https://github.com/tensorflow/tensorflow/issues/5901, I modified the file and error passed.

thanks
",vangogh0318,b'type:bug',2016-12-07T09:57:15Z,2016-12-08T02:52:31Z,,,,,,,
490,[slim] performance reduce when train cifarnet with multi-gpu,"I want to train cifarnet on single machine with 4 gpus, but the performance reduces comparing with training with only one gpu.
## [slim] Train cifarnet using the default script slim/scripts/train_cifarnet_on_cifar10.sh

When using the default script the speed is as follow:

```
INFO:tensorflow:global step 13900: loss = 0.7609 (0.06 sec/step)
```
## Modify slim/scripts/train_cifarnet_on_cifar10.sh by set num_clones=4

The speed become slow (I also try change num_preprocessing_threads = 1/2/4/8/16, num_readers=4/8, useless)

```
INFO:tensorflow:global step 14000: loss = 0.7438 (0.26 sec/step)
INFO:tensorflow:global step 14100: loss = 0.6690 (0.26 sec/step)
```
## Hardware

Four Titan X
02:00.0 VGA compatible controller: NVIDIA Corporation Device 17c2 (rev a1)
03:00.0 VGA compatible controller: NVIDIA Corporation Device 17c2 (rev a1)
06:00.0 VGA compatible controller: ASPEED Technology, Inc. ASPEED Graphics Family (rev 30)
82:00.0 VGA compatible controller: NVIDIA Corporation Device 17c2 (rev a1)
83:00.0 VGA compatible controller: NVIDIA Corporation Device 17c2 (rev a1)
+------------------------------------------------------+  
| NVIDIA-SMI 352.30     Driver Version: 352.30         |  
|-----------------------------------+----------------------+------------------------+
| GPU  Name            Persistence-M  | Bus-Id               Disp.A |      Volatile Uncorr. ECC  |
| Fan   Temp    Perf  Pwr:Usage/Cap |            Memory-Usage |   GPU-Util  Compute M. |
|=========================+=================+=================|
|   0     GeForce  GTX TIT...        On   |     0000:02:00.0     Off |                                   N/A |
| 28%   67C         P2      75W / 250W |      228MiB / 12287MiB |                 0%      Default |
+----------------------------------+-----------------------+------------------------+
。。。

32 processor each as follow ：
processor       : 0
vendor_id       : GenuineIntel
cpu family      : 6
model           : 63
model name      : Intel(R) Xeon(R) CPU E5-2630 v3 @ 2.40GHz
## Finally

Could anyone give some advices?
I read some issues about multi-gpu in this rep, but still can't solve this.
I think it caused by IO, because I notice that when train on single gpu the GPU-Util is above 90%( when train with 4 gpus, the GPU-Util is about 20% ).
And I don't think it's due to the hardware performance of my machine.
",D-X-Y,b'stat:awaiting model gardener type:bug',2016-10-02T15:50:56Z,2017-09-25T15:33:03Z,,,,,,,
54,[ distribution ] How to use multiple GPU on each replica ?,"The [Code Here](https://github.com/tensorflow/models/blob/master/inception/inception/imagenet_distributed_train.py) shows how to set each replica which has a single tower that uses one GPU. I'm wondering if there is a way changing this code a little bit to make use of multiple GPU on one machine like [that example](https://github.com/tensorflow/models/blob/master/inception/inception/inception_train.py). 

The way I currently used for using all GPU on a worker machine is starting the number of workers that equal to the number of GPUs. then the workers can communicate to each other as if they are not on one machine. That is slower than if I can start a woker that control more than one GPU. 
",ZhuFengdaaa,b'type:bug',2016-04-26T09:49:21Z,2018-08-28T09:46:01Z,,,,,,,
