id,Title,Body,User,Label,Created At,Updated At
14218,A couple of Documentation changes ,"<!--
Please make sure you've read and understood our contributing guidelines;
https://github.com/keras-team/keras/blob/master/CONTRIBUTING.md

Note:
We are no longer adding new features to multi-backend Keras (we only fix bugs), as we are refocusing development efforts on tf.keras. If you are still interested in submitting a feature pull request, please direct it to tf.keras in the TensorFlow repository instead.
-->

### Summary

### Related Issues

### PR Overview

- [ ] This PR requires new unit tests [y/n] (make sure tests are included)
- [ ] This PR requires to update the documentation [y/n] (make sure the docs are up-to-date)
- [ ] This PR is backwards compatible [y/n]
- [ ] This PR changes the current API [y/n] (all API changes need to be approved by fchollet)
",k-sashank,None,2020-09-14T16:34:19Z,2020-09-14T16:34:31Z
14217,A couple of Documentation changes,"<!--
Please make sure you've read and understood our contributing guidelines;
https://github.com/keras-team/keras/blob/master/CONTRIBUTING.md

Note:
We are no longer adding new features to multi-backend Keras (we only fix bugs), as we are refocusing development efforts on tf.keras. If you are still interested in submitting a feature pull request, please direct it to tf.keras in the TensorFlow repository instead.
-->

### Summary

### Related Issues

### PR Overview

- [x] This PR requires new unit tests [y/n] (make sure tests are included)
- [x] This PR requires to update the documentation [y/n] (make sure the docs are up-to-date)
- [x] This PR is backwards compatible [y/n]
- [x] This PR changes the current API [y/n] (all API changes need to be approved by fchollet)
",k-sashank,None,2020-09-14T16:31:53Z,2020-09-14T16:33:26Z
14216,Updates,"<!--
Please make sure you've read and understood our contributing guidelines;
https://github.com/keras-team/keras/blob/master/CONTRIBUTING.md

Note:
We are no longer adding new features to multi-backend Keras (we only fix bugs), as we are refocusing development efforts on tf.keras. If you are still interested in submitting a feature pull request, please direct it to tf.keras in the TensorFlow repository instead.
-->

### Summary

### Related Issues

### PR Overview

- [ ] This PR requires new unit tests [y/n] (make sure tests are included)
- [ ] This PR requires to update the documentation [y/n] (make sure the docs are up-to-date)
- [ ] This PR is backwards compatible [y/n]
- [ ] This PR changes the current API [y/n] (all API changes need to be approved by fchollet)
",anishmo99,None,2020-09-14T16:17:18Z,2020-09-18T16:51:22Z
14188,"Solved: UnknownError: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. [[node model/conv2d/Conv2D (defined at :6) ]] [Op:__inference_distributed_function_7653]","This is my input:

`history = model.fit(train_images,
                    train_masks/255,
                    validation_split = 0.1,
                    epochs=EPOCHS)`

The error is:

`Train on 6274 samples, validate on 698 samples
Epoch 1/100
  32/6274 [..............................] - ETA: 37s
---------------------------------------------------------------------------
UnknownError                              Traceback (most recent call last)
<ipython-input-21-107e0c8149d7> in <module>
      2                     train_masks/255,
      3                     validation_split = 0.1,
----> 4                     epochs=EPOCHS)
      5 model.save(""D:/python/building_detection/8_building/building_final.h5"")

~\anaconda3\envs\tensorflow\lib\site-packages\tensorflow_core\python\keras\engine\training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)
    817         max_queue_size=max_queue_size,
    818         workers=workers,
--> 819         use_multiprocessing=use_multiprocessing)
    820 
    821   def evaluate(self,

~\anaconda3\envs\tensorflow\lib\site-packages\tensorflow_core\python\keras\engine\training_v2.py in fit(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)
    340                 mode=ModeKeys.TRAIN,
    341                 training_context=training_context,
--> 342                 total_epochs=epochs)
    343             cbks.make_logs(model, epoch_logs, training_result, ModeKeys.TRAIN)
    344 

~\anaconda3\envs\tensorflow\lib\site-packages\tensorflow_core\python\keras\engine\training_v2.py in run_one_epoch(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)
    126         step=step, mode=mode, size=current_batch_size) as batch_logs:
    127       try:
--> 128         batch_outs = execution_function(iterator)
    129       except (StopIteration, errors.OutOfRangeError):
    130         # TODO(kaftan): File bug about tf function and errors.OutOfRangeError?

~\anaconda3\envs\tensorflow\lib\site-packages\tensorflow_core\python\keras\engine\training_v2_utils.py in execution_function(input_fn)
     96     # `numpy` translates Tensors to values in Eager mode.
     97     return nest.map_structure(_non_none_constant_value,
---> 98                               distributed_function(input_fn))
     99 
    100   return execution_function

~\anaconda3\envs\tensorflow\lib\site-packages\tensorflow_core\python\eager\def_function.py in __call__(self, *args, **kwds)
    566         xla_context.Exit()
    567     else:
--> 568       result = self._call(*args, **kwds)
    569 
    570     if tracing_count == self._get_tracing_count():

~\anaconda3\envs\tensorflow\lib\site-packages\tensorflow_core\python\eager\def_function.py in _call(self, *args, **kwds)
    597       # In this case we have created variables on the first call, so we run the
    598       # defunned version which is guaranteed to never create variables.
--> 599       return self._stateless_fn(*args, **kwds)  # pylint: disable=not-callable
    600     elif self._stateful_fn is not None:
    601       # Release the lock early so that multiple threads can perform the call

~\anaconda3\envs\tensorflow\lib\site-packages\tensorflow_core\python\eager\function.py in __call__(self, *args, **kwargs)
   2361     with self._lock:
   2362       graph_function, args, kwargs = self._maybe_define_function(args, kwargs)
-> 2363     return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access
   2364 
   2365   @property

~\anaconda3\envs\tensorflow\lib\site-packages\tensorflow_core\python\eager\function.py in _filtered_call(self, args, kwargs)
   1609          if isinstance(t, (ops.Tensor,
   1610                            resource_variable_ops.BaseResourceVariable))),
-> 1611         self.captured_inputs)
   1612 
   1613   def _call_flat(self, args, captured_inputs, cancellation_manager=None):

~\anaconda3\envs\tensorflow\lib\site-packages\tensorflow_core\python\eager\function.py in _call_flat(self, args, captured_inputs, cancellation_manager)
   1690       # No tape is watching; skip to running the function.
   1691       return self._build_call_outputs(self._inference_function.call(
-> 1692           ctx, args, cancellation_manager=cancellation_manager))
   1693     forward_backward = self._select_forward_and_backward_functions(
   1694         args,

~\anaconda3\envs\tensorflow\lib\site-packages\tensorflow_core\python\eager\function.py in call(self, ctx, args, cancellation_manager)
    543               inputs=args,
    544               attrs=(""executor_type"", executor_type, ""config_proto"", config),
--> 545               ctx=ctx)
    546         else:
    547           outputs = execute.execute_with_cancellation(

~\anaconda3\envs\tensorflow\lib\site-packages\tensorflow_core\python\eager\execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)
     65     else:
     66       message = e.message
---> 67     six.raise_from(core._status_to_exception(e.code, message), None)
     68   except TypeError as e:
     69     keras_symbolic_tensors = [

~\anaconda3\envs\tensorflow\lib\site-packages\six.py in raise_from(value, from_value)

UnknownError:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.
	 [[node model/conv2d/Conv2D (defined at <ipython-input-17-45130942bb4a>:6) ]] [Op:__inference_distributed_function_7653]

Function call stack:
distributed_function`",ujwalakoriraj,b'backend:tensorflow',2020-08-11T19:55:39Z,2020-08-13T15:08:58Z
14174,"keras.models.load_model can not work with Flask service? Keras==2.4.2, Flask==1.1.2","I builded an API to train keras model. It worked if i run normaly (not build as flask service). But when i build as service and call it did not response anything and just stay at keras.models.load_model.

Here my code:

server.py

```
from predictor import Predictor
from retrain import retrain
from flask import Flask, request, render_template, jsonify, send_file
import os
import sys
os.environ[""CUDA_VISIBLE_DEVICES""] = ""-1""

app = Flask(__name__)

UPLOAD_FOLDER = 'data_image'
fe = FeatureExtractor(f'models/cls-B0-v0.h5')
predictor = Predictor(fe=fe)

@app.route('/train', methods=['POST'])
def train():
    scratch = request.form[""from_scratch""]
    loss, acc, f1 = retrain(fe=fe, scratch=scratch)
    return jsonify({'loss': loss, 'accuracy': f1})
if __name__ == ""__main__"":
    app.run(host=""0.0.0.0"", port=7197, threaded=False, processes=5)
```
predictor.py

```
class Predictor:
    def __init__(self, fe):
        with open(f'Labels/labels.json') as json_file:
            self.labels = json.load(json_file)
        if f'linear-v0.h5' not in os.listdir('models'):
            retrain(fe=fe, scratch='False')
        self.model = keras.models.load_model(f'models/linear-v0.h5')
```
retrain.py

```
if f'linear-v0.h5' not in os.listdir('models/temp'):
    train_model = Sequential([Dense(number_of_class, input_shape=(1280,), activation='softmax')])
else:
    train_model = keras.models.load_model(f'models/temp/linear-v0.h5')
    if number_of_class != train_model.output.shape[1]:
        train_model = Sequential([Dense(number_of_class, input_shape=(1280,), activation='softmax')])
```
I dont know why line ""train_model = keras.models.load_model(f'models/temp/linear-v0.h5')"" did not work, and if i commend ""predictor = Predictor(fe=fe)"", it worked. Mean that i can load only one model in my code. i have 2 ""linear-v0.h5"" on models and models/temp. Please tell me if u faced with this problem. Thank you so much. In addition, when i debug the problem at keras/engine/sequential.py file, line 399: model.add(layer)

```
@classmethod
  def from_config(cls, config, custom_objects=None):
    if 'name' in config:
      name = config['name']
      build_input_shape = config.get('build_input_shape')
      layer_configs = config['layers']
    else:
      name = None
      build_input_shape = None
      layer_configs = config
    model = cls(name=name)
    for layer_config in layer_configs:
      layer = layer_module.deserialize(layer_config,
                                       custom_objects=custom_objects)
      model.add(layer)
    if (not model.inputs and build_input_shape and
        isinstance(build_input_shape, (tuple, list))):
      model.build(build_input_shape)
    return model
```",ChungNPH,None,2020-07-28T07:24:04Z,2020-07-28T10:12:45Z
14133,"What is the ""PR""'s meaning?What's the full name of it?","**Important note:** the development of Keras is currently taking place at [`github.com/tensorflow/tensorflow`](https://github.com/tensorflow/tensorflow). Please file your bug report by creating a new issue in the TensorFlow repository.

Please note that multi-backend Keras development has been discontinued. Do not report issues about multi-backend Keras (Keras 2.3.1 and lower), only report issues about the TensorFlow implementation of Keras (tf.keras).
",yang-gis,b'backend:tensorflow',2020-06-24T07:03:34Z,2020-06-24T22:43:20Z
14128,Latest Keras version is not compatible with Python 2.7 anymore,"Latest Keras version requires tensorflow >= 2.2.0 but tensorflow 2.2.0 only has wheels for Python 3.5+. This means that trying to install keras in Python 2.7 or Python 3.4 leads to the following traceback:

```
DEPRECATION: Python 2.7 reached the end of its life on January 1st, 2020. Please upgrade your Python as Python 2.7 is no longer maintained. pip 21.0 will drop support for Python 2.7 in January 2021. More details about Python 2 support in pip, can be found at https://pip.pypa.io/en/latest/development/release-process/#python-2-support
Collecting keras
  Using cached Keras-2.4.0-py2.py3-none-any.whl (170 kB)
Collecting scipy>=0.14
  Using cached scipy-1.2.3-cp27-cp27mu-manylinux1_x86_64.whl (24.8 MB)
Processing /home/lothiraldan/.cache/pip/wheels/d1/d5/a0/3c27cdc8b0209c5fc1385afeee936cf8a71e13d885388b4be2/PyYAML-5.3.1-cp27-cp27mu-linux_x86_64.whl
Collecting numpy>=1.9.1
  Using cached numpy-1.16.6-cp27-cp27mu-manylinux1_x86_64.whl (17.0 MB)
ERROR: Could not find a version that satisfies the requirement tensorflow>=2.2.0 (from keras) (from versions: 0.12.0rc0, 0.12.0rc1, 0.12.0, 0.12.1, 1.0.0, 1.0.1, 1.1.0rc0, 1.1.0rc1, 1.1.0rc2, 1.1.0, 1.2.0rc0, 1.2.0rc1, 1.2.0rc2, 1.2.0, 1.2.1, 1.3.0rc0, 1.3.0rc1, 1.3.0rc2, 1.3.0, 1.4.0rc0, 1.4.0rc1, 1.4.0, 1.4.1, 1.5.0rc0, 1.5.0rc1, 1.5.0, 1.5.1, 1.6.0rc0, 1.6.0rc1, 1.6.0, 1.7.0rc0, 1.7.0rc1, 1.7.0, 1.7.1, 1.8.0rc0, 1.8.0rc1, 1.8.0, 1.9.0rc0, 1.9.0rc1, 1.9.0rc2, 1.9.0, 1.10.0rc0, 1.10.0rc1, 1.10.0, 1.10.1, 1.11.0rc0, 1.11.0rc1, 1.11.0rc2, 1.11.0, 1.12.0rc0, 1.12.0rc1, 1.12.0rc2, 1.12.0, 1.12.2, 1.12.3, 1.13.0rc0, 1.13.0rc1, 1.13.0rc2, 1.13.1, 1.13.2, 1.14.0rc0, 1.14.0rc1, 1.14.0, 1.15.0rc0, 1.15.0rc1, 1.15.0rc2, 1.15.0rc3, 1.15.0, 2.0.0a0, 2.0.0b0, 2.0.0b1, 2.0.0rc0, 2.0.0rc1, 2.0.0rc2, 2.0.0, 2.1.0rc0, 2.1.0rc1, 2.1.0rc2, 2.1.0)
ERROR: No matching distribution found for tensorflow>=2.2.0 (from keras)
```

If that was planned, I would suggest to update the setup.py file with the correct https://packaging.python.org/guides/distributing-packages-using-setuptools/#python-requires so pip can takes Keras 2.3.1 on incompatible Python versions.

I would also recommend yanking the release 2.4.0 as pip will try to get the 2.4.0 release if a 2.4.1 is released with the correct metadata.",Lothiraldan,b'backend:tensorflow type:bug/performance',2020-06-18T12:12:59Z,2020-06-24T13:18:11Z
14120,Twice as many bias elements in GRU layer weight file,"**System information**  
- Have I written custom code (as opposed to using example directory):  yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  ArchLinux 5.4.46-1-lts
- TensorFlow backend (yes / no):  yes
- TensorFlow version:  2.2.0
- Keras version:  2.3.0-tf
- Python version:  3.6
- CUDA/cuDNN version:  
- GPU model and memory:  

**Describe the current behavior**  
I have noticed, that when a gru layer is saved to a file, two almost identical bias vectors are written to the weight file, even though one of them would be enough. The bias data has the dimension (2x3*kernel_row_dimension) = rank 2. I am not sure whether this is intended, but I think that this is unlikely, given that only one set of kernel tensors is saved. 

**Describe the expected behavior**  
The bias tensor should be of rank 1

**Code to reproduce the issue**  
```python
from tensorflow.keras.layers import Input, GRU
from tensorflow.keras.models import Sequential
model = Sequential([Input((3, 12, )), GRU(3)])
model.save_weights(""test.h5"")

import h5py
F = h5py.File(""test.h5"", ""r"")
F[""gru""][""gru""][""gru_cell""][""bias:0""]
```
The output is
```
<HDF5 dataset ""bias:0"": shape (2,9), type ""<f4"">
```
Whereas I would expect to see something like (1, 9) since for a GRU 3 operations of the form activation(W x input + U x hidden + b) are evaluated, and since dim(hidden) and dim(input) is 3 here, the bias should store 9 elements in total. When the model is trained beforehand, the two bias vectors stored in the two rows are almost identical and can diverge on the order of a few % for increasing vector indices (I tested this with a bias vector of length 32).
",VukanJ,b'backend:tensorflow type:bug/performance',2020-06-15T21:38:19Z,2020-10-01T22:56:48Z
14101,While installing tensorflow background in the backend in ubuntu should I install it in virtual enviornment or in main python files?,"<em>Please make sure that this is a Bug or a Feature Request and provide all applicable information asked by the template.
If your issue is an **implementation question**, please ask your question on [StackOverflow](http://stackoverflow.com/questions/tagged/keras) or [on the Keras Slack channel](https://keras-slack-autojoin.herokuapp.com/) instead of opening a GitHub issue.</em>  

**System information**  
- Have I written custom code (as opposed to using example directory):  
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  
- TensorFlow backend (yes / no):  
- TensorFlow version:  
- Keras version:  
- Python version:  
- CUDA/cuDNN version:  
- GPU model and memory:  

You can obtain the TensorFlow version with:  
python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""  
You can obtain the Keras version with:  
python -c 'import keras as k; print(k.__version__)'  

**Describe the current behavior**  

**Describe the expected behavior**  

**Code to reproduce the issue**  
Provide a reproducible test case that is the bare minimum necessary to generate the problem.  

**Other info / logs**  
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.  
",siddharth87,b'backend:tensorflow',2020-06-07T08:26:35Z,2020-06-07T08:27:32Z
14045,return_dict in evaluate() method doesn't work,"I'm not sure if this is a bug, is a documentation incoherence or it's just an issue with the keras version that kaggle uses.

**System information**  
- Have I written custom code (as opposed to using example directory): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  Docker container for kaggle
- TensorFlow backend (yes / no):  yes
- TensorFlow version:  2.1.0
- Keras version:  2.3.1
- Python version:  3.7.6.

**Describe the current behavior**  

[In the docs for the model.evaluate method](https://keras.io/api/models/model_training_apis/#evaluate-method) it says you can use the argument ""return_dict"" to get a dictionary instead of a list for the output. However, I get an error when I specify such argument:
```
TypeError: evaluate() got an unexpected keyword argument 'return_dict'
```

**Describe the expected behavior**  
No error an dict with the output of the evaluation.

**Code to reproduce the issue**  
`results = model.evaluate(X_test, y_test, batch_size=24, return_dict=True)`

same thing if I use `return_dict = False`.

**Other info / logs**  
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.  
",Akronix,b'backend:tensorflow type:bug/performance',2020-05-12T12:44:26Z,2020-08-13T14:26:31Z
14038,Fix DeprecationWarning for collections.abc.Iterable,"https://docs.python.org/3/library/collections.abc.html#collections.abc.Iterable

% __pytest__
```
=============================== warnings summary ===============================
/home/travis/virtualenv/python3.8.1/lib/python3.8/site-packages/keras/callbacks/callbacks.py:19
Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.9 it will stop working
from collections import Iterable
```

<!--
Please make sure you've read and understood our contributing guidelines;
https://github.com/keras-team/keras/blob/master/CONTRIBUTING.md

Note:
We are no longer adding new features to multi-backend Keras (we only fix bugs), as we are refocusing development efforts on tf.keras. If you are still interested in submitting a feature pull request, please direct it to tf.keras in the TensorFlow repository instead.
-->

### Summary

### Related Issues

### PR Overview

- [ ] This PR requires new unit tests [y/n] (make sure tests are included)
- [ ] This PR requires to update the documentation [y/n] (make sure the docs are up-to-date)
- [x] This PR is backwards compatible [y/n]
- [ ] This PR changes the current API [y/n] (all API changes need to be approved by fchollet)
",cclauss,None,2020-05-09T06:42:01Z,2020-07-14T07:49:49Z
14037,Memory Leak when using keras.layers.Lambda and tf.map_fn,"**System information**  
- Have I written custom code (as opposed to using example directory):  Yes, see below
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  Arch Linux
- TensorFlow backend (yes / no):  yes
- TensorFlow version:  2.2.0-rc3
- Keras version:   2.3.1
- Python version:  3.8.2
- CUDA/cuDNN version:   V10.2.89
- GPU model and memory:  GeForce GTX 1060 6GB


The following program produces a memory leak.

```
#!/usr/bin/env python
import keras
import numpy as np
import tensorflow as tf
import gc
import os

@tf.function
def extractVector(inp):
	return tf.stack([inp[0]]*40, axis=0)

x_train = np.random.rand(3200, 40)
y_train = np.random.rand(3200, 40, 40)
embedding_vecs = np.random.rand(4592, 300)

input_layer = keras.layers.Input(shape=(40,))
embedding_layer = keras.layers.Embedding(4592, 300, weights=[embedding_vecs], input_length=40, trainable=False)(input_layer)
lstm_layer = keras.layers.LSTM(40, return_sequences=True)(embedding_layer)
lambda_layer = keras.layers.Lambda(lambda inp: tf.map_fn(extractVector, inp))(lstm_layer)
output_layer = lambda_layer

model = keras.models.Model(inputs=input_layer, outputs=output_layer)
model.compile(loss=""categorical_crossentropy"", optimizer=""adam"")

class GarbageCollectorCallback(tf.keras.callbacks.Callback):
    def on_epoch_end(self, epoch, logs=None):
        gc.collect()

class PrintRamCallback(tf.keras.callbacks.Callback):
    def on_epoch_end(self, epoch, logs=None):
        os.system(""pmap -x ""+str(os.getpid())+"" | tail -n 1"")

model.fit(x_train, y_train, batch_size=128, epochs=100, callbacks=[GarbageCollectorCallback(), PrintRamCallback()], verbose=0)

```

The output of the program above is:

> 2020-05-08 18:09:00.187454: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
> 2020-05-08 18:09:00.218519: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 3300655000 Hz
> 2020-05-08 18:09:00.218983: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5594d82c4200 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
> 2020-05-08 18:09:00.219023: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
> 2020-05-08 18:09:00.220331: I tensorflow/core/common_runtime/process_util.cc:147] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.
> Using TensorFlow backend.
> WARNING:tensorflow:AutoGraph could not transform <function extractVector at 0x7f74044ca310> and will run it as-is.
> Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
> Cause: module 'gast' has no attribute 'Constant'
> To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
> total kB         3554580  613100  429920
> total kB         3685652  753188  570008
> total kB         3816724  893884  710704
> total kB         3947796 1034252  851072
> total kB         4078868 1174528  991348
> total kB         4209940 1314880 1131700
> total kB         4341012 1455372 1272192
> total kB         4472084 1595540 1412360
> total kB         4603156 1741396 1558216
> total kB         4734228 1881492 1698312
> total kB         4865300 2021600 1838420
> total kB         4996372 2163068 1979888
> total kB         5192980 2303140 2119960
> total kB         5389588 2443292 2260112
> total kB         5520660 2583584 2400404
> total kB         5651732 2723784 2540604
> total kB         5782804 2863836 2680656
> total kB         5913876 3004144 2820964
> total kB         6044948 3144256 2961076
> total kB         6176020 3284412 3101232
> total kB         6307092 3424500 3241320
> total kB         6438164 3564720 3381540
> total kB         6569236 3705064 3521884
> total kB         6700308 3845276 3662096
> total kB         6831380 3985636 3802456
> total kB         7027988 4125896 3942716
> total kB         7159060 4266096 4082916
> total kB         7290132 4406160 4222980
> total kB         7421204 4546380 4363200
> total kB         7552276 4686528 4503348
> total kB         7683348 4826604 4643424
> total kB         7879956 4966828 4783648
> total kB         8011028 5106936 4923756
> total kB         8142100 5247296 5064116
> total kB         8273172 5383988 5204424
> total kB         8404244 5492128 5344856
> total kB         8535316 5494272 5485284
> total kB         8731924 5633596 5625676
> total kB         8862996 5772616 5765768
> total kB         8994068 5912720 5905752
> total kB         9125140 6052912 6045960
> total kB         9256212 6192840 6186032
> total kB         9387284 6236800 6226492
> total kB         9518356 6332196 6321296
> total kB         9649428 6379904 6369476
> total kB         9780500 6442764 6432232
> total kB         9977108 6490412 6480072
> total kB         10108180 6518504 6508008

You can see that it uses 430 MB to complete the first epoch, but 6500 MB for the 48'th Epoch .",Volker-Weissmann,b'backend:tensorflow type:bug/performance',2020-05-08T16:31:13Z,2020-07-17T17:03:50Z
14008,"Fix incorrect loss_weights error message, clarify docs","<!--
Please make sure you've read and understood our contributing guidelines;
https://github.com/keras-team/keras/blob/master/CONTRIBUTING.md

Note:
We are no longer adding new features to multi-backend Keras (we only fix bugs), as we are refocusing development efforts on tf.keras. If you are still interested in submitting a feature pull request, please direct it to tf.keras in the TensorFlow repository instead.
-->

### Summary

loss_weights argument to model.fit only accepts python lists, so no numpy arrays. clarify docs for that. Also the error message was incorrect, asking for a ""list **of** dicts"" instead of a ""list **or** dict"" as the docs ask for.

### PR Overview

No special requirements, minor change to docs, error message

- `n` This PR requires new unit tests [y/n] (make sure tests are included)
- `?` This PR requires to update the documentation [y/n] (make sure the docs are up-to-date)
- `n` This PR is backwards compatible [y/n]
- `n` This PR changes the current API [y/n] (all API changes need to be approved by fchollet)

Edit:
Force-pushed to reflow text to fit in 85 cols",MingweiSamuel,None,2020-04-26T23:39:30Z,2020-07-29T14:07:41Z
13965,Removed an unused variable `num_predictions` from CIFAR-10 CNN example.,"The variable `num_predictions` was perhaps confusing too in addition to being unnecessary because:

- `num_classes = 10` is present 2 lines above it. (Only 10 classes in CIFAR-10)
- `model.predict` is never used in the example. Maybe the variable is vestigial?
 
<!--
Please make sure you've read and understood our contributing guidelines;
https://github.com/keras-team/keras/blob/master/CONTRIBUTING.md

Note:
We are no longer adding new features to multi-backend Keras (we only fix bugs), as we are refocusing development efforts on tf.keras. If you are still interested in submitting a feature pull request, please direct it to tf.keras in the TensorFlow repository instead.
-->

### Summary
I removed the unused variable `num_predictions` in the CIFAR-10 CNN example.

### Related Issues
None

### PR Overview

- [n] This PR requires new unit tests [y/n] (make sure tests are included)
- [y] This PR requires to update the documentation [y/n] (make sure the docs are up-to-date)
- [y] This PR is backwards compatible [y/n]
- [n] This PR changes the current API [y/n] (all API changes need to be approved by fchollet)
",candh,None,2020-04-13T15:29:06Z,2020-04-13T15:31:03Z
13955,updated 'acc' to 'accuracy' and 'val_acc' to val_accuracy,"# Plot training & validation accuracy values
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])

<!--
Please make sure you've read and understood our contributing guidelines;
https://github.com/keras-team/keras/blob/master/CONTRIBUTING.md

Note:
We are no longer adding new features to multi-backend Keras (we only fix bugs), as we are refocusing development efforts on tf.keras. If you are still interested in submitting a feature pull request, please direct it to tf.keras in the TensorFlow repository instead.
-->

### Summary

### Related Issues

### PR Overview

- [ ] This PR requires new unit tests [y/n] (make sure tests are included)
- [ ] This PR requires to update the documentation [y/n] (make sure the docs are up-to-date)
- [ ] This PR is backwards compatible [y/n]
- [ ] This PR changes the current API [y/n] (all API changes need to be approved by fchollet)
",ashishpatel26,None,2020-04-11T09:26:29Z,2020-04-11T09:27:05Z
13930,tensorflow testing,"<em>Please make sure that this is a Bug or a Feature Request and provide all applicable information asked by the template.tensorflow
If your issue is an **implementation question**, please ask your question on [StackOverflow](http://stackoverflow.com/questions/tagged/keras) or [on the Keras Slack channel](https://keras-slack-autojoin.herokuapp.com/) instead of opening a GitHub issue.</em>  

**System information**  
- Have I written custom code (as opposed to using example directory):  
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  
- TensorFlow backend (yes / no):  
- TensorFlow version:  
- Keras version:  
- Python version:  
- CUDA/cuDNN version:  
- GPU model and memory:  

You can obtain the TensorFlow version with:  
python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""  
You can obtain the Keras version with:  
python -c 'import keras as k; print(k.__version__)'  

**Describe the current behavior**  

**Describe the expected behavior**  

**Code to reproduce the issue**  
Provide a reproducible test case that is the bare minimum necessary to generate the problem.  

**Other info / logs**  
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.  
",rthadur,b'backend:tensorflow',2020-04-01T17:55:54Z,2020-04-01T17:56:20Z
13913,tensorflow test,"<em>Please make sure that this is a Bug or a Feature Request and provide all applicable information asked by the template.
If your issue is an **implementation question**, please ask your question on [StackOverflow](http://stackoverflow.com/questions/tagged/keras) or [on the Keras Slack channel](https://keras-slack-autojoin.herokuapp.com/) instead of opening a GitHub issue.</em>  

**System information**  
- Have I written custom code (as opposed to using example directory):  
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  
- TensorFlow backend (yes / no):  
- TensorFlow version:  
- Keras version:  
- Python version:  
- CUDA/cuDNN version:  
- GPU model and memory:  

You can obtain the TensorFlow version with:  
python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""  
You can obtain the Keras version with:  
python -c 'import keras as k; print(k.__version__)'  

**Describe the current behavior**  

**Describe the expected behavior**  

**Code to reproduce the issue**  
Provide a reproducible test case that is the bare minimum necessary to generate the problem.  

**Other info / logs**  
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.  
",tensorflowbutler,b'backend:tensorflow',2020-03-27T00:19:42Z,2020-03-27T00:20:00Z
13912,tensorflow,"<em>Please make sure that this is a Bug or a Feature Request and provide all applicable information asked by the template.
If your issue is an **implementation question**, please ask your question on [StackOverflow](http://stackoverflow.com/questions/tagged/keras) or [on the Keras Slack channel](https://keras-slack-autojoin.herokuapp.com/) instead of opening a GitHub issue.</em>  

**System information**  
- Have I written custom code (as opposed to using example directory):  
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  
- TensorFlow backend (yes / no):  
- TensorFlow version:  
- Keras version:  
- Python version:  
- CUDA/cuDNN version:  
- GPU model and memory:  

You can obtain the TensorFlow version with:  
python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""  
You can obtain the Keras version with:  
python -c 'import keras as k; print(k.__version__)'  

**Describe the current behavior**  

**Describe the expected behavior**  

**Code to reproduce the issue**  
Provide a reproducible test case that is the bare minimum necessary to generate the problem.  

**Other info / logs**  
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.  
",tensorflowbutler,None,2020-03-26T21:31:07Z,2020-03-26T21:32:10Z
13901,"tensorflow.python.framework.errors_impl.InvalidArgumentError: Tensor conv2d_1_input:0, specified in either feed_devices or fetch_devices was not found in the Graph","Hi, i'm using keras and tensorflow for this code
```
from flask import Flask, request, jsonify, render_template
import numpy
from PIL import Image
import os
import tensorflow.keras
from werkzeug.utils import secure_filename
from keras.models import load_model

app = Flask(__name__)

model = load_model('traffic_classifier.h5')
model._make_predict_function()
classes = { 1:'Speed limit (20km/h)',
            2:'Speed limit (30km/h)',      
            3:'Speed limit (50km/h)',       
            4:'Speed limit (60km/h)',      
            5:'Speed limit (70km/h)',    
            6:'Speed limit (80km/h)',      
            7:'End of speed limit (80km/h)',     
            8:'Speed limit (100km/h)',    
            9:'Speed limit (120km/h)',     
           10:'No passing',   
           11:'No passing veh over 3.5 tons',     
           12:'Right-of-way at intersection',     
           13:'Priority road',    
           14:'Yield',     
           15:'Stop',       
           16:'No vehicles',       
           17:'Veh > 3.5 tons prohibited',       
           18:'No entry',       
           19:'General caution',     
           20:'Dangerous curve left',      
           21:'Dangerous curve right',   
           22:'Double curve',      
           23:'Bumpy road',     
           24:'Slippery road',       
           25:'Road narrows on the right',  
           26:'Road work',    
           27:'Traffic signals',      
           28:'Pedestrians',     
           29:'Children crossing',     
           30:'Bicycles crossing',       
           31:'Beware of ice/snow',
           32:'Wild animals crossing',      
           33:'End speed + passing limits',      
           34:'Turn right ahead',     
           35:'Turn left ahead',       
           36:'Ahead only',      
           37:'Go straight or right',      
           38:'Go straight or left',      
           39:'Keep right',     
           40:'Keep left',      
           41:'Roundabout mandatory',     
           42:'End of no passing',      
           43:'End no passing veh > 3.5 tons' }

@app.route('/')
def index():
    # Main page
    return render_template('index.html')

@app.route('/traffic')
def traffic():
    # Main page
    return render_template('traffic.html')

@app.route('/sleep')
def sleep():
    # Main page
    return render_template('sleep.html')

@app.route('/predict',methods=['POST'])
def predict():
    '''
    For rendering results on HTML GUI
    '''
    if request. method == ""POST"":
        #image=request. form[""fileupload""]
    
        f = request.files['file']

        # Save the file to ./uploads
        basepath = os.path.dirname(__file__)
        file_path = os.path.join(
            basepath, 'uploads', secure_filename(f.filename))
        f.save(file_path)  
    
   
    image = Image.open(file_path)
    image = image.resize((30,30))
    image = numpy.expand_dims(image, axis=0)
    image = numpy.array(image)

    pred = model.predict_classes([image])[0]
   
    sign = classes[pred+1]


    
    

    return render_template('traffic.html', prediction_text='This sign represents {}'.format(sign))


if __name__ == ""__main__"":
    app.run(debug=True)
```


it shows the error 
tensorflow.python.framework.errors_impl.InvalidArgumentError: Tensor conv2d_1_input:0, specified in either feed_devices or fetch_devices was not found in the Graph

please help me on this

",Ananthan4451,None,2020-03-19T17:33:04Z,2020-03-19T18:23:58Z
13888,Hi ,"<em>Please make sure that this is a Bug or a Feature Request and provide all applicable information asked by the template.
If your issue is an **implementation question**, please ask your question on [StackOverflow](http://stackoverflow.com/questions/tagged/keras) or [on the Keras Slack channel](https://keras-slack-autojoin.herokuapp.com/) instead of opening a GitHub issue.</em>  

**System information**  
- Have I written custom code (as opposed to using example directory):  
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  
- TensorFlow backend (yes / no):  
- TensorFlow version:  
- Keras version:  
- Python version:  
- CUDA/cuDNN version:  
- GPU model and memory:  

You can obtain the TensorFlow version with:  
python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""  
You can obtain the Keras version with:  
python -c 'import keras as k; print(k.__version__)'  

**Describe the current behavior**  

**Describe the expected behavior**  

**Code to reproduce the issue**  
Provide a reproducible test case that is the bare minimum necessary to generate the problem.  

**Other info / logs**  
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.  
",sumannelli,None,2020-03-11T21:18:46Z,2020-03-12T14:35:46Z
13855,Merge pull request #1 from keras-team/master,"synchronous update

<!--
Please make sure you've read and understood our contributing guidelines;
https://github.com/keras-team/keras/blob/master/CONTRIBUTING.md

Note:
We are no longer adding new features to multi-backend Keras (we only fix bugs), as we are refocusing development efforts on tf.keras. If you are still interested in submitting a feature pull request, please direct it to tf.keras in the TensorFlow repository instead.
-->

### Summary

### Related Issues

### PR Overview

- [ ] This PR requires new unit tests [y/n] (make sure tests are included)
- [ ] This PR requires to update the documentation [y/n] (make sure the docs are up-to-date)
- [ ] This PR is backwards compatible [y/n]
- [ ] This PR changes the current API [y/n] (all API changes need to be approved by fchollet)
",bruce1408,None,2020-03-03T06:08:45Z,2020-03-03T06:09:59Z
13853,Update lstm_text_generation.py,"shortened the declaration code for  x & y

<!--
Please make sure you've read and understood our contributing guidelines;
https://github.com/keras-team/keras/blob/master/CONTRIBUTING.md

Note:
We are no longer adding new features to multi-backend Keras (we only fix bugs), as we are refocusing development efforts on tf.keras. If you are still interested in submitting a feature pull request, please direct it to tf.keras in the TensorFlow repository instead.
-->

### Summary

### Related Issues

### PR Overview

- [x] This PR requires new unit tests [y/n] (make sure tests are included)
- [x] This PR requires to update the documentation [y/n] (make sure the docs are up-to-date)
- [x] This PR is backwards compatible [y/n]
- [ ] This PR changes the current API [y/n] (all API changes need to be approved by fchollet)
",Dynmi,None,2020-03-03T04:44:36Z,2020-08-18T16:31:05Z
13850,deleted everything,"<!--
Please make sure you've read and understood our contributing guidelines;
https://github.com/keras-team/keras/blob/master/CONTRIBUTING.md

Note:
We are no longer adding new features to multi-backend Keras (we only fix bugs), as we are refocusing development efforts on tf.keras. If you are still interested in submitting a feature pull request, please direct it to tf.keras in the TensorFlow repository instead.
-->

### Summary

### Related Issues

### PR Overview

- [ ] This PR requires new unit tests [y/n] (make sure tests are included)
- [ ] This PR requires to update the documentation [y/n] (make sure the docs are up-to-date)
- [ ] This PR is backwards compatible [y/n]
- [ ] This PR changes the current API [y/n] (all API changes need to be approved by fchollet)
",paulkangdev,None,2020-03-02T02:07:36Z,2020-03-02T02:07:48Z
13848,"ValueError: Invalid input_shape argument (None, 13): model has 0 tensor inputs.","**Ensemble model not working after loading from h5**
I'm building ensemble model with Keras and Tensorflow as backend. I have a couple pretrained ANN models saved in .h5 format - all works well. Then I create ensemble as follow:

For each network
 - First remove `Input` with `model.pop(0)`. 
 - Next create `Lambda layer` as firs layer of network
 - Create new `Input layer`  for netwok and crete new model from new Input layer and existing model

Then buidl ensemble model with following code:
```
model_input = Input(shape=(input_count, ))
for i in range(len(self.networks)):
    model = self.networks[i]
    for _layer in model.layers:
        _layer.trainable = False
        _layer.name = 'ensemble_' + str(i) + '_' + _layer.name

yModels=[model(model_input) for model in self.networks]

concatenated = Concatenate()(yModels)

def weighted_sum(x, w):
    """""" weights from formula 7 """"""
    w = K.variable(w)
    tensor = K.sum(x * w, axis= -1)
    return tensor
        
args = {""w"": self.w}
ens_output = Lambda(weighted_sum, arguments=args)(concatenated)
        
# build model
self.ensemble_model = Model(inputs=model_input, outputs=ens_output, name='ensemble')
self.ensemble_model.compile(loss='mean_absolute_error', optimizer = 'adam', metrics=['accuracy'])
```
`esemble_model` predict  OK results. After saving model to .h5 and loading back I get error:

```
Traceback (most recent call last):
  File ""test_laod_models.py"", line 8, in <module>
    model = load_model('ensemble_1.h5')
  File ""C:\Users\krstic\AppData\Local\conda\conda\envs\tensorflow\lib\site-packages\keras\engine\saving.py"", line 419, in load_model
    model = _deserialize_model(f, custom_objects, compile)
  File ""C:\Users\krstic\AppData\Local\conda\conda\envs\tensorflow\lib\site-packages\keras\engine\saving.py"", line 225, in _deserialize_model
    model = model_from_config(model_config, custom_objects=custom_objects)
  File ""C:\Users\krstic\AppData\Local\conda\conda\envs\tensorflow\lib\site-packages\keras\engine\saving.py"", line 458, in model_from_config
    return deserialize(config, custom_objects=custom_objects)
  File ""C:\Users\krstic\AppData\Local\conda\conda\envs\tensorflow\lib\site-packages\keras\layers\__init__.py"", line 55, in deserialize
    printable_module_name='layer')
  File ""C:\Users\krstic\AppData\Local\conda\conda\envs\tensorflow\lib\site-packages\keras\utils\generic_utils.py"", line 145, in deserialize_keras_object
    list(custom_objects.items())))
  File ""C:\Users\krstic\AppData\Local\conda\conda\envs\tensorflow\lib\site-packages\keras\engine\network.py"", line 1032, in from_config
    process_node(layer, node_data)
  File ""C:\Users\krstic\AppData\Local\conda\conda\envs\tensorflow\lib\site-packages\keras\engine\network.py"", line 991, in process_node
    layer(unpack_singleton(input_tensors), **kwargs)
  File ""C:\Users\krstic\AppData\Local\conda\conda\envs\tensorflow\lib\site-packages\keras\engine\base_layer.py"", line 474, in __call__
    output_shape = self.compute_output_shape(input_shape)
  File ""C:\Users\krstic\AppData\Local\conda\conda\envs\tensorflow\lib\site-packages\keras\engine\network.py"", line 593, in compute_output_shape
    str(len(self._input_layers)) + ' tensor inputs.')
ValueError: Invalid input_shape argument (None, 13): model has 0 tensor inputs.
```

In short:
 - enseble_model - works OK
 - save_model() - OK
 - load _model() - raise error",lazarkrstic,b'type:bug/performance',2020-03-01T13:10:10Z,2020-04-01T15:37:36Z
13816,val_loss missing from logs (but computed correctly at epoch end),"**System information**

- OS Platform and Distribution: Windows 10 Enterprise 1803 (build 17134.1246)
- TensorFlow backend: yes
- TensorFlow version: 2.0.0
- Keras version: '2.2.4-tf' (called from tensorflow.keras)
- Python version: 3.7
- CUDA/cuDNN version: -
- GPU model and memory: -

I'm trying to use the `ModelCheckpoint` callback in keras. However, it keeps saying to me that `val_loss` is not available. I added a print statement in the code of `ModelCheckpoint` to check the content of the `logs` variable passed to the callback. You can indeed see below that `val_loss` is not present in the dictionary.

The weird thing is that `val_loss` is correctly reported at the end of each epoch and it is present in the `history` object generated by `model.fit`. Clearly I provide validation data (otherwise val_loss could not be evaluated at the end of each epoch).

```
...
3/3 - 65s - loss: 0.2053 - val_loss: 0.1153
Epoch 2/45
logs={'batch': 0, 'size': 30000, 'loss': 0.20355584}
WARNING:tensorflow:Can save best model only with val_loss available, skipping.
...
```",pj1989,b'type:bug/performance',2020-02-21T09:16:18Z,2020-03-01T12:28:36Z
13813,num_states = len(self.cell.state_size) TypeError: object of type 'numpy.int64' has no len() when using CuDNNGRU,"**System information**  
- Have I written custom code (as opposed to using example directory):   Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  Ubuntu 16.04
- TensorFlow backend (yes / no):  yes
- TensorFlow version:  1.13.1
- Keras version:  2.3.1
- Python version:  3.6
- CUDA/cuDNN version:  10.0
- GPU model and memory:  1080Ti, 11GB


**Describe the current behavior**  
I used the CuDNNGRU to implement the GRU, and the code is shown as below. And it gave me this error as shown below. I have searched online and found someone ran into similar problems but I didn't find any solutions. I am not sure if it's a bug or a implementation problem. However, the same code work fine with CuDNNLSTM. I just can't figure out where the problem is. The error is shown as below:

Traceback (most recent call last):
  File ""/home/zz/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py"", line 2963, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File ""<ipython-input-2-e007a89c7bef>"", line 1, in <module>
    runfile('/media/zz/data/all_process_test_GRU.py', wdir='/media/zz/data/')
  File ""/snap/pycharm-professional/183/plugins/python/helpers/pydev/_pydev_bundle/pydev_umd.py"", line 197, in runfile
    pydev_imports.execfile(filename, global_vars, local_vars)  # execute the script
  File ""/snap/pycharm-professional/183/plugins/python/helpers/pydev/_pydev_imps/_pydev_execfile.py"", line 18, in execfile
    exec(compile(contents+""\n"", file, 'exec'), glob, loc)
  File ""/media/zz/data/.py"", line 409, in <module>
    main()
  File ""/media/zz/data/all_process_test_GRU.py"", line 346, in main
    train_model(new_train_data, y_train, new_vali_data, y_vali, result_path_1st, hidden_nodes[j])
  File ""/media/zz/data/all_process_test_GRU.py"", line 206, in train_model
    dropout_rate=dropout_rate, learning_rate=learning_rate)
  File ""/media/zz/data/all_process_test_GRU.py"", line 143, in build_model_GRU
    lstm1 = CuDNNGRU(units,  stateful=False, return_sequences=True)(inputs1)
  File ""/home/zz/anaconda3/lib/python3.6/site-packages/keras/layers/recurrent.py"", line 541, in __call__
    return super(RNN, self).__call__(inputs, **kwargs)
  File ""/home/zz/anaconda3/lib/python3.6/site-packages/keras/engine/base_layer.py"", line 489, in __call__
    output = self.call(inputs, **kwargs)
  File ""/home/zz/anaconda3/lib/python3.6/site-packages/keras/layers/cudnn_recurrent.py"", line 81, in call
    if len(initial_state) != len(self.states):
  File ""/home/zz/anaconda3/lib/python3.6/site-packages/keras/layers/recurrent.py"", line 438, in states
    num_states = len(self.cell.state_size)
TypeError: object of type 'numpy.int64' has no len()


**Code to reproduce the issue**  
```
def build_model_GRU(timesteps, features, units, dropout_rate, learning_rate):
    inputs1 = Input(shape=(timesteps, features[0]))
    lstm1 = CuDNNGRU(units,  stateful=False, return_sequences=True)(inputs1)
    drop_layer1 = Dropout(dropout_rate)(lstm1)
    dense_1 = Dense(units, activation='relu')(drop_layer1)
    average_pooling1 = GlobalAveragePooling1D()(dense_1)

    inputs2 = Input(shape=(timesteps, features[1]))
    lstm2 = CuDNNGRU(units,  stateful=False, return_sequences=True)(inputs2)
    drop_layer2 = Dropout(dropout_rate)(lstm2)
    dense_2 = Dense(units, activation='relu')(drop_layer2)
    average_pooling2 = GlobalAveragePooling1D()(dense_2)

    inputs3 = Input(shape=(timesteps, features[2]))
    lstm3 = CuDNNGRU(units,  stateful=False, return_sequences=True)(inputs3)
    drop_layer3 = Dropout(dropout_rate)(lstm3)
    dense_3 = Dense(units, activation='relu')(drop_layer3)
    average_pooling3 = GlobalAveragePooling1D()(dense_3)

    merged = concatenate([average_pooling1, average_pooling2, average_pooling3])
    dense_all = Dense(10, activation='relu')(merged)
    output = Dense(2, activation='sigmoid')(dense_all)
    model = Model(inputs=[inputs1, inputs2, inputs3], outputs=output)
    opt = keras.optimizers.Adam(learning_rate, decay=1e-5)
    model.compile(loss=[focal_loss(alpha=0.25, gamma=2)], optimizer=opt,
                  metrics=['acc'])
    return model

n_timesteps=100
n_features=np.array([10,40,80])
n_units=32
dropout_rate=0.5
learning_rate=0.00001
model = build_model_GRU(timesteps=n_timesteps, features=n_features, units=n_units, dropout_rate=dropout_rate, learning_rate=learning_rate)
```",zzstefan,None,2020-02-20T17:16:01Z,2020-02-20T22:23:45Z
13808,Changing i to i-1 to correct the embedding matrix,"<!--
Please make sure you've read and understood our contributing guidelines;
https://github.com/keras-team/keras/blob/master/CONTRIBUTING.md

Note:
We are no longer adding new features to multi-backend Keras (we only fix bugs), as we are refocusing development efforts on tf.keras. If you are still interested in submitting a feature pull request, please direct it to tf.keras in the TensorFlow repository instead.
-->

### Summary

Change the loop index so that the embedding matrix is built correctly.

### Related Issues

This embedding_matrix[i] = embedding_vector should be embedding_matrix[i-1] = embedding_vector.

The loop starts from index 1 in word_index.items(), so this ""i"" starts as 1. Therefore, it always ignores the first row of the embedding matrix (leaving it all zeros) and shifts every word embedding vector backward, so that each word now has the vector of its previous word.

The Keras blog post can be found at [here](https://blog.keras.io/using-pre-trained-word-embeddings-in-a-keras-model.html).

### PR Overview

- [ ] This PR requires new unit tests [y/n] (make sure tests are included)
- [x] This PR requires to update the documentation [y/n] (make sure the docs are up-to-date)
- [x] This PR is backwards compatible [y/n]
- [ ] This PR changes the current API [y/n] (all API changes need to be approved by fchollet)",chrisliu298,None,2020-02-20T02:47:02Z,2020-02-20T03:24:38Z
13789,Keras fit generator - ValueError: Failed to find data adapter that can handle input,"Hey, I'm trying to fit my deep learning model with a custom generator.

When i fit the model, it shows me this error:
`Traceback (most recent call last):
  File ""/home/castilho/PycharmProjects/Chargrid/Chargrid/main.py"", line 201, in <module>
    target_path=target_path, prefix=prefix_splits, make_new_representation=False, train=True)
  File ""/home/castilho/PycharmProjects/Chargrid/Chargrid/main.py"", line 117, in main
    nn.train(representations_path=representations_path, target_path=target_path, training_filenames = data['train_imgs'], validation_filenames=data['val_imgs'])
  File ""/home/castilho/PycharmProjects/Chargrid/Chargrid/neural_network.py"", line 150, in train
    validation_steps=int(len(validation_filenames) // batch_size))
  File ""/home/castilho/PycharmProjects/Chargrid/venv/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py"", line 819, in fit
    use_multiprocessing=use_multiprocessing)
  File ""/home/castilho/PycharmProjects/Chargrid/venv/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py"", line 235, in fit
    use_multiprocessing=use_multiprocessing)
  File ""/home/castilho/PycharmProjects/Chargrid/venv/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py"", line 533, in _process_training_inputs
    adapter_cls = data_adapter.select_data_adapter(x, y)
  File ""/home/castilho/PycharmProjects/Chargrid/venv/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/data_adapter.py"", line 998, in select_data_adapter
    _type_name(x), _type_name(y)))
ValueError: Failed to find data adapter that can handle input: <class 'Chargrid.dataset_generator.RepresentationGenerator'>, <class 'NoneType'>

Process finished with exit code 1
`



I this this a bug in Keras. Below, is a part of the code when i fit the model.
`       def train(self, representations_path: str, target_path: str, training_filenames: list, validation_filenames: list,
              batch_size: int = 7):
        
        train_generator = RepresentationGenerator(representation_path=representations_path, target_path=target_path,
                                                  filenames=training_filenames, batch_size=batch_size)
        val_generator = RepresentationGenerator(representation_path=representations_path, target_path=target_path,
                                                filenames=validation_filenames, batch_size=batch_size)
        self.model_semantic.fit(x=train_generator, batch_size=7,
                                steps_per_epoch=int(len(training_filenames) // batch_size),
                                epochs=10,
                                verbose=1,
                                validation_data=val_generator,
                                validation_steps=int(len(validation_filenames) // batch_size))
        return 0`


My class RepresentationGenerator is:

`from tensorflow_core.python.keras.utils.data_utils import Sequence


class RepresentationGenerator(Sequence):

    def __init__(self, representation_path, target_path, filenames, batch_size):
        self.filenames = np.array(filenames)
        self.batch_size = batch_size
        self.representation_path = representation_path
        self.target_path = target_path

    def __len__(self):
        return (np.ceil(len(self.filenames) / float(self.batch_size))).astype(np.int)

    def __getitem__(self, idx):
        files_to_batch = self.filenames[idx * self.batch_size: (idx + 1) * self.batch_size]
        batch_x, batch_y = [], []
        for file in files_to_batch:
            batch_x.append(np.load(self.representation_path + file + "".npy"", allow_pickle=True))
            batch_y.append(np.load(self.target_path + file + "".npy"", allow_pickle=True))

        return np.array(batch_x), np.array(batch_y)
`


When i fit the model with a generator, the variable Y assume as None and it shows the error above. How can i fix that?

**System information**  
- Have I written custom code (as opposed to using example directory):  Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  Linux Ubuntu 18.04
- TensorFlow backend (yes / no):  Yes
- TensorFlow version:  2.1.0
- Keras version:  2.3.1
- Python version:  3.6
- GPU model and memory:  NVIDIA Corporation GP108M [GeForce MX250]


",castilho25,b'type:support',2020-02-17T10:35:58Z,2020-02-28T12:31:11Z
13777,BUG: Shape inference now works for transposed convolutions,"### Summary
Wrong backend call (K.shape instead of K.int_shape) resulted in undefined output shapes when using transposed convolutions, both when using or not using the output_padding argument.

### PR Overview

- [ ] This PR requires new unit tests [y/n] (make sure tests are included)
- [ ] This PR requires to update the documentation [y/n] (make sure the docs are up-to-date)
- [X] This PR is backwards compatible [y/n]
- [ ] This PR changes the current API [y/n] (all API changes need to be approved by fchollet)
",davideboschetto,None,2020-02-14T15:07:13Z,2020-02-14T15:58:54Z
13762,model.predict() gives different results when batch_size =1 using Batch Norm,"<em>Please make sure that this is a Bug or a Feature Request and provide all applicable information asked by the template.
If your issue is an **implementation question**, please ask your question on [StackOverflow](http://stackoverflow.com/questions/tagged/keras) or [on the Keras Slack channel](https://keras-slack-autojoin.herokuapp.com/) instead of opening a GitHub issue.</em>  

**System information**  
- Have I written custom code (as opposed to using example directory):  No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  Ubuntu 18.04 LTS
- TensorFlow backend (yes / no):  yes
- TensorFlow version:  2.1.0
- Keras version:  2.2.4-tf
- Python version:  3.6.7
- CUDA/cuDNN version:  
- GPU model and memory:  

You can obtain the TensorFlow version with:  
python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""  
You can obtain the Keras version with:  
python -c 'import keras as k; print(k.__version__)'  

**Describe the current behavior**  
Running model.predict() on a batch gives accurate values. However, when run on a single sample, i.e. batch size 1 gives same output [8] on every individual sample of the original batch. 
**Describe the expected behavior**  
Running predict() on batch_size = 1 should not result in the above behavior
**Code to reproduce the issue**  
Testing the behaviour of batch norm layer in keras using MNIST number dataset using the model from the original BatchNorm paper. Using 3 dense layers (100 units each) with 3 adjacent bnorm layers and a final dense layer with 10 units; input flattened from 28*28 to 784; batch size = 60; no activation for the final layer. Please find attached is .h5 (fmt: model_{epoch}-{val_loss}) file for the model
[model_10-0.119.zip](https://github.com/keras-team/keras/files/4185898/model_10-0.119.zip)


**Other info / logs**  
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.  
",sameervk,None,2020-02-11T13:35:23Z,2020-02-11T16:43:42Z
13742,Incorrect archive link provided for missing cudart64_100.dll,"<em>Please make sure that this is a Bug or a Feature Request and provide all applicable information asked by the template.
If your issue is an **implementation question**, please ask your question on [StackOverflow](http://stackoverflow.com/questions/tagged/keras) or [on the Keras Slack channel](https://keras-slack-autojoin.herokuapp.com/) instead of opening a GitHub issue.</em>  

**System information**  
- Have I written custom code (as opposed to using example directory):  No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  Windows 10 v1809 Build 
- TensorFlow backend (yes / no):  yes
- TensorFlow version:  1.14.0
- Keras version:  2.2.5
- Python version:  3.7.4
- CUDA/cuDNN version:  9
- GPU model and memory:  Nvidia Geforce GTX 1050Ti - 4GB

You can obtain the TensorFlow version with:  
python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""  
You can obtain the Keras version with:  
python -c 'import keras as k; print(k.__version__)'  

**Describe the current behavior**  
The archive link provided for cuda point to 9.0
https://developer.nvidia.com/cuda-90-download-archive

**Describe the expected behavior**  
The download link should currently point to 10:
https://developer.nvidia.com/cuda-10.1-download-archive-update2

**Code to reproduce the issue**  
Provide a reproducible test case that is the bare minimum necessary to generate the problem.  

**Other info / logs**  
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.  

```py
>>> import keras
Using TensorFlow backend.
Traceback (most recent call last):
  File ""C:\Users\drago\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow\python\platform\self_check.py"", line 75, in preload_check
    ctypes.WinDLL(build_info.cudart_dll_name)
  File ""C:\Users\drago\AppData\Local\Programs\Python\Python37\lib\ctypes\__init__.py"", line 364, in __init__
    self._handle = _dlopen(self._name, mode)
OSError: [WinError 126] The specified module could not be found

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""C:\Users\drago\AppData\Local\Programs\Python\Python37\lib\site-packages\keras\__init__.py"", line 3, in <module>
    from . import utils
  File ""C:\Users\drago\AppData\Local\Programs\Python\Python37\lib\site-packages\keras\utils\__init__.py"", line 6, in <module>
    from . import conv_utils
  File ""C:\Users\drago\AppData\Local\Programs\Python\Python37\lib\site-packages\keras\utils\conv_utils.py"", line 9, in <module>
    from .. import backend as K
  File ""C:\Users\drago\AppData\Local\Programs\Python\Python37\lib\site-packages\keras\backend\__init__.py"", line 1, in <module>
    from .load_backend import epsilon
  File ""C:\Users\drago\AppData\Local\Programs\Python\Python37\lib\site-packages\keras\backend\load_backend.py"", line 89, in <module>
    from .tensorflow_backend import *
  File ""C:\Users\drago\AppData\Local\Programs\Python\Python37\lib\site-packages\keras\backend\tensorflow_backend.py"", line 5, in <module>
    import tensorflow as tf
  File ""C:\Users\drago\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow\__init__.py"", line 28, in <module>
    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import
  File ""C:\Users\drago\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow\python\__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""C:\Users\drago\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 30, in <module>
    self_check.preload_check()
  File ""C:\Users\drago\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow\python\platform\self_check.py"", line 82, in preload_check
    % (build_info.cudart_dll_name, build_info.cuda_version_number))
ImportError: Could not find 'cudart64_100.dll'. TensorFlow requires that this DLL be installed in a directory that is named in your %PATH% environment variable. Download and install CUDA 10.0 from this URL: https://developer.nvidia.com/cuda-90-download-archive
```",Hyperclaw79,b'type:bug/performance',2020-02-04T14:46:56Z,2020-02-20T15:54:06Z
13709,"ValueError: Error when checking input: expected input_1 to have 5 dimensions, but got array with shape (1221, 50, 50, 1)","<em>Please make sure that this is a Bug or a Feature Request and provide all applicable information asked by the template.
If your issue is an **implementation question**, please ask your question on [StackOverflow](http://stackoverflow.com/questions/tagged/keras) or [on the Keras Slack channel](https://keras-slack-autojoin.herokuapp.com/) instead of opening a GitHub issue.</em>  

**System information**  
- Have I written custom code (as opposed to using example directory):  
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  
- TensorFlow backend (yes / no):  
- TensorFlow version:  
- Keras version:  
- Python version:  
- CUDA/cuDNN version:  
- GPU model and memory:  

You can obtain the TensorFlow version with:  
python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""  
You can obtain the Keras version with:  
python -c 'import keras as k; print(k.__version__)'  

**Describe the current behavior**  

**Describe the expected behavior**  

**Code to reproduce the issue**  
Provide a reproducible test case that is the bare minimum necessary to generate the problem.  

**Other info / logs**  
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.  
",rustombhesania,b'backend:tensorflow type:support',2020-01-20T10:16:59Z,2020-02-04T07:58:27Z
13679,"Training Script failed with no Error Stack ""exit code 1073740791 0xc0000409""","-Keras Version: 2.3.1
-Tensorflow Version: 2.0
-OS: Windows 10
-Running on: CPU Processor	Intel(R) Core(TM) i7-8850H
-Developed in: PyCharm

I'm attempting to build a novel model using an implementation of a highway layer (implementation found at: https://gist.github.com/iskandr/a874e4cf358697037d14a17020304535). There was a typo listed on this page which is corrected in my copy of the code.

I have a simplified version of the code I'm using below:

```python
import scipy.io as io
import os
import numpy as np
from keras import layers, losses, Input
from keras.models import Model
from keras2_highway_network import highway_layers

def simple_generator(dim1, dim2, dim3, batch_size=5):
    while True:
        samples = np.random.random_sample((batch_size, dim1, dim2, dim3))
        targets = np.random.random_sample((batch_size, 3))
        yield samples, targets

example_shape = (1100, 4096, 2)

train_gen = simple_generator(example_shape[0], example_shape[1], example_shape[2], batch_size=10)
val_gen = simple_generator(example_shape[0], example_shape[1], example_shape[2])
test_gen = simple_generator(example_shape[0], example_shape[1], example_shape[2])

input_tensor = Input(shape=example_shape)
x = layers.Conv2D(32, 3, activation='relu')(input_tensor)
x = layers.MaxPool2D(pool_size=(3, 3), strides=3)(x)
x = layers.Dense(32, activation='relu')(x)
x = highway_layers(x, 32, activation='relu')
x = highway_layers(x, 32, activation='relu')
x = highway_layers(x, 32, activation='relu')
x = layers.Conv2D(32, 3, activation='relu')(x)
x = layers.MaxPool2D(pool_size=(3, 3), strides=3)(x)
x = layers.Dense(16, activation='relu')(x)
x = highway_layers(x, 16, activation='relu')
x = highway_layers(x, 16, activation='relu')
x = highway_layers(x, 16, activation='relu')
x = layers.Flatten()(x)
output_tensor = layers.Dense(3)(x)

model = Model(input_tensor, output_tensor)

model.compile(loss=losses.mean_absolute_error, optimizer='sgd')
model.summary()

history = model.fit_generator(generator=train_gen, steps_per_epoch=25, epochs=12, validation_data=val_gen, validation_steps=10, verbose=True)
```

The resulting network has around 2.5 million parameters, which despite the warnings my machine prints it can handle no problem. Once training begins I get a warning about the amount of memory I'm using, which I expect, and then the script simply stops running. The only stack trace I get is: ""exit code 1073740791 0xc0000409""

I have seen this is one other issue that was raised in this git, however it has been tagged as ""stale"" with no answer posted, so I thought I'd ask again.

Thanks in advance for your time!
All the best,
Oisín.


",OisinWatkins,b'backend:tensorflow type:bug/performance',2020-01-09T12:11:12Z,2020-02-06T10:56:01Z
13657,Keras 2.3.1 PyQt5 QThread '_thread._local' object has no attribute 'value',"`tensorflow==2.1.0
Keras==2.3.1`

self.model.add(Dense(units=128, input_dim=input_dim, kernel_initializer=self.init, activation='relu'))

throw:

`if _SYMBOLIC_SCOPE.value:
AttributeError: '_thread._local' object has no attribute 'value'
`

but

`tensorflow==1.14
Keras==2.2.5`

OK",tinyms,b'backend:tensorflow type:bug/performance',2019-12-28T16:29:22Z,2020-01-06T08:25:16Z
13636,Update datasets.md,"Failure in the code where the order order of the tuples is incorrect.

<!--
Please make sure you've read and understood our contributing guidelines;
https://github.com/keras-team/keras/blob/master/CONTRIBUTING.md

Note:
We are no longer adding new features to multi-backend Keras (we only fix bugs), as we are refocusing development efforts on tf.keras. If you are still interested in submitting a feature pull request, please direct it to tf.keras in the TensorFlow repository instead.
-->

### Summary

### Related Issues

### PR Overview

- [ ] This PR requires new unit tests [y/n] (make sure tests are included)
- [x] This PR requires to update the documentation [y/n] (make sure the docs are up-to-date)
- [x] This PR is backwards compatible [y/n]
- [ ] This PR changes the current API [y/n] (all API changes need to be approved by fchollet)
",MagicElyas,None,2019-12-14T14:16:50Z,2019-12-15T09:49:30Z
13618,Fixed Capsule Implementation,"<!--
Please make sure you've read and understood our contributing guidelines;
https://github.com/keras-team/keras/blob/master/CONTRIBUTING.md

Note:
We are no longer adding new features to multi-backend Keras (we only fix bugs), as we are refocusing development efforts on tf.keras. If you are still interested in submitting a feature pull request, please direct it to tf.keras in the TensorFlow repository instead.
-->

### Summary
Modified past version of the ""cifar10_cnn_capsule.py"" so that it works with the latest version. TF/Keras changed the batch_dot implementation, so this version skips batch_dot in favor for an included ""caps_batch_dot"" function.

### Related Issues
Relies on tf.matmul, because K.dot modifies the dimensions, due to the Numpy implementation.

### PR Overview

- [ n  ] This PR requires new unit tests [y/n] (make sure tests are included)
- [ y (examples) ] This PR requires to update the documentation [y/n] (make sure the docs are up-to-date)
- [ y ] This PR is backwards compatible [y/n]
- [ n ] This PR changes the current API [y/n] (all API changes need to be approved by fchollet)
",ns3284,None,2019-12-10T10:34:19Z,2019-12-10T10:38:42Z
13549,"fit_generator is slow, and I/O ain't the cause","OS: Ubuntu Server 18.04, with xanmod kernel
Python: Anaconda 3.7
Tensorflow: 2.0.0 MKL
Keras: TF built-in
CPU: Intel(R) Core(TM)2 Quad CPU Q9300
No GPU
model.fit works as expected
```
import numpy as np
import tensorflow.keras as keras
from tensorflow.keras.layers import *
from tensorflow.keras.models import Model
from tensorflow.keras.regularizers import l2
from tensorflow.keras import optimizers
from tensorflow.keras import backend as K
import time, itertools, random

def makeModel(arch, constructor, name):
    inputs = Input(arch)
    model = Model(inputs, constructor(inputs), name=name)
    try:
        model.load_weights(""%s.h5""%name)
    except:
        print(""new %s""%name)
    return model

def saveModel(model):
    model.save_weights(""%s.h5""%model.name)

def g():
    return l2(.00001)

def sr2x(obj):
    for i in range(4):
        obj = Conv1D(96, 1, activation='tanh', kernel_initializer='he_uniform', kernel_regularizer=g(), bias_regularizer=g())(obj)
        obj = GaussianNoise(.001)(obj)
    obj = Conv1D(96, 1, kernel_initializer='he_uniform', kernel_regularizer=g(), bias_regularizer=g())(obj)
    obj = Lambda(lambda x: K.sum(x, axis=1))(obj)
    obj = Reshape((3, 32))(obj)
    obj = Activation(""softmax"")(obj)
    return obj

sr = makeModel((None, 5,), sr2x, ""sr2x"")
sr.summary()
sr.compile(optimizer=optimizers.Adam(.00001), loss='categorical_crossentropy', metrics=['categorical_accuracy'])
i = 0

data = np.mgrid[0:32, 0:32, 0:32].T.reshape(-1, 3)
inp = np.dstack(((np.exp(np.float32(data[:, None])*.1789)-1.0)/255.0, np.zeros((len(data), 1, 2), dtype=np.float32)))
out = keras.utils.to_categorical(data, 32)

print(inp.shape, out.shape)

class MyCallback(keras.callbacks.Callback):
    def on_epoch_end(self, epoch, logs=None):
        saveModel(sr)

try:
    sr.fit(inp, out, 32, epochs=100, callbacks=[MyCallback()])
except KeyboardInterrupt:
    print(""one second..."")
    time.sleep(1)
    print(""saving..."")
saveModel(sr)
print(""saved..."")
```
model.fit_generator is 16x slower. No I/O is performed. My tests show 60000hz minimum performance outside keras.
```
import numpy as np
import tensorflow.keras as keras
from tensorflow.keras.layers import *
from tensorflow.keras.models import Model
from tensorflow.keras.regularizers import l2
from tensorflow.keras import optimizers
from tensorflow.keras import backend as K
import time, itertools, random

def makeModel(arch, constructor, name):
    inputs = Input(arch)
    model = Model(inputs, constructor(inputs), name=name)
    try:
        model.load_weights(""%s.h5""%name)
    except:
        print(""new %s""%name)
    return model

def saveModel(model):
    model.save_weights(""%s.h5""%model.name)

def g():
    return l2(.00001)

def sr2x(obj):
    for i in range(4):
        obj = Conv1D(96, 1, activation='tanh', kernel_initializer='he_uniform', kernel_regularizer=g(), bias_regularizer=g())(obj)
        obj = GaussianNoise(.001)(obj)
    obj = Conv1D(96, 1, kernel_initializer='he_uniform', kernel_regularizer=g(), bias_regularizer=g())(obj)
    obj = Lambda(lambda x: K.sum(x, axis=1))(obj)
    obj = Reshape((3, 32))(obj)
    obj = Activation(""softmax"")(obj)
    return obj

sr = makeModel((None, 5,), sr2x, ""sr2x"")
sr.summary()
sr.compile(optimizer=optimizers.Adam(.00001), loss='categorical_crossentropy', metrics=['categorical_accuracy'])
i = 0



def sampler():
    data = np.mgrid[0:32, 0:32, 0:32].T.reshape(-1, 3)
    inp = np.dstack(((np.exp(np.float32(data[:, None])*.1789)-1.0)/255.0, np.zeros((len(data), 1, 2), dtype=np.float32)))
    out = keras.utils.to_categorical(data, 32)
    rg = np.arange(len(inp), dtype=np.uint32)
    while True:
        np.random.shuffle(rg)
        inpc = inp[rg]
        outc = out[rg]
        for i in range(0, len(rg), 32):
            yield inpc[i:i+32], outc[i:i+32]

class MyCallback(keras.callbacks.Callback):
    def on_epoch_end(self, epoch, logs=None):
        saveModel(sr)

try:
    sr.fit_generator(sampler(), steps_per_epoch=1024, epochs=100, callbacks=[MyCallback()])
except KeyboardInterrupt:
    print(""one second..."")
    time.sleep(1)
    print(""saving..."")
saveModel(sr)
print(""saved..."")
```
Edit: fixed the bug. Data was not shuffled properly.",ghost,b'backend:tensorflow type:bug/performance',2019-11-13T07:13:09Z,2019-11-27T11:56:13Z
13538,Slow import of Keras array_to_img,"trying upload just one function from eras take me considerable time 
this is on ubuntu 18.04 under aws 
other functions such as bumpy are ok 
this is the only line of code I expect it to be much faster maybe 0.2 sec not 1+ why is it like so and is it solvable? how ? 
I hope this is a legit question I looked on the internet and did not find any hint of what to do.

<from keras.preprocessing.image import array_to_img > 

2019-11-10 10:09:51,380 - root - DEBUG - np 1 1573380591.3805187
2019-11-10 10:09:52,989 - root - DEBUG - tf 1 1573380592.9898841
",sivi29y,b'backend:tensorflow type:bug/performance',2019-11-10T10:23:39Z,2019-12-17T09:11:59Z
13511,Fix too many values to unpack error,"In the example script lstm_seq2seq_restore.py and lstm_seq2seq.py, when
parse the data using line.split(""\t""), it will return 3 values rather than2, a simple modification can fix it.

<!--
Please make sure you've read and understood our contributing guidelines;
https://github.com/keras-team/keras/blob/master/CONTRIBUTING.md

Note:
We are no longer adding new features to multi-backend Keras (we only fix bugs), as we are refocusing development efforts on tf.keras. If you are still interested in submitting a feature pull request, please direct it to tf.keras in the TensorFlow repository instead.
-->

### Summary

### Related Issues

### PR Overview

- [ ] This PR requires new unit tests [y/n] (make sure tests are included)
- [ ] This PR requires to update the documentation [y/n] (make sure the docs are up-to-date)
- [x] This PR is backwards compatible [y/n]
- [ ] This PR changes the current API [y/n] (all API changes need to be approved by fchollet)
",xemcerk,None,2019-11-01T08:09:02Z,2020-04-02T09:09:30Z
13494,a new class for realizing Early Stopping,"<!--
Please make sure you've read and understood our contributing guidelines;
https://github.com/keras-team/keras/blob/master/CONTRIBUTING.md

Note:
We are no longer adding new features to multi-backend Keras (we only fix bugs), as we are refocusing development efforts on tf.keras. If you are still interested in submitting a feature pull request, please direct it to tf.keras in the TensorFlow repository instead.
-->

### Summary

I want to add a new class for realizing Early Stopping. I have already implemented the class in my own code.

It is based on 3 metrics from paper ""Early Stopping - but when? Lutz Prechelt, University Karlsrhe"". 

1. **Generalization Loss**(GL). GL can be described as a metric that can measure how much current validation loss exceeds the lowest validation loss. Training will stop as soon as GL exceeds a certain threshold. 

2. **Progress Quotient**(PQ).  It considers training strip of length `k`. Progress means how much was the average training error during the strip larger than the minimum training error during the strip. Quotient means use the quotient of GL and Progress. Thus, training will stop as soon as the PQ exceeds a certain threshold. 

3. **UP**. This is simple. Training will stop when the generalization error increased in `s` successive strips.

Combining these metrics, there are 5 modes for doing early stopping. 1, 2, 3, 1+3, 2+3.

I think basically all workers using Keras will be beneficial from this.

Now the EarlyStopping class of Keras can only stop training based on patience and delta, whereas there are advanced and useful early stopping methods.

### Related Issues

This idea comes from others paper, I just realized it. For further info, please refer to the paper.
[early stopping - but when.pdf](https://github.com/keras-team/keras/files/3774689/early.stopping.-.but.when.pdf)


### PR Overview

- [ ] This PR requires new unit tests [n] (make sure tests are included)
- [x] This PR requires to update the documentation [y] (make sure the docs are up-to-date)
- [ ] This PR is backwards compatible [y/n]
- [ ] This PR changes the current API [n] (all API changes need to be approved by fchollet)
",wubowen416,None,2019-10-26T09:42:34Z,2019-10-28T14:13:41Z
13490,WIP: Travis CI: Upgrade from Python 3.6 to 3.8,"WIP: Do not merge.  https://docs.python.org/3/whatsnew/3.8.html

<!--
Please make sure you've read and understood our contributing guidelines;
https://github.com/keras-team/keras/blob/master/CONTRIBUTING.md

Note:
We are no longer adding new features to multi-backend Keras (we only fix bugs), as we are refocusing development efforts on tf.keras. If you are still interested in submitting a feature pull request, please direct it to tf.keras in the TensorFlow repository instead.
-->

### Summary

### Related Issues

### PR Overview

- [ ] This PR requires new unit tests [y/n] (make sure tests are included)
- [ ] This PR requires to update the documentation [y/n] (make sure the docs are up-to-date)
- [ ] This PR is backwards compatible [y/n]
- [ ] This PR changes the current API [y/n] (all API changes need to be approved by fchollet)
",cclauss,None,2019-10-24T10:14:55Z,2019-10-24T10:17:53Z
13481,Update np_utils.py,"<!--
Please make sure you've read and understood our contributing guidelines;
https://github.com/keras-team/keras/blob/master/CONTRIBUTING.md

Note:
We are no longer adding new features to multi-backend Keras (we only fix bugs), as we are refocusing development efforts on tf.keras. If you are still interested in submitting a feature pull request, please direct it to tf.keras in the TensorFlow repository instead.
-->

### Summary
Fixing words in document 'Utils'
I changed 'Numpy' -> 'NumPy'
### Related Issues

### PR Overview

- [N] This PR requires new unit tests [y/n] (make sure tests are included)
- [Y] This PR requires to update the documentation [y/n] (make sure the docs are up-to-date)
- [N] This PR is backwards compatible [y/n]
- [N] This PR changes the current API [y/n] (all API changes need to be approved by fchollet)
",Denny-Hwang,None,2019-10-22T01:16:16Z,2019-10-24T19:52:19Z
13478,Trying to fix the mean_iou test,"<!--
Please make sure you've read and understood our contributing guidelines;
https://github.com/keras-team/keras/blob/master/CONTRIBUTING.md

Note:
We are no longer adding new features to multi-backend Keras (we only fix bugs), as we are refocusing development efforts on tf.keras. If you are still interested in submitting a feature pull request, please direct it to tf.keras in the TensorFlow repository instead.
-->

### Summary

### Related Issues

### PR Overview

- [ ] This PR requires new unit tests [y/n] (make sure tests are included)
- [ ] This PR requires to update the documentation [y/n] (make sure the docs are up-to-date)
- [ ] This PR is backwards compatible [y/n]
- [ ] This PR changes the current API [y/n] (all API changes need to be approved by fchollet)
",gabrieldemarmiesse,None,2019-10-21T15:45:23Z,2019-10-21T16:08:01Z
13477,Fix h5py group naming while model saving,"<!--
Please make sure you've read and understood our contributing guidelines;
https://github.com/keras-team/keras/blob/master/CONTRIBUTING.md

Note:
We are no longer adding new features to multi-backend Keras (we only fix bugs), as we are refocusing development efforts on tf.keras. If you are still interested in submitting a feature pull request, please direct it to tf.keras in the TensorFlow repository instead.
-->

### Summary

This pull request is related to issue [#12195 ](url). There is a bug while saving .h5 models. In a model, if a layer name is prefix of a previously defined layer name, then h5py will fail with error: ""ValueError: Unable to create group (name already exists)"".

```
Traceback (most recent call last):
  File ""$PATH/test.py"", line 12, in <module>
    model.save_weights('test.h5')
  File ""$PATH/keras/keras/engine/saving.py"", line 449, in save_wrapper
    save_function(obj, filepath, overwrite, *args, **kwargs)
  File ""$PATH/keras/keras/engine/network.py"", line 1184, in save_weights
    saving.save_weights_to_hdf5_group(f, self.layers)
  File ""$PATH/keras/keras/engine/saving.py"", line 748, in save_weights_to_hdf5_group
    g = group.create_group(layer.name)
  File ""$PATH/keras_pr_py3/lib/python3.5/site-packages/h5py/_hl/group.py"", line 68, in create_group
    gid = h5g.create(self.id, name, lcpl=lcpl, gcpl=gcpl)
  File ""h5py/_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper
  File ""h5py/_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper
  File ""h5py/h5g.pyx"", line 161, in h5py.h5g.create
ValueError: Unable to create group (name already exists)

```

This problem is even more present in Tensorflow 2.0 because saving a model with tf.ones_like, tf.zeros_like, tf.boolean_mask, ...  Tensors will lead to this error.

The first commit of this pull request sorts the model layers by name to ensure that h5py group names are strictly growing to avoid prefix issues. File: keras/engine/saving.py
The second commit of this pull request add a test described problem.
Function: test_saving_group_naming_h5py() in File: tests/test_model_saving.py


### Related Issues
Fixes #12195 .

### PR Overview

- [y] This PR requires new unit tests [y/n] (make sure tests are included)
     Included in second commit
- [n] This PR requires to update the documentation [y/n] (make sure the docs are up-to-date)
- [y] This PR is backwards compatible [y/n]
- [n] This PR changes the current API [y/n] (all API changes need to be approved by fchollet)
",Tbuhet,None,2019-10-21T14:28:52Z,2019-10-22T14:14:40Z
13472,Update core.py,"<!--
Please make sure you've read and understood our contributing guidelines;
https://github.com/keras-team/keras/blob/master/CONTRIBUTING.md

Note:
We are no longer adding new features to multi-backend Keras (we only fix bugs), as we are refocusing development efforts on tf.keras. If you are still interested in submitting a feature pull request, please direct it to tf.keras in the TensorFlow repository instead.
-->

### Summary
`channels_first` -> `'channels_first'`
`channels_last`, ""channels_last"" -> `'channels_last'`


data_format='channels_first' -> `data_format='channels_first'`
data_format='channels_last' -> `data_format='channels_last'`

### Related Issues

### PR Overview

- [n] This PR requires new unit tests [y/n] (make sure tests are included)
- [y] This PR requires to update the documentation [y/n] (make sure the docs are up-to-date)
- [y] This PR is backwards compatible [y/n]
- [n] This PR changes the current API [y/n] (all API changes need to be approved by fchollet)
",Naruu,None,2019-10-20T11:38:16Z,2019-10-21T13:46:18Z
13471,Update local.py,"

<!--
Please make sure you've read and understood our contributing guidelines;
https://github.com/keras-team/keras/blob/master/CONTRIBUTING.md

Note:
We are no longer adding new features to multi-backend Keras (we only fix bugs), as we are refocusing development efforts on tf.keras. If you are still interested in submitting a feature pull request, please direct it to tf.keras in the TensorFlow repository instead.
-->

### Summary
`channels_first` ->`'channels_first'`.
`channels_last` -> `'channels_last'`.

data_format='channels_first' -> `data_format='channels_first'`
data_format='channels_last' -> `data_format='channels_last'`
### Related Issues

### PR Overview

- [n] This PR requires new unit tests [y/n] (make sure tests are included)
- [y] This PR requires to update the documentation [y/n] (make sure the docs are up-to-date)
- [y] This PR is backwards compatible [y/n]
- [n] This PR changes the current API [y/n] (all API changes need to be approved by fchollet)
",Naruu,None,2019-10-20T04:05:36Z,2019-10-20T04:06:48Z
13467,Update pooling.py,"<!--
Please make sure you've read and understood our contributing guidelines;
https://github.com/keras-team/keras/blob/master/CONTRIBUTING.md

Note:
We are no longer adding new features to multi-backend Keras (we only fix bugs), as we are refocusing development efforts on tf.keras. If you are still interested in submitting a feature pull request, please direct it to tf.keras in the TensorFlow repository instead.
-->

### Summary
Added Integer at the `pool_size` and `strides`  of `MaxPooling3D`, `AveragePooling3D`
Made `strides` argument have all same format

`channels_first` ->`""channels_first""`
`channels_last` ->`""channels_last""`
  ""channels_last""->`""channels_last""`

### Related Issues

### PR Overview

- [n] This PR requires new unit tests [y/n] (make sure tests are included)
- [y] This PR requires to update the documentation [y/n] (make sure the docs are up-to-date)
- [y] This PR is backwards compatible [y/n]
- [n] This PR changes the current API [y/n] (all API changes need to be approved by fchollet)
",Naruu,None,2019-10-19T14:19:29Z,2019-10-21T13:43:47Z
13447,tf tensorflow ,"<em>Please make sure that this is a Bug or a Feature Request and provide all applicable information asked by the template.
If your issue is an **implementation question**, please ask your question on [StackOverflow](http://stackoverflow.com/questions/tagged/keras) or [on the Keras Slack channel](https://keras-slack-autojoin.herokuapp.com/) instead of opening a GitHub issue.</em>  

**System information**  
- Have I written custom code (as opposed to using example directory):  
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  
- TensorFlow backend (yes / no):  
- TensorFlow version:  
- Keras version:  
- Python version:  
- CUDA/cuDNN version:  
- GPU model and memory:  

You can obtain the TensorFlow version with:  
python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""  
You can obtain the Keras version with:  
python -c 'import keras as k; print(k.__version__)'  

**Describe the current behavior**  
Does anyone know about Sum Pooling layer or SPoC operation available for keras 

tf tensorflow
**Describe the expected behavior**  

**Code to reproduce the issue**  
Provide a reproducible test case that is the bare minimum necessary to generate the problem.  

**Other info / logs**  
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.  
",tensorflowbutler,None,2019-10-16T22:41:59Z,2019-10-16T22:44:26Z
13446,Update CONTRIBUTING.md,"<!--
Please make sure you've read and understood our contributing guidelines;
https://github.com/keras-team/keras/blob/master/CONTRIBUTING.md

Note:
We are no longer adding new features to multi-backend Keras (we only fix bugs), as we are refocusing development efforts on tf.keras. If you are still interested in submitting a feature pull request, please direct it to tf.keras in the TensorFlow repository instead.
-->

### Summary

### Related Issues

### PR Overview

- [ ] This PR requires new unit tests [y/n] (make sure tests are included)
- [ ] This PR requires to update the documentation [y/n] (make sure the docs are up-to-date)
- [ ] This PR is backwards compatible [y/n]
- [ ] This PR changes the current API [y/n] (all API changes need to be approved by fchollet)
",AJAYK-01,None,2019-10-16T19:05:19Z,2020-05-16T20:48:36Z
13440,mish activation,"<!--
Please make sure you've read and understood our contributing guidelines;
https://github.com/keras-team/keras/blob/master/CONTRIBUTING.md

Note:
We are no longer adding new features to multi-backend Keras (we only fix bugs), as we are refocusing development efforts on tf.keras. If you are still interested in submitting a feature pull request, please direct it to tf.keras in the TensorFlow repository instead.
-->

### Summary

### Related Issues

### PR Overview

- [ ] This PR requires new unit tests [y/n] (make sure tests are included)
- [ ] This PR requires to update the documentation [y/n] (make sure the docs are up-to-date)
- [ ] This PR is backwards compatible [y/n]
- [ ] This PR changes the current API [y/n] (all API changes need to be approved by fchollet)
",serengil,None,2019-10-15T07:36:31Z,2019-10-18T08:05:55Z
13439,mish activation test,"<!--
Please make sure you've read and understood our contributing guidelines;
https://github.com/keras-team/keras/blob/master/CONTRIBUTING.md

Note:
We are no longer adding new features to multi-backend Keras (we only fix bugs), as we are refocusing development efforts on tf.keras. If you are still interested in submitting a feature pull request, please direct it to tf.keras in the TensorFlow repository instead.
-->

### Summary

### Related Issues

### PR Overview

- [ ] This PR requires new unit tests [y/n] (make sure tests are included)
- [ ] This PR requires to update the documentation [y/n] (make sure the docs are up-to-date)
- [ ] This PR is backwards compatible [y/n]
- [ ] This PR changes the current API [y/n] (all API changes need to be approved by fchollet)
",serengil,None,2019-10-15T07:35:50Z,2019-10-18T08:06:12Z
13434,mish activation,"Recently, a new overperforming activation function announced as Mish (https://arxiv.org/abs/1908.08681v2)

<!--
Please make sure you've read and understood our contributing guidelines;
https://github.com/keras-team/keras/blob/master/CONTRIBUTING.md

Note:
We are no longer adding new features to multi-backend Keras (we only fix bugs), as we are refocusing development efforts on tf.keras. If you are still interested in submitting a feature pull request, please direct it to tf.keras in the TensorFlow repository instead.
-->

### Summary

### Related Issues

### PR Overview

- [ ] This PR requires new unit tests [y/n] (make sure tests are included)
- [ ] This PR requires to update the documentation [y/n] (make sure the docs are up-to-date)
- [ ] This PR is backwards compatible [y/n]
- [ ] This PR changes the current API [y/n] (all API changes need to be approved by fchollet)
",serengil,None,2019-10-14T19:33:23Z,2019-10-15T07:33:35Z
13432,mish activation function,"Recently, a new overperforming activation function announced as Mish (https://arxiv.org/abs/1908.08681v2)

<!--
Please make sure you've read and understood our contributing guidelines;
https://github.com/keras-team/keras/blob/master/CONTRIBUTING.md

Note:
We are no longer adding new features to multi-backend Keras (we only fix bugs), as we are refocusing development efforts on tf.keras. If you are still interested in submitting a feature pull request, please direct it to tf.keras in the TensorFlow repository instead.
-->

### Summary

### Related Issues

### PR Overview

- [ ] This PR requires new unit tests [y/n] (make sure tests are included)
- [ ] This PR requires to update the documentation [y/n] (make sure the docs are up-to-date)
- [ ] This PR is backwards compatible [y/n]
- [ ] This PR changes the current API [y/n] (all API changes need to be approved by fchollet)
",serengil,None,2019-10-14T18:48:02Z,2019-10-15T07:33:59Z
13429,Update io_utils.py,"I just fixed Numpy -> NumPy in HDF5Matrix class.

<!--
Please make sure you've read and understood our contributing guidelines;
https://github.com/keras-team/keras/blob/master/CONTRIBUTING.md

Note:
We are no longer adding new features to multi-backend Keras (we only fix bugs), as we are refocusing development efforts on tf.keras. If you are still interested in submitting a feature pull request, please direct it to tf.keras in the TensorFlow repository instead.
-->

### Summary

### Related Issues

### PR Overview

- [ ] This PR requires new unit tests [y/n] (make sure tests are included)
- [ ] This PR requires to update the documentation [y/n] (make sure the docs are up-to-date)
- [ ] This PR is backwards compatible [y/n]
- [ ] This PR changes the current API [y/n] (all API changes need to be approved by fchollet)
",Denny-Hwang,None,2019-10-14T13:38:26Z,2019-10-18T08:06:50Z
13426,Update autogen.py,"fix duplicate module name for callbacks module

Callback() should be 
`keras.callbacks.Callback()`
but autogen.py generated
`keras.callbacks.callbacks.Callback()`

Classes in callbacks module had the same issue.
Added callback in `post_process_signature` method in autogen.py

<!--
Please make sure you've read and understood our contributing guidelines;
https://github.com/keras-team/keras/blob/master/CONTRIBUTING.md

Note:
We are no longer adding new features to multi-backend Keras (we only fix bugs), as we are refocusing development efforts on tf.keras. If you are still interested in submitting a feature pull request, please direct it to tf.keras in the TensorFlow repository instead.
-->

### Summary

### Related Issues

### PR Overview

- [n] This PR requires new unit tests [y/n] (make sure tests are included)
- [n] This PR requires to update the documentation [y/n] (make sure the docs are up-to-date)
- [y] This PR is backwards compatible [y/n]
- [n] This PR changes the current API [y/n] (all API changes need to be approved by fchollet)
",Naruu,None,2019-10-13T06:13:29Z,2019-10-13T17:15:52Z
13424,contribucion,"<!--
Please make sure you've read and understood our contributing guidelines;
https://github.com/keras-team/keras/blob/master/CONTRIBUTING.md

Note:
We are no longer adding new features to multi-backend Keras (we only fix bugs), as we are refocusing development efforts on tf.keras. If you are still interested in submitting a feature pull request, please direct it to tf.keras in the TensorFlow repository instead.
-->

### Summary

### Related Issues

### PR Overview

- [x] This PR requires new unit tests [y/n] (make sure tests are included)
- [x] This PR requires to update the documentation [y/n] (make sure the docs are up-to-date)
- [x] This PR is backwards compatible [y/n]
- [ ] This PR changes the current API [y/n] (all API changes need to be approved by fchollet)
",Emilio4585,None,2019-10-13T00:14:36Z,2019-10-13T21:16:09Z
13422,Change `batch_size` descriptions to proper ones,"### Summary
- Since there're no gradients to be updated during `evaulate` and `predict` processes, changed their `batch_size` docstrings from `""Number of samples per gradient update""` to `""Number of samples per evaluation step""` and `""Number of samples to be predicted at once""`. (The sentence in fit remains unchanged.)

- Corrected `callbacks` description docstrings in `evaluate_generator` and `predict_generator`: `""List of callbacks to apply during training""` -> `""- during evaluation""`, `""- during prediction""`.

I hope this fix would change related auto-generated documents as well.

<!--
Please make sure you've read and understood our contributing guidelines;
https://github.com/keras-team/keras/blob/master/CONTRIBUTING.md

Note:
We are no longer adding new features to multi-backend Keras (we only fix bugs), as we are refocusing development efforts on tf.keras. If you are still interested in submitting a feature pull request, please direct it to tf.keras in the TensorFlow repository instead.
-->

### Related Issues

### PR Overview

- [ ] This PR requires new unit tests [y/n] (make sure tests are included)
- [x] This PR requires to update the documentation [y/n] (make sure the docs are up-to-date)
- [x] This PR is backwards compatible [y/n]
- [ ] This PR changes the current API [y/n] (all API changes need to be approved by fchollet)
",EthanJYK,None,2019-10-11T08:59:36Z,2019-10-11T21:19:30Z
13421,Change description of `batch_size` to proper one,"Since there're no gradients updated within `evaulate` and `predict` processes, changed their `batch_size` docstrings from `""Number of samples per gradient update""` to `""Number of samples to be computed at once""`. (The sentence in `fit` remains unchanged.) 

I hope this fix would change related auto-generated documents as well.

<!--
Please make sure you've read and understood our contributing guidelines;
https://github.com/keras-team/keras/blob/master/CONTRIBUTING.md

Note:
We are no longer adding new features to multi-backend Keras (we only fix bugs), as we are refocusing development efforts on tf.keras. If you are still interested in submitting a feature pull request, please direct it to tf.keras in the TensorFlow repository instead.
-->

### Summary

### Related Issues

### PR Overview

- [ ] This PR requires new unit tests [y/n] (make sure tests are included)
- [x] This PR requires to update the documentation [y/n] (make sure the docs are up-to-date)
- [x] This PR is backwards compatible [y/n]
- [ ] This PR changes the current API [y/n] (all API changes need to be approved by fchollet)
",EthanJYK,None,2019-10-11T08:43:09Z,2019-10-11T08:51:42Z
13411,fix trainable attribute to enable embedding layer 'trainable' option,"<!--
Please make sure you've read and understood our contributing guidelines;
https://github.com/keras-team/keras/blob/master/CONTRIBUTING.md

Note:
We are no longer adding new features to multi-backend Keras (we only fix bugs), as we are refocusing development efforts on tf.keras. If you are still interested in submitting a feature pull request, please direct it to tf.keras in the TensorFlow repository instead.
-->

### Summary
This pull fix the embedding layer trainable option. 

### Related Issues
Embedding trainable option does not work since the `trainable` arg  is not specified in `keras/layers/embeddings.py`.

To enable the `trainable` option in `Embedding`, I did minor fix in the method of `add_weights()` in `base_layer.py`. 

### PR Overview

- [ ] This PR requires new unit tests [y/n] (make sure tests are included)
NO
- [ ] This PR requires to update the documentation [y/n] (make sure the docs are up-to-date)
No
- [ ] This PR is backwards compatible [y/n]
Yes
- [ ] This PR changes the current API [y/n] (all API changes need to be approved by fchollet)
No
",anjiefang,None,2019-10-09T03:36:44Z,2019-10-10T20:46:21Z
13409,Reverted space,"<!--
Please make sure you've read and understood our contributing guidelines;
https://github.com/keras-team/keras/blob/master/CONTRIBUTING.md

Note:
We are no longer adding new features to multi-backend Keras (we only fix bugs), as we are refocusing development efforts on tf.keras. If you are still interested in submitting a feature pull request, please direct it to tf.keras in the TensorFlow repository instead.
-->

### Summary

### Related Issues

### PR Overview

- [ ] This PR requires new unit tests [y/n] (make sure tests are included)
- [ ] This PR requires to update the documentation [y/n] (make sure the docs are up-to-date)
- [ ] This PR is backwards compatible [y/n]
- [ ] This PR changes the current API [y/n] (all API changes need to be approved by fchollet)
",MichelleVivita,None,2019-10-08T06:14:21Z,2019-10-08T09:55:00Z
13405,Michelle,"<!--
Please make sure you've read and understood our contributing guidelines;
https://github.com/keras-team/keras/blob/master/CONTRIBUTING.md

Note:
We are no longer adding new features to multi-backend Keras (we only fix bugs), as we are refocusing development efforts on tf.keras. If you are still interested in submitting a feature pull request, please direct it to tf.keras in the TensorFlow repository instead.
-->

### Summary

### Related Issues

### PR Overview

- [ ] This PR requires new unit tests [y/n] (make sure tests are included)
- [ ] This PR requires to update the documentation [y/n] (make sure the docs are up-to-date)
- [ ] This PR is backwards compatible [y/n]
- [ ] This PR changes the current API [y/n] (all API changes need to be approved by fchollet)
",MichelleVivita,None,2019-10-07T15:38:59Z,2019-10-08T09:55:26Z
13402,"tf.keras works, tf.python.keras doesn't","**DOESN'T WORK**:
```python
from tensorflow.python.keras.layers import Input, Dense
from tensorflow.python.keras.models import Model
from tensorflow.python.keras.optimizers import Nadam

ipt = Input(shape=(4,))
out = Dense(1, activation='sigmoid')(ipt)

model = Model(ipt, out)
model.compile(optimizer=Nadam(lr=1e-4), loss='binary_crossentropy')

X = np.random.randn(32,4)
Y = np.random.randint(0,2,(32,1))
model.train_on_batch(X,Y)
```
**WORKS**: remove `.python` from above's imports. Above's error trace below.

Keras 2.3.0 and TensorFlow 2.0.0 freshly-installed via Anaconda, older versions uninstalled. Why the difference?

<hr>

```python

  File ""<ipython-input-7-1e86d21d8fc4>"", line 13, in <module>
    model.train_on_batch(X,Y)

  File ""D:\Anaconda\envs\tf2_env\lib\site-packages\tensorflow_core\python\keras\engine\training.py"", line 1017, in train_on_batch
    self._make_train_function()

  File ""D:\Anaconda\envs\tf2_env\lib\site-packages\tensorflow_core\python\keras\engine\training.py"", line 2116, in _make_train_function
    params=self._collected_trainable_weights, loss=self.total_loss)

  File ""D:\Anaconda\envs\tf2_env\lib\site-packages\tensorflow_core\python\keras\optimizers.py"", line 653, in get_updates
    grads = self.get_gradients(loss, params)

  File ""D:\Anaconda\envs\tf2_env\lib\site-packages\tensorflow_core\python\keras\optimizers.py"", line 92, in get_gradients
    if None in grads:

  File ""D:\Anaconda\envs\tf2_env\lib\site-packages\tensorflow_core\python\ops\math_ops.py"", line 1336, in tensor_equals
    return gen_math_ops.equal(self, other)

  File ""D:\Anaconda\envs\tf2_env\lib\site-packages\tensorflow_core\python\ops\gen_math_ops.py"", line 3627, in equal
    name=name)

  File ""D:\Anaconda\envs\tf2_env\lib\site-packages\tensorflow_core\python\framework\op_def_library.py"", line 545, in _apply_op_helper
    (input_name, err))

ValueError: Tried to convert 'y' to a tensor and failed. Error: None values not supported.
```
<hr>

**UPDATE:** Debugging the two side-by-side, while both use the [same files](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/engine/training.py#L1008), execution diverges fairly quickly:

```python
# .\tensorflow_core\python\keras\engine\training.py

### TF.KERAS
    if self._experimental_run_tf_function: #  TRUE
	
### TF.PYTHON.KERAS
    if self._experimental_run_tf_function: #  FALSE
```
Former proceeds to call `training_v2_utils.train_on_batch(...)` and returns thereafter, latter `self._standardize_user_data(...)` and others before ultimately failing. 

One difference I noted between linked file and mine is, latter's short by ~100 lines - though I installed TF 2 via pip after the file's last update 12 days ago according to Github.",OverLordGoldDragon,b'backend:tensorflow type:bug/performance',2019-10-06T03:09:27Z,2019-10-09T19:32:59Z
13401,fix: `recurrent_activation` parameter's docstring,"<!--
Please make sure you've read and understood our contributing guidelines;
https://github.com/keras-team/keras/blob/master/CONTRIBUTING.md

Note:
We are no longer adding new features to multi-backend Keras (we only fix bugs), as we are refocusing development efforts on tf.keras. If you are still interested in submitting a feature pull request, please direct it to tf.keras in the TensorFlow repository instead.
-->

### Summary

Fixing `recurrent_activation` parameter docstring, it was saying that the default is ""hard_sigmoid"" [even though the code defaults to ""sigmoid""](https://github.com/keras-team/keras/blob/master/keras/layers/recurrent.py#L1206) (I only selected the `GRUCell` because multi-line cross referencing isn't a feature. BTW, if you're wondering whether `tf.keras` has the same issue, [it's not](https://github.com/tensorflow/tensorflow/blob/r2.0/tensorflow/python/keras/layers/recurrent_v2.py#L766). 
### Related Issues

### PR Overview

- [n] This PR requires new unit tests [y/n] (make sure tests are included)
- [n] This PR requires to update the documentation [y/n] (make sure the docs are up-to-date)
- [y] This PR is backwards compatible [y/n]
- [n] This PR changes the current API [y/n] (all API changes need to be approved by fchollet)
",andrewnaguib,None,2019-10-05T22:35:43Z,2019-10-06T21:08:29Z
13400,Adding example for MNIST training on low resources.,"<!--
Please make sure you've read and understood our contributing guidelines;
https://github.com/keras-team/keras/blob/master/CONTRIBUTING.md

Note:
We are no longer adding new features to multi-backend Keras (we only fix bugs), as we are refocusing development efforts on tf.keras. If you are still interested in submitting a feature pull request, please direct it to tf.keras in the TensorFlow repository instead.
-->

### Summary

### Related Issues

### PR Overview

- [ ] This PR requires new unit tests [y/n] (make sure tests are included)
- [ ] This PR requires to update the documentation [y/n] (make sure the docs are up-to-date)
- [ ] This PR is backwards compatible [y/n]
- [ ] This PR changes the current API [y/n] (all API changes need to be approved by fchollet)
",akshaybahadur21,None,2019-10-05T19:05:10Z,2019-10-06T19:02:26Z
13396,TF2 K.get_value() - bug or feature?,"Calling `K.get_value(self.param)` inside `optimizer.get_update()` yields below error: 

```python
NotImplementedError: numpy() is only available when eager execution is enabled.
```

Debugging, I learn that `context.executing_eagerly()` evaluates to `False` in given scope, but to `True` in `optimizer.get_config()`. I note the latter is always called in a declared scope - e.g. `with strategy.scope()` [here](https://github.com/tensorflow/tensorflow/blob/64c3d382cadf7bbe8e7e99884bede8284ff67f56/tensorflow/python/keras/distribute/multi_worker_test.py#L216). 

_However_ - the buggy aspect here is that `K.get_value()` works fine _post-error_ - i.e. if I run `K.get_value(model.optimizer.param)`, it evaluates successfully. This is accomplished via the `K.symbolic` wrapper, which calls `tensorflow_backend.symbolic()` post-error - which, when finishes executing, changes the parameter as follows:

```python
<tf.Variable 'Adam/param:0' shape=() dtype=int64>
# into
<tf.Variable 'Adam/param:0' shape=() dtype=int64, numpy=100>
```
Also, calling `param.numpy()` directly yields the same error. I'm using `Keras 2.3.0` w/ `TensorFlow 2.0.0`. -- Bug or feature? And how do I now retrieve `K.variable` values during optimizer compilation? (usage is boolean - e.g. `if param == 1`)

<hr>
<b>UPDATE</b>: 

`print(self.param); print(tf.executing_eagerly)` under each of below yields, respectively:


```python
# def __init__(self, ...)
<tf.Variable 'Adam/param:0' shape=() dtype=int64, numpy=100>
True

# def get_updates(self)
<tf.Variable 'Adam/param:0' shape=() dtype=int64>
False
```
The wrappers appear to be involved - from `K.symbolic.__doc__`: 

> ""Decorator used in TensorFlow 2.0 to enter the Keras graph""

So this is at the expense of class attribute values getting lost? Should `__init__` also be wrapped then?",OverLordGoldDragon,b'backend:tensorflow type:bug/performance',2019-10-05T01:08:14Z,2019-10-10T21:36:13Z
13395,Fixing typos in the docstrings,"<!--
Please make sure you've read and understood our contributing guidelines;
https://github.com/keras-team/keras/blob/master/CONTRIBUTING.md

Note:
We are no longer adding new features to multi-backend Keras (we only fix bugs), as we are refocusing development efforts on tf.keras. If you are still interested in submitting a feature pull request, please direct it to tf.keras in the TensorFlow repository instead.
-->

### Summary
Fixing typos in the docstrings

### Related Issues
NA

### PR Overview

- [ ] This PR requires new unit tests [y/n] (make sure tests are included)
- [x] This PR requires to update the documentation [y/n] (make sure the docs are up-to-date)
- [x] This PR is backwards compatible [y/n]
- [ ] This PR changes the current API [y/n] (all API changes need to be approved by fchollet)
",haifeng-jin,None,2019-10-04T20:34:09Z,2019-10-06T18:48:27Z
13390,Issue #12890,"<!--
Please make sure you've read and understood our contributing guidelines;
https://github.com/keras-team/keras/blob/master/CONTRIBUTING.md

Note:
We are no longer adding new features to multi-backend Keras (we only fix bugs), as we are refocusing development efforts on tf.keras. If you are still interested in submitting a feature pull request, please direct it to tf.keras in the TensorFlow repository instead.
-->

### Summary

### Related Issues

### PR Overview

- [ ] This PR requires new unit tests [y/n] (make sure tests are included)
- [ ] This PR requires to update the documentation [y/n] (make sure the docs are up-to-date)
- [ ] This PR is backwards compatible [y/n]
- [ ] This PR changes the current API [y/n] (all API changes need to be approved by fchollet)
",MichelleVivita,None,2019-10-02T06:40:59Z,2019-10-07T15:57:04Z
13373,Update local.py,"stride value implies the input argument of 'stride', and dilation_rate implies the input argument of 'dilation rate' of Conv1D function.
It is more explicit to express as code rather than using words stride value, dilation value.
Or, at least both stride and dilation_rate should be written in code, not only dilation rate as before document

<!--
Please make sure you've read and understood our contributing guidelines;
https://github.com/keras-team/keras/blob/master/CONTRIBUTING.md

Note:
We are no longer adding new features to multi-backend Keras (we only fix bugs), as we are refocusing development efforts on tf.keras. If you are still interested in submitting a feature pull request, please direct it to tf.keras in the TensorFlow repository instead.
-->

### Summary
change documentation words.
stride != -1, dilation_rate != -1 to code

### Related Issues

### PR Overview

- [n ] This PR requires new unit tests [y/n] (make sure tests are included)
- [y] This PR requires to update the documentation [y/n] (make sure the docs are up-to-date)
- [y] This PR is backwards compatible [y/n]
- [n] This PR changes the current API [y/n] (all API changes need to be approved by fchollet)
",Naruu,None,2019-09-29T01:49:12Z,2019-09-29T19:59:33Z
13355,Fix encoding error,"<!--
Please make sure you've read and understood our contributing guidelines;
https://github.com/keras-team/keras/blob/master/CONTRIBUTING.md

Note:
We are no longer adding new features to multi-backend Keras (we only fix bugs), as we are refocusing development efforts on tf.keras. If you are still interested in submitting a feature pull request, please direct it to tf.keras in the TensorFlow repository instead.
-->

### Summary
Running `autogen.py` in Windows fails with the following error:
`UnicodeDecodeError: 'cp949' codec can't decode byte 0xbf in position 2: illegal multibyte sequence
`

Passing `utf-8` encoding argument fixes the error. 

### Related Issues

### PR Overview

- [n] This PR requires new unit tests [y/n] (make sure tests are included)
- [n] This PR requires to update the documentation [y/n] (make sure the docs are up-to-date)
- [y] This PR is backwards compatible [y/n]
- [n] This PR changes the current API [y/n] (all API changes need to be approved by fchollet)
",fuzzythecat,None,2019-09-23T08:42:06Z,2019-09-26T08:18:27Z
13339,Correct spelling mistake,"<!--
Please make sure you've read and understood our contributing guidelines;
https://github.com/keras-team/keras/blob/master/CONTRIBUTING.md

Note:
We are no longer adding new features to multi-backend Keras (we only fix bugs), as we are refocusing development efforts on tf.keras. If you are still interested in submitting a feature pull request, please direct it to tf.keras in the TensorFlow repository instead.
-->

### Summary

### Related Issues

### PR Overview

- [n] This PR requires new unit tests [y/n] (make sure tests are included)
- [n] This PR requires to update the documentation [y/n] (make sure the docs are up-to-date)
- [y] This PR is backwards compatible [y/n]
- [n] This PR changes the current API [y/n] (all API changes need to be approved by fchollet)
",shivdhar,None,2019-09-19T06:27:25Z,2019-09-20T17:49:04Z
13336,Calling`model.predict()` from inside batch generator raises thread-local storage error ,"**System information**  
- Have I written custom code (as opposed to using example directory): Some, but the issue arises with a relatively simple case.
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04 in Docker on a Mac 
- TensorFlow backend (yes / no):  Yes
- TensorFlow version:  1.14.0 but also occurs in 2.0.0rc1
- Keras version: 2.3.0
- Python version: 3.7
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A

**Describe the current behavior**
When calling a model during training (e.g., from a batch generator), an attribute error is raised related to thread-local data. This occurs in Keras 2.3.0 but not in Keras <= 2.2.5. It appears the thread-local storage elements were added in Keras 2.3.0.

**Describe the expected behavior**
I expect the model to be callable during training, as has been the case in prior Keras versions. The test code is intentionally trivial to demonstrate the issue. In practice, being able to call a model during batch generation is useful for cases where we generate batches based on current model behavior (e.g., selecting hard examples for a model using triplet loss).

**Code to reproduce the issue**  

```python
import keras
import numpy as np

input_layer = keras.layers.Input((1, ))
x = keras.layers.Dense(1, activation='sigmoid')(input_layer)
model = keras.models.Model(inputs=input_layer, outputs=x)
model.compile(loss='binary_crossentropy', optimizer='sgd')
model._make_predict_function() 
def generate():
    while True:
        # If you comment this next line out, no error is raised.
        yt = model.predict(np.random.randn(5, 1))
        yield np.random.randn(5, 1), np.ones((5, 1))

model.fit_generator(generate(), epochs=3, steps_per_epoch=10)
```

**Other info / logs**  
```
---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
<ipython-input-1-79d7cb1668dc> in <module>
     12         yield np.random.randn(5, 1), np.ones((5, 1))
     13 
---> 14 model.fit_generator(generate(), epochs=3, steps_per_epoch=10)

/usr/src/.venv/lib/python3.7/site-packages/keras/legacy/interfaces.py in wrapper(*args, **kwargs)
     89                 warnings.warn('Update your `' + object_name + '` call to the ' +
     90                               'Keras 2 API: ' + signature, stacklevel=2)
---> 91             return func(*args, **kwargs)
     92         wrapper._original_function = func
     93         return wrapper

/usr/src/.venv/lib/python3.7/site-packages/keras/engine/training.py in fit_generator(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)
   1730             use_multiprocessing=use_multiprocessing,
   1731             shuffle=shuffle,
-> 1732             initial_epoch=initial_epoch)
   1733 
   1734     @interfaces.legacy_generator_methods_support

/usr/src/.venv/lib/python3.7/site-packages/keras/engine/training_generator.py in fit_generator(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)
    183             batch_index = 0
    184             while steps_done < steps_per_epoch:
--> 185                 generator_output = next(output_generator)
    186 
    187                 if not hasattr(generator_output, '__len__'):

/usr/src/.venv/lib/python3.7/site-packages/keras/utils/data_utils.py in get(self)
    740                     ""`use_multiprocessing=False, workers > 1`.""
    741                     ""For more information see issue #1638."")
--> 742             six.reraise(*sys.exc_info())

/usr/src/.venv/lib/python3.7/site-packages/six.py in reraise(tp, value, tb)
    691             if value.__traceback__ is not tb:
    692                 raise value.with_traceback(tb)
--> 693             raise value
    694         finally:
    695             value = None

/usr/src/.venv/lib/python3.7/site-packages/keras/utils/data_utils.py in get(self)
    709                 try:
    710                     future = self.queue.get(block=True)
--> 711                     inputs = future.get(timeout=30)
    712                     self.queue.task_done()
    713                 except mp.TimeoutError:

/usr/local/lib/python3.7/multiprocessing/pool.py in get(self, timeout)
    655             return self._value
    656         else:
--> 657             raise self._value
    658 
    659     def _set(self, i, obj):

/usr/local/lib/python3.7/multiprocessing/pool.py in worker(inqueue, outqueue, initializer, initargs, maxtasks, wrap_exception)
    119         job, i, func, args, kwds = task
    120         try:
--> 121             result = (True, func(*args, **kwds))
    122         except Exception as e:
    123             if wrap_exception and func is not _helper_reraises_exception:

/usr/src/.venv/lib/python3.7/site-packages/keras/utils/data_utils.py in next_sample(uid)
    648         The next value of generator `uid`.
    649     """"""
--> 650     return six.next(_SHARED_SEQUENCES[uid])
    651 
    652 

<ipython-input-1-79d7cb1668dc> in generate()
      9 def generate():
     10     while True:
---> 11         yt = model.predict(np.random.randn(5, 1))
     12         yield np.random.randn(5, 1), np.ones((5, 1))
     13 

/usr/src/.venv/lib/python3.7/site-packages/keras/engine/training.py in predict(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)
   1460                                             verbose=verbose,
   1461                                             steps=steps,
-> 1462                                             callbacks=callbacks)
   1463 
   1464     def train_on_batch(self, x, y,

/usr/src/.venv/lib/python3.7/site-packages/keras/engine/training_arrays.py in predict_loop(model, f, ins, batch_size, verbose, steps, callbacks)
    274             indices_for_conversion_to_dense.append(i)
    275 
--> 276     callbacks.model.stop_training = False
    277     callbacks._call_begin_hook('predict')
    278 

/usr/src/.venv/lib/python3.7/site-packages/keras/engine/network.py in __setattr__(self, name, value)
    321                     'forgot to call `super(YourClass, self).__init__()`.'
    322                     ' Always start with this line.')
--> 323         super(Network, self).__setattr__(name, value)
    324 
    325     @property

/usr/src/.venv/lib/python3.7/site-packages/keras/engine/base_layer.py in __setattr__(self, name, value)
   1213         # We do this so that we can maintain the correct order of metrics by adding
   1214         # the instance to the `metrics` list as soon as it is created.
-> 1215         if not _DISABLE_TRACKING.value:
   1216             from .. import metrics as metrics_module
   1217             if isinstance(value, metrics_module.Metric):

AttributeError: '_thread._local' object has no attribute 'value'
```
",faustomorales,b'backend:tensorflow type:bug/performance',2019-09-18T18:26:12Z,2020-06-19T10:46:57Z
13334,Add a link to the metrics document,"Link to the metrics document(/metrics) was missing in 'Compilation' section. Added one just as other explained arguments.

<!--
Please make sure you've read and understood our contributing guidelines;
https://github.com/keras-team/keras/blob/master/CONTRIBUTING.md

Note:
We are no longer adding new features to multi-backend Keras (we only fix bugs), as we are refocusing development efforts on tf.keras. If you are still interested in submitting a feature pull request, please direct it to tf.keras in the TensorFlow repository instead.
-->

### Summary

### Related Issues

### PR Overview

- [ ] This PR requires new unit tests [y/n] (make sure tests are included)
- [x] This PR requires to update the documentation [y/n] (make sure the docs are up-to-date)
- [x] This PR is backwards compatible [y/n]
- [ ] This PR changes the current API [y/n] (all API changes need to be approved by fchollet)
",EthanJYK,None,2019-09-18T06:23:00Z,2019-09-18T20:35:55Z
13332,Bug fix: Saving Input layers with predefined tensors,"### Summary

Fixes an issue with saving and loading `Input` layers that have a predefined tensor.

Predefined tensors for `Input` are used to create constant input values for a Model.
However, the data from a predefined tensors provided to `Input` are not saved when a Model is serialized to an hdf5 file. 
Not saving this information causes two main issues:

1.  The ""constant"" layer is interpreted as a ""placeholder"" on loading, leading to a different input signature.
1. Any values provided to the ""constant"" layer are lost

This PR addresses these issues by changing the `get_config` and `from_config` functions of `InputLayer` to store whether an input is a placeholder or not.
Changing these functions also required modifying the `__init__` function of `InputLayer`.

### Related Issues

None that I can find... but I'll dig some more. 

### PR Overview

- [x] This PR requires new unit tests [y/n] (make sure tests are included)
- [ ] This PR requires to update the documentation [y/n] (make sure the docs are up-to-date)
- [x] This PR is backwards compatible [y/n]
- [ ] This PR changes the current API [y/n] (all API changes need to be approved by fchollet)
",WardLT,None,2019-09-17T23:11:14Z,2019-09-18T21:32:51Z
13327,Update cifar10_cnn.py,"Dear, master.

While I study using Keras example (cifar10_cnn), I met errors. And I fixed it a little bit.
Please check this one. My Keras version is 2.5.5 and Tensorflow version is 1.13.1.

Best regards,
Thank you.

Denny Hwang.

<!--
Please make sure you've read and understood our contributing guidelines;
https://github.com/keras-team/keras/blob/master/CONTRIBUTING.md

Note:
We are no longer adding new features to multi-backend Keras (we only fix bugs), as we are refocusing development efforts on tf.keras. If you are still interested in submitting a feature pull request, please direct it to tf.keras in the TensorFlow repository instead.
-->

### Summary
- Example error fixing.
I changed the expression 'learning_rate' to 'lr' for fixing error.

### Related Issues
- ""cifar10_cnn"" example

### PR Overview

- [N] This PR requires new unit tests [y/n] (make sure tests are included)
- [Y] This PR requires to update the documentation [y/n] (make sure the docs are up-to-date)
- [N] This PR is backwards compatible [y/n]
- [N] This PR changes the current API [y/n] (all API changes need to be approved by fchollet)
",Denny-Hwang,None,2019-09-16T14:35:46Z,2019-09-16T17:16:41Z
13322,Fix sequence timeout deadlock,"<!--
Please make sure you've read and understood our contributing guidelines;
https://github.com/keras-team/keras/blob/master/CONTRIBUTING.md

Note:
We are no longer adding new features to multi-backend Keras (we only fix bugs), as we are refocusing development efforts on tf.keras. If you are still interested in submitting a feature pull request, please direct it to tf.keras in the TensorFlow repository instead.
-->

### Summary
In the case when fetching the batch from the worker is not finished within the timeout, `queue.task_done` method is not called. This leads to a deadlock at the end of the epoch when we do `self._wait_queue()` preventing from getting batches for the next epoch. The correct behavior would be to mark task in the queue as done regardless of if it was processed in the worker or on the main thread after the timeout.
### Related Issues

### PR Overview

- [y] This PR requires new unit tests [y/n] (make sure tests are included)
- [n] This PR requires to update the documentation [y/n] (make sure the docs are up-to-date)
- [y] This PR is backwards compatible [y/n]
- [n] This PR changes the current API [y/n] (all API changes need to be approved by fchollet)
",andreyz4k,None,2019-09-15T12:09:36Z,2019-09-15T17:49:15Z
13313,Pytorch Autograd no_grad equivalent in Keras,"Hi, I am not sure if this is a bug/ feature, more of a general issue. I recently came to know of a feature in `pytorch` Autograd where we can pass `no_grad` as described [here](https://pytorch.org/docs/stable/autograd.html#torch.autograd.no_grad). I read somewhere that pytorch calculates gradients even during inference and ends up consuming more than 1GB GPU RAM due to it. This feature allows users to stop this and save space (I don't use pytorch so not 100pc sure). I am looking around Keras to find if Keras does this too? And is there anything we can do to stop this? (Yet to find something). Any pointers would be appreciated.
Thanks!",tonmoyborah,None,2019-09-13T09:44:20Z,2019-09-13T16:58:39Z
13302,Multi-GPU Model fails to detect CPU,"When running 

`p_model = multi_gpu_model(model)`

I get

ValueError: To call `multi_gpu_model` with `gpus=4`, we expect the following devices to be available: ['/cpu:0', '/gpu:0', '/gpu:1', '/gpu:2', '/gpu:3']. However this machine only has: ['/gpu:0', '/gpu:1', '/gpu:2', '/gpu:3']. Try reducing `gpus`

Running the following correctly lists all GPUs and a CPU:

```
from tensorflow.python.client import device_lib
device_lib.list_local_devices()
```
I have tried :
 with and without 
`os.environ['CUDA_VISIBLE_DEVICES'] = ""0,1,2,3,4"" `
and permutations of those numbers (ie 0,1,2,3)
 building the initial model with and without
`with tf.device('/cpu:0'):`
building the subsequent parallel model with and without
`with tf.device('/cpu:0'):`

this error only happens on the latest branch, I installed via 
`pip3.6 install git+https://github.com/keras-team/keras --upgrade --no-deps`
and have tried with both TF 1.13 and 1.14

",JamesDConley,b'backend:tensorflow type:bug/performance',2019-09-10T14:15:56Z,2019-09-10T18:23:17Z
13268,predictions different with same weight,"<em>Please make sure that this is a Bug or a Feature Request and provide all applicable information asked by the template.
If your issue is an **implementation question**, please ask your question on [StackOverflow](http://stackoverflow.com/questions/tagged/keras) or [on the Keras Slack channel](https://keras-slack-autojoin.herokuapp.com/) instead of opening a GitHub issue.</em>  

**System information**  
- Have I written custom code (as opposed to using example directory):  
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  Linux CentOS 7.0
- TensorFlow backend (yes / no):  yes
- TensorFlow version:  1.14
- Keras version:  2.2.0
- Python version:  2.7
- CUDA/cuDNN version:  8.0
- GPU model and memory:  single GPU with 16GB memory

You can obtain the TensorFlow version with:  
python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""  
You can obtain the Keras version with:  
python -c 'import keras as k; print(k.__version__)'  

**Describe the current behavior**  

**Describe the expected behavior**  

**Code to reproduce the issue**  
Provide a reproducible test case that is the bare minimum necessary to generate the problem.  

**Other info / logs**  
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.  

Hi ,I found I run the same code and same weight with same images but got different predictions each time ,my code and images are on github [binary_categorical](https://github.com/yasohasakii/binary_categorical) and you can run the `ipynb` script on colab, and weight `.h5` file has been upload to [google dirver](https://drive.google.com/open?id=1sCIAgoQ7Og18iBmhwaOUmVSbRziAX5fo). Below codes are my result for twice times.  
`./PetImages/test/Cat/10000.jpg 0.070283316  
./PetImages/test/Cat/10001.jpg 0.04877737  `  
`./PetImages/test/Cat/10000.jpg 0.39205018  
./PetImages/test/Cat/10001.jpg 0.06655105  `

",yasohasakii,b'type:support',2019-08-30T03:14:38Z,2019-12-26T02:01:43Z
13258,'Model' object has no attribute 'in_multi_worker_mode',"<em>Please make sure that this is a Bug or a Feature Request and provide all applicable information asked by the template.
If your issue is an **implementation question**, please ask your question on [StackOverflow](http://stackoverflow.com/questions/tagged/keras) or [on the Keras Slack channel](https://keras-slack-autojoin.herokuapp.com/) instead of opening a GitHub issue.</em>  

**System information**  
- Have I written custom code (as opposed to using example directory):  
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  
- TensorFlow backend (yes / no):  yes
- TensorFlow version:  tf-nightly-gpu
- Keras version:  2.2.5
- Python version:  3.7
- CUDA/cuDNN version:  9.2/7.0
- GPU model and memory: Nvidia gtx 1080 

I think keras is imcompatible with tf-nightly-gpu since it works fine with py36/tf 1.13/keras.
Is there any resolution for this problem?
",Charlie4zc,b'backend:tensorflow stat:awaiting response',2019-08-28T09:59:40Z,2020-06-08T11:12:55Z
13254,A CNN while working for a while crashes with no error,"<em>Please make sure that this is a Bug or a Feature Request and provide all applicable information asked by the template.
If your issue is an **implementation question**, please ask your question on [StackOverflow](http://stackoverflow.com/questions/tagged/keras) or [on the Keras Slack channel](https://keras-slack-autojoin.herokuapp.com/) instead of opening a GitHub issue.</em>  

**System information**  
- Have I written custom code (as opposed to using example directory):  The code does training a Resnet using Keras pretrained model.
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  Centos (Cluster)
- TensorFlow backend (yes / no):  Yes
- TensorFlow version:  tensorflow-gpu==1.12.0
- Keras version:  Keras==2.2.4
- Python version:  3.6
- CUDA/cuDNN version:  9.0
- GPU model and memory:  P100, 12GB

**Describe the current behavior**  
I have written a Keras code with using the ResNet50 architecture which is available in Keras pretrained models. My training dataset is huge (70K 512*512 images). The network can be trained with no problem for a while (sometimes a week, sometimes for two weeks, and it can happen on different epochs); but it suddenly crashes with no error.
The code, dataset, and system remain intact while the code working.
Also, I am saving the weights for each epoch and printing the log of training for each batch which does not show any failure.

I run everything on UPenn cluster and I have talked with our cluster admin; he mentioned there is no error recorded on the cluster side. Since, this has happened a couple of time, he suggested me to contact you to check if you have seen such behavior from Keras models?
If not, can you please help us if there is any way in the Keras training procedure to check the followings:
1) stack size
2) working set size
3) number of open files
4) the name of each function or sub-routine as it is called -- to see if the program always exits from the same place     
5) internal information about the variables & data structures within your program

I can print all these from python but I do not know how to do that while my network is being trained. 

Please let me know if you can help.

Bests,
Omid",omaghsoudi,b'backend:tensorflow type:support',2019-08-27T15:16:36Z,2019-08-27T18:00:27Z
13221,'recurrent_dropout' with 'relu' in LSTM yields NaNs,"Any non-zero `recurrent_dropout` yields NaN losses and weights; latter are either 0 or NaN. Happens for stacked, shallow, `stateful`, `return_sequences` = any, with & w/o `Bidirectional()`, `activation='relu'`, `loss='binary_crossentropy'`. NaNs occur within a few batches - the more layers, the sooner. 

Any fixes? Help's appreciated.

<hr>
<b>TROUBLESHOOTING ATTEMPTED</b>:

 - `recurrent_dropout=0.2,0.1,0.01,1e-6`
 - `kernel_constraint=maxnorm(0.5,axis=0)`
 - `recurrent_constraint=maxnorm(0.5,axis=0)`
 - `clipnorm=50`  (empirically determined), Nadam optimizer 
 - `activation='tanh'` - no NaNs, weights stable, tested for up to 10 batches
 - `lr=2e-6,2e-5` - no NaNs, weights stable, tested for up to 10 batches
 - `lr=5e-5` - no NaNs, weights stable, for 3 batches - NaNs on batch 4

_NOTE_: `batch_shape=(32,672,16)`, 17 calls to `train_on_batch` per batch

<hr>
<b>ENVIRONMENT</b>:

 - Keras 2.2.4 (TensorFlow backend), Python 3.7, Spyder 3.3.7 via Anaconda
 - GTX 1070 6GB, i7-7700HQ, 12GB RAM, Win-10.0.17134 x64
 - CuDNN 10+, latest Nvidia drives",OverLordGoldDragon,b'backend:tensorflow type:bug/performance',2019-08-15T21:36:08Z,2020-01-09T03:18:16Z
13219,Huge differences in prediction between versions of Keras (1.2.2 & 2.0.4) - Possible bug?,"Today I've ran into some very strange behavior of Keras. When I try to do a classification run on the iris-dataset with a simple model, keras version 1.2.2 gives me +- 95% accuracy, whereas a keras version of 2.2.4 predicts the same class for every training example (leading to an accuracy of +- 35%, as there are three types of iris). The only thing that makes my model predict +-95% accuracy is downgrading keras to a version below 2.0:

I think it is a problem with Keras, as I have tried the following things, all do not make a difference;

- Switching activation function in the last layer (from Sigmoid to softmax).
- Switching backend (Theano and Tensorflow both give roughly same performance).
- Using a random seed.
- Varying the number of neurons in the hidden layer (I only have 1 hidden layer in this simple model).
- Switching loss-functions.

 Dependencies to reproduce the problem:
- numpy=1.16.4
- pandas=0.25.0
- sk-learn=0.21.2
- theano=1.0.4
- tensorflow=1.14.0

Below is my code; it's only a short script, and I've included the iris data so the problem should be easily reproduced.
```
import pandas as pd
from keras.models import Sequential
from keras.layers import Dense
from keras.wrappers.scikit_learn import KerasClassifier
from keras.utils import np_utils
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import KFold
from sklearn.preprocessing import LabelEncoder

#Load data
data_frame = pd.read_csv(""iris.csv"", header=None)
data_set = data_frame.values
X = data_set[:, 0:4].astype(float)
Y = data_set[:, 4]

#Encode class values as integers
encoder = LabelEncoder()
encoder.fit(Y)
encoded_Y = encoder.transform(Y)

# convert integers to dummy variables (i.e. one hot encoded)
dummy_y = np_utils.to_categorical(encoded_Y)

def baseline_model():
    #Create & Compile model
    model = Sequential()
    model.add(Dense(8, input_dim=4, init='normal', activation='relu'))
    model.add(Dense(3, init='normal', activation='sigmoid'))
    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
    return model

#Create Wrapper For Neural Network Model For Use in scikit-learn
estimator = KerasClassifier(build_fn=baseline_model, nb_epoch=200, batch_size=5, verbose=0)

#Create kfolds-cross validation
kfold = KFold(n_splits=10, shuffle=True)

#Evaluate our model (Estimator) on dataset (X and dummy_y) using a 10-fold cross-validation procedure (kfold).
results = cross_val_score(estimator, X, dummy_y, cv=kfold)
print(""Accuracy: {:2f}% ({:2f}%)"".format(results.mean()*100, results.std()*100))
```

Rename this file to iris.csv and you're good to go
[iris.txt](https://github.com/keras-team/keras/files/3503042/iris.txt)





",Psychotechnopath,None,2019-08-14T19:45:55Z,2019-08-16T13:31:20Z
13205,keras is using tensorflow backend while running thru terminal but trying to use theano while running thru pycharm console,"Description:
A. Open Anaconda prompt and run following commands:
1. `activate <my_environment_name>`
2. `set ""KERAS_BACKEND=tensorflow""`
3. `python`
4. `import keras`
Output (as expected): 
`Using TensorFlow backend.`

B. Open python console thru pycharm (which use the python.exe of the environment from A. as interpreter) and run following command:
1. `import keras`
Output (failed):
```

Using Theano backend.
Traceback (most recent call last):
  File ""C:\Users\Ido\AppData\Local\conda\conda\envs\py36\lib\site-packages\theano\gof\lazylinker_c.py"", line 81, in <module>
    actual_version, force_compile, _need_reload))
ImportError: Version check of the existing lazylinker compiled file. Looking for version 0.211, but found None. Extra debug information: force_compile=False, _need_reload=True

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Users\Ido\AppData\Local\conda\conda\envs\py36\lib\site-packages\theano\gof\lazylinker_c.py"", line 105, in <module>
    actual_version, force_compile, _need_reload))
ImportError: Version check of the existing lazylinker compiled file. Looking for version 0.211, but found None. Extra debug information: force_compile=False, _need_reload=True


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
You can find the C code in this temporary file: C:\Users\Ido\AppData\Local\Temp\theano_compilation_error_kkg8qfej
  File ""C:\Program Files\JetBrains\PyCharm Community Edition 2019.2\helpers\pydev\pydevd.py"", line 2060, in <module>
    main()
  File ""C:\Program Files\JetBrains\PyCharm Community Edition 2019.2\helpers\pydev\pydevd.py"", line 2054, in main
    globals = debugger.run(setup['file'], None, None, is_module)
  File ""C:\Program Files\JetBrains\PyCharm Community Edition 2019.2\helpers\pydev\pydevd.py"", line 1405, in run
    return self._exec(is_module, entry_point_fn, module_name, file, globals, locals)
  File ""C:\Program Files\JetBrains\PyCharm Community Edition 2019.2\helpers\pydev\pydevd.py"", line 1412, in _exec
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File ""C:\Program Files\JetBrains\PyCharm Community Edition 2019.2\helpers\pydev\_pydev_imps\_pydev_execfile.py"", line 18, in execfile
    exec(compile(contents+""\n"", file, 'exec'), glob, loc)
  File ""C:/Users/Ido/Documents/Products/ABI_product/Codes/src/nba_py_learning/real_time_predictions.py"", line 1, in <module>
    import keras
  File ""C:\Users\Ido\AppData\Local\conda\conda\envs\py36\lib\site-packages\keras\__init__.py"", line 3, in <module>
    from . import utils
  File ""C:\Users\Ido\AppData\Local\conda\conda\envs\py36\lib\site-packages\keras\utils\__init__.py"", line 6, in <module>
    from . import conv_utils
  File ""C:\Users\Ido\AppData\Local\conda\conda\envs\py36\lib\site-packages\keras\utils\conv_utils.py"", line 9, in <module>
    from .. import backend as K
  File ""C:\Users\Ido\AppData\Local\conda\conda\envs\py36\lib\site-packages\keras\backend\__init__.py"", line 86, in <module>
    from .theano_backend import *
  File ""C:\Users\Ido\AppData\Local\conda\conda\envs\py36\lib\site-packages\keras\backend\theano_backend.py"", line 7, in <module>
    import theano
  File ""C:\Users\Ido\AppData\Local\conda\conda\envs\py36\lib\site-packages\theano\__init__.py"", line 110, in <module>
    from theano.compile import (
  File ""C:\Users\Ido\AppData\Local\conda\conda\envs\py36\lib\site-packages\theano\compile\__init__.py"", line 12, in <module>
    from theano.compile.mode import *
  File ""C:\Users\Ido\AppData\Local\conda\conda\envs\py36\lib\site-packages\theano\compile\mode.py"", line 11, in <module>
    import theano.gof.vm
  File ""C:\Users\Ido\AppData\Local\conda\conda\envs\py36\lib\site-packages\theano\gof\vm.py"", line 674, in <module>
    from . import lazylinker_c
  File ""C:\Users\Ido\AppData\Local\conda\conda\envs\py36\lib\site-packages\theano\gof\lazylinker_c.py"", line 140, in <module>
    preargs=args)
  File ""C:\Users\Ido\AppData\Local\conda\conda\envs\py36\lib\site-packages\theano\gof\cmodule.py"", line 2396, in compile_str
    (status, compile_stderr.replace('\n', '. ')))
. 

Process finished with exit code 1
```
OS: Windows 10
(base) anaconda version: 5.2.0 (run: `conda list anaconda$` thru anaconda prompt) 
(<my_environment_name>) anaconda version: ""custom"" (run: `conda list anaconda$` thru anaconda prompt) 
python: 3.6.8
tensorflow: 1.13.1
Keras: 2.2.4

*Note-  
If I set the `backend` in the file _.keras.json_ it works as expected in the python console of pycharm , but since I have 2 environments (one of python 2.7 and the other of python 3.6) I am looking for efficient approach to run projects on those different environments (one using theano and the other using tensorflow).
",idohi,None,2019-08-09T23:47:01Z,2019-08-11T12:26:21Z
13199,acc and val_acc are not displayed on the progress bar of the training,"I use CNN for semantic segmentation, create 4 output branches, and customize the loss function.

I'm using the following versions:

- Keras 2.2.4
- Python 3.6.8
- tensorflow 1.12.0

When I training,acc and val_acc are not displayed on the progress bar,But loss and val_loss are normally displayed.

`436/436 [==============================] - 160s 367ms/step - loss: 0.4628 - output_0_loss: 0.0351 - output_1_loss: 0.0698 - output_2_loss: 0.1572 - output_3_loss: 0.2008 - output_0_acc: 0.6728 - output_1_acc: 0.6944 - output_2_acc: 0.8087 - output_3_acc: 0.7010 - val_loss: 0.3001 - val_output_0_loss: 0.0145 - val_output_1_loss: 0.0261 - val_output_2_loss: 0.1511 - val_output_3_loss: 0.1083 - val_output_0_acc: 0.9742 - val_output_1_acc: 0.8642 - val_output_2_acc: 0.7887 - val_output_3_acc: 0.8423`

My loss function is binary_crossentropy,I use the metric is ['accuracy']:
`model.compile(loss=my_binary_crossentropy,
                  optimizer=optimizer_name,
                  metrics=['accuracy'])`

The acc and val_acc in history is None: 
`epoch-loss:[0.44138801848175424, 0.31117319703451685] 
 epoch-acc:[None, None] 
 epoch-val_loss:[0.2681478185099933, 0.21369548345525233] 
 epoch-val_acc:[None, None]`

How should I deal with this problem or where to debug it?",cloudpanl,None,2019-08-07T09:38:58Z,2019-08-09T06:47:41Z
13166,importing Keras removes logging handler?,"This is very weird - for whathever reason whenever I import Keras it removes any additional handlers my root logger contained.

``` python
import logging
logging.basicConfig(level=logging.DEBUG,
                    format='%(asctime)s - %(levelname)s - %(message)s',
                    handlers=[
                        logging.FileHandler(""testlog.log""),
                        logging.StreamHandler()
                    ])

print(logging.getLogger().handlers)

import keras

print(logging.getLogger().handlers)
```

This script will return the above:
```
[<FileHandler /Users/agralak/PycharmProjects/QML/testlog.log (NOTSET)>, <StreamHandler <stderr> (NOTSET)>]
Using TensorFlow backend.
[<FileHandler /Users/agralak/PycharmProjects/QML/testlog.log (NOTSET)>]
```

Let me know if I need to provide anything else!",agralak-queueco,None,2019-07-30T13:13:53Z,2019-07-30T13:43:29Z
13138,RNN initial state: bug fix + suppress false warning,"
### Summary
1 - Suppresses a false warning when serializing models containing RNNs with initial state (makes people think seq2seq models are not serializable)

2 - Makes custom RNNs with extra args in `call()` serializable when an initial state is also provided (super niche, I know)

### Related Issues

#9914 
[StackOverflow Saving Keras model - UserWarning: Layer XX was passed non-serializable keyword arguments](https://stackoverflow.com/questions/53761145)

### PR Overview

- [y] This PR requires new unit tests [y/n] (make sure tests are included)
- [n] This PR requires to update the documentation [y/n] (make sure the docs are up-to-date)
- [y] This PR is backwards compatible [y/n]
- [n] This PR changes the current API [y/n] (all API changes need to be approved by fchollet)
",farizrahman4u,None,2019-07-22T22:01:18Z,2019-07-25T20:29:50Z
13128,Keras predict_generator fit_generator memory leak with keras.utils.Sequence data generator,"As title told, the memory keep growing when I train my model with fit_generator or do prediction with predict_generator with keras.utils.Sequence data generator, until the program crashed.

The workaround I found as below:

![A82A66E0-26BC-473C-8796-A8F191A6CB87](https://user-images.githubusercontent.com/24580114/61574536-bdd2e280-aaf3-11e9-92cb-ac0d773bb322.jpeg)

That is: splitting the dataset again and in between call gc.collect purposely to stabilize the memory usage.

So I believe this is a bug, somehow keras doesn't release the unnecessary memory in between batches.
",lnshi,None,2019-07-20T05:42:14Z,2019-07-20T09:54:36Z
13126,Explanation on ConvS2S prediction array,"<em>Please make sure that this is a Bug or a Feature Request and provide all applicable information asked by the template.
If your issue is an **implementation question**, please ask your question on [StackOverflow](http://stackoverflow.com/questions/tagged/keras) or [on the Keras Slack channel](https://keras-slack-autojoin.herokuapp.com/) instead of opening a GitHub issue.</em>  

**System information**  
- Have I written custom code (as opposed to using example directory):  
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  
- TensorFlow backend (yes / no):  
- TensorFlow version:  
- Keras version:  
- Python version:  
- CUDA/cuDNN version:  
- GPU model and memory:  

You can obtain the TensorFlow version with:  
python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""  
You can obtain the Keras version with:  
python -c 'import keras as k; print(k.__version__)'  

**Describe the current behavior**  

**Describe the expected behavior**  

**Code to reproduce the issue**  
Provide a reproducible test case that is the bare minimum necessary to generate the problem.  

**Other info / logs**  
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. 

I'm running the ConvS2S example, the model trains just fine, but the inference code it's not clear enough, why does the prediction arrays have the length of the inputs_texts?

Thanks in advance.

![image](https://user-images.githubusercontent.com/16644771/61557993-28c0e280-aa3c-11e9-8b43-dd1519deb66f.png)



",limapedro,b'type:support',2019-07-19T18:46:38Z,2019-07-23T21:09:52Z
13093,Non-OK-status:  Internal: invalid configuration argument Aborted (core dumped),"<em>Please make sure that this is a Bug or a Feature Request and provide all applicable information asked by the template.
If your issue is an **implementation question**, please ask your question on [StackOverflow](http://stackoverflow.com/questions/tagged/keras) or [on the Keras Slack channel](https://keras-slack-autojoin.herokuapp.com/) instead of opening a GitHub issue.</em>  

**System information**  
- Have I written custom code (as opposed to using example directory):  
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  Linux Ubuntu 16.04
- TensorFlow backend (yes / no):  yes
- TensorFlow version:  v1.14.0-rc1-22-gaf24dc91b5 1.14.0
- Keras version:  2.2.4
- Python version:  3.6
- CUDA/cuDNN version:  Cuda compilation tools, release 10.0, V10.0.130
- GPU model and memory:  2 gpus, each 11 GB

You can obtain the TensorFlow version with:  
python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""  
You can obtain the Keras version with:  
python -c 'import keras as k; print(k.__version__)'  

**Describe the current behavior**  
I was using below code to build a LSTM model.
```
    left = Input(shape=(128, 3072), dtype='float32', name='Input-Left')
    right = Input(shape=(128, 3072), dtype='float32', name='Input-Right')
    lstm = Bidirectional(LSTM(units=768,
                              activation='tanh'),
                         name='Bidirectional-LSTM')
    l_lstm = lstm(left)
    r_lstm = lstm(right)
    subtracted = Subtract(name='Subtract')([l_lstm, r_lstm])
    abs_subtracted = Lambda(function=backend.abs)(subtracted)
    mul = Multiply(name='multiplication')([l_lstm, r_lstm])
    concat = concatenate([abs_subtracted, mul])
    output = Dense(units=1)(concat)
    model = Model(inputs=[left, right],
                  outputs=output)
    model = multi_gpu_model(model, gpus=2)
    model.compile(loss='mean_squared_error',
                  optimizer='Adam',
                  metrics=['acc'])
```

**Describe the expected behavior**  
expect the code run without error.

**Code to reproduce the issue**  
Provide a reproducible test case that is the bare minimum necessary to generate the problem.  

**Other info / logs**  
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.  

get the following error
```
2019-07-11 00:34:47.259516: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-07-11 00:34:47.261497: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-07-11 00:34:47.263346: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-07-11 00:34:47.263979: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-07-11 00:34:47.264617: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0, 1
2019-07-11 00:34:49.404341: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-11 00:34:49.404385: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 1 
2019-07-11 00:34:49.404390: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N Y 
2019-07-11 00:34:49.404394: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 1:   Y N 
2019-07-11 00:34:49.404729: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-07-11 00:34:49.405481: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-07-11 00:34:49.406172: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-07-11 00:34:49.406916: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9428 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
2019-07-11 00:34:49.407465: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-07-11 00:34:49.408128: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 10039 MB memory) -> physical GPU (device: 1, name: GeForce GTX 1080 Ti, pci bus id: 0000:02:00.0, compute capability: 6.1)
2019-07-11 00:34:49.942669: F ./tensorflow/core/kernels/random_op_gpu.h:227] Non-OK-status: CudaLaunchKernel(FillPhiloxRandomKernelLaunch<Distribution>, num_blocks, block_size, 0, d.stream(), gen, data, size, dist) status: Internal: invalid configuration argument
Aborted (core dumped)
```

",xinsu626,b'backend:tensorflow stat:awaiting tensorflower type:bug/performance',2019-07-11T05:42:14Z,2020-09-08T14:56:18Z
13092,SimpleRNN layer output a wrong shape tensor,"<em>Please make sure that this is a Bug or a Feature Request and provide all applicable information asked by the template.
If your issue is an **implementation question**, please ask your question on [StackOverflow](http://stackoverflow.com/questions/tagged/keras) or [on the Keras Slack channel](https://keras-slack-autojoin.herokuapp.com/) instead of opening a GitHub issue.</em>  

**System information**  
Keras 2.2.4
TensorFlow 1.14.0
Python 3.6

You can obtain the TensorFlow version with:  
python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""  
You can obtain the Keras version with:  
python -c 'import keras as k; print(k.__version__)'  

**Describe the current behavior**  
```
import keras as k
# ---------------
ins = k.layers.Input(shape=(1,10,))
pre = k.layers.Input(shape=(1,10,))
feature_processed, cur_state = k.layers.SimpleRNN(10, return_state=True)(inputs=ins, initial_state=pre)
out = feature_processed
# ---------------
m = k.models.Model(inputs=[ins,pre], outputs=out)
m.compile(optimizer='SGD', loss='mean_squared_error')
# ---------------
res = m.predict(x=[np.concatenate((np.zeros((1,1,10)), np.ones((1,1,10)), np.zeros((1,1,10))), axis=0), np.zeros((3,1,10))])
res.shape
```
> (3, 3, 10)

**Describe the expected behavior**  
> (3, 10)
or
> (3, 1, 10)

**Code to reproduce the issue**  
Provide a reproducible test case that is the bare minimum necessary to generate the problem.  

**Other info / logs**  
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.  
",GuanxiongLiu,None,2019-07-10T20:22:01Z,2019-07-10T20:54:28Z
13075,How to reset the connection of a layer?,"<em>Please make sure that this is a Bug or a Feature Request and provide all applicable information asked by the template.
If your issue is an **implementation question**, please ask your question on [StackOverflow](http://stackoverflow.com/questions/tagged/keras) or [on the Keras Slack channel](https://keras-slack-autojoin.herokuapp.com/) instead of opening a GitHub issue.</em>  

**System information**  
- Have I written custom code (as opposed to using example directory):  
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  
- TensorFlow backend (yes / no):  
- TensorFlow version:  
- Keras version:  
- Python version:  
- CUDA/cuDNN version:  
- GPU model and memory:  

You can obtain the TensorFlow version with:  
python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""  
You can obtain the Keras version with:  
python -c 'import keras as k; print(k.__version__)'  

**Describe the current behavior**  

**Describe the expected behavior**  

**Code to reproduce the issue**  
Provide a reproducible test case that is the bare minimum necessary to generate the problem.  

**Other info / logs**  
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.  


I want to clone a Conv2D layer without makes it has more than one inbounds node for later usage. ",zxydi1992,b'backend:tensorflow type:support',2019-07-06T19:31:39Z,2019-07-08T23:04:46Z
13064,layers.Bidirectional doesn't support multi_gpu_model() method,"**System information**  
- Have I written custom code (as opposed to using example directory):  Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  Ubuntu 16.04
- TensorFlow backend (yes / no):  Yes
- TensorFlow version:  1.12.0
- Keras version:  Latest
- Python version:  3.6
- CUDA/cuDNN version:  CUDA 9.0 / libcudnn7_7.0.5.15-1+cuda9.0_amd64
- GPU model and memory:  2 * RTX 2070 8G

**Describe the current behavior**  
I created a model by using the bidirectional LSTM but it cannot be passed through multi_gpu_model() method when I trying to do the distributed training.
```
with tf.device('/cpu:0'):
     model = tf.keras.Sequential()
     model.add(layers.Bidirectional(layers.LSTM(_HIDDEN_SIZE, return_sequences=True, input_shape=(_TIME_STEPS, _FEATURE_DIMENTIONS))))
     model.add(layers.Dropout(0.5))
     model.add(layers.Bidirectional(layers.LSTM(_HIDDEN_SIZE, return_sequences=True)))
     model.add(layers.Dropout(0.5))
     model.add(layers.TimeDistributed(layers.Dense(_NUM_CLASSES)))
     model.add(layers.Flatten())
     model.add(layers.Dense(_NUM_CLASSES, activation='softmax'))
```
If you remove the bidirectional wrapper and use the normal LSTM layer, the error below will not happen:
```
2019-07-05 12:09:29.034218: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-05 12:09:29.199596: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-07-05 12:09:29.200231: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: GeForce RTX 2070 major: 7 minor: 5 memoryClockRate(GHz): 1.725
pciBusID: 0000:01:00.0
totalMemory: 7.76GiB freeMemory: 7.42GiB
2019-07-05 12:09:29.329679: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-07-05 12:09:29.330551: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 1 with properties: 
name: GeForce RTX 2070 major: 7 minor: 5 memoryClockRate(GHz): 1.725
pciBusID: 0000:03:00.0
totalMemory: 7.77GiB freeMemory: 7.65GiB
2019-07-05 12:09:29.330632: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0, 1
2019-07-05 12:09:29.806507: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-05 12:09:29.806532: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 1 
2019-07-05 12:09:29.806537: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N N 
2019-07-05 12:09:29.806540: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 1:   N N 
2019-07-05 12:09:29.807007: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7134 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2070, pci bus id: 0000:01:00.0, compute capability: 7.5)
2019-07-05 12:09:29.807412: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 7358 MB memory) -> physical GPU (device: 1, name: GeForce RTX 2070, pci bus id: 0000:03:00.0, compute capability: 7.5)
Traceback (most recent call last):
  File ""debug.py"", line 54, in <module>
    para_model = multi_gpu_model(model, gpus = _GPUs, cpu_merge = True, cpu_relocation = False)
  File ""/home/tpc2/anaconda3/envs/machine-learning/lib/python3.6/site-packages/tensorflow/python/keras/utils/multi_gpu_utils.py"", line 239, in multi_gpu_model
    outputs = model(inputs)
  File ""/home/tpc2/anaconda3/envs/machine-learning/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py"", line 694, in __call__
    in_deferred_mode = isinstance(input_list[0], DeferredTensor)
IndexError: list index out of range
```
**Code to reproduce the issue**  
The testing code has been attached below:
```
import numpy as np
import csv
import time
import math
import tensorflow as tf
from tensorflow.keras import layers
from tensorflow.keras.utils import multi_gpu_model


# parameters here
_GPUs = 2
_LR = 0.00003
_BATCH_SIZE = 128
_EPOCH = 150
_NUM_CLASSES = 2
_TIME_STEPS = 10
_FEATURE_DIMENTIONS = 34
_HIDDEN_SIZE = 300


# Model defined below: Bidirectional LSTM + Fully connected layers
with tf.device('/cpu:0'):
    model = tf.keras.Sequential()
    model.add(layers.Bidirectional(layers.LSTM(_HIDDEN_SIZE, return_sequences=True, input_shape=(_TIME_STEPS, _FEATURE_DIMENTIONS))))
    model.add(layers.Dropout(0.5))
    model.add(layers.Bidirectional(layers.LSTM(_HIDDEN_SIZE, return_sequences=True)))
    model.add(layers.Dropout(0.5))
    model.add(layers.TimeDistributed(layers.Dense(_NUM_CLASSES)))
    model.add(layers.Flatten())
    model.add(layers.Dense(_NUM_CLASSES, activation='softmax'))
    opt = tf.keras.optimizers.Adam(lr = _LR)

para_model = multi_gpu_model(model, gpus = _GPUs, cpu_merge = True, cpu_relocation = False)
para_model.compile(optimizer = opt, loss = 'binary_crossentropy', metrics = ['accuracy'])
```
Anyone know it's a bug or caused by myself? Thank you.",KimMeen,None,2019-07-05T02:20:48Z,2019-07-06T02:21:57Z
13057,multi_gpu_model not working w/ TensorFlow 1.14 ,"
**System information**  
- Have I written custom code (as opposed to using example directory):  No/Yes (very slight change to an example)
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  Ubuntu 16.04
- TensorFlow backend (yes / no):  yes
- TensorFlow version:  1.14
- Keras version: Latest master from github
- Python version:  3.7 (through Anaconda)
- CUDA/cuDNN version:  10.0/7.4.2
- GPU model and memory:  2x Tesla K80 (11GB each)

**Describe the current behavior**  

I am using the cifar-10 ResNet example from the Keras examples directory, with the addition of the following line at Line number 360 (just before compilation) in order to use multiple GPUs while training. However this doesn't work.

Line Added:
`model = keras.utils.multi_gpu_model(model, gpus=2)`

Traceback Error log:

```
Traceback (most recent call last):
  File ""cifar10_resnet_multigpu.py"", line 360, in <module>
    model = keras.utils.multi_gpu_model(model, gpus=2)
  File ""/local/home/manasa/vpds2/conda/anaconda3/envs/tensorflow114/lib/python3.7/site-packages/keras/utils/multi_gpu_utils.py"", line 230, in multi_gpu_model
    outputs = model(inputs)
  File ""/local/home/manasa/vpds2/conda/anaconda3/envs/tensorflow114/lib/python3.7/site-packages/keras/engine/base_layer.py"", line 451, in __call__
    output = self.call(inputs, **kwargs)
  File ""/local/home/manasa/vpds2/conda/anaconda3/envs/tensorflow114/lib/python3.7/site-packages/keras/engine/network.py"", line 570, in call
    output_tensors, _, _ = self.run_internal_graph(inputs, masks)
  File ""/local/home/manasa/vpds2/conda/anaconda3/envs/tensorflow114/lib/python3.7/site-packages/keras/engine/network.py"", line 727, in run_internal_graph
    layer.call(computed_tensor, **kwargs))
  File ""/local/home/manasa/vpds2/conda/anaconda3/envs/tensorflow114/lib/python3.7/site-packages/keras/layers/normalization.py"", line 185, in call
    epsilon=self.epsilon)
  File ""/local/home/manasa/vpds2/conda/anaconda3/envs/tensorflow114/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py"", line 2053, in normalize_batch_in_training
    if not _has_nchw_support() and list(reduction_axes) == [0, 2, 3]:
  File ""/local/home/manasa/vpds2/conda/anaconda3/envs/tensorflow114/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py"", line 299, in _has_nchw_support
    explicitly_on_cpu = _is_current_explicit_device('CPU')
  File ""/local/home/manasa/vpds2/conda/anaconda3/envs/tensorflow114/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py"", line 272, in _is_current_explicit_device
    device = _get_current_tf_device()
  File ""/local/home/manasa/vpds2/conda/anaconda3/envs/tensorflow114/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py"", line 252, in _get_current_tf_device
    g._apply_device_functions(op)
  File ""/local/home/manasa/vpds2/conda/anaconda3/envs/tensorflow114/lib/python3.7/site-packages/tensorflow/python/framework/ops.py"", line 4581, in _apply_device_functions
    op._set_device_from_string(device_string)
AttributeError: '_TfDeviceCaptureOp' object has no attribute '_set_device_from_string'

```

**Describe the expected behavior** 

Previously, this typically worked fine and results in faster training due to parallelization across GPUs. 

**Note:** This works fine if the backend is Tensorflow 1.13, so this is a regression. 
",rohit-gupta,b'backend:tensorflow stat:awaiting tensorflower type:bug/performance',2019-07-03T11:05:14Z,2020-09-29T09:52:42Z
13056,training accuracy increase fast validation accuracy not change,"I'm training a model with inception_v3 net in keras to classify the images into 4 categories. However, after many times debugging, my validation accuracy not change and the training accuracy reaches very high about 95% at the first epoch. I got a large dataset including 407 tf-records files. can someone help me?

I'm trying to classify images into 4 categories which are Crystal, Clear, Precipitate and Other, their label are 0, 1, 2, 3. But my code seems not get good result. https://marco.ccr.buffalo.edu/download This is the website of the dataset.

I don't know why the training acc increases so fast while the validation acc not change even run up to more than 10 epochs. There must be some problem with my code. Can some one help me?

`batch_size = 64
num_classes = 4
epochs = 2000
train_steps_per_epoch = 6500
vali_steps_per_epoch = 735

ignore_order = tf.data.Options()
ignore_order.experimental_deterministic = False
AUTO = tf.data.experimental.AUTOTUNE

train_files = tf.data.Dataset.list_files(""./work/train/train*"", seed=2)
train_files = train_files.with_options(ignore_order)
train_files = train_files.interleave(tf.data.TFRecordDataset, 
                             cycle_length=407,
                             num_parallel_calls=tf.data.experimental.AUTOTUNE)

validation_files = tf.data.Dataset.list_files(""./work/test/test*"", seed=3)
validation_files = validation_files.with_options(ignore_order)
validation_files = validation_files.interleave(tf.data.TFRecordDataset,
                                                cycle_length=46,
                                                num_parallel_calls=tf.data.experimental.AUTOTUNE)

def decode_example(example_proto):
    image_feature_description = {
    'image/height': tf.io.FixedLenFeature([], tf.int64),
    'image/width': tf.io.FixedLenFeature([], tf.int64),
    'image/colorspace': tf.io.FixedLenFeature([], tf.string),
    'image/channels': tf.io.FixedLenFeature([], tf.int64),
    'image/class/label': tf.io.FixedLenFeature([], tf.int64),
    'image/class/raw': tf.io.FixedLenFeature([], tf.int64),
    'image/class/source': tf.io.FixedLenFeature([], tf.int64),
    'image/class/text': tf.io.FixedLenFeature([], tf.string),
    'image/format': tf.io.FixedLenFeature([], tf.string),
    'image/filename': tf.io.FixedLenFeature([], tf.string),
    'image/id': tf.io.FixedLenFeature([], tf.int64),
    'image/encoded': tf.io.FixedLenFeature([], tf.string),
}
    parsed_features = tf.io.parse_single_example(example_proto, image_feature_description)
    height = tf.cast(parsed_features['image/height'], tf.int32)
    width = tf.cast(parsed_features['image/width'], tf.int32)
    channels = tf.cast(parsed_features['image/channels'], tf.int32)
    label = tf.cast(parsed_features['image/class/label'], tf.int32)
    image_buffer = parsed_features['image/encoded']
    image = tf.io.decode_jpeg(image_buffer, channels=3)
    image = tf.image.central_crop(image, 0.8)
    image = tf.image.resize(image, [299, 299])
    image = tf.cast(image, tf.float32) / 255.0
    return image, label

def image_augmentation(image, label):
    if random.random() < 0.5:
        image = tf.image.random_flip_left_right(image)
    image = tf.image.random_brightness(image=image, max_delta=32/255.0)
    image = tf.image.random_contrast(image, 0.5, 1.5)
    image = tf.image.random_hue(image, 0.2)
    return image, label

def processed_dataset(dataset):
    dataset = dataset.shuffle(buffer_size=10000, seed=1)
    dataset = dataset.repeat()
    dataset = dataset.batch(batch_size)
    dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)
    return dataset

def data_generator(dataset):
    iter = tf.compat.v1.data.make_one_shot_iterator(dataset)
    image, label = iter.get_next()
    while True:
        yield image, tf.keras.utils.to_categorical(label, num_classes=num_classes)

train_dataset = train_files.map(decode_example, num_parallel_calls=AUTO)
train_dataset = train_dataset.map(image_augmentation, num_parallel_calls=AUTO)
train_dataset = processed_dataset(train_dataset)
validation_dataset = validation_files.map(decode_example, num_parallel_calls=AUTO)
validation_dataset = processed_dataset(validation_dataset)

model = tf.keras.applications.inception_v3.InceptionV3(include_top=True, weights=None, input_tensor=None, input_shape=None, pooling=None, classes=4)

def step_decay(epoch):
    initial_lrate = 0.005
    drop = 0.94
    epochs_drop = 2.0
    lrate = initial_lrate * math.pow(drop,  
           math.floor((1+epoch)/epochs_drop))
    return lrate

model.compile(loss='categorical_crossentropy',
              optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.005, momentum=0.9, epsilon=0.1, decay=0.9),
              metrics=['accuracy'])

checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(""classification_model.h5"",                                          
                                                   save_best_only=True)
early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=10,                                  
                                                  restore_best_weights=True)

lrate = tf.keras.callbacks.LearningRateScheduler(step_decay)

history = model.fit_generator(
    data_generator(train_dataset),
    steps_per_epoch=train_steps_per_epoch,
    epochs=epochs,
    verbose=1,
    callbacks=[lrate, checkpoint_cb, early_stopping_cb],
    validation_data=data_generator(validation_dataset),
    validation_steps=vali_steps_per_epoch,
    workers = 0 
)`


result:
Epoch 1/2000
6500/6500 [==============================] - 3942s 606ms/step - loss: 0.0065 - accuracy: 0.9982 - val_loss: 3.2384 - val_accuracy: 0.4062
Epoch 2/2000
6500/6500 [==============================] - 3151s 485ms/step - loss: 8.6521e-04 - accuracy: 1.0000 - val_loss: 3.2648 - val_accuracy: 0.4062
Epoch 3/2000
6500/6500 [==============================] - 3152s 485ms/step - loss: 8.1589e-04 - accuracy: 1.0000 - val_loss: 3.2768 - val_accuracy: 0.4062
Epoch 4/2000
6500/6500 [==============================] - 3152s 485ms/step - loss: 7.9254e-04 - accuracy: 1.0000 - val_loss: 3.2835 - val_ac
Thank you!
",Johnny65456,b'stat:awaiting response type:support',2019-07-03T05:44:34Z,2019-08-02T17:26:08Z
13047,model created through Sequential and Functional APIs behaves differently.,"
Created two same CNN one with Sequential API and another with Functional API. One created using Sequential API outputs good validation accuracy around 80-85% but another created with Functional API behaves weird and output validation accuracy about 10-20%.

",shivg7706,b'backend:tensorflow stat:awaiting tensorflower type:bug/performance',2019-07-02T07:01:22Z,2019-07-31T04:54:30Z
13009,BatchNormalization doesn,"<em>Please make sure that this is a Bug or a Feature Request and provide all applicable information asked by the template.
If your issue is an **implementation question**, please ask your question on [StackOverflow](http://stackoverflow.com/questions/tagged/keras) or [on the Keras Slack channel](https://keras-slack-autojoin.herokuapp.com/) instead of opening a GitHub issue.</em>  

**System information**  
- Have I written custom code (as opposed to using example directory):  
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  
- TensorFlow backend (yes / no):  
- TensorFlow version:  
- Keras version:  
- Python version:  
- CUDA/cuDNN version:  
- GPU model and memory:  

You can obtain the TensorFlow version with:  
python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""  
You can obtain the Keras version with:  
python -c 'import keras as k; print(k.__version__)'  

**Describe the current behavior**  

**Describe the expected behavior**  

**Code to reproduce the issue**  
Provide a reproducible test case that is the bare minimum necessary to generate the problem.  

**Other info / logs**  
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.  
",LukeBolly,None,2019-06-26T02:57:51Z,2019-06-26T02:58:40Z
12999,Can I use BatchNormalization after a conv3d layer?  ,"<em>Please make sure that this is a Bug or a Feature Request and provide all applicable information asked by the template.
If your issue is an **implementation question**, please ask your question on [StackOverflow](http://stackoverflow.com/questions/tagged/keras) or [on the Keras Slack channel](https://keras-slack-autojoin.herokuapp.com/) instead of opening a GitHub issue.</em>  

**System information**  
- Have I written custom code (as opposed to using example directory):  
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  
- TensorFlow backend (yes / no):  
- TensorFlow version:  
- Keras version:  
- Python version:  
- CUDA/cuDNN version:  
- GPU model and memory:  

You can obtain the TensorFlow version with:  
python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""  
You can obtain the Keras version with:  
python -c 'import keras as k; print(k.__version__)'  

**Describe the current behavior**  

**Describe the expected behavior**  

**Code to reproduce the issue**  
Provide a reproducible test case that is the bare minimum necessary to generate the problem.  

**Other info / logs**  
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.  
",xuzhang5788,None,2019-06-22T00:32:39Z,2019-06-22T00:33:29Z
12988,custom objective function ,"<em>Please make sure that this is a Bug or a Feature Request and provide all applicable information asked by the template.
If your issue is an **implementation question**, please ask your question on [StackOverflow](http://stackoverflow.com/questions/tagged/keras) or [on the Keras Slack channel](https://keras-slack-autojoin.herokuapp.com/) instead of opening a GitHub issue.</em>  

**System information**  
- Have I written custom code (as opposed to using example directory):  
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  
- TensorFlow backend (yes / no):  
- TensorFlow version:  
- Keras version:  
- Python version:  
- CUDA/cuDNN version:  
- GPU model and memory:  

You can obtain the TensorFlow version with:  
python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""  
You can obtain the Keras version with:  
python -c 'import keras as k; print(k.__version__)'  

**Describe the current behavior**  

**Describe the expected behavior**  

**Code to reproduce the issue**  
Provide a reproducible test case that is the bare minimum necessary to generate the problem.  

**Other info / logs**  
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.  
",chengjianhong,None,2019-06-20T00:43:46Z,2019-06-20T00:46:09Z
12974,custom loss function | keras,"<em>Please make sure that this is a Bug or a Feature Request and provide all applicable information asked by the template.
If your issue is an **implementation question**, please ask your question on [StackOverflow](http://stackoverflow.com/questions/tagged/keras) or [on the Keras Slack channel](https://keras-slack-autojoin.herokuapp.com/) instead of opening a GitHub issue.</em>  

**System information**  
- Have I written custom code (as opposed to using example directory):  
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  
- TensorFlow backend (yes / no):  
- TensorFlow version:  
- Keras version:  
- Python version:  
- CUDA/cuDNN version:  
- GPU model and memory:  

You can obtain the TensorFlow version with:  
python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""  
You can obtain the Keras version with:  
python -c 'import keras as k; print(k.__version__)'  

**Describe the current behavior**  

**Describe the expected behavior**  

**Code to reproduce the issue**  
Provide a reproducible test case that is the bare minimum necessary to generate the problem.  

**Other info / logs**  
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.  
",SwagatDas,None,2019-06-17T10:52:55Z,2019-06-17T10:53:17Z
12969,Receiving AttributeError: 'Tensor' object has no attribute 'numpy' in keras backend.,"Okay, so... I'm trying to implement a custom loss function in tf-keras. 

My tf version is 1.13.1, my keras version is 2.2.4, my OS is Linux Mint Ubuntu 16.04, and my python version is Anaconda Python 3.6.8


Basically, this loss function is a Keras dense siamese neural network that I'm trying to get to learn a loss between y_true and y_pred. However I receive the above error every time the model above this loss func. compiles. The input_shape param is (1, 1920), and the code is as follows:

Siamese Net Code:
```
class SiameseNetwork:
    def __init__(self, input_shape):
        self.input_shape = input_shape
        self.true_input = (1,) + input_shape
        
        self.base_net = self.build_base()
        self.input_one = Input(shape=self.input_shape)
        self.input_two = Input(shape=self.input_shape)

        self.processed_one = self.base_net(self.input_one)
        self.processed_two = self.base_net(self.input_two)

        self.distance = Lambda(self.euclidean_distance)([self.processed_one, self.processed_two])
        self.together = Dense(1, activation=self.reverse_sigmoid)(self.distance)

        self.siamese_net = Model([self.input_one, self.input_two], self.together)
        self.siamese_net.summary()

        loss = self.contrastive_meta_loss
        optimizer = RMSprop()

        self.siamese_net.compile(loss=loss, optimizer=optimizer)

        self.loss = 1.0

        self.random_input = np.random.random_sample(self.true_input)

        print(""Random input shape"", self.random_input.shape)

        self.y_pred = self.random_input
        self.y_true = self.random_input
        
        print('debugging: y_true shape:',   self.y_true.shape)
        
    def reverse_sigmoid(self, x):
        return K.sigmoid(-x)

    def contrastive_meta_loss(self, y_true, y_pred):
        margin = 1

        square_pred = K.square(y_pred)
        margin_square = K.square(K.maximum(margin - y_pred, 0))
        return K.mean(y_true * square_pred + (1 - y_true) * margin_square)
    
    def build_base(self):
        inputs = Input(shape=self.input_shape)
        x = Flatten()(inputs)
        x = tf.layers.Dense(1024, activation='relu')(x)
        x = tf.layers.Dropout(.1)(x)
        x = tf.layers.Dense(1024, activation='relu')(x)
        x = tf.layers.Dropout(.1)(x)
        x = tf.layers.Dense(1024, activation='relu')(x)
        model = Model(inputs, x)
        print(""Debugging: 110XA25B:"")
        model.summary()
        return model
    
    def euclidean_distance(self, vects):
        x, y = vects
        sum_sq = K.sum(K.square(x - y), axis = 1, keepdims=True)
        return K.sqrt(K.maximum(sum_sq, K.epsilon()))
    
    def siamese_loss(self, fake_y_true, fake_y_pred):

        print(""Debugging: 110XA1SS:"", self.y_true.shape, self.y_pred.shape)

    
        self.loss = self.siamese_net.predict([self.y_true, self.y_pred])

        self.siamese_net.fit(x=[y_true, y_pred], y=self.loss, epochs=1, verbose=0)
        return self.loss
```

Error + Traceback:

```
Traceback (most recent call last):
  File ""run_mouse_rewards.py"", line 109, in <module>
    run()
  File ""run_mouse_rewards.py"", line 45, in run
    dqn.initialize()
  File ""/home/ai/Downloads/ScreenMouse/Organized/ba2c.py"", line 232, in initialize
    self.actor.compile(loss=self.actor_loss, optimizer = self.optimizer)
  File ""/home/ai/anaconda3/envs/drl/lib/python3.6/site-packages/tensorflow/python/training/checkpointable/base.py"", line 442, in _method_wrapper
    method(self, *args, **kwargs)
  File ""/home/ai/anaconda3/envs/drl/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py"", line 449, in compile
    output_loss = weighted_loss(y_true, y_pred, sample_weight, mask)
  File ""/home/ai/anaconda3/envs/drl/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_utils.py"", line 647, in weighted
    score_array = fn(y_true, y_pred)
  File ""/home/ai/Downloads/ScreenMouse/Organized/ba2c.py"", line 87, in siamese_loss
    self.loss = self.siamese_net.predict([self.y_true, self.y_pred])
  File ""/home/ai/anaconda3/envs/drl/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py"", line 1113, in predict
    self, x, batch_size=batch_size, verbose=verbose, steps=steps)
  File ""/home/ai/anaconda3/envs/drl/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py"", line 329, in model_iteration
    batch_outs = f(ins_batch)
  File ""/home/ai/anaconda3/envs/drl/lib/python3.6/site-packages/tensorflow/python/keras/backend.py"", line 3168, in __call__
    [x.numpy() for x in outputs])
  File ""/home/ai/anaconda3/envs/drl/lib/python3.6/site-packages/tensorflow/python/keras/backend.py"", line 3168, in <listcomp>
    [x.numpy() for x in outputs])
AttributeError: 'Tensor' object has no attribute 'numpy'
```
",ZeroMaxinumXZ,b'backend:tensorflow stat:awaiting response type:bug/performance',2019-06-16T06:28:32Z,2019-06-20T08:23:39Z
12961,keras v 2.2.4-tf save model ValueError: Could not pack sequence.,"I am using tensorflow.keras on colab.research.google.com. It runs good till today.
I notice the tf version upgraded from 1.13 to 1.14.0-rc1, and tf.keras.__version__ is 2.2.4-tf.
I have trained the same model and saved well before. But now, when I call model.save( ... ), an error occurs like:

> 
<ipython-input-7-4c39570d6921> in ChkEvaluate()
     18         MinEvaLoss = EvLoss
     19         if EvLoss < 0.47:
---> 20             mo.save( DIR + 'model3_Rd' )
     21             Saved += 1
     22             print( '--------- model saved. ---------' )

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/network.py in save(self, filepath, overwrite, include_optimizer, save_format)
   1209     ```
   1210     """"""
-> 1211     saving.save_model(self, filepath, overwrite, include_optimizer, save_format)
   1212 
   1213   def save_weights(self, filepath, overwrite=True, save_format=None):

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/save.py in save_model(model, filepath, overwrite, include_optimizer, save_format)
    111           'or using `save_weights`.')
    112     hdf5_format.save_model_to_hdf5(
--> 113         model, filepath, overwrite, include_optimizer)
    114     return
    115 

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/hdf5_format.py in save_model_to_hdf5(model, filepath, overwrite, include_optimizer)
     97         {
     98             'class_name': model.__class__.__name__,
---> 99             'config': model.get_config()
    100         },
    101         default=serialization.get_json_type).encode('utf8')

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/network.py in get_config(self)
    991       model_inputs.append(
    992           tf_utils.ListWrapper([layer.name, new_node_index, tensor_index]))
--> 993     model_inputs = nest.pack_sequence_as(self._nested_inputs, model_inputs)
    994     # Preserve external Keras compat for Models with single input.
    995     if not nest.is_sequence(model_inputs):

/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py in pack_sequence_as(structure, flat_sequence, expand_composites)
    447           ""Could not pack sequence. Structure had %d elements, but ""
    448           ""flat_sequence had %d elements.  Structure: %s, flat_sequence: %s."" %
--> 449           (len(flat_structure), len(flat_sequence), structure, flat_sequence))
    450   return _sequence_like(structure, packed)
    451 

ValueError: Could not pack sequence. Structure had 21 elements, but flat_sequence had 1 elements.  Structure: [<tf.Tensor 'tshare_1:0' shape=(?, 240, 1) dtype=float32>, <tf.Tensor 'm_5_1:0' shape=(?, 3, 20, 1) dtype=float32>, <tf.Tensor 'm_15_1:0' shape=(?, 3, 20, 1) dtype=float32>, <tf.Tensor 'm_60_1:0' shape=(?, 3, 20, 1) dtype=float32>, <tf.Tensor 'm_240_1:0' shape=(?, 3, 20, 1) dtype=float32>, <tf.Tensor 'm1680_1:0' shape=(?, 3, 20, 1) dtype=float32>, <tf.Tensor 'm4800_1:0' shape=(?, 3, 20, 1) dtype=float32>, <tf.Tensor 'r15_1:0' shape=(?, 3, 15, 1) dtype=float32>, <tf.Tensor 'r60_1:0' shape=(?, 3, 15, 1) dtype=float32>, <tf.Tensor 'r240_1:0' shape=(?, 3, 15, 1) dtype=float32>, <tf.Tensor 'r1680_1:0' shape=(?, 3, 15, 1) dtype=float32>, <tf.Tensor 'r4800_1:0' shape=(?, 3, 15, 1) dtype=float32>, <tf.Tensor 'indik15_1:0' shape=(?, 3, 13, 1) dtype=float32>, <tf.Tensor 'indik60_1:0' shape=(?, 3, 13, 1) dtype=float32>, <tf.Tensor 'indik240_1:0' shape=(?, 3, 13, 1) dtype=float32>, <tf.Tensor 'indik1680_1:0' shape=(?, 3, 13, 1) dtype=float32>, <tf.Tensor 'indik4800_1:0' shape=(?, 3, 13, 1) dtype=float32>, <tf.Tensor 'ks_1:0' shape=(?, 60) dtype=float32>, <tf.Tensor 'dayinfo_1:0' shape=(?, 4) dtype=float32>, <tf.Tensor 'maday_1:0' shape=(?, 5, 10, 1) dtype=float32>, <tf.Tensor 'polyline_1:0' shape=(?, 20, 4, 1) dtype=float32>], flat_sequence: [<tensorflow.python.keras.utils.tf_utils.ListWrapper object at 0x7f44949ea2b0>].",saintthor,b'backend:tensorflow stat:awaiting response type:bug/performance',2019-06-14T14:59:49Z,2019-07-09T16:19:18Z
12959,tf.keras.Model.evaluate skews score in custom tf.keras.callbacks.Callback,"**System information**  
- Have I written custom code (as opposed to using example directory): YES
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  Ubuntu 18.04.2 LTS
- TensorFlow backend (yes / no):  YES
- TensorFlow version:  2.0.0-dev20190601
- Keras version:  2.2.4-tf
- Python version:  3.6
- CUDA/cuDNN version:  7.3.1
- GPU model and memory:  4 GeForce GTX 1080 w/8119MiB

**Describe the current behavior**  
I am using the TensorFlow Dataset api with the Keras Model.fit function. When `x` is a Dataset (and therefor no `y` is provided), an error is thrown if we provide a `batch_size` argument. However, a `batch_size` is required is we want to use `validation_data` (I would already classify this as an error).

So, I wrote my own custom callback to perform a call to Model.evaluate with the validation dataset I had already prepared after every `n`-th batch and after every single epoch. 

During training, at, say, step 1000 (and before the first epoch), the accuracy reported by Tensorboard (I use the Tensorboard Keras callback for train loss and accuracy), as well as the accuracy reported by the metrics display next to the progress bar, might be at ~19%. 

However, after the CustomCallback runs it's function on_batch_end(self, batch, logs=None) and a call to self.model.evaluate is made, the training accuracy displayed by the progress bar and by Tensorboard picks up where the validation accuracy left off. That is, if val accuracy happened to be ~28% (higher due to no Dropout), then the training metric would also read 28% from then on.

**Describe the expected behavior**  
Calling the model's evaluate function from within a custom callback should not change what is displayed for train accuracy. Also, built-in Dataset validation would be nice.

**Code to reproduce the issue**  

This is the custom callback. Instantiating this callback with a subdirectory for valdiation events and a Dataset instance, and then including this callback in a call to model.fit should reproduce the error. I invite you to provide the data. I am abandoning the Keras Model.fit pipeline for now due to time constraints but I thought I would still log the error. 

For this bug to be noticeable, the training accuracy must be noticeably lower due to dropout than the val acc. (the color is blue but this is train accuracy, I promise. The jump is at step 1000, at which point Model.evaluate was called).

![batch_acc](https://user-images.githubusercontent.com/11124194/59510020-efcca580-8eb2-11e9-8a3f-0261d69e4fdd.png)

`
class Validation(tf.keras.callbacks.Callback):
    
    def __init__(self, log_dir, dataset, *args, **kwargs):
        self.dataset = dataset
        self.writer = tf.summary.create_file_writer(f""{log_dir}/validation"")

    def on_train_begin(self, logs=None):
        self.history = {}
        self.step = 0

    def on_batch_end(self, batch, logs=None):
        self.step += 1
        if self.step % Config.val_log_freq == 0:
            metrics = self.model.evaluate(self.dataset, verbose=0)
            for k, v in zip(self.model.metrics_names, metrics):
                with self.writer.as_default():
                    tf.summary.scalar(f""batch_{k}"", v, step=self.step)
            self.writer.flush()
        
    def on_epoch_end(self, epoch, logs=None):
        metrics = self.model.evaluate(self.dataset, verbose=0)
        for k, v in zip(self.model.metrics_names, metrics):
            self.history.setdefault(k, []).append(v)
            with self.writer.as_default():
                tf.summary.scalar(f""epoch_{k}"", v, step=self.step)
        self.writer.flush()
            
validation_callback = Validation(log_dir, valid_dataset)`

**Other info / logs**  
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.  
",jkamalu,b'backend:tensorflow type:bug/performance',2019-06-14T12:50:12Z,2019-06-24T22:17:06Z
12948,Potential Bug in detecting input shape by Conv2D,"**System information**  
- Have I written custom code (as opposed to using example directory):  No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  Linux Ubuntu 16.04
- TensorFlow backend (yes / no):  yes
- TensorFlow version:  tensorflow_gpu 1.5.0 
- Keras version:  latest 2.2.4, pulled from `master`
- Python version:  2.7 (executed on Jupyter)

## **Describe the current behavior**  
To reduce the amount of code to build my Convolutional Keras model, I want to loop through different `Conv2D` layers stored in a `list`, in order to stack layers together, instead of calling `Conv2D` `n` times that results into a long code. 

My model should be multi-layered and uses residual blocks, where each block shares a specific number of feature maps across all its hidden convolutional layers. Unfortunately, through looping across `Conv2D` blocks, if two `Conv2D`s at positions `i` and `i+1` have a different input_shape, the `i+1` layer fails to infer the correct input shape.

Here is a minimal code to reproduce the error:
```py
fm = 8
n = 100
inputs = Input((512, 512,1))
layers = [Conv2D( fm, 3,  kernel_initializer='glorot_normal', padding='same')] * n

h = inputs
for i in range(0, len(layers)):
    z = layers[i](h)
    h = Activation('relu')(z)
```
The models holds with *n* `Conv2D` layers. The construction, however, breaks at `i = 1`, where `layers[i]` expects a input shape of `(512, 512, 1)` (similar to the shape of the very first input layer), where it should be bound correctly if I don't use a `for` loop.

Bellow is the error stacktrace: 
```
ValueError                                Traceback (most recent call last)
<ipython-input-9-a034e0a2ff2a> in <module>()
      1 h = inputs
      2 for i in range(0, len(layers)):
----> 3     z = layers[i](h)
      4     h = Activation('relu')(z)

/usr/local/lib/python2.7/dist-packages/keras/engine/base_layer.pyc in __call__(self, inputs, **kwargs)
    432             # Raise exceptions in case the input is not compatible
    433             # with the input_spec set at build time.
--> 434             self.assert_input_compatibility(inputs)
    435 
    436             # Handle mask propagation.

/usr/local/lib/python2.7/dist-packages/keras/engine/base_layer.pyc in assert_input_compatibility(self, inputs)
    344                                 str(axis) + ' of input shape to have '
    345                                 'value ' + str(value) +
--> 346                                 ' but got shape ' + str(x_shape))
    347             # Check shape.
    348             if spec.shape is not None:

ValueError: Input 0 is incompatible with layer conv2d_6: expected axis -1 of input shape to have value 1 but got shape (None, 512, 512, 8)

```
## **Describe the expected behavior**  

To overcome to this behavior, as a workaround, one can pass the input_shape explicitly to each `Conv2D` constructor. But if I would have 300 convolutional layers with different sizes henced by `MaxPool2D` or `UpSampling2D`, this might be time-consuming and yields redundancy in code in order to bind different blocks together. 

**Ideal, would be, that the `Conv2D` infer automatically the input_shape from the output shape of the previous layers.** 

Or at least, it might be a nice optional feature.

## **Code to reproduce the issue**  
Code given in a section above is minimal. Here is a more elaborated code, to give an intuition of the encountered error:
```py
fm = 8
n = 50
inputs = Input((512, 512,1))
layers_8 = [Conv2D( fm, 3,  kernel_initializer='glorot_normal', padding='same')] * n
layers_16 = [Conv2D( 2*fm, 3,  kernel_initializer='glorot_normal', padding='same')] * n

h = inputs
# Breaks here
for i in range(0, len(layers_8)):
    z = layers_8[i](h)
    h = Activation('relu')(z)
# Breaks here, if you dodge the previous error with the work-around.
for i in range(0, len(layers_16)):
    z = layers_16[i](h)
    h = Activation('relu')(z)
```

Thank you for your attention. ",AhmedRekik93,b'backend:tensorflow stat:awaiting response type:feature',2019-06-12T11:30:10Z,2019-06-13T14:50:58Z
12931,ValueError: Tried to convert 'shape' to a tensor and failed. Error: None values not supported.,"```
def build_model(input_shape, num_classes):
    x = Input(input_shape)
    x = Embedding(10000, 64)(x)#, input_length=28)(x)
    print(x.shape)
    #x = Bidirectional(GRU(14, input_shape=(28, 64), return_sequences=True))(x)
    x = Bidirectional(GRU(14, return_sequences=True))(x)
    print(x.shape)
    #forw = GRU(14, return_sequences=True)(x)
    #forw = GRU(14)(forw)
    #back = GRU(14, return_sequences=True, go_backwards=True)(x)
    #back = GRU(14, go_backward=True)(x)
    #y = Concatenate(-1)([forw, back])
    y = Reshape((None,28,28,1))(x)
    y = Conv2D(32, (3, 3), activation='relu')(y)
    y = MaxPooling2D((2,2))(y)
    y = Conv2D(64, (3, 3), activation='relu')(y)
    y = MaxPooling2D((2,2))(y)
    y = Flatten()(y)
    y = Dense(num_classes, activation='softmax')(y)
    return Model(x,y)

```

Hi there, I am trying to build this model ,but the error returns as follow:
```
(?, 28, 64)
(?, ?, 28)

ValueErrorTraceback (most recent call last)
<ipython-input-16-66bdf6604ccd> in <module>()
    105 
    106 
--> 107 model = build_model(image_shape, num_classes)
    108 
    109 model.summary()

5 frames
/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.pyc in _apply_op_helper(self, op_type_name, name, **keywords)
    526               raise ValueError(
    527                   ""Tried to convert '%s' to a tensor and failed. Error: %s"" %
--> 528                   (input_name, err))
    529             prefix = (""Input '%s' of '%s' Op has type %s that does not match"" %
    530                       (input_name, op_type_name, observed))

ValueError: Tried to convert 'shape' to a tensor and failed. Error: None values not supported.
```

I print the shape of the data after word embedding and gru. The shape of the output gru is (?,?,28) which is so wierd. Can anyone give some hints? Thanks.",dzhao123,b'backend:tensorflow stat:awaiting response type:bug/performance',2019-06-07T21:33:28Z,2019-06-21T23:05:41Z
12929,Unable to release GPU memory after training Keras model ,"In order to preform a object detection like task, I used a CNN. I am using a custom generator that follows this [example](https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly)

My machine is a MacOS High Sierra 10.13.6, yet I am running my code using Google Colab's GPU so my machine's performances has nothing to do with the issue(right ?). It should be noted that I have tested my code on another platform (FloydHub's Tesla K80 GPU) and had the same problem.

I am using 
- Keras 2.2.4
- Tensorflow backend 1.13.1  
- Python (3.7)
- CUDA release 10.1, V10.1.168
- GPU model and memory:  Tesla K80 (up to my knowledge, this is what google uses on Colab) 

I run out of GPU memory quickly, when passing my model's training in a for loop (looking for optimal hyper-parameters) the program stops on **Out Of Memory Error** after the first iteration. Before the beginning of the first epoch and shortly before the loading arrow for the first epoch appears, the GPU usage jumps to a value of 98%. I put a **gc.collect()** , **del model** and **K.clear_session()** in the end of my training in order to release memory for the next model but it seems to have no effect on GPU which remains at 98% before eventually crashing my notebook.  
```
---------------------------------------------------------------------------
ResourceExhaustedError                    Traceback (most recent call last)
<ipython-input-75-31b4f9e0b883> in <module>()
     15 models={}
     16 compile_model(model,OPTIMIZER,LOSS,METRICS,LR,MOMENTUM,DECAY)
---> 17 allinone2(Hist,model,Data,VAL_SPLIT,OPTIMIZER,LOSS,METRICS,LR,MOMENTUM,DECAY,BATCH_SIZE,EPOCHS,PARAMS,True)

9 frames
<ipython-input-71-125d04498229> in allinone2(Hist, model, Data, validation_split, optimizer, loss, metric, lr, momentum, decay, batch_size, epochs, params, showbboxs)
      2   if TPU :
      3       model = tf.contrib.tpu.keras_to_tpu_model(model,strategy=tf.contrib.tpu.TPUDistributionStrategy(tf.contrib.cluster_resolver.TPUClusterResolver(TPU_WORKER)))
----> 4   train_gen,validation_gen,Hist = fit(model,Hist,Data,VAL_SPLIT,BATCH_SIZE,EPOCHS,PARAMS)
      5   Save_model(SAVE_DIR,name_json=""model"",nameh5=""model"",save=SAVE_MODEL)
      6   training_results(Hist,str(validation_split)+str(batch_size)+str(epochs),savefig=SAVE_FIG)

<ipython-input-64-efd2c5419ad6> in fit(model, Hist, Data, validation_split, batch_size, epochs, params)
     17                    validation_steps = lenvalidation // batch_size,
     18                    callbacks=[Hist],
---> 19                    validation_data = validation_gen
     20                    ) 
     21 

/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py in wrapper(*args, **kwargs)
     89                 warnings.warn('Update your `' + object_name + '` call to the ' +
     90                               'Keras 2 API: ' + signature, stacklevel=2)
---> 91             return func(*args, **kwargs)
     92         wrapper._original_function = func
     93         return wrapper

/usr/local/lib/python3.6/dist-packages/keras/engine/training.py in fit_generator(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)
   1416             use_multiprocessing=use_multiprocessing,
   1417             shuffle=shuffle,
-> 1418             initial_epoch=initial_epoch)
   1419 
   1420     @interfaces.legacy_generator_methods_support

/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py in fit_generator(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)
    215                 outs = model.train_on_batch(x, y,
    216                                             sample_weight=sample_weight,
--> 217                                             class_weight=class_weight)
    218 
    219                 outs = to_list(outs)

/usr/local/lib/python3.6/dist-packages/keras/engine/training.py in train_on_batch(self, x, y, sample_weight, class_weight)
   1215             ins = x + y + sample_weights
   1216         self._make_train_function()
-> 1217         outputs = self.train_function(ins)
   1218         return unpack_singleton(outputs)
   1219 

/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py in __call__(self, inputs)
   2713                 return self._legacy_call(inputs)
   2714 
-> 2715             return self._call(inputs)
   2716         else:
   2717             if py_any(is_tensor(x) for x in inputs):

/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py in _call(self, inputs)
   2673             fetched = self._callable_fn(*array_vals, run_metadata=self.run_metadata)
   2674         else:
-> 2675             fetched = self._callable_fn(*array_vals)
   2676         return fetched[:len(self.outputs)]
   2677 

/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py in __call__(self, *args, **kwargs)
   1437           ret = tf_session.TF_SessionRunCallable(
   1438               self._session._session, self._handle, args, status,
-> 1439               run_metadata_ptr)
   1440         if run_metadata:
   1441           proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)

/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/errors_impl.py in __exit__(self, type_arg, value_arg, traceback_arg)
    526             None, None,
    527             compat.as_text(c_api.TF_Message(self.status.status)),
--> 528             c_api.TF_GetCode(self.status.status))
    529     # Delete the underlying status object from memory otherwise it stays alive
    530     # as there is a reference to status from this from the traceback due to

ResourceExhaustedError: OOM when allocating tensor with shape[3114176,32] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc
	 [[{{node training_3/Adam/gradients/dense_17/MatMul_grad/MatMul_1}}]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.
```
I should be able to free the GPU memory in order to run my tests, It should be noted that my dataset has 1000 images of 800x1000 shape.    

A snippet of the code that causes the problem (.ipynb => .py) :
````
!pip install gputil
!pip install psutil
!pip install humanize
#Imports ...

def penalty(y_true, y_pred):
    a = tf.placeholder(tf.float64)
    p = 20
    loss = K.switch(tf.less(y_true - y_pred, 0.1), K.square(y_true - y_pred) , p * K.square(y_true - y_pred))
    return K.max(loss)
  
def cusloss(y_true,y_pred): 
    return K.mean(K.equal(K.round(100*y_pred , 100*y_true)),tf.zeros_like(y_pred))

# Global parameters
IMG_SIZE = 800,1000,3
BATCH_SIZEs = [4,8,16,32]
EPOCHSs = [10]
PARAMSs = [{""rotation"":20,""scale"":0.1,""shear"":0.1,""translate"":0.1,""scale"":0.1}]
OPTIMIZERs = ['adam']
LOSSEs = [penalty]
METRICSs = [[cusloss,penalty,losses.msle,losses.mae,losses.mse,losses.logcosh]]
LRs = [0.01,0.005]
MOMENTUMs = [0.05,0.1]
DECAYs = [0.2]
VAL_SPLITs = [0.2]

def load_data(*args):
    ...
    return Data

class Generator(keras.utils.Sequence):
    
    def __init__(self, Data, params ,batch_size):
        """"""Initials an image generator""""""
        self.x = col(Data,0,1) 
        self.y = np.array(col(Data,1,5))
        self.batch_size = batch_size
        self.params = params
        self.on_epoch_end()

    def __len__(self):
        """"""Our generator's length""""""
        return int(np.ceil(len(self.x) / float(self.batch_size)))

    def __getitem__(self, idx):
        """""" __getitem__ gives access to an item of our generator which will be a batch of BATCH_SIZE size. It is called via the brackets []""""""
        images_list = self.x
        bboxes = self.y
        batch_size =  self.batch_size
        w,h = IMG_SIZE[:2]
        required_transformations = self.params.keys()
        
        # Generate indexes of the batch
        indexes = self.indexes[idx*self.batch_size:(idx+1)*self.batch_size]
        if sum(indexes) == 0 :        # check if indexes is empty
          return None
        
        # extracting BATCH_SIZE images from the dataset
        x_temp = [self.x[i]  for i in indexes]
        y_temp = np.array([self.y[i,] for i in indexes])
        
        # shuffling our batch's elements
        Ids,y0 = sklearn.utils.shuffle(x_temp,y_temp)
        
        # Initiate our batchs
        X = np.zeros((batch_size,h,w,1))
        y = np.zeros((batch_size,4))
      
        for i,image in enumerate(Ids) :
            image = image[0]
            try : 
                img = cv2.imread(""scans/""+image+"".png"")
            except : 
                print(""Unable to read %s""%(image))
                img = None

            # Starting preprocessing
            if not (img is None) : 
                img = cv2.resize(img,(w,h))
                bbox = y0[i,]
                try :
                    X[i,:,:,:] = np.expand_dims(rgb2gray(img_),axis=2)
                    y[i,:] = bboxes_

                except Exception as exc:
                    # Prints the error without stoping the process
                    print(""Error found at index %d""%(i))
                    print(traceback.format_exc())
                    print(exc)

            else : 
                print(""%s is None""%(image))
        return X,y
    
    def on_epoch_end(self):
        'Updates indexes after each epoch'
        self.indexes = np.arange(len(self.x))
        np.random.shuffle(self.indexes)

def fit(model,Hist,Data,validation_split,batch_size,epochs,params):
  """""" Fits our input to the output""""""
  n = len(Data)
  lenvalidation = int(validation_split*n)
  lentrain =  n - lenvalidation
  train_set = sklearn.utils.shuffle(Data[:lentrain])
  validation_set = sklearn.utils.shuffle(Data[lentrain:])
  train_gen = Generator(train_set,params,batch_size)
  validation_gen = Generator(validation_set,params,batch_size)
  
  print(""starting training..."")
  model.fit_generator(train_gen,
                   steps_per_epoch = lentrain // batch_size,
                   epochs=epochs,
                   validation_steps = lenvalidation // batch_size,
                   callbacks=[Hist],
                   validation_data = validation_gen
                   ) 

  return train_gen,validation_gen,Hist

def create_model():
  # History initialisation
  Hist = History()
  # Defining the architecture of our CNN based NN 
  model = Sequential()
  model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(IMG_SIZE[1],IMG_SIZE[0],1)))
  model.add(MaxPooling2D(pool_size=(2, 2),strides=(2,2)))
  model.add(Dropout(0.25))
  model.add(Conv2D(64, kernel_size=(5, 5), activation='relu'))
  model.add(MaxPooling2D(pool_size=(2, 2),strides=(2,2)))
  model.add(Dropout(0.3))
  model.add(Flatten())
  model.add(Dense(32, activation='relu'))
  model.add(Dropout(0.3))
  model.add(Dense(4))
  return Hist,model

def compile_model(model,optimize,loss,metric,lr,momentum,decay):
  # Compiles the model  
  run_opts = tf.RunOptions(report_tensor_allocations_upon_oom = True)
  model.compile(optimizer=optimize , loss = loss, metrics = metric, options = run_opts)

  # Define optimizers
  K.set_value(model.optimizer.lr, lr)
  K.set_value(model.optimizer.decay, decay)
  try :
      K.set_value(optimizer.momentum, momentum) 
  except :
    pass

def allinone(Hist,model,Data,validation_split,optimizer,loss,metric,lr,momentum,decay,batch_size,epochs,params) : 
  compile_model(model,optimizer,loss,metric,lr,momentum,decay)
  train_gen,validation_gen,Hist = fit(model,Hist,Data,VAL_SPLIT,BATCH_SIZE,EPOCHS,PARAMS)
  torch.cuda.empty_cache()
  del model 
  gc.collect()
  K.clear_session()

def printmm(y_true=0,y_pred=0):
  GPUs = GPUtil.getGPUs()
  gpu = GPUs[0]
  print(GPUtil.showUtilization())
  return(tf.Variable(gpu.memoryUtil*100))

# The Ultimate test
Data = load_data()
Hist,model = create_model()
for EPOCHS in EPOCHSs:
  for BATCH_SIZE in BATCH_SIZEs:
    for PARAMS in PARAMSs :
      for OPTIMIZER in OPTIMIZERs:
        for LOSS in LOSSEs :
          for METRICS in METRICSs:
            for LR in LRs :
              for MOMENTUM in MOMENTUMs:
                for DECAY in DECAYs:
                  for VAL_SPLIT in VAL_SPLITs :
                    allinone(Hist,model,Data,VAL_SPLIT,OPTIMIZER,LOSS,METRICS,LR,MOMENTUM,DECAY,BATCH_SIZE,EPOCHS,PARAMS)

",YKritet,b'backend:tensorflow stat:awaiting response type:bug/performance',2019-06-07T14:34:36Z,2019-07-16T00:02:21Z
12923,Unable to release GPU memory after training a model (OOM),"Hi, 
On a Google Colab notebook with keras(2.2.4) and tensorflow(1.13.1) as a backend, I am trying to tune a CNN, I use a simple and basic table of hyper-parameters and run my tests in a set of loops. 
My problem is that I can't free the GPU memory after each iteration and Keras doesn't seem to be able to release GPU memory automatically. So every time I get a **Ressource Exhausted : Out Of Memory (OOM)**
I did some digging up and run into this function that reassembles different solutions that have been suggested to solve this problem (didn't work for me though) : 
```python
def reset_keras():
    sess = get_session()
    clear_session()
    sess.close()
    sess = get_session()

    try:
        del model # this is from global space - change this as you need
    except:
        pass

    print(gc.collect()) # if it's done something you should see a number being outputted

    # use the same config as you used to create the session
    config = tf.ConfigProto()
    config.gpu_options.per_process_gpu_memory_fraction = 1
    config.gpu_options.visible_device_list = ""0""
    set_session(tf.Session(config=config))
```
The only thing that i didn't fully grasp is the ""*same config as you used to create your model* "" since with Keras we don't chose explicitly a certain configuration. I get by for one iteration, some times two, but I can't go beyond. I already tried to change the batch_size and for the moment I am unable to afford for a machine with higher performances.",YKritet,b'backend:tensorflow stat:awaiting response type:bug/performance',2019-06-06T11:38:37Z,2019-06-10T12:52:32Z
12899,"BugFix of ""AttributeError: 'ProgbarLogger' object has no attribute 'target'"" (or 'log_values') error (#12898) (#12893) (#8944)","This Change set is fixing two missing attribute bugs in `callback.ProgbarLogger` class
* AttributeError: 'ProgbarLogger' object has no attribute 'target' #12898
  Abstract reproduction scenario is provided in ticket
* AttributeError: 'ProgbarLogger' object has no attribute 'log_values' #3657
* AttributeError: 'ProgbarLogger' object has no attribute 'log_values' #8944 (dup)

Related changes:
* Cases of regression are covered by tests.
* Some potential bugs with same nature are prevented and covered by manifestation checks.
* run with empty data array (but having valid shape) is now handled properly
  and yielding related warnings on callback and training routine level without execution fail

Note:
Changes that affect `ProgbarLogger` should be aware of following things:
* proper target initialisation is requiring two attributes: `params` and `use_steps` to be defined
* `use_steps` is guaranteed attribute the is set in the constructor (but could be altered after object instantiation. It's currently safe condition.
* class `params` attribute could be altered between initialisation and training start. And current logic is made to be aware of this
* we don't have `params` initialisation in constructor, this attribute will be assigned on call of `set_params` of base class somewhere on caller level (no strict guarantees :( )
* `seen` attribute is working in pair with `target` during `log_values` initialisation and their initialisation should be under the equal condition, currently thats not true
* `if self.seen < self.target` condition is being checked whenever verbose mode value so both of them should be initialised without any conditions
* `if self.seen < self.target` is checking for training iteration being not finished but in case of degenerate case with zero length it will not be called and `log_values` will stay not initialised but i don't see any explicit logic preventing using it on exit from 0-length training cycle and potentially it is the bug of some kind that is prevented on caller logic level
* `progbar` attribute initialisation is definitely related to output verbosity (log values accumulation are not) and should be left under verbosity condition

<!--
Please make sure you've read and understood our contributing guidelines;
https://github.com/keras-team/keras/blob/master/CONTRIBUTING.md
-->

### Summary

### Related Issues

### PR Overview

- [x] This PR requires new unit tests [y/n] (make sure tests are included)
- [ ] This PR requires to update the documentation [y/n] (make sure the docs are up-to-date)
- [x] This PR is backwards compatible [y/n]
- [ ] This PR changes the current API [y/n] (all API changes need to be approved by fchollet)
",mrjj,None,2019-05-31T04:35:07Z,2019-09-11T21:31:22Z
12897,Run Default code for imdb_cnn.py it gives pickle-errors,"<em>Please make sure that this is a Bug or a Feature Request and provide all applicable information asked by the template.
If your issue is an **implementation question**, please ask your question on [StackOverflow](http://stackoverflow.com/questions/tagged/keras) or [on the Keras Slack channel](https://keras-slack-autojoin.herokuapp.com/) instead of opening a GitHub issue.</em>  

**System information**  
- Have I written custom code (as opposed to using example directory):  
>> I used the default code exactly as written.

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  
Microsoft Windows 10 Enterprise

- TensorFlow backend (yes / no): 
yes
 
- TensorFlow version:  
1.13.1

- Keras version:  
2.2.4

- Python version:  
Python 3.7.3

- CUDA/cuDNN version:  
None.  I'm using cpu-only vanilla keras installed by Anaconda. 

- GPU model and memory:  
NVidia Quadra P1000


**Describe the current behavior**  
It crashes when I hit F5 in Spyder.  It talks about pickle error.

```
using TensorFlow backend.
Loading data...
Traceback (most recent call last):

  File ""<ipython-input-1-4a5d5f4a1034>"", line 1, in <module>
    runfile('C:/work/imdb_cnn.py', wdir='c:/work')

  File ""C:\ProgramData\Anaconda3\envs\Step2\lib\site-packages\spyder_kernels\customize\spydercustomize.py"", line 827, in runfile
    execfile(filename, namespace)

  File ""C:\ProgramData\Anaconda3\envs\Step2\lib\site-packages\spyder_kernels\customize\spydercustomize.py"", line 110, in execfile
    exec(compile(f.read(), filename, 'exec'), namespace)

  File ""C:/work/imdb_cnn.py"", line 28, in <module>
    (x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)

  File ""C:\ProgramData\Anaconda3\envs\Step2\lib\site-packages\keras\datasets\imdb.py"", line 59, in load_data
    x_train, labels_train = f['x_train'], f['y_train']

  File ""C:\ProgramData\Anaconda3\envs\Step2\lib\site-packages\numpy\lib\npyio.py"", line 262, in __getitem__
    pickle_kwargs=self.pickle_kwargs)

  File ""C:\ProgramData\Anaconda3\envs\Step2\lib\site-packages\numpy\lib\format.py"", line 692, in read_array
    raise ValueError(""Object arrays cannot be loaded when ""

ValueError: Object arrays cannot be loaded when allow_pickle=False
```

**Describe the expected behavior**  

I would expect it to get to line 29 and print something about the training sequence count.

Line 28, where it is choking, is 
`(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)`

It doesn't get to print ""train sequences"" after attempting to load data, so it isn't getting past line 29.  

When I re-select line 28, and hit F9 (run highlighted) it gives the same error again.

**Code to reproduce the issue**  
You already have it.  It was literally copy-paste-run-crash

**Other info / logs**  
Traceback is included in what it did.
",EngrStudent,b'backend:tensorflow stat:awaiting response type:bug/performance',2019-05-30T17:33:28Z,2019-05-30T18:57:07Z
12880,Output tensors to a Model must be the output of a Keras `Layer`,"<em>Please make sure that this is a Bug or a Feature Request and provide all applicable information asked by the template.
If your issue is an **implementation question**, please ask your question on [StackOverflow](http://stackoverflow.com/questions/tagged/keras) or [on the Keras Slack channel](https://keras-slack-autojoin.herokuapp.com/) instead of opening a GitHub issue.</em>  

**System information**  
- Have I written custom code (as opposed to using example directory):   yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  Linux Ubuntu 18.04
- TensorFlow backend (yes / no):  yes
- TensorFlow version:  tf 1.13.1
- Keras version:  2.2.4
- Python version:  3.7
- CUDA/cuDNN version:  10.1/7.5 [ nvidia-smi says CUDA Version: 10.2 ]
- GPU model and memory:  RTX2070, 8 gb

You can obtain the TensorFlow version with:  
python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""  
You can obtain the Keras version with:  
python -c 'import keras as k; print(k.__version__)'  

**Describe the current behavior**  

Error : ValueError: Output tensors to a Model must be the output of a Keras `Layer` (thus holding past layer metadata). Found: Tensor(""truediv:0"", shape=(?, 2048, 1024, 128), dtype=float32)

I see that after adding activation layers at various segments of my model, layer drops 2 attributes _keras_history and _keras_shape. 

Currently, the model isn't compiling as my architecture has an activation layer at the end applied after computing logits. 

Note: The same code works perfectly fine with tf.keras and tf 2.0 alpha

I'm compiling the model with with the output layer activated by softmax. 

**Describe the expected behavior**  
model should compile.
**Code to reproduce the issue**  
Provide a reproducible test case that is the bare minimum necessary to generate the problem.  

x = keras.activations.relu(x)
ff_layer2 = keras.layers.DepthwiseConv2D(128, strides=(1, 1), depth_multiplier=1, padding='same')(x)
classifier = keras.activations.softmax(ff_layer2)

**Other info / logs**  
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.  
",SyedShaQutub,b'backend:tensorflow type:support',2019-05-27T15:29:38Z,2019-06-26T21:36:02Z
12877,keras.examples.cifar10_cnn.py  ignores batch_size in absence of data_augmentation,"
**System information**  
- Have I written custom code (as opposed to using example directory):  No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  Linux Ubuntu 18/04
- TensorFlow backend (yes / no):  yes
- TensorFlow version:  1.13.1
- Keras version:  2.2.4
- Python version:  2.7.16
- CUDA/cuDNN version:  10.1/7.6
- GPU model and memory:  1080M / 8GB

**Describe the current behavior**  
When `cifar10_cnn.py` is run without data_augmentation, it seems to ignore the fact that `batch_size` has been set to 32.

The training output appears as follows:

```
Epoch 1/100
50000/50000 [==============================] - 9s 172us/step - loss: 1.8029 - acc: 0.3383 - val_loss: 1.4823 - val_acc: 0.4573
Epoch 2/100
50000/50000 [==============================] - 7s 135us/step - loss: 1.4775 - acc: 0.4650 - val_loss: 1.3312 - val_acc: 0.5218

```

**Describe the expected behavior**  

It should appear this way (since 50000/32 = 1562)

```
Epoch 1/100
1562/1562 [==============================] - 16s 10ms/step - loss: 1.8887 - acc: 0.3054 - val_loss: 1.5615 - val_acc: 0.4398
Epoch 2/100
1562/1562 [==============================] - 14s 9ms/step - loss: 1.5818 - acc: 0.4231 - val_loss: 1.3624 - val_acc: 0.5110


```
**Code to reproduce the issue**  
Just run `cifar10_cnn.py`, after setting `data_augmentation` to `False`



**Other info / logs**  
I think the problem lies in the way `Progbar` and `ProgbarLogger` are called from `training_arrays.py` in the `fit_loop` method, where around line 110, we see:

```
    if verbose:
        if steps_per_epoch is not None:
            count_mode = 'steps'
        else:
            count_mode = 'samples'
        _callbacks.append(
            cbks.ProgbarLogger(
                count_mode,
                stateful_metrics=model.stateful_metric_names))

```
Where the assumption is that unless `steps_per_batch` is specified, we are counting samples, rather than steps (i.e. batches). This assumption is transferred to the `__init__` method of `ProgbarLogger`, which then transfers it to `Progbar`. My assumption is that if the creation of `Progbar` is prone to this error, then the actual training might be too, but I haven't verified that.

I'd assume that the fix would be to find all the places where `steps_per_epoch` is used to see if mini-batches are being used in training. For now, I think the best quick/dirty fix is to **always** specify `steps_per_epoch` in a manner consistent with `batch_size` 
",smgutstein,b'backend:tensorflow stat:awaiting response type:bug/performance',2019-05-27T03:07:40Z,2019-07-08T21:45:49Z
12875,"""You must compile your model before using it"" only occurs when fit_generator and Sequential model are used together","<em>Please make sure that this is a Bug or a Feature Request and provide all applicable information asked by the template.
If your issue is an **implementation question**, please ask your question on [StackOverflow](http://stackoverflow.com/questions/tagged/keras) or [on the Keras Slack channel](https://keras-slack-autojoin.herokuapp.com/) instead of opening a GitHub issue.</em>  

**System information**  

I've reproduced the behavior on two systems and included information on both:

```
Have I written custom code (as opposed to using example directory): Yes, included in original post with comments.
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS High Sierra Version 10.13.6
TensorFlow backend (yes / no): yes
TensorFlow version: 1.13.1   
Keras version: 2.2.4 
Python version:  3.7.3
CUDA/cuDNN version: I do not have cuda and do not have a gpu on this system. I think my code disables using GPU.
GPU model and memory:
```

```
Have I written custom code (as opposed to using example directory): Yes, included in original post with comments.
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04.1 LTS
TensorFlow backend (yes / no): yes
TensorFlow version: 1.12.0
Keras version: 2.2.4.1
Python version: 3.6.7
CUDA/cuDNN version: I do not have cuda and do not have a gpu on this system. I think my code disables using GPU.
GPU model and memory:
```
**Describe the current behavior**  

When a Bidirectional LSTM model is used as a Sequential model with fit_generator a ""You must compile your model before using it"" error crashes the script. This error does not occur when either an identical model is used with the Functional API or when identical data is fed through fit instead of fit_generator.

**Describe the expected behavior**  

I would expect the error to either be thrown in all four cases (Sequential or Functional API, fit or fit_generator) or none of them. Either I misunderstand something about the Keras API or this is a bug.

**Code to reproduce the issue**  
Provide a reproducible test case that is the bare minimum necessary to generate the problem.  

```
import os
os.environ[""CUDA_DEVICE_ORDER""] = ""PCI_BUS_ID""   # see issue #152
os.environ[""CUDA_VISIBLE_DEVICES""] = """"

from keras.models import *
from keras.layers import *
import keras
import numpy as np

use_sequential = False
use_fit_generator = True

batch_size = 5
input_length = 10
input_size = 3
hidden_size = 8
output_length = 5
output_size = 1
epochs = 1

class DataGenerator(keras.utils.Sequence):
    def __init__(self):
    	pass
            
    def __len__(self):
    	return 1

    def __getitem__(self, index):
        return np.zeros((batch_size, input_length, input_size)), np.zeros((batch_size, output_length, output_size))

train_generator = DataGenerator()
validation_generator = DataGenerator()
X,y = train_generator[0]


# ------------------------------------------
# Sequential model works with model.fit but not with model.fit_generator

if use_sequential:
	model = Sequential()
	model.add(Bidirectional(LSTM(hidden_size, input_shape=(input_length, input_size), return_sequences=False, return_state=False))) 
	model.add(RepeatVector(output_length))
	model.add(TimeDistributed(Dense(output_size)))
	model.compile(loss='mse', optimizer='adam', metrics=['accuracy', 'mape']) 

# ------------------------------------------

# ------------------------------------------
# Functional model works with both model.fit and model.fit_generator

else:
	input_sequences = Input(shape=(input_length, input_size))
	output = Bidirectional(LSTM(hidden_size, input_shape=(input_length, input_size), return_sequences=False, return_state=False))(input_sequences)
	output = RepeatVector(output_length)(output)
	output = TimeDistributed(Dense(output_size))(output)
	model = Model(inputs=[input_sequences], outputs=[output])
	model.compile(loss='mse', optimizer='adam', metrics=['accuracy', 'mape']) 

# ------------------------------------------

if use_fit_generator:
	
	history = model.fit_generator(generator=train_generator,
	    validation_data=validation_generator,
	    epochs=epochs)

else:

	history = model.fit(X, y, epochs=epochs)

# This final line causes a ""You must compile your model before using it."" 
# error when the sequential model is used with model.fit_generator
# but in no other case.

print(model.summary()) 
```

**Other info / logs**  
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.  

Traceback on Failure (when use_sequential=True, use_fit_generator=True):
```
Using TensorFlow backend.
WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
Traceback (most recent call last):
  File ""keras_test.py"", line 61, in <module>
    epochs=epochs)
  File ""/usr/local/lib/python3.7/site-packages/keras/legacy/interfaces.py"", line 91, in wrapper
    return func(*args, **kwargs)
  File ""/usr/local/lib/python3.7/site-packages/keras/engine/training.py"", line 1418, in fit_generator
    initial_epoch=initial_epoch)
  File ""/usr/local/lib/python3.7/site-packages/keras/engine/training_generator.py"", line 40, in fit_generator
    model._make_train_function()
  File ""/usr/local/lib/python3.7/site-packages/keras/engine/training.py"", line 496, in _make_train_function
    raise RuntimeError('You must compile your model before using it.')
RuntimeError: You must compile your model before using it.
```

Traceback on Success (when any of use_sequential or use_fit_generator are False):
```
Using TensorFlow backend.
WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
Epoch 1/1
2019-05-26 16:57:43.028629: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
1/1 [==============================] - 1s 1s/step - loss: 0.0000e+00 - acc: 1.0000 - mean_absolute_percentage_error: 0.0000e+00 - val_loss: 0.0000e+00 - val_acc: 1.0000 - val_mean_absolute_percentage_error: 0.0000e+00
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 10, 3)             0         
_________________________________________________________________
bidirectional_1 (Bidirection (None, 16)                768       
_________________________________________________________________
repeat_vector_1 (RepeatVecto (None, 5, 16)             0         
_________________________________________________________________
time_distributed_1 (TimeDist (None, 5, 1)              17        
=================================================================
Total params: 785
Trainable params: 785
Non-trainable params: 0
_________________________________________________________________
None
```",mhgump,b'backend:tensorflow stat:awaiting response type:support',2019-05-26T21:05:12Z,2019-08-07T21:50:39Z
12872,`AttributeError: 'InputLayer' object has no attribute 'outbound_nodes'`,"I followed the keras blog https://blog.keras.io/using-pre-trained-word-embeddings-in-a-keras-model.html on word embeddings. When reaching this point of the tutorial:
```python
from keras.layers import Input
embedding_layer = Embedding(len(word_index) + 1,EMBEDDING_DIM,weights=[embedding_matrix],input_length=MAX_SEQUENCE_LENGTH,
                            trainable=False)
sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')
embedded_sequences = embedding_layer(sequence_input)
```
I experience a crash:
`'AttributeError: 'InputLayer' object has no attribute 'outbound_nodes''`

**System information**  
- Code taken from:  https://blog.keras.io/using-pre-trained-word-embeddings-in-a-keras-model.html
- OS Platform and Distribution: Outdated version of scientific linux, used anaconda to fetch packages
- TensorFlow backend (yes / no):  yes
- TensorFlow version:  1.13.1 
- Keras version:  2.2.4 
- Python version:  3.7.3
- CUDA/cuDNN version:  not available
- GPU model and memory:  no GPU

**Describe the current behavior**  
`AttributeError: 'InputLayer' object has no attribute 'outbound_nodes'`
**Describe the expected behavior**  
it doesn't crash
**Code to reproduce the issue**  
Provide a reproducible test case that is the bare minimum necessary to generate the problem.  

**Other info / logs**  
Traceback:
```python
AttributeError                            Traceback (most recent call last)
<ipython-input-16-fd4b0bbd5a48> in <module>
      3                             trainable=False)
      4 sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')
----> 5 embedded_sequences = embedding_layer(sequence_input)
      6 x = Conv1D(128, 5, activation='relu')(embedded_sequences)
      7 x = MaxPooling1D(5)(x)

~/share/new_conda_for_me/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py in __call__(self, inputs, *args, **kwargs)
    582           if base_layer_utils.have_all_keras_metadata(inputs):
    583             inputs, outputs = self._set_connectivity_metadata_(
--> 584                 inputs, outputs, args, kwargs)
    585           if hasattr(self, '_set_inputs') and not self.inputs:
    586             # Subclassed network: explicitly set metadata normally set by

~/share/new_conda_for_me/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py in _set_connectivity_metadata_(self, inputs, outputs, args, kwargs)
   1414     kwargs.pop('mask', None)  # `mask` should not be serialized.
   1415     self._add_inbound_node(
-> 1416         input_tensors=inputs, output_tensors=outputs, arguments=kwargs)
   1417     return inputs, outputs
   1418 

~/share/new_conda_for_me/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py in _add_inbound_node(self, input_tensors, output_tensors, arguments)
   1522         input_tensors=input_tensors,
   1523         output_tensors=output_tensors,
-> 1524         arguments=arguments)
   1525 
   1526     # Update tensor history metadata.

~/share/new_conda_for_me/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py in __init__(self, outbound_layer, inbound_layers, node_indices, tensor_indices, input_tensors, output_tensors, arguments)
   1740         # For compatibility with external Keras, we use the deprecated
   1741         # accessor here.
-> 1742         layer.outbound_nodes.append(self)
   1743     # For compatibility with external Keras, we use the deprecated
   1744     # accessor here.

AttributeError: 'InputLayer' object has no attribute 'outbound_nodes'```",luciasalar,b'backend:tensorflow type:bug/performance',2019-05-25T22:39:56Z,2020-06-02T15:43:12Z
12866,"keras multi input model , when  extract the feature of the dense_1 layer does not get the all feature label ","<em>Please make sure that this is a Bug or a Feature Request and provide all applicable information asked by the template.
If your issue is an **implementation question**, please ask your question on [StackOverflow](http://stackoverflow.com/questions/tagged/keras) or [on the Keras Slack channel](https://keras-slack-autojoin.herokuapp.com/) instead of opening a GitHub issue.</em>  

**System information**  
- Have I written custom code (as opposed to using example directory):  
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  
- TensorFlow backend (yes / no):  yes
- TensorFlow version:  1.9.0'
- Keras version:  2.2.1
- Python version:  3.5

You can obtain the TensorFlow version with:  
python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""  
You can obtain the Keras version with:  
python -c 'import keras as k; print(k.__version__)'  

**Describe the current behavior**  
when i extract the the feature of the dense layer i got the features and labels but i did not get the all labels i expect 10 labels but i got 9 labels 1 label is missing why this is happening
**Describe the expected behavior**  

**Code to reproduce the issue**  
Provide a reproducible test case that is the bare minimum necessary to generate the problem.  
```python
input_1 = Input(shape=(img_width,img_height,1))
#input_2 = Input(shape=(img_width,img_height,1))
input_3 = Input(shape=(img_width,img_height,1)) 
#input_4 = Input(shape=(img_width,img_height,1))

FF=10

output_1 = Conv2D(FF,(3,3), activation='sigmoid')(input_1)
output_1 = Conv2D(FF,(3,3), activation='sigmoid')(output_1 )
#output_1 = Conv2D(FF,(2,2), activation='relu')(output_1 )
#output_1 = Conv2D(FF,(2,2), activation='relu')(output_1 )
#output_1 = BatchNormalization()(output_1)
#output_1 = MaxPooling2D(pool_size=(2,2))(output_1)
output_1 = Dropout(0.2)(output_1)
output_1 = Flatten()(output_1)

#output_2 = Conv2D(FF,(2,2), activation='relu')(input_2)
#output_2 = Conv2D(FF,(2,2), activation='relu')(output_2 )
#output_2 = BatchNormalization()(output_2)
#output_2 = MaxPooling2D(pool_size=(2,2))(output_2)
#output_2 = Dropout(0.25)(output_2)
#output_2 = Flatten()(output_2)

output_3 = Conv2D(FF,(3,3), activation='sigmoid')(input_3)
output_3 = Conv2D(FF,(3,3), activation='sigmoid')(output_3 )
#output_3 = Conv2D(FF,(2,2), activation='relu')(output_3 )
#output_3 = Conv2D(FF,(2,2), activation='relu')(output_3 )
#output_3 = BatchNormalization()(output_3)
#output_3 = MaxPooling2D(pool_size=(2,2))(output_3)
output_3 = Dropout(0.2)(output_3)
output_3 = Flatten()(output_3)

#output_4 = Conv2D(FF,(2,2), activation='relu')(input_4)
#output_4 = Conv2D(FF,(2,2), activation='relu')(output_4 )
#output_4 = BatchNormalization()(output_4)
#output_4 = MaxPooling2D(pool_size=(2,2))(output_4)
#output_4 = Dropout(0.25)(output_4)
#output_4 = Flatten()(output_4)

inputs =[input_1,input_3]
outputs =[output_1,output_3]
combine = concatenate(outputs)

output = Dense(400,activation='sigmoid',name ='dense_1')(combine)
output = Dense(num_classes,activation='softmax')(output)

model = Model(inputs,[output])
model.compile(optimizer='adadelta', loss='categorical_crossentropy',
                        metrics=['accuracy', categorical_accuracy,mean_pred,recall,precision, fmeasure, matthews_correlation,kullback_leibler_divergence,binary_crossentropy])


hist=model.fit([X_train_g,X_train_b],Y_train,epochs=num_epoch, batch_size=batch_size,validation_data=([X_test_g,X_test_b],Y_test))  

extract =Model(model.input,[model.get_layer(""dense_1"").output,model.output])

extract.summary() 
test_feature,test_labels = extract.predict(XT)
```
**Other info / logs**  
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.  
",sanaullah-ashfat,b'backend:tensorflow stat:awaiting response',2019-05-24T08:33:30Z,2019-06-03T19:24:46Z
12847,Could Keras prefetch data like tensorflow Dataset?,"<em>Please make sure that this is a Bug or a Feature Request and provide all applicable information asked by the template.
If your issue is an **implementation question**, please ask your question on [StackOverflow](http://stackoverflow.com/questions/tagged/keras) or [on the Keras Slack channel](https://keras-slack-autojoin.herokuapp.com/) instead of opening a GitHub issue.</em>  

**System information**  
- Have I written custom code (as opposed to using example directory):  
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  
Ubuntu 18.04
- TensorFlow backend (yes / no):  yes
- TensorFlow version:  1.13
- Keras version:  2.2.4
- Python version:  3.6
- CUDA/cuDNN version:  9.0
- GPU model and memory:  1070ti

You can obtain the TensorFlow version with:  
python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""  
You can obtain the Keras version with:  
python -c 'import keras as k; print(k.__version__)'  

**Describe the current behavior**  
Current approach - Data is generated only then next batch is proceeded. Even If I use custom datagen. I have something like this:
``` python
class DataGenerator(Sequence):
'''
Sample usage:
test_generator = DataGenerator(x_train, y_train, 1, 
                           image_sizes, image_sizes, 1, True)
Xtest, ytest = test_generator.__getitem__(1)
plt.imshow(Xtest[0])
plt.show()
plt.imshow(ytest[0, :,:,0])
plt.show()
'''
def __init__(self, X, y, batch_size,  height,width, nb_y_features, augmentation = True):
    'Initialization'
    self.batch_size = batch_size
    self.X = X
    self.y = y
    self.indexes = None
    self.currentIndex = 0
    self.augmentation = augmentation
    self.on_epoch_end()
    self.height = height
    self.width = width
    self.nb_y_features = nb_y_features

def __len__(self):

    'Denotes the number of batches per epoch'
    return int(np.ceil(len(self.X) / self.batch_size))

def __getitem__(self, index):
    'Generate one batch of data'
    # Generate indexes of the batch
    data_index_min = int(index*self.batch_size)
    data_index_max = int(min((index+1)*self.batch_size, len(self.indexes)))
    indexes = self.indexes[data_index_min:data_index_max]

    this_batch_size = len(indexes) # The last batch can be smaller than the others

    X = np.empty((this_batch_size, self.width, self.height, 3)) #, dtype=int)
    y = np.empty((this_batch_size, self.width, self.height, self.nb_y_features), dtype=int)

    for i, sample_index in enumerate(indexes):
        data_index = self.indexes[index * self.batch_size + i]
        X_sample, y_sample = self.X[data_index].copy(), self.y[data_index].copy()
        if self.augmentation:
            augmented = aug()(image=X_sample, mask=y_sample)

            image_augm = augmented['image']
            mask_augm = augmented['mask']#.reshape(self.width, self.height, self.nb_y_features)
            X[i, ...] = image_augm
            y[i, ...] = mask_augm

        else:
            X[i, ...] = X_sample
            y[i, ...] = y_sample

    return X, y

def on_epoch_end(self):
    'Updates indexes after each epoch'
    self.indexes = list(range(len(self.X)))
    np.random.shuffle(self.indexes)
```
**Describe the expected behavior**  
In TensorFlow's Dataset API, we can use dataset.prefetch(buffer_size=xxx) to preload other batches' data while GPU is processing the current batch's data, therefore, I can make full use of GPU. How to modify current code to get it start working with preloading batches behavior.
**Code to reproduce the issue**  
Calling fit predict in keras
 
",Diyago,None,2019-05-21T15:35:23Z,2019-05-22T07:51:15Z
12825,Seq2Seq Model with GRU  tf.map_fn error,"<em>Please make sure that this is a Bug or a Feature Request and provide all applicable information asked by the template.
If your issue is an **implementation question**, please ask your question on [StackOverflow](http://stackoverflow.com/questions/tagged/keras) or [on the Keras Slack channel](https://keras-slack-autojoin.herokuapp.com/) instead of opening a GitHub issue.</em>  

**System information**  
- Have I written custom code (as opposed to using example directory):  
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  
- TensorFlow backend (yes / no):  Yes
- TensorFlow version:   1.13.1
- Keras version:   2.2.4
- Python version:  3.6.8
- CUDA/cuDNN version:  No CUDA
- GPU model and memory:  No GPU

You can obtain the TensorFlow version with:  
python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""  
You can obtain the Keras version with:  
python -c 'import keras as k; print(k.__version__)'  

**Describe the current behavior**  

I'm prototyping as Seq2Seq Model as described in the https://blog.keras.io/a-ten-minute-introduction-to-sequence-to-sequence-learning-in-keras.html blog post. It works fine with a LSTM layer for inference, using GRU for training works OK, but the code for inference doesn't work at all, I suspect that my code must have some error or something like like.

**Describe the expected behavior**  

I haven't code for inference in the blog post for GRUs, does anyone have used before?

**Code to reproduce the issue**  
Provide a reproducible test case that is the bare minimum necessary to generate the problem.  

Here's the code: 
from keras.models import Model
from keras.layers import Input, Dense, GRU, Bidirectional
import numpy as np

input_texts = []
target_texts = []
chars = set()
num_sentences = 1024

for i, line in enumerate(open('fra.txt', 'r', encoding='utf-8')):
	line = line.lower()
	line = line.replace('\n', '')
	inp, out = line.split('\t')
	input_texts.append(inp)
	out = '\t' + out + '\n'
	target_texts.append(out)
	
	for ch in inp:
		if ch not in chars:
			chars.add(ch)
			
	for ch in out:
		if ch not in chars:
			chars.add(ch)
	
	if i > num_sentences:
		break
		
		
chr2idx = {}
idx2chr = {}

for i, ch in enumerate(chars):
	idx2chr[i] = ch
	chr2idx[ch] = i
	
print(chr2idx)

max_seq = 64
num_tokens = len(chars)
num_samples = len(input_texts)

encoder_input_data = np.zeros((num_samples, max_seq, num_tokens), dtype='float32')
decoder_input_data = np.zeros((num_samples, max_seq, num_tokens), dtype='float32')
decoder_target_data = np.zeros((num_samples, max_seq, num_tokens), dtype='float32')

for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):
    for t, char in enumerate(input_text):
        encoder_input_data[i, t, chr2idx[char]] = 1.0
    for t, char in enumerate(target_text):
        decoder_input_data[i, t, chr2idx[char]] = 1.0
        if t > 0:
            decoder_target_data[i, t - 1, chr2idx[char]] = 1.0


def Encoder(latent_dim, num_tokens):
	_input = Input(shape=(None, num_tokens))
	encoder = Bidirectional(GRU(latent_dim, return_state=True))
	outputs, hf, hb = encoder(_input)
	return {'input' : _input, 'encoder' : encoder, 'states' : [hf, hb]}
	
	
def Decoder(latent_dim, num_tokens, states):
	_input = Input(shape=(None, num_tokens))
	decoder = Bidirectional(GRU(latent_dim, return_sequences=True))
	outputs = decoder(_input, initial_state=states)
	fc = Dense(num_tokens, activation='softmax')
	output = fc(outputs)
	return {'input' : _input, 'decoder' : decoder, 'output' : output}
	
	
latent_dim = 128

encoder = Encoder(latent_dim, num_tokens)
decoder = Decoder(latent_dim, num_tokens, encoder['states'])

model = Model([encoder['input'], decoder['input']], decoder['output'])
model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])
model.summary()


encoder_infer = Model(encoder['input'], encoder['states'])
h = Input(shape=(None, num_tokens))
outputs, hf, hb = decoder['decoder'](h)

output = decoder['output'](outputs)
decoder_infer = Model([decoder['input']], [decoder['output']] + [hf, hb])

cont = encoder_infer.predict(encoder_input_data[0])
out = decoder_infer.predict(cont)
print(out)

#model.fit([encoder_input_data, decoder_input_data], decoder_target_data, batch_size=128, epochs=1000)




**Other info / logs**  
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.  

This is the error message that I getting: Traceback (most recent call last):
  File ""bi_gru.py"", line 84, in <module>
    outputs, hf, hb = decoder['decoder'](h)
  File ""C:\Program Files\Python36\lib\site-packages\tensorflow\python\framework\ops.py"", line 442, in __iter__
    ""Tensor objects are only iterable when eager execution is ""
TypeError: Tensor objects are only iterable when eager execution is enabled. To iterate over this tensor use tf.map_fn.

Cheers.",limapedro,b'backend:tensorflow type:support',2019-05-14T21:30:45Z,2019-05-15T18:05:52Z
12820,Train on Batch error for generator,"<em>Please make sure that this is a Bug or a Feature Request and provide all applicable information asked by the template.
If your issue is an **implementation question**, please ask your question on [StackOverflow](http://stackoverflow.com/questions/tagged/keras) or [on the Keras Slack channel](https://keras-slack-autojoin.herokuapp.com/) instead of opening a GitHub issue.</em>  

**System information**  
- Have I written custom code (as opposed to using example directory):  no
- Windows 10
- TensorFlow backend (yes / no):  yes
- TensorFlow version:  1.13.1 / 1.12.0
- Keras version:  2.2.4
- Python version:  3.6.8
- CUDA/cuDNN version:  no
- GPU model and memory:  -

**Describe the current behavior**  
When trying to train a convolutional 3d model on batch data the following tensorflow error shows up: 
F .\tensorflow/core/util/mkl_util.h:607] Check failed: dims == sizes.size() (5 vs. 4)

**Describe the expected behavior**  
Generator model should train on batch. It works for the critic, but not generator. 
It worked for Conv2D for both models, but doesn't for Conv3D.

**Code to reproduce the issue**  


```
    gan = WGAN_3d()
    gan.train(epochs=500, batch_size=32)
```

```
from keras.layers.merge import _Merge
from keras.layers import Input, Dense, Reshape, Flatten, Dropout
from keras.layers import BatchNormalization, Activation, ZeroPadding3D
from keras.layers.advanced_activations import LeakyReLU
from keras.layers.convolutional import UpSampling3D, Conv3D
from keras.models import Sequential, Model
from keras.optimizers import RMSprop
from functools import partial

import keras.backend as K

import sys
import time
import numpy as np


class RandomWeightedAverage(_Merge):
    def _merge_function(self, inputs):
        alpha = K.random_uniform((28, 1, 1, 1))
        return (alpha * inputs[0]) + ((1 - alpha) * inputs[1])

class WGAN_3D():
    def __init__(self):
        self.x_axis = 28
        self.y_axis = 28
        self.z_axis = 28
        self.channels = 1
        self.shape = (self.x_axis, self.y_axis, self.z_axis, self.channels)
        self.latent_dim = 100

        self.n_critic = 5
        optimizer = RMSprop(lr=0.00005)

        self.generator = self.build_generator()
        self.critic = self.build_critic()

        # Stop generator during training of critic
        self.generator.trainable = False

        given_data = Input(shape=self.shape)

        noise_input = Input(shape=(self.latent_dim,))

        fake_body = self.generator(noise_input)

        fake = self.critic(fake_body)
        validity = self.critic(given_data)

        interpolation = RandomWeightedAverage()([given_data, fake_body])
        validity_interpolated = self.critic(interpolation)

        partial_gp_loss = partial(self.gradient_penalty_loss, averaged_samples=interpolation)
        partial_gp_loss.__name__ = 'gradient_penalty'

        data_in = [given_data, noise_input]
        data_out = [validity, fake, validity_interpolated]
        self.critic_model = Model(inputs=data_in, outputs=data_out)
        loss_param = [self.wasserstein_loss, self.wasserstein_loss, partial_gp_loss]
        self.critic_model.compile(loss=loss_param, optimizer=optimizer, loss_weights=[1, 1, 10])

        self.critic.trainable = False
        self.generator.trainable = True

        z_gen = Input(shape=(100,))
        generated_bodies = self.generator(z_gen)
        validity = self.critic(generated_bodies)
        self.generator_model = Model(z_gen, validity)
        self.generator_model.compile(loss=self.wasserstein_loss, optimizer=optimizer)

    def gradient_penalty_loss(self, y_true, y_pred, averaged_samples):
        gradients = K.gradients(y_pred, averaged_samples)[0]
        gradients_sqr = K.square(gradients)
        gradients_sqr_sum = K.sum(gradients_sqr, axis=np.arange(1, len(gradients_sqr.shape)))
        gradient_l2_norm = K.sqrt(gradients_sqr_sum)
        gradient_penalty = K.square(1 - gradient_l2_norm)
        return K.mean(gradient_penalty)

    def wasserstein_loss(self, y_true, y_pred):
        return K.mean(y_true * y_pred)

    def build_generator(self):

        generator = Sequential()

        generator.add(Dense(128*7*7*7, activation=""relu"", input_dim=self.latent_dim))
        generator.add(Reshape((7, 7, 7, 128)))
        generator.add(UpSampling3D())
        generator.add(Conv3D(128, kernel_size=4, padding=""same""))
        generator.add(BatchNormalization(momentum=0.8))
        generator.add(LeakyReLU(alpha=0.2))
        generator.add(UpSampling3D())
        generator.add(Conv3D(64, kernel_size=4, padding=""same""))
        generator.add(BatchNormalization(momentum=0.8))
        generator.add(LeakyReLU(alpha=0.2))
        generator.add(Conv3D(self.channels, kernel_size=4, padding=""same""))
        generator.add(Activation(""tanh""))

        generator.summary()
        noise = Input(shape=(self.latent_dim,))
        generator = generator(noise)
        return Model(noise, generator)

    def build_critic(self):

        critic = Sequential()

        critic.add(Conv3D(1, kernel_size=3, strides=2, input_shape=self.shape, padding=""same""))
        critic.add(LeakyReLU(alpha=0.2))
        critic.add(Dropout(0.25))
        critic.add(Conv3D(2, kernel_size=3, strides=2, padding=""same""))
        critic.add(ZeroPadding3D(padding=((0,1),(0,1),(0,1))))
        critic.add(BatchNormalization(momentum=0.8))
        critic.add(LeakyReLU(alpha=0.2))
        critic.add(Dropout(0.25))
        critic.add(Conv3D(2, kernel_size=3, strides=2, padding=""same""))
        critic.add(BatchNormalization(momentum=0.8))
        critic.add(LeakyReLU(alpha=0.2))
        critic.add(Dropout(0.25))
        critic.add(Conv3D(2, kernel_size=3, strides=1, padding=""same""))
        critic.add(BatchNormalization(momentum=0.8))
        critic.add(LeakyReLU(alpha=0.2))
        critic.add(Dropout(0.25))
        critic.add(Flatten())
        critic.add(Dense(1))

        critic.summary()
        item = Input(shape=self.shape)
        validity = critic(item)
        return Model(item, validity)

    def train(self, epochs, batch_size, sample_interval=50):
        X_train = ellipses_3d(100, 28, 28, 28)
        X_train = np.expand_dims(X_train, axis=4)

        valid = -np.ones((batch_size, 1))
        fake = np.ones((batch_size, 1))
        dummy = np.zeros((batch_size, 1))

        for epoch in range(epochs):
            for _ in range(self.n_critic):
                rand = np.random.randint(0, X_train.shape[0], batch_size)
                vol = X_train[rand]
                noise = np.random.normal(0, 1, (batch_size, self.latent_dim))

                d_loss = self.critic_model.train_on_batch([vol, noise], [valid, fake, dummy])

            g_loss = self.generator_model.train_on_batch(noise, valid)
            print(""%d [D loss: %f] [G loss: %f]"" % (epoch, d_loss[0], g_loss))


def random_3d_ellipsoid(size_x, size_y, size_z):
    a = np.random.normal(3, 2.5)
    b = np.random.normal(3, 2.5)
    c = np.random.normal(3, 2.5)

    x = np.linspace(-5, 5, size_x)
    y = np.linspace(-5, 5, size_y)
    z = np.linspace(-5, 5, size_z)
    xgrid, ygrid, zgrid = np.meshgrid(x, y, z)
    ellipse = (xgrid / a)**2 + (ygrid / b)**2 + (zgrid / c)**2

    ellipse_array = np.zeros((size_x, size_y, size_z))
    ellipse_array[ellipse < 1] = 1
    return ellipse_array


def ellipses_3d(n, x, y, z):
    arr = []
    for i in range(int(n)):
        arr.append(random_3d_ellipsoid(x, y, z))
    return np.asarray(arr)
 
```

**Other info / logs**  
WARNING:tensorflow:From C:\Anaconda3\lib\site-packages\tensorflow\python\ops\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
C:\Anaconda3\lib\site-packages\keras\engine\training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?
  'Discrepancy between trainable weights and collected trainable'
2019-05-13 22:49:13.000254: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2
2019-05-13 22:49:13.001538: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 4. Tune using inter_op_parallelism_threads for best performance.
2019-05-13 22:51:19.833601: F .\tensorflow/core/util/mkl_util.h:607] Check failed: dims == sizes.size() (5 vs. 4)
2019-05-13 
Process finished with exit code -1073740791 (0xC0000409)
",def-roth,b'backend:tensorflow type:support',2019-05-13T20:54:47Z,2019-07-17T20:41:22Z
12813,custom tflite  GPUdelegate build failed on Android P(reno),"<em>Please make sure that this is a Bug or a Feature Request and provide all applicable information asked by the template.
If your issue is an **implementation question**, please ask your question on [StackOverflow](http://stackoverflow.com/questions/tagged/keras) or [on the Keras Slack channel](https://keras-slack-autojoin.herokuapp.com/) instead of opening a GitHub issue.</em>  

**System information**  
- Have I written custom code (as opposed to using example directory):  
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  
- TensorFlow backend (yes / no):  yes
- TensorFlow version:  1.12.2
- Keras version:  
- Python version:  3.5
- CUDA/cuDNN version:  
- GPU model and memory:  

You can obtain the TensorFlow version with:  
python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""  
You can obtain the Keras version with:  
python -c 'import keras as k; print(k.__version__)'  

**Describe the current behavior**  

build GPUdelegate  failed   on android P

**Describe the expected behavior**  
build pass 

**Code to reproduce the issue**  

I convert my model like this:
freeze_graph --input_graph=eval.pb  --input_checkpoint=./model_quant_self/model.ckpt-19-19    --output_graph=frozen_eval_graph.pb  --output_node_names=Softmax  
tflite_convert  --output_file=poolnet_gzq.tflite --graph_def_file=./model_gzq.pb  --inference_type=FLOAT    --input_arrays=Placeholder --input_shapes=1,224,224,3 --output_arrays=oup
  

**Other info / logs**  
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.  

here is the log:

2019-05-13 16:25:04.870 20456-22983/? W/System.err: java.lang.RuntimeException: java.lang.IllegalArgumentException: Internal error: Failed to apply delegate: GpuDelegate Prepare: fuse_auto_input failedNode number 133 (GpuDelegate) failed to prepare.

2019-05-13 16:25:04.870 20456-22983/? W/System.err: Caused by: java.lang.IllegalArgumentException: Internal error: Failed to apply delegate: GpuDelegate Prepare: fuse_auto_input failedNode number 133 (GpuDelegate) failed to prepare.
failedNode133 is my outputNode Sigmiod/Softmax  ,I had tried ,both are failed
",sunzhe09,None,2019-05-13T08:27:34Z,2019-05-13T08:28:30Z
12770,Siamese Network Performance Issues,"Please make sure that the boxes below are checked before you submit your issue. If your issue is an implementation question, please ask your question on [StackOverflow](http://stackoverflow.com/questions/tagged/keras) or [join the Keras Slack channel](https://keras-slack-autojoin.herokuapp.com/) and ask there instead of filing a GitHub issue.

Thank you!

- [x] Check that you are up-to-date with the master branch of Keras. You can update with:
pip install git+git://github.com/keras-team/keras.git --upgrade --no-deps

- [x] If running on TensorFlow, check that you are up-to-date with the latest version. The installation instructions can be found [here](https://www.tensorflow.org/get_started/os_setup).

- [ ] If running on Theano, check that you are up-to-date with the master branch of Theano. You can update with:
pip install git+git://github.com/Theano/Theano.git --upgrade --no-deps

- [x] Provide a link to a GitHub Gist of a Python script that can reproduce your issue (or just copy the script here if it is short).

###################################
###################################

So I am building a Siamese Network using VGG19 as my base network. Everything went fine throughout training and testing. However, I noticed that during training, my accuracy is quite high (only took 2 epochs to reach 100% accuracy, which was amazing), but when testing, the accuracy is around 0% (sometimes even lower, as shown below). The code is in ```train.py``` and ```test.py``` located in my repo [here](https://github.com/ayaz-amin/AyazNet). 

When I run ```train.py```, this is the output:

```
Epoch 1/2
1/1 [==============================] - 20s 20s/sample - loss: 0.6932 - accuracy: 0.3265
Epoch 2/2
1/1 [==============================] - 19s 19s/sample - loss: 0.6659 - accuracy: 1.0000
```
When I run ```test.py```, this is the output:
```
Prediction:  [[[[6.8002939e-04]
   [3.8743019e-07]
   [0.0000000e+00]
   [0.0000000e+00]
   [4.1723251e-07]
   [2.6953220e-04]
   [8.9406967e-08]]

  [[9.2387199e-07]
   [1.4901161e-07]
   [0.0000000e+00]
   [0.0000000e+00]
   [0.0000000e+00]
   [0.0000000e+00]
   [0.0000000e+00]]

  [[1.1920929e-07]
   [0.0000000e+00]
   [1.3113022e-06]
   [0.0000000e+00]
   [0.0000000e+00]
   [0.0000000e+00]
   [1.9937754e-05]]

  [[0.0000000e+00]
   [0.0000000e+00]
   [0.0000000e+00]
   [0.0000000e+00]
   [0.0000000e+00]
   [1.0132790e-06]
   [0.0000000e+00]]

  [[0.0000000e+00]
   [0.0000000e+00]
   [0.0000000e+00]
   [0.0000000e+00]
   [0.0000000e+00]
   [0.0000000e+00]
   [0.0000000e+00]]

  [[0.0000000e+00]
   [0.0000000e+00]
   [0.0000000e+00]
   [0.0000000e+00]
   [0.0000000e+00]
   [0.0000000e+00]
   [0.0000000e+00]]

  [[0.0000000e+00]
   [0.0000000e+00]
   [0.0000000e+00]
   [0.0000000e+00]
   [0.0000000e+00]
   [0.0000000e+00]
   [9.3051212e-36]]]]
```
I was expecting the output to be showing ones (0 means no similarity, 1 meaning full similarity). I am pretty sure their is nothing wrong with this code. Am I doing anything wrong? Or is it a bug? Also, I am using tf.keras from Tensorflow 2.0.
",ayaz-amin,None,2019-05-01T01:11:43Z,2019-05-02T01:29:21Z
12765,Bug in engine/training_arrays while calling call_begin_hook,"fit_loop() method is  calling callback to like ``` callbacks._call_begin_hook('train') ``` but method expects different format as ```_TRAIN```.
```
    def _call_begin_hook(self, mode):
        """"""Helper function for on_{train|test|predict}_begin methods.""""""
        if mode == _TRAIN:
            self.on_train_begin()
        elif mode == _TEST:
            self.on_test_begin()
        else:
            self.on_predict_begin()
```
",mayurnewase,None,2019-04-29T02:22:44Z,2019-04-29T02:23:12Z
12742,Concatenate layer error unhashable type: 'Dimension',"I was trying to do a simple test; Concatenating two layers.

Below is the code

```
inputs = Input(shape=(seq_length, latent_dim)) # seq_length = 3, latend_dim=2
reshaped_d_inputs = Reshape((inputs.get_shape()[1] * inputs.get_shape()[2], ))(inputs)
print(reshaped_d_inputs.get_shape()) # (?, 3, 2)
repeat_d_repeat = RepeatVector(seq_length)(reshaped_d_inputs)
repeat_d = Reshape((seq_length, inputs.get_shape()[1], inputs.get_shape()[2]))(repeat_d_repeat)
print(repeat_d.get_shape()) # (?, 3, 3, 2)


permuted_e = Permute((2, 1))(inputs)
reshaped_e_inputs = Reshape((inputs.get_shape()[1] * inputs.get_shape()[2], ))(permuted_e)
permuted_e_repeat = RepeatVector(seq_length)(reshaped_e_inputs)
repeat_e = Reshape((seq_length, inputs.get_shape()[2], inputs.get_shape()[1]))(permuted_e_repeat)
repeat_e = Permute((1, 3, 2))(repeat_e)
print(repeat_e.get_shape()) # (?, 3, 3, 2)

outputs = Concatenate(-1)([repeat_d, repeat_e])
model = Model(inputs=inputs, outputs=outputs)
model.compile(optimizer='rmsprop', loss='mse')
output_array = model.predict(input_array)
```

But it emits an error like below

> TypeError                                 Traceback (most recent call last)
> <ipython-input-95-11688d9ddbec> in <module>
>      14 print(repeat_e.get_shape())
>      15 
> ---> 16 outputs = Concatenate(-1)([repeat_d, repeat_e])
>      17 model = Model(inputs=inputs, outputs=outputs)
>      18 model.compile(optimizer='rmsprop', loss='mse')
> 
> d:\igs_projects\nlp_nlu\venv\lib\site-packages\keras\engine\base_layer.py in __call__(self, inputs, **kwargs)
>     429                                          'You can build it manually via: '
>     430                                          '`layer.build(batch_input_shape)`')
> --> 431                 self.build(unpack_singleton(input_shapes))
>     432                 self.built = True
>     433 
> 
> d:\igs_projects\nlp_nlu\venv\lib\site-packages\keras\layers\merge.py in build(self, input_shape)
>     355         for i in range(len(reduced_inputs_shapes)):
>     356             del reduced_inputs_shapes[i][self.axis]
> --> 357             shape_set.add(tuple(reduced_inputs_shapes[i]))
>     358         if len(shape_set) > 1:
>     359             raise ValueError('A `Concatenate` layer requires '
> 
> **TypeError: unhashable type: 'Dimension'**

I do not know if it is me doing something wrong or Keras bug...

After digging a while I realize that the tensor of right after the RepeatVector could be Concatenate but won't be concatenated once the posterior code is added.

",gilgarad,b'type:support',2019-04-26T02:30:34Z,2019-06-20T06:22:09Z
12724,Keras appears to generate non-deterministic tensorflow graph,"**System information**  
- Have I written custom code (as opposed to using example directory):  Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  Ubuntu 18.04
- TensorFlow backend (yes / no):   yes
- TensorFlow version:  1.13.1
- Keras version:  2.4.4 (bug exists on latest master as well)
- Python version:  3.6.8
- CUDA/cuDNN version:  not using cuda for this
- GPU model and memory:  not using cuda for this

**Describe the current behavior**  
If I set all the random seeds, use only the CPU, disable CPU multiprocessing, and I run the same experiment 10 times, the loss of the second `train_for_step()` call comes out as one of two different values each time.

**Describe the expected behavior**  
The loss should be bit-perfect reproducible in this situation.

**Code to reproduce the issue**  
```
import random
random.seed(999)
import numpy as np
np.random.seed(999)
import tensorflow as tf
tf.set_random_seed(999)

import keras
from keras.layers import (Activation, Conv2D, Dense, Dropout, Flatten,
                          MaxPooling2D, Layer)
from keras.losses import categorical_crossentropy
from keras.models import Sequential
from keras.optimizers import RMSprop, Adam
from keras.utils.data_utils import get_file

session = tf.Session(
        graph=tf.get_default_graph(),
        config=tf.ConfigProto(intra_op_parallelism_threads=1,
                              inter_op_parallelism_threads=1)
        )
keras.backend.set_session(session)

# Model taken from the keras cifar10 example
model = Sequential()
# specifying input shape upfront does not matter
#model.add(Conv2D(32, (3, 3), padding=""same"", input_shape=[ 32, 32, 3 ]))
model.add(Conv2D(32, (3, 3), padding=""same""))
model.add(Activation(""relu""))
model.add(Conv2D(32, (3, 3)))
model.add(Activation(""relu""))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.25))

model.add(Conv2D(64, (3, 3), padding=""same""))
model.add(Activation(""relu""))
model.add(Conv2D(64, (3, 3)))
model.add(Activation(""relu""))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.25))

model.add(Flatten())
model.add(Dense(512))
model.add(Activation(""relu""))
# eliminating this dropout layer restores reproducibility:
model.add(Dropout(0.5))
model.add(Dense(10))
model.add(Activation(""softmax""))

# setting decay to 0.0 or using Adam restores reproducibility
optimizer = RMSprop(lr=1e-4, decay=1e-6)
#optimizer = RMSprop(lr=1e-4, decay=0.0)
#optimizer = Adam(lr=1e-4, decay=1e-6)
model.compile(loss=categorical_crossentropy,
              optimizer=optimizer,
              metrics=[keras.metrics.categorical_accuracy,
                       keras.metrics.categorical_accuracy])

# metrics which break reproducibility:
#   losses.categorical_hinge x1
#   metrics.categorical_accuracy x2
#   losses.hinge x2
#   losses.mean_absolute_percentage_error x2

# metrics which seem fine:
#   losses.mean_squared_error
#   losses.mean_absolute_error

# build some phony data
xtrain = np.ones([64,32,32,3])
xtest = np.ones([64,32,32,3])
ytrain = np.array([[1,0,0,0,0,0,0,0,0,0] for _ in range(64)])
ytest = np.array([[1,0,0,0,0,0,0,0,0,0] for _ in range(64)])

xtrain = xtrain.astype('float32')
xtest = xtest.astype('float32')
xtrain /= 255
xtest /= 255

# train two batches

start = 0
xbatch = xtrain[start:start+32]
ybatch = ytrain[start:start+32]
print( model.train_on_batch(xbatch, ybatch) )

start = 32
xbatch = xtrain[start:start+32]
ybatch = ytrain[start:start+32]
print( model.train_on_batch(xbatch, ybatch) )

```
Check the reproducibility with the following command:

    for i in `seq 10` ; do python3 code_example.py 2>/dev/null | tail -n 1 ; done

Result:
```
[2.2911897, 1.0, 1.0]
[2.2910979, 1.0, 1.0]
[2.2910979, 1.0, 1.0]
[2.2910979, 1.0, 1.0]
[2.2911897, 1.0, 1.0]
[2.2911897, 1.0, 1.0]
[2.2910979, 1.0, 1.0]
[2.2910979, 1.0, 1.0]
[2.2911897, 1.0, 1.0]
[2.2910979, 1.0, 1.0]
```

**Other info / logs**


There are a variety of things which affect whether or not the training is bit-perfect reproducible:
 - The loss is always consistent after the first `train_for_batch()`.  Training for three steps exhibits identical behavior to training for two steps (all losses come out to one of two values)
 - Commenting out various layers restores reproducibility (see comments in code example)
 - Eliminating the decay from `RMSprop` optimizer (or using `Adam` optimizer with decay) restores reproducibility
 - Metric selection affects reproducibility.  Some metrics break reproducibility when included twice, one metric, `losses.categorical_hinge` breaks reproducibility when included at all.
 - I noticed no change in behavior when I used the git master branch.
 - Inserting a `tf.print()` into the graph, while using the RMSprop with decay, will restore reproducibility.  Patch:
```
*** optimizers.py	2019-04-23 11:10:15.269380564 -0700
--- new	2019-04-23 09:57:50.773179254 -0700
***************
*** 255,274 ****
--- 255,275 ----
      def get_updates(self, loss, params):
          grads = self.get_gradients(loss, params)
          accumulators = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]
          self.weights = accumulators
          self.updates = [K.update_add(self.iterations, 1)]
  
          lr = self.lr
          if self.initial_decay > 0:
              lr = lr * (1. / (1. + self.decay * K.cast(self.iterations,
                                                        K.dtype(self.decay))))
+         self.updates.append(tf.print(lr))
  
          for p, g, a in zip(params, grads, accumulators):
              # update accumulator
              new_a = self.rho * a + (1. - self.rho) * K.square(g)
              self.updates.append(K.update(a, new_a))
              new_p = p - lr * g / (K.sqrt(new_a) + self.epsilon)
  
              # Apply constraints.
              if getattr(p, 'constraint', None) is not None:
                  new_p = p.constraint(new_p)

```
",rb-determined-ai,b'backend:tensorflow stat:awaiting tensorflower type:support',2019-04-23T23:03:02Z,2019-07-08T17:47:25Z
12709,I can not load the MobileNet network. ,"This worked fine couple of days ago but today I could not load a base model of the MobileNet getting this error with the traceback below. Also if I use tensorflow.keras instead of simply keras, everywhere in the notebook, this works fine and the model gets loaded. But I need to run it in keras for now. 

import numpy as np
import keras
from keras import backend as K
from keras.layers.core import Dense, Activation
from keras.optimizers import Adam
from keras.metrics import categorical_crossentropy
from keras.preprocessing.image import ImageDataGenerator
from keras.preprocessing import image
from keras.models import Model
from keras.applications import imagenet_utils
from sklearn.metrics import confusion_matrix
import itertools
import matplotlib.pyplot as plt
%matplotlib inline

mobile = keras.applications.mobilenet.MobileNet() #this is where it fails

---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
<ipython-input-2-a135d4b4ac1c> in <module>
----> 1 mobile = keras.applications.mobilenet.MobileNet()

~/anaconda3/envs/python3.6/lib/python3.6/site-packages/keras/applications/__init__.py in wrapper(*args, **kwargs)
     26             kwargs['models'] = models
     27             kwargs['utils'] = utils
---> 28         return base_fun(*args, **kwargs)
     29 
     30     return wrapper

~/anaconda3/envs/python3.6/lib/python3.6/site-packages/keras/applications/mobilenet.py in MobileNet(*args, **kwargs)
      9 @keras_modules_injection
     10 def MobileNet(*args, **kwargs):
---> 11     return mobilenet.MobileNet(*args, **kwargs)
     12 
     13 

~/anaconda3/envs/python3.6/lib/python3.6/site-packages/keras_applications/mobilenet.py in MobileNet(input_shape, alpha, depth_multiplier, dropout, include_top, weights, input_tensor, pooling, classes, **kwargs)
    231 
    232     if input_tensor is None:
--> 233         img_input = layers.Input(shape=input_shape)
    234     else:
    235         if not backend.is_keras_tensor(input_tensor):

~/anaconda3/envs/python3.6/lib/python3.6/site-packages/keras/engine/input_layer.py in Input(shape, batch_shape, name, dtype, sparse, tensor)
    176                              name=name, dtype=dtype,
    177                              sparse=sparse,
--> 178                              input_tensor=tensor)
    179     # Return tensor including _keras_shape and _keras_history.
    180     # Note that in this case train_output and test_output are the same pointer.

~/anaconda3/envs/python3.6/lib/python3.6/site-packages/keras/legacy/interfaces.py in wrapper(*args, **kwargs)
     89                 warnings.warn('Update your `' + object_name + '` call to the ' +
     90                               'Keras 2 API: ' + signature, stacklevel=2)
---> 91             return func(*args, **kwargs)
     92         wrapper._original_function = func
     93         return wrapper

~/anaconda3/envs/python3.6/lib/python3.6/site-packages/keras/engine/input_layer.py in __init__(self, input_shape, batch_size, batch_input_shape, dtype, input_tensor, sparse, name)
     37         if not name:
     38             prefix = 'input'
---> 39             name = prefix + '_' + str(K.get_uid(prefix))
     40         super(InputLayer, self).__init__(dtype=dtype, name=name)
     41 

~/anaconda3/envs/python3.6/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py in get_uid(prefix)
     72     """"""
     73     global _GRAPH_UID_DICTS
---> 74     graph = tf.get_default_graph()
     75     if graph not in _GRAPH_UID_DICTS:
     76         _GRAPH_UID_DICTS[graph] = defaultdict(int)

AttributeError: module 'tensorflow' has no attribute 'get_default_graph'",rachita97,b'backend:tensorflow type:bug/performance',2019-04-21T21:02:56Z,2019-05-07T15:50:16Z
12696,Want to build custom layer just before Conv2d layer using keras  for that how do I initialize filter weight to zero,"<em>Please make sure that this is a Bug or a Feature Request and provide all applicable information asked by the template.
If your issue is an **implementation question**, please ask your question on [StackOverflow](http://stackoverflow.com/questions/tagged/keras) or [on the Keras Slack channel](https://keras-slack-autojoin.herokuapp.com/) instead of opening a GitHub issue.</em>  

**System information**  
- Have I written custom code (as opposed to using example directory):  
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  
- TensorFlow backend (yes / no):  
- TensorFlow version:  
- Keras version:  
- Python version:  
- CUDA/cuDNN version:  
- GPU model and memory:  

You can obtain the TensorFlow version with:  
python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""  
You can obtain the Keras version with:  
python -c 'import keras as k; print(k.__version__)'  

**Describe the current behavior**  

**Describe the expected behavior**  

**Code to reproduce the issue**  
Provide a reproducible test case that is the bare minimum necessary to generate the problem.  

**Other info / logs**  
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.  
",HinalVakharia,b'backend:tensorflow type:support',2019-04-18T14:16:23Z,2019-04-24T18:30:01Z
12691,AttributeError: 'model' object has no attribute 'layers',"<em>Please make sure that this is a Bug or a Feature Request and provide all applicable information asked by the template.
If your issue is an **implementation question**, please ask your question on [StackOverflow](http://stackoverflow.com/questions/tagged/keras) or [on the Keras Slack channel](https://keras-slack-autojoin.herokuapp.com/) instead of opening a GitHub issue.</em>  

**System information**  
- Have I written custom code (as opposed to using example directory):  
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  
- TensorFlow backend (yes / no):  
- TensorFlow version:  
- Keras version:  
- Python version:  
- CUDA/cuDNN version:  
- GPU model and memory:  

You can obtain the TensorFlow version with:  
python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""  
You can obtain the Keras version with:  
python -c 'import keras as k; print(k.__version__)'  

**Describe the current behavior**  

**Describe the expected behavior**  

**Code to reproduce the issue**  
Provide a reproducible test case that is the bare minimum necessary to generate the problem.  

**Other info / logs**  
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.  
",farazBhatti,b'backend:tensorflow stat:awaiting response type:support',2019-04-17T10:26:32Z,2019-04-23T17:29:49Z
12675,change plot_model to fully support plotting submodel and fix bugs,"### Summary

Changed plot_model function in vis_utils.py to fully support plotting submodels and also fixed some bugs. Previous PR [#11431](https://github.com/keras-team/keras/pull/11431) had add ability to visualize only wrapped submodels with plot_model function, but it works wrong sometimes, as shown below later. This PR can not only support plotting wrapped submodels, but also add ability to plot unwrapped submodels. And it doesn't get wrong results according to my tests.

For example, this model is from [Video question answering model](https://keras.io/getting-started/functional-api-guide/#video-question-answering-model) in Keras Documentation.

```python
from keras.layers import Conv2D, MaxPooling2D, Flatten
from keras.layers import Input, LSTM, Embedding, Dense
from keras.layers import TimeDistributed
from keras.models import Model, Sequential
from keras.utils.vis_utils import plot_model
import keras

# Define a vision model using a Sequential model.
# This model will encode an image into a vector.
vision_model = Sequential()
vision_model.add(Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=(224, 224, 3)))
vision_model.add(Conv2D(64, (3, 3), activation='relu'))
vision_model.add(MaxPooling2D((2, 2)))
vision_model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))
vision_model.add(Conv2D(128, (3, 3), activation='relu'))
vision_model.add(MaxPooling2D((2, 2)))
vision_model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))
vision_model.add(Conv2D(256, (3, 3), activation='relu'))
vision_model.add(Conv2D(256, (3, 3), activation='relu'))
vision_model.add(MaxPooling2D((2, 2)))
vision_model.add(Flatten())

# This is our video encoded via the previously trained vision_model (weights are reused)
video_input = Input(shape=(100, 224, 224, 3))
encoded_frame_sequence = TimeDistributed(vision_model)(video_input)  # the output will be a sequence of vectors
encoded_video = LSTM(256)(encoded_frame_sequence)  # the output will be a vector

# Define a language model to encode the question into a vector.
# Each question will be at most 100 word long,
# and we will index words as integers from 1 to 9999.
question_input = Input(shape=(100,), dtype='int32')
embedded_question = Embedding(input_dim=10000, output_dim=256, input_length=100)(question_input)
encoded_question = LSTM(256)(embedded_question)

# This is a model-level representation of the question encoder
question_encoder = Model(inputs=question_input, outputs=encoded_question)

# Let's use it to encode the question:
video_question_input = Input(shape=(100,), dtype='int32')
encoded_video_question = question_encoder(video_question_input)

# And this is our video question answering model:
merged = keras.layers.concatenate([encoded_video, encoded_video_question])
output = Dense(1000, activation='softmax')(merged)
video_qa_model = Model(inputs=[video_input, video_question_input], outputs=output)
```

Calling plot_model without parameter ```expand_nested``` will produce:
```python
plot_model(video_qa_model, to_file=""model.png"", show_shapes=True)
```
![model_new_not_expand](https://user-images.githubusercontent.com/42084654/56105055-1763c800-5f6d-11e9-98b7-19b2a3042b50.png)

Calling plot_model with parameter ```expand_nested=True``` will produce the picture below. As we can see, it plotted both wrapped submodels and unwrapped submodels, i.e., time_distributed_1(sequential_1) and model_1.

```python
plot_model(video_qa_model, to_file=""model.png"", show_shapes=True, expand_nested=True)
```
![model_new_expand](https://user-images.githubusercontent.com/42084654/56105079-2c405b80-5f6d-11e9-8d4a-6524fc67fa6e.png)

However, calling the same with previous PR will produce something wrong as below. First, it can't plot unwrapped models; Second, it  even got wrong model structure, which is the bug we talked before.

![model_old_expand](https://user-images.githubusercontent.com/42084654/56105095-3a8e7780-5f6d-11e9-955a-7d27661f15ec.png)


### Related Issues

[#5937](https://github.com/keras-team/keras/issues/5937)

### Related PRs

[#11431](https://github.com/keras-team/keras/pull/11431)

### PR Overview

- [ ] This PR requires new unit tests [y/n] (make sure tests are included)
- [ ] This PR requires to update the documentation [y/n] (make sure the docs are up-to-date)
- [x] This PR is backwards compatible [y/n]
- [ ] This PR changes the current API [y/n] (all API changes need to be approved by fchollet)
",ccgccc,None,2019-04-15T02:59:44Z,2019-04-27T22:28:21Z
12618,Fix a minor bug in the VAE example,"<!--
Please make sure you've read and understood our contributing guidelines;
https://github.com/keras-team/keras/blob/master/CONTRIBUTING.md
-->

### Summary

In the original code, len(pixel_range) is 31, which does not affect the plot though.

This commit makes `len(pixel_range) == len(sample_range_x) == len(sample_range_y) == 30`.

### Related Issues

### PR Overview

- [ ] This PR requires new unit tests [y/n] (make sure tests are included)
- [ ] This PR requires to update the documentation [y/n] (make sure the docs are up-to-date)
- [ ] This PR is backwards compatible [y/n]
- [ ] This PR changes the current API [y/n] (all API changes need to be approved by fchollet)
",BiggerHao,None,2019-04-04T06:04:36Z,2019-04-04T16:31:36Z
12594,NameError: name 'embed' is not defined,"Please make sure that the boxes below are checked before you submit your issue.
If your issue is an **implementation question**, please ask your question on [StackOverflow](http://stackoverflow.com/questions/tagged/keras) or [on the Keras Slack channel](https://keras-slack-autojoin.herokuapp.com/) instead of opening a GitHub issue.

Thank you!

- [x] Check that you are up-to-date with the master branch of Keras. You can update with:
`pip install git+git://github.com/keras-team/keras.git --upgrade --no-deps`

- [x] Check that your version of TensorFlow is up-to-date. The installation instructions can be found [here](https://www.tensorflow.org/get_started/os_setup).

- [x] Provide a link to a GitHub Gist of a Python script that can reproduce your issue (or just copy the script here if it is short).




I'm working on Keras model which uses Universal Sentence Embedding to encode the provided sentences. However, when I save the model for future usage, the mentioned error is thrown. NameError: name 'embed' is not defined

The sentences are converted to embedding using UniversalEmbedding(x) function. The code of whole model is taken from this link.

```
!wget https://raw.githubusercontent.com/Tony607/Keras-Text-Transfer-Learning/master/train_5500.txt
!wget https://raw.githubusercontent.com/Tony607/Keras-Text-Transfer-Learning/master/test_data.txt

import tensorflow as tf
import tensorflow_hub as hub
import matplotlib.pyplot as plt
import numpy as np
import os
import pandas as pd
import re
import seaborn as sns
import keras.layers as layers
from keras.models import Model
from keras import backend as K
np.random.seed(10)

def get_dataframe(filename):
    lines = open(filename, 'r').read().splitlines()
    data = []
    for i in range(0, len(lines)):
        label = lines[i].split(' ')[0]
        label = label.split("":"")[0]
        text = ' '.join(lines[i].split(' ')[1:])
        text = re.sub('[^A-Za-z0-9 ,\?\'\""-._\+\!/\`@=;:]+', '', text)
        data.append([label, text])

    df = pd.DataFrame(data, columns=['label', 'text'])
    df.label = df.label.astype('category')
    return df

df_train = get_dataframe('train_5500.txt')
df_train = get_dataframe('test_data.txt')

category_counts = len(df_train.label.cat.categories)
module_url = ""https://tfhub.dev/google/universal-sentence-encoder-large/3"" 
embed = hub.Module(module_url)
embed_size = embed.get_output_info_dict()['default'].get_shape()[1].value

def UniversalEmbedding(x):
    return embed(tf.squeeze(tf.cast(x, tf.string)), signature=""default"", as_dict=True)[""default""]

input_text = layers.Input(shape=(1,), dtype='string')
embedding = layers.Lambda(UniversalEmbedding, output_shape=(embed_size,))(input_text)
dense = layers.Dense(256, activation='relu')(embedding)
pred = layers.Dense(category_counts, activation='softmax')(dense)
model = Model(inputs=[input_text], outputs=pred)
model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

train_text = df_train['text'].tolist()
train_text = np.array(train_text, dtype=object)[:, np.newaxis]

train_label = np.asarray(pd.get_dummies(df_train.label), dtype = np.int8)

df_test = get_dataframe('test_data.txt')
test_text = df_test['text'].tolist()
test_text = np.array(test_text, dtype=object)[:, np.newaxis]
test_label = np.asarray(pd.get_dummies(df_test.label), dtype = np.int8)


with tf.Session() as session:
  K.set_session(session)
  session.run(tf.global_variables_initializer())
  session.run(tf.tables_initializer())
  history = model.fit(train_text, 
            train_label,
            validation_data=(test_text, test_label),
            epochs=2,
            batch_size=32)
  model.save_weights('./model.h5')
  model.save('mod.h5')
```

When I try to load the model like

```
from keras.models import load_model

load_model('mod.h5') 
```


",bhaskar-dhariyal,b'backend:tensorflow stat:awaiting tensorflower type:bug/performance',2019-04-01T13:19:07Z,2020-01-31T22:19:22Z
12592,"After training the model of InceptionV3 ,  how to modify the  Atrribute of 'FusedBatchNorm' from 'is_training:True'  to 'is_training:False' ?","After I  trained the model and convert it from '.model' to '.pb'  by keras ,  I found the Attribute of  node named 'FusedBatchNorm'  is 'is_training : True',   so  I add the code to  modify  the attribute from True to False,  but it  did not work,   is there anyone helping me ?

My .pb graph shows as follows, (the attribute 'is_training' of FusedBatchNorm is True )
<img width=""915"" alt=""360截图18141217433342"" src=""https://user-images.githubusercontent.com/14754815/55325327-4c751280-54b7-11e9-9b72-ac1da5ee68f2.png"">


My convertion code from '.hdf5' to '.pb' is as follows  :
`def h5_to_pb(h5_model,output_dir,model_name,out_prefix = ""output_"",log_tensorboard = True):

    if osp.exists(output_dir) == False:
        os.mkdir(output_dir)
        
    out_nodes = []
    for i in range(len(h5_model.outputs)):
        out_nodes.append(out_prefix + str(i + 1))
        tf.identity(h5_model.output[i],out_prefix + str(i + 1))

    from tensorflow.python.framework import graph_util,graph_io
    sess = K.get_session()
    init_graph = sess.graph.as_graph_def()

    **for i in range(len(init_graph.node)):
        node = init_graph.node[i]
        print('node %d :'%i) 
        print (node)
        if node.op == 'FusedBatchNorm':
            if 'is_training' in node.attr: 
                node.attr['is_training'] = False**
    main_graph = graph_util.convert_variables_to_constants(sess,init_graph,out_nodes)
    graph_io.write_graph(main_graph,output_dir,name = model_name,as_text = False)`


when I run the code above , the error occurs as follows:
  File ""model2pb3.py"", line 155, in h5_to_pb
    node.attr['is_training'] = False
ValueError: Direct assignment of submessage not allowed



",ib198669,b'backend:tensorflow type:bug/performance',2019-04-01T11:54:04Z,2019-06-10T09:42:46Z
12547,Cannot restore a frozen graph .pb which contains a tf.keras.layers.BatchNormalization layer,"Freezing a Keras graph which contains a BatchNormalization Layer creates a graph which cannot be loaded by the Tensorflow API. The following error is produced:

```
Traceback (most recent call last):
  File ""C:\Program Files\JetBrains\PyCharm 2018.2.5\helpers\pydev\pydevd.py"", line 1664, in <module>
    main()
  File ""C:\Program Files\JetBrains\PyCharm 2018.2.5\helpers\pydev\pydevd.py"", line 1658, in main
    globals = debugger.run(setup['file'], None, None, is_module)
  File ""C:\Program Files\JetBrains\PyCharm 2018.2.5\helpers\pydev\pydevd.py"", line 1068, in run
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File ""C:\Program Files\JetBrains\PyCharm 2018.2.5\helpers\pydev\_pydev_imps\_pydev_execfile.py"", line 18, in execfile
    exec(compile(contents+""\n"", file, 'exec'), glob, loc)
  File ""C:/code sandbox/keras_load_batchnorm.py"", line 37, in <module>
    tf.import_graph_def(graph_def)
  File ""C:\Users\lukeb\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\util\deprecation.py"", line 488, in new_func
    return func(*args, **kwargs)
  File ""C:\Users\lukeb\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\framework\importer.py"", line 422, in import_graph_def
    raise ValueError(str(e))
ValueError: Input 0 of node import/bn/cond/ReadVariableOp/Switch was passed float from import/bn/gamma:0 incompatible with expected resource.
```

It seems that the ""convert_variables_to_constants"" method doesn't know what to do with the Batch Normalization layer.

Here is a fully working example that demonstrates the error:
```
import os
import tensorflow as tf
from tensorflow.python.framework.graph_util import convert_variables_to_constants
from tensorflow.python.platform import gfile

path = ""graph\\""
dirname = os.path.dirname(os.path.realpath(__file__))
filename = ""frozen_graph.pb""
output_folder = os.path.join(dirname, path)
output_file = os.path.join(output_folder, filename)
os.makedirs(output_folder, exist_ok=True)

sess = tf.Session()
tf.keras.backend.set_session(sess)

input = tf.keras.layers.Input(shape=(1, 1, 1), name=""input"")
x = tf.keras.layers.BatchNormalization(name=""bn"")(input)
x = tf.keras.layers.Activation(""relu"", name=""ouput"")(x)
model = tf.keras.models.Model(input, x)
model.compile(""adam"", loss=""mse"")

sess.run([tf.global_variables_initializer(), tf.local_variables_initializer()])

input_graph_def = sess.graph.as_graph_def()
output_names = [node.op.name for node in model.outputs]
freeze_var_names = list(set(v.op.name for v in tf.global_variables()))

frozen_graph = convert_variables_to_constants(sess, input_graph_def, output_names, freeze_var_names)
tf.train.write_graph(frozen_graph, """", output_file, as_text=False)

with sess:
   with gfile.FastGFile(output_file,'rb') as f:
       graph_def = tf.GraphDef()
   graph_def.ParseFromString(f.read())
   sess.graph.as_default()
   tf.import_graph_def(graph_def)
```

I have tried the solutions suggested by the following:
-[Altering nodes before saving: ](https://github.com/tensorflow/tensorflow/issues/3628#issuecomment-272149052)This one doesn't fix it
-[Setting learning phase: ](https://stackoverflow.com/a/52823701/6936275)This one cannot be used outside of a Keras environment
-[Rolling batchnorm layer into previous layers: ](https://stackoverflow.com/a/51157850/6936275)I started this one but it gets very complicated when your layers are not simply stacked.

This is a real showstopper for getting models into production, especially with Keras becoming the main API for RNN's in tf 2.0.",LukeBolly,b'backend:tensorflow stat:awaiting tensorflower type:bug/performance',2019-03-25T10:10:57Z,2019-04-12T04:03:13Z
12457,"Keras Error: Variable does not exist, or was not created with tf.get_variable()","```
import tensorflow.keras as ks
def scope_error_test():
    input_holder = tf.placeholder(dtype=tf.float32,
                                  shape=(None, 368, 368, 3),
                                  name='input')
    with tf.variable_scope(""scope_1""):
        with tf.variable_scope(""scope_2""):
            conv1 = ks.layers.Conv2D(kernel_size=7,
                                     filters=64,
                                     strides=2,
                                     padding='same',
                                     activation=tf.nn.relu,
                                     name='conv1')(input_holder)
            pool1 = ks.layers.MaxPool2D(pool_size=3, padding='same',
                                        strides=2,
                                        name='pool1')(inputs=conv1)
    print(pool1.get_shape().as_list())
with tf.Session() as sess:
        scope_error_test()
        sess.run(tf.global_variables_initializer())
        print(tf.global_variables())
        with tf.variable_scope('', reuse=True):
            for variable in tf.global_variables():
                var_name = variable.name.split(':')[0]
                var_tf = tf.get_variable(var_name)
```
In this example code, I want to understand why I get this error: ValueError: Variable scope_1/scope_2/conv1/kernel does not exist, or was not created with tf.get_variable(). Did you mean to set reuse=tf.AUTO_REUSE in VarScope?

Note: I used `tensorflow.contrib.layers` instead of `tensorflow.keras.layers` and It was working correctly! Could be a bug !?

I have tried `tensorflow 1.9.0` and `tensorflow 1.12.0`",rafikg,b'backend:tensorflow stat:cross-posting to TF type:bug/performance',2019-03-12T01:25:47Z,2019-05-07T22:22:25Z
12454,[tf-2] added PIL and pandas to setup.py,"<!--
Please make sure you've read and understood our contributing guidelines;
https://github.com/keras-team/keras/blob/master/CONTRIBUTING.md
-->

### Summary
I am trying to fix the tests in the tf-2 branch to make it robust with TF-2.0
Currently pytest throws 7 errors, 5 of which are import errors for libraries PIL, pandas, flaky and pyux, one is [this](https://github.com/keras-team/keras/blob/ed387f1243893936de2d118657676549b6864eb6/keras/backend/tensorflow_backend.py#L190) runtime error for getting Keras backend session and the last one is [this](https://github.com/pytest-dev/pytest/issues/3221) bug with pytest module.
I want to solve these one by one.
This PR solves the import errors. 
2nd can be solved by removing the exception catching in that function (I checked), but would want an opinion (Because the check _is_tf_1() has been used multiple times in that script, dont know why, considering it is a tf-2 branch).
I also have a working solution for 3rd problem (remove the pytest decorators for  [this](https://github.com/keras-team/keras/blob/14625e57af7fe85eae501582ce1da135fc04c8e8/tests/keras/layers/convolutional_recurrent_test.py#L24) function) 
Please let me know if I can submit those PRs as well or if I need to change my direction.

### Related Issues

### PR Overview

- [ ] This PR requires new unit tests [y/n] (make sure tests are included) No
- [ ] This PR requires to update the documentation [y/n] (make sure the docs are up-to-date) No
- [ ] This PR is backwards compatible [y/n] Dont know
- [ ] This PR changes the current API [y/n] (all API changes need to be approved by fchollet) No
",piyush-kgp,None,2019-03-11T14:52:38Z,2019-03-11T15:57:34Z
12450,Siamese Network used with pre-trained Resnet50 does not get trained (loss decreases while accuracy stuck at 50%),"I am trying to build a siamese network for recommending visually similar items. My goal is to have two inputs, shared pre-trained ResNet50 architecture (+ 512 dense layer) which is connected to one another 512 dense layer. It's heavily inspired by official [keras siamese mnist example](https://github.com/keras-team/keras/blob/master/examples/mnist_siamese.py) It seems that my implementation sometimes works, however, most of the time loss decreases while accuracy stays the same. When I created new AWS EC2 instance and ran it for the first time the decreased and accuracy increased very rapidly, after I ran the script second time (without doing any changes) it got stuck at 50% (±1%). Now no matter what I do the accuracy does not change (although loss decreases).

I have spent last 2 weeks debugging this issue. It seems to be related to batch-normalization, but I could be wrong. Also, it seems that I am not the only one having this issue [here](https://stackoverflow.com/questions/50297393/siamese-network-not-getting-trained) or [here](https://stackoverflow.com/questions/44262807/why-does-this-keras-siamese-network-for-image-matching-not-learn-anything)

I am attaching Jupyter Notebook with the entire script [here](https://github.com/mkondela/siamese-network/blob/master/siamese_network.ipynb) (easy to follow and easy to reproduce).
ANY help is much appreciated. If this is not a bug related to Keras than I apologise. 
",kondela,None,2019-03-11T11:08:27Z,2019-07-10T20:09:56Z
12274,"Loss on last training step and sklearn calculated log_loss differ, but validation_loss doesn't","Hi,

I am using Keras 2.2.4, tensorflow 1.12.0.

I am experiencing a problem, where I use the sklearn.metrics log_loss function on my training and validation data to calculate the loss. Upon comparing it to the result that model.fit prints in the last step, I realized that the validation losses of the model.fit and log_loss function are identical (which they should be), but for the training data, they aren't.
I reproduced the issue on a simple iris network.

The model is set up via
`train_x, test_x, train_y, test_y = model_selection.train_test_split(X,Y,test_size = 0.1, random_state = 0)`
`input_dim = len(data.columns) - 1`
`model = Sequential()`
`model.add(Dense(8, input_dim = input_dim , activation = 'relu'))`
`model.add(Dense(10, activation = 'relu'))`
`model.add(Dense(10, activation = 'relu'))`
`model.add(Dense(10, activation = 'relu'))`
`model.add(Dense(3, activation = 'softmax'))`
`model.compile(loss = 'categorical_crossentropy' , optimizer = 'adam' )`
`validation_data = (test_x, test_y)`
`model.fit(train_x, train_y, epochs = 1, batch_size = 2, validation_data=validation_data)`

and afterwards the losses are calculated like this:
`p = model.predict_proba(train_x, batch_size=2)`
`ll = log_loss(train_y, p)`
`p = model.predict_proba(test_x, batch_size=2)`
`ll = log_loss(test_y, p)`

The generated output then is:
 `2/127 [..............................] - ETA: 30s - loss: 0.0097`
`66/127 [==============>...............] - ETA: 0s - loss: 2.4860`
`127/127 [==============================] - 1s 5ms/step - loss: 1.8052 - val_loss: 0.9724`
`# training | log loss: 0.98358043, AUC: 69.53%, accuracy: 0.00%`
`# testing  | log loss: 0.97241303, AUC: 73.33%, accuracy: 0.00%`

Any ideas on why the testing/validation loss are equal, but test loss isn't?",ceroxlol,b'type:bug/performance',2019-02-14T17:17:41Z,2019-02-15T20:25:49Z
12273,`y_true` is changed during training when passed to custom metric,"### **Edit**: The problem was just that Keras is printing a moving average of whatever the metric returns. I checked the true labels in the right way. You can notice that the formula: 
![image](https://user-images.githubusercontent.com/23250250/53177830-b51ac680-35be-11e9-8662-936483e74e22.png)
### is applied to each value returned. x_n is the current value and A_n is the average of n values.


While working on a semantic segmentation task, I needed to implement a custom metric instead of using accuracy. I noticed that the values are weird, so I decided to just print the maximum of my y_true tensor.  My assumption is that `y_true ` only contains the labels values.

**Information**: 
- Keras version 2.2.4 with Tensorflow backend ( v 1.12.0)
- I have a mask (which is my target/y_true) of shape (batchSize, imgHeight, imgWidth, imgRegions) = (1,512,512,2) which only contains values 0 or 1 (I already check that my mask doesn't have wrong values)
- Softmax is used, currently I have two classes (background and object of interest).

**For debugging:**
- No Data Augmentation was Used
- I used batch size of 1
- No class weighting 
- I use as my metric:
`def TP(y_true, y_pred):`
` return K.max(y_true[:,:,:,1]) + K.max(y_true[:,:,:,0])`
- In the training_generator.py file in Keras, line 154. I print the max value of the mask when it is fetched from the generator:
`if len(generator_output) == 2:`
`x, y = generator_output`
`import numpy as np`
`print(' Deb ', np.max(y[:,:,:,0]) + np.max(y[:,:,:,1]))`
`sample_weight = None`
The value is always correct (i.e the value is a whole number).
- I also tried summing the `y_pred ` tensor. It gives me a sum that equals 512*512 + eps (very small error) as expected.
- I use a simple model:
![image](https://user-images.githubusercontent.com/23250250/52798148-5779fd80-3045-11e9-9a68-d00328db9c01.png)
- My training function:
![image](https://user-images.githubusercontent.com/23250250/52798233-8001f780-3045-11e9-9a09-7c77e45b92a6.png)

Here are the results of my training:
![image](https://user-images.githubusercontent.com/23250250/52798800-a5dbcc00-3046-11e9-9524-f38b7c530cb9.png)

Did I miss something on the way I use keras for this task?

",nHeidelberg,b'To investigate',2019-02-14T16:13:24Z,2020-05-28T10:03:39Z
12263,Saved model starts with initital loss and accuracy values after loading,"I am building a model for machine comprehension. It's a heavy model required to train on lots of data and this requires me more time. I have used keras callbacks to save model after every epoch and also save a history of loss and accuracy.

The problem is, when I am loading a trained model, and try to continue it's training using `initial_epoch` argument, the loss and accuracy values are same as untrained model.

Here is the code: https://github.com/ParikhKadam/bidaf-keras
The code used to save and load model is in /models/bidaf.py
The script I am using to load the model is:
```

from .models import BidirectionalAttentionFlow
from .scripts.data_generator import load_data_generators
import os
import numpy as np


def main():
    emdim = 400
    bidaf = BidirectionalAttentionFlow(emdim=emdim, num_highway_layers=2,
                                       num_decoders=1, encoder_dropout=0.4, decoder_dropout=0.6)
    bidaf.load_bidaf(os.path.join(os.path.dirname(__file__), 'saved_items', 'bidaf_29.h5')) 
    train_generator, validation_generator = load_data_generators(batch_size=16, emdim=emdim, shuffle=True)
    model = bidaf.train_model(train_generator, epochs=50, validation_generator=validation_generator, initial_epoch=29, 
                              save_history=False, save_model_per_epoch=False)


if __name__ == '__main__':
    main()

```

The training history is quite good which is:

```
epoch,accuracy,loss,val_accuracy,val_loss
0,0.5021367247352657,5.479433422293752,0.502228641179383,5.451400522458351
1,0.5028450897193741,5.234336488338403,0.5037527732234647,5.0748545675049
2,0.5036885394022954,5.042028017280698,0.5039489093881276,5.0298488218407975
3,0.503893446146289,4.996997425685413,0.5040753162241299,4.976164487656699
4,0.5040576918224873,4.955544574118662,0.5041905890181151,4.931354981493792
5,0.5042372655790888,4.909940965651957,0.5043896965802341,4.881359395178988
6,0.504458428129642,4.8542871887472465,0.5045972716586732,4.815464454729135
7,0.50471843351102,4.791098495962496,0.5048680457262408,4.747811231472629
8,0.5050776754196002,4.713560494026321,0.5054184527602898,4.64730478015052
9,0.5058853749443502,4.580552254050073,0.5071290369370443,4.446513280167718
10,0.5081544614246304,4.341471499420364,0.5132941329030303,4.145318906086552
11,0.5123970410575613,4.081624463197288,0.5178775145611896,4.027316586998608
12,0.5149879128865782,3.9577423109634613,0.5187159608315838,3.950151870168726
13,0.5161411008840144,3.8964761709052578,0.5191430166876064,3.906301355196609
14,0.5168211272672539,3.8585826589385697,0.5191263493850466,3.865382308412537
15,0.5173216891201444,3.830764191839807,0.519219763635108,3.8341492204942607
16,0.5177805591697787,3.805340048675155,0.5197178382215892,3.8204319018292585
17,0.5181171635676399,3.7877712072310343,0.5193657963810704,3.798006804522368
18,0.5184295824699279,3.77086071548255,0.5193122694008523,3.7820449101377243
19,0.5187343664397653,3.7555085003534194,0.5203585262348183,3.776260506494833
20,0.519005008308583,3.7430062334375065,0.5195983755362352,3.7605361109533995
21,0.5192872482429703,3.731001830462149,0.5202017035842986,3.7515058917231405
22,0.5195097722222706,3.7194103983513553,0.5207148585133065,3.7446572377159795
23,0.5197511249107636,3.7101052441559905,0.5207420740297026,3.740088335181619
24,0.5199862479678652,3.701593302911729,0.5200187951731082,3.7254406861185188
25,0.5200847805044403,3.6944093077914464,0.520112738649039,3.7203616696860786
26,0.5203289568582412,3.6844954882274092,0.5217114634669081,3.7214983577364547
27,0.5205629846610852,3.6781935968943595,0.520915311442328,3.705435317731209
28,0.5206827641463226,3.6718110897539193,0.5214088439286978,3.7003081666703377

```

Also, I have already taken care of loading custom objects such as layers, loss function and accuracy.

I am kind of frustrated by now as I took me  days to train this model upto epochs and now I can't resume training. I have referred various threads in keras issues and found many people are facing such issues but can't find a solution.

Someone in a thread said that ""Keras will not save RNN states"" (I ain't using stateful RNNs) and someone else said ""Keras reinitializes all the weights before saving which we can handle using a flag."" I mean, if such problems exist in Keras, what will be the use of functions like save().

I have also tried saving only weights after every epoch and then building model from scratch and then loading those weights into it. But that didn't work. You can find the old code I used to save weights only in the above listed github repo's older branches.

I have referred this issue with no help - https://github.com/keras-team/keras/issues/4875

That issue is open from past two years. Can't understand what all the developers are doing! Is anyone here who can help? Should I switch to tensorflow or I will face the same issues in that too?

Please help...",ParikhKadam,b'To investigate type:bug/performance',2019-02-13T09:00:56Z,2020-08-10T05:54:02Z
12257,Total parameter shown in summary does not correlate with the number of layer in my model..I don't know if is the bug in Keras or it my model problem,"This is the Model summary

Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 8, 1200, 1 0                                            
__________________________________________________________________________________________________
input_2 (InputLayer)            (None, 1, 8, 1200, 1 0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 1, 8, 1200, 1 0                                            
__________________________________________________________________________________________________
input_4 (InputLayer)            (None, 1, 8, 1200, 1 0                                            
__________________________________________________________________________________________________
input_5 (InputLayer)            (None, 1, 8, 1200, 1 0                                            
__________________________________________________________________________________________________
input_6 (InputLayer)            (None, 1, 8, 1200, 1 0                                            
__________________________________________________________________________________________________
input_7 (InputLayer)            (None, 1, 8, 1200, 1 0                                            
__________________________________________________________________________________________________
input_8 (InputLayer)            (None, 1, 8, 1200, 1 0                                            
__________________________________________________________________________________________________
input_9 (InputLayer)            (None, 1, 8, 1200, 1 0                                            
__________________________________________________________________________________________________
input_10 (InputLayer)           (None, 1, 8, 1200, 1 0                                            
__________________________________________________________________________________________________
average_pooling3d_1 (AveragePoo (None, 1, 8, 240, 24 0           input_1[0][0]                    
__________________________________________________________________________________________________
average_pooling3d_4 (AveragePoo (None, 1, 8, 240, 24 0           input_2[0][0]                    
__________________________________________________________________________________________________
average_pooling3d_7 (AveragePoo (None, 1, 8, 240, 24 0           input_3[0][0]                    
__________________________________________________________________________________________________
average_pooling3d_10 (AveragePo (None, 1, 8, 240, 24 0           input_4[0][0]                    
__________________________________________________________________________________________________
average_pooling3d_13 (AveragePo (None, 1, 8, 240, 24 0           input_5[0][0]                    
__________________________________________________________________________________________________
average_pooling3d_16 (AveragePo (None, 1, 8, 240, 24 0           input_6[0][0]                    
__________________________________________________________________________________________________
average_pooling3d_19 (AveragePo (None, 1, 8, 240, 24 0           input_7[0][0]                    
__________________________________________________________________________________________________
average_pooling3d_22 (AveragePo (None, 1, 8, 240, 24 0           input_8[0][0]                    
__________________________________________________________________________________________________
average_pooling3d_25 (AveragePo (None, 1, 8, 240, 24 0           input_9[0][0]                    
__________________________________________________________________________________________________
average_pooling3d_28 (AveragePo (None, 1, 8, 240, 24 0           input_10[0][0]                   
__________________________________________________________________________________________________
reshape_1 (Reshape)             (None, 8, 1, 240, 24 0           average_pooling3d_1[0][0]        
__________________________________________________________________________________________________
reshape_4 (Reshape)             (None, 8, 1, 240, 24 0           average_pooling3d_4[0][0]        
__________________________________________________________________________________________________
reshape_7 (Reshape)             (None, 8, 1, 240, 24 0           average_pooling3d_7[0][0]        
__________________________________________________________________________________________________
reshape_10 (Reshape)            (None, 8, 1, 240, 24 0           average_pooling3d_10[0][0]       
__________________________________________________________________________________________________
reshape_13 (Reshape)            (None, 8, 1, 240, 24 0           average_pooling3d_13[0][0]       
__________________________________________________________________________________________________
reshape_16 (Reshape)            (None, 8, 1, 240, 24 0           average_pooling3d_16[0][0]       
__________________________________________________________________________________________________
reshape_19 (Reshape)            (None, 8, 1, 240, 24 0           average_pooling3d_19[0][0]       
__________________________________________________________________________________________________
reshape_22 (Reshape)            (None, 8, 1, 240, 24 0           average_pooling3d_22[0][0]       
__________________________________________________________________________________________________
reshape_25 (Reshape)            (None, 8, 1, 240, 24 0           average_pooling3d_25[0][0]       
__________________________________________________________________________________________________
reshape_28 (Reshape)            (None, 8, 1, 240, 24 0           average_pooling3d_28[0][0]       
__________________________________________________________________________________________________
conv_lst_m2d_1 (ConvLSTM2D)     (None, 8, 16, 240, 2 9856        reshape_1[0][0]                  
__________________________________________________________________________________________________
conv_lst_m2d_3 (ConvLSTM2D)     (None, 8, 16, 240, 2 9856        reshape_4[0][0]                  
__________________________________________________________________________________________________
conv_lst_m2d_5 (ConvLSTM2D)     (None, 8, 16, 240, 2 9856        reshape_7[0][0]                  
__________________________________________________________________________________________________
conv_lst_m2d_7 (ConvLSTM2D)     (None, 8, 16, 240, 2 9856        reshape_10[0][0]                 
__________________________________________________________________________________________________
conv_lst_m2d_9 (ConvLSTM2D)     (None, 8, 16, 240, 2 9856        reshape_13[0][0]                 
__________________________________________________________________________________________________
conv_lst_m2d_11 (ConvLSTM2D)    (None, 8, 16, 240, 2 9856        reshape_16[0][0]                 
__________________________________________________________________________________________________
conv_lst_m2d_13 (ConvLSTM2D)    (None, 8, 16, 240, 2 9856        reshape_19[0][0]                 
__________________________________________________________________________________________________
conv_lst_m2d_15 (ConvLSTM2D)    (None, 8, 16, 240, 2 9856        reshape_22[0][0]                 
__________________________________________________________________________________________________
conv_lst_m2d_17 (ConvLSTM2D)    (None, 8, 16, 240, 2 9856        reshape_25[0][0]                 
__________________________________________________________________________________________________
conv_lst_m2d_19 (ConvLSTM2D)    (None, 8, 16, 240, 2 9856        reshape_28[0][0]                 
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 8, 16, 240, 2 960         conv_lst_m2d_1[0][0]             
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 8, 16, 240, 2 960         conv_lst_m2d_3[0][0]             
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 8, 16, 240, 2 960         conv_lst_m2d_5[0][0]             
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 8, 16, 240, 2 960         conv_lst_m2d_7[0][0]             
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 8, 16, 240, 2 960         conv_lst_m2d_9[0][0]             
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 8, 16, 240, 2 960         conv_lst_m2d_11[0][0]            
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 8, 16, 240, 2 960         conv_lst_m2d_13[0][0]            
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 8, 16, 240, 2 960         conv_lst_m2d_15[0][0]            
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 8, 16, 240, 2 960         conv_lst_m2d_17[0][0]            
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 8, 16, 240, 2 960         conv_lst_m2d_19[0][0]            
__________________________________________________________________________________________________
conv_lst_m2d_2 (ConvLSTM2D)     (None, 8, 16, 240, 2 18496       batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv_lst_m2d_4 (ConvLSTM2D)     (None, 8, 16, 240, 2 18496       batch_normalization_2[0][0]      
__________________________________________________________________________________________________
conv_lst_m2d_6 (ConvLSTM2D)     (None, 8, 16, 240, 2 18496       batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv_lst_m2d_8 (ConvLSTM2D)     (None, 8, 16, 240, 2 18496       batch_normalization_4[0][0]      
__________________________________________________________________________________________________
conv_lst_m2d_10 (ConvLSTM2D)    (None, 8, 16, 240, 2 18496       batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv_lst_m2d_12 (ConvLSTM2D)    (None, 8, 16, 240, 2 18496       batch_normalization_6[0][0]      
__________________________________________________________________________________________________
conv_lst_m2d_14 (ConvLSTM2D)    (None, 8, 16, 240, 2 18496       batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv_lst_m2d_16 (ConvLSTM2D)    (None, 8, 16, 240, 2 18496       batch_normalization_8[0][0]      
__________________________________________________________________________________________________
conv_lst_m2d_18 (ConvLSTM2D)    (None, 8, 16, 240, 2 18496       batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv_lst_m2d_20 (ConvLSTM2D)    (None, 8, 16, 240, 2 18496       batch_normalization_10[0][0]     
__________________________________________________________________________________________________
reshape_2 (Reshape)             (None, 16, 8, 240, 2 0           conv_lst_m2d_2[0][0]             
__________________________________________________________________________________________________
reshape_5 (Reshape)             (None, 16, 8, 240, 2 0           conv_lst_m2d_4[0][0]             
__________________________________________________________________________________________________
reshape_8 (Reshape)             (None, 16, 8, 240, 2 0           conv_lst_m2d_6[0][0]             
__________________________________________________________________________________________________
reshape_11 (Reshape)            (None, 16, 8, 240, 2 0           conv_lst_m2d_8[0][0]             
__________________________________________________________________________________________________
reshape_14 (Reshape)            (None, 16, 8, 240, 2 0           conv_lst_m2d_10[0][0]            
__________________________________________________________________________________________________
reshape_17 (Reshape)            (None, 16, 8, 240, 2 0           conv_lst_m2d_12[0][0]            
__________________________________________________________________________________________________
reshape_20 (Reshape)            (None, 16, 8, 240, 2 0           conv_lst_m2d_14[0][0]            
__________________________________________________________________________________________________
reshape_23 (Reshape)            (None, 16, 8, 240, 2 0           conv_lst_m2d_16[0][0]            
__________________________________________________________________________________________________
reshape_26 (Reshape)            (None, 16, 8, 240, 2 0           conv_lst_m2d_18[0][0]            
__________________________________________________________________________________________________
reshape_29 (Reshape)            (None, 16, 8, 240, 2 0           conv_lst_m2d_20[0][0]            
__________________________________________________________________________________________________
average_pooling3d_2 (AveragePoo (None, 16, 8, 80, 80 0           reshape_2[0][0]                  
__________________________________________________________________________________________________
average_pooling3d_5 (AveragePoo (None, 16, 8, 80, 80 0           reshape_5[0][0]                  
__________________________________________________________________________________________________
average_pooling3d_8 (AveragePoo (None, 16, 8, 80, 80 0           reshape_8[0][0]                  
__________________________________________________________________________________________________
average_pooling3d_11 (AveragePo (None, 16, 8, 80, 80 0           reshape_11[0][0]                 
__________________________________________________________________________________________________
average_pooling3d_14 (AveragePo (None, 16, 8, 80, 80 0           reshape_14[0][0]                 
__________________________________________________________________________________________________
average_pooling3d_17 (AveragePo (None, 16, 8, 80, 80 0           reshape_17[0][0]                 
__________________________________________________________________________________________________
average_pooling3d_20 (AveragePo (None, 16, 8, 80, 80 0           reshape_20[0][0]                 
__________________________________________________________________________________________________
average_pooling3d_23 (AveragePo (None, 16, 8, 80, 80 0           reshape_23[0][0]                 
__________________________________________________________________________________________________
average_pooling3d_26 (AveragePo (None, 16, 8, 80, 80 0           reshape_26[0][0]                 
__________________________________________________________________________________________________
average_pooling3d_29 (AveragePo (None, 16, 8, 80, 80 0           reshape_29[0][0]                 
__________________________________________________________________________________________________
average_pooling3d_3 (AveragePoo (None, 16, 8, 8, 8)  0           average_pooling3d_2[0][0]        
__________________________________________________________________________________________________
average_pooling3d_6 (AveragePoo (None, 16, 8, 8, 8)  0           average_pooling3d_5[0][0]        
__________________________________________________________________________________________________
average_pooling3d_9 (AveragePoo (None, 16, 8, 8, 8)  0           average_pooling3d_8[0][0]        
__________________________________________________________________________________________________
average_pooling3d_12 (AveragePo (None, 16, 8, 8, 8)  0           average_pooling3d_11[0][0]       
__________________________________________________________________________________________________
average_pooling3d_15 (AveragePo (None, 16, 8, 8, 8)  0           average_pooling3d_14[0][0]       
__________________________________________________________________________________________________
average_pooling3d_18 (AveragePo (None, 16, 8, 8, 8)  0           average_pooling3d_17[0][0]       
__________________________________________________________________________________________________
average_pooling3d_21 (AveragePo (None, 16, 8, 8, 8)  0           average_pooling3d_20[0][0]       
__________________________________________________________________________________________________
average_pooling3d_24 (AveragePo (None, 16, 8, 8, 8)  0           average_pooling3d_23[0][0]       
__________________________________________________________________________________________________
average_pooling3d_27 (AveragePo (None, 16, 8, 8, 8)  0           average_pooling3d_26[0][0]       
__________________________________________________________________________________________________
average_pooling3d_30 (AveragePo (None, 16, 8, 8, 8)  0           average_pooling3d_29[0][0]       
__________________________________________________________________________________________________
reshape_3 (Reshape)             (None, 8, 16, 8, 8)  0           average_pooling3d_3[0][0]        
__________________________________________________________________________________________________
reshape_6 (Reshape)             (None, 8, 16, 8, 8)  0           average_pooling3d_6[0][0]        
__________________________________________________________________________________________________
reshape_9 (Reshape)             (None, 8, 16, 8, 8)  0           average_pooling3d_9[0][0]        
__________________________________________________________________________________________________
reshape_12 (Reshape)            (None, 8, 16, 8, 8)  0           average_pooling3d_12[0][0]       
__________________________________________________________________________________________________
reshape_15 (Reshape)            (None, 8, 16, 8, 8)  0           average_pooling3d_15[0][0]       
__________________________________________________________________________________________________
reshape_18 (Reshape)            (None, 8, 16, 8, 8)  0           average_pooling3d_18[0][0]       
__________________________________________________________________________________________________
reshape_21 (Reshape)            (None, 8, 16, 8, 8)  0           average_pooling3d_21[0][0]       
__________________________________________________________________________________________________
reshape_24 (Reshape)            (None, 8, 16, 8, 8)  0           average_pooling3d_24[0][0]       
__________________________________________________________________________________________________
reshape_27 (Reshape)            (None, 8, 16, 8, 8)  0           average_pooling3d_27[0][0]       
__________________________________________________________________________________________________
reshape_30 (Reshape)            (None, 8, 16, 8, 8)  0           average_pooling3d_30[0][0]       
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 8, 16, 8, 80) 0           reshape_3[0][0]                  
                                                                 reshape_6[0][0]                  
                                                                 reshape_9[0][0]                  
                                                                 reshape_12[0][0]                 
                                                                 reshape_15[0][0]                 
                                                                 reshape_18[0][0]                 
                                                                 reshape_21[0][0]                 
                                                                 reshape_24[0][0]                 
                                                                 reshape_27[0][0]                 
                                                                 reshape_30[0][0]                 
__________________________________________________________________________________________________
reshape_31 (Reshape)            (None, 8, 10240)     0           concatenate_1[0][0]              
__________________________________________________________________________________________________
time_distributed_1 (TimeDistrib (None, 8, 8)         81928       reshape_31[0][0]                 
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 8, 8)         0           time_distributed_1[0][0]         
__________________________________________________________________________________________________
time_distributed_2 (TimeDistrib (None, 8, 8)         72          dropout_1[0][0]                  
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 8, 8)         0           time_distributed_2[0][0]         
__________________________________________________________________________________________________
time_distributed_3 (TimeDistrib (None, 8, 2)         18          dropout_2[0][0]                  
==================================================================================================
Total params: 375,138
Trainable params: 370,338
Non-trainable params: 4,800
__________________________________________________________________________________________________


Thank you!
",kaiche12,b'type:support',2019-02-12T14:27:18Z,2019-02-14T09:49:57Z
12205,Fix clone_model,"### Summary

Try to fix a bug inside `keras.models._clone_functional_model`, which can cause an error when clone a model containing a layer with 2 or more outputs

I'm not sure whether or not the issue needs a new unit test.. In fact I faced it when I'm using `multi_gpu_model` as mentioned in my earlier issue，so maybe it's a better idea to do some more test on 
`multi_gpu_model` instead (but I have no idea about that...)

### Related Issues

https://github.com/keras-team/keras/issues/12202

### PR Overview

- [y] This PR requires new unit tests [y/n] (make sure tests are included)
- [n] This PR requires to update the documentation [y/n] (make sure the docs are up-to-date)
- [y] This PR is backwards compatible [y/n]
- [n] This PR changes the current API [y/n] (all API changes need to be approved by fchollet)
",Mistariano,None,2019-02-05T03:16:18Z,2019-02-15T23:58:45Z
12202,'Could not compute output Tensor' error when I‘m using clone_model(),"Hi guys, I think I just met a bug. 
There was something wrong when I was using `multi_gpu_model` with `cpu_relocation=True`. After analyzing the traceback I think it is a bug inside `keras.models.clone_model`
The script below can reproduce it

```python
from keras.models import Model, clone_model
from keras.layers import Input, Add, Lambda
from keras.utils import multi_gpu_model


def build_model():
    input_layer = Input(shape=(1,))
    test1, test2 = Lambda(lambda x: [x, x])(input_layer)
    add = Add()([test1, test2])
    model = Model(inputs=[input_layer], outputs=[add])
    return model


if __name__ == '__main__':
    model = build_model()
    model = clone_model(model)
    # model = multi_gpu_model(model, cpu_relocation=True)  # it uses clone_model when set cpu_relocation=True
```
If I didn't make any mistake, the script will raise `AssertionError: Could not compute output Tensor(""add_1/add:0"", shape=(?, 1), dtype=float32)`

My environment:

- Keras 2.2.4
- tensorflow 1.12.0

I met the error on both 4 GTX1080tis and my own laptop with a GTX1060MQ

------

I noticed that `output_masks` here will always be `[None]`(but `[None, None]` is expected)
https://github.com/keras-team/keras/blob/a1397169ddf8595736c01fcea084c8e34e1a3884/keras/models.py#L157

and that's because `layer.compute_mask(...)` will always return `None` since `Lambda` doesn't support using masks
https://github.com/keras-team/keras/blob/a1397169ddf8595736c01fcea084c8e34e1a3884/keras/models.py#L153

So if I'm using a functional model with a layer which has more outputs without a mask support, I think the error can appear.

------

P.S. thanks a lot for your brilliant works :)  
From my perspective, Keras is an amazing gift to everyone. Thank you all!


",Mistariano,b'backend:tensorflow type:bug/performance',2019-02-04T16:52:31Z,2019-02-26T08:06:36Z
12196,I get wrong prediction on face recognition using Keras,"I downloaded Keras weight VGG16 (vgg16_weights_tf_dim_ordering_tf_kernels.h5) from here: https://github.com/fchollet/deep-learning-models/releases/

The training is working, using this code:
**VGG16.py**
```
from keras.models import Sequential
from keras.layers.core import Flatten, Dense, Dropout
from keras.layers.convolutional import Conv2D, MaxPooling2D, ZeroPadding2D
from keras.optimizers import SGD
import cv2, numpy as np

def VGG16_Model():
    model = Sequential()
    model.add(ZeroPadding2D((1,1),input_shape=(224,224,3)))
    model.add(Conv2D(64, (3, 3), activation='relu'))
    model.add(ZeroPadding2D((1,1)))
    model.add(Conv2D(64, (3, 3), activation='relu'))
    model.add(MaxPooling2D((2,2), strides=(2,2)))

    model.add(ZeroPadding2D((1,1)))
    model.add(Conv2D(128, (3, 3), activation='relu'))
    model.add(ZeroPadding2D((1,1)))
    model.add(Conv2D(128, (3, 3), activation='relu'))
    model.add(MaxPooling2D((2,2), strides=(2,2)))

    model.add(ZeroPadding2D((1,1)))
    model.add(Conv2D(256, (3, 3), activation='relu'))
    model.add(ZeroPadding2D((1,1)))
    model.add(Conv2D(256, (3, 3), activation='relu'))
    model.add(ZeroPadding2D((1,1)))
    model.add(Conv2D(256, (3, 3), activation='relu'))
    model.add(MaxPooling2D((2,2), strides=(2,2)))

    model.add(ZeroPadding2D((1,1)))
    model.add(Conv2D(512, (3, 3), activation='relu'))
    model.add(ZeroPadding2D((1,1)))
    model.add(Conv2D(512, (3, 3), activation='relu'))
    model.add(ZeroPadding2D((1,1)))
    model.add(Conv2D(512, (3, 3), activation='relu'))
    model.add(MaxPooling2D((2,2), strides=(2,2)))

    model.add(ZeroPadding2D((1,1)))
    model.add(Conv2D(512, (3, 3), activation='relu'))
    model.add(ZeroPadding2D((1,1)))
    model.add(Conv2D(512, (3, 3), activation='relu'))
    model.add(ZeroPadding2D((1,1)))
    model.add(Conv2D(512, (3, 3), activation='relu'))
    model.add(MaxPooling2D((2,2), strides=(2,2)))

    model.add(Flatten())
    model.add(Dense(4096, activation='relu'))
    model.add(Dropout(0.5))
    model.add(Dense(4096, activation='relu'))
    model.add(Dropout(0.5))
    model.add(Dense(1000, activation='softmax'))

    model.load_weights('C:/Users/w024029h/PycharmProjects/keras_pretrained/vgg16_weights_tf_dim_ordering_tf_kernels.h5')

    return model
```

**vgg16_keras_finetuning.py**
```
from pathlib import Path
from keras.models import Sequential
from keras.layers.core import Dense
from keras.optimizers import Adam
from keras.preprocessing.image import ImageDataGenerator

import VGG16

# image_prep
train_path = Path(""database"") / ""train""
test_path = Path(""database"") / ""test""
validation_path = Path(""database"") / ""validation""
class_list = ['P1','P2','P3','P4','P5','P6','P7','P8','P9','P10']

train_batches = ImageDataGenerator().flow_from_directory(train_path, target_size=(224,224), classes=class_list, batch_size=12, class_mode=""categorical"")
validation_batches = ImageDataGenerator().flow_from_directory(validation_path, target_size=(224,224), classes=class_list, batch_size=4, class_mode=""categorical"")

# Fine tune VGG16
# ====================================================================================================
vgg16_model = VGG16.VGG16_Model()
# vgg16_model.summary()

# print(type(vgg16_model))

model = Sequential()
for layer in vgg16_model.layers[:-1]:
    model.add(layer)

# model.summary()

# # add 12 Dense Layer
model.add(Dense(10, activation='softmax', name='predictions'))
model.summary()

# compile fine-tuning vgg16
model.compile(optimizer=Adam(lr=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])
history = model.fit_generator(train_batches, steps_per_epoch=10,
                    validation_data=validation_batches, validation_steps=10, epochs=5, verbose=1)

# save model weight
model.save('vgg16_finetuning.h5')

# summarize history for accuracy
import matplotlib.pyplot as plt
plt.plot(history.history['acc'])
plt.plot(history.history['val_acc'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()
# summarize history for loss
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()
```
**Training Result**

```
Found 42 images belonging to 10 classes.
Found 23 images belonging to 10 classes.
Found 31 images belonging to 10 classes.
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
zero_padding2d_1 (ZeroPaddin (None, 226, 226, 3)       0
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 224, 224, 64)      1792
_________________________________________________________________
zero_padding2d_2 (ZeroPaddin (None, 226, 226, 64)      0
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 224, 224, 64)      36928
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 112, 112, 64)      0
_________________________________________________________________
zero_padding2d_3 (ZeroPaddin (None, 114, 114, 64)      0
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 112, 112, 128)     73856
_________________________________________________________________
zero_padding2d_4 (ZeroPaddin (None, 114, 114, 128)     0
_________________________________________________________________
conv2d_4 (Conv2D)            (None, 112, 112, 128)     147584
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 56, 56, 128)       0
_________________________________________________________________
zero_padding2d_5 (ZeroPaddin (None, 58, 58, 128)       0
_________________________________________________________________
conv2d_5 (Conv2D)            (None, 56, 56, 256)       295168
_________________________________________________________________
zero_padding2d_6 (ZeroPaddin (None, 58, 58, 256)       0
_________________________________________________________________
conv2d_6 (Conv2D)            (None, 56, 56, 256)       590080
_________________________________________________________________
zero_padding2d_7 (ZeroPaddin (None, 58, 58, 256)       0
_________________________________________________________________
conv2d_7 (Conv2D)            (None, 56, 56, 256)       590080
_________________________________________________________________
max_pooling2d_3 (MaxPooling2 (None, 28, 28, 256)       0
_________________________________________________________________
zero_padding2d_8 (ZeroPaddin (None, 30, 30, 256)       0
_________________________________________________________________
conv2d_8 (Conv2D)            (None, 28, 28, 512)       1180160
_________________________________________________________________
zero_padding2d_9 (ZeroPaddin (None, 30, 30, 512)       0
_________________________________________________________________
conv2d_9 (Conv2D)            (None, 28, 28, 512)       2359808
_________________________________________________________________
zero_padding2d_10 (ZeroPaddi (None, 30, 30, 512)       0
_________________________________________________________________
conv2d_10 (Conv2D)           (None, 28, 28, 512)       2359808
_________________________________________________________________
max_pooling2d_4 (MaxPooling2 (None, 14, 14, 512)       0
_________________________________________________________________
zero_padding2d_11 (ZeroPaddi (None, 16, 16, 512)       0
_________________________________________________________________
conv2d_11 (Conv2D)           (None, 14, 14, 512)       2359808
_________________________________________________________________
zero_padding2d_12 (ZeroPaddi (None, 16, 16, 512)       0
_________________________________________________________________
conv2d_12 (Conv2D)           (None, 14, 14, 512)       2359808
_________________________________________________________________
zero_padding2d_13 (ZeroPaddi (None, 16, 16, 512)       0
_________________________________________________________________
conv2d_13 (Conv2D)           (None, 14, 14, 512)       2359808
_________________________________________________________________
max_pooling2d_5 (MaxPooling2 (None, 7, 7, 512)         0
_________________________________________________________________
flatten_1 (Flatten)          (None, 25088)             0
_________________________________________________________________
dense_1 (Dense)              (None, 4096)              102764544
_________________________________________________________________
dropout_1 (Dropout)          (None, 4096)              0
_________________________________________________________________
dense_2 (Dense)              (None, 4096)              16781312
_________________________________________________________________
dropout_2 (Dropout)          (None, 4096)              0
_________________________________________________________________
predictions (Dense)          (None, 10)                40970
=================================================================
Total params: 134,301,514
Trainable params: 134,301,514
Non-trainable params: 0
_________________________________________________________________
Epoch 1/5

 1/10 [==>...........................] - ETA: 1:11 - loss: 4.1517 - acc: 0.1667
 2/10 [=====>........................] - ETA: 1:10 - loss: 3.7662 - acc: 0.1667
 3/10 [========>.....................] - ETA: 1:02 - loss: 3.6699 - acc: 0.1944
 4/10 [===========>..................] - ETA: 53s - loss: 3.4681 - acc: 0.1875
 5/10 [==============>...............] - ETA: 45s - loss: 3.2101 - acc: 0.2167
 6/10 [=================>............] - ETA: 36s - loss: 3.1064 - acc: 0.1944
 7/10 [====================>.........] - ETA: 27s - loss: 2.8932 - acc: 0.2262
 8/10 [=======================>......] - ETA: 17s - loss: 2.7874 - acc: 0.2396
 9/10 [==========================>...] - ETA: 8s - loss: 2.7347 - acc: 0.2407
10/10 [==============================] - 95s 10s/step - loss: 2.6706 - acc: 0.2496 - val_loss: 2.7206 - val_acc: 0.2821
Epoch 2/5

 1/10 [==>...........................] - ETA: 1:26 - loss: 2.7270 - acc: 0.2500
 2/10 [=====>........................] - ETA: 1:16 - loss: 2.7057 - acc: 0.2500
 3/10 [========>.....................] - ETA: 1:06 - loss: 2.2910 - acc: 0.3056
 4/10 [===========>..................] - ETA: 50s - loss: 2.1614 - acc: 0.3125
 5/10 [==============>...............] - ETA: 43s - loss: 2.1302 - acc: 0.3000
 6/10 [=================>............] - ETA: 35s - loss: 2.0387 - acc: 0.3333
 7/10 [====================>.........] - ETA: 25s - loss: 1.9969 - acc: 0.3571
 8/10 [=======================>......] - ETA: 17s - loss: 1.9431 - acc: 0.3750
 9/10 [==========================>...] - ETA: 8s - loss: 1.8929 - acc: 0.3611
10/10 [==============================] - 98s 10s/step - loss: 1.8601 - acc: 0.3662 - val_loss: 1.0251 - val_acc: 0.7105
Epoch 3/5

 1/10 [==>...........................] - ETA: 48s - loss: 0.8584 - acc: 0.6667
 2/10 [=====>........................] - ETA: 1:00 - loss: 0.9798 - acc: 0.6250
 3/10 [========>.....................] - ETA: 57s - loss: 1.0065 - acc: 0.6111
 4/10 [===========>..................] - ETA: 51s - loss: 0.9981 - acc: 0.6042
 5/10 [==============>...............] - ETA: 43s - loss: 0.8804 - acc: 0.6667
 6/10 [=================>............] - ETA: 32s - loss: 0.8887 - acc: 0.6944
 7/10 [====================>.........] - ETA: 25s - loss: 0.8915 - acc: 0.7024
 8/10 [=======================>......] - ETA: 17s - loss: 0.8466 - acc: 0.7187
 9/10 [==========================>...] - ETA: 8s - loss: 0.7842 - acc: 0.7407
10/10 [==============================] - 97s 10s/step - loss: 0.7643 - acc: 0.7500 - val_loss: 0.4308 - val_acc: 0.8684
Epoch 4/5

 1/10 [==>...........................] - ETA: 48s - loss: 0.4381 - acc: 0.8333
 2/10 [=====>........................] - ETA: 59s - loss: 0.3394 - acc: 0.8750
 3/10 [========>.....................] - ETA: 47s - loss: 0.2472 - acc: 0.9167
 4/10 [===========>..................] - ETA: 45s - loss: 0.1970 - acc: 0.9375
 5/10 [==============>...............] - ETA: 39s - loss: 0.2454 - acc: 0.9333
 6/10 [=================>............] - ETA: 32s - loss: 0.2432 - acc: 0.9306
 7/10 [====================>.........] - ETA: 25s - loss: 0.2265 - acc: 0.9286
 8/10 [=======================>......] - ETA: 17s - loss: 0.2135 - acc: 0.9375
 9/10 [==========================>...] - ETA: 8s - loss: 0.1938 - acc: 0.9444
10/10 [==============================] - 94s 9s/step - loss: 0.1803 - acc: 0.9501 - val_loss: 0.0712 - val_acc: 0.9487
Epoch 5/5

 1/10 [==>...........................] - ETA: 1:26 - loss: 0.0243 - acc: 1.0000
 2/10 [=====>........................] - ETA: 1:00 - loss: 0.0434 - acc: 1.0000
 3/10 [========>.....................] - ETA: 57s - loss: 0.1203 - acc: 0.9444
 4/10 [===========>..................] - ETA: 51s - loss: 0.0990 - acc: 0.9583
 5/10 [==============>...............] - ETA: 43s - loss: 0.0846 - acc: 0.9667
 6/10 [=================>............] - ETA: 35s - loss: 0.1600 - acc: 0.9583
 7/10 [====================>.........] - ETA: 27s - loss: 0.1376 - acc: 0.9643
 8/10 [=======================>......] - ETA: 17s - loss: 0.1204 - acc: 0.9688
 9/10 [==========================>...] - ETA: 8s - loss: 0.1270 - acc: 0.9537
10/10 [==============================] - 94s 9s/step - loss: 0.1527 - acc: 0.9416 - val_loss: 0.1040 - val_acc: 0.9474
```

**similarity_calc.py**
```
from math import sqrt
from scipy import spatial

def findEuclideanDistance(source_representation, test_representation):
    calculate = sum(pow(a - b, 2) for a, b in zip(source_representation, test_representation))
    euclideanResult = sqrt(calculate)
    return euclideanResult

def findCosineDistance(source_representation, test_representation):
    result = 1 - spatial.distance.cosine(source_representation, test_representation)
    return result
```

On the image database I got 10 Images faces from P1 to P10, but 
When I tested with OpenCV i got wrong prediction anybody know what wrong with my code?
**run.py**
```
from flask import Flask, render_template, Response
import cv2
import numpy as np
from face_detector import vgg16, vgg16_keras_finetuning
from face_detector import detect_face, imgdb_extracts, similarity_calc

np.set_printoptions(threshold=np.nan)

# call vgg16 model
# model = vgg16.loadVggFaceModel_16()
model = vgg16_keras_finetuning.vgg16_finetuning()

# get face extraction from imgdb
imgdb_path = ""C:/Users/w024029h/PycharmProjects/flask_dlib/database""
people = imgdb_extracts.extract_by_path(imgdb_path, model)
print(""db image retrieved successfully"")

# test result of people dictionary
for person, val in people.items():
    print(person,' - val: ', np.array(val))

# Flask
app = Flask(__name__)
camera = cv2.VideoCapture(0)
# fps = camera.get(cv2.CAP_PROP_FPS)

@app.route('/')
def index():
    """"""Load template to index""""""
    return render_template('index.html')

def load():
    """"""Load Image from Camera""""""
    while True:
        success, frame = camera.read()

        # detect face locations
        face_locations, scores, face_type = detect_face.detect_locations(frame)
        total_face = detect_face.total_faces(face_locations)

        if total_face < 1:
            frame = cv2.imencode('.jpg', frame)[1].tobytes()
            yield (b'--frame\r\n'b'Content-Type: image/jpeg\r\n\r\n' + frame + b'\r\n')
            frame = cv2.imdecode(np.fromstring(frame, dtype=np.uint8), cv2.IMREAD_COLOR)

        else:
            for face_location in face_locations:
                top, left, bottom, right = face_location.top(), face_location.left(), face_location.bottom(), face_location.right()

                print('Camera found {} face(s)'.format(total_face))
                cv2.rectangle(frame, (left,top), (right,bottom), (0,255,0), 3) #green rectangle

                crop = frame[top:bottom, left:right]
                detected_face = cv2.resize(crop, (224, 224), interpolation = cv2.INTER_AREA)
                face2pixels = vgg16.preprocess_image(detected_face)
                captured_image = model.predict(face2pixels)[0, :]

                found = 0
                results = list()
                labels = list()
                for person in people:
                    img_representation = people[person]
                    labels.append(person)

                    euclidean_image = similarity_calc.findEuclideanDistance(img_representation, captured_image)
                    results.append(euclidean_image)
                    # cosine_image = similarity_calc.findCosineDistance(img_representation, captured_image)
                    # results.append(cosine_image)

                # print(labels)
                # print(results)

                # show result on terminal
                for name, value in zip(labels, results):
                    print(name,':',value)

                # add all result to file
                # with open(""result.txt"", ""a+"") as myfile:
                #     for idx, value in enumerate(results):
                #         myfile.write(str(value+'\n'))
                #         myfile.write(str(labels[idx]+'\n'))

                (val, idx) = min((v,i) for i,v in enumerate(results))
                # (val, idx) = max((v, i) for i, v in enumerate(results))

                # show prediction on terminal
                print('======================')
                print(labels[idx])
                print(val)
                print('======================')

                # save prediction to file
                with open(""result.txt"", ""a+"") as myfile:
                    myfile.write('======================\n')
                    myfile.write(str(labels[idx])+'\n')
                    myfile.write(str(val)+'\n')
                    myfile.write('======================\n')

                if val:
                    found = 1
                    person_name = labels[idx]
                    print('Detected', person_name)
                    font = cv2.FONT_HERSHEY_DUPLEX
                    cv2.putText(frame, person_name, (left + 6, bottom - 6), font, 1.0, (0, 0, 255), 2)

                    frame = cv2.imencode('.jpg', frame)[1].tobytes()
                    yield (b'--frame\r\n'b'Content-Type: image/jpeg\r\n\r\n' + frame + b'\r\n')
                    frame = cv2.imdecode(np.fromstring(frame, dtype=np.uint8),cv2.IMREAD_COLOR)
                else:
                    found = 0
                    person_name = 'Unknown'
                    print('Detected', person_name)
                    font = cv2.FONT_HERSHEY_DUPLEX
                    cv2.putText(frame, person_name, (left + 6, bottom - 6), font, 1.0, (0, 0, 255), 2)

                    frame = cv2.imencode('.jpg', frame)[1].tobytes()
                    yield (b'--frame\r\n'b'Content-Type: image/jpeg\r\n\r\n' + frame + b'\r\n')
                    frame = cv2.imdecode(np.fromstring(frame, dtype=np.uint8), cv2.IMREAD_COLOR)

@app.route('/video_feed')
def video_feed():
    # return Response(load(), mimetype='multipart/x-mixed-replace; boundary=frame')
    return Response(load(),  mimetype='multipart/x-mixed-replace; boundary=frame')

if __name__ == '__main__':
    app.debug = True
    app.threaded = True
    app.run(use_reloader=False)
```

When I scan P10 picture i got constant value of P8",sekti92,b'type:support',2019-02-03T18:01:21Z,2019-05-08T20:35:56Z
12195,ValueError: Unable to create group (Name already exists) with model.save_weights(),"This is a similar issue to https://github.com/keras-team/keras/issues/6005 but I believe it is caused by the way `h5py` defines groups. In particular, if a layer named `foo` is in a network after a layer named `foo/bar`, `h5py` throws an exception. But the same does not occur if `foo` comes first. To reproduce, see the snippet below.

```
from keras import layers, models

# This raises an exception.
input_layer = layers.Input((None, None, 3), name='test_input')
x = layers.Conv2D(1, 1, name='conv1/conv')(input_layer)
x = layers.BatchNormalization(name='conv1/bn')(x)
x = layers.Activation('relu', name='conv1')(x)
models.Model(inputs=input_layer, outputs=x).save_weights('test.h5')

# This doesn't raise an exception
input_layer = layers.Input((None, None, 3), name='test_input')
x = layers.Conv2D(1, 1, name='conv1')(input_layer)
x = layers.BatchNormalization(name='conv1/bn')(x)
x = layers.Activation('relu', name='conv1/relu')(x)
models.Model(inputs=input_layer, outputs=x).save_weights('test.h5')
```

Perhaps we could provide a more helpful error message in `keras/engine/saving.py`? For example, changing part of `save_weights_to_hdf5_group` to the following would help trace the offending layer name.

```
for layer in layers:
    try:
         g = group.create_group(layer.name)
    except ValueError:
         raise ValueError('An error occurred creating weights group for {0}.'.format(layer.name))
    symbolic_weights = layer.weights
    weight_values = K.batch_get_value(symbolic_weights)
```

Happy to create PR if this is helpful.",faustomorales,b'type:bug/performance',2019-02-03T18:01:19Z,2020-09-05T06:35:52Z
12189,Nadam optimizer arguments description missed schedule_decay,"
Both documentation https://keras.io/optimizers/ and the source code https://github.com/keras-team/keras/blob/master/keras/optimizers.py#L605 missed the description of an argument schedule_decay. Currently, it is:  
# Arguments
        lr: float >= 0. Learning rate.
        beta_1/beta_2: floats, 0 < beta < 1. Generally close to 1.
        epsilon: float >= 0. Fuzz factor. If `None`, defaults to `K.epsilon()`.
While actual list of parameters is: lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=None, schedule_decay=0.004
I propose to add a line like schedule_decay: float >= 0, determines ""what it actually does"". Could do it myself also.",slavikkom,b'stat:contributions welcome type:bug/performance',2019-02-01T14:26:48Z,2019-02-02T12:51:09Z
12188,TypeError: object of type 'ImageDataGenerator' has no len(),"Hi all!

I have an error when I am trying to use **ImageDataGenerator** with **flow_from_directory** function for transfer learning of NasNet model from **keras.applications**.

OS: ArchLinux
Tensorflow version: 1.12.0
Keras version: 2.2.4 (updated from master)
GPUs: GeForce GTX 1080 Ti
CUDA version: 9.0.176-4
CUDNN version: 7.0.5-2

My code:

```from keras.applications.nasnet import NASNetMobile
from keras.preprocessing.image import ImageDataGenerator
from keras.models import Model
from keras.layers import Dense, GlobalAveragePooling2D
from keras import backend as K
from keras.optimizers import SGD, Adam
from keras.callbacks import ModelCheckpoint

TRAIN_SAMPLES = 2081
TEST_SAMPLES = 904
BATCH_SIZE = 32

TRAIN_DATA_DIR = './train'
TEST_DATA_DIR = './test'

# create the base pre-trained model
base_model = NASNetMobile(weights='imagenet', include_top=False)

# add a global spatial average pooling layer
x = base_model.output
x = GlobalAveragePooling2D()(x)
# let's add a fully-connected layer
x = Dense(1024, activation='relu')(x)
# and a logistic layer -- let's say we have 200 classes
predictions = Dense(200, activation='softmax')(x)

# this is the model we will train
model = Model(inputs=base_model.input, outputs=predictions)

# first: train only the top layers (which were randomly initialized)
# i.e. freeze all convolutional InceptionV3 layers
for layer in base_model.layers:
    layer.trainable = False

# prepare train dataset
train_gen = ImageDataGenerator(rescale=1. / 255,
                               shear_range=0.2,
                               zoom_range=0.2,
                               horizontal_flip=True)

train_gen.flow_from_directory(directory=TRAIN_DATA_DIR,
                              target_size=base_model.input.shape[1:3],
                              class_mode='categorical',
                              batch_size=BATCH_SIZE,
                              shuffle=True)

# prepare test dataset
val_gen = ImageDataGenerator(rescale=1. / 255)

val_gen.flow_from_directory(directory=TEST_DATA_DIR,
                            target_size=base_model.input.shape[1:3],
                            class_mode='categorical',
                            batch_size=BATCH_SIZE)

# compile the model (should be done *after* setting layers to non-trainable)
model.compile(optimizer=Adam(lr=0.00001), loss='categorical_crossentropy')

checkpoint = ModelCheckpoint(filepath=""./NasNet_mobile_model_weights.h5"",
                             monitor=[""acc""],
                             verbose=1,
                             mode='max')

# train the model on the new data for a few epochs
model.fit_generator(train_gen,
                    steps_per_epoch=TRAIN_SAMPLES//BATCH_SIZE,
                    epochs=50,
                    validation_data=val_gen,
                    validation_steps=TEST_SAMPLES//BATCH_SIZE,
                    callbacks=[checkpoint],
                    verbose=2, 
                    workers=4
                    )
```

Output I get:

```
Using TensorFlow backend.
2019-02-01 10:07:40.704532: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:02:00.0
totalMemory: 10.91GiB freeMemory: 10.76GiB
2019-02-01 10:07:40.856400: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 1 with properties: 
name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:03:00.0
totalMemory: 10.92GiB freeMemory: 10.76GiB
2019-02-01 10:07:41.022663: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 2 with properties: 
name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:82:00.0
totalMemory: 10.92GiB freeMemory: 10.76GiB
2019-02-01 10:07:41.204602: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 3 with properties: 
name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
totalMemory: 10.92GiB freeMemory: 10.76GiB
2019-02-01 10:07:41.206764: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0, 1, 2, 3
2019-02-01 10:07:42.265616: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-02-01 10:07:42.265657: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 1 2 3 
2019-02-01 10:07:42.265663: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N Y N N 
2019-02-01 10:07:42.265667: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 1:   Y N N N 
2019-02-01 10:07:42.265670: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 2:   N N N Y 
2019-02-01 10:07:42.265674: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 3:   N N Y N 
2019-02-01 10:07:42.266421: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10401 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:02:00.0, compute capability: 6.1)
2019-02-01 10:07:42.266867: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 10403 MB memory) -> physical GPU (device: 1, name: GeForce GTX 1080 Ti, pci bus id: 0000:03:00.0, compute capability: 6.1)
2019-02-01 10:07:42.267168: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 10403 MB memory) -> physical GPU (device: 2, name: GeForce GTX 1080 Ti, pci bus id: 0000:82:00.0, compute capability: 6.1)
2019-02-01 10:07:42.267448: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:3 with 10403 MB memory) -> physical GPU (device: 3, name: GeForce GTX 1080 Ti, pci bus id: 0000:83:00.0, compute capability: 6.1)
Found 2081 images belonging to 15 classes.
Found 904 images belonging to 15 classes.
Traceback (most recent call last):
  File ""/home/smirnvla/PycharmProjects/keras-nasnet/train.py"", line 118, in <module>
    verbose=2
  File ""/usr/lib/python3.6/site-packages/keras/legacy/interfaces.py"", line 91, in wrapper
    return func(*args, **kwargs)
  File ""/usr/lib/python3.6/site-packages/keras/engine/training.py"", line 1418, in fit_generator
    initial_epoch=initial_epoch)
  File ""/usr/lib/python3.6/site-packages/keras/engine/training_generator.py"", line 133, in fit_generator
    if len(validation_data) == 2:
TypeError: object of type 'ImageDataGenerator' has no len()

Process finished with exit code 1
```

I tried to debug the code and seems like in this line https://github.com/keras-team/keras/blob/e59570ae26670f788d6c649191031e4a8824f955/keras/engine/training_generator.py#L110 if statement is false due **val_gen == False**. In the code above variable **val_gen** could be initialized as False because generator has no **\_\_next\_\_** or **next** functions.

Is it normal behavior?

",smivv,b'Enhancement Good first issue stat:contributions welcome',2019-02-01T07:37:01Z,2019-02-01T17:11:32Z
12174,[Dev] Deprecation procedure,"I would like to have a procedure to deprecate something or fix bugs that cannot be fixed because it would cause a major breaking change (like the infamous off by one error in keras.preprocessing.text). 

Right now, we have no resource to achieve this and once we agree to a procedure, it should be added to the wiki and to the CONTRIBUTING.md.

We have several different cases (with my proposition) :
1. Deprecate an argument
	* DeprecateWarning till the next minor.
	* Passed this date, remove
2. Deprecate a function
	* DeprecateWarning for 2 minors.
3. A bug that is fixable, but we did not fix it (off by one)
	* Make a V2 of the function with the bug
	* Add a warning in the faulty function that the user needs to switch to the new version.

If I forgot a case, please add a comment and I'll add it.
I don't think there are many resources to do this *the right way*. I'm open to suggestions.",Dref360,b'Dev',2019-01-29T19:48:18Z,2019-02-01T14:46:14Z
12152,Store layer for simply storing a value in Keras,"Hello all,

I have found useful sometimes to have a layer which just stores some value and does nothing more. It could be useful when you need to output multiple values from one layer or for debug purposes. I haven't found this in Keras documentation and/or source code, so I've written on myself:


```
class Store(Layer):
    def __init__(self, **kwargs):
        super(Store, self).__init__(**kwargs)

    def call(self, x, mask=None):
        return x

    def compute_mask(self, input_tensor, mask=None):
        return None

    def get_output_shape_for(self, input_shape):
        return input_shape

    def compute_output_shape(self, input_shape):
        return input_shape

```

Hope it will be useful for someone else.",madrugado,None,2019-01-28T11:46:00Z,2019-01-28T12:47:08Z
12121,Lambda layer with tf.fft.fft2d error,"I have a problem trying to make a Lambda layer that aplies fft2d to a tensor:
```
from keras.layers import Lambda, Input
import tensorflow as tf


inp = Input(shape=(299,299),dtype='complex64')
tensorTransformada = Lambda(tf.fft2d)(Inp)

```
Even if I have declared the first tensor as 'complex64', the next error appears:

    Traceback (most recent call last):

    File """", line 1, in

    File ""/usr/local/lib/python3.6/dist-packages/keras/engine/base_layer.py"", line 474, in call

    output_shape = self.compute_output_shape(input_shape)

    File ""/usr/local/lib/python3.6/dist-packages/keras/layers/core.py"", line 648, in compute_output_shape x = self.call(x) File ""/usr/local/lib/python3.6/dist-packages/keras/layers/core.py"", line 682, in call return self.function(inputs, **arguments)

    File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_spectral_ops.py"", line 437, in fft2d ""FFT2D"", input=input, name=name)

    File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py"", line 609, in _apply_op_helper param_name=input_name)

    File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py"", line 60, in _SatisfiesTypeConstraint "", "".join(dtypes.as_dtype(x).name for x in allowed_list)))

    TypeError: Value passed to parameter 'input' has DataType float32 not in list of allowed values: complex64, complex128

Please solve this bug

Running on Python 3.6.7, keras 2.2.2, tensorflow 1.11.0 on CPU,",isega24,b'type:bug/performance',2019-01-24T14:01:09Z,2019-04-26T17:54:18Z
12106,Update optimizers.py,"### Summary
fix bug in TFOptimizer, this optimizer should call tensorflow native optimizer with the named param var_list
### Related Issues
Without this fix i can't use my custom tensorflow optimizer that use **kwargs

```python
def compute_gradients(self, loss, **kwargs):
	grads_and_vars = super(MyTfOptimizer, self).compute_gradients(loss, **kwargs)
```

### PR Overview

- [ ] This PR requires new unit tests [**n**] (make sure tests are included)
- [ ] This PR requires to update the documentation [**n**] (make sure the docs are up-to-date)
- [ ] This PR is backwards compatible [**y**]
- [ ] This PR changes the current API [**n**] (all API changes need to be approved by fchollet)
",noamwies,None,2019-01-22T15:40:02Z,2019-01-23T21:56:41Z
12080,Bug in example (cifar10_resnet.py),"Hi,
here is a bug in this example here:
https://github.com/keras-team/keras/blob/master/examples/cifar10_resnet.py#L423

The Exception is:
```
ValueError: `steps_per_epoch=None` is only valid for a generator based on the 
`keras.utils.Sequence` class. Please specify `steps_per_epoch` or use the 
`keras.utils.Sequence` class.
```

`model.fit_generator` whould specify `steps_per_epoch`.

By example:
```
    model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),
                        steps_per_epoch=int(50000/batch_size),
                        validation_data=(x_test, y_test),
                        epochs=epochs, verbose=1, workers=4,
                        callbacks=callbacks)
```",PhilipMay,None,2019-01-20T08:50:20Z,2019-01-31T22:28:35Z
12069,Callback warning error,"I receive the following error when using `fit_generator` with callbacks in Keras:

```
/opt/conda/lib/python3.6/site-packages/Keras-2.2.4-py3.6.egg/keras/callbacks.py in _call_batch_hook(self, mode, hook, batch, logs)
     93                 'Method (%s) is slow compared '
     94                 'to the batch update (%f). Check your callbacks.', hook_name,
---> 95                 delta_t_median)
     96         if hook == 'begin':
     97             self._t_enter_batch = time.time()

TypeError: integer argument expected, got float

```

Apparently it happens with some combination of warnings package and Keras packages, or something else. Any idea for a quick workaround that does not involve removing callbacks?",psinger,b'Good first issue stat:contributions welcome type:bug/performance',2019-01-18T10:18:29Z,2019-02-19T05:51:00Z
12026,Problem with RNN with multiple states,"I'm trying to create a custom RNN cell that takes in a list of input tensors (e.g. feature blocks from a convolutional layer) and has multiple tensors in its state (with the same dimensions as the inputs). My approach for doing this was to create a custom RNN cell and pass it to the RNN layer. However, an error occurs because RNN.input_spec is set to [None] rather than the actual size of the input. Looking through source code of RNN and it's super class, I don't see anywhere where this input_spec would be correctly set, so I'm wondering if this is a bug in its implementation. The code to reproduce it is copied below. It doesn't seem to have anything to do with the custom RNN cell I wrote, so for brevity I replaced it with SimpleRNNCell (even though the architecture this gives probably won't work for other reasons).


```
from tensorflow import keras as ks
from pyramid_rnn import PyramidRNNCell

# Build initial featurizer which takes an image as an input and outputs a list of features
inputs = ks.layers.Input(shape=(512, 512, 1))
outputs = [ks.layers.Conv2D(32, 5)(inputs), ks.layers.Conv2D(54, 10)(inputs)]
featurizer = ks.models.Model(inputs=inputs, outputs=outputs)
feature_shapes = [tensor.shape for tensor in featurizer.outputs]

# make list of time series for inputs to RNN
time_series_input = ks.layers.Input(shape=(None, 512, 512, 1))
rnn_inputs = []
# apply TimeDistributed to each feature block
for feature_block in featurizer.outputs:
    rnn_inputs.append(ks.layers.TimeDistributed(
        ks.models.Model(featurizer.input, feature_block))(time_series_input))

# create initial state for RNN, which are same dimensionality as inputs
rnn_initial_state = []
for shapes in feature_shapes:
    rnn_initial_state.append(ks.layers.Input(shape=shapes[1:]))

cell = ks.layers.SimpleRNNCell(10)
rnn_output = ks.layers.RNN(cell)([rnn_inputs, *rnn_initial_state])

```",henrypinkard,b'stat:awaiting tensorflower type:support',2019-01-11T21:42:03Z,2019-04-15T16:39:31Z
12016,metrics are not evaluated if loss is None,"- [x ] Check that you are up-to-date with the master branch of Keras. You can update with:
`pip install git+git://github.com/keras-team/keras.git --upgrade --no-deps`

- [ x] Check that your version of TensorFlow is up-to-date. The installation instructions can be found [here](https://www.tensorflow.org/get_started/os_setup).

- [ x] Provide a link to a GitHub Gist of a Python script that can reproduce your issue (or just copy the script here if it is short).

Using the [VAE example from Keras](https://github.com/keras-team/keras/blob/master/examples/variational_autoencoder.py), one can easily reproduce the effect that any metric defined in the `model.compile` call will not be evaluated if the `loss` argument is None. For instance, substituting `vae.compile(optimizer='adam')` in [line 188](https://github.com/keras-team/keras/blob/master/examples/variational_autoencoder.py#L188) with 
```
    def kl_loss_fun(y_true, y_pred):
        return kl_loss
    def reconstruction_loss_fun(y_true, y_pred):
        return reconstruction_loss
    vae.compile(optimizer='adam', metrics=[kl_loss_fun, reconstruction_loss])
```
shows no output of the metrics when `fit` is called.

I found out that, if [compile](https://github.com/keras-team/keras/blob/master/keras/engine/training.py#L37) is called, that the metrics are just skipped if the corresponding loss per output is None in [line 443](https://github.com/keras-team/keras/blob/master/keras/engine/training.py#L443). Removing the conditional fixes the issue!

**So the main question is, why is the calculation of the metric conditioned on the losses at all? If the user demands it explicitly it should not depend on the loss which is given in the compile call.**",tik0,b'stat:contributions welcome type:bug/performance',2019-01-10T16:30:46Z,2019-01-10T20:22:54Z
12007,Fix Arguments display in Docs,"### Summary

Fix display bug in the docs. When Arguments is the last section of a docstring, it generally doesn't display the bullet points of the function arguments properly. This PR fixes this bug.

### Related Issues

https://github.com/keras-team/keras/issues/11673
https://github.com/keras-team/keras/issues/12006

### PR Overview

- [y] This PR requires new unit tests [y/n] (make sure tests are included)
- [n] This PR requires to update the documentation [y/n] (make sure the docs are up-to-date)
- [y] This PR is backwards compatible [y/n]
- [n] This PR changes the current API [y/n] (all API changes need to be approved by fchollet)
",RaphaelMeudec,None,2019-01-08T19:42:57Z,2019-01-08T23:22:46Z
12006,EarlyStopping documentation with wrong format,"EarlyStopping documentation has the wrong format. See here:
https://keras.io/callbacks/#earlystopping

The Arguments section is bugged.",PhilipMay,None,2019-01-08T17:12:24Z,2019-01-08T23:33:54Z
11973,Why does LearningRateScheduler not write the learning rate to Tensorboard ?,"The title pretty much says it all, when you use model.fit with ReduceLRonPlateau or without it along with the Tensorboard callback, Keras writes the learning rate by epoch to Tensorboard, but if you LearningRateScheduler, it doesn't ? Is there any particular reason for this ? Its technically not a bug, but its very unexpected behavior.

- [X] Check that you are up-to-date with the master branch of Keras. You can update with:
`pip install git+git://github.com/keras-team/keras.git --upgrade --no-deps`

- [X] Check that your version of TensorFlow is up-to-date. The installation instructions can be found [here](https://www.tensorflow.org/get_started/os_setup).

- [X] Provide a link to a GitHub Gist of a Python script that can reproduce your issue (or just copy the script here if it is short).
",rohit-gupta,b'backend:tensorflow type:bug/performance',2019-01-04T08:34:32Z,2019-03-14T23:08:42Z
11950,Input_shape bug,"So my issue is when Im trying to make the first Conv2D layer of my CNN
I have scoured the docs, and the web for hours finding different answers and I've bruteforced every possible combination of input_shape. Basically, the parameter input_shape (for the Conv2D layer) is behaving weird. I set input_shape to (28, 28, 3) which is the rows, columns, and channels of my images. 
I have also tried adding channels first. I have also tried setting data_format to ""channels_last"" etc.
I keep getting an error no matter what. Here is my most recent error 
`ValueError: Error when checking input: expected conv2d_1_input to have 4 dimensions, but got array with shape (60000, 28, 28)`

Here is the code:
`model.add(Conv2D(32, kernel_size=(3,3), activation='relu', input_shape = (28,28,1)))`
Please help thank you

",Mcilie,b'type:support',2018-12-30T03:21:53Z,2018-12-31T02:42:39Z
11941,Data Scaling issue using Python Keras multi_gpu_model with LSTM / GRU to predict Timeseries data,"There appears to be an data scaling issue with python keras LSTM / GRU layers with `multi_gpu_model` for machine learning. 

When I use a single GPU, the predictions work correctly matching the sinusoidal data in the script below. See image labeled ""1 GPUs"".

When I use multiple GPUs, the inverse transforms of both the training and test data return results that cluster around the lows of the original data  See image labeled ""4 GPUs"".

![gpus-4](https://user-images.githubusercontent.com/16875803/50510480-b73d2a80-0a3e-11e9-8420-3e8f9956d3ef.png)
![gpus-1](https://user-images.githubusercontent.com/16875803/50510490-c02dfc00-0a3e-11e9-8490-f5a56b2c674b.png)

It appears to be a bug, or the `multi_gpu_model` documentation isn't complete with a caveat to cover this specific case.

Versions

```
Keras                   2.2.4  
Keras-Applications      1.0.6  
Keras-Preprocessing     1.0.5  
tensorboard             1.12.0 
tensorflow-gpu          1.12.0 
```

GPUs

```
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 410.79       Driver Version: 410.79       CUDA Version: 10.0     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  GeForce GTX 107...  Off  | 00000000:08:00.0 Off |                  N/A |
| 30%   42C    P0    36W / 180W |      0MiB /  8119MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   1  GeForce GTX 107...  Off  | 00000000:09:00.0 Off |                  N/A |
| 36%   48C    P0    37W / 180W |      0MiB /  8119MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   2  GeForce GTX 107...  Off  | 00000000:41:00.0 Off |                  N/A |
| 34%   44C    P0    34W / 180W |      0MiB /  8119MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   3  GeForce GTX 107...  Off  | 00000000:42:00.0 Off |                  N/A |
| 31%   42C    P0    32W / 180W |      0MiB /  8112MiB |      5%      Default |
+-------------------------------+----------------------+----------------------+

```
Script
```
#!/usr/bin/env python3
""""""LSTM for sinusoidal data problem with regression framing.

Based on:

https://machinelearningmastery.com/time-series-prediction-lstm-recurrent-neural-networks-python-keras/

""""""

# Standard imports
import argparse
import math

# PIP3 imports
import numpy
import matplotlib.pyplot as plt
from pandas import DataFrame
from keras.models import Sequential
from keras.layers import Dense
from keras.layers import LSTM
from keras.utils import multi_gpu_model

import tensorflow as tf
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error

# convert an array of values into a dataset matrix
def create_dataset(dataset, look_back=1):
    dataX, dataY = [], []
    for i in range(len(dataset)-look_back-1):
        a = dataset[i:(i+look_back), 0]
        dataX.append(a)
        dataY.append(dataset[i + look_back, 0])
    return numpy.array(dataX), numpy.array(dataY)

def main():
    # fix random seed for reproducibility
    numpy.random.seed(7)

    # Get CLI arguments
    parser = argparse.ArgumentParser()
    parser.add_argument(
        '--gpus',
        help='Number of GPUs to use.',
        type=int, default=1)
    args = parser.parse_args()
    gpus = args.gpus

    # load the dataset
    dataframe = DataFrame(
        [0.00000, 5.99000, 11.92016, 17.73121, 23.36510, 28.76553, 33.87855,
         38.65306, 43.04137, 46.99961, 50.48826, 53.47244, 55.92235, 57.81349,
         59.12698, 59.84970, 59.97442, 59.49989, 58.43086, 56.77801, 54.55785,
         51.79256, 48.50978, 44.74231, 40.52779, 35.90833, 30.93008, 25.64279,
         20.09929, 14.35496, 8.46720, 2.49484, -3.50245, -9.46474, -15.33247,
         -21.04699, -26.55123, -31.79017, -36.71147, -41.26597, -45.40815,
         -49.09663, -52.29455, -54.96996, -57.09612, -58.65181, -59.62146,
         -59.99540, -59.76988, -58.94716, -57.53546, -55.54888, -53.00728,
         -49.93605, -46.36587, -42.33242, -37.87600, -33.04113, -27.87613,
         -22.43260, -16.76493, -10.92975, -4.98536, 1.00883, 6.99295, 12.90720,
         18.69248, 24.29100, 29.64680, 34.70639, 39.41920, 43.73814, 47.62007,
         51.02620, 53.92249, 56.28000, 58.07518, 59.29009, 59.91260, 59.93648,
         59.36149, 58.19339, 56.44383, 54.13031, 51.27593, 47.90923, 44.06383,
         39.77815, 35.09503, 30.06125, 24.72711, 19.14590, 13.37339, 7.46727,
         1.48653, -4.50907, -10.45961, -16.30564, -21.98875, -27.45215,
         -32.64127, -37.50424, -41.99248, -46.06115, -49.66959, -52.78175,
         -55.36653, -57.39810, -58.85617, -59.72618, -59.99941, -59.67316,
         -58.75066, -57.24115, -55.15971, -52.52713, -49.36972, -45.71902,
         -41.61151, -37.08823, -32.19438, -26.97885, -21.49376, -15.79391,
         -9.93625, -3.97931, 2.01738, 7.99392, 13.89059, 19.64847, 25.21002,
         30.51969, 35.52441, 40.17419, 44.42255, 48.22707, 51.54971, 54.35728,
         56.62174, 58.32045, 59.43644, 59.95856, 59.88160, 59.20632, 57.93947,
         56.09370, 53.68747, 50.74481, 47.29512, 43.37288, 39.01727, 34.27181,
         29.18392, 23.80443, 18.18710, 12.38805, 6.46522, 0.47779, -5.51441,
         -11.45151])
    dataset = dataframe.values
    dataset = dataset.astype('float32')

    # normalize the dataset
    scaler = MinMaxScaler(feature_range=(0, 1))
    dataset = scaler.fit_transform(dataset)

    # split into train and test sets
    train_size = int(len(dataset) * 0.67)
    test_size = len(dataset) - train_size
    train, test = dataset[0:train_size, :], dataset[train_size:len(dataset), :]

    # reshape into X=t and Y=t+1
    look_back = 1
    trainX, trainY = create_dataset(train, look_back)
    testX, testY = create_dataset(test, look_back)

    # reshape input to be [samples, time steps, features]
    trainX = numpy.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))
    testX = numpy.reshape(testX, (testX.shape[0], 1, testX.shape[1]))

    # create and fit the LSTM network
    with tf.device('/cpu:0'):
        serial_model = Sequential()
    serial_model.add(LSTM(4, input_shape=(1, look_back)))
    serial_model.add(Dense(1))
    if gpus == 1:
        parallel_model = serial_model
    else:
        parallel_model = multi_gpu_model(
            serial_model,
            cpu_relocation=True,
            gpus=gpus)
    parallel_model.compile(
        loss='mean_squared_error', optimizer='adam')
    parallel_model.fit(
        trainX, trainY,
        epochs=100,
        batch_size=int(dataset.size * gpus / 20),
        verbose=2)

    # make predictions
    if gpus == 1:
        trainPredict = parallel_model.predict(trainX)
        testPredict = parallel_model.predict(testX)
    else:
        trainPredict = serial_model.predict(trainX)
        testPredict = serial_model.predict(testX)

    # invert predictions
    trainPredict = scaler.inverse_transform(trainPredict)
    trainY = scaler.inverse_transform([trainY])
    testPredict = scaler.inverse_transform(testPredict)
    testY = scaler.inverse_transform([testY])

    # calculate root mean squared error
    trainScore = math.sqrt(mean_squared_error(trainY[0], trainPredict[:, 0]))
    print('Train Score: %.2f RMSE' % (trainScore))
    testScore = math.sqrt(mean_squared_error(testY[0], testPredict[:, 0]))
    print('Test Score: %.2f RMSE' % (testScore))

    # shift train predictions for plotting
    trainPredictPlot = numpy.empty_like(dataset)
    trainPredictPlot[:, :] = numpy.nan
    trainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict

    # shift test predictions for plotting
    testPredictPlot = numpy.empty_like(dataset)
    testPredictPlot[:, :] = numpy.nan
    testPredictPlot[
        len(trainPredict)+(look_back*2)+1:len(dataset)-1, :] = testPredict

    # plot baseline and predictions
    plt.plot(scaler.inverse_transform(dataset), label='Complete Data')
    plt.plot(trainPredictPlot, label='Training Data')
    plt.plot(testPredictPlot, label='Prediction Data')
    plt.legend(loc='upper left')
    plt.title('Using {} GPUs'.format(gpus))
    plt.show()


if __name__ == ""__main__"":
    main()
```
",palisadoes,b'To investigate',2018-12-28T09:24:47Z,2018-12-31T18:17:55Z
11940,keras model add layer created by k.stack in order to create stacked output,"I am using keras with tf backend to create a siamese network, I am trying to create a custom loss function for triplet loss and need to 
pass it with multiple outputs in a one tensor that I can then split in the loss function in order to calculate the gradient. 

I am trying to use what explained [here](https://stackoverflow.com/questions/52095790/concatenate-error-the-added-layer-must-be-an-instance-of-class-layer) as for how to use multiple outputs in a concatenated form, and use it in my code in the following way 

    input_layer = Input(shape=(784,))                               
    a = Dense(100, activation=""relu"")(input_layer)                  
    o = Dense(40, activation=""relu"")(a)                             
    layer1 = Lambda(lambda x: K.expand_dims(x, axis=2))(o)          
    layer2 = Lambda(lambda x: K.expand_dims(x, axis=2))(o)          
    concat_layer = concatenate([layer1, layer2], axis=2)            
                                                                    
    model = Model(input_layer, concat_layer)                        
    model.compile(optimizer=SGD(), loss=triplet_loss_wrapper())     
                                                                    
    (x_train, y_train), (x_test, y_test) = mnist.load_data()        
    x_test = x_test.reshape(x_test.shape[0], 784)                   
                                                                    
                                                                    
    model.fit(x_test, [1] * len(x_test))

                            
I get the following error 

                                                                

> (np_val.shape, subfeed_t.name, str(subfeed_t.get_shape())))
> ValueError: Cannot feed value of shape (32, 1) for Tensor
> 'concatenate_1_target:0', which has shape '(?, ?, ?)'

please also see my connected SO [question](https://stackoverflow.com/posts/53947008/edit) 


  ",thebeancounter,b'backend:tensorflow type:bug/performance',2018-12-28T07:06:06Z,2019-02-22T02:54:53Z
11938,MemoryError on linux ,"I try to build a network model using cnn. The code works well in my local area.
`
def generate_model_then_predict_model(model_name:str,epochs=2):

	train_size = len(os.listdir(DOG_SUMU_DIR)) + len(os.listdir(DOG_JINMAO_DIR))
	train_fi = len(os.listdir(DOG_JINMAO_DIR))
	trains = np.empty((train_size,DOG_PIC_WIDTH,DOG_PIC_HEIGHT,3),dtype=""float32"")
	labels = np.empty((train_size),dtype=""int32"")

	for ind in range(len(os.listdir(DOG_JINMAO_DIR))):
		img = Image.open(os.path.join(DOG_JINMAO_DIR, os.listdir(DOG_JINMAO_DIR)[ind]))
		arr = np.asarray(img,dtype=""float32"")
		trains[ind,:,:,:] = arr.reshape(DOG_PIC_WIDTH,DOG_PIC_HEIGHT,3) # (460,585,3)
		labels[ind] = 0

	for ind in range(len(os.listdir(DOG_SUMU_DIR))):
		img = Image.open(os.path.join(DOG_SUMU_DIR, os.listdir(DOG_SUMU_DIR)[ind]))#tf.image.decode_jpeg(img,channels=3)
		arr = np.asarray(img,dtype=""float32"")
		trains[ind+train_fi,:,:,:] = arr.reshape(DOG_PIC_WIDTH,DOG_PIC_HEIGHT,3)
		labels[ind+train_fi] = 1

	write_log(str(labels),file=log_file)

	model = keras.Sequential([
		keras.layers.Flatten(input_shape=(DOG_PIC_WIDTH,DOG_PIC_HEIGHT,3)),
		keras.layers.Dense(2,activation=tf.nn.relu,input_shape=(DOG_PIC_WIDTH,DOG_PIC_HEIGHT,3)),
		keras.layers.Dense(2,activation=tf.nn.relu),
		keras.layers.Dense(2,activation=tf.nn.softmax)
	])

	model.compile(
		optimizer =tf.train.AdamOptimizer(),
		loss = 'sparse_categorical_crossentropy',
		metrics = ['accuracy']
	)

	model.fit(trains,labels,epochs=epochs,steps_per_epoch=20)
	model.save(test_6_MODEL+""/""+model_name)
	predict_dog(model,test_jinmao)

`
But when I use a CentOS 7.3 Ali Cloud server, hint the following error
`
-> if __name__ == '__main__':
(Pdb) n
> /srv/dog-face-identify/dog-face-check/cnn/_test_cnn_6.py(132)<module>()
-> generate_model_then_predict_model(""1915_01.h5"",10)
(Pdb) n
MemoryError
> /srv/dog-face-identify/dog-face-check/cnn/_test_cnn_6.py(132)<module>()
-> generate_model_then_predict_model(""1915_01.h5"",10)
(Pdb) n
--Return--
> /srv/dog-face-identify/dog-face-check/cnn/_test_cnn_6.py(132)<module>()->None
-> generate_model_then_predict_model(""1915_01.h5"",10)
(Pdb) n
MemoryError
> <string>(1)<module>()->None
(Pdb) n
--Return--
> <string>(1)<module>()->None
(Pdb) n
Traceback (most recent call last):
  File ""/usr/local/python3/lib/python3.6/pdb.py"", line 1667, in main
    pdb._runscript(mainpyfile)
  File ""/usr/local/python3/lib/python3.6/pdb.py"", line 1548, in _runscript
    self.run(statement)
  File ""/usr/local/python3/lib/python3.6/bdb.py"", line 434, in run
    exec(cmd, globals, locals)
  File ""<string>"", line 1, in <module>
  File ""/srv/dog-face-identify/dog-face-check/cnn/_test_cnn_6.py"", line 132, in<module>
    generate_model_then_predict_model(""1915_01.h5"",10)
  File ""/srv/dog-face-identify/dog-face-check/cnn/_test_cnn_6.py"", line 97, in generate_model_then_predict_model
    trains = np.empty((train_size,DOG_PIC_WIDTH,DOG_PIC_HEIGHT,3),dtype=""float32"")
MemoryError
Uncaught exception. Entering post mortem debugging
Running 'cont' or 'step' will restart the program
> /srv/dog-face-identify/dog-face-check/cnn/_test_cnn_6.py(97)generate_model_then_predict_model()
-> trains = np.empty((train_size,DOG_PIC_WIDTH,DOG_PIC_HEIGHT,3),dtype=""float32"")

`",fingerecho,None,2018-12-27T02:36:20Z,2018-12-30T06:33:08Z
11924,Fix function 'get_file()' is inconsistent with keras backend when 'KERAS_HOME' is not `~/.keras`,"### Summary
the default value(None) for param `cache_dir` in function `get_file()` is inconsistent with keras backend when 'KERAS_HOME' is not `~/.keras`.
when we set `KERAS_HOME` and `KERAS_HOME` is not `~/.keras`, models and datasets will still be in `~/.keras`(when the cache_dir is default value) while the config file `keras.json` in `KERAS_HOME`.
The config file `keras.json`, models and datasets should be in the same folder by default

bug fix the unit test `test_data_utils ()` in `tests/keras/utils/data_utils_test.py` where the cache_dir remain extracted-file `test.txt`(which should be removed at last) when `untar` is `True`

### Related Issues
This applies the fix in issue [#11923](https://github.com/keras-team/keras/issues/11923)

### PR Overview

- [n] This PR requires new unit tests [y/n] (make sure tests are included)
- [n] This PR requires to update the documentation [y/n] (make sure the docs are up-to-date)
- [y] This PR is backwards compatible [y/n]
- [n] This PR changes the current API [y/n] (all API changes need to be approved by fchollet)
",stanpcf,None,2018-12-23T12:55:26Z,2019-01-01T17:17:20Z
11921,Creating model with shared layers,"I'm trying to implement model for triplet loss using FacenetModel.By far I have written this code :

`        
     def batch_generator(batch_size = 64):
            while True:
                pos = positiveImg[np.random.choice(len(positiveImg), batch_size)]
                neg = negativeImg[np.random.choice(len(negativeImg), batch_size)]
                anc = anchorsImg[np.random.choice(len(anchorsImg), batch_size)]
        
                x_data = {'inp1': anc,
                          'inp2': pos,
                          'inp3': neg
                          }
                y_data = {'y1': np.zeros((64,0)),
                          'y2': np.zeros((64,0)),
                          'y3': np.zeros((64,0))}
                yield (x_data, y_data)
        
        def triplet_loss(y_true, y_pred):    
            anchor, positive, negative = y_pred[0], y_pred[1], y_pred[2]
            pos_dist = tf.reduce_sum(tf.square(tf.subtract(anchor, positive)), axis=-1)
            neg_dist = tf.reduce_sum(tf.square(tf.subtract(anchor, negative)), axis=-1)
            basic_loss = tf.add(tf.subtract(pos_dist, neg_dist), 0.2)
            loss = tf.reduce_sum(tf.maximum(basic_loss, 0.0))
        
            return loss
        
        def getModels():
            FRmodel = keras.models.load_model('FR.h5', custom_objects={'triplet_loss': triplet_loss})
        
            inp1 = Input((3, 96, 96), name= 'inp1')
            inp2 = Input((3, 96, 96), name= 'inp2')
            inp3 = Input((3, 96, 96), name= 'inp3')
        
            pred1 = FRmodel(inp1)
            pred2 = FRmodel(inp2)
            pred3 = FRmodel(inp3)
        
            inputs = [inp1, inp2, inp3]
            outputs = [pred1, pred2, pred3]
        
            model = keras.models.Model(inputs=[inp1, inp2, inp3], outputs= [pred1, pred2, pred3])
        
            return FRmodel, model
        
        generator = batch_generator(64)
        
        FRmodel, my_model = getModels()
        my_model.compile(optimizer = 'adam', loss = triplet_loss, metrics = ['accuracy'])   
        my_model.fit_generator(generator, epochs=5,steps_per_epoch=30)`

But when I compile this model. I get this error: ValueError: No data provided for ""FaceRecoModel"". Need data for each key in: ['FaceRecoModel', 'FaceRecoModel', 'FaceRecoModel']

What is the correct way to do this?

Please don't get mad. I'm not getting any responses on stackoverflow. Please help.",sainimohit23,b'type:bug/performance',2018-12-22T12:53:12Z,2019-01-18T23:28:37Z
11907,Strange Bug (float argument cannot be Dimension),"Hello!

When i try the code
```
x = Input((28,28,20))
y = Conv2D(32, 1)(x)
x2 = Input(shape=x.shape[1:])
y2 = Conv2D(32, 1)(x2)
```
then x/y and x2/y2 should be exactly the same. Even the shape of both x and x2 is printed exactly as the same. But in the second Conv2D (last line) it says:
TypeError: float() argument must be a string or a number, not 'Dimension'.

```
---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
<ipython-input-27-0b935c716286> in <module>()
      3 y = Conv2D(32, 1)(x)
      4 x2 = Input(shape=x.shape[1:])
----> 5 y2 = Conv2D(32, 1)(x2)

d:\winpython-64bit-3.6.6.1\python-3.6.6.amd64\lib\site-packages\keras\engine\base_layer.py in __call__(self, inputs, **kwargs)
    429                                          'You can build it manually via: '
    430                                          '`layer.build(batch_input_shape)`')
--> 431                 self.build(unpack_singleton(input_shapes))
    432                 self.built = True
    433 

d:\winpython-64bit-3.6.6.1\python-3.6.6.amd64\lib\site-packages\keras\layers\convolutional.py in build(self, input_shape)
    136                                       name='kernel',
    137                                       regularizer=self.kernel_regularizer,
--> 138                                       constraint=self.kernel_constraint)
    139         if self.use_bias:
    140             self.bias = self.add_weight(shape=(self.filters,),

d:\winpython-64bit-3.6.6.1\python-3.6.6.amd64\lib\site-packages\keras\legacy\interfaces.py in wrapper(*args, **kwargs)
     89                 warnings.warn('Update your `' + object_name +
     90                               '` call to the Keras 2 API: ' + signature, stacklevel=2)
---> 91             return func(*args, **kwargs)
     92         wrapper._original_function = func
     93         return wrapper

d:\winpython-64bit-3.6.6.1\python-3.6.6.amd64\lib\site-packages\keras\engine\base_layer.py in add_weight(self, name, shape, dtype, initializer, regularizer, trainable, constraint)
    247         if dtype is None:
    248             dtype = K.floatx()
--> 249         weight = K.variable(initializer(shape),
    250                             dtype=dtype,
    251                             name=name,

d:\winpython-64bit-3.6.6.1\python-3.6.6.amd64\lib\site-packages\keras\initializers.py in __call__(self, shape, dtype)
    207             scale /= max(1., fan_out)
    208         else:
--> 209             scale /= max(1., float(fan_in + fan_out) / 2)
    210         if self.distribution == 'normal':
    211             # 0.879... = scipy.stats.truncnorm.std(a=-2, b=2, loc=0., scale=1.)

TypeError: float() argument must be a string or a number, not 'Dimension'
```",mha-py,None,2018-12-20T02:59:13Z,2018-12-26T21:48:05Z
11877,Confused information on keras fit_generator() steps_per_epoch/validation_steps parameters documentation,"On the Keras documentation we find the following information for **steps_per_epoch** and **validation_steps** when using the fit_generator() function:

> It should typically be equal to the number of samples of your validation dataset divided by the batch size.

I'm writing a [new generator](https://gist.github.com/kleysonr/a41f0d72891afec8a49990c8cc24f5e4) and while debugging my code I didn't get the full dataset that was expected for one epoch.

Below my fit_generator:

```python
kbg = KerasBatchGenerator('/home/kleysonr/Downloads/keras-generator/dataset', batch_size=6, imagesize=(100, 100), test_ratio=0.3)

model.fit_generator(kbg.generate(set='train'), 
                    steps_per_epoch=training_steps,
                    epochs=1,
                    verbose=1,
                    validation_data=kbg.generate(set='test'),
                    validation_steps=validation_steps,
                    use_multiprocessing=False,
                    workers=0)

```

Setting steps_per_epoch and validation_steps, as:

```python
training_steps = kbg.getTrainingSize() // kbg.getBatchSize()
validation_steps = kbg.getTestingSize() // kbg.getBatchSize()
```

The batch process was (missing 3 images for the full training dataset):

```
Epoch 1/1
Batch: 0-0 <<train>> /home/kleysonr/Downloads/keras-generator/dataset/class3/c3-10.jpg
Batch: 0-1 <<train>> /home/kleysonr/Downloads/keras-generator/dataset/class1/c1-2.jpg
Batch: 0-2 <<train>> /home/kleysonr/Downloads/keras-generator/dataset/class2/c2-1.jpg
Batch: 0-3 <<train>> /home/kleysonr/Downloads/keras-generator/dataset/class3/c3-2.jpg
Batch: 0-4 <<train>> /home/kleysonr/Downloads/keras-generator/dataset/class2/c2-2.jpg
Batch: 0-5 <<train>> /home/kleysonr/Downloads/keras-generator/dataset/class1/c1-9.jpg
1/3 [=========>....................] - ETA: 1s - loss: 1.1116 - acc: 0.1667
Batch: 1-0 <<train>> /home/kleysonr/Downloads/keras-generator/dataset/class2/c2-8.jpg
Batch: 1-1 <<train>> /home/kleysonr/Downloads/keras-generator/dataset/class1/c1-7.jpg
Batch: 1-2 <<train>> /home/kleysonr/Downloads/keras-generator/dataset/class1/c1-8.jpg
Batch: 1-3 <<train>> /home/kleysonr/Downloads/keras-generator/dataset/class2/c2-9.jpg
Batch: 1-4 <<train>> /home/kleysonr/Downloads/keras-generator/dataset/class1/c1-1.jpg
Batch: 1-5 <<train>> /home/kleysonr/Downloads/keras-generator/dataset/class3/c3-6.jpg
2/3 [===================>..........] - ETA: 0s - loss: 1.1519 - acc: 0.1667
Batch: 2-0 <<train>> /home/kleysonr/Downloads/keras-generator/dataset/class3/c3-9.jpg
Batch: 2-1 <<train>> /home/kleysonr/Downloads/keras-generator/dataset/class1/c1-4.jpg
Batch: 2-2 <<train>> /home/kleysonr/Downloads/keras-generator/dataset/class2/c2-5.jpg
Batch: 2-3 <<train>> /home/kleysonr/Downloads/keras-generator/dataset/class2/c2-6.jpg
Batch: 2-4 <<train>> /home/kleysonr/Downloads/keras-generator/dataset/class1/c1-10.jpg
Batch: 2-5 <<train>> /home/kleysonr/Downloads/keras-generator/dataset/class3/c3-1.jpg
3/3 [==============================] - 1s 392ms/step - loss: 1.1632 - acc: 0.2222 - val_loss: 1.0733 - val_acc: 0.3333
```

Setting steps_per_epoch and validation_steps, as:

```python
training_steps = math.ceil(kbg.getTrainingSize() / kbg.getBatchSize())
validation_steps = math.ceil(kbg.getTestingSize() / kbg.getBatchSize())
```

The batch process was (got the full training dataset):

```
Epoch 1/1
Batch: 0-0 <<train>> /home/kleysonr/Downloads/keras-generator/dataset/class2/c2-6.jpg
Batch: 0-1 <<train>> /home/kleysonr/Downloads/keras-generator/dataset/class2/c2-1.jpg
Batch: 0-2 <<train>> /home/kleysonr/Downloads/keras-generator/dataset/class1/c1-2.jpg
Batch: 0-3 <<train>> /home/kleysonr/Downloads/keras-generator/dataset/class3/c3-5.jpg
Batch: 0-4 <<train>> /home/kleysonr/Downloads/keras-generator/dataset/class1/c1-5.jpg
Batch: 0-5 <<train>> /home/kleysonr/Downloads/keras-generator/dataset/class3/c3-9.jpg
1/4 [======>.......................] - ETA: 3s - loss: 1.1336 - acc: 0.1667
Batch: 1-0 <<train>> /home/kleysonr/Downloads/keras-generator/dataset/class1/c1-9.jpg
Batch: 1-1 <<train>> /home/kleysonr/Downloads/keras-generator/dataset/class2/c2-9.jpg
Batch: 1-2 <<train>> /home/kleysonr/Downloads/keras-generator/dataset/class1/c1-6.jpg
Batch: 1-3 <<train>> /home/kleysonr/Downloads/keras-generator/dataset/class2/c2-4.jpg
Batch: 1-4 <<train>> /home/kleysonr/Downloads/keras-generator/dataset/class1/c1-10.jpg
Batch: 1-5 <<train>> /home/kleysonr/Downloads/keras-generator/dataset/class2/c2-7.jpg
2/4 [==============>...............] - ETA: 1s - loss: 1.1540 - acc: 0.1667
Batch: 2-0 <<train>> /home/kleysonr/Downloads/keras-generator/dataset/class1/c1-3.jpg
Batch: 2-1 <<train>> /home/kleysonr/Downloads/keras-generator/dataset/class2/c2-3.jpg
Batch: 2-2 <<train>> /home/kleysonr/Downloads/keras-generator/dataset/class3/c3-3.jpg
Batch: 2-3 <<train>> /home/kleysonr/Downloads/keras-generator/dataset/class3/c3-10.jpg
Batch: 2-4 <<train>> /home/kleysonr/Downloads/keras-generator/dataset/class3/c3-6.jpg
Batch: 2-5 <<train>> /home/kleysonr/Downloads/keras-generator/dataset/class3/c3-8.jpg
3/4 [=====================>........] - ETA: 0s - loss: 1.3066 - acc: 0.2222
Batch: 3-0 <<train>> /home/kleysonr/Downloads/keras-generator/dataset/class3/c3-1.jpg
Batch: 3-1 <<train>> /home/kleysonr/Downloads/keras-generator/dataset/class1/c1-7.jpg
Batch: 3-2 <<train>> /home/kleysonr/Downloads/keras-generator/dataset/class2/c2-10.jpg
1544964579 --train-- New epoch
4/4 [==============================] - 2s 391ms/step - loss: 1.2351 - acc: 0.3238 - val_loss: 1.1089 - val_acc: 0.2222
```

Is the second approach - using math.ceil() - the correct way to set the parameters ?
If yes, I'm wondering if the documentation could be more clear about setting those parameters.

Below more useful information:

```
Information about dataset:
  Dataset size: 30
  Training size: 21
  Test size: 9
  Classes: 3
  Batch Size: 6
```
```
$ pip3 freeze | egrep ""Keras|tensorflow""
Keras==2.2.4
Keras-Applications==1.0.6
Keras-Preprocessing==1.0.5
tensorflow-gpu==1.12.0
```
```
$ python3 --version
Python 3.5.2
```

Best Regards.
Kleyson Rios.",kleysonr,b'Good first issue type:docs',2018-12-16T13:43:01Z,2019-01-29T14:15:52Z
11870,Loading multi_gpu_model on Windows fails with SystemError: unknown opcode,"- [x] Check that you are up-to-date with the master branch of Keras. You can update with:
`pip install git+git://github.com/keras-team/keras.git --upgrade --no-deps`

- [x] Check that your version of TensorFlow is up-to-date. The installation instructions can be found [here](https://www.tensorflow.org/get_started/os_setup).

- [x] Provide a link to a GitHub Gist of a Python script that can reproduce your issue (or just copy the script here if it is short).

When i try to load a multi_gpu_model on windows with either `load_model` or `model_from_json` i get the following Error:

```
XXX lineno: 184, opcode: 0
Traceback (most recent call last):
  File ""C:\Program Files\JetBrains\PyCharm 2018.2.4\helpers\pydev\pydevd.py"", line 1664, in <module>
    main()
  File ""C:\Program Files\JetBrains\PyCharm 2018.2.4\helpers\pydev\pydevd.py"", line 1658, in main
    globals = debugger.run(setup['file'], None, None, is_module)
  File ""C:\Program Files\JetBrains\PyCharm 2018.2.4\helpers\pydev\pydevd.py"", line 1068, in run
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File ""C:\Program Files\JetBrains\PyCharm 2018.2.4\helpers\pydev\_pydev_imps\_pydev_execfile.py"", line 18, in execfile
    exec(compile(contents+""\n"", file, 'exec'), glob, loc)
  File ""C:/Users/auser/.PyCharm2018.2/config/scratches/scratch_6.py"", line 6, in <module>
    model = keras.models.model_from_json(jsonString)
  File ""C:\Users\auser\AppData\Local\Programs\Python\Python36\lib\site-packages\keras\engine\saving.py"", line 492, in model_from_json
    return deserialize(config, custom_objects=custom_objects)
  File ""C:\Users\auser\AppData\Local\Programs\Python\Python36\lib\site-packages\keras\layers\__init__.py"", line 55, in deserialize
    printable_module_name='layer')
  File ""C:\Users\auser\AppData\Local\Programs\Python\Python36\lib\site-packages\keras\utils\generic_utils.py"", line 147, in deserialize_keras_object
    list(custom_objects.items())))
  File ""C:\Users\auser\AppData\Local\Programs\Python\Python36\lib\site-packages\keras\engine\network.py"", line 1029, in from_config
    process_node(layer, node_data)
  File ""C:\Users\auser\AppData\Local\Programs\Python\Python36\lib\site-packages\keras\engine\network.py"", line 988, in process_node
    layer(unpack_singleton(input_tensors), **kwargs)
  File ""C:\Users\auser\AppData\Local\Programs\Python\Python36\lib\site-packages\keras\engine\base_layer.py"", line 457, in __call__
    output = self.call(inputs, **kwargs)
  File ""C:\Users\auser\AppData\Local\Programs\Python\Python36\lib\site-packages\keras\layers\core.py"", line 707, in call
    return self.function(inputs, **arguments)
  File ""/usr/local/lib/python3.5/dist-packages/keras/utils/multi_gpu_utils.py"", line 184, in get_slice
SystemError: unknown opcode
```

In the last line of the traceback it is saying `File ""/usr/local/lib/python3.5/dist-packages/keras/utils/multi_gpu_utils.py"", line 184, in get_slice` which is realy strange, since i am on Windows 10 64-bit.

I tried to reproduce the error with the same model files on ubuntu 16.04 with the same keras version (2.2.4) and there everything works just fine.

So it seems to be a Windows specific error. 

Important! The model was trained and saved on a ubuntu machine. Maybe this is part of the problem.
",albert-92,b'backend:tensorflow',2018-12-14T15:14:17Z,2018-12-17T17:21:05Z
11858,BatchNormalization produces NaN weights without NaN loss,"Hi,

Not sure this can be labelled as a bug, but it's problematic. BatchNormalization seems to silently produce NaN weights when training a `multi_gpu_model` if the training dataset size is not a multiple of `batch_size`.

For example, with a training dataset (1825, 401, 401, 3), validation dataset (140, 401, 401, 3), `epochs=1`, `batch_size=16`, `gpu_number=2`

```python
    # instantiate model
    with tf.device('/cpu:0'):
        # DenseNet121: blocks=[6, 12, 24, 16]
        base_model = densenet.DenseNet121(include_top=False, weights=None,
                                       input_shape=(401, 401, 3), pooling='avg')
        x = Dense(units=1, activation='sigmoid', name='fc1')(base_model.output)
        model = Model(inputs=base_model.input, outputs=x)

    # compile model
    parallel_model = multi_gpu_model(model, gpus=gpu_number)
    parallel_model.compile(loss={'fc1': 'binary_crossentropy'},
                           optimizer='Adadelta',
                           metrics={'fc1': ['acc']})

    # train model
    tic = datetime.datetime.now()
    parallel_model.fit(train_onecell_im,
                       {'fc1': (train_onecell_dice >= quality_threshold).astype(np.float32)},
                       validation_data=(test_onecell_im,
                                        {'fc1': (test_onecell_dice >= quality_threshold).astype(np.float32)}),
                       batch_size=batch_size, epochs=epochs, initial_epoch=0)
    toc = datetime.datetime.now()
    print('Training duration: ' + str(toc - tic))
```

The training apparently goes fine

```
Train on 1825 samples, validate on 140 samples
Epoch 1/1
1825/1825 [==============================] - 108s 59ms/step - loss: 0.6604 - acc: 0.6323 - val_loss: 0.6932 - val_acc: 0.4643
Training duration: 0:02:08.115762

```

but the weights have NaNs, e.g.

```
model.get_layer('conv1/bn').get_weights()
[array([1.0001292 , 1.        , 0.9996672 , 0.9999442 , 1.000509  ,
       1.0001016 , 1.0002009 , 1.0004678 , 0.9999988 , 0.999962  ,
       1.0003603 , 1.0001667 , 0.9999296 , 0.9999381 , 1.00001   ,
       0.99967813, 0.9999821 , 0.99981546, 0.9999899 , 1.0002408 ,
       0.9999446 , 0.9999995 , 0.99989605, 1.0000395 , 1.0000094 ,
       0.9999432 , 0.999968  , 0.99994946, 0.9997129 , 1.0000957 ,
       0.99997395, 1.000016  , 0.99995   , 0.99981534, 0.99984217,
       0.9999743 , 0.99999624, 1.0005921 , 1.0001019 , 1.000008  ,
       0.99993116, 0.99998087, 0.9999631 , 0.9999878 , 0.9999804 ,
       1.0003394 , 0.999895  , 0.9997747 , 0.9999677 , 0.99998355,
       1.000003  , 0.9998863 , 0.9999338 , 0.9998308 , 1.0000825 ,
       1.000022  , 0.9999998 , 0.9997648 , 1.0000801 , 1.000631  ,
       1.0000259 , 0.9996165 , 1.0001084 , 0.9996289 ], dtype=float32), array([ 0.00369794, -0.00307915, -0.0148356 ,  0.01176912, -0.00456085,
        0.00461122,  0.00392016, -0.00510793, -0.00388927,  0.00678776,
       -0.0033672 ,  0.0020039 ,  0.00688829,  0.00877651,  0.00838199,
       -0.0217527 , -0.00673187, -0.01623467,  0.00523926, -0.0005527 ,
        0.00700372, -0.00372984, -0.01347521, -0.00636716,  0.00206494,
        0.00884918, -0.00814271, -0.00801541, -0.02038615,  0.00171547,
        0.00709944, -0.00221861,  0.00538696, -0.01515745, -0.01330438,
        0.00306095,  0.00399868, -0.0049634 , -0.00725381,  0.00373429,
       -0.01107734, -0.00610222, -0.00854702, -0.00504343, -0.0080514 ,
       -0.00920443,  0.00863727, -0.01750346,  0.00656873, -0.00534429,
        0.00434025, -0.01352841, -0.00819136, -0.01453205, -0.00043049,
       -0.00257635, -0.00448346, -0.01370949,  0.00355583, -0.00480247,
        0.00179911, -0.01858746, -0.00059417, -0.0123234 ], dtype=float32), array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
      dtype=float32), array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
      dtype=float32)]
```

I think this happens because the training dataset of 1825 gets split into sets of `batch_size=16`. So there's going to be a set of 1 training image, and maybe that doesn't work with BatchNormalization.

Inference with the trained model gives

```
foo = model.predict(test_onecell_im)

foo
array([[nan],
       [nan],
       [nan],
...
       [nan],
       [nan]], dtype=float32)
```

A solution is to make sure that the number of training images is a multiple of `batch_size`.",rcasero,b'backend:tensorflow stat:awaiting response',2018-12-12T15:27:04Z,2018-12-12T18:13:06Z
11847,Fix bug for save nested models with shared parameters.,"### Summary
Problem loading models that have nested models with shared parameters. It is common to find this type of architecture in Siamese networks or triplets.

The problem occurs when once the network has been saved, it is tried to load again.

The problem is that you are trying to load multiple times the weights of the same model that is shared.

### Related Issues
https://github.com/keras-team/keras/issues/10428
https://github.com/experiencor/keras-yolo2/issues/358
https://github.com/keras-team/keras/issues/9562

### PR Overview

- [ ] This PR requires new unit tests [y/n] (make sure tests are included)
- [ ] This PR requires to update the documentation [y/n] (make sure the docs are up-to-date)
- [ ] This PR is backwards compatible [y/n]
- [ ] This PR changes the current API [y/n] (all API changes need to be approved by fchollet)
",adriaciurana,None,2018-12-11T12:01:56Z,2020-01-17T03:46:10Z
11829,Removed a useless check which can cause an infinite loop.,"### Summary

Here, we check if `inbound_layer_name` is in `created_layers`. If it is not, we delay the task and come back at it later on.

The problem is, if  `inbound_layer_name` is NOT in `created_layers`, it will never be because we don't modify the `created_layers` (last time this variable was modified was at line 1019 when we called `process_layer`).

This is very dangerous because it can tranform a simple keras bug (`KeyError`) into an infinite loop. 

And no one likes to debug infinite loops.

### Related Issues

### PR Overview

The check is removed. A `KeyError` is much better and it will make the code simpler to understand.

- [ ] This PR requires new unit tests [y/n] (make sure tests are included)
- [ ] This PR requires to update the documentation [y/n] (make sure the docs are up-to-date)
- [x] This PR is backwards compatible [y/n]
- [ ] This PR changes the current API [y/n] (all API changes need to be approved by fchollet)
",gabrieldemarmiesse,None,2018-12-09T16:52:37Z,2018-12-09T21:28:41Z
11807,Data generator shape checking,"Hello I am beginner in keras, currently I am using Keras 2.2.4 and tensorflow 1.9. MY problem is binary classification. I have a problem with memory so I load my data from directory using directory flow.
```
train_data_dir = 'data/train'
validation_data_dir = 'data/test'
test_data_dir = 'data/validation'
nb_train_samples = 857
nb_validation_samples = 216
nb_test_samples = 270
epochs = 50
batch_size = 32

if K.image_data_format() == 'channels_first':
    input_shape = (3, img_width, img_height)
else:
    input_shape = (img_width, img_height, 3)

# this is the augmentation configuration we will use for training
train_datagen = ImageDataGenerator(
    rescale=1. / 255,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True)

# this is the augmentation configuration we will use for testing:
# only rescaling
test_datagen = ImageDataGenerator(rescale=1. / 255)

train_generator = train_datagen.flow_from_directory(
    train_data_dir,
    target_size=(img_width, img_height),
    batch_size=batch_size,
    class_mode='binary')

validation_generator = test_datagen.flow_from_directory(
    validation_data_dir,
    target_size=(img_width, img_height),
    batch_size=batch_size,
    class_mode='binary')
```
Here is my model declaration, since I am using XCeption and want to do finetuning.
```
num_class = 2
# create the base pre-trained model
base_model = Xception(include_top=False, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000)

# add a global spatial average pooling layer
x = base_model.output
x = GlobalAveragePooling2D()(x)
# let's add a fully-connected layer
x = Dense(1024, activation='relu')(x)
# and a logistic layer -- let's say we have 2 classes
predictions = Dense(num_class, activation='softmax')(x)

# this is the model we will train
model = Model(inputs=base_model.input, outputs=predictions)
```
After I run, Keras successfully found the images. Which means no problem with the data loading
```
Found 857 images belonging to 2 classes.
Found 270 images belonging to 2 classes.
Found 216 images belonging to 2 classes.
```
```
model.compile(loss='binary_crossentropy',
              optimizer=Adam(lr=lr_schedule(0)),
              metrics=['accuracy'])
```
Here is the model summary.
![image](https://user-images.githubusercontent.com/2309538/49544364-a6a10500-f915-11e8-95e3-1b5ef4b107ff.png)

However when I am doing fitting process it said the output of the model and the train generator is not same.
```
model.fit_generator(
    generator=train_generator,
    steps_per_epoch=nb_train_samples // batch_size,
    epochs=50,
    validation_data=validation_generator,
    validation_steps=nb_validation_samples // batch_size,
    verbose=1, workers=4,
    callbacks=callbacks)
```
![image](https://user-images.githubusercontent.com/2309538/49544453-d5b77680-f915-11e8-9f17-b49c2990d275.png)

How to fixed this?, is there any way to debug it by printing the data input and target shape?, so we can check which side is wrong.
",herleeyandi,b'type:support',2018-12-05T21:15:26Z,2018-12-07T21:37:58Z
11804,"Error: InvalidArgumentError: Incompatible shapes, while training a RNN model on python 2.7 with accuracy metric","- [x] Check that you are up-to-date with the master branch of Keras. You can update with:
`pip install git+git://github.com/keras-team/keras.git --upgrade --no-deps`

- [x] Check that your version of TensorFlow is up-to-date. The installation instructions can be found [here](https://www.tensorflow.org/get_started/os_setup).

- [x] Provide a link to a GitHub Gist of a Python script that can reproduce your issue (or just copy the script here if it is short).

Python 2.7.12
The Keras version is 2.2.4
The tf version is 1.12.0

The issue is a continuation of [https://github.com/keras-team/keras/issues/11749](https://github.com/keras-team/keras/issues/11749) . I would suggest to read the linked issue thoroughly and to reproduce the bug before going ahead.

So, when we add the metric parameter in the model.compile method and train the RNN model, it throws an error:
```
InvalidArgumentError: Incompatible shapes: [9] vs. [3,3]
	 [[{{node metrics/acc/Equal}} = Equal[T=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](metrics/acc/Reshape, metrics/acc/Cast)]]
```
I was able to execute the code on python 3.5 but not on python 2.7 as it is raising the above error.

Points to remember:

1. The model is trained without raising an error when the batch size is 1, but while evaluating the model, it gives out an error.
2.  It works well when we don't mention the metric parameter in the model.compile method , later we have to create our custom metric method to get the desired kind of metrics.
3. It works on python 2.7  only when we convert the true labels into a hot vector and have the categorical loss function.
4. There's no issue with the _sparse_categorical_accuracy method_, as I executed the method independently with predicted labels and true labels as arguments on python 2.7 and it was working fine. The error raises only when I add the metric parameter in the model.compile method.

There seems to be an issue in the _fit_loop_ method when the model is being trained. I think the issue is with the keras callback function while it's calculating the metric. Will look more thoroughly into it.
Would like more perspectives on it. 

Regards.

",kaushikb11,b'To investigate',2018-12-05T15:38:12Z,2018-12-07T08:18:43Z
11792,Update readme to encourage virtualenv use,"`sudo pip` can cause system instabilities because it brings the system package manger (`apt`, `yum`, `pacman`, etc) into conflict with `pip` as to who ""owns"" a given package.  

In the worst case this can lead to damaged operating systems.  Normally it leads to damaged python installations, which present as hard to debug and semi-obscure `ModuleNotFound` errors.

These may be avoided by using `venv` or `virtualenv`, and their use should be encouraged.

### Summary

### Related Issues

### PR Overview

- [ ] This PR requires new unit tests [y/n] (make sure tests are included)
- [x] This PR requires to update the documentation [y/n] (make sure the docs are up-to-date)
- [x] This PR is backwards compatible [y/n]
- [ ] This PR changes the current API [y/n] (all API changes need to be approved by fchollet)
",gvoysey,None,2018-12-04T19:42:29Z,2018-12-09T21:32:00Z
11769,The method `evaluate` appears to fail on the following model:,"```python
    inputs = Input(shape=(3,))
    x = Dense(2)(inputs)
    outputs = Dense(3)(x)

    model = Model(inputs, outputs)
    model.compile(loss=losses.MSE,
                  optimizer=optimizers.Adam(),
                  metrics=['mse'],
                  weighted_metrics=['mse'])
```

This is due to the model expecting to be fed sample weights (due to the presence of a weighted metric) yet receiving none.

Note created by @fchollet in the ""Requests for contributions"".",gabrieldemarmiesse,b'stat:contributions welcome type:bug/performance',2018-12-02T12:57:29Z,2018-12-05T00:51:50Z
11753,Bug: Model summary is incorrect with custom layer,"- [x] Check that you are up-to-date with the master branch of Keras. You can update with:
`pip install git+git://github.com/keras-team/keras.git --upgrade --no-deps`

- [x] Check that your version of TensorFlow is up-to-date. The installation instructions can be found [here](https://www.tensorflow.org/get_started/os_setup).

- [x] Provide a link to a GitHub Gist of a Python script that can reproduce your issue (or just copy the script here if it is short).

*Issue*: I have a custom max pooling layer. It works similar to a normal max pooling in terms of dimensionality reduction. So from 32 x 32 to 16 x 16 with `padding=same` and `strides=2`. However I notice that `model.summary` reports the output shape to still be `32 x 32`

Here is the result of `model.summary`:
```
Layer (type)                 Output Shape              Param #
=================================================================
input_1 (InputLayer)         (None, 32, 32, 3)         0
_________________________________________________________________
conv (Conv2D)                (None, 32, 32, 96)        2688
_________________________________________________________________
reshape_conv (Reshape)       (None, 32, 32, 1, 96)     0
_________________________________________________________________
primary_caps (ConvCapsuleLay (None, 32, 32, 8, 96)     664320
_________________________________________________________________
caps_conv_1 (ConvCapsuleLaye (None, 32, 32, 8, 96)     664320
_________________________________________________________________
max_pool_caps_1 (CapsMaxPool (None, 32, 32, 8, 96)     0
_________________________________________________________________
caps_conv_2 (ConvCapsuleLaye (None, 32, 32, 12, 192)   1992960
_________________________________________________________________
caps_conv_3 (ConvCapsuleLaye (None, 32, 32, 12, 192)   3983616
_________________________________________________________________
max_pool_caps_2 (CapsMaxPool (None, 32, 32, 12, 192)   0
_________________________________________________________________
caps_conv_4 (ConvCapsuleLaye (None, 30, 30, 16, 192)   5311488
_________________________________________________________________
caps_conv_5 (ConvCapsuleLaye (None, 30, 30, 16, 192)   5311488
_________________________________________________________________
caps_conv_6 (ConvCapsuleLaye (None, 30, 30, 20, 10)    345800
_________________________________________________________________
caps_norm (CapsuleNorm)      (None, 30, 30, 20)        0
_________________________________________________________________
avg_pool (GlobalAveragePooli (None, 20)                0
_________________________________________________________________
subclass_out (Dense)         (None, 100)               2100
=================================================================
Total params: 18,278,780
Trainable params: 18,278,780
Non-trainable params: 0
```

Both `max_pool_caps_1` and `max_pool_caps_2` has `strides=(2,2)` and I would expect that `model.summary` would report the output to be 16 x 16 not 32 x 32 for `max_pool_caps_1` (the first two dimensions after `None`).

I checked that the output shape is indeed 16 x 16:
```python
max_pool_caps_1 = CapsMaxPool(pool_size=(3,3), strides=(2,2), padding='SAME', name='max_pool_caps_1')(caps_conv_1)
print('max_pool_caps_1 shape', max_pool_caps_1.shape)
```
and result is `max_pool_caps_1 shape (?, 16, 16, 8, 96)`

Now I tried to check inside the `build()` call of the next layer (which is also custom) and I get `caps_conv_2 build() input shape (None, 32, 32, 8, 96)`.

Then I tried to debug to Keras code where `build()` is called. It's called [here](https://github.com/keras-team/keras/blob/d18c564548104c862892a1f73423e333f11f7ce2/keras/engine/base_layer.py#L431). I printed `x_elem._keras_shape` and `x_elem.shape` and this is what I get
`caps_conv_2 x_elem shape (?, 16, 16, 8, 96) caps_conv_2 x_elem keras shape (None, 32, 32, 8, 96)`

Clearly it is wrong. I assume it would help to look at what my custom max pooling layer is doing and here it is:

```python
import tensorflow as tf
from keras.layers import Layer
from keras.utils.conv_utils import conv_output_length

class CapsMaxPool(Layer):
  def __init__(self, pool_size=(2,2), strides=None, padding='VALID', **kwargs):
    """"""Max pooling for [capsules]_

    Layer to perform max pooling given a previous capsule comprised (or treated)
    as capsules.

    Max pooling is done by taking the norm of the capsule which is interpreted as the
    probability of an entity (color, shade, line etc.) exists at a particular region
    of the data. Using the norm we run them through a ""filtering"", similar to usual
    2D max pool with pool size and strides, and choose the capsules which has the greatest
    norm in a particular pooling area over the whole input.

    :param pool_size: Pool size, defaults to (2,2)
    :type pool_size: tuple[int]|list[int], optional - Dimension should be [height x width]
    :param strides: Strides to take for the pooling (only consider along height and axis), defaults to None
    :type strides: tuple[int]|list[int], optional - Dimension should be [height x width]
    :param padding: Padding criteria: see [tensorflow convolution], defaults to 'VALID'
    :type padding: str, optional
    :param kwargs: Some common options to Keras layer
    :type kwargs: dict

    .. [capsules]: https://arxiv.org/pdf/1710.09829.pdf
    .. [tensorflow convolution]: https://www.tensorflow.org/api_guides/python/nn#Convolution
    .. note::
      The implementation is inspired and possible by the following resources:
      * https://www.tensorflow.org/api_docs/python/tf/nn/max_pool_with_argmax
      * https://www.tensorflow.org/api_docs/python/tf/gather_nd
    """"""
    if strides is None:
      strides = pool_size

    assert isinstance(pool_size, list) or isinstance(pool_size, tuple)
    assert len(pool_size) == 2, 'Pool size needs to be over height and width only'
    assert isinstance(strides, list) or isinstance(strides, tuple)
    assert len(strides) == 2, 'Strides need be over height and width only'

    # readjust pool size stride to have dimension [batch size x height x width x capsule channels]
    self.pool_size = [1,*pool_size,1]
    self.strides = [1,*strides,1]
    self.padding = padding
    super().__init__(**kwargs)

  def build(self, input_shape):
    # do nothing because there are no weights during pooling
    super().build(input_shape)

  def call(self, input):
    """"""Capsule max pool call

    Do the max pooling

    :param input: An input Tensor assumed to be coming from a capsule layer.
    :type input: Tensor, [batch size x height x width x capsule channels x atoms (instantiation parameters)]
    """"""
    assert input.shape.ndims == 5, 'Input rank needs to be 5'
    capsule_entity_probabilities = tf.norm(input, ord='euclidean', axis=-1)
    maxpooled_with_argmax = tf.nn.max_pool_with_argmax(
      capsule_entity_probabilities,
      ksize=self.pool_size,
      strides=self.strides,
      padding=self.padding,
      name='entity_probability_max_pool'
    )
    flattened_indices_of_greatest_probabilities = tf.reshape(maxpooled_with_argmax.argmax, shape=[-1], name='flattened_argmax')
    input_shape = input.shape
    input_dynamic_shape = tf.shape(input)
    # will only have two dimensions from here on out [rank x number of elements after max pool]
    unraveled_indices_of_greatest_probabilities = tf.unravel_index(
      flattened_indices_of_greatest_probabilities,
      dims=tf.cast(input_dynamic_shape[:-1], dtype=tf.int64),
      name='map_argmax_indices_to_original'
    )
    unraveled_indices_of_greatest_probabilities = tf.transpose(unraveled_indices_of_greatest_probabilities, (1,0))
    # shape will be rank
    max_pool_on_capsules = tf.gather_nd(
      input,
      indices = unraveled_indices_of_greatest_probabilities,
      name='max_pooling_over_capsules'
    )
    # reshape to be the same shape
    shape_after_maxpool = maxpooled_with_argmax.output.shape
    dynamic_shape_after_maxpool = tf.shape(maxpooled_with_argmax.output)
    shape_for_capsule_maxpool = [
      dynamic_shape_after_maxpool[0],
      shape_after_maxpool[1],
      shape_after_maxpool[2],
      shape_after_maxpool[3],
      input_shape[-1]
    ]
    max_pool_on_capsules = tf.reshape(max_pool_on_capsules, shape_for_capsule_maxpool, name='maxpooled_caps')
    max_pool_on_capsules.set_shape((None, shape_after_maxpool[1], shape_after_maxpool[2], shape_after_maxpool[3], input_shape[-1]))
    return max_pool_on_capsules

  def compute_input_shape(self, input_shape):
    """"""Compute input shape

    Function to compute end input shape result after max pooling.
    Adapted from https://github.com/keras-team/keras/blob/f899d0fb336cce4061093a575a573c4f897106e1/keras/layers/pooling.py#L180

    :param input_shape: Shape of input
    :type input_shape: Tensor, dimension [batch size x height x width x channels x instantiation parameters]
    """"""
    assert input_shape.shape.ndims == 5
    height = input_shape[1]
    width = input_shape[2]

    print(""COMPUTE INPUT SHAPE CALLED"")
    height = conv_output_length(height, self.pool_size[1], self.padding, self.strides[1])
    width = conv_output_length(width, self.pool_size[2], self.padding, self.strides[2])
    return (input_shape[0], height, width, input_shape[-2], input_shape[-1])
```

I can't run my model now, it would output some error about mismatching shapes later down the line in some operations and I assume this is causing that
",btruhand,b'To investigate',2018-11-29T04:38:25Z,2019-12-17T19:50:48Z
11731,keras.utils.Sequence keeps on sending index 0 in each call and training doesn't start,"Hi .. I tried to create a keras.utils.Sequence class which I can use for multi gpus in keras. See below for my implementation              

    class quickdrawSequence(Sequence):
        def __init__(self, size, batch_size, total_len):
            self.size = size
            self.total_len = total_len
            self.batch_size = batch_size
    
        def __len__(self):
            return self.total_len//self.batch_size
    
        def __draw(raw_strokes, size=256, lw=6, time_color=True):
            img = np.zeros((BASE_SIZE, BASE_SIZE), np.uint8)
            for t, stroke in enumerate(raw_strokes):
                for i in range(len(stroke[0]) - 1):
                    color = 255 - min(t, 10) * 13 if time_color else 255
                    _ = cv2.line(img, (stroke[0][i], stroke[1][i]),
                                 (stroke[0][i + 1], stroke[1][i + 1]), color, lw)
            if size != BASE_SIZE:
                return cv2.resize(img, (self.size, self.size))
            else:
                return img
    
        def __data_generation(self, skiprows):
            train_filename = os.path.join(BASE_DIR, 'data', 'train.csv')
            df = pd.read_csv(train_filename, 
                             header=None, 
                             skiprows=skiprows, 
                             nrows=self.batch_size)
            df[1] = df[1].apply(ast.literal_eval)
            x = np.zeros((len(df), self.size, self.size, 1))
            for i, raw_strokes in enumerate(df[1].values):
              x[i, :, :, 0] = self.__draw(raw_strokes)
            print('After rawstrokes processing:', x.shape)
            x = preprocess_input(x).astype(np.float32)
            y = keras.utils.to_categorical(df.y, num_classes=NCATS)
            print(x.shape, y.shape)
            return x,y
    
        def __getitem__(self, idx):
            skiprows = 1+(idx*self.batch_size)
            print(idx, skiprows)
            x,y = self.__data_generation(skiprows)
            return x, y

This is the `fit_generator` step

    hist = model.fit_generator(generator=quickdrawSequence(128, 512, 49673597),
                               steps_per_epoch=2000,
                               epochs=5,
                               verbose=1,
                               validation_data=(x_valid, y_valid),
                               callbacks=callbacks,
                               max_queue_size=2,
                               workers=2,
                               use_multiprocessing=True,
                               shuffle=True,
                               )

While running this with 2 gpus..The training doesn't start..and generator keeps on sending idx=0 indefinitely. I have printed `idx` for debugging purposes inside `__getitem__`. Below is what it prints.  

    Epoch 1/1
    74133 37956097
    36175 18521601
    0 1
    0 1
    0 1

Any idea what lacks in my code. 
There is a single `train.csv` that has all the data and I am trying to read each batch from this file using pandas `pd.read_csv` with `skiprows` &amp; `nrows`.          
Is there anything wrong that I am doing.      
I am on keras 2.2.4, TF 1.8 & Python 3.6.          
Also I have set `workers=2` and `max_queue_size=2` then shouldn't it stop after passing 2 indexes and wait for them to complete. While here it keeps on sending 0 and none of the batch gets completed and send for training.     ",AwasthiMaddy,b'type:support',2018-11-26T03:19:42Z,2020-04-15T08:25:20Z
11696,Fixing a confusing URL faliure error message in get_file() exception …,"…handler

### Summary
The error message of the URL failure exception handler in get_file() is confusing because the link showed up by the error message is appended with ':' without splitting and therefore included in the link itself. It always leads to an ""error 404"" page when clicking on it, so I suggest to split it from the url by a simple space ' ' in order to get the meant web page when debugging the error resulting code.
### Related Issues

### PR Overview

- [n] This PR requires new unit tests [y/n] (make sure tests are included)
- [n] This PR requires to update the documentation [y/n] (make sure the docs are up-to-date)
- [y] This PR is backwards compatible [y/n]
- [n] This PR changes the current API [y/n] (all API changes need to be approved by fchollet)
",OmarGhoneim,None,2018-11-20T19:41:26Z,2018-11-27T21:32:02Z
11681,Fix bug in sparse_top_k_categorical_accuracy,"### Summary
K.flatten doesn't work with n-dimensional labels. 
Use K.squeeze here - just like in sparse_categorical_accuracy
### Related Issues
https://github.com/keras-team/keras/pull/11373
### PR Overview

- [n] This PR requires new unit tests [y/n] (make sure tests are included)
- [n] This PR requires to update the documentation [y/n] (make sure the docs are up-to-date)
- [y] This PR is backwards compatible [y/n]
- [n] This PR changes the current API [y/n] (all API changes need to be approved by fchollet)
",KonstZ,None,2018-11-19T17:40:11Z,2018-11-19T19:14:22Z
11665,Poor memory performance of K.batch_dot under tensorflow backend relative to batched tf.matmul,"- [ x] Check that you are up-to-date with the master branch of Keras. You can update with:
`pip install git+git://github.com/keras-team/keras.git --upgrade --no-deps`

- [ x] Check that your version of TensorFlow is up-to-date. The installation instructions can be found [here](https://www.tensorflow.org/get_started/os_setup).

- [x ] Provide a link to a GitHub Gist of a Python script that can reproduce your issue (or just copy the script here if it is short).

I am performing batch matrix multiplies of two tensors of size (batch, N, M) and (batch, M, K) to get a tensor of size (batch, N, K), with the matrix products. This behavior can be done with both tf.matmul and K.batch_dot with the default axis arguments.

However in K.batch_dot, the elementwise multiplication in the line https://github.com/keras-team/keras/blob/75a35032e194a2d065b0071a9e786adf6cee83ea/keras/backend/tensorflow_backend.py#L1248 eats up a lot of memory. The elementwise multiplication followed by summing over an axis is of course mathematically equivalent to the matrix multiply, but in the two-step implementation, Tensorflow assigns memory to the intermediate very large tensor.

In this simple example, my small GPU (Nvidia 970) is able to perform the calculation using tf.matmul, but using K.batch_dot Tensorflow fails with an OOM error.

```
import numpy as np
import tensorflow as tf
from keras import backend as K

a = np.random.normal(size=(100, 500, 10000)).astype(np.float32)
b = np.random.normal(size=(100, 10000, 32)).astype(np.float32)

a_t = K.placeholder(a.shape)
b_t = K.placeholder(b.shape)

td = tf.matmul(a_t, b_t)
bd = K.batch_dot(a_t, b_t)

sess = K.get_session()
sess.run(td, feed_dict={a_t: a, b_t: b})
sess.run(bd, feed_dict={a_t: a, b_t: b})
```

This fails when it tries to assign a tensor of size (100, 10000, 500, 32) in the elementwise multiply in batch_dot (the dimension of 10000 not being strictly necessary in this case since we are only interested in the sum).",mawright,b'backend:tensorflow type:bug/performance',2018-11-18T07:38:53Z,2018-11-25T14:51:06Z
11663,Training the model and model predicting so different values,"I have the model which gets 3 inputs and gives 1 output using CNTK background. My output data consists of 2 numbers which can be between 0 and 15, so it could be [0,0] [12,8] [3,1] [15,15] etc so I expect two numbers between 0 and 15.

I use MSE as loss func and adam optimizer. when I try to train my model there are two things I ve noticed going on weirdly, 
1) the loss coming from MSE is about 50 at beginning, and when I predict something using my model, according to me the loss of that prediction was about 250 - 1000, I think it s so weird. 
2) after I train model the numbers are so different from what I want to get and train for, like I want numbers between 0 and 15, but the model gives me 1000-1500 as two numbers, why are they so big? and why my loss going to 0 and still it gives wrong numbers

```
input1 = Input(shape=(256,256,3))

model = Convolution2D(16, kernel_size=(3, 3), activation='relu')(input1)
model = MaxPooling2D(pool_size=(2,2))(model)
model = Dropout(0.2)(model)
model = Convolution2D(32, kernel_size=(3, 3), activation='relu')(model)
model = MaxPooling2D(pool_size=(2,2))(model)
model = Dropout(0.2)(model)
model = Convolution2D(64, kernel_size=(3, 3), activation='relu')(model)
model = MaxPooling2D(pool_size=(2,2))(model)
model = Dropout(0.2)(model)
model = Convolution2D(128, kernel_size=(3, 3), activation='relu')(model)
model = MaxPooling2D(pool_size=(2,2))(model)
model = Dropout(0.2)(model)
model = Convolution2D(156, kernel_size=(3, 3), activation='relu')(model)
model = MaxPooling2D(pool_size=(2,2))(model)
model = Dropout(0.2)(model)
model = Convolution2D(200, kernel_size=(3, 3), activation='relu')(model)
model = MaxPooling2D(pool_size=(2,2))(model)
model = Flatten()(model)

input3 = Input(shape=(256,256,1))

model3 = Convolution2D(16, kernel_size=(3, 3), activation='relu')(input3)
model3 = MaxPooling2D(pool_size=(2,2))(model3)
model3 = Dropout(0.2)(model3)
model3 = Convolution2D(32, kernel_size=(3, 3), activation='relu')(model3)
model3 = MaxPooling2D(pool_size=(2,2))(model3)
model3 = Dropout(0.2)(model3)
model3 = Convolution2D(64, kernel_size=(3, 3), activation='relu')(model3)
model3 = MaxPooling2D(pool_size=(2,2))(model3)
model3 = Dropout(0.2)(model3)
model3 = Convolution2D(128, kernel_size=(3, 3), activation='relu')(model3)
model3 = MaxPooling2D(pool_size=(2,2))(model3)
model3 = Dropout(0.2)(model3)
model3 = Convolution2D(256, kernel_size=(3, 3), activation='relu')(model3)
model3 = MaxPooling2D(pool_size=(2,2))(model3)
model3 = Dropout(0.2)(model3)
model3 = Convolution2D(400, kernel_size=(3, 3), activation='relu')(model3)
model3 = MaxPooling2D(pool_size=(2,2))(model3)
model3 = Flatten()(model3)


input2 = Input(shape=(3,))
model2 = Dense(20, activation='relu')(input2)
model2 = Dense(100, activation='relu')(model2)
model2 = Dense(200, activation='relu')(model2)
model2 = Dense(300, activation='relu')(model2)
model = concatenate([model, model3, model2])

model = Dropout(0.2)(model)
model = Dense(500, activation='relu')(model)
model = Dropout(0.2)(model)
model = Dense(200, activation='relu')(model)
model = Dropout(0.2)(model)
model = Dense(50, activation='relu')(model)
model = Dropout(0.2)(model)
output = Dense(2, activation='linear')(model)

model = Model(inputs=(input1, input2, input3), outputs=output)
 # 8. Compile model
model.compile(loss='mean_squared_error',
              optimizer= keras.optimizers.adam(lr=0.0005, decay=0), shuffle=True, metrics = ['MSE'])

history = model.fit([x_train, x2_train, x3_train] , y_train, 
          batch_size=40, epochs=10, verbose=1)

plt.plot(history.history['acc'])
plt.title('Model accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Train', 'Test'], loc='upper left')
plt.show()

# Plot training & validation loss values
plt.plot(history.history['loss'])
plt.title('Model loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Train', 'Test'], loc='upper left')
plt.show()
```
Is there some type of bug or am I doing things wrongly?",faruknane,None,2018-11-17T19:04:53Z,2018-11-17T19:09:36Z
11661,TensorBoard Callback write_images,"I want to use the TensorBoard callback to visualize my conv layer kernels. But i can only see the first conv layer kernel in TensorBoard and my Dense layers at the end. For the other conv layers i can just see the bias values and not the kernels.

Here is my sample code for the Keras model.
```
# Imports
import tensorflow as tf
import numpy as np
import os
from os import makedirs
from os.path import exists, join
from keras.datasets import mnist
import time

from keras.layers import *
from keras.activations import *
from keras.models import *
from keras.optimizers import *
from keras.initializers import *
from keras.callbacks import TensorBoard
from keras.callbacks import ModelCheckpoint
from keras.utils.np_utils import to_categorical

from plotting import *

log_dir = '""./""

# Load MNIST dataset
(x_train, y_train), (x_test, y_test) = mnist.load_data()

batch_size = 128
epochs = 10
width = 28
height = 28
depth = 1
num_classes = 10
train_size = x_train.shape[0]
test_size = x_test.shape[0]

x_train = x_train.reshape(train_size, width, height, depth)
y_train = to_categorical(y_train, num_classes=num_classes)
x_test = x_test.reshape(test_size, width, height, depth)
y_test = to_categorical(y_test, num_classes=num_classes)

tb = TensorBoard(
    log_dir=log_dir, 
    histogram_freq=1, 
    write_graph=True, 
    write_images=True)

# Define the DNN
model = Sequential()
model.add(Conv2D(filters=16, kernel_size=3, input_shape=(width, height, depth), name=""conv1""))
model.add(Activation(""relu""))
model.add(Conv2D(filters=20, kernel_size=3, name=""conv2""))
model.add(Activation(""relu""))
model.add(MaxPool2D())

model.add(Conv2D(filters=24, kernel_size=3, name=""conv3""))
model.add(Activation(""relu""))
model.add(Conv2D(filters=28, kernel_size=3, name=""conv4""))
model.add(Activation(""relu""))
model.add(MaxPool2D())

model.add(Flatten())
model.add(Dense(128))
model.add(Activation(""relu""))
model.add(Dense(num_classes, name=""features""))
model.add(Activation(""softmax""))

# Print the DNN layers
model.summary()

# Train the DNN
lr = 1e-3
optimizer = Adam(lr=lr)
model.compile(loss=""categorical_crossentropy"", optimizer=optimizer, metrics=[""accuracy""])
model.fit(x_train, y_train, verbose=1, batch_size=batch_size, epochs=epochs, validation_data=(x_test, y_test), callbacks=[tb])

# Test the DNN
score = model.evaluate(x_test, y_test, batch_size=batch_size)
print(""Test performance: "", score)
```
Here is the resulting screenshot from TensorBoard.
![unbenannt](https://user-images.githubusercontent.com/20141069/48664190-37b15880-ea9b-11e8-9339-aad7acf1a8cd.png)
",franneck94,b'backend:tensorflow type:bug/performance',2018-11-17T18:02:35Z,2020-05-06T01:40:46Z
11660,Added a decorator for flaky tests which rerun the test on specific errors.,"### Summary

Let's be frank, this PR is putting our flaky tests under the rug. This is obviously a bad thing to do, but they are hard to reproduce and fix, and won't be fixed right now.

We still have the issues open for the flaky tests (tagged as ""flaky test"" and ""bug""). And it's also easy to do a search for `@flaky` to find all the flaky tests in the codebase. I think it's a better option than to disable them.

For tests where it's possible, I'll split them, making them smaller, and making them easier to debug. (Idea taken from https://testing.googleblog.com/2017/04/where-do-our-flaky-tests-come-from.html). But for me to do a PR, I'll need the build to pass.

### Related Issues

### PR Overview

See https://github.com/box/flaky for usages.

- [ ] This PR requires new unit tests [y/n] (make sure tests are included)
- [ ] This PR requires to update the documentation [y/n] (make sure the docs are up-to-date)
- [x] This PR is backwards compatible [y/n]
- [ ] This PR changes the current API [y/n] (all API changes need to be approved by fchollet)
",gabrieldemarmiesse,None,2018-11-17T15:06:53Z,2018-11-25T14:27:38Z
11658,KerasRegressor.predict does not squeeze batch dims,"### Summary
If the input to KerasRegressor.predict() is an array with one example, then the output should be a 1D array with one example, not a 0D array.

### Related Issues
Fixes #11657 

### PR Overview

- [X] This PR requires new unit tests [n] (make sure tests are included)
It's a pretty minor change, but I'm willing to add tests if requested.
- [X] This PR requires to update the documentation [n] (make sure the docs are up-to-date):
It makes the code match the documentation, which claims the output has shape `(n_samples,)`
- [x] This PR is backwards compatible [n]:
It fixes a bug that caused behaviour inconsistent with both the scikit-learn API and the documentation for KerasRegressor and would only appear if the input data has exactly one example. Technically users could be depending on the buggy behaviour, but it seems unlikely to me.
- [X] This PR changes the current API [n] (all API changes need to be approved by fchollet)
",edlanglois,None,2018-11-16T23:41:10Z,2018-12-09T14:28:29Z
11657,Scikit Learn wrapper predict() inappropriately squashes size-1 batch dimension,"Please make sure that the boxes below are checked before you submit your issue.
If your issue is an **implementation question**, please ask your question on [StackOverflow](http://stackoverflow.com/questions/tagged/keras) or [on the Keras Slack channel](https://keras-slack-autojoin.herokuapp.com/) instead of opening a GitHub issue.

Thank you!

- [X] Check that you are up-to-date with the master branch of Keras. You can update with:
`pip install git+git://github.com/keras-team/keras.git --upgrade --no-deps`
Using Keras version 2.2.4

- [X] Check that your version of TensorFlow is up-to-date. The installation instructions can be found [here](https://www.tensorflow.org/get_started/os_setup).
Using Tensorflow version 1.12.0

- [X] Provide a link to a GitHub Gist of a Python script that can reproduce your issue (or just copy the script here if it is short).

If predict() is called on input with shape `(1, num_features)`, then the output is a 0-dimensional array instead of a 1-dimensional array with 1 element.

```python
import keras
import keras.wrappers.scikit_learn
import numpy as np
import sklearn.linear_model
import sklearn.metrics

def build_net():
    model = keras.models.Sequential([keras.layers.Dense(units=1, input_dim=2)])
    model.compile(loss=keras.losses.mean_squared_error, optimizer=""sgd"")
    return model

regressor = keras.wrappers.scikit_learn.KerasRegressor(build_fn=build_net)
# Works with the sklearn regressors
# regressor = sklearn.linear_model.LinearRegression()
X = np.zeros((1, 2))
Y = np.zeros((1,))
regressor.fit(X, Y)
Y_pred = regressor.predict(X)
print(Y_pred.shape)  # Is (), should be (1,)
# As a result, this fails with an exception
# TypeError: Singleton array array(0., dtype=float32) cannot be considered a valid collection.
print(sklearn.metrics.mean_squared_error(y_true=Y, y_pred=Y_pred))
```",edlanglois,b'type:bug/performance',2018-11-16T23:22:24Z,2018-12-09T14:28:28Z
11634,Using fit_generator and keras.utils.Sequence does not work when use_multiprocessing=True with workers > 1 ,"Hi, as said in the title, if set use_multiprocessing=True while using fit_generator and keras.utils.Sequence the code get stuck and the gpu activity remains at 0%. No errors are shown.

I am using keras 2.2.2 in Ubuntu 18.04.1 LTS.
I am seeing the displayed information:

2018-11-14 11:10:27.834657: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2018-11-14 11:10:28.009869: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1105] Found device 0 with properties: 
name: GeForce GTX 1080 major: 6 minor: 1 memoryClockRate(GHz): 1.7335
pciBusID: 0000:02:00.0
totalMemory: 7.93GiB freeMemory: 7.81GiB
2018-11-14 11:10:28.163209: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1105] Found device 1 with properties: 
name: GeForce GTX 1080 major: 6 minor: 1 memoryClockRate(GHz): 1.7335
pciBusID: 0000:03:00.0
totalMemory: 7.93GiB freeMemory: 7.81GiB
2018-11-14 11:10:28.164488: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Device peer to peer matrix
2018-11-14 11:10:28.164532: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1126] DMA: 0 1 
2018-11-14 11:10:28.164542: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1136] 0:   Y Y 
2018-11-14 11:10:28.164549: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1136] 1:   Y Y 
2018-11-14 11:10:28.164561: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1195] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: GeForce GTX 1080, pci bus id: 0000:02:00.0, compute capability: 6.1)
2018-11-14 11:10:28.164569: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1195] Creating TensorFlow device (/device:GPU:1) -> (device: 1, name: GeForce GTX 1080, pci bus id: 0000:03:00.0, compute capability: 6.1)
",Schiboni,b'backend:tensorflow stat:awaiting response type:bug/performance',2018-11-14T10:46:05Z,2018-11-28T21:53:09Z
11617,ValueError: Unknown layer:name ,"I am getting 
**ValueError: Unknown layer:name**
when I use the following code
`model = load_model('cartpole.h5')`
**_This is a bit strange as I am not using any custom objects in my model.It_** might be a bug.
The full error 
` File ""E:\New folder\tensorflow\core\venv\app\deepq\main.py"", line 24, in <module>
    model = load_model('cartpole.h5'')
  File ""E:\New folder\tensorflow\core\venv\lib\site-packages\keras\engine\saving.py"", line 260, in load_model
    model = model_from_config(model_config, custom_objects=custom_objects)
  File ""E:\New folder\tensorflow\core\venv\lib\site-packages\keras\engine\saving.py"", line 334, in model_from_config
    return deserialize(config, custom_objects=custom_objects)
  File ""E:\New folder\tensorflow\core\venv\lib\site-packages\keras\layers\__init__.py"", line 55, in deserialize
    printable_module_name='layer')
  File ""E:\New folder\tensorflow\core\venv\lib\site-packages\keras\utils\generic_utils.py"", line 145, in deserialize_keras_object
    list(custom_objects.items())))
  File ""E:\New folder\tensorflow\core\venv\lib\site-packages\keras\engine\sequential.py"", line 292, in from_config
    custom_objects=custom_objects)
  File ""E:\New folder\tensorflow\core\venv\lib\site-packages\keras\layers\__init__.py"", line 55, in deserialize
    printable_module_name='layer')
  File ""E:\New folder\tensorflow\core\venv\lib\site-packages\keras\utils\generic_utils.py"", line 165, in deserialize_keras_object
    ':' + function_name)
ValueError: Unknown layer:name`
I have keras version 2.2.2
Thanks for the feedback

",Aryanr64x,b'To investigate',2018-11-11T08:46:37Z,2020-03-14T03:26:42Z
11603,Hangs before training starts,"I am using Keras 2.2.4 (it also happens on 2.2.0). Training is not starting at all. Even after waiting for 12 hours. I am using Xception (but even a simple model as shown below results the same thing). The following `fit` generates the following log

```
model.fit_generator(
    train_generator,
    steps_per_epoch=nb_train_samples // batch_size,
    epochs=epochs,
    validation_data=validation_generator,
    validation_steps=nb_validation_samples // batch_size,
    # class_weight=class_weights,
    callbacks=[
        reduce_lr,
        checkpoint #,
        # tensorboard
    ],
    verbose=1)
```

For the following configuration parameters:

```
nb_train_samples = 142785
nb_validation_samples = 10000
epochs = 10
patience = 20
batch_size = 16
number_of_classes = 2
```
With the following simple model or Xception or anything else problem is the same:

```
def simple_model():
    model = Sequential(name='simple_model')
    model.add(Conv2D(32, (3, 3), input_shape=input_shape))
    model.add(Activation('relu'))
    model.add(MaxPooling2D(pool_size=(2, 2)))

    model.add(Conv2D(32, (3, 3)))
    model.add(Activation('relu'))
    model.add(MaxPooling2D(pool_size=(2, 2)))

    model.add(Conv2D(64, (3, 3)))
    model.add(Activation('relu'))
    model.add(MaxPooling2D(pool_size=(2, 2)))

    model.add(Conv2D(128, (3, 3)))
    model.add(Activation('relu'))
    model.add(MaxPooling2D(pool_size=(2, 2)))

    model.add(Flatten())
    model.add(Dense(64))
    model.add(Activation('relu'))
    model.add(Dropout(0.5))
    model.add(Dense(number_of_classes, activation='softmax'))

    return model
``` 

```
Using TensorFlow backend.
2018-11-07 23:17:33.919972: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-11-07 23:17:33.920367: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1356] Found device 0 with properties:
name: GeForce GTX 1070 major: 6 minor: 1 memoryClockRate(GHz): 1.721
pciBusID: 0000:01:00.0
totalMemory: 7.93GiB freeMemory: 7.83GiB
2018-11-07 23:17:33.920382: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1435] Adding visible gpu devices: 0
2018-11-07 23:17:34.135313: I tensorflow/core/common_runtime/gpu/gpu_device.cc:923] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-11-07 23:17:34.135508: I tensorflow/core/common_runtime/gpu/gpu_device.cc:929]      0
2018-11-07 23:17:34.135574: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 0:   N
2018-11-07 23:17:34.135772: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7568 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1)
Found 142785 images belonging to 2 classes.
Found 10000 images belonging to 2 classes.
Epoch 1/10
```

The GPU is not being used at all, as it shows 0% usage. I have tried to force the CPU usage to see if that was a problem related to GPU communication or whatnot, but the it also hangs  with the `""Epoch 1/10""` when using CPU forever.

```
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 390.87                 Driver Version: 390.87                    |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  GeForce GTX 1070    Off  | 00000000:01:00.0 Off |                  N/A |
|  0%   53C    P8    12W / 151W |   7721MiB /  8117MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+

+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID   Type   Process name                             Usage      |
|=============================================================================|
|    0     26075      C   python                                      7711MiB |
+-----------------------------------------------------------------------------+
```

I am wondering what are the possible causes of such problem? I am having a hard time to debug it properly as not log is out and no apparent problems seems to exist. Any suggestion is welcome. Thanks in advance.",edumucelli,b'To investigate backend:tensorflow',2018-11-07T22:34:17Z,2018-11-12T00:38:40Z
11602,Adding a job for tf 1.12. This job can fail without making travis fail.,"### Summary
This PR is to track possible bugs that we would have by upgrading TF, this will allow us to fix those bugs progressively if there are a lot of them (possible since it's a big jump).

### Related Issues

#11348

### PR Overview

- [ ] This PR requires new unit tests [y/n] (make sure tests are included)
- [ ] This PR requires to update the documentation [y/n] (make sure the docs are up-to-date)
- [x] This PR is backwards compatible [y/n]
- [ ] This PR changes the current API [y/n] (all API changes need to be approved by fchollet)
",gabrieldemarmiesse,None,2018-11-07T22:21:11Z,2018-11-16T08:14:31Z
11588,Fixed loading bug for shared layers accross multiple depths,"### Summary
There is a bug in the from_config method of the Keras Network class. This bug occurs when loading a model from a config when a layer that is shared at multiple depths and the input tensors to the shared layer are not in the order of the layers in the model config file.

Note that if we change the order that we apply the shared layer so that model layer order changes this bug is not triggered. The code to reproduce the bug including code to create the layers in an order that doesn't trigger the bug is on this gist:
https://gist.github.com/adocherty/5f5c9983310ef2cf28e3ccb63ad39740

### Related Issues
This applies the fix in issue #11159 

### PR Overview

- [n] This PR requires new unit tests [y/n] (make sure tests are included)
- [n] This PR requires to update the documentation [y/n] (make sure the docs are up-to-date)
- [y] This PR is backwards compatible [y/n]
- [n] This PR changes the current API [y/n] (all API changes need to be approved by fchollet)
",adocherty,None,2018-11-05T22:27:55Z,2019-01-22T22:47:32Z
11543,ValueError: Expecting object: line 1 column 26 (char 25),"Here is the error that comes out randomly. I use `fit_generator` to read data from file on disk.
So what is the hidden bug infered from the error message.
```
 789/5000 [===>..........................] - ETA: 1:59:05 - loss: 0.0217 - mean_absolute_error: 0.0651
 790/5000 [===>..........................] - ETA: 1:58:58 - loss: 0.0217 - mean_absolute_error: 0.0651
 791/5000 [===>..........................] - ETA: 1:58:51 - loss: 0.0217 - mean_absolute_error: 0.0650
 792/5000 [===>..........................] - ETA: 1:58:44 - loss: 0.0217 - mean_absolute_error: 0.0650Traceback (most recent call last):
  File ""main_train_pure_topics.py"", line 222, in <module>
    epochs=40, verbose=1, callbacks = callbacks_list)
  File ""/usr/local/lib/python2.7/dist-packages/keras/legacy/interfaces.py"", line 91, in wrapper
    return func(*args, **kwargs)
  File ""/usr/local/lib/python2.7/dist-packages/keras/engine/training.py"", line 1418, in fit_generator
    initial_epoch=initial_epoch)
  File ""/usr/local/lib/python2.7/dist-packages/keras/engine/training_generator.py"", line 181, in fit_generator
    generator_output = next(output_generator)
  File ""/usr/local/lib/python2.7/dist-packages/keras/utils/data_utils.py"", line 709, in get
    six.reraise(*sys.exc_info())
  File ""/usr/local/lib/python2.7/dist-packages/keras/utils/data_utils.py"", line 685, in get
    inputs = self.queue.get(block=True).get()
  File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get
    raise self._value
ValueError: Expecting object: line 1 column 26 (char 25)
```",yananchen1989,None,2018-11-01T10:11:22Z,2018-11-01T12:12:53Z
11542,Fix incorrect assertion syntax in example,"This reverts a minor bug in the example code that was introduced in #10968.

You can't safely wrap an `assert` body with parens, because it makes it a tuple, and assertion of a tuple either always succeeds (if non-empty) or always throws (if empty).

```py
assert condition, ""message"" # correct
assert (condition, ""message"") # incorrect, will never throw
```

This could cause confusion for beginners reading the examples so I thought I'd bring it up.",jonstaryuk,None,2018-11-01T05:38:13Z,2018-11-01T22:55:00Z
11532,[BUG] Bug in adadelta optimizer's learning rate,"The learning rate is not part of the original AdaDelta algorithm. If we want to add it as a parameter, it should be considered as part of the `update` variable in order to accumulate it into the `delta_accumulators` variable, if not, when it reaches a local minimum it starts bouncing and no total convergence is achieved.

I.e. we should add the actual update in the numerator of the LR adjustment



",ivallesp,None,2018-10-30T19:52:49Z,2019-09-11T21:42:09Z
11508,bug fix: can't use code blocks in multiple sections in docstrings.,"### Summary

Having blocks of code in multiple sections of the same docstring breaks the rendering of the documentation. To see exactly what I mean, see the test which I added.

### Related Issues

### PR Overview

The problem came from this line:
https://github.com/keras-team/keras/blob/267ccbb4a76913680f4db6b400e05dea7aa84db7/docs/autogen.py#L456

Because the `replace` was used on the full docstring (not the slice of the docstring correnponding to the section being worked on), even code blocks which were in other sections were replaced.

So as the parser progressed, some code blocks were replaced multiple times, and the parser lost the content of the last blocks of code, because the parser only remember what it just replaced. 
See this line which does it: https://github.com/keras-team/keras/blob/267ccbb4a76913680f4db6b400e05dea7aa84db7/docs/autogen.py#L453

When we arrive at this line for the last code block, the code isn't there, only the marker. So the marker gets saved instead of `$CODE_BLOCK_%d`. 

Feel free to use a debugger to understand what I mean. I hope I was clear enough. I advise the reviewer to be very careful, as this PR can potentially break many pages in the docs. I checked most of them, but well... we never know.

- [ ] This PR requires new unit tests [y/n] (make sure tests are included)
- [ ] This PR requires to update the documentation [y/n] (make sure the docs are up-to-date)
- [x] This PR is backwards compatible [y/n]
- [ ] This PR changes the current API [y/n] (all API changes need to be approved by fchollet)
",gabrieldemarmiesse,None,2018-10-27T19:36:10Z,2018-10-29T19:44:41Z
11498,Bug in K.rnn masking of output and states when they have more than 2 dimensions ,"**Summary**
Outputs and states are not masked correctly in `tensorflow_backend.rnn` when the number of dimensions of any of these is larger than 2. The issue is that masks are only ""tiled"" along the second dimension of outputs/states, see e.g. this [line](https://github.com/keras-team/keras/blob/master/keras/backend/tensorflow_backend.py#L2943). Note that the docs [does not state](https://github.com/keras-team/keras/blob/master/keras/backend/tensorflow_backend.py#L2854) that outputs or states should be restricted to 2 dimensions.

**Examples replicating the issue**
Output ndim > 2
```
n_samples = 3
n_timesteps = 4

def step_function(inputs, states):
    outputs = K.tile(K.expand_dims(inputs), [1, 1, 2])
    return outputs, states

inputs_vals = np.ones((n_samples, n_timesteps, 5))
inputs_vals[:, -1] = 0  # this should be ignored due to mask
initial_state_vals = [np.ones((n_samples, 6))]
mask_vals = np.ones((n_samples, n_timesteps))
mask_vals[:, -1] = 0  # final timestep masked

inputs = K.variable(inputs_vals)
initial_state = [K.variable(initial_state_vals[0])]
mask = K.variable(mask_vals)
for unroll in [True , False]:
    last_output, outputs, last_states = K.rnn(
        step_function,
        inputs,
        initial_state,
        mask=mask,
        unroll=unroll)

    expected_outputs = np.ones((n_samples, n_timesteps, 5, 2))
    assert_allclose(K.eval(outputs), expected_outputs)
```
Gives:
```
ValueError: Shapes must be equal rank, but are 3 and 2 for 'Select' (op: 'Select') with input shapes: [3,5], [3,5,2], [3,5,2].
```

States ndim > 2
```
n_samples = 3
n_timesteps = 4

def step_function(inputs, states):
    return inputs, [s + 1 for s in states]

inputs_vals = np.ones((n_samples, n_timesteps, 5))
initial_state_vals = [np.zeros((n_samples, 6, 6))]
mask_vals = np.ones((n_samples, n_timesteps))
mask_vals[:, -1] = 0  # final timestep masked

inputs = K.variable(inputs_vals)
initial_state = [K.variable(initial_state_vals[0])]
mask = K.variable(mask_vals)
for unroll in [True , False]:
    last_output, outputs, last_states = K.rnn(
        step_function,
        inputs,
        initial_state,
        mask=mask,
        unroll=unroll)
    # not updated last timestep:
    expected_last_state = np.ones((n_samples, 6, 6)) * (n_timesteps - 1)
    assert_allclose(K.eval(last_states[0]), expected_last_state)
```
Gives:
```
ValueError: Shapes must be equal rank, but are 3 and 2 for 'Select_1' (op: 'Select') with input shapes: [3,6], [3,6,6], [3,6,6]
```

**Further Implications**
Becasue of this, masking does not work for e.g. `ConvLSTM2D`, modified unit test below:
```
def test_convolutional_recurrent():

    class Masking5D(Masking):
        """"""Regular masking layer returns wrong shape of mask for RNN""""""
        def compute_mask(self, inputs, mask=None):
            return K.any(K.not_equal(inputs, 0.), axis=[2, 3, 4])

    for data_format in ['channels_first', 'channels_last']:

        if data_format == 'channels_first':
            inputs = np.random.rand(num_samples, sequence_len,
                                    input_channel,
                                    input_num_row, input_num_col)
        else:
            inputs = np.random.rand(num_samples, sequence_len,
                                    input_num_row, input_num_col,
                                    input_channel)

        for use_mask in [False, True]:  # MODIFIED
            for return_sequences in [True, False]:
                # test for return state:
                x = Input(batch_shape=inputs.shape)
                kwargs = {'data_format': data_format,
                          'return_sequences': return_sequences,
                          'return_state': True,
                          'stateful': True,
                          'filters': filters,
                          'kernel_size': (num_row, num_col),
                          'padding': 'valid'}
                layer = convolutional_recurrent.ConvLSTM2D(**kwargs)
                layer.build(inputs.shape)
                
                # MODIFIED
                if use_mask:
                    outputs = layer(Masking5D()(x))
                else:
                    outputs = layer(x)
                
                output, states = outputs[0], outputs[1:]
                assert len(states) == 2
                model = Model(x, states[0])
                state = model.predict(inputs)
                np.testing.assert_allclose(
                    K.eval(layer.states[0]), state, atol=1e-4)

                # test for output shape:
                output = layer_test(convolutional_recurrent.ConvLSTM2D,
                                    kwargs={'data_format': data_format,
                                            'return_sequences': return_sequences,
                                            'filters': filters,
                                            'kernel_size': (num_row, num_col),
                                            'padding': 'valid'},
                                    input_shape=inputs.shape)
```
Gives:
```
ValueError: Dimension must be 2 but is 5 for 'conv_lst_m2d_5/transpose_1' (op: 'Transpose') with input shapes: [1,2], [5]
``` ",andhus,None,2018-10-26T17:00:21Z,2018-11-05T23:33:49Z
11489,"Possible bug, that using pretrained ResNet50 results in contradictory losses in training and validation set?","I'm using ResNet50 pretrained model as building block for a Unet:

    def ResNet50(include_top=True, weights='imagenet',
             input_tensor=None, input_shape=None,
             pooling=None,
             classes=1000):
    if weights not in {'imagenet', None}:
        raise ValueError('The `weights` argument should be either '
                         '`None` (random initialization) or `imagenet` '
                         '(pre-training on ImageNet).')

    if weights == 'imagenet' and include_top and classes != 1000:
        raise ValueError('If using `weights` as imagenet with `include_top`'
                         ' as true, `classes` should be 1000')

    if input_tensor is None:
        img_input = Input(shape=input_shape)
    else:
        if not K.is_keras_tensor(input_tensor):
            img_input = Input(tensor=input_tensor, shape=input_shape)
        else:
            img_input = input_tensor
    if K.image_data_format() == 'channels_last':
        bn_axis = 3
    else:
        bn_axis = 1

    x = Conv2D(64, (7, 7), strides=(2, 2), padding='same', name='conv1')(img_input)
    x = BatchNormalization(axis=bn_axis, name='bn_conv1')(x)
    x = Activation('relu')(x)
    x = MaxPooling2D((3, 3), strides=(2, 2), padding=""same"")(x)

    x = conv_block(x, 3, [64, 64, 256], stage=2, block='a', strides=(1, 1))
    x = identity_block(x, 3, [64, 64, 256], stage=2, block='b')
    x = identity_block(x, 3, [64, 64, 256], stage=2, block='c')

    x = conv_block(x, 3, [128, 128, 512], stage=3, block='a')
    x = identity_block(x, 3, [128, 128, 512], stage=3, block='b')
    x = identity_block(x, 3, [128, 128, 512], stage=3, block='c')
    x = identity_block(x, 3, [128, 128, 512], stage=3, block='d')

    x = conv_block(x, 3, [256, 256, 1024], stage=4, block='a')
    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='b')
    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='c')
    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='d')
    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='e')
    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='f')

    x = conv_block(x, 3, [512, 512, 2048], stage=5, block='a')
    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='b')
    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='c')

    # Ensure that the model takes into account
    # any potential predecessors of `input_tensor`.
    if input_tensor is not None:
        inputs = get_source_inputs(input_tensor)
    else:
        inputs = img_input
    # Create model.
    model = Model(inputs, x, name='resnet50')

    # load weights
    if weights == 'imagenet':
        if include_top:
            weights_path = get_file('resnet50_weights_tf_dim_ordering_tf_kernels.h5',
                                    WEIGHTS_PATH,
                                    cache_subdir='models',
                                    md5_hash='a7b3fe01876f51b976af0dea6bc144eb')
        else:
            weights_path = get_file('resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5',
                                    WEIGHTS_PATH_NO_TOP,
                                    cache_subdir='models',
                                    md5_hash='a268eb855778b3df3c7506639542a6af')
        model.load_weights(weights_path,by_name=True)
    return model

Creating the Unet:

    def conv_block_simple(prevlayer, filters, prefix, strides=(1, 1)):
    conv = Conv2D(filters, (3, 3), padding=""same"", kernel_initializer=""he_normal"", strides=strides, name=prefix + ""_conv"")(prevlayer)
    conv = BatchNormalization(name=prefix + ""_bn"")(conv)
    conv = Activation('relu', name=prefix + ""_activation"")(conv)
    return conv 

    def conv_block_simple_no_bn(prevlayer, filters, prefix, strides=(1, 1)):
    conv = Conv2D(filters, (3, 3), padding=""same"", kernel_initializer=""he_normal"", strides=strides, name=prefix + ""_conv"")(prevlayer)
    conv = Activation('relu', name=prefix + ""_activation"")(conv)
    return conv

    K.clear_session()

    def get_unet_resnet(input_shape):
        resnet_base = ResNet50(input_shape=input_shape, include_top=False)
        
        for l in resnet_base.layers:
            l.trainable = False 
    
    
        conv1 = resnet_base.get_layer(""activation_1"").output
        conv2 = resnet_base.get_layer(""activation_10"").output
        conv3 = resnet_base.get_layer(""activation_22"").output
        conv4 = resnet_base.get_layer(""activation_40"").output
        conv5 = resnet_base.get_layer(""activation_49"").output
    
        up6 = concatenate([UpSampling2D()(conv5), conv4], axis=-1)
        conv6 = conv_block_simple(up6, 256, ""conv6_1"")
        conv6 = conv_block_simple(conv6, 256, ""conv6_2"")
    
        up7 = concatenate([UpSampling2D()(conv6), conv3], axis=-1)
        conv7 = conv_block_simple(up7, 192, ""conv7_1"")
        conv7 = conv_block_simple(conv7, 192, ""conv7_2"")
    
        up8 = concatenate([UpSampling2D()(conv7), conv2], axis=-1)
        conv8 = conv_block_simple(up8, 128, ""conv8_1"")
        conv8 = conv_block_simple(conv8, 128, ""conv8_2"")
    
        up9 = concatenate([UpSampling2D()(conv8), conv1], axis=-1)
        conv9 = conv_block_simple(up9, 64, ""conv9_1"")
        conv9 = conv_block_simple(conv9, 64, ""conv9_2"")
    
        up10 = UpSampling2D()(conv9)
        conv10 = conv_block_simple(up10, 32, ""conv10_1"")
        conv10 = conv_block_simple(conv10, 32, ""conv10_2"")
        conv10 = SpatialDropout2D(0.2)(conv10)
        x = Conv2D(1, (1, 1), activation=""sigmoid"", name=""prediction"")(conv10)
        
        model = Model(resnet_base.input, x)
        
        model.summary()
        
        return model

I freezed the pretrained ResNet50 layers as proposed in several papers:

    for l in resnet_base.layers:
        l.trainable = False 

Without the freezing the network works fine, but tends to hugely overfit, which I decreased with higher `SpatialDropout2D()` value. 
When I freeze it however the train losses decrease but the validation losses circulate about some weird high value but actually stagnate.
I can't figure out, why the frozen network do work on training set, meanwhile it doesn't on validation set. I see no logical reason for it (on my current knowledge level).

I tried playing with learning rate, but no success.

What could be the problem?
Any help would be highly appreciated.
Thank you.",matthewmav,b'type:support',2018-10-25T12:39:42Z,2018-12-11T10:11:59Z
11488,BatchNormalization center and scale flags swapped,"Please make sure that the boxes below are checked before you submit your issue.
If your issue is an **implementation question**, please ask your question on [StackOverflow](http://stackoverflow.com/questions/tagged/keras) or [on the Keras Slack channel](https://keras-slack-autojoin.herokuapp.com/) instead of opening a GitHub issue.

Thank you!

- [ ] Check that you are up-to-date with the master branch of Keras. You can update with:
`pip install git+git://github.com/keras-team/keras.git --upgrade --no-deps`

- [ ] Check that your version of TensorFlow is up-to-date. The installation instructions can be found [here](https://www.tensorflow.org/get_started/os_setup).

- [ ] Provide a link to a GitHub Gist of a Python script that can reproduce your issue (or just copy the script here if it is short).

I know the description above urges the use of latest versions, but I cant use those sadly; but I doubt it has any bearing on this bug anyway. These are the packages I am using:
TF 1.8.0, conda-forge
Keras 2.2.4, conda-forge

I have an input tensor with strictly positive values, that I would like to have normalised in scale; without losing the positivity.

From reading the docstring and underlying code, it seems clear that this should be accomplished with the center=False kwarg. However, in practice it seem that using scale=False gives me the expected high level behavior.

Digging in a little deeper, I can indeed verify that I pass on only positive values; yet that right after the BN with center=False, I may end up with negative values (even though they ought only to have been scaled). And this does not happen with scale=False.

It seems to me that somewhere in the (very long) calling chain, these flags are getting swapped in meaning. I havnt been able to pin down where this happens; but as for a stylistic suggestion, that may be related to this... There is a lot of calling of functions with lots of arguments going on, without using kwarg names explicitly at the calling site. Having a long list of positional arguments without an obvious implied ordering makes for code that is very hard to check for correctness!",EelcoHoogendoorn,b'To investigate',2018-10-25T11:28:14Z,2018-10-25T15:09:03Z
11487,"fit generator adds yields to each ""epoch""","Hello,

I wanted to check the behaviour of my generator in order to fit a model and I noticed that my generator actually yield more than **x** steps defined in arguments. Outputs and code speak more than words.

The following output is what i logged. I put as ""commentary"" some shortcuts to shorten this for you, you get the idea

```
// .... 
DEBUG - Fitting the model :: 14 training steps to expect
DEBUG - Fitting the model :: 2 validation steps to expect
DEBUG - Number of train_docs : 220
DEBUG - Number of train_labels : 220
DEBUG - Number of val_docs : 25
DEBUG - Number of val_labels : 25
Epoch 1/250
DEBUG - [train] starting epoch.
DEBUG - [train] number of steps : 14
DEBUG - [train] number of docs : 220
DEBUG - [train] number of labels : 220
DEBUG - [train] yielding 0:16
// 13 more yields log printing
DEBUG - [train] starting epoch.
DEBUG - [train] number of steps : 14
DEBUG - [train] number of docs : 220
DEBUG - [train] number of labels : 220
DEBUG - [train] yielding 0:16
// 9 more yields log printing
DEBUG - [val] starting epoch.
DEBUG - [val] number of steps : 2
DEBUG - [val] number of docs : 25
DEBUG - [val] number of labels : 25
DEBUG - [val] yielding 0:16
DEBUG - [val] yielding 16:32
// The 6 previous lines are printed again 5 times
 - 18s - loss: 1.0193 - categorical_accuracy: 0.4955 - val_loss: 0.9229 - val_categorical_accuracy: 0.6400
```

So for the first epoch, before the `fit_generator` consider it as one epoch, my loop yields 24 times instead of 14 times (2 'epochs') for the training generator and 10 times instead of 2 (5 'epochs').

Here is the main code used to get these results :

```python
def generator(self, type, docs, labels, steps, predict=False):  # TODO: remove (type)
  # vectorizing stuff, getting X and y 
  
  while True:
    self.logger.debug(""[{}] starting epoch."".format(type))  # TODO: remove after debugging
    self.logger.debug(""[{}] number of steps : {}"".format(type, steps))  # TODO: remove after debugging
    self.logger.debug(""[{}] number of docs : {}"".format(type, len(docs)))  # TODO: remove after debugging
    self.logger.debug(""[{}] number of labels : {}"".format(type, len(labels)))  # TODO: remove after debugging

    indices = list(range(len(docs)))
    if not predict:
      indices = np.random.permutation(indices)

    for bi in range(steps):
      batch = indices[(bi * self.batch_size):((bi + 1) * self.batch_size)]
      self.logger.debug(""[{}] yielding {}:{}"".format(
        type,
        bi * self.batch_size,
        (bi + 1) * self.batch_size))
      yield X[batch] if predict else (X[batch], y[batch])
```

this is a class method, `self.batch_size = 16` FYI 
Then the `fit_generator` is called like this :

```python
# ...
self.logger.debug(""Number of train_docs : {}"".format(len(train_docs)))  # TODO : remove
self.logger.debug(""Number of train_labels : {}"".format(len(train_labels)))  # TODO : remove
self.logger.debug(""Number of val_docs : {}"".format(len(val_docs)))  # TODO : remove
self.logger.debug(""Number of val_labels : {}"".format(len(val_labels)))  # TODO : remove
self.model.fit_generator(
  self.generator('train', train_docs, train_labels, training_steps),
  validation_data=self.generator('val', val_docs, val_labels, validation_steps),
  epochs=self.epochs,
  steps_per_epoch=training_steps,
  validation_steps=validation_steps,
  callbacks=[early_stopping, board],
  verbose=2)
```

TL;DR : I can't understand why keras consider epochs being finish after **exactly** ten yields more than the number precised in arguments. My **while loop** is not bad though because it restarts after the good number of steps.

What did I miss ? 

Thank you :) ",luccitan,None,2018-10-25T10:07:11Z,2019-02-20T16:47:36Z
11473,"Fix bug in masking of output in tensorflow_backend.rnn(..., unroll=False)","### Summary
Fixes https://github.com/keras-team/keras/issues/11472 for tensorflow backend.

### PR Overview
- [y] This PR requires new unit tests [y/n] (make sure tests are included)
- [n] This PR requires to update the documentation [y/n] (make sure the docs are up-to-date)
- [y] This PR is backwards compatible [y/n]
- [n] This PR changes the current API [y/n] (all API changes need to be approved by fchollet)",andhus,None,2018-10-24T07:46:47Z,2018-11-02T23:10:56Z
11472,"Bug in masking of output in K.rnn(..., unroll=False) (for tensorflow and cntk)","**Summary**
Outputs are not masked correctly in `tensorflow_backend.rnn(..., unroll=False)`. The issue is that `states[0]` is assumed to be equal to the `output` of the `step_function` in this [line](https://github.com/keras-team/keras/blob/master/keras/backend/tensorflow_backend.py#L2976) (not so in other backends or with `unroll=True`). This holds for the built-in RNNCells, which is the reason the bug has gone undetected. Especially since the [introduction of `output_size` in the RNNCell](https://github.com/keras-team/keras/commit/66f8cc7ac4942f7f9fe0164a2a854a6264b87735) it is clear that this should not generally be assumed.

**Implications**
1) `RNN` returns the wrong output when mask is used and the `output` is not equal to `states[0]` _but has same size_ - i.e. a **quiet error**:
```
class Cell(keras.layers.Layer):

    def __init__(self):
        self.state_size = None
        self.output_size = None
        super(Cell, self).__init__()

    def build(self, input_shape):
        self.state_size = input_shape[-1]
        self.output_size = input_shape[-1]

    def call(self, inputs, states):
        return inputs, [s + 1 for s in states]

x = Input((3, 1), name=""x"")
x_masked = Masking()(x)
s_0 = Input((1,), name=""s_0"")
y, s = recurrent.RNN(Cell(),
                     return_state=True,
                     unroll=False)(x_masked, initial_state=s_0)
model = Model([x, s_0], [y, s])
model.compile(optimizer='sgd', loss='mse')

# last time step masked
x_arr = np.array([[[1.],[2.],[0.]]])
s_0_arr = np.array([[10.]])
y_arr, s_arr = model.predict([x_arr, s_0_arr])

# 1 is added to initial state two times
assert_allclose(s_arr, s_0_arr + 2)
# expect last output to be the same as last output before masking
assert_allclose(y_arr, x_arr[:, 1, :])  # Fails!
```
Gives:
```
       AssertionError: 
       Not equal to tolerance rtol=1e-07, atol=0
       
       (mismatch 100.0%)
        x: array([12.], dtype=float32)
        y: array([2.])
```

2) Exception is raised when trying to apply an RNN with a cell which `output_size != state_size[0]`
```
class Cell(keras.layers.Layer):

    def __init__(self):
        self.state_size = None
        self.output_size = None
        super(Cell, self).__init__()

    def build(self, input_shape):
        self.state_size = input_shape[-1]
        self.output_size = input_shape[-1] * 2

    def call(self, inputs, states):
        return keras.layers.concatenate([inputs]*2), [s + 1 for s in states]

x = Input((3, 1), name=""x"")
x_masked = Masking()(x)
s_0 = Input((1,), name=""s_0"")
y, s = recurrent.RNN(Cell(),
                     return_state=True,
                     unroll=False)(x_masked, initial_state=s_0)  # Fails!
```
Gives:
```
ValueError: Dimension 1 in both shapes must be equal, but are 2 and 1. Shapes are [?,2] and [?,1]. for 'rnn_1/while/Select' (op: 'Select') with input shapes: [?,?], [?,2], [?,1].
```",andhus,None,2018-10-24T07:44:41Z,2018-11-05T23:33:48Z
11462,Flaky test on travis: Failed: DID NOT RAISE <type 'exceptions.RuntimeError'>,"We have this flaky test on travis:

```
=================================== FAILURES ===================================
______________________ test_generator_enqueuer_threadsafe ______________________
[gw1] linux2 -- Python 2.7.15 /home/travis/miniconda/envs/test-environment/bin/python
    def test_generator_enqueuer_threadsafe():
        enqueuer = GeneratorEnqueuer(create_generator_from_sequence_pcs(
            DummySequence([3, 200, 200, 3])), use_multiprocessing=False)
        enqueuer.start(3, 10)
        gen_output = enqueuer.get()
        with pytest.raises(RuntimeError) as e:
>           [next(gen_output) for _ in range(10)]
E           Failed: DID NOT RAISE <type 'exceptions.RuntimeError'>
tests/keras/utils/data_utils_test.py:207: Failed
```

See the full log here: https://travis-ci.org/keras-team/keras/jobs/444740254

This issue is to track this bug and see if we can find a way to solve it.
@Dref360 ",gabrieldemarmiesse,b'stat:contributions welcome',2018-10-23T10:43:18Z,2018-10-25T14:14:25Z
11458,Bug fix: Batch dot,"* Almost total rewrite of `batch_dot` for Tensorflow and CNTK backend.
* Fixes various bugs in edge cases(e.g #11035)
* Rewrite `batch_dot` implementation in `reference_operations.py`  (had bugs and overall implementation was bloated)
* Does early input validation with helpful messages.
* Earlier, the methods had partial `tf.tensordot()` like behavior, which was undocumented. This was possibly a bug first introduced in TF backend and the logic was probably copied when writing the CNTK backend. This now returns with a helpful error message.
* Reduces number of ops as much as possible.
* Slightly better docstrings
* Thorough unit tests.
 ",farizrahman4u,None,2018-10-23T06:15:11Z,2018-10-26T22:39:26Z
11427,Fine-tuned VGG model.evaluate() and confusion matrix give different evaluation,"I have been struggling with this issue for a while and I'm starting to think that it might be more than just an implementation problem. 

After fine tuning a Keras VGG 16 on my dataset and getting good accuracy on both Training and Validation sets, I try to evaluate it on my Testing set. However, the two methods I use give me very contradicting results. While Keras model.evaluate() shows a good accuracy, the confusion matrix shows a really bad one. 

This is the script I am using:

```
from sklearn.metrics import classification_report, confusion_matrix
import keras
from keras import backend as K
from keras.preprocessing.image import ImageDataGenerator
import numpy as np
from keras.models import load_model


image_size = 224
test_dir = 'D:/pytorch-pwc-master/DataSet_Prince - flow/test'
test_batchsize = 9


test_datagen = ImageDataGenerator(rescale=1./255)
test_generator = test_datagen.flow_from_directory(
        test_dir,
        target_size=(image_size, image_size),
        batch_size=test_batchsize,
        class_mode='categorical',
        shuffle=True)

FLOW1_model = load_model('VGG_FLOW1.h5')

#Confusion Matrix and Classification Report
Y_pred = FLOW1_model.predict_generator(test_generator, test_generator.samples // test_generator.batch_size)
y_pred = np.argmax(Y_pred, axis=1)
print('Confusion Matrix')
print(confusion_matrix(test_generator.classes, y_pred))
print('Classification Report')
target_names = ['Bark', 'Jump', 'Stand','Walk']
print(classification_report(test_generator.classes, y_pred, target_names=target_names))


#Evaluating using Keras model_evaluate:
x, y = zip(*(test_generator[i] for i in range(len(test_generator))))
x_test, y_test = np.vstack(x), np.vstack(y)
loss, acc = FLOW1_model.evaluate(x_test, y_test, batch_size=64)

print(""Accuracy: "" ,acc)
print(""Loss: "", loss)
```

And these are the results I get:

Confusion Matrix and Report:

```
Confusion Matrix
[[66 53 70 81]
 [64 70 61 75]
 [67 71 64 68]
 [64 65 57 84]]
Classification Report
             precision    recall  f1-score   support

       Bark       0.25      0.24      0.25       270
       Jump       0.27      0.26      0.26       270
      Stand       0.25      0.24      0.25       270
       Walk       0.27      0.31      0.29       270

avg / total       0.26      0.26      0.26      1080
```

And then the evaluate:

```
Accuracy:  0.8601851860682169
Loss:  0.40207018432793795
```

What can be the cause of this issue ? I tried training again and again but still similar results. Even when I try to predict my training dataset and use the confusion matrix/report it gives me similar weird results. As if the prediction is evenly split among the 4 classes.

My environment: Anaconda 3. Python 3.6. Windows 10 64bits, Keras 2.1.1 Tensorflow-gpu 1.4.0

Any help/advice will be very appreciated. I am starting to believe there is a bug somewhere...

",Wazaki-Ou,b'To investigate',2018-10-18T08:35:49Z,2018-10-19T13:07:08Z
11378,Parametrizing the metrics tests to get one test per metric.,"### Summary

We can take advantage of pytest's error reporting when testing metrics to get one test per metric and have better insights in case of bugs.

### Related Issues

### PR Overview

- [ ] This PR requires new unit tests [y/n] (make sure tests are included)
- [ ] This PR requires to update the documentation [y/n] (make sure the docs are up-to-date)
- [x] This PR is backwards compatible [y/n]
- [ ] This PR changes the current API [y/n] (all API changes need to be approved by fchollet)
",gabrieldemarmiesse,None,2018-10-13T11:33:39Z,2018-11-07T17:05:52Z
11373, Fix bug in sparse_categorical_accuracy ,"### Summary

With reccurent layer output of the model can be `[num_samples, timesteps, output_dim]`, but in the `sparse_categorical_accuracy` for `y_true` values `Flatten` is used. That creates a bug like ""Incompatible shapes: [80] vs. [16,5]"" (if timesteps=16 and output_dim=5).
Bug fixed by adding `Flatten` to `K.cast(K.argmax(y_pred, axis=-1), K.floatx()))` too.

### Related Issues

#11100

### PR Overview

- [ ] This PR requires new unit tests [y/n] (make sure tests are included)
- [ ] This PR requires to update the documentation [y/n] (make sure the docs are up-to-date)
- [x] This PR is backwards compatible [y/n]
- [ ] This PR changes the current API [y/n] (all API changes need to be approved by fchollet)
",DaniyarM,None,2018-10-12T12:21:11Z,2018-10-13T18:22:49Z
11336,Converted the print calls in the backend package initialization into Python logging calls,"### Summary

This pull request converts the print calls in the backend package initialization (responsible of printing on stderr the ""Using X backend"" messages) into Python logging calls; so that the application(s) consuming the Keras library do not end up with these messages in between their logging on stderr and are free to handle the Keras logging at their discretion.

The log level for the ""Using X backend"" messages has been set to ""debug"" since if everything is working as expected there is no need to inform about which backend is being used. On the other hand, I understand that maintainers might want to elevate this specific message to an ""info"".

### Related Issues
#1406
#11332

###  PR Overview
[n] This PR requires new unit tests [y/n] (make sure tests are included)
[y] This PR requires to update the documentation [y/n] (make sure the docs are up-to-date)
[y] This PR is backwards compatible [y/n]
[n] This PR changes the current API [y/n] (all API changes need to be approved by fchollet)
",sarusso,None,2018-10-08T23:21:40Z,2018-10-12T12:41:59Z
11333,[REMOVED due to a missing edit in the doc] Converted the print calls in the backend package initialization into Python logging calls,"### Summary

This pull request moves from printing on stderr the ""Using X backend"" message to sending it to the Python logging module in the backend package `__init__.py` file.

The log level for these messages has been set to ""debug"" as if everything works as expected there is no need to inform about which backend is used. On the other hand, I understand that maintainers might want to elevate this specific message to an ""info"".

### Related Issues

### PR Overview

- [n] This PR requires new unit tests [y/n] (make sure tests are included)
- [y] This PR requires to update the documentation [y/n] (make sure the docs are up-to-date)
- [y] This PR is backwards compatible [y/n]
- [n] This PR changes the current API [y/n] (all API changes need to be approved by fchollet)
",sarusso,None,2018-10-08T19:16:33Z,2018-10-08T23:40:18Z
11289,Bug fix: model save when file already exists,"### Summary

### Related Issues

### PR Overview

- [y ] This PR requires new unit tests [y/n] (make sure tests are included)
- [n ] This PR requires to update the documentation [y/n] (make sure the docs are up-to-date)
- [y ] This PR is backwards compatible [y/n]
- [n ] This PR changes the current API [y/n] (all API changes need to be approved by fchollet)
",farizrahman4u,None,2018-10-03T15:38:31Z,2018-10-03T18:51:29Z
11276,ModelCheckpoint not saving best version due to issue with opening h5py file,"Having checked that everything is as it should be (latest version of keras, and latest version of tensorflow both installed), I have found that running a model with a model checkpoint callback that saves the best model so far causes an issue with serialisation of the model. 

[Here's a script which, when run, shows the issue.](https://gist.github.com/Microno95/cc3a34ba54cc4e7f646ce971486f57ee)

The output during imports and initialisation of the Tensorflow backend is:

~~~~
2018-10-02 12:34:47.868073: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: GeForce GTX 1080 major: 6 minor: 1 memoryClockRate(GHz): 1.7335
pciBusID: 0000:03:00.0
totalMemory: 7.93GiB freeMemory: 7.09GiB
2018-10-02 12:34:47.868102: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2018-10-02 12:34:48.075527: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-10-02 12:34:48.075556: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2018-10-02 12:34:48.075562: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2018-10-02 12:34:48.075728: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6837 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080, pci bus id: 0000:03:00.0, compute capability: 6.1)
Using TensorFlow backend.
2018-10-02 12:34:51.635814: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2018-10-02 12:34:51.635853: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-10-02 12:34:51.635859: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2018-10-02 12:34:51.635863: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2018-10-02 12:34:51.636042: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6837 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080, pci bus id: 0000:03:00.0, compute capability: 6.1)
~~~~

The full error traceback is:

~~~~
Traceback (most recent call last):
  File ""selfcontained.py"", line 107, in <module>
    print(""75th percentile of test predictions is: {:.2e}"".format(main(**CNN_params)))
  File ""selfcontained.py"", line 92, in main
    raise e
  File ""selfcontained.py"", line 76, in main
    shuffle=True, verbose=0, callbacks=[early_stopping_cb, model_saver_cb, test_csv_cb])
  File ""/home/persephone/anaconda3/lib/python3.6/site-packages/keras/engine/training.py"", line 1039, in fit
    validation_steps=validation_steps)
  File ""/home/persephone/anaconda3/lib/python3.6/site-packages/keras/engine/training_arrays.py"", line 217, in fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File ""/home/persephone/anaconda3/lib/python3.6/site-packages/keras/callbacks.py"", line 79, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File ""/home/persephone/anaconda3/lib/python3.6/site-packages/keras/callbacks.py"", line 446, in on_epoch_end
    self.model.save(filepath, overwrite=True)
  File ""/home/persephone/anaconda3/lib/python3.6/site-packages/keras/engine/network.py"", line 1090, in save
    save_model(self, filepath, overwrite, include_optimizer)
  File ""/home/persephone/anaconda3/lib/python3.6/site-packages/keras/engine/saving.py"", line 382, in save_model
    _serialize_model(model, f, include_optimizer)
  File ""/home/persephone/anaconda3/lib/python3.6/site-packages/keras/engine/saving.py"", line 78, in _serialize_model
    f['keras_version'] = str(keras_version).encode('utf8')
  File ""/home/persephone/anaconda3/lib/python3.6/site-packages/keras/utils/io_utils.py"", line 214, in __setitem__
    'Group with name ""{}"" exists.'.format(attr))
KeyError: 'Cannot set attribute. Group with name ""keras_version"" exists.'
~~~~

The problem seems to arise from the fact that the mode flag for opening an h5py file is not propagated through the h5dict class in keras/utils/io_utils.py when opening the file, thus the h5py file is opened with default flags that prevent overwriting existing files. 

The solution is simple (unless I am missing a key aspect of file management when it comes to serialisation) where line 186 in keras/utils/io_utils.py needs to be changed from 

```python
185        elif isinstance(path, str):
>>> 186            self.data = h5py.File(path,)
187            self._is_file = True
```

to

```python
185        elif isinstance(path, str):
>>> 186            self.data = h5py.File(path,mode)
187            self._is_file = True
```

Doing this propagates the mode parameter in the __init__ call to the underlying h5py.File object. 

As I'm not sure what the best way to submit a code patch is, I thought it would be best to create an issue outlining the problem and a potential solution.",Microno95,b'stat:contributions welcome type:bug/performance',2018-10-02T11:49:44Z,2019-07-16T16:18:18Z
11275,Unable to use load_model with Keras 2.2.3,"After updating Keras to 2.2.3 and using Tensorflow version 1.11.0, I am unable to load saved models. 

I am running a script on Google Cloud's Debian machine and am able to save and load the model there, but I am facing the error ""UnboundLocalError: local variable 'name' referenced before assignment"" when calling load_model on my local Ubuntu machine.",nole-lin,b'type:bug/performance',2018-10-02T04:21:34Z,2018-10-05T06:13:42Z
11263,Added a global timeout for the test suite.,"### Summary

The stalling build is a big issue. We need tools to be able to debug it.
I believe we should merge this into master and wait until we have the timeout issue again to see a stacktrace.

### Related Issues

### PR Overview

If the test suite is taking more than 12 minutes to run, stop the run and give a stacktrace.

- [ ] This PR requires new unit tests [y/n] (make sure tests are included)
- [ ] This PR requires to update the documentation [y/n] (make sure the docs are up-to-date)
- [x] This PR is backwards compatible [y/n]
- [ ] This PR changes the current API [y/n] (all API changes need to be approved by fchollet)
",gabrieldemarmiesse,None,2018-09-30T18:49:26Z,2018-11-07T17:05:31Z
11260,Travis was ignoring PEP8 failures. Now fixed.,"### Summary

Before, Travis was ignoring PEP8 failures. I think it was since #11163. My take on it is that travis only cares about the last exit code (with `$?` or something like that) after each instruction (at each `-` symbol). I think chaining the instructions with `&&` will solve the issue.

### Related Issues

#11163
#11258
#11254

### PR Overview

There is the fix of travis.yml and also fixing the pep8 errors which were merged into master since the apparition of the bug.

- [ ] This PR requires new unit tests [y/n] (make sure tests are included)
- [ ] This PR requires to update the documentation [y/n] (make sure the docs are up-to-date)
- [x] This PR is backwards compatible [y/n]
- [ ] This PR changes the current API [y/n] (all API changes need to be approved by fchollet)
",gabrieldemarmiesse,None,2018-09-30T15:21:57Z,2018-11-07T17:05:34Z
11242,"Fix h5py error ""Unable to create attribute (object header message is too large)""","### Summary

Fixes a minor bug introduced by https://github.com/keras-team/keras/commit/9a4c5d8f10667e571c23f1b2f2e0397a85368bea: The `H5Dict` object tried to save (large) `numpy` objects without the `dataset` interface from `h5py`. This produced the error ` Unable to create attribute (object header message is too large)`

### Related Issues

https://github.com/keras-team/keras/issues/11104
https://github.com/Skuldur/Classical-Piano-Composer/issues/8

### PR Overview

- [ ] This PR requires new unit tests [y/n] (make sure tests are included)
- [ ] This PR requires to update the documentation [y/n] (make sure the docs are up-to-date)
- [x] This PR is backwards compatible [y/n]
- [ ] This PR changes the current API [y/n] (all API changes need to be approved by fchollet)
",lvapeab,None,2018-09-28T09:51:19Z,2018-09-28T18:43:08Z
11217,Enhance error text for Model.summary(),"For following python script,

```
from keras.models import Sequential
from keras.layers import Dense,Conv2D, Flatten

model=Sequential()
model.add(Conv2D(10,(3,3)))
model.add(Conv2D(10,(3,3)))
model.add(Flatten())
model.add(Dense(20))
model.add(Dense(10))

model.compile(loss='categorical_crossentropy',
              optimizer='sgd',
              metrics=['accuracy'])

model.summary()

```

In the keras version [2.2.2](https://github.com/keras-team/keras/releases/tag/2.2.2), the error message is like following

```
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
<ipython-input-83-30ace2d20b7d> in <module>()
     13               metrics=['accuracy'])
     14 
---> 15 model.summary()

/opt/conda/lib/python3.6/site-packages/keras/engine/network.py in summary(self, line_length, positions, print_fn)
   1245         if not self.built:
   1246             raise ValueError(
-> 1247                 'This model has never been called, thus its weights '
   1248                 'have not yet been created, so no summary can be displayed. '
   1249                 'Build the model first '

ValueError: This model has never been called, thus its weights have not yet been created, so no summary can be displayed. Build the model first (e.g. by calling it on some test data).
```

But in the keras version [2.1.6](https://github.com/keras-team/keras/releases/tag/2.1.6), it is like following
```
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
<ipython-input-8-30ace2d20b7d> in <module>()
      3 
      4 model=Sequential()
----> 5 model.add(Conv2D(10,(3,3)))
      6 model.add(Conv2D(10,(3,3)))
      7 model.add(Flatten())

/usr/local/lib/python3.6/dist-packages/keras/models.py in add(self, layer)
    482                     # know about its input shape. Otherwise, that's an error.
    483                     if not hasattr(layer, 'batch_input_shape'):
--> 484                         raise ValueError('The first layer in a '
    485                                          'Sequential model must '
    486                                          'get an `input_shape` or '

ValueError: The first layer in a Sequential model must get an `input_shape` or `batch_input_shape` argument.
```

**The difference here is that version 2.1.6 doesn't allow to add the first layer if input_shape is missing and version 2.2.2 allows to build the model even if input shape is missing**. I am new to this repository so, I am not sure about it but I think that keras 2.2.2 will figure out input_shape when fit() is called for the first time, and that is being suggested by error msg in version 2.2.2. From looking at the code I can say that it is checking whether or not the model is built or not before calling summary utility.

But error message seems misleading, it asks to fit the model before calling summary() but many times we need to see the number of parameters and output shapes (especially CNN) before actually training. And it is very likely that such error will occur due to **not specifying ""input_shape"" by mistake. And in such scenario debugging the error will be very difficult.**

So i am suggesting following error message

```
ValueError: This model has not yet been built, so no summary can be displayed. Build the model first (e.g. by calling it on some test data) or specify the 'input_shape' in the first layer
```

**Above suggested error message would help in debugging if ""input_shape"" is not specified due to a mistake and creating a model which computes input shape on the go is not the intention**

 **I will be happy to send PR to fix this issue, but I want to discuss it with the community first.**


Issue Guidelines List : 
- [X] Check that you are up-to-date with the master branch of Keras. You can update with:
pip install git+git://github.com/keras-team/keras.git --upgrade --no-deps

- [X] If running on TensorFlow, check that you are up-to-date with the latest version. The installation instructions can be found [here](https://www.tensorflow.org/get_started/os_setup).
   
    _Used keras 2.2.2 and 2.1.6_

- [X] If running on Theano, check that you are up-to-date with the master branch of Theano. You can update with:
pip install git+git://github.com/Theano/Theano.git --upgrade --no-deps

     _I am using tensorflow backend_

- [X] Provide a link to a GitHub Gist of a Python script that can reproduce your issue (or just copy the script here if it is short).
     
   _Provided above_
",blue-atom,b'Enhancement stat:contributions welcome',2018-09-24T19:00:39Z,2018-12-24T04:20:04Z
11196,Fix bug in sparse_top_k_categorical_accuracy,"### Summary
For the input of ```sparse_top_k_categorical_accuracy```, the shape of ```y_true``` can be ```(num_samples, 1)``` or ```(num_samples,)```.
* Train with Numpy array, the shape of ```y_true``` is ```(num_samples, 1)```. Because ```y_true``` is feed with a placeholder which is generated according the shape of ```y_pred```.
* Train with TensorFlow dataset API, the shape of ```y_true``` is _usually_ ```(num_samples,)``` according your input.

https://github.com/tensorflow/tensorflow/issues/22190 has reported a relevant bug.
#11100 has fixed this issue for ```sparse_categorical_accuracy```, this PR add the same fix for ```sparse_top_k_categorical_accuracy```.

### Related Issues
#11100
https://github.com/tensorflow/tensorflow/issues/22190
https://github.com/tensorflow/tensorflow/pull/22392

### PR Overview

- [x] This PR requires new unit tests [y/n] (make sure tests are included)
- [ ] This PR requires to update the documentation [y/n] (make sure the docs are up-to-date)
- [x] This PR is backwards compatible [y/n]
- [ ] This PR changes the current API [y/n] (all API changes need to be approved by fchollet)
",yanboliang,None,2018-09-22T01:49:39Z,2018-09-24T18:36:27Z
11177,Tensorflow / CNTK compatibility issue for index selection,"The simple code

```
from keras import backend as K

var = K.ones(shape=(3, 4, 5))

print(var[...,1].shape)
```
gives (3, 4) under Tensorflow backend
gives (3,4,1) under CNTK backend.
",christopher5106,b'type:bug/performance wontfix',2018-09-18T19:44:36Z,2018-09-19T07:47:49Z
11159,Bug in loading model with shared layers accross multiple levels.,"There is a bug in the `from_config` method of the Keras Network class. This bug occurs when loading a model from a config when the model uses a layer that is shared at *multiple depths* and the input tensors to the shared layer are not in the order of the layers in the model config file. 

For example, the following model creates a single dense layer then applies it to the reshaped input `x2`. It is then applied to the non-reshaped input `x1`, and again at the reshaped output.
```
sl = Dense(12)

x2 = Input((1, 12))
r2 = Reshape((12,))(x2)
r21 = sl(r2)

x1 = Input((1, 12))
r1 = Reshape((12,))(sl(x1))

r11 = sl(r1)
c1 = Concatenate()([r11, r21])
o1 = Dense(2)(c1)
```

The layers of the model are as follows:
```
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to
==================================================================================================
input_2 (InputLayer)            (None, 1, 12)        0
__________________________________________________________________________________________________
dense_1 (Dense)                 multiple             156         reshape_1[0][0]
                                                                 input_2[0][0]
                                                                 reshape_2[0][0]
__________________________________________________________________________________________________
input_1 (InputLayer)            (None, 1, 12)        0
__________________________________________________________________________________________________
reshape_2 (Reshape)             (None, 12)           0           dense_1[1][0]
__________________________________________________________________________________________________
reshape_1 (Reshape)             (None, 12)           0           input_1[0][0]
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 24)           0           dense_1[2][0]
                                                                 dense_1[0][0]
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 2)            50          concatenate_1[0][0]
==================================================================================================
```

Note that the `dense_2` layer has `reshape_1` and `reshape_2` as inputs but those layers come after `dense_2` in the list of layers.

The code in `keras/engine/network.py` contains the `from_config` method that loads the model. Then loading, the layer order of above is followed when recreating the model. At each layer Keras attempts to deserialize the layer using the inputs. When trying to deserialize  the `dense_2` layer Keras tries to create the first output but cannot because the input layers `reshape_1` aren't available, Keras next tries to create the second output using `input_2` which works because these layers are available. Keras will re-queue the first node (and third node) and will creates it at the next attempt when the input layers are available, unfortunately in doing this it swaps the output order of the output nodes of the `dense_2` layer. The model loading then fails at the `concatenate_1` layer as it uses the output nodes [0] and [2] of `dense_2` but the output node [0] is now from `input_2` which has the incorrect shape.

Note that if we change the order that we apply the shared layer so that model layer order changes this bug can be avoided. The code to reproduce the bug including code to create the layers in an order that doesn't trigger the bug is on this gist:
https://gist.github.com/adocherty/5f5c9983310ef2cf28e3ccb63ad39740

The error triggered by this script is as follows:
```
  File ""example_load_bug.py"", line 57, in <module>
    models.load_model(""test.h5"")
  File "".../lib/python3.6/site-packages/keras/engine/saving.py"", line 260, in load_model
    model = model_from_config(model_config, custom_objects=custom_objects)
  File "".../lib/python3.6/site-packages/keras/engine/saving.py"", line 334, in model_from_config
    return deserialize(config, custom_objects=custom_objects)
  File "".../lib/python3.6/site-packages/keras/layers/__init__.py"", line 55, in deserialize
    printable_module_name='layer')
  File "".../lib/python3.6/site-packages/keras/utils/generic_utils.py"", line 145, in deserialize_keras_object
    list(custom_objects.items())))
  File "".../lib/python3.6/site-packages/keras/engine/network.py"", line 1027, in from_config
    process_node(layer, node_data)
  File "".../lib/python3.6/site-packages/keras/engine/network.py"", line 986, in process_node
    layer(unpack_singleton(input_tensors), **kwargs)
  File "".../lib/python3.6/site-packages/keras/engine/base_layer.py"", line 431, in __call__
    self.build(unpack_singleton(input_shapes))
  File "".../lib/python3.6/site-packages/keras/layers/merge.py"", line 354, in build
    'Got inputs shapes: %s' % (input_shape))
ValueError: A `Concatenate` layer requires inputs with matching shapes except for the concat axis. Got inputs shapes: [(None, 12), (None, 1, 12)]
```",adocherty,b'To investigate',2018-09-17T02:27:15Z,2019-01-22T20:16:28Z
11145,Can not train the VGG-16 OR Resnet-50 Normally In Keras（Loss Stable）,"The main code is as follows:
![issue](https://user-images.githubusercontent.com/25716030/45582351-b98cd600-b8e0-11e8-9234-3165cab6b717.png)
![issue2](https://user-images.githubusercontent.com/25716030/45582479-581a3680-b8e3-11e8-89f4-a786237354bd.png)
![issue3](https://user-images.githubusercontent.com/25716030/45582480-5badbd80-b8e3-11e8-9e5a-061db382a65b.png)

I make a model which has 3 input and make vgg-16 be its feature extractor.
I want to do similarity measure after feature extraction.
But I failed to train it on the official vgg model and successfully train it on my own sequential CNN model.
The loss is always const.
I change the lr to 1 but the problem always exists.
I think it's a bug in keras.


",ChawDoe,b'type:support',2018-09-15T04:36:38Z,2018-09-16T07:54:55Z
11125,Fix bug in dilated conv for CNTK,"### Summary
If the number of channels is great than 1, we should add a non-zero value at the begin of ```dilation``` to line up with the input channel axis for ```C.convolution```. The extra non-zero value doesn't have effect even if the number of channels is 1, so we can always add a prefix ```(1,)``` to ```dilation_rate``` when calling ```C.convolution```. This PR fixed this bug in ```Conv1D, Conv2D, Conv3D, Conv2DTranspose```. For other conv layers, it has several other issues should be fixed as well, I'll send follow-up PRs later.
I found related unit tests only run cases that the number of channels is 1. I enforced them to run against both input and output channels are great than 1 which is more common case, and check output as expected given an input. I have run all these unit tests on a machine with 2 GPUs, they produce expected output and exactly same as TF and TH backend.

### Related Issues

### PR Overview

- [x] This PR requires new unit tests [y/n] (make sure tests are included)
- [ ] This PR requires to update the documentation [y/n] (make sure the docs are up-to-date)
- [x] This PR is backwards compatible [y/n]
- [ ] This PR changes the current API [y/n] (all API changes need to be approved by fchollet)
",yanboliang,None,2018-09-12T21:11:54Z,2018-09-17T18:17:20Z
11123,Fix bug in BatchNorm when channel=1,"### Summary
When channel=1 and we call `squeeze` the tensors become scalars. This is not accepted by Tensorflow. This is an issue only on GPU.
### Related Issues

### PR Overview

- [x] This PR requires new unit tests [y/n] (make sure tests are included)
- [ ] This PR requires to update the documentation [y/n] (make sure the docs are up-to-date)
- [x] This PR is backwards compatible [y/n]
- [ ] This PR changes the current API [y/n] (all API changes need to be approved by fchollet)
",Dref360,None,2018-09-12T15:58:57Z,2018-09-12T16:29:28Z
11106,Chrome timeline is broken for TensorFlow backend,"Chrome timeline is very useful to profile a Keras model, we can get the execution time for each node in the TF graph. Keras has already supported it since https://github.com/keras-team/keras/pull/6693 . But it seems this feature is broken since Keras 2.2. Run the following code to reproduce this bug:
```
import keras
from keras.datasets import mnist
from keras.models import Sequential
from keras.layers import Dense, Dropout
from keras.optimizers import RMSprop

import tensorflow as tf
from tensorflow.python.client import timeline

(x_train, y_train), (x_test, y_test) = mnist.load_data()

x_train = x_train.reshape(60000, 784).astype('float32')
y_train = keras.utils.to_categorical(y_train, 10)

model = Sequential()
model.add(Dense(512, activation='relu', input_shape=(784,)))
model.add(Dropout(0.2))
model.add(Dense(512, activation='relu'))
model.add(Dropout(0.2))
model.add(Dense(10, activation='softmax'))

run_options = tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE)
run_metadata = tf.RunMetadata()

model.compile(loss='categorical_crossentropy',
              optimizer=RMSprop(),
              metrics=['accuracy'],
              options=run_options,
              run_metadata=run_metadata)

history = model.fit(x_train, y_train,
                    batch_size=128,
                    epochs=1)

trace = timeline.Timeline(step_stats=run_metadata.step_stats)
with open('/tmp/timeline.json', 'w') as f:
    f.write(trace.generate_chrome_trace_format())
```
This is the exception:
```
Using TensorFlow backend.
Traceback (most recent call last):
  File ""test.py"", line 72, in <module>
    epochs=1)
  File ""build/bdist.macosx-10.13-intel/egg/keras/engine/training.py"", line 1016, in fit
  File ""build/bdist.macosx-10.13-intel/egg/keras/engine/training.py"", line 516, in _make_train_function
  File ""build/bdist.macosx-10.13-intel/egg/keras/backend/tensorflow_backend.py"", line 2705, in function
  File ""build/bdist.macosx-10.13-intel/egg/keras/backend/tensorflow_backend.py"", line 2552, in __init__
ValueError: ('Some keys in session_kwargs are not supported at this time: %s', ['run_metadata', 'options'])
```
It seems ```run_metadata``` and ```options``` arguments are not supported by ```K.Function```.",yanboliang,b'type:bug/performance',2018-09-08T02:07:44Z,2018-09-10T17:50:18Z
11104,"Cannot save optimizer weights due to h5 error ""object header message is too large""","When trying to save my model I get the runtime error below. There was a similar issue when model layers names were too long and it can be solved by giving layers shorter names. This time the error pops up when saving optimizer weights. getattr(model.optimizer,'weights') shows

```
[<tf.Variable 'Adam/iterations:0' shape=() dtype=int64_ref>,
 <tf.Variable 'training/Adam/Variable:0' shape=(3, 3, 1, 64) dtype=float32_ref>,
 <tf.Variable 'training/Adam/Variable_1:0' shape=(64,) dtype=float32_ref>,
 <tf.Variable 'training/Adam/Variable_2:0' shape=(64,) dtype=float32_ref>,
...]

```
and if I convert it to numpy array its length is above the 64k limits which gives h5 runtime. I can save the model if I use save_model(....,include_optimizer=False) but I need the optimizer state. Is there any way I can reduce the length of ""training/Adam/Variable:0""... names so as to fit them into 64k hdf5 table limit. Thanks.

```
---------------------------------------------------------------------------
RuntimeError                              Traceback (most recent call last)
<ipython-input-130-d231b4a5a40c> in <module>()
----> 1 model.save('model')

C:\Anaconda3\lib\site-packages\keras\engine\network.py in save(self, filepath, overwrite, include_optimizer)
   1083             raise NotImplementedError
   1084         from ..models import save_model
-> 1085         save_model(self, filepath, overwrite, include_optimizer)
   1086 
   1087     def save_weights(self, filepath, overwrite=True):

C:\Anaconda3\lib\site-packages\keras\engine\saving.py in save_model(model, filepath, overwrite, include_optimizer)
    173                     #print('Weight names',weight_names,len(weight_names),np.asarray(weight_names).nbytes)
    174                     optimizer_weights_group.attrs[
--> 175                         'weight_names'] = weight_names
    176                     for name, val in zip(weight_names, weight_values):
    177                         param_dset = optimizer_weights_group.create_dataset(

h5py\_objects.pyx in h5py._objects.with_phil.wrapper()

h5py\_objects.pyx in h5py._objects.with_phil.wrapper()

C:\Anaconda3\lib\site-packages\h5py\_hl\attrs.py in __setitem__(self, name, value)
     93         use the methods create() and modify().
     94         """"""
---> 95         self.create(name, data=value, dtype=base.guess_dtype(value))
     96 
     97     @with_phil

C:\Anaconda3\lib\site-packages\h5py\_hl\attrs.py in create(self, name, data, shape, dtype)
    186 
    187             try:
--> 188                 attr = h5a.create(self._id, self._e(tempname), htype, space)
    189             except:
    190                 raise

h5py\_objects.pyx in h5py._objects.with_phil.wrapper()

h5py\_objects.pyx in h5py._objects.with_phil.wrapper()

h5py\h5a.pyx in h5py.h5a.create()

RuntimeError: Unable to create attribute (object header message is too large)
```



Please make sure that the boxes below are checked before you submit your issue. If your issue is an implementation question, please ask your question on [StackOverflow](http://stackoverflow.com/questions/tagged/keras) or [join the Keras Slack channel](https://keras-slack-autojoin.herokuapp.com/) and ask there instead of filing a GitHub issue.

Thank you!

- [ ] Check that you are up-to-date with the master branch of Keras. You can update with:
pip install git+git://github.com/keras-team/keras.git --upgrade --no-deps

- [ ] If running on TensorFlow, check that you are up-to-date with the latest version. The installation instructions can be found [here](https://www.tensorflow.org/get_started/os_setup).

- [ ] If running on Theano, check that you are up-to-date with the master branch of Theano. You can update with:
pip install git+git://github.com/Theano/Theano.git --upgrade --no-deps

- [ ] Provide a link to a GitHub Gist of a Python script that can reproduce your issue (or just copy the script here if it is short).
",sakvaua,b'type:bug/performance',2018-09-07T08:36:58Z,2018-09-28T18:59:59Z
11081,"fix a bug in VAE-CNN example, ""vae = vae.load_weights"" to ""vae.load_weights"", because load_weights doesn't return anything","### Summary
fix a bug in VAE-CNN example, ""vae = vae.load_weights"" to ""vae.load_weights"", because load_weights doesn't return anything
### Related Issues

### PR Overview

- [ ] This PR requires new unit tests [y/n] (make sure tests are included)
- [ ] This PR requires to update the documentation [y/n] (make sure the docs are up-to-date)
- [ ] This PR is backwards compatible [y/n]
- [ ] This PR changes the current API [y/n] (all API changes need to be approved by fchollet)
",linjinjin123,None,2018-09-05T03:35:58Z,2018-09-05T22:50:18Z
11070,Accuracy oscillates between ~0% and ~70% when creating new models,"Hi all,

**I've found that the problem doesn't occur when TensorFlow is forced to use the CPU** -- (I think) this implies that it's a TensorFlow bug and not a Keras bug, so maybe this issue can be closed.

First off, I'm using the Keras that's distributed with TensorFlow 1.10.0 so let me know if I should have opened the issue on their repo instead.

I'm using a sequence-to-sequence model based on the [Keras blogpost](https://blog.keras.io/a-ten-minute-introduction-to-sequence-to-sequence-learning-in-keras.html) which I've wrapped into a fairly complicated object (although the issue also occurs with a simplified version linked below). When I create a new model (which I have to do for gridsearch and for clearing the TF session when the graph gets too big and slows down training) it starts with accuracy of either 0% or 70%.

Here are a pair of screenshots that show what I mean:
 * Good: https://i.imgur.com/7mT5Siv.png
 * Bad: https://i.imgur.com/MZ3NdCB.png

You can see that in the first screenshot, the accuracy is low but trending upwards. In the second, the accuracy of two models starts at 70% and doesn't increase (another model starts at 3% and also doesn't increase).

This happens whether I create new, blank models or load pretrained weights into new models with `model.load_weights()`.

- [ ] Check that you are up-to-date with the master branch of Keras. You can update with:
pip install git+git://github.com/keras-team/keras.git --upgrade --no-deps

- [X] If running on TensorFlow, check that you are up-to-date with the latest version. The installation instructions can be found [here](https://www.tensorflow.org/get_started/os_setup).

- [ ] If running on Theano, check that you are up-to-date with the master branch of Theano. You can update with:
pip install git+git://github.com/Theano/Theano.git --upgrade --no-deps

- [X] Provide a link to a GitHub Gist of a Python script that can reproduce your issue (or just copy the script here if it is short).

Here is a minimal Gist which reproduces the problem: https://gist.github.com/ChrisSwinchatt/97304761e9f875dfd34e3339891a5475",ChrisSwinchatt,None,2018-09-03T16:19:52Z,2018-09-05T17:39:44Z
11059,Bug fix: batch_dot,"* Almost total rewrite of `batch_dot` for Tensorflow and CNTK backend.
* Fixes various bugs in edge cases(e.g #11035)
* Does early input validation with helpful messages.
* Earlier, the methods had partial `tf.tensordot()` like behavior, which was undocumented. This was possibly a bug first introduced in TF backend and the logic was probably copied when writing the CNTK backend. This now returns with a helpful error message.
* Reduces number of ops as much as possible.
* Slightly better docstrings
* Thorough unit tests.
 ",farizrahman4u,None,2018-09-02T13:41:43Z,2018-10-23T06:14:53Z
11047,show activation functions for Dense layer in the model plot,"### Summary

I added activation functions in the model plot to help debugging for complicated networks.  An example is given below:

Before:

![model](https://user-images.githubusercontent.com/6883429/44925553-59106d00-ad14-11e8-9c2b-6529d0196cb2.png)


After:

![model](https://user-images.githubusercontent.com/6883429/44925380-ef905e80-ad13-11e8-895f-8b37d4c31a78.png)


### PR Overview

- [n] This PR requires new unit tests [y/n] (make sure tests are included)
- [n] This PR requires to update the documentation [y/n] (make sure the docs are up-to-date)
- [y] This PR is backwards compatible [y/n]
- [n] This PR changes the current API [y/n] (all API changes need to be approved by fchollet)
",weiHelloWorld,None,2018-08-31T16:53:01Z,2018-08-31T17:08:56Z
11035,batch_dot() behavior inconsistent between different backends,"The following code worked well using the backend of tensorflow.
```python
import numpy as np
np.random.seed=0
a=np.random.uniform(0,100,[2,4,3])
b=np.random.uniform(0,100,[2,3,5])
import keras
k=keras.backend
ka=k.variable(a)
kb=k.variable(b)
kc=k.batch_dot(ka, kb, (2,1))
k.eval(kc)
```
But it returned incorrect result using the backend of cntk: kc.shape=[2,4,2,5].",Giszy,b'type:bug/performance',2018-08-30T11:02:33Z,2018-11-26T21:01:21Z
11032,Keras model with Batchnorm layer => frozen graph => error when loading frozen graph,"I have a tf.keras model which contains a Batchnorm Layer.

This is what I want to do:
Keras model => Checkpoint files => frozen_graph.pb => Load frozen graph (ERROR)

I get the following error message: 
`Input 0 of node inference/conv1_1_3x3_s2_bn/cond/ReadVariableOp/Switch was passed float from inference/conv1_1_3x3_s2_bn/gamma:0 incompatible with expected resource.`

Here is a jupyter notebook which reproduces the error:
https://gist.github.com/JanRuettinger/6ba8662c4b8df86213bfc2ec6ee426ca#file-batchnorm-bug",JanRuettinger,b'backend:tensorflow',2018-08-30T09:13:30Z,2019-06-13T09:29:00Z
11031,"fix a bug in VAE example, ""vae = vae.load_weights"" to ""vae.load_weights"", because load_weights doesn't return anything","### Summary
fix a bug in VAE example, ""vae = vae.load_weights"" to ""vae.load_weights"", because load_weights doesn't return anything
### Related Issues

### PR Overview

- [ ] This PR requires new unit tests [y/n] (make sure tests are included)
- [ ] This PR requires to update the documentation [y/n] (make sure the docs are up-to-date)
- [ ] This PR is backwards compatible [y/n]
- [ ] This PR changes the current API [y/n] (all API changes need to be approved by fchollet)
",linjinjin123,None,2018-08-30T08:34:59Z,2018-08-30T16:56:42Z
11019,Loading weights two times in same script,"I am facing a really strange bug, using TF backend. I have the need to load multiple keras models in the same script, as this example:
```
model1 =  Model(...)
model1.compile(...)
model1.load_weights('model.h5', by_name=True)  # This works!!

model2 =  Model(...)
model2.compile(...)
model2.load_weights('model.h5', by_name=True)  # This DOES NOT work!!
```
So far I have only tested examples where `model1` and `model2` are exactly the same, but I think it should happen with different models. It should be correlated with how the computation graph is being initialized in the background, so that `load_weights` always tries to assign weights to the first model created in the script (perhaps??). I have tested that the weights of the second model do not changed by checking them before and after the function call.",JoaoLages,None,2018-08-28T16:05:35Z,2018-08-28T16:26:50Z
10967,Fix dilated convolution for CNTK backend.,"### Summary
2D Dilated convolution gives wrong output for CNTK backend:
```
from keras.layers import Input, Conv2D
from keras.models import Model
import numpy as np

inputs = Input(shape=(10, 10, 1))
m = Conv2D(1, kernel_size=(3, 3), padding='valid', dilation_rate=(2, 2))(inputs)
model = Model(inputs=inputs, outputs=m)
model.summary()

x = np.random.random((1, 10, 10, 1)).astype(np.float32)
y = model.predict(x)
print(""y.shape = "" + str(y.shape))
```
output is:
```
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
input_1 (InputLayer)         (None, 10, 10, 1)         0
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 6, 6, 1)           10
=================================================================
Total params: 10
Trainable params: 10
Non-trainable params: 0
_________________________________________________________________
y.shape = (1, 4, 4, 1)
```
The output shape should be ```(None, 6, 6, 1)``` according keras shape inference, but it's ```(1, 4, 4, 1)``` after evaluation. This is because it passed ```dilation_rate``` to ```strides``` by mistake at CNTK backend when ```dilation > 2```. 

### How to test this fix
There is ```test_convolution_2d``` in ```convolutional_test.py```, but I still skip it due to CNTK only supports dilated convolution on GPU, but CI doesn't have GPU node. I run the following code with TF backend(CPU or GPU) and CNTK backend(GPU), they gives the same output.
Test code:
```
from keras.layers import Input, Conv2D
from keras.models import Model
from keras.initializers import Constant
import numpy as np

kernel = np.arange(9).reshape((3, 3, 1, 1))
print(kernel.shape)

inputs = Input(shape=(10, 10, 1))
m = Conv2D(1, kernel_size=(3,3), padding='valid', dilation_rate=(2, 2), kernel_initializer=Constant(kernel))(inputs)
model = Model(inputs=inputs, outputs=m)
model.summary()


x = np.arange(100).reshape((1, 10, 10, 1)).astype(np.float32) 
y = model.predict(x)

print(np.squeeze(y))
print(y.shape)
```
Output:
```
(3, 3, 1, 1)
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
input_1 (InputLayer)         (None, 10, 10, 1)         0
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 6, 6, 1)           10
=================================================================
Total params: 10
Trainable params: 10
Non-trainable params: 0
_________________________________________________________________
[[1164. 1200. 1236. 1272. 1308. 1344.]
 [1524. 1560. 1596. 1632. 1668. 1704.]
 [1884. 1920. 1956. 1992. 2028. 2064.]
 [2244. 2280. 2316. 2352. 2388. 2424.]
 [2604. 2640. 2676. 2712. 2748. 2784.]
 [2964. 3000. 3036. 3072. 3108. 3144.]]
(1, 6, 6, 1)
```

Meanwhile, I found a CNTK dilated conv bug if number of channel > 1(need confirm from CNTK guys), I reported to https://github.com/Microsoft/CNTK/issues/3371. But I think it doesn't have effect of the code structure at Keras.

### Related Issues

### PR Overview

- [ ] This PR requires new unit tests [y/n] (make sure tests are included)
- [ ] This PR requires to update the documentation [y/n] (make sure the docs are up-to-date)
- [x] This PR is backwards compatible [y/n]
- [ ] This PR changes the current API [y/n] (all API changes need to be approved by fchollet)
",yanboliang,None,2018-08-23T05:28:21Z,2018-08-23T18:35:13Z
10944,Keras >= 2.2.1 no longer respects fit_generator(validation_steps=...),"It seems that starting with Keras 2.2.1 `fit_generator()` no longer stops the validation process after `validation_steps` steps, but continues through the entire sequence. See this example code:

```
import numpy
from keras import Input, Model
from keras.layers import Dense
from keras.utils import Sequence

class Gen(Sequence):
    def __init__(self, name):
        super().__init__()
        self.name = name

    def __len__(self):
        return 1000

    def __getitem__(self, index):
        print('Generate %s %d' % (self.name, index))
        return numpy.zeros(shape=(10, 10)), numpy.zeros(shape=(10, 2))

i = Input(shape=(10,))
o = Dense(units=2)(i)
m = Model(i, o)
m.compile('sgd', 'mse')
m.fit_generator(
    generator=Gen('training_data'),
    shuffle=False,
    steps_per_epoch=5,
    validation_data=Gen('validation_data'),
    validation_steps=5,
    workers=1,
    max_queue_size=1,
    verbose=0,
)
```

Which will output

```
Generate validation_data 0
Generate validation_data 1
Generate training_data 0
Generate training_data 1
Generate training_data 2
Generate training_data 3
Generate training_data 4
Generate training_data 5
Generate training_data 6
Generate validation_data 2
Generate validation_data 3
Generate validation_data 4
Generate validation_data 5
Generate validation_data 6
Generate validation_data 7
...
Generate validation_data 998
Generate validation_data 999
```

This was working fine in keras 2.2.0.",jlherren,b'type:bug/performance',2018-08-20T07:47:35Z,2018-08-21T22:51:01Z
10912,ENH: all save_model/load_model to accept h5py.Group,"- [n] This PR requires new unit tests [y/n] (make sure tests are included)
- [y] This PR requires to update the documentation [y/n] (make sure the docs are up-to-date)
- [y] This PR is backwards compatible [y/n]
- [n] This PR changes the current API [y/n] (all API changes need to be approved by fchollet)

This is inspired by a bug report to
h5py (https://github.com/h5py/h5py/issues/1076) to allow the user to
pass a Group or a File (which is a sub-class of Group) into save_model
and load_model",tacaswell,None,2018-08-15T00:56:49Z,2018-08-17T13:01:58Z
10893,Unable to use Identity initializer for LSTM or GRU recurrent kernel,"In `GRUCell` and `LSTMCell`, we speedup GRU and LSTM by combining multiple recurrent weights to a big one (#2523, #2633). However, it introduces problem when we want to initalize RNN recurrent weight with `Identity` initializer, since shape of the combined weight is not square.

To reproduce this bug:
```python
from keras.layers import Input, LSTM
x = Input(shape=(16, 4))
out = LSTM(4, recurrent_initializer='identity')(x)
```

We may fix it by adding weight individually:
```python
_recurrent_kernels = [
    self.add_weight(
        shape=(self.units, self.units),
        name='recurrent_kernel_{}'.format(t),
        initializer=self.recurrent_initializer,
        regularizer=self.recurrent_regularizer,
        constraint=self.recurrent_constraint)
    for t in ('i', 'f', 'c', 'p')
 ]
self.recurrent_kernel = K.concatenate(_recurrent_kernels)
```",joelthchao,None,2018-08-12T11:02:09Z,2018-08-22T03:33:06Z
10859,Some code refactoring using `transpose_shape` in tensorflow_backend.py. Part 2,"### Summary
Some refactoring. 
### Related Issues

### PR Overview

There was a bug in the code in the `channels_last` part:

`x += reshape(bias, (1, 1, 1, bias_shape[0]))`

The new shape should be of size 5, here it is only 4. My refactoring fixes this.

- [ ] This PR requires new unit tests [y/n] (make sure tests are included)
- [ ] This PR requires to update the documentation [y/n] (make sure the docs are up-to-date)
- [x] This PR is backwards compatible [y/n]
- [ ] This PR changes the current API [y/n] (all API changes need to be approved by fchollet)
",gabrieldemarmiesse,None,2018-08-06T20:22:59Z,2018-09-18T06:33:54Z
10845,RNN.call should get initial state from full input spec,"### Summary
This PR fix a critical bug in ```RNN``` which reported at #9449 and #10830 .

In ```RNN.call```, if ```initial_state``` is a tensor that was returned by a Keras layer, we should get ```initial_state``` from full input spec(including training data, state and constants) which was generated at ```RNN.__call__```, as it could be copied to multiple GPUs. Otherwise, it would use the original ```initial_states``` which is not be sliced according the number of GPUs.
BTW, I have also check ```CuDNNRNN```, it use the correct way, so we don't need to modify it.

I run the following test code in a machine with 2 GPUs, it works well after this fix.
```
import numpy as np
import keras
from keras import layers as L
from keras.models import Sequential, Model
from keras.utils.multi_gpu_utils import multi_gpu_model

x = L.Input((4,3))
init_state = L.Input((3,))
y = L.SimpleRNN(3,return_sequences=True)(x,initial_state=init_state)
_x = [np.random.randn(2,4,3),np.random.randn(2,3)]
_y = np.random.randn(2,4,3)
m = Model([x,init_state],y)
m2 = multi_gpu_model(m,2)
m2.compile(loss='mean_squared_error',optimizer='adam')
m2.train_on_batch(_x,_y)
```

### Related Issues
#9449
#10830
 
### PR Overview

- [x] This PR requires new unit tests [y/n] (make sure tests are included)
- [ ] This PR requires to update the documentation [y/n] (make sure the docs are up-to-date)
- [x] This PR is backwards compatible [y/n]
- [ ] This PR changes the current API [y/n] (all API changes need to be approved by fchollet)
",yanboliang,None,2018-08-04T08:01:34Z,2019-08-18T13:23:09Z
10768,Why tokenizer work only for chars? Bugreport probably,"Last keras, testing code:

```
text = open(os.path.join(work_dir, 'train_text_en.txt'), 'r', encoding='utf-8').read()
tokenizer = Tokenizer(char_level=False)
tokenizer.fit_on_texts(text)
print(tokenizer.word_index)
```

in output get chars
`{'e': 1, 't': 2, 'a': 3, 'o': 4, 'i': 5, 'n': 6, 's': 7, 'r': 8, 'h': 9, 'l': 10, 'd': 11, 'm': 12, 'c': 13, 'u': 14, 'f': 15, 'p': 16, 'g': 17, 'y': 18, 'w': 19, 'b': 20, 'v': 21, 'k': 22, 'x': 23, '—': 24, ""'"": 25, 'z': 26, 'j': 27, 'q': 28, '0': 29, '1': 30, '5': 31, '2': 32, '3': 33, '4': 34, '6': 35, '7': 36, '9': 37, '8': 38, '…': 39, 'с': 40}`",hadaev8,None,2018-07-24T19:13:18Z,2018-07-24T19:44:58Z
10733,BUG FIX #6351: Make sparse_categorical_crossentropy work with 3D outputs.,"### Summary
Make sparse_categorical_crossentropy work with 3D outputs.

### Related Issues
#6351

### PR Overview

- [ ] This PR requires new unit tests [y/n] (make sure tests are included)
- [ ] This PR requires to update the documentation [y/n] (make sure the docs are up-to-date)
- [X] This PR is backwards compatible [y/n]
- [ ] This PR changes the current API [y/n] (all API changes need to be approved by fchollet)
",Cheukting,None,2018-07-19T23:05:13Z,2018-08-22T18:15:43Z
10716,Gradients w.r.t. VGG conv block are None when attaching a custom head to the base model,"
- [ X] Check that you are up-to-date with the master branch of Keras. You can update with:
pip install git+git://github.com/keras-team/keras.git --upgrade --no-deps

- [ X] If running on TensorFlow, check that you are up-to-date with the latest version. The installation instructions can be found [here](https://www.tensorflow.org/get_started/os_setup).

- [ X] If running on Theano, check that you are up-to-date with the master branch of Theano. You can update with:
pip install git+git://github.com/Theano/Theano.git --upgrade --no-deps

- [ X] Provide a link to a GitHub Gist of a Python script that can reproduce your issue (or just copy the script here if it is short).

As demonstrated by @fchollet in the DL with Python notebook ""Visualizing what convnets learn"", we can get the gradients of the output w.r.t. an arbitrary conv layer in the pretrained model (minimal example below).

However, when we attach a custom head to the model and try to get the gradients w.r.t. a layer of the VGG model included, the gradients are None (minimal example below).

Is this a bug, or expected behavior - and if so, is there an alternative way to get the gradients in this case?
Many thanks in advance!

Works:

```
from keras.applications.vgg16 import VGG16
from keras import backend as K

model = VGG16(weights='imagenet')
last_conv_layer = model.get_layer('block5_conv3')
grads = K.gradients(model.output, last_conv_layer.output)[0]
grads
```

Gradients are None:

```
from keras.applications.vgg16 import VGG16
from keras import backend as K
from keras import models
from keras import layers


conv_base = VGG16(weights='imagenet',
                  include_top=False,
                  input_shape=(224, 224, 3))
                  
model = models.Sequential()
model.add(conv_base)
model.add(layers.Flatten())
model.add(layers.Dense(256, activation='relu'))
model.add(layers.Dense(1, activation='sigmoid'))

conv_layer = model.layers[0].get_layer(""block5_conv3"")
conv_layer 
grads = K.gradients(model.output, conv_layer.output)[0]
print(grads)
```


",skeydan,None,2018-07-17T19:23:20Z,2019-05-21T16:59:45Z
10706,custom metric MAE and RMSE are the same,"This is a reproducible example: 

consider this 

```
from keras.models import Sequential
from keras.layers import Dense, Activation
import numpy as np








import keras.backend as K

def rmse (y_true, y_pred):
    return K.sqrt(K.mean(K.square(y_pred -y_true), axis=-1))




model = Sequential([
    Dense(32, input_shape=(50,)),
    Activation('relu'),
    Dense(1),
])

model.compile(optimizer='adam', loss='mse', metrics=['mae',rmse])





data = np.random.random((1000, 50))
labels = np.random.randint(2, size=(1000, 1))

model.fit(data, labels, epochs=5, batch_size=64)
```

Both RMSE and MAE are the same. This happens when i placed them together. Is there a bug?

the output is:

![image](https://user-images.githubusercontent.com/22788747/42806109-39fc16be-89e0-11e8-80d8-5e73ba8b2541.png)
",germayneng,None,2018-07-17T08:40:56Z,2020-05-24T23:48:13Z
10684,Batch Normalization should squeeze mean/var/beta/gama tensors when calling tf.nn.fused_batch_norm,"### Summary
```BatchNormalization``` layer, mean/var/beta/gama tensors may be [broadcast](https://github.com/keras-team/keras/blob/master/keras/layers/normalization.py#L140). 
```
input = Input(shape=(3, 1001, 1001), dtype='float32')
x = Conv2D(filters=64, kernel_size=(3, 3), strides=1, padding='same')(input)
x = BatchNormalization(axis=1)(x)
```
In the above example, as you set ```axis=1```, the mean/var/beta/gama tensors would be reshaped as [1,64,1,1]. For TF backend, it will try to call the optimized ```tf.nn.fused_batch_norm``` if possible. But ```tf.nn.fused_batch_norm``` only accept mean/var/beta/gama as 1 dimension tensor, we need to squeeze them ahead.
Actually we have did same preprocessing for [CNTK backend](https://github.com/keras-team/keras/blob/master/keras/backend/cntk_backend.py#L1070).

Note: This bug should only happened when TF-GPU as backend, since TF-CPU FusedBatchNorm doesn't support NCHW format, and it will fall back to the default ```tf.nn.batch_normalization```.   

### Related Issues
https://github.com/keras-team/keras/issues/10648

### PR Overview

- [ ] This PR requires new unit tests [y/n] (make sure tests are included)
- [ ] This PR requires to update the documentation [y/n] (make sure the docs are up-to-date)
- [x] This PR is backwards compatible [y/n]
- [ ] This PR changes the current API [y/n] (all API changes need to be approved by fchollet)
",yanboliang,None,2018-07-15T04:41:32Z,2019-01-09T13:37:16Z
10673,[Bug] Fix Stateful Metrics in fit_generator with TensorBoard,"### Summary
Currently ``TensorBoard `` does not work with ``fit_generator`` because of

```python
line 942, in on_epoch_end
    summary_value.simple_value = value.item()
AttributeError: 'float' object has no attribute 'item'
```
This is a simple casting issue.

### Related Issues
https://github.com/keras-team/keras/issues/10628
https://github.com/keras-team/keras/issues/10623

### PR Overview

- [n] This PR requires new unit tests [y/n] (make sure tests are included)
- [n] This PR requires to update the documentation [y/n] (make sure the docs are up-to-date)
- [y] This PR is backwards compatible [y/n]
- [n] This PR changes the current API [y/n] (all API changes need to be approved by fchollet)
",briannemsick,None,2018-07-13T20:34:40Z,2018-07-23T21:20:00Z
10651,Use get_shape() in loss function,"Hello everyone. I have written the following loss function, but it doesn't seem to suit Keras requirement. 


```
def custom_loss_(y_true, y_pred):
	bool_mask = K.greater(y_true[..., 2] * y_true[..., 3], 	0)
	e0 = np.zeros(y_true.get_shape().as_list()) # BUG /!\ # 
	e1 = np.zeros(y_true.get_shape().as_list())
	e0[..., 0:4] = np.sqrt(5) 
	e0[..., 4:] = 1
        e0 = tf.constant(e0)
        e1 = tf.constant(e1)
	mask_coord = K.switch(bool_mask, e0, e1)


	bool_mask = K.equal(y_true[..., 2] * y_true[..., 3], 0)
	e0 = np.zeros(y_true.get_shape().as_list())
	e1 = np.zeros(y_true.get_shape().as_list())
	e0[...,5] = np.sqrt(0.5)
        e0 = tf.constant(e0)
        e1 = tf.constant(e1)
	conf_coord = K.switch(bool_mask, e0, e1)

	mask = mask_coord + conf_coord
	return tf.reduce_mean(K.square(K.multiply(y_true - y_pred, mask)), axis = 0)
```
At run time, I get the following error:

> TypeError                                 Traceback (most recent call last)
> ~/MFG/YOLO/Y2K/network.py in <module>()
>      70 yolo = buildYolo()
>      71 yolo.summary()
> ---> 72 yolo.compile(loss = custom_loss, optimizer = 'adadelta')
>      73
>      74
> 
> ~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py in compile(self, optimizer, loss, metrics, loss_weights, sample_weight_mode, weighted_metrics, target_tensors, **kwargs)
>     330                 with K.name_scope(self.output_names[i] + '_loss'):
>     331                     output_loss = weighted_loss(y_true, y_pred,
> --> 332                                                 sample_weight, mask)
>     333                 if len(self.outputs) > 1:
>     334                     self.metrics_tensors.append(output_loss)
> 
> ~/anaconda3/lib/python3.6/site-packages/keras/engine/training_utils.py in weighted(y_true, y_pred, weights, mask)
>     401         """"""
>     402         # score_array has ndim >= 2
> --> 403         score_array = fn(y_true, y_pred)
>     404         if mask is not None:
>     405             # Cast the mask to floatX to avoid float64 upcasting in Theano
> 
> ~/YOLO/Y2K/network.py in custom_loss(y_true, y_pred)
>      48
>      49         bool_mask = K.greater(y_true[..., 2] * y_true[..., 3],  0)
> ---> 50         e0 = np.zeros(y_true.get_shape().as_list())
>      51         e1 = np.zeros(y_true.get_shape().as_list())
>      52         e0[..., 0:4] = np.sqrt(5)
> 
> TypeError: 'NoneType' object cannot be interpreted as an integer

I would greatly appreciate if someone can help understand why this function doesn't work / and how to fix this. Thank you a LOT !",rodriguel,None,2018-07-11T22:49:23Z,2018-07-12T18:52:06Z
10648,Bug with BatchNormalization(axis=1): ValueError: Shape must be rank 1 but is rank 4 for 'batch_normalization_1/cond/FusedBatchNorm',"Current master version of keras (commit b3cb261b22a73d195a527592b49ca57e8c9ac9f5), TensorFlow 1.8.0

`BatchNormalization(axis=1)` for `'channels_first'` seems to fail.

```python
import os
os.environ['KERAS_BACKEND'] = 'tensorflow'
import keras.backend as K
from keras.layers import Activation, Conv2D, Input
from keras.layers.normalization import BatchNormalization

# declare network model with channels first: ERROR
K.set_image_data_format('channels_first')
input = Input(shape=(3, 1001, 1001), dtype='float32')
x = Conv2D(filters=64, kernel_size=(3, 3), strides=1, padding='same')(input)
x = BatchNormalization(axis=1)(x)
x = Activation('relu')(x)
```

gives the error

```
Traceback (most recent call last):
  File ""/home/rcasero/.conda/envs/cytometer_tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 1567, in _create_c_op
    c_op = c_api.TF_FinishOperation(op_desc)
tensorflow.python.framework.errors_impl.InvalidArgumentError: Shape must be rank 1 but is rank 4 for 'batch_normalization_1/cond/FusedBatchNorm' (op: 'FusedBatchNorm') with input shapes: [?,64,1001,1001], [1,64,1,1], [1,64,1,1], [1,64,1,1], [1,64,1,1].
During handling of the above exception, another exception occurred:
Traceback (most recent call last):
  File ""<input>"", line 11, in <module>
  File ""/home/rcasero/.conda/envs/cytometer_tensorflow/lib/python3.6/site-packages/keras/engine/base_layer.py"", line 459, in __call__
    output = self.call(inputs, **kwargs)
  File ""/home/rcasero/.conda/envs/cytometer_tensorflow/lib/python3.6/site-packages/keras/layers/normalization.py"", line 204, in call
    training=training)
  File ""/home/rcasero/.conda/envs/cytometer_tensorflow/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py"", line 3069, in in_train_phase
    x = switch(training, x, alt)
  File ""/home/rcasero/.conda/envs/cytometer_tensorflow/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py"", line 3004, in switch
    else_expression_fn)
  File ""/home/rcasero/.conda/envs/cytometer_tensorflow/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py"", line 432, in new_func
    return func(*args, **kwargs)
  File ""/home/rcasero/.conda/envs/cytometer_tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py"", line 2072, in cond
    orig_res_f, res_f = context_f.BuildCondBranch(false_fn)
  File ""/home/rcasero/.conda/envs/cytometer_tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py"", line 1913, in BuildCondBranch
    original_result = fn()
  File ""/home/rcasero/.conda/envs/cytometer_tensorflow/lib/python3.6/site-packages/keras/layers/normalization.py"", line 165, in normalize_inference
    epsilon=self.epsilon)
  File ""/home/rcasero/.conda/envs/cytometer_tensorflow/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py"", line 1894, in batch_normalization
    is_training=False
  File ""/home/rcasero/.conda/envs/cytometer_tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/nn_impl.py"", line 904, in fused_batch_norm
    name=name)
  File ""/home/rcasero/.conda/envs/cytometer_tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/gen_nn_ops.py"", line 3429, in _fused_batch_norm
    is_training=is_training, name=name)
  File ""/home/rcasero/.conda/envs/cytometer_tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py"", line 787, in _apply_op_helper
    op_def=op_def)
  File ""/home/rcasero/.conda/envs/cytometer_tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 3392, in create_op
    op_def=op_def)
  File ""/home/rcasero/.conda/envs/cytometer_tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 1734, in __init__
    control_input_ops)
  File ""/home/rcasero/.conda/envs/cytometer_tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 1570, in _create_c_op
    raise ValueError(str(e))
ValueError: Shape must be rank 1 but is rank 4 for 'batch_normalization_1/cond/FusedBatchNorm' (op: 'FusedBatchNorm') with input shapes: [?,64,1001,1001], [1,64,1,1], [1,64,1,1], [1,64,1,1], [1,64,1,1].
```

Meanwhile, `BatchNormalization(axis=3)` for `'channels_last'` works.

```python
import os
os.environ['KERAS_BACKEND'] = 'tensorflow'
import keras.backend as K
from keras.layers import Activation, Conv2D, Input
from keras.layers.normalization import BatchNormalization

# declare network model with channels last: NO ERROR
K.set_image_data_format('channels_last')
input = Input(shape=(1001, 1001, 3), dtype='float32')
x = Conv2D(filters=64, kernel_size=(3, 3), strides=1, padding='same')(input)
x = BatchNormalization(axis=3)(x)
x = Activation('relu')(x)
```

doesn't give any error.
",rcasero,b'backend:tensorflow',2018-07-11T16:11:29Z,2020-09-06T15:55:47Z
10609,Fix a bug to write no-need blank lines to each line of csv file on Windows,"On Windows, `open` method writes line terminator of '\r\n' on default. ([When writing output to the stream, if newline is None, any '\n' characters written are translated to the system default line separator, os.linesep.](https://docs.python.org/3.3/library/functions.html#open))
But, we should use line terminator of '\n' on all platform. ([Do not use os.linesep as a line terminator when writing files opened in text mode](https://docs.python.org/3.3/library/os.html#os.linesep))

The default behavior of `open` method causes to add no-need blank lines to each line of csv file viewing by excel or csv library.
(`foo.csv` is generated by old `CSVLogger`)
```
In [1]: import csv

In [2]: with open('foo.csv', 'r') as f:
   ...:     reader = csv.reader(f)
   ...:     for row in reader:
   ...:         print(row)
   ...:
['epoch', 'acc', 'loss', 'val_acc', 'val_loss']
['', '', '', '', '']
['0', '0.92615', '0.244615294', '0.9675', '0.10786899']
['', '', '', '', '']
['1', '0.9689', '0.103249485', '0.9694', '0.092479979']
```

This PR remove this no-need blank lines.
(`bar.csv` is generated by `CSVLogger` of this PR)
```
In [3]: with open('bar.csv', 'r') as f:
   ...:     reader = csv.reader(f)
   ...:     for row in reader:
   ...:         print(row)
   ...:
['epoch', 'acc', 'loss', 'val_acc', 'val_loss']
['0', '0.9231166666666667', '0.24697612047990164', '0.9635', '0.11830915709584952']
['1', '0.9684666666348776', '0.1029080352028211', '0.9764', '0.0800724924955517']
```

I don't have environments of Unix and Mac OS, so I wrote code to effect only for Windows.
Please check behavior on other environments and write code for the environments.

Thank you.",huyu398,None,2018-07-05T10:22:12Z,2018-09-13T18:56:11Z
10574,keras : fit_generator ERROR,"I am learning Keras CNN. Was trying to create a object detection model. 

Model:
`model=MobileNet(weights='imagenet', include_top=True, input_shape=(img_width, img_height, 3))`
`model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])`

For the data i am using  `flow_from_directory`:
```

datagen = ImageDataGenerator(featurewise_center=True,
                             featurewise_std_normalization=True,
                             width_shift_range=0.2, height_shift_range=0.2)

train_generator = datagen.flow_from_directory(
                       train_data_dir,
                        target_size=(img_width, img_height),
                       ...)

datagen = validation_datagen = ImageDataGenerator(rescale=1. / 255)

validation_generator = datagen.flow_from_directory(
                       valid_data_dir,
                        target_size=(img_width, img_height),
                        ...)
```
When i use `model.fit_generator` : 

```
model.fit_generator(
                train_generator,
                steps_per_epoch=train_samples // batch_size,
                epochs=epochs,
                validation_data=validation_generator,
                validation_steps=valid_samples // batch_size,
                verbose=1)
```

I get the following error .  I am unable to debug the problem. Can someone help...

```
ValueError                                Traceback (most recent call last)
<ipython-input-7-1019b1c1eec2> in <module>()
      5                 validation_data=validation_generator,
      6                 validation_steps=valid_samples // batch_size,
----> 7                 verbose=1)

E:\Anaconda3\envs\env\lib\site-packages\keras\legacy\interfaces.py in wrapper(*args, **kwargs)
     89                 warnings.warn('Update your `' + object_name +
     90                               '` call to the Keras 2 API: ' + signature, stacklevel=2)
---> 91             return func(*args, **kwargs)
     92         wrapper._original_function = func
     93         return wrapper

E:\Anaconda3\envs\env\lib\site-packages\keras\engine\training.py in fit_generator(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)
   1424             use_multiprocessing=use_multiprocessing,
   1425             shuffle=shuffle,
-> 1426             initial_epoch=initial_epoch)
   1427 
   1428     @interfaces.legacy_generator_methods_support

E:\Anaconda3\envs\env\lib\site-packages\keras\engine\training_generator.py in fit_generator(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)
    189                 outs = model.train_on_batch(x, y,
    190                                             sample_weight=sample_weight,
--> 191                                             class_weight=class_weight)
    192 
    193                 if not isinstance(outs, list):

E:\Anaconda3\envs\env\lib\site-packages\keras\engine\training.py in train_on_batch(self, x, y, sample_weight, class_weight)
   1212             x, y,
   1213             sample_weight=sample_weight,
-> 1214             class_weight=class_weight)
   1215         if self._uses_dynamic_learning_phase():
   1216             ins = x + y + sample_weights + [1.]

E:\Anaconda3\envs\env\lib\site-packages\keras\engine\training.py in _standardize_user_data(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)
    790                 feed_output_shapes,
    791                 check_batch_axis=False,  # Don't enforce the batch size.
--> 792                 exception_prefix='target')
    793 
    794             # Generate sample-wise weight values given the `sample_weight` and

E:\Anaconda3\envs\env\lib\site-packages\keras\engine\training_utils.py in standardize_input_data(data, names, shapes, check_batch_axis, exception_prefix)
    134                             ': expected ' + names[i] + ' to have shape ' +
    135                             str(shape) + ' but got array with shape ' +
--> 136                             str(data_shape))
    137     return data
    138 

ValueError: Error when checking target: expected reshape_2 to have shape (1000,) but got array with shape (1,)
```

",ghost,None,2018-07-01T11:18:55Z,2018-09-25T02:33:11Z
10573,Problem with losses when loading and training a saved model which uses target_tensors,"I'm having a problem with loading and running a saved keras model using target_tensors.

The configurations:
- Python 3.5.2
- tensorflow-gpu 1.8.0
- Keras 2.2.0
- GTX 1080 Ti
- Ubuntu 16.04.4 LTS
- Cuda 9.0.176-1
- cuDNN 7.1.4.18-1+cuda9.0
- tensorrt 4.0.0.3-1+cuda9.0

Trying to be simple: I'm creating a model of image autoencoder. I receive an image and it simply downsamples and upsamples the image. I compare this output with the input and creates a residue. I input this residue in another autoencoder of the same structure. This autoencoder outputs something that's compared with the input (a residue from the preceding autoencoder). I actually do this many times, with many ""sequential"" residual autoencoders. I'm implementing it based on an article.

In each output, I've included a loss function that compares the output with the input. I've done it with the use of target_tensors:
```python
enc_input = [Input(shape=self._gen_conf.input_shape)]                    
dec_output = []                                                          
for cont in range(self._gen_conf.num_of_iterations):                     
     enc_output = self._add_enc_layers(enc_input[-1], cont)               
     dec_output += [self._add_dec_layers(enc_output, cont)]               
     enc_input += [Subtract(name='subtract' + str(cont))([enc_input[-1], dec_output[-1]])]                     
                                                                                                                                         
# Tensorflow does not allow the input_feed to be specified here. It         
# gives an error of 'Endpoint [...] fed more than once'                  
self._model = Model(inputs=enc_input[0], outputs=dec_output)             
targets = [K.identity(enc_input[0])] + enc_input[1:-1]
```

I use these targets to feed the intermediate losses (in another piece of code):
```python
self._model.compile(optimizer=optimizer, loss=loss, target_tensors=target_tensors)
```

I'm handling a huge database, so I'm training it with generators. The generator feed just the original images, since the losses are calculated from tensors.

```python
history = self._model.fit_generator(train_gen.generator(True, True),     
               steps_per_epoch=train_gen.get_num_steps_per_epoch(),                 
               epochs=confs.max_epochs, verbose=1, callbacks=confs.callbacks,       
               validation_data=val_gen.generator(),                                 
               validation_steps=val_gen.get_num_steps_per_epoch())
```

And the special point is: besides other callbacks, i have a checkpoint.
```
checkpoint = ModelCheckpoint(gen_conf['models_name_pattern'], verbose=1)
```

It's currently saving the whole model in each epoch.

So, with this, I've created a ""complex"" autoencoder and it works. 

I'm inserting a piece of the graph from tensorflow below. It's a much simpler network, although the same problem happens. You can see this strategy there. The input to each stage is used as reference to a loss:

![cool1](https://user-images.githubusercontent.com/35977339/42128618-f7b5b484-7c85-11e8-991a-974c8fe23c5b.png)

![cool2](https://user-images.githubusercontent.com/35977339/42128621-1055d2ee-7c86-11e8-9faa-7c99ed551769.png)

So now comes the problem. When I load any saved model of this to continue training, I use the function load_model from keras.models. As the documentation says:

> You can then use keras.models.load_model(filepath) to reinstantiate your model. load_model will also take care of compiling the model using the saved training configuration (unless the model was never compiled in the first place)_.

So, as I've already compiled it, it seems it's ok to use the .fit_generator directly. But, I've received the following error when I have 2 models (just one intermediate loss, which I call in the code as iterations):

>tensorflow.python.framework.errors_impl.InvalidArgumentError: You must feed a value for placeholder tensor 'd.conv01_sample_weights' with dtype float and shape [?]
	 [[Node: d.conv01_sample_weights = Placeholder[dtype=DT_FLOAT, shape=[?], _device=""/job:localhost/replica:0/task:0/device:GPU:0""]()]]
	 [[Node: loss_1/d.conv11_loss/Mean_3/_519 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device_incarnation=1, tensor_name=""edge_974_loss_1/d.conv11_loss/Mean_3"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:CPU:0""]()]]
Uncaught exception. Entering post mortem debugging

And the following when I have 1 or 3 or more models, with the same code showed above:
>tensorflow.python.framework.errors_impl.InvalidArgumentError: You must feed a value for placeholder tensor 'd.conv21_target' with dtype float and shape [?,?,?,?]
	 [[Node: d.conv21_target = Placeholder[dtype=DT_FLOAT, shape=[?,?,?,?], _device=""/job:localhost/replica:0/task:0/device:GPU:0""]()]]
	 [[Node: training/Adam/gradients/subtract1_1/sub_grad/Shape_1/_689 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device_incarnation=1, tensor_name=""edge_315_training/Adam/gradients/subtract1_1/sub_grad/Shape_1"", tensor_type=DT_INT32, _device=""/job:localhost/replica:0/task:0/device:CPU:0""]()]]
Uncaught exception. Entering post mortem debugging

Actually, I've tried with many ""residuals"": 2, 3, 4, 5. It gives error this error cause in this case, the losses are considering the ""weights"" as input. The graphs of the loaded version:

![not_cool1](https://user-images.githubusercontent.com/35977339/42128693-c6a51360-7c87-11e8-9886-eb356983d541.png)

![not_cool2](https://user-images.githubusercontent.com/35977339/42128694-c8cdf0ee-7c87-11e8-8094-c8b7934d8387.png)

I've done nothing in this case. Just the loading and after that, the .fit_generator. But now the loss considers the input of the decoder, the output and some ""weights"" variable for something. 

I'm inserting bellow the expansion of the losses in the two cases:

![cool3](https://user-images.githubusercontent.com/35977339/42128744-0ea848f2-7c89-11e8-955d-5e6c03baef64.png)

![not_cool3](https://user-images.githubusercontent.com/35977339/42128745-13ecbc9e-7c89-11e8-8430-4a5b9502878e.png)

So, It seems strange to me. I have not tried to compile the model manually in the loading case since the documentation says it's not necessary. I don't know if there's something wrong, but seems the loading is not ""maintaining"" the structure of the network.",nguerinjr,None,2018-06-30T20:55:09Z,2019-10-28T15:30:26Z
10562,Fix Dense layer bias_add bug when ndim > 2.,"This fix https://github.com/keras-team/keras/issues/10530 .
When input ndim > 2, Dense layer should add bias to the last dim, so we should always set  ```data_format``` with ```channels_last``` when calling ```K.bias_add```. This is different from other layers such as CNN or RNN, which is determinated by keras configuration.",yanboliang,None,2018-06-28T21:50:46Z,2018-07-10T19:20:04Z
10534,Attention Mechanism Implementation (ConvLSTM),"When trying to reproduce Polygon RNN++ (Efﬁcient Interactive Annotation of Segmentation Datasets with Polygon-RNN++, arxiv: https://arxiv.org/pdf/1803.09693.pdf), I am wondering if the attention weighted feature (3.2) on each hidden state of ConvLSTM can be implemented. I tried TimeDistributed, return_sequence = True, and return_state = True; however, I don't know if I have gotten the right output (check the stated problem below. 

```
    # branch 2 : ConvLSTM 
    # to ConvLSTM decoders
    # first ConvLSTM decoder
    # filter = 64
    convlstm1, state_h_1, state_c_1 = ConvLSTM2D(filters=64, kernel_size=(3, 3),
                   input_shape=(-1, 28, 28, 128),
                   padding='same', return_sequences=True, return_state=True)(X)
    
    print(convlstm1)
    
    # Attention weighted features (return_state=True)
    
    attention1 = TimeDistributed(Dense(128))(state_h_1)
    
    X = BatchNormalization(axis=1)(convlstm1)    
    
    # second ConvLSTM decoder
    # filter = 16
    convlstm2, state_h_2, state_c_2 = ConvLSTM2D(filters=16, kernel_size=(3, 3),
                   padding='same', return_sequences=True, return_state=True)(X)
    
    # Attention weighted features (return_state=True)
    attention2 = TimeDistributed(Dense(128))(state_h_2)
    
    X = BatchNormalization(axis=1)(convlstm2)
    
    # attention weighted features
    
    fatt = Add()([skipfeature, attention1, attention2])
    alpha_t = Activation('softmax')(fatt)
    f_t = Multiply()([skipfeature, alpha_t])
    f_t = Concatenate()([f_t, convlstm2[-1], convlstm2[-2], polygon_preds]) 
    # polygon_preds is the the first vertex prediction, y0
    # I assume these will yield the last two output of the whole convolutional lstm process instead of the output 
    # at time step t-1 and t-2
    print(f_t)
    
    # Create model
    model = Model(inputs=X_input, outputs=X, name='ResNet50')

    return model
```

The code above can be run without any bug. However, for layer f_t, I assume these will yield the last two output of the whole convolutional lstm process instead of the output at time step t-1 and t-2. Can anyone please help verify if this will return the output at time step t-1 and t-2? 

In addition, is there any way to add f_t as the input of the next time step (of the convlstm layers)? I cannot see the attention layer being added to model.summary(). So is there any way to integrate the attention layer to the model? The output of the model should be a series of one-hot encoding of the vertices. 

Thanks,
Max

P.S. skipfeature is the convolution encoder's output, shape: (?, 112, 112, 128)",Max-Fu,None,2018-06-26T07:04:29Z,2018-09-14T06:12:38Z
10519,Debug Help !,"I dont understand the error , neither do I know how to fix it . Can anyone please help ? 
File ""C:\Users\Saheli\Anaconda3\envs\deeplearning\lib\site-packages\keras\engine\training.py"", line 76, in _standardize_input_data
    data = [np.expand_dims(x, 1) if x is not None and x.ndim == 1 else x for x in data]
  File ""C:\Users\Saheli\Anaconda3\envs\deeplearning\lib\site-packages\keras\engine\training.py"", line 76, in <listcomp>
    data = [np.expand_dims(x, 1) if x is not None and x.ndim == 1 else x for x in data]
AttributeError: 'str' object has no attribute 'ndim'",SaheliDe,None,2018-06-23T20:48:34Z,2020-08-05T08:28:35Z
10417,Loading saved model fails with ValueError You are trying to load a weight file containing 1 layers into a model with 0 layers,"This toy example
```
import sys
import keras
from keras import Sequential
from keras.activations import linear
from keras.engine import InputLayer
from keras.layers import Dense
from keras.losses import mean_squared_error
from keras.metrics import mean_absolute_error
from keras.models import load_model
from keras.optimizers import sgd

print(""Python version: "" + sys.version)
print(""Keras version: "" + keras.__version__)

model = Sequential()
model.add(InputLayer(batch_input_shape=(1, 5)))
model.add(Dense(10, activation=linear))
model.compile(loss=mean_squared_error, optimizer=sgd(), metrics=[mean_absolute_error])

model.save('test.h5')
del model
load_model('test.h5')
```
gives the following output/error
```
Using TensorFlow backend.
Python version: 3.6.5 (default, Apr 25 2018, 14:23:58) 
[GCC 4.2.1 Compatible Apple LLVM 9.1.0 (clang-902.0.39.1)]
Keras version: 2.2.0
2018-06-13 12:02:50.570395: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
Traceback (most recent call last):
  File ""/Users/samb/IdeaProjects/connect-four-challenge-client-python3/test.py"", line 22, in <module>
    load_model('test.h5')
  File ""/Users/samb/IdeaProjects/connect-four-challenge-client-python3/venv/lib/python3.6/site-packages/keras/engine/saving.py"", line 264, in load_model
    load_weights_from_hdf5_group(f['model_weights'], model.layers)
  File ""/Users/samb/IdeaProjects/connect-four-challenge-client-python3/venv/lib/python3.6/site-packages/keras/engine/saving.py"", line 901, in load_weights_from_hdf5_group
    str(len(filtered_layers)) + ' layers.')
ValueError: You are trying to load a weight file containing 1 layers into a model with 0 layers.
```

Looking at https://github.com/keras-team/keras/blob/2.2.0/keras/engine/saving.py#L883 when debugging, I see that in
```
    filtered_layers = []
    for layer in layers:
        weights = layer.weights
        if weights:
          filtered_layers.append(layer)
```
the value of `weights` is always the empty list `[]` whereas in the subsequent block
```
    layer_names = filtered_layer_names
    if len(layer_names) != len(filtered_layers):
        raise ValueError('You are trying to load a weight file '
                         'containing ' + str(len(layer_names)) +
                         ' layers into a model with ' +
                         str(len(filtered_layers)) + ' layers.')
```
the value of `layer_names` (respectively, `filtered_layer_names`), is the singleton list `['dense_1']` leading to the error message shown above.

I'm not quite certain what the cause of the problem is. Is something going wrong in saving the model? Or is something wrong when loading the model (before loading the weights)? Or is something wrong in this logic for loading the weights?
```",SamuelBucheliZ,None,2018-06-13T10:12:53Z,2020-10-03T08:58:59Z
10409,Keras 2.2.0 bug in keras.legacy,"I tried to install Keras 2.2.0 and it breaks my codebase when I try to use the legacy submodule 

Installing with pip:

`sudo pip install --upgrade keras
`
or

```
sudo uninstall keras
sudo pip install keras
```

leads to the following error:

```
    from keras.legacy import models as legacy_models
  File ""/Users/kiddo/anaconda/lib/python3.6/site-packages/keras/legacy/models.py"", line 5, in <module>
    from .layers import Merge
ImportError: cannot import name 'Merge'
```

I do not use Merge at all, but if Merge is removed, you better completely remove it from keras code.


Installing directly from github repo:

```
git clone https://github.com/keras-team/keras.git
cd keras
sudo python setup.py install
```

leads to the following error:

```
    from keras.legacy import models as legacy_models
ImportError: cannot import name 'models'
```

Here the whole submodule (folder) is missing...

I removed calls to legacy from my codebase, but still keras code should be able to load correctly.

",iliaschalkidis,None,2018-06-12T10:52:15Z,2018-06-13T07:11:23Z
10406,Keras create model problem,"i am new in keras and i fallow just a simple tuto about it, 
when i try to execute the fallowing code from the official website of keras i'm getting an error .
i use the last version of keras using theano 2.1.6 as backend
```
from keras.models import Sequential 
from keras.layers import Dense, Activation

model = Sequential([
    Dense(32, input_shape=(784,)),
    Activation('relu'),
    Dense(10),
    Activation('softmax'),
])
```
and the error is
```
---------------------------------------------------------------------------
OSError                                   Traceback (most recent call last)
<ipython-input-7-6a9867103bba> in <module>()
      1 model = Sequential()
----> 2 model.add(Dense(12, input_dim=8, activation='relu'))
      3 model.add(Dense(8, activation='relu'))
      4 model.add(Dense(1, activation='sigmoid'))

/usr/local/lib/python2.7/dist-packages/keras/models.pyc in add(self, layer)
    495                 # and create the node connecting the current layer
    496                 # to the input layer we just created.
--> 497                 layer(x)
    498 
    499             if len(layer._inbound_nodes[-1].output_tensors) != 1:

/usr/local/lib/python2.7/dist-packages/keras/engine/topology.pyc in __call__(self, inputs, **kwargs)
    590                                          '`layer.build(batch_input_shape)`')
    591                 if len(input_shapes) == 1:
--> 592                     self.build(input_shapes[0])
    593                 else:
    594                     self.build(input_shapes)

/usr/local/lib/python2.7/dist-packages/keras/layers/core.pyc in build(self, input_shape)
    862                                       name='kernel',
    863                                       regularizer=self.kernel_regularizer,
--> 864                                       constraint=self.kernel_constraint)
    865         if self.use_bias:
    866             self.bias = self.add_weight(shape=(self.units,),

/usr/local/lib/python2.7/dist-packages/keras/legacy/interfaces.pyc in wrapper(*args, **kwargs)
     89                 warnings.warn('Update your `' + object_name +
     90                               '` call to the Keras 2 API: ' + signature, stacklevel=2)
---> 91             return func(*args, **kwargs)
     92         wrapper._original_function = func
     93         return wrapper

/usr/local/lib/python2.7/dist-packages/keras/engine/topology.pyc in add_weight(self, name, shape, dtype, initializer, regularizer, trainable, constraint)
    411         if dtype is None:
    412             dtype = K.floatx()
--> 413         weight = K.variable(initializer(shape),
    414                             dtype=dtype,
    415                             name=name,

/usr/local/lib/python2.7/dist-packages/keras/initializers.pyc in __call__(self, shape, dtype)
    215             limit = np.sqrt(3. * scale)
    216             return K.random_uniform(shape, -limit, limit,
--> 217                                     dtype=dtype, seed=self.seed)
    218 
    219     def get_config(self):

/usr/local/lib/python2.7/dist-packages/keras/backend/theano_backend.pyc in random_uniform(shape, minval, maxval, dtype, seed)
   2319         seed = np.random.randint(1, 10e6)
   2320     rng = RandomStreams(seed=seed)
-> 2321     return rng.uniform(shape, low=minval, high=maxval, dtype=dtype)
   2322 
   2323 

/usr/local/lib/python2.7/dist-packages/theano/sandbox/rng_mrg.pyc in uniform(self, size, low, high, ndim, dtype, nstreams, **kwargs)
    870         if nstreams is None:
    871             nstreams = self.n_streams(size)
--> 872         rstates = self.get_substream_rstates(nstreams, dtype)
    873 
    874         d = {}

/usr/local/lib/python2.7/dist-packages/theano/configparser.pyc in res(*args, **kwargs)
    115         def res(*args, **kwargs):
    116             with self:
--> 117                 return f(*args, **kwargs)
    118         return res
    119 

/usr/local/lib/python2.7/dist-packages/theano/sandbox/rng_mrg.pyc in get_substream_rstates(self, n_streams, dtype, inc_rstate)
    777         # If multMatVect.dot_modulo isn't compiled, compile it.
    778         if multMatVect.dot_modulo is None:
--> 779             multMatVect(rval[0], A1p72, M1, A2p72, M2)
    780 
    781         # This way of calling the Theano fct is done to bypass Theano overhead.

/usr/local/lib/python2.7/dist-packages/theano/sandbox/rng_mrg.pyc in multMatVect(v, A, m1, B, m2)
     60         o = DotModulo()(A_sym, s_sym, m_sym, A2_sym, s2_sym, m2_sym)
     61         multMatVect.dot_modulo = function(
---> 62             [A_sym, s_sym, m_sym, A2_sym, s2_sym, m2_sym], o, profile=False)
     63 
     64     # This way of calling the Theano fct is done to bypass Theano overhead.

/usr/local/lib/python2.7/dist-packages/theano/compile/function.pyc in function(inputs, outputs, mode, updates, givens, no_default_updates, accept_inplace, name, rebuild_strict, allow_input_downcast, profile, on_unused_input)
    315                    on_unused_input=on_unused_input,
    316                    profile=profile,
--> 317                    output_keys=output_keys)
    318     return fn

/usr/local/lib/python2.7/dist-packages/theano/compile/pfunc.pyc in pfunc(params, outputs, mode, updates, givens, no_default_updates, accept_inplace, name, rebuild_strict, allow_input_downcast, profile, on_unused_input, output_keys)
    484                          accept_inplace=accept_inplace, name=name,
    485                          profile=profile, on_unused_input=on_unused_input,
--> 486                          output_keys=output_keys)
    487 
    488 

/usr/local/lib/python2.7/dist-packages/theano/compile/function_module.pyc in orig_function(inputs, outputs, mode, accept_inplace, name, profile, on_unused_input, output_keys)
   1839                   name=name)
   1840         with theano.change_flags(compute_test_value=""off""):
-> 1841             fn = m.create(defaults)
   1842     finally:
   1843         t2 = time.time()

/usr/local/lib/python2.7/dist-packages/theano/compile/function_module.pyc in create(self, input_storage, trustme, storage_map)
   1713             theano.config.traceback.limit = theano.config.traceback.compile_limit
   1714             _fn, _i, _o = self.linker.make_thunk(
-> 1715                 input_storage=input_storage_lists, storage_map=storage_map)
   1716         finally:
   1717             theano.config.traceback.limit = limit_orig

/usr/local/lib/python2.7/dist-packages/theano/gof/link.pyc in make_thunk(self, input_storage, output_storage, storage_map)
    697         return self.make_all(input_storage=input_storage,
    698                              output_storage=output_storage,
--> 699                              storage_map=storage_map)[:3]
    700 
    701     def make_all(self, input_storage, output_storage):

/usr/local/lib/python2.7/dist-packages/theano/gof/vm.pyc in make_all(self, profiler, input_storage, output_storage, storage_map)
   1089                                                  compute_map,
   1090                                                  [],
-> 1091                                                  impl=impl))
   1092                 linker_make_thunk_time[node] = time.time() - thunk_start
   1093                 if not hasattr(thunks[-1], 'lazy'):

/usr/local/lib/python2.7/dist-packages/theano/gof/op.pyc in make_thunk(self, node, storage_map, compute_map, no_recycling, impl)
    953             try:
    954                 return self.make_c_thunk(node, storage_map, compute_map,
--> 955                                          no_recycling)
    956             except (NotImplementedError, utils.MethodNotDefined):
    957                 # We requested the c code, so don't catch the error.

/usr/local/lib/python2.7/dist-packages/theano/gof/op.pyc in make_c_thunk(self, node, storage_map, compute_map, no_recycling)
    856         _logger.debug('Trying CLinker.make_thunk')
    857         outputs = cl.make_thunk(input_storage=node_input_storage,
--> 858                                 output_storage=node_output_storage)
    859         thunk, node_input_filters, node_output_filters = outputs
    860 

/usr/local/lib/python2.7/dist-packages/theano/gof/cc.pyc in make_thunk(self, input_storage, output_storage, storage_map, keep_lock)
   1215         cthunk, module, in_storage, out_storage, error_storage = self.__compile__(
   1216             input_storage, output_storage, storage_map,
-> 1217             keep_lock=keep_lock)
   1218 
   1219         res = _CThunk(cthunk, init_tasks, tasks, error_storage, module)

/usr/local/lib/python2.7/dist-packages/theano/gof/cc.pyc in __compile__(self, input_storage, output_storage, storage_map, keep_lock)
   1155                                             output_storage,
   1156                                             storage_map,
-> 1157                                             keep_lock=keep_lock)
   1158         return (thunk,
   1159                 module,

/usr/local/lib/python2.7/dist-packages/theano/gof/cc.pyc in cthunk_factory(self, error_storage, in_storage, out_storage, storage_map, keep_lock)
   1617             for node in self.node_order:
   1618                 node.op.prepare_node(node, storage_map, None, 'c')
-> 1619             module = get_module_cache().module_from_key(
   1620                 key=key, lnk=self, keep_lock=keep_lock)
   1621 

/usr/local/lib/python2.7/dist-packages/theano/gof/cc.pyc in get_module_cache(init_args)
     46 
     47     """"""
---> 48     return cmodule.get_module_cache(config.compiledir, init_args=init_args)
     49 
     50 

/usr/local/lib/python2.7/dist-packages/theano/gof/cmodule.pyc in get_module_cache(dirname, init_args)
   1577         init_args = {}
   1578     if _module_cache is None:
-> 1579         _module_cache = ModuleCache(dirname, **init_args)
   1580         atexit.register(_module_cache._on_atexit)
   1581     elif init_args:

/usr/local/lib/python2.7/dist-packages/theano/gof/cmodule.pyc in __init__(self, dirname, check_for_broken_eq, do_refresh)
    693 
    694         if do_refresh:
--> 695             self.refresh()
    696 
    697     age_thresh_use = config.cmodule.age_thresh_use  # default 24 days

/usr/local/lib/python2.7/dist-packages/theano/gof/cmodule.pyc in refresh(self, age_thresh_use, delete_if_problem, cleanup)
    784             if not os.path.isdir(root):
    785                 continue
--> 786             files = os.listdir(root)
    787             if not files:
    788                 rmtree_empty(root, ignore_nocleanup=True,

OSError: [Errno 13] Permission denied: '/home/tuxkiller/.theano/compiledir_Linux-4.15--generic-x86_64-with-Ubuntu-18.04-bionic-x86_64-2.7.15rc1-64/tmp6AeDTf'
```",tuxkiller17,None,2018-06-12T00:56:17Z,2018-06-12T01:13:36Z
10325,TensorBoard Debugger with Keras; TypeError: zip argument #1 must support iteration,"- [x] Check that you are up-to-date with the master branch of Keras. You can update with:
pip install git+git://github.com/keras-team/keras.git --upgrade --no-deps

- [x] If running on TensorFlow, check that you are up-to-date with the latest version. The installation instructions can be found [here](https://www.tensorflow.org/get_started/os_setup).

- [x] Provide a link to a GitHub Gist of a Python script that can reproduce your issue (or just copy the script here if it is short).


Is it possible to use Keras with the TensorBoard debugger? I have used the code posted under Keras within TensorBoard:

import tensorflow as tf
from tensorflow.python import debug as tf_debug
import keras

keras.backend.set_session(
    tf_debug.TensorBoardDebugWrapperSession(tf.Session(), ""DESKTOP-AB123CD:6064"")).
model.fit(...)

**The callbacks are generated with:**
tensorboard=TensorBoard(log_dir=""logs/{}"".format(time())
along wit the callbacks=[tensorboard] in model.fit()


**It is opened in command line with:**
tensorboard --logdir=logs/ --port 6006 --debugger 6064

**But, I get the following error when it runs.**

Traceback (most recent call last):
  File ""C:\Program Files\JetBrains\PyCharm 2018.1.3\helpers\pydev\pydevd.py"", line 1664, in <module>
    main()
  File ""C:\Program Files\JetBrains\PyCharm 2018.1.3\helpers\pydev\pydevd.py"", line 1658, in main
    globals = debugger.run(setup['file'], None, None, is_module)
  File ""C:\Program Files\JetBrains\PyCharm 2018.1.3\helpers\pydev\pydevd.py"", line 1068, in run
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File ""C:\Program Files\JetBrains\PyCharm 2018.1.3\helpers\pydev\_pydev_imps\_pydev_execfile.py"", line 18, in execfile
    exec(compile(contents+""\n"", file, 'exec'), glob, loc)
  File ""C:/Users/Name/Desktop/files/CNN.py"", line 139, in <module>
    CNN.add(Conv3D(50,kernel_size=(3,3,3),activation='relu',input_shape=(4,20,20,20), data_format='channels_first',kernel_initializer='glorot_uniform',name='test'))
  File ""C:\Users\Name\venv\lib\site-packages\keras\models.py"", line 497, in add
    layer(x)
  File ""C:\Users\Name\venv\lib\site-packages\keras\engine\topology.py"", line 619, in __call__
    output = self.call(inputs, **kwargs)
  File ""C:\Users\Name\venv\lib\site-packages\keras\layers\convolutional.py"", line 176, in call
    dilation_rate=self.dilation_rate)
  File ""C:\Users\Name\venv\lib\site-packages\keras\backend\tensorflow_backend.py"", line 3559, in conv3d
    x, tf_data_format = _preprocess_conv3d_input(x, data_format)
  File ""C:\Users\Name\venv\lib\site-packages\keras\backend\tensorflow_backend.py"", line 3235, in _preprocess_conv3d_input
    if not _has_nchw_support():
  File ""C:\Users\Name\venv\lib\site-packages\keras\backend\tensorflow_backend.py"", line 286, in _has_nchw_support
    gpus_available = len(_get_available_gpus()) > 0
  File ""C:\Users\Name\venv\lib\site-packages\keras\backend\tensorflow_backend.py"", line 272, in _get_available_gpus
    _LOCAL_DEVICES = get_session().list_devices()
  File ""C:\Users\Name\venv\lib\site-packages\keras\backend\tensorflow_backend.py"", line 195, in get_session
    for flag, v in zip(is_initialized, candidate_vars):
TypeError: zip argument #1 must support iteration



**I have tried quite a few different ways to get this to work, but it seems it may not be supported by Keras yet? **

I also get an error when initially opening up the TensorBoard link in a browser:
/[[_dataImageSrc]] not found, sending 404
/[[_imagureURL]] not found, sending 404

But this may not be related and doesn't seem to affect anything.


Thanks",ghost,None,2018-05-30T23:07:07Z,2018-06-02T02:20:24Z
10297,"I can get flatten input size, however, the output size is unknown.","Please make sure that the boxes below are checked before you submit your issue. If your issue is an implementation question, please ask your question on [StackOverflow](http://stackoverflow.com/questions/tagged/keras) or [join the Keras Slack channel](https://keras-slack-autojoin.herokuapp.com/) and ask there instead of filing a GitHub issue.

Thank you!

- [Y] Check that you are up-to-date with the master branch of Keras. You can update with:
pip install git+git://github.com/keras-team/keras.git --upgrade --no-deps

- [Y] If running on TensorFlow, check that you are up-to-date with the latest version. The installation instructions can be found [here](https://www.tensorflow.org/get_started/os_setup).

- [N] If running on Theano, check that you are up-to-date with the master branch of Theano. You can update with:
pip install git+git://github.com/Theano/Theano.git --upgrade --no-deps

- [Y] Provide a link to a GitHub Gist of a Python script that can reproduce your issue (or just copy the script here if it is short).


I run [cifar10_resnet.py](https://github.com/keras-team/keras/blob/master/examples/cifar10_resnet.py), I want to get flatten layer output size but the the result is unknown.
```
model.get_layer('flatten_1').output
<tf.Tensor 'flatten_1/Reshape:0' shape=(?, ?) dtype=float32>

```
however, the input is known
```
model.get_layer('flatten_1').input
<tf.Tensor 'average_pooling2d_1/AvgPool:0' shape=(?, 1, 1, 64) dtype=float32>
```

Is it bug?
@fchollet ",FrancisYizhang,b'wontfix',2018-05-27T15:12:35Z,2018-05-27T15:47:29Z
10265,"model.load_weights(, by_name=True, skip_mismatch=False) doesn't fail if weight shapes mismatch","# Intro
- Pulled from master at abd029405c97733de24102695cb4b6cef1f47bff

- Using Theano backend, version 1.0.1+100.g2c19431b1, with a GPU device

- Repro gist: https://gist.github.com/AmirAlavi/cfac18bb1ac00c500e8bdeb879db3d5e
    - part1.py (saves weights from a model)
    - part2.py (creates a very similar architecture, last layer has different size, loads weights from part1 and trains (like fine tuning))

When loading weights from a weights file that may have slightly different architecture, we typically use load_weights with an argument of `by_name=True` (common if you are using pretrained weights from strategies such as stacked DAEs). However, layers with the same name can still differ in size (example: in some pretraining strategies (unsupervised), a final classification layer is ignored, so its size is arbitrary, and if saved, can disagree with the final supervised model).

# Expected behavior:
If I try to load weights with `load_weights(by_name=True, skip_mismatch=False)`, and a saved layer weight has different shape than the model's corresponding weight, this function should call should result in a ValueError, similar to when the number of weights don't match.

# Observed behavior:
Aforementioned `load_weights` call succeeds, user encounters an input dimension mismatch downstream during training.

part1.py output:
```
Using Theano backend.
WARNING (theano.configdefaults): install mkl with `conda install mkl-service`: No module named 'mkl'
WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.
ERROR (theano.gpuarray): pygpu was configured but could not be imported or is too old (version 0.7 or higher required)
NoneType: None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 20)                0         
_________________________________________________________________
dense_1 (Dense)              (None, 15)                315       
_________________________________________________________________
dense_2 (Dense)              (None, 10)                160       
_________________________________________________________________
dense_3 (Dense)              (None, 30)                330       
=================================================================
Total params: 805
Trainable params: 805
Non-trainable params: 0
_________________________________________________________________
None
```
part2.py output **(Note how the number of parameters in dense_3 changed after the call to `load_weights`)**:
```
Using Theano backend.
WARNING (theano.configdefaults): install mkl with `conda install mkl-service`: No module named 'mkl'
WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.
ERROR (theano.gpuarray): pygpu was configured but could not be imported or is too old (version 0.7 or higher required)
NoneType: None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 20)                0         
_________________________________________________________________
dense_1 (Dense)              (None, 15)                315       
_________________________________________________________________
dense_2 (Dense)              (None, 10)                160       
_________________________________________________________________
dense_3 (Dense)              (None, 7)                 77        
=================================================================
Total params: 552
Trainable params: 552
Non-trainable params: 0
_________________________________________________________________
None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 20)                0         
_________________________________________________________________
dense_1 (Dense)              (None, 15)                315       
_________________________________________________________________
dense_2 (Dense)              (None, 10)                160       
_________________________________________________________________
dense_3 (Dense)              (None, 7)                 330       
=================================================================
Total params: 805
Trainable params: 805
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/1
Traceback (most recent call last):
  File ""/home/aalavi/anaconda2/envs/keras_pr/lib/python3.6/site-packages/theano/compile/function_module.py"", line 903, in __call__
    self.fn() if output_subset is None else\
ValueError: Input dimension mis-match. (input[0].shape[1] = 30, input[3].shape[1] = 7)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""part2.py"", line 32, in <module>
    main()
  File ""part2.py"", line 29, in main
    model2.fit(X, y)
  File ""/home/aalavi/anaconda2/envs/keras_pr/lib/python3.6/site-packages/Keras-2.1.6-py3.6.egg/keras/engine/training.py"", line 1037, in fit
  File ""/home/aalavi/anaconda2/envs/keras_pr/lib/python3.6/site-packages/Keras-2.1.6-py3.6.egg/keras/engine/training_arrays.py"", line 199, in fit_loop
  File ""/home/aalavi/anaconda2/envs/keras_pr/lib/python3.6/site-packages/Keras-2.1.6-py3.6.egg/keras/backend/theano_backend.py"", line 1254, in __call__
  File ""/home/aalavi/anaconda2/envs/keras_pr/lib/python3.6/site-packages/theano/compile/function_module.py"", line 917, in __call__
    storage_map=getattr(self.fn, 'storage_map', None))
  File ""/home/aalavi/anaconda2/envs/keras_pr/lib/python3.6/site-packages/theano/gof/link.py"", line 325, in raise_with_op
    reraise(exc_type, exc_value, exc_trace)
  File ""/home/aalavi/anaconda2/envs/keras_pr/lib/python3.6/site-packages/six.py"", line 692, in reraise
    raise value.with_traceback(tb)
  File ""/home/aalavi/anaconda2/envs/keras_pr/lib/python3.6/site-packages/theano/compile/function_module.py"", line 903, in __call__
    self.fn() if output_subset is None else\
ValueError: Input dimension mis-match. (input[0].shape[1] = 30, input[3].shape[1] = 7)
Apply node that caused the error: Elemwise{Composite{((i0 * i1 * i2 * i3 * i4) / (i5 * i6 * i6))}}(Elemwise{Composite{AND(GE(i0, i1), LE(i0, i2))}}.0, Elemwise{Composite{(i0 / (i1 * i2))}}.0, InplaceDimShuffle{0,x}.0, /dense_3_target, SoftmaxWithBias.0, Elemwise{Clip}[(0, 0)].0, InplaceDimShuffle{0,x}.0)
Toposort index: 33
Inputs types: [TensorType(bool, matrix), TensorType(float32, (True, True)), TensorType(float32, col), TensorType(float32, matrix), TensorType(float32, matrix), TensorType(float32, matrix), TensorType(float32, col)]
Inputs shapes: [(32, 30), (1, 1), (32, 1), (32, 7), (32, 30), (32, 30), (32, 1)]
Inputs strides: [(30, 1), (4, 4), (4, 4), (28, 4), (120, 4), (120, 4), (4, 4)]
Inputs values: ['not shown', array([[0.03125]], dtype=float32), 'not shown', 'not shown', 'not shown', 'not shown', 'not shown']
Outputs clients: [[Sum{axis=[1], acc_dtype=float64}(Elemwise{Composite{((i0 * i1 * i2 * i3 * i4) / (i5 * i6 * i6))}}.0)]]

HINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.
HINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.
```

# Proposed solution:
Check shapes, and unless user specifies `skip_mismatch=True`, fail with a message.",AmirAlavi,None,2018-05-22T21:04:33Z,2018-05-25T02:09:37Z
10213,Bug---Custom loss with metrics [acc] when using sparse categories.,"when i use a custom loss and the second label is sparse.
if the model.compile like this:
model.compile(loss=['binary_crossentropy', self_loss], optimizer='SGD', loss_weights=[1, 1], metrics=['acc']).
the accuracy of the second output will not be correct, i dig into the source code [keras/engine/training] and find that:

for metric in metrics:
                if metric in ('accuracy', 'acc', 'crossentropy', 'ce'):
                    # custom handling of accuracy/crossentropy
                    # (because of class mode duality)
                    output_shape = K.int_shape(self.outputs[i])
                    if (output_shape[-1] == 1 or
                       self.loss_functions[i] == losses.binary_crossentropy):
                        # case: binary accuracy/crossentropy
                        if metric in ('accuracy', 'acc'):
                            metric_fn = metrics_module.binary_accuracy
                        elif metric in ('crossentropy', 'ce'):
                            metric_fn = metrics_module.binary_crossentropy
                    elif self.loss_functions[i] == losses.sparse_categorical_crossentropy:
                        # case: categorical accuracy/crossentropy
                        # with sparse targets
                        if metric in ('accuracy', 'acc'):
                            metric_fn = metrics_module.sparse_categorical_accuracy
                        elif metric in ('crossentropy', 'ce'):
                            metric_fn = metrics_module.sparse_categorical_crossentropy
                    else:
                        # case: categorical accuracy/crossentropy
                        if metric in ('accuracy', 'acc'):
                            metric_fn = metrics_module.categorical_accuracy
                        elif metric in ('crossentropy', 'ce'):
                            metric_fn = metrics_module.categorical_crossentropy

the source code will use categorical_crossentropy if you do not use sparse_categorical_crossentropy when compile. So, i think may be there is a bug. Hope for answering!",LCorleone,None,2018-05-16T11:52:22Z,2018-05-16T11:53:31Z
10175,"Bidirectional(Wrapper),  inputs is not reversed, is a bug !!!  ???","keras.layers.wrapper

y = self.forward_layer.call(inputs, initial_state=forward_state, **kwargs)
y_rev = self.backward_layer.call(inputs, initial_state=backward_state, **kwargs)
",wwmmqq,None,2018-05-11T14:32:09Z,2018-05-13T12:05:27Z
10173,fix TensorBoard callback with unit test,"There's a bug with `TensorBoard` with `histogram_freq>0` and a layer which produces a list of output tensors with different ranks (e.g., an rnn layer with `return_sequences=True` and `return_states=True`). In this situation, the callback attempts to get the mean on the `output` without validating whether it is a tensor or not, which will lead to an error. This pr aims to solve this problem by taking the mean of each output separately. 



BTW, here's another issue which I didn't solve in this pr but want to discuss. Currently `TensorBoard` can not get the output histograms from layers with multiple outputs: It doesn't check the `get_output_at` of those layers in that case, and the 'output' does not exist in those layers. 
Because the same layer can be reused in different models and then not all the outputs of that layer belong to the current model. Is there any efficient way to know if the output at node `i` is part of one model or not?",PeterChe1990,None,2018-05-11T13:48:19Z,2018-05-14T23:52:42Z
10170,keras.utils.sequence loads entire dataset into memory,"https://github.com/keras-team/keras/blob/0ba6d95e768eb7a0d74a6fda3ea893e7fb2d7a67/keras/utils/data_utils.py#L372

Looking at `keras.utils.Sequence` as a possibility to feed a large dataset into a model I came across this line. I might misjudge the context, but it looks to me as if Sequence will pre-fetch the entire dataset (as batches) and then yield single batches from memory.

This makes me wonder, what is the intended use case of Sequence? I think there are more convenient ways to feed a dataset into Keras if it is in memory anyway. I wonder if this is a bug or intended behavior, but I can't tell from the information I have. Please advise.

I can always overwrite `__iter__` and create something that actually loads batches from disk, but since this is not recommended anywhere or talked about, I'm not sure if this is the intended approach.",FirefoxMetzger,None,2018-05-11T07:35:05Z,2020-08-21T14:00:08Z
10156,Conv2D outputting incorrect shape when being run (but not in the model summary),"I have the following in my model description:

        conv_1 = Conv2D(self.network_channel_sizes[0], kernel_size=self.down_conv_kernel, padding='same')(up_4)
        conv_2 = Conv2D(self.network_channel_sizes[0], kernel_size=self.down_conv_kernel, padding='same')(conv_1)
        outputs = Conv2D(filters=1, kernel_size=(1, 1), strides=1, padding='same')(conv_2)
        outputs = LeakyReLU(alpha=self.leaky_alpha)(outputs)

My model summary says this:

    conv2d_17 (Conv2D)              (None, 512, 512, 8)  1160        concatenate_4[0][0]              
    __________________________________________________________________________________________________
    conv2d_18 (Conv2D)              (None, 512, 512, 8)  584         conv2d_17[0][0]                  
    __________________________________________________________________________________________________
    conv2d_19 (Conv2D)              (None, 512, 512, 1)  9           conv2d_18[0][0]                  
    __________________________________________________________________________________________________
    leaky_re_lu_17 (LeakyReLU)      (None, 512, 512, 1)  0           conv2d_19[0][0]                  ```

When I run the training I get this:

    ValueError: Error when checking target: expected leaky_re_lu_17 to have shape (512, 512, 1) but got array with shape (512, 512, 3)

As you can see, conv2d_19 is defined with 1 filter and the leaky_re_lu_17 takes that conv2d_19 as input. In the model summary, the output shape of conv2d_19 matches with this: (None, 512, 512, 1). But when the model is actually run (verified using debug), the shape is (3, 512, 512, 3). Have I done something incorrect in my description, or is this a bug?

EDIT: this is using TF backend if that isn't obvious.
",mikelane,None,2018-05-09T22:10:28Z,2018-05-10T17:38:36Z
10146,Hi keras team. I think i find a bug in imdb.load_data().,"![_20180509171435](https://user-images.githubusercontent.com/22995170/39806472-9f0355aa-53ac-11e8-8bf7-c1210a625a88.png)

I think this is right logic.
Thanks.

",JYLFamily,None,2018-05-09T09:16:11Z,2018-05-22T08:15:20Z
10080,CuDNN RNN layers nested in Model are not converted when loading,"Analogous to CuDNN RNN nested in Bidirectional: #8908

In addition same bug as in: Convert h5py Dataset to np.array before preprocess_weights_for_loading (#9662)

I've already wrote a fix and I'll post a detailed description soon.

```
ValueError: Shapes must be equal rank, but are 2 and 1 for 'Assign_732' (op: 'Assign') with input shapes: [2,384], [768].
```

Bias is not converted from `CuDNNGRU` shape (2*units*gates) to CuDNN-compatible, `GRU(reset_after=True` shape (2, units*gates). The reason that nesting to Model is missing in `keras.topology.saving.preprocess_weights_for_loading()`.

We can do the same as in the block for converting from Keras 1 model.

In addition `weights[2]` is H5 dataset:

```
biases = weights[2].reshape((2, -1) if from_cudnn else -1)
```

and fails with:

```
'Dataset' object has no attribute 'reshape'
```

Fix is:

```
biases = np.array(weights[2]).reshape((2, -1) if from_cudnn else -1)
```",bzamecnik,None,2018-05-01T09:23:25Z,2018-06-05T12:11:10Z
10073,Bug of cntk backend,"I found some bug of cntk backend.

Example code:
```python
import keras.backend as K
import cntk as C
import numpy as np

A=np.array([[1,1,1]])[:,:,np.newaxis]
x = K.placeholder(ndim=3)
f = K.function([x],[C.softmax(x,axis=1)])
print f([A])
print C.softmax(A, axis=1).eval()
```

The result is 
```
[array([[[1.],
        [1.],
        [1.]]], dtype=float32)]
[[[0.33333334]
  [0.33333334]
  [0.33333334]]]
```

It should be the same but the result is different.",bobchennan,None,2018-04-30T17:28:58Z,2018-09-13T11:19:17Z
10068,Pretrained Models have zero accuracy on Imagenet,"I have a problem with pretrained models, I tried to debug, watch variables and everything possible for several days, and I still have the same problem. 
I start loading x_train and y_train, which are a list of all training files on imagenet (in the same folder) and the corresponding list of ground truth values, as a list. 
Then I run the relatively short code that you can find here :
 https://gist.github.com/fernande2000/69f57202c391ec08d1552827d7c635b8
to prepare the data and feed it to a pretrained keras  model with imagenet weights.
The problem is that I get an accuracy=0.0 all the time, even if I keep training. 
The same happens if I use one of the batches, using model.evaluate I also get zero accuracy, even if by hand I can count that the decoded prediction and the provided labels and they agree about 30% of the time (this should also be an issue, an accuracy of 0.3 is still very low for  pretrained weights).  Is there any obvious mistakes in the code, that makes it do something unintended? Thanks!!!
UPDATE: After training a few hours accuracy is up to 50%, I will let it a little more and see what it is that it has learned, which could perhaps give me a clue.",fernande2000,None,2018-04-29T21:27:38Z,2018-05-01T13:49:06Z
9947,Bug: l2_normalize() broken in Keras 2.1.5 with TensorFlow backend,"Gist with minimal reproduceable example to reproduce the bug:

https://gist.github.com/pierluigiferrari/29664c7cd5787a8713e0623eb08f6ca8

Bug description:

Since Keras 2.1.5, if you use the TensorFlow backend, `l2_normalize()` throws the following error when called:

```
---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
<ipython-input-42-56edaf12926f> in <module>()
      1 tensor = K.ones(shape=(16,10,10,256))
----> 2 tensor = K.l2_normalize(tensor, axis=3)

/Users/pierluigiferrari/anaconda/envs/tf1keras2/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py in l2_normalize(x, axis)
   3149         A tensor.
   3150     """"""
-> 3151     return tf.nn.l2_normalize(x, axis=axis)
   3152 
   3153 

TypeError: l2_normalize() got an unexpected keyword argument 'axis'
```

I get this behavior with TF v1.4.1.",pierluigiferrari,None,2018-04-15T17:29:15Z,2018-04-15T17:54:29Z
9946,Static Learning Phase ignored on CNTK,"While working on a bigger PR for the behaviour of Learning Phase on BatchNormalization, I noticed that there is a bug on the CNTK backend that affects how it handles static learning phases. It seems that when the user sets a static learning_phase, it is ignored. I believe the bigger PR requires building a case and thorough discussion, so I decided to split the changes into 2 parts (I will soon document the problem on BN and submit another PR).

**What's the problem on CNTK:**
- The current implementation of learning_phase on CNTK requires it to [always be a tensor](https://github.com/keras-team/keras/blob/master/keras/backend/cntk_backend.py#L63); it can never be an integer even when it is set statically.
- Unfortunately multiple methods on [training.py](https://github.com/keras-team/keras/blob/master/keras/engine/training.py#L1828) check if `isinstance(K.learning_phase(), int)` to decide if the learning phase is static.
- Since the learning_phase on CNTK is never an integer, if the user sets `K.set_learning_phase(1)` it is ignored.

**Things to know about this PR:**
- On the first commit of this PR, I added a test which fails on the current master. The test shows that BatchNormalization operates in test-mode even when the user explicitly sets learning_phase to 1. After applying the patch all tests pass.
- This fix addresses the problem but it's not an elegant solution. If we don't like it, I'm happy to update or close the PR and someone else can provide a better solution.
- I have never worked with CNTK backend before. So I would really appreciate a thorough review from any of the people who wrote the CNTK backend (@taehoonlee, @fchollet, @souptc or @ozabluda)",datumbox,None,2018-04-15T14:56:44Z,2018-04-17T00:49:51Z
9936,limiting number of CPUs with intra_op_parallelism_threads (tensorflow backend),"I'm trying to use a VGG16 model (only predict, no training) on a CPU cluster. However, since it is a shared cluster I have to limit the number of cores used. From googling around, I've landed on the following sample code.

```
from keras.applications.vgg16 import VGG16
from keras import backend as K
import numpy as np

conf = K.tf.ConfigProto(device_count={'CPU': 1}, 
                        intra_op_parallelism_threads=2, 
                        inter_op_parallelism_threads=2)
K.set_session(K.tf.Session(config=conf))
model = VGG16(weights='imagenet', include_top=False)
x = np.random.randn(1000, 224, 224, 3)  # example data
features = model.predict(x)
```

I've tried various variations on this, including setting `allow_soft_placement=True`. However, none of it seems to work: all 128 logical cores on the cluster are used. Might be related to [this issue](https://github.com/tensorflow/tensorflow/issues/4455). 

I'm not sure if this is a keras bug, tensorflow bug or me doing something wrong. Anyway, it would be nice if there was a way to choose the number of CPUs (or GPUs) used using keras, independent of the backend.

Versions:
Tensorflow: 1.6.0
Keras: 2.1.5",wdobbels,None,2018-04-14T12:14:26Z,2020-03-20T16:20:06Z
9885,Different input samples and target samples count from flow_from_directory,"I tried to implement https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html with slight modification because I need to make multi-class classification model. But, for some reason the input and target samples count returning different number.

```
datagen = ImageDataGenerator(rescale=1.0 / 255)

# Read images and labels from train directory and dump it to a file
generator = datagen.flow_from_directory(
    train_data_dir,
    target_size=(img_width, img_height),
    batch_size=batch_size,
    class_mode=None,
    shuffle=False)
bottleneck_features_train = model.predict_generator(
    generator, len(generator.filenames) // batch_size, verbose=1, workers=8)
pickle.dump(bottleneck_features_train, open('bottleneck_features_train.npy', 'wb'))

train_labels = generator.classes
num_classes = generator.class_indices
train_labels = pd.get_dummies(pd.Series(train_labels))

train_data = np.load('bottleneck_features_train.npy')

# for debugging purpose to show this issue
print(len(train_data), len(train_labels))

model = Sequential()
model.add(Flatten(input_shape=train_data.shape[1:]))
model.add(Dense(256, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(34, activation='sigmoid'))

model.compile(optimizer='rmsprop',
              loss='categorical_crossentropy', metrics=['accuracy'])

# It will fail here because the train_data and train_labels are not the same length for some reason
history = model.fit(
    train_data,
    train_labels,
    epochs=epochs,
    batch_size=batch_size)
```

Here's the console result:
![image](https://user-images.githubusercontent.com/2961388/38489173-2b8f8748-3c18-11e8-81e3-c690159d66ed.png)

What I've checked:
- File formats, I've made sure all of them are JPGs
- Corrupted files: I've tried to go through each file and open it using `PIL` and everything load just fine",haydarai,None,2018-04-09T09:10:01Z,2018-04-10T16:26:20Z
9865,Fixed the NASNet issue.,"This fixes the bug reported in #9812 .

To reproduce the bug:
```python
from keras.applications import NASNetLarge
NASNetLarge(include_top=False, input_shape=(512,512,3))
```

We get this traceback:
```
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
<ipython-input-4-f0280447738f> in <module>()
----> 1 NASNetLarge(include_top=False, input_shape=(512,512,3))

/mnt/c/Users/yolo/Desktop/projects/keras/keras/applications/nasnet.py in NASNetLarge(input_shape, include_top, weights, input_tensor, pooling, classes)
    364                   pooling=pooling,
    365                   classes=classes,
--> 366                   default_size=331)
    367
    368

/mnt/c/Users/yolo/Desktop/projects/keras/keras/applications/nasnet.py in NASNet(input_shape, penultimate_filters, num_blocks, stem_block_filters, skip_reduction, filter_multiplier, include_top, weights, input_tensor, pooling, classes, default_size)
    169                                       data_format=K.image_data_format(),
    170                                       require_flatten=include_top or weights,
--> 171                                       weights=weights)
    172
    173     if K.image_data_format() != 'channels_last':

/mnt/c/Users/yolo/Desktop/projects/keras/keras/applications/imagenet_utils.py in _obtain_input_shape(input_shape, default_size, min_size, data_format, require_flatten, weights)
    269                                  'and loading `imagenet` weights, '
    270                                  '`input_shape` should be ' +
--> 271                                  str(default_shape) + '.')
    272         return default_shape
    273     if input_shape:

ValueError: When setting`include_top=True` and loading `imagenet` weights, `input_shape` should be (331, 331, 3).
```

Should I add a test to the PR or is it overkill?",gabrieldemarmiesse,None,2018-04-06T17:53:42Z,2018-09-18T06:32:09Z
9701,How to get out last softmax's input,"Is there an easy way to get out the **input** of the last softmax activation function?
I have bigger (512) Dense layer before my classification layer (Dense layer with 12 neurons, with softmax activation) and want to get out the input of the softmax function. 

```python
model = Sequential()
# ...
# Layer 5
model.add(Dense(512, activation=""relu"",
                  kernel_initializer=""he_uniform"", bias_initializer=""zeros"",
                  kernel_regularizer=l2(l**2*(0.7) / (2.*N))))
model.add(Dropout(0.3))
# Layer 6
model.add(Dense(12, activation=""softmax"",
                  kernel_initializer=""he_uniform"", bias_initializer=""zeros""))
``` 

By doing `K.function([model.layers[0].input, K.learning_phase()], [model.layers[-1].input])`  I got an (1, 512) array (just as `model.layers[-2].output`) - but I want an (1, 12) array, just as `model.layers[-1].output`

PS: I've tried to add a `lambda x: x` debug layer, but that has the same (512) shape as the layer before",andrisecker,None,2018-03-19T11:44:28Z,2018-03-19T14:24:59Z
9683,load_weights by_name didn't work,"there is a key part of my code.(the weights file is downloaded from url in the source code)
```
from keras.applications import Xception
cnn_model = Xception(include_top=False, input_shape=(width, width, 3), weights=None)
cnn_model.load_weights('./xception_weights_tf_dim_ordering_tf_kernels_notop.h5')
```
it works **alright**, and loss is good.

However,when I only modify the last line of code to
`cnn_model.load_weights('./xception_weights_tf_dim_ordering_tf_kernels_notop.h5',by_name=True)`


there is no error or any warning,however, ths loss is much **worse** than before(just like random initial).



I suspect whether the parameter **by_name=True** works right.is this a bug or just my fault?



(I am going to modify the Xception structure and use pre-trained weights.So,i try this code.",dddzg,None,2018-03-17T13:33:31Z,2020-04-12T08:03:02Z
9657,Fix to add_ngram function and docstring,"This PR addresses a small bug first noted in Issue #7352. The `add_ngram` function does not check the full sequence when `ngram_range` is greater than 2. This small change fixes that, and updates the docstring to reflect the effect of the change.",edrogers,None,2018-03-14T16:27:25Z,2018-03-14T22:28:35Z
9599,bug fix - run_internal_graph(),See #9565,farizrahman4u,None,2018-03-08T20:07:55Z,2019-03-01T11:51:29Z
9595,A model saved with Python3.5 cannot be loaded in Python3.6,"... at least if it includes a Lambda layer.

Minimal example:

Run save_model.py on Python3.5:

```
from keras.layers import Input, Lambda
from keras.models import Model

def noop(x):
    return x

inp = Input(shape=(None, 1))
output = Lambda(noop)(inp)

model = Model(inputs=inp, outputs=output)
model.save('result.h5')
```

Loading the model from Python3.5 also works:
```
from keras.models import load_model
load_model('result.h5')
```

But Python3.6 raises a SystemError:

```
XXX lineno: 7, opcode: 0
Traceback (most recent call last):
  File ""load_model.py"", line 3, in <module>
    load_model('result.h5')
  File ""/home/david/.virtualenvs/py36/lib/python3.6/site-packages/keras/models.py"", line 243, in load_model
    model = model_from_config(model_config, custom_objects=custom_objects)
  File ""/home/david/.virtualenvs/py36/lib/python3.6/site-packages/keras/models.py"", line 317, in model_from_config
    return layer_module.deserialize(config, custom_objects=custom_objects)
  File ""/home/david/.virtualenvs/py36/lib/python3.6/site-packages/keras/layers/__init__.py"", line 55, in deserialize
    printable_module_name='layer')
  File ""/home/david/.virtualenvs/py36/lib/python3.6/site-packages/keras/utils/generic_utils.py"", line 144, in deserialize_keras_object
    list(custom_objects.items())))
  File ""/home/david/.virtualenvs/py36/lib/python3.6/site-packages/keras/engine/topology.py"", line 2524, in from_config
    process_node(layer, node_data)
  File ""/home/david/.virtualenvs/py36/lib/python3.6/site-packages/keras/engine/topology.py"", line 2481, in process_node
    layer(input_tensors[0], **kwargs)
  File ""/home/david/.virtualenvs/py36/lib/python3.6/site-packages/keras/engine/topology.py"", line 619, in __call__
    output = self.call(inputs, **kwargs)
  File ""/home/david/.virtualenvs/py36/lib/python3.6/site-packages/keras/layers/core.py"", line 663, in call
    return self.function(inputs, **arguments)
  File ""save_model.py"", line 7, in self_outer
    return x
SystemError: unknown opcode
```

Contrary to what was stated in bug #7297, the problem is indeed in Keras, since the error is triggered before any call to the backend. The problem appears in both Tensorflow and Theano. Also, both in Keras 2.1.5 and master.",Dapid,None,2018-03-08T13:02:09Z,2019-01-31T05:11:50Z
9565,[Bug ?] : Model with two-output Lambda layer cannot be called,"Hey, 

I needed to normalize my input data, to keep the norm and inverse the normalization. I used a Lambda layer for this and it works well.

```
import numpy as np
from keras import backend as K
from keras import Input, Model, Sequential
from keras.layers import Dense, Lambda, TimeDistributed, multiply

def l2(x):
    axis=-1
    square_sum = K.sum(K.square(x), axis=axis, keepdims=True)
    norm = K.sqrt(K.maximum(square_sum, K.epsilon()))
    return [x/norm, norm]
    
def l2_output_shape(input_shape):
    return [input_shape, input_shape]

def build_generator(a, b):
    inp = Input(shape=(None, a, b))
    x, norm = Lambda(l2, output_shape=l2_output_shape)(inp)
    x = TimeDistributed(Dense(b))(x)
    out = multiply([x, norm])
    model = Model(inp, out)
    return model

a = 10
b = 50
generator = build_generator(a, b)
```
If I compile the model, I can use the methods `predict` and `fit` without problem. 

But I don't compile the model just yet, because I want to use it as the generator of a GAN. So I do something similar to the [mnist_acgan example](https://github.com/keras-team/keras/blob/master/examples/mnist_acgan.py#L138).

```
generator_inp = Input(shape=(a, b))
fake = generator(generator_inp)
```
And this doesn't work, I give you the full traceback : 
```
AssertionError                            Traceback (most recent call last)
/home/claire/Bureau/Main/decibel-se/minimal_example.py in <module>()
     31 
     32 generator_inp = Input(shape=(a, b))
---> 33 fake = generator(generator_inp)
     34 
     35 

/home/claire/anaconda2/lib/python2.7/site-packages/keras/engine/topology.pyc in __call__(self, inputs, **kwargs)
    617 
    618             # Actually call the layer, collecting output(s), mask(s), and shape(s).
--> 619             output = self.call(inputs, **kwargs)
    620             output_mask = self.compute_mask(inputs, previous_mask)
    621 

/home/claire/anaconda2/lib/python2.7/site-packages/keras/engine/topology.pyc in call(self, inputs, mask)
   2081             return self._output_tensor_cache[cache_key]
   2082         else:
-> 2083             output_tensors, _, _ = self.run_internal_graph(inputs, masks)
   2084             return output_tensors
   2085 

/home/claire/anaconda2/lib/python2.7/site-packages/keras/engine/topology.pyc in run_internal_graph(self, inputs, masks)
   2285         output_shapes = []
   2286         for x in self.outputs:
-> 2287             assert str(id(x)) in tensor_map, 'Could not compute output ' + str(x)
   2288             tensor, mask = tensor_map[str(id(x))]
   2289             if hasattr(tensor, '_keras_shape') and output_shapes is not None:

AssertionError: Could not compute output Tensor(""multiply_1/mul:0"", shape=(?, 10, 50), dtype=float32)
```

I can make it work in this way, but it's not efficient and it tells me that the only problem is that the Lambda layer has two outputs.
Here I use two lambda layers which are doing the computation twice but each one has only one output. 
```
import numpy as np
from keras import backend as K
from keras import Input, Model, Sequential
from keras.layers import Dense, Lambda, TimeDistributed, multiply

def l2(x):
    axis=-1
    square_sum = K.sum(K.square(x), axis=axis, keepdims=True)
    norm = K.sqrt(K.maximum(square_sum, K.epsilon()))
    return x/norm

def ret_l2(x):
    axis=-1
    square_sum = K.sum(K.square(x), axis=axis, keepdims=True)
    norm = K.sqrt(K.maximum(square_sum, K.epsilon()))
    return norm

def l2_output_shape(input_shape):
    return input_shape

def build_generator(a, b):
    inp = Input(shape=(a, b))
    x = Lambda(l2, output_shape=l2_output_shape)(inp)
    norm = Lambda(ret_l2, output_shape=l2_output_shape)(inp)
    x = TimeDistributed(Dense(b))(x)
    out = multiply([x, norm])
    model = Model(inp, out)
    return model

a = 10
b = 50
generator = build_generator(a, b)
generator_inp = Input(shape=(a, b))
fake = generator(generator_inp)
```

Any ideas on this? Is it intentional that a model including a two-output Lambda layer cannot be called? 
@fchollet @Dref360 @farizrahman4u ? 
Thanks in advance",mpariente,None,2018-03-05T15:21:36Z,2020-01-14T14:37:45Z
9520,Bug-fix cifar10 capsule missing K.sum() margin_loss,"Fix https://github.com/keras-team/keras/issues/9519
In accordance to issue 9519 I implemented the missing sum around the margin_loss implementation.",saralajew,None,2018-03-01T08:49:47Z,2018-03-01T19:36:20Z
9519,missing K.sum() in margin_loss of cifar10_cnn_capsule.py ,"The capsule implementation of cifar10 has a bug.
Line 47 of the `margin_loss()` implementation. There is a missing `K.sum()` around the return. 
Without this the final loss computation over all capsules is `K.mean()`; see Keras `traning.py` line 444. 
",saralajew,None,2018-03-01T08:41:13Z,2018-03-01T19:36:20Z
9513,Fix sequence bug,So Travis is not working right (hence the multiple PR) Sorry for that.,Dref360,None,2018-02-28T14:37:53Z,2018-02-28T18:42:15Z
9512,Fix a bug for worker == 0, https://github.com/keras-team/keras/issues/9506,Dref360,None,2018-02-28T14:29:37Z,2018-02-28T14:34:56Z
9506,Sequence as validation_data fails in fit_generator when workers=0,"Calling `fit_generator` with validation_data as a sequence works as expected for `workers > 0` but fails for `workers == 0`.

I get:
```
Traceback (most recent call last):
  File ""sequence_test.py"", line 27, in <module>
    workers=0
  File ""/home/aplotnicki/envs/tf/lib/python3.5/site-packages/keras/legacy/interfaces.py"", line 87, in wrapper
    return func(*args, **kwargs)
  File ""/home/aplotnicki/envs/tf/lib/python3.5/site-packages/keras/engine/training.py"", line 2169, in fit_generator
    use_multiprocessing=use_multiprocessing)
  File ""/home/aplotnicki/envs/tf/lib/python3.5/site-packages/keras/legacy/interfaces.py"", line 87, in wrapper
    return func(*args, **kwargs)
  File ""/home/aplotnicki/envs/tf/lib/python3.5/site-packages/keras/engine/training.py"", line 2280, in evaluate_generator
    generator_output = next(output_generator)
TypeError: 'TestSequence' object is not an iterator
```

When running the following script. If `workers > 0` there is no problem.

```
import keras.utils
from keras.models import Model, Input
import numpy as np

class TestSequence(keras.utils.Sequence):
    def __init__(self):
        pass
        
    def __len__(self):
        return 1
    
    def __getitem__(self, idx):
        return np.array([1.]), np.array([1.])
    
def TestGenerator():
    while True:
        yield np.array([1.]), np.array([1.])
        
input = Input((None,))
model = Model(input, input)
model.compile(optimizer='adam', loss='mse')

model.fit_generator(
    TestGenerator(),
    steps_per_epoch=10,
    validation_data=TestSequence(),
    workers=0
)
```

Why would I want to do this? Testing related to investigating thread safety of my generator and sequence implementations.

What probably causes this?

I expect that [this line](https://github.com/keras-team/keras/blob/master/keras/engine/training.py#L2150) leads to code that handles sequences, but at the `else` clause, [this line](https://github.com/keras-team/keras/blob/master/keras/engine/training.py#L2165) does not.

Checkboxes:

- [X] Check that you are up-to-date with the master branch of Keras. You can update with:
pip install git+git://github.com/keras-team/keras.git --upgrade --no-deps
**Cloned and installed from github as at now. 6b2a04f**

- [ ] If running on TensorFlow, check that you are up-to-date with the latest version. The installation instructions can be found [here](https://www.tensorflow.org/get_started/os_setup).
**tensorflow.__version__ == 1.4.0
Don't believe this is significant.**

- [X] Provide a link to a GitHub Gist of a Python script that can reproduce your issue (or just copy the script here if it is short).
",alekseynp,b'type:bug/performance',2018-02-27T21:07:59Z,2018-03-01T18:54:30Z
9438,Fixing minor bug in pretrained_word_embeddings example,"tokenizer.word_index starts from index 1, so we need to account for one additional index when getting num_words. This example using 20_newsgroup dataset works with or without this fix but I think it is good to update the code as people may reuse it for other datasets.

Why does this example work?
If MAX_NUM_WORDS is set to a value greater than  len(word_index) [17405] eg. 175K embedding_vector we get for index 17405 is None. So we do not try to set embedding_matrix for this index
```embedding_matrix[i] = embedding_vector```

If there exists an embedding_vector for the word at the last index in word_index dict, we will see index out of bounds error.",pavithrasv,None,2018-02-21T00:09:25Z,2018-02-21T00:25:18Z
9434,Error with multiprocessing on Sequence in fit_generator(),"I'm trying to use a `Sequence` as the generator for `model.fit_generator()`.

With `use_multiprocessing=False` it works fine, but with `use_multiprocessing=True` an error is produced.

**Minimal working example:**
```python
from keras.utils import Sequence
from keras.models import Sequential
from keras.layers import Dense
from keras.utils import to_categorical
import numpy as np

class DummySequence(Sequence):
    
    def __init__(self, x_set, y_set, batch_size):
        self.x, self.y = x_set, y_set
        self.batch_size = batch_size

    def __len__(self):
        return int(np.ceil(len(self.x) / float(self.batch_size)))

    def __getitem__(self, idx):
        batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]
        batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]

        return np.array(batch_x), np.array(batch_y)

if __name__ == '__main__':

    x = np.random.random((100, 3))
    y = to_categorical(np.random.random(100) > .5).astype(int)

    seq = DummySequence(x, y, 10)

    model = Sequential()
    model.add(Dense(32, input_dim=3))
    model.add(Dense(2, activation='softmax'))
    model.compile(optimizer='rmsprop',
                  loss='categorical_crossentropy',
                  metrics=['accuracy'])

    model.fit_generator(generator=seq, workers=2, use_multiprocessing=True)
```
**Error:**
```
Traceback (most recent call last):
  File ""C:\Users\elcombato\AppData\Local\Continuum\Anaconda3\envs\ml\lib\multiprocessing\pool.py"", line 119, in worker
    result = (True, func(*args, **kwds))
  File ""C:\Users\elcombato\AppData\Local\Continuum\Anaconda3\envs\ml\lib\site-packages\keras\utils\data_utils.py"", line 392, in get_index
    return _SHARED_SEQUENCES[uid][i]
KeyError: 0
```

**Setup**
Windows 10
Python 3.6.4
Keras 2.1.3
Tensorflow 1.2.1",elcombato,b'type:bug/performance',2018-02-20T15:49:58Z,2018-02-21T18:52:02Z
9270,Fix issue 9267,"Fixes issue [9267](https://github.com/keras-team/keras/issues/9267)

Tests in engine/topology pass; all tests still running because my laptop is slow. Could do with someone checking this over though, as it seems like it's a simple bug fix but I may have misunderstood the intended behaviour. ",N-McA,None,2018-01-31T17:28:18Z,2018-02-13T03:38:38Z
9248,Fix __call__ for Bidirectional wrapper,"Fix a bug in model topology when `initial_state` is provided to the `Bidirectional` wrapper. `initial_state` should be handled in a same way as in `RNN.__call__`.

```python
input1 = Input(shape=(None, 5))
input2 = Input(shape=(None, 5))
states = Bidirectional(GRU(2, return_state=True))(input1)[1:]
out = Bidirectional(GRU(2, return_sequences=True))(input2, initial_state=states)
model = Model([input1, input2], out)
print(model.layers)
model.summary()
```
Outputs:
```
[<keras.engine.topology.InputLayer object at 0x117d760f0>, <keras.layers.wrappers.Bidirectional object at 0x117ec5550>]
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
input_2 (InputLayer)         (None, None, 5)           0
_________________________________________________________________
bidirectional_2 (Bidirection (None, None, 4)           96
=================================================================
Total params: 96
Trainable params: 96
Non-trainable params: 0
_________________________________________________________________

```
This PR basically copies `RNN.__call__` into `Bidirectional.__call__`, but without the lines handling `constants`.

Also modifies `wrappers_test.test_Bidirectional_state_reuse` to cover this use case.",yuyang-huang,None,2018-01-30T16:38:40Z,2018-11-02T11:40:54Z
9240,fix a bug,"If we change the `trainable` property of `layer`, the weights will be updated. So the comments on the line I have moved are wrong. ",XikunZhang,None,2018-01-29T23:42:18Z,2018-01-30T01:01:22Z
9195,Revert #9025 because it introduces a bug,"#9025 introduces a bug in zca_whitening so that it doesn't work when the samples are more than the dimensions. It **breaks most people's pipelines**.

Quick example to show which pipelines are broken.

```python
from keras.datasets import cifar10
from keras.preprocessing.image import ImageDataGenerator

(x_train, _), _ = cifar10.load_data()
gen = ImageDataGenerator(zca_whitening=True, featurewise_center=True)
gen.fit(x_train) # ValueError and much more time waiting
```

Detailed examples follow that explain what is going on.

```python
import numpy as np
import numpy.random as npr
import numpy.linalg as linalg

def princomps_old(flat_x):
    sigma = np.dot(flat_x.T, flat_x) / flat_x.shape[0]
    u, s, _ = linalg.svd(sigma)
    principal_components = np.dot(np.dot(u, np.diag(1. / np.sqrt(s + 1e-5))), u.T)
    return principal_components
 
def princomps_new(flat_x):
    n_examples = flat_x.shape[0]
    u, s, vt = linalg.svd(flat_x / np.sqrt(n_examples))
    # s_expand = np.hstack((s, np.zeros(max(0, vt.shape[0] - n_examples), dtype=flat_x.dtype)))
    s_expand = np.hstack((s, np.zeros(vt.shape[0] - n_examples, dtype=flat_x.dtype)))
    principal_components = (vt.T / np.sqrt(s_expand**2 + 1e-5)).dot(vt)
    return principal_components

x = np.random.rand(100, 50)
x -= x.mean()
princomps_new(x) # ValueError
```

Although the error can be fixed by introducing `max(0, vt.shape[0] - n_examples)` I argue that the reasoning behind the PR is a bit flawed. The bottleneck in that code is SVD so the speedup only comes when N < dims. Otherwise that code causes a slowdown.

```python
x = np.random.rand(1000, 500)
x -= x.mean()
%timeit princomps_old(x)
10 loops, best of 3: 90.4 ms per loop
%timeit princomps_new_fixed(x)
1 loop, best of 3: 156 ms per loop
```

Finally regarding the extra dot product to compute the principal components. It is redundant in `princomps_old` as well.",angeloskath,None,2018-01-26T12:02:42Z,2018-01-31T00:44:42Z
9194,TypeError: string indices must be integers when using model config,"Hi, I used config = model.get_config() to get model config and insert it into a mysql table. When I select it from mysql table I can get and print it out as a list (inside is dictionary format). However, when I tried to re-instantiate it using model = Model.from_config(config) or model = Sequential.from_config(config). I got error as below.

Traceback (most recent call last):
  File ""testcallmodel.py"", line 48, in <module>
    model_id=args.mi,
  File ""testcallmodel.py"", line 32, in call
    model = Sequential.from_config(config)
  File ""/usr/local/lib/python3.5/dist-packages/keras/models.py"", line 1348, in from_config
    return cls.legacy_from_config(config)
  File ""/usr/local/lib/python3.5/dist-packages/keras/models.py"", line 1416, in legacy_from_config
    first_layer = normalize_legacy_config(first_layer)
  File ""/usr/local/lib/python3.5/dist-packages/keras/models.py"", line 1397, in normalize_legacy_config
    class_name = conf['name']
TypeError: string indices must be integers

While the config that I can print out look like this. Sorry that I did not show all the config here. But I think you can figure out if it is a bug or not. 

config: [{'class_name': 'LSTM', 'config': {'kernel_initializer': {'class_name': 'VarianceScaling',  ..........................................'bias_constraint': None, 'use_bias': True, 'kernel_constraint': None, 'activity_regularizer': None, 'trainable': True, 'name': 'dense_2', 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_regularizer': None}}]

Many thanks!








Please make sure that the boxes below are checked before you submit your issue. If your issue is an implementation question, please ask your question on [StackOverflow](http://stackoverflow.com/questions/tagged/keras) or [join the Keras Slack channel](https://keras-slack-autojoin.herokuapp.com/) and ask there instead of filing a GitHub issue.

Thank you!

- [x] Check that you are up-to-date with the master branch of Keras. You can update with:
pip install git+git://github.com/keras-team/keras.git --upgrade --no-deps

- [x] If running on TensorFlow, check that you are up-to-date with the latest version. The installation instructions can be found [here](https://www.tensorflow.org/get_started/os_setup).

- [ ] If running on Theano, check that you are up-to-date with the master branch of Theano. You can update with:
pip install git+git://github.com/Theano/Theano.git --upgrade --no-deps

- [ ] Provide a link to a GitHub Gist of a Python script that can reproduce your issue (or just copy the script here if it is short).
",ghost,None,2018-01-26T09:15:22Z,2018-01-26T09:51:05Z
9175,"batch_dot ""Dimensions must be equal""","`batch_dot` does not work when the input is 4D and needs ""broadcasting"".

```
import keras.backend as K
from keras.layers import Input

x_batch = K.ones(shape=(32, 20, 1, 1))
y_batch = K.ones(shape=(32, 30, 20, 3))

xy_batch_dot = K.batch_dot(x_batch, y_batch, axes=[1, 2])
```
`ValueError: Dimension 1 in both shapes must be equal, but are 20 and 30 for 'MatMul_1' (op: 'BatchMatMul') with input shapes: [32,20,1,1], [32,30,20,3].`

Running on: Windows, tensorflow, CPU

Firstly I would like confirmation that other people agree that this is a bug, before we try fixing it.

- [x] Check that you are up-to-date with the master branch of Keras. You can update with:
pip install git+git://github.com/keras-team/keras.git --upgrade --no-deps

- [x] If running on TensorFlow, check that you are up-to-date with the latest version. The installation instructions can be found [here](https://www.tensorflow.org/get_started/os_setup).

- [ ] If running on Theano, check that you are up-to-date with the master branch of Theano. You can update with:
pip install git+git://github.com/Theano/Theano.git --upgrade --no-deps

- [x] Provide a link to a GitHub Gist of a Python script that can reproduce your issue (or just copy the script here if it is short).
",MortenHannemose,None,2018-01-24T15:26:09Z,2018-01-26T18:35:30Z
9112,Allow weights trained with CuDNNGRU to be used without GPU,"TL;DR: This PR extends the plain Keras `GRU` layer with a CuDNN-compatible mode, so that we can reuse weights trained on GPU with `CuDNNGRU` for inference on CPU.

Since #8860 (#8307) we're able to train a LSTM layer quickly on GPU with CuDNN and load the weights to plain LSTM implementation which runs also on a CPU. Since GRU in CuDNN is based on a slightly different convention we can't directly load its weights in a similar way. A possible solution is to provide implementation of GRU layer in plain Keras (similar to existing one) but using the same convention as in CuDNN, so that we can reuse the weights.

As I [described in detail](https://github.com/keras-team/keras/pull/8307#issuecomment-354652830) there are two conventions of GRU:

- most common (Keras, TensorFlow, etc.): hidden input first multiplied by reset gate, then projected by matrix 
- original paper (CuDNN): hidden input first projected, then multiplied by reset gate

In addition CuDNN uses two sets of biases, while Keras just one set.

Note that default `recurrent_activation` (for gates) in Keras is `hard_sigmoid`, while CuDNN uses `sigmoid`, so we should specify that option explicitly.

In this PR we're adding a mode to the `GRU` layer (resp. its `GRUCell`) to use the latter CuDNN-compatible convention and code to convert weights the analogously to the LSTM case (#8307).

Making a separate class for GRU layer or cell allowed easier development/debugging, but results in much code duplication and worse usage, so in the end I just added one more boolean parameter to `GRUCell` to switch between code paths: `variant` which can take values 'reset_before' (reset before multiplication, default), 'reset_after' (reset after multiplication - CuDNN-compatible).

`GRUCell` has already two `implementation`s, one simple, other with fused matrices where possible. Both have been adapted to both conventions. So we have four modes in total.

A basic test for converting weights from CuDNNGRU to GRU is available. Besides that the code has been manually tested on the IMDB RNN example to obtain same results up to numerical precision.

Documentation has been extended to cover this case and reference also the original paper.

UPDATE: I've made a notebook with example of using the code on IMDB example and measuring precision of results and speedup: https://gist.github.com/bzamecnik/bd3786a074f8cb891bc2a397343070f1.

Request for comments:
- Mixing two variants and two implementations is not perfectly readable, but different classes result in too much duplication. At least I tried to deduplicate common code between the two variants. Can you imagine a better way how to structure the code?
- Do you think of any better names for the flag and its values?

Thanks.

UPDATE - results of discussion:

- new `GRU` argument is `reset_after` boolean, default `False`, indicates using the original CuDNN-compatible convention
- shape of stored weights is the same (compared to CuDNNGRU) for kernels, but different for biases
  - ordering of individual weights is different and conversion is possible
  - biases (for input and recurrent kernels) are of shape `(2, 3 * units)`, while in CuDNNGRU, they're flat
    - this is the least bad way to allow distinguishing between weights from `GRU(reset_after=True)` and `CuDNNGRU` since we do not store layer metadata beyond name (such as type or arguments)
- it's possible to convert weights between `GRU(reset_after=True)` and `CuDNNGRU` and also `CuDNNLSTM` and `LSTM` in both directions!",bzamecnik,b'Reviewers wanted',2018-01-18T15:18:51Z,2018-12-13T09:38:18Z
9098,Regularization bug. Tests and fix.,"This PR and the new and clean version of this PR: #8932 

## The bug:
The bug was that when using two models sharing layers in a bigger model, the regularization loss was duplicated. Here are the tests that were written to show the bug.

### test_regularization_shared_layer() -> PASSED
The same layer is used twice in the final model.

### test_regularization_shared_model() -> FAILED
The same model is used twice in the final model

### test_regularization_shared_layer_in_different_models() -> FAILED
Two different model instances are used in the final model. 
But those two model instances refer to a single unique layer.

## Why does it happen?
Because when models/containers gather losses, there is no check on the provenance of the loss. This can be seen in `Layer.add_loss(self, losses, inputs=None)`.

## The fix:
This bug has been fixed. This was done in the function `def losses(self)` as suggested in the previous PR.
We run over the list and de-dupe at this stage. We use the `is` operator. This was the only way I found to compare the origins of the losses.

",gabrieldemarmiesse,None,2018-01-17T09:16:55Z,2018-09-18T06:32:02Z
9035,Format state_spec in the error message,"Right now the error message is not quite useful when an incompatible state is passed to an RNN. For example,

```python
x = Input(shape=(None, 10))
states = [Input((32,)), Input((32,))]
x = RNN([GRUCell(32), GRUCell(64)])(x, initial_state=states)
```
gives the error:
```
ValueError: An initial_state was passed that is not compatible with `cell.state_size`. Received `state_spec`=[<keras.engine.topology.InputSpec object at 0x7f740559fd50>, <keras.engine.topology.InputSpec object at 0x7f740559fd90>]; However `cell.state_size` is (64, 32)
```
Printing the `state_spec` is good for debugging purpose, but the default python formatting generates something like `<keras.engine.topology.InputSpec object at 0x7f740559fd50>`.

This PR implements `__repr__` method for `InputSpec` so that the printed `state_spec` is more useful for debugging purpose:

```
ValueError: An `initial_state` was passed that is not compatible with `cell.state_size`. Received `state_spec`=[InputSpec(shape=(None, 32), ndim=2), InputSpec(shape=(None, 32), ndim=2)]; however `cell.state_size` is (64, 32)
```",yuyang-huang,None,2018-01-10T06:51:50Z,2018-01-11T04:01:26Z
9028,BN: Use sample variance - unbiased estimator of population variance,"Resolves https://github.com/keras-team/keras/issues/8982

Currently, with `N=2`, the code in Issue https://github.com/keras-team/keras/issues/8982 produces wrong population variance (**0.47084832**), while the correct one is **1.0+-...** (with this PR the result is **0.99781173**). This is due to current code using wrong ""variance of the sample""  `1/N` biased estimator instead of correct unbiased ""sample variance"" estimator `(1/(N-1)`, which for N=2 is exactly 2x smaller.

This is contrary to the ""Batch Normalization"" paper (https://arxiv.org/abs/1502.03167), where Algorithm 2, step 10 uses unbiased estimator: 
```
Var[x] ← m/(m−1) E_B[σ_B^2]
``` 
and everywhere else the paper consistently uses `Var[x]`, not `E[Var[B]]` or something (although ""Batch renormalization"" paper has it garbled).

The reason we don't typically see the obvious manifestation of the bug is because typically N is larger, and we normalize across the whole feature map (but we should see is for small N for Dense layers). Nevertheless, for **cifar10_resnet.py** example, after **epoch 1**,  **val_acc** improves from **0.5118** to **0.5235** (and together with PR https://github.com/keras-team/keras/pull/9003 improves again to **0.5860**. FWIW, final **val_acc** ""improved"" from **0.9195** to **0.9223**).
  
  ",ozabluda,None,2018-01-09T18:11:59Z,2019-03-23T19:44:46Z
8999,"Weights are now loaded by name in ""applications"".","## The bug:

#8998 
When using applications models with a input tensor passed in argument to the function that creates the model, imagenet weights can't get loaded. This is because the final model has more layers than expected and the loading of the weights is based on the topology of the model.

## A minimal script to reproduce the bug

```
from keras.layers import *
from keras.applications.vgg16 import VGG16
from keras.models import Model

a = Input(shape=(None, None, 3))
b = Conv2D(3,3, padding=""same"")(a)
model = VGG16(include_top=False,weights='imagenet',input_tensor=b)
```
The message given is:

```
ValueError                                Traceback (most recent call last)
<ipython-input-1-f23c5c6a7e7b> in <module>()
      5 a = Input(shape=(None, None, 3))
      6 b = Conv2D(3,3, padding=""same"")(a)
----> 7 model = VGG16(include_top=False,weights='imagenet',input_tensor=b)

c:\users\a\desktop\gabriel\keras\keras\applications\vgg16.py in VGG16(include_top, weights, input_tensor, input_shape, pooling, classes)
    174                                     cache_subdir='models',
    175                                     file_hash='6d6bbae143d832006294945121d1f1fc')
--> 176         model.load_weights(weights_path)
    177         if K.backend() == 'theano':
    178             layer_utils.convert_all_kernels_in_model(model)

c:\users\a\desktop\gabriel\keras\keras\engine\topology.py in load_weights(self, filepath, by_name, skip_mismatch)
   2637                 f, self.layers, skip_mismatch=skip_mismatch)
   2638         else:
-> 2639             load_weights_from_hdf5_group(f, self.layers)
   2640 
   2641         if hasattr(f, 'close'):

c:\users\a\desktop\gabriel\keras\keras\engine\topology.py in load_weights_from_hdf5_group(f, layers)
   3130                          'containing ' + str(len(layer_names)) +
   3131                          ' layers into a model with ' +
-> 3132                          str(len(filtered_layers)) + ' layers.')
   3133 
   3134     # We batch weight value assignments in a single backend call

ValueError: You are trying to load a weight file containing 13 layers into a model with 14 layers.
```

## The fix
There are two possibilities:
- The weights files were created from models having the same layers names as what is currently in keras/applications/*. In this case, the fix is simple, adding `by_name=True` when calling `load_weights()`. I've bet on this so that is what I applied (but I have actually no idea since I don't know how the weights files were created).
- The other possibility is that the weights files have random names for the layers, in which case there should be an exception raised when trying to load the weights from imagenet and passing a custom tensor as input. It should be easy too.

## The tests
I could have added tests, but since keras tests on Travis are really slow, and downloading the weights takes a long time, I chose not to do it. If the bosses say it's necessary, I'll do it though. I just have to know if I must test each model or not.

Thanks for reviewing! 
  ",gabrieldemarmiesse,None,2018-01-08T13:43:44Z,2018-01-08T17:36:34Z
8982,BatchNormalization population statistics is wrong with small minibatches,"With `N=2`, the code below produces wrong population variance (0.47084832), while the correct one is 1.0. I am pretty sure (due to experiments with N=2,3,4... and code inspection) that this is due to current code using wrong ""variance of the sample""  `1/N`, biased estimator instead of correct unbiased ""sample variance"" estimator `(1/(N-1)`, which for N=2 is exactly 2x smaller.

This is contrary to the ""Batch Normalization"" paper (https://arxiv.org/abs/1502.03167), where Algorithm 2, step 10 uses unbiased estimator: 
```
Var[x] ← m/(m−1) E_B[σ_B^2]
``` 
and everywhere else the paper consistently uses `Var[x]`, not `E[Var[B]]` or something (although ""Batch renormalization"" paper has it garbled).

The reason we don't typically see the manifestation of the bug is because typically N is larger, and we normalize across the whole feature map (but we should see is for small N for Dense layers).

I am pretty sure it's a Keras bug, not a TF bug (except in the docs), because TF unfathomably delegates updating running averages to the user.

```
# Script for reproducing a BatchNormalization2 bug
# https://gist.github.com/ozabluda/84c36af4ced13f060524f743c7fe65c5
# https://github.com/keras-team/keras/issues/8982

from keras.models import Sequential, Model
from keras.layers import Dense, BatchNormalization, Input, concatenate
import numpy as np

m = Sequential([
    BatchNormalization(input_shape=(1,),
                       center=True,
                       scale=True,
                       gamma_initializer='one',  # variance
                       beta_initializer='zero',    # mean
                       moving_mean_initializer='zero',
                       moving_variance_initializer='one',
                       epsilon=0.00001,
                       #momentum=0.
    ),
])
m.summary()
print(m.layers[0].weights)
N=2

x  = np.random.normal(loc=0, scale=1, size=10000)
print(np.var(x, axis=None), np.mean(x, axis=None))
y  = x

m.compile(optimizer='sgd', loss='mse')
print(""Before evaluate:"", m.evaluate(x,y))
print(np.array(m.layers[0].get_weights()).ravel())

m.fit(x, y, verbose=1, epochs=2, shuffle=False, batch_size=N,
      validation_data=(x,y))

print(""After evaluate:"", m.evaluate(x,y), m.predict(x))
print(np.array(m.layers[0].get_weights()).ravel())
```

Output
```
[<tf.Variable 'batch_normalization_1/gamma:0' shape=(1,) dtype=float32_ref>, <tf.Variable 'batch_normalization_1/beta:0' shape=(1,) dtype=float32_ref>, <tf.Variable 'batch_normalization_1/moving_mean:0' shape=(1,) dtype=float32_ref>, <tf.Variable 'batch_normalization_1/moving_variance:0' shape=(1,) dtype=float32_ref>]
('Before evaluate/predict:', 2.4932038522607058e-11)
[ 1.  0.  0.  1.]
Train on 10000 samples, validate on 10000 samples
Epoch 1/2
10000/10000 [==============================] - 22s 2ms/step - loss: 0.6948 - val_loss: 0.0484
Epoch 2/2
10000/10000 [==============================] - 23s 2ms/step - loss: 0.6938 - val_loss: 0.0484
10000/10000 [==============================] - 1s 54us/step
('After evaluate/predict:', 0.048399086749553677)
[ 0.54530275 -0.13030723 -0.06153991  0.47084832]

```
  ",ozabluda,None,2018-01-06T01:46:13Z,2018-01-28T20:54:13Z
8963,Is keras have save/restore API to save training process periodically?,"I just start using keras. But I train  a model for 5 minutes and at the end of the program, I have a bug. I have to start over.  In tensorflow I usually save training to checkpoint file periodically. I check keras documentation. Don't find anything related to it. 

Does keras have this function?",scotthuang1989,None,2018-01-04T14:11:16Z,2018-01-05T00:42:54Z
8955,cifar10_resnet: Simplify and improve logic,"- improve `if/then/else/return` logic, remove some duplicated code. also removes latent bug in the `else:` branch - hardcoded `Activation('relu')`
- replace `if activation:` with `if activation is not None:`
- compact model definition by moving definition of `inputs`.
- remove cast to `int`, which has no effect
- remove not really used variable `filter_multiplier`, improve related logic.
- rename `i` to `stack` (matches paper authors' terminology)  
- replace `is_first_layer_but_not_first_block` with inline `if`
- improve docstrings
- rename `num_sub_blocks` to `num_res_units` and 'j' to 'res_unit'. This matches paper authors' terminology and avoids name collision with `resnet_block()`
",ozabluda,None,2018-01-03T18:04:39Z,2018-01-16T22:38:49Z
8933,[Request for Contributions (Issues)] Adding test to show that fit() is reducing reproducibility.,"Hi!

Folowing #8906 

Calling fit changes the numpy random state. I don't think this is a bug, but I don't have much experience so I'm giving it the benefit of the doubt. Please tell me if this necessitate changes in the codebase, so that I can make a PR.

Citing @MaxG87 :

> Checking the source code I noticed that model.fit finally invokes np.random.shuffle(...), thus altering the global random state. This can be fixed very easily by introducing a new member of type np.random.RandomState, and then using this one instead of the global one.
I would appreciate very much if this could be fixed as it would remove one source of irreproducibility.
In my opinion, calling functions should not alter the global random state.
",gabrieldemarmiesse,None,2018-01-01T14:34:59Z,2020-04-19T05:26:09Z
8932,[Requests for Contributions (Issues)] Added test for a bug about regularization.,"## The issue
I added a test showing that the regularization has a different behavior if a layer is shared or if a model that has this layer is shared. 

If a layer is shared, the regularization is counted only once, but if a model is shared, the regularization corresponding to this model is counted multiple times (as many times as this shared model is used).

It was show in this issue: #8807 

## The test
In the test, I compared the L1 regularization loss of two models. The first one has a shared dense layer, the second one has a shared dense layer, but this layer is wrapped in another model.

I don't know if this is an expected behavior or not, but it sure is strange. If this is a bug, let me know so that I can work on it. 

Thank you.",gabrieldemarmiesse,None,2018-01-01T10:54:08Z,2018-09-18T06:31:53Z
8909,Removing layers from model gives the same output as original model,"Hello there,

During some feature extraction experiments, I noticed that the  'model.pop()'   functionality is not working as expected. For a pretrained model like vgg16, after using  'model.pop()'  ,  model.summary() shows that the layer has been removed (expected 4096 features), however on passing an image through the new model, it results in the same number of features (1000) as the original model. No matter how many layers are removed including a completely empty model, it generates the same output. See short example here, full code is attached at the end of this post. Looking for your guidance on what might be the issue.


```
#Passing an image through the full vgg16 model
model = VGG16(weights = 'imagenet', include_top = True, input_shape = (224,224,3))
img = image.load_img( 'cat.jpg', target_size=(224,224) )
img = image.img_to_array( img )
img = np.expand_dims( img, axis=0 )
img = preprocess_input( img )
features = model.predict( img )
features = features.flatten()
print(len(features)) #Expected 1000 features corresponding to 1000 imagenet classes
```
1000
```
model.layers.pop()
img = image.load_img( 'cat.jpg', target_size=(224,224) )
img = image.img_to_array( img )
img = np.expand_dims( img, axis=0 )
img = preprocess_input( img )
features2 = model.predict( img )
features2 = features2.flatten()
print(len(features2)) #Expected 4096 features, but still getting 1000. Why?
#No matter how many layers are removed, the output is still 1000
```
**1000**

Thank you!

See full code here:
[bug-feature-extraction.pdf](https://github.com/keras-team/keras/files/1592641/bug-feature-extraction.pdf)
",koul,None,2017-12-29T06:24:02Z,2020-01-14T18:26:57Z
8881,Tokenizer: add optional OOV token for sequences,"This update adds an optional feature to `keras.preprocessing.text.Tokenizer`, for dealing with out-of-vocabulary words when covering texts to sequences.  
The current implementation of `texts_to_sequences`silently omits words that were not seen during `fit_on_texts`. While this is fine for many applications it can lead to hard to trace bugs in some cases, especially when it is followed with `pad_sequences`. For example in Sequence Labeling, when evaluating a model with text that contains unseen words, converting the input text into a sequence and then padding it could inadvertently change the sequence in an unexpected way. Then we end up predicting and evaluating a wrong sequence. 

Demo:
```
x_train = ['This text has only known words']
x_test = ['But this text has some unknown words']

# current behavior:
tokenizer =  Tokenizer(num_words=MAX_NUM_WORDS)
tokenizer.fit_on_texts(x_train)

x_test_seq = pad_sequences(tokenizer.texts_to_sequences(x_test), maxlen=MAX_SEQUENCE_LENGTH)
print(x_test_seq)
# >>> [[0 0 0 0 0 0 1 2 3 6]]   # we lose trace of 3 OOV words


# With new changes
tokenizer =  Tokenizer(num_words=MAX_NUM_WORDS, oov_token='<unk>')
tokenizer.fit_on_texts(x_train)

x_test_seq = pad_sequences(tokenizer.texts_to_sequences(x_test), maxlen=MAX_SEQUENCE_LENGTH)
print(x_test_seq)
# >>> [[0 0 0 7 1 2 3 7 7 6]]   # we get sequence of all 7 words with placeholder for OOVs

```

Of course, a careful and informed user can deal with the issue through a little bit of pre and post-processing of the data, but it is much easier and keras like to do it with a simple flag like this. 

Note: This update should not affect the behavior of existing uses of the Tokenizer API, it only works if intentionally turned on.

",fgaim,None,2017-12-24T12:33:01Z,2018-01-17T05:58:20Z
8860,CuDNNGRU/LSTM weights trained on GPU can't be used on GRU/LSTM (i.e CPU versions),"If you train a model on the GPU using the CuDNN (GRU or LSTM) layers and save the weights, it is not possible to load those weights into their respective CPU variants.

Is this a bug or expected? I tried messing about with `implementation=0, 1, 2` for the `GRU` layer but this didn't seem to help.

The code below raises the following exception
```
ValueError: Dimension 0 in both shapes must be equal, but are 48 and 96 for 'Assign_39' (op: 'Assign') with input shapes: [48], [96].
```
```
import numpy as np
import keras
from keras import layers
from keras.utils.np_utils import to_categorical

T = 10
k = 3
batch_size = 32
classes = 5

X = np.random.random((32, T, k))
y = to_categorical(np.random.randint(0, classes, size=(32, )), num_classes=classes)

model=keras.models.Sequential()
model.add(layers.InputLayer(input_shape=(T, 3)))
model.add(layers.CuDNNGRU(16 ,return_sequences=False))
model.add(layers.Dense(classes, activation='softmax'))
model.compile(loss='categorical_crossentropy',optimizer='sgd')

model.fit(X, y)

model.save_weights('GPU.weights')

cpu_model=keras.models.Sequential()
cpu_model.add(layers.InputLayer(input_shape=(T, 3)))
cpu_model.add(layers.GRU(16 ,return_sequences=False))
cpu_model.add(layers.Dense(classes, activation='softmax'))
cpu_model.compile(loss='categorical_crossentropy',optimizer='sgd')
cpu_model.load_weights('GPU.weights')
```


- [x ] Check that you are up-to-date with the master branch of Keras. You can update with:
pip install git+git://github.com/keras-team/keras.git --upgrade --no-deps

- [x ] If running on TensorFlow, check that you are up-to-date with the latest version. The installation instructions can be found [here](https://www.tensorflow.org/get_started/os_setup).

- [ x] Provide a link to a GitHub Gist of a Python script that can reproduce your issue (or just copy the script here if it is short).",allentran,None,2017-12-21T19:13:29Z,2018-11-14T17:30:58Z
8807,"When Dense layer is shared Siamese-style, regularization loss is counted multiple times","It's probably true of all layers other than `Dense` as well. The code below demostrates it:
```
# Script for reproducing a shared layer regularization bug
# https://gist.github.com/ozabluda/11326307bbf13936f18063a1a4165adc
# https://github.com/keras-team/keras/issues/8807

from keras.models import Sequential, Model
from keras.layers import Dense, Input, concatenate
from keras.regularizers import l1_l2
import numpy as np

m = Sequential([
    Dense(units=1, input_dim=1, use_bias=False,
          kernel_initializer='ones',
          kernel_regularizer=l1_l2(l1=1,l2=0),
          trainable=False),
])
m.summary()

if False: # not shared
    x  = np.array([0])
    y  = np.array([0])

    m.compile(optimizer='sgd', loss='mse', metrics=['mse'])
    print(m.metrics_names, m.evaluate(x,y), m.predict(x))

    m.fit(x, y, verbose=1, epochs=1)

    print(m.metrics_names, m.evaluate(x,y), m.predict(x))
else: # shared
    input_a = Input(shape=(1,))
    input_b = Input(shape=(1,))

    processed_a = m(input_a)
    processed_b = m(input_b)

    c = concatenate([processed_a, processed_b])
    c = Dense(1, kernel_initializer='ones', use_bias=False, trainable=False)(c)
    s = Model([input_a, input_b], c)
    s.compile(optimizer='sgd', loss='mse', metrics=['mse'])
    s.summary()

    x0 = np.array([0])
    x1 = np.array([0])
    x  = [x0,x1]
    y  = np.array([0])

    print(s.metrics_names, s.evaluate(x,y), s.predict(x))

    s.fit(x, y, verbose=1, epochs=1)

    print(s.metrics_names, s.evaluate(x,y), s.predict(x))
```
output (you can see that the regularization loss is equal to 2):
```
1/1 [==============================] - 2s 2s/step
(['loss', 'mean_squared_error'], [2.0, 0.0], array([[ 0.]], dtype=float32))
Epoch 1/1
1/1 [==============================] - 0s 9ms/step - loss: 2.0000 - mean_squared_error: 0.0000e+00
1/1 [==============================] - 0s 2ms/step
(['loss', 'mean_squared_error'], [2.0, 0.0], array([[ 0.]], dtype=float32))
```
",ozabluda,None,2017-12-16T00:51:43Z,2018-01-28T20:57:34Z
8804,Fix Adam saving,"Fix a bug in model saving caused by PR #8693.

`K.batch_get_value` does not support `None` values. An error occurs when it is called in `save_model` to get `Adam(amsgrad=False)` optimizer weights (on all 3 backends).

Fix it by creating size-1 zero tensors instead of `None`. Cannot use size-0 tensors because `K.batch_set_value` would fail on size-0 tensors during model loading.

Also changed a test in test_model_saving.py (switching from `RMSprop` to `Adam`) to cover this case.",yuyang-huang,None,2017-12-15T19:41:08Z,2017-12-16T06:16:49Z
8797,[BUG] CSVLogger fails if training stops in the first epoch,"`callbacks.py: CSVLogger: on_epoch_end` - the `self.keys` dict is `None` when `model.stop_training = True` and the first epoch have not been completed yet. This results in `TypeError: 'NoneType' object is not iterable`.

Short example:
```python
from keras.callbacks import Callback, CSVLogger
from keras.layers import InputLayer
from keras.models import Sequential


class TerminateInFirstEpoch(Callback):
    """"""Callback that terminates before the first epoch is completed.
    """"""

    def on_batch_end(self, batch, logs=None):
        self.model.stop_training = True


model = Sequential()
model.add(InputLayer(input_shape=(1,)))
model.compile(optimizer='sgd', loss='mse')

terminator = TerminateInFirstEpoch()
logger = CSVLogger('./log.csv')

x, y = [1, 2, 3, 4], [1, 2, 3, 4]
model.fit(x, y, batch_size=2, callbacks=[terminator, logger])
```",novotnj3,None,2017-12-15T09:35:50Z,2017-12-15T19:00:20Z
8794,"When BatchNormalization layer is shared Siamese-style, moving_variance is incorrect.","When `BatchNormalization` layer is shared Siamese-style, `moving_variance` is calculated incorrectly. In the code below, if `BatchNormalization` is not shared (`if` branch of the conditional) the final weights are correct: 
```
[ 1.00000203  1.          0.99995679  0.99995679]
```
the order is
```
[gamma, beta, moving_mean, moving_variance]
```
but if the `BatchNormalization` layer is shared (`else` branch of the conditional), the final weights are incorrect:
```
[  0.00000000e+00   6.13518556e-37   9.99296010e-01   0.00000000e+00]
```
namely, `moving_variance` (last weight) is zero, which is the most likely, the root cause of it. It's as if one of the shared `BatchNormalization` layers, overwrites `moving_variance` of the other. Note that `moving_mean` is calculated correctly in a shared way. `gamma` and `beta` also work ""correctly"" to compensate for the wrong `moving_variance`.

```
# Script for reproducing a BatchNormalization bug
# https://gist.github.com/ozabluda/11326307bbf13936f18063a1a4165adc

from keras.models import Sequential, Model
from keras.layers import Dense, BatchNormalization, Input, concatenate
import numpy as np

m = Sequential([
    BatchNormalization(input_shape=(1,),
                       center=True,
                       scale=True,
                       gamma_initializer='zero',
                       beta_initializer='one',
                       moving_mean_initializer='zero',
                       moving_variance_initializer='zero',
                       epsilon=0.00001
    ),
])
m.summary()
print(m.layers[0].weights)

if False: # not shared
    x  = np.array([0, 2])
    y  = np.array([0, 2])

    m.compile(optimizer='sgd', loss='mse')
    print(m.evaluate(x,y), m.predict(x))
    print(np.array(m.layers[0].get_weights()).ravel())

    m.fit(x, y, verbose=0, epochs=1000)

    print(m.evaluate(x,y), m.predict(x))
    print(np.array(m.layers[0].get_weights()).ravel())

else: #shared
    input_a = Input(shape=(1,))
    input_b = Input(shape=(1,))

    processed_a = m(input_a)
    processed_b = m(input_b)

    c = concatenate([processed_a, processed_b])
    c = Dense(1, kernel_initializer='ones', use_bias=False, trainable=False)(c)
    s = Model([input_a, input_b], c)
    s.compile(optimizer='sgd', loss='mse')
    s.summary()

    x0 = np.array([0])
    x1 = np.array([2])
    x  = [x0,x1]
    y  = np.array([0])

    print(np.array(s.layers[2].layers[0].get_weights()).ravel())

    s.fit(x, y, verbose=0, epochs=200)

    print(s.evaluate(x,y), s.predict(x))
    print(np.array(s.layers[2].layers[0].get_weights()).ravel())
```

========

- [x] Check that you are up-to-date with the master branch of Keras. [OZ: Keras version is after https://github.com/keras-team/keras/pull/8785 

- [x] If running on TensorFlow, check that you are up-to-date with the latest version. [OZ: TF is 1.4.1]

",ozabluda,None,2017-12-15T00:58:36Z,2019-10-17T17:35:54Z
8723,Optimizer for weights in custom layer can not be assigned,"Hi,

I've implemented a custom layer with four weigths/bias-variables. Build the layer works fine, but when it comes to training there are no optimizers assigned for the weights. I'm using sgd as optimizer.

I debugged into keras.training and keras.optimizers and found that there must be some kind of bug.
In the get_updates method of keras.optimizers module should the optimizers be loaded:

```
 def get_updates(self, loss, params):
        grads = self.get_gradients(loss, params)
        ...
```

This loads the optimizers for every weight from the other layers, but `None` for the weights of my custom layer.
So i went a little deeper until i got to tf.gradients (which is located in gradients_impl.py):
```
def gradients(loss, variables):
    ...
    return tf.gradients(loss, variables, colocate_gradients_with_ops=True)
```
There happens a lot of stuff I don't get... but it seems like a `grads` dict is build which stores a lot of gradients/optimizers and at the end it extracts the gradients for the weigths from this dict:

`return [_GetGrad(grads, x) for x in xs]`

```
def _GetGrad(grads, t):
  """"""Gets gradient for tensor ""t"".""""""
  op = t.op
  op_grads = grads.get(op)  #<---- This is allways None for custom-layer weights
  if not op_grads:
    return None
  t_grad = op_grads[t.value_index]
  assert not isinstance(t_grad, list), (
      ""gradients list should have been aggregated by now."")
  return t_grad
```

Has anyone an idea why this happens?
In call-method i'm using methods from keras.backend, tensorflow, activation-funtions from keras (softmax, sigmoid), keras-layers (Lambda, TimeDistributed) applied to tensors and standard for loops. Am I just allowed to use keras.backend-methods? If so is there an equivalent for tf.TensorArray? Is it allowed to use other layers on e.g. the input-tensor in the call-method? Is there an keras/tf iterator to handle list elements?

I would appreciate any help or hints
Thanks in advance


",stoney95,None,2017-12-07T16:48:07Z,2017-12-08T14:30:34Z
8702,Validation bug when using dropout on RNNs,"Adding dropout to RNNs gives unexpected validation loss.
This issue can easily be seen and reproduced by setting your validation inputs/targets to be the same as your training inputs/targets. In this case you would expect to get the same results for training and validation error, and you do unless you use dropout. It may be expected when using dropout that the two losses may differ if dropout is only applied for training but not for validation, but in this case the validation loss should be _lower_ than the training loss, but what you find is that the validation loss is significantly worse than training loss. I can get the training accuracy to 100% but it is impossible to get the validation that high, despite them being the exact same data. This is the exact opposite behavior I get in past experiences doing this same test. 

What makes this even stranger and more convincingly a bug is that it only happens specifically when setting dropout for an RNN's inputs - 
`model.add(LSTM(neurons, dropout=0.5, input_shape=(inputs.shape[1], inputs.shape[2])))`
You can add dropout anywhere else you want, as much as you want, (to fully connected layers after the LSTM for example) and even add ""recurrent_dropout"" to the LSTM and not get this issue at all. The test and validation loss will be equal as expected. But as soon as you add dropout to the RNN's inputs the validation loss doesn't behave as expected which is a big issue for me being able to tell if dropout is actually being applied correctly and if the validation loss I see is correct. 

I have changed virtually every factor around (which type of RNN I use, amount of dropout, loss function, optimizer, network architecture, inputs/targets etc) and get the same odd behavior. 
Another thing to note is that the more dropout the worse the validation is. And even stranger, a dropout of 0.8 or higher actually makes the validation loss get worse over time while the training loss gets better, despite being identical data. I can't think of any way to explain this, and it doesn't happen in my custom implementation of dropout on LSTMs. 


Please make sure that the boxes below are checked before you submit your issue. If your issue is an implementation question, please ask your question on [StackOverflow](http://stackoverflow.com/questions/tagged/keras) or [join the Keras Slack channel](https://keras-slack-autojoin.herokuapp.com/) and ask there instead of filing a GitHub issue.

Thank you!

- [x ] Check that you are up-to-date with the master branch of Keras. You can update with:
pip install git+git://github.com/fchollet/keras.git --upgrade --no-deps

- [x ] If running on TensorFlow, check that you are up-to-date with the latest version. The installation instructions can be found [here](https://www.tensorflow.org/get_started/os_setup).

- [x ] If running on Theano, check that you are up-to-date with the master branch of Theano. You can update with:
pip install git+git://github.com/Theano/Theano.git --upgrade --no-deps

- [x ] Provide a link to a GitHub Gist of a Python script that can reproduce your issue (or just copy the script here if it is short).
",neilthefrobot,None,2017-12-06T07:38:37Z,2017-12-07T04:36:38Z
8665,fit_generator has thread leak?,"**Issue:**
I am experiencing an issue with becoming overrun with threads produced when I run the below code using fit_generator functionality. 

Attached is a screenshot displaying the # of threads over time at 0.5s intervals.
![screenshot from 2017-12-02 16-36-27](https://user-images.githubusercontent.com/8198523/33519940-fd31751c-d77e-11e7-8be4-8dfad1b442c7.png)

I know my code invokes the `OrderedEnqueuer` functionality, using threads and not processes. 
Placing a debug print in the `__init__()` fucntion shows that it is created every epoch.

**Questions:**
1. Can anyone else confirm this issue? 
To watch the threads I used: `watch -n 0.5 ps -elfT | grep scriptname` 
2. Is the creation of the OrderedEnqueuer on every epoch normal behaviour?

**Versions:**
Keras (2.1.2, installed from fchollet/keras, 2 Dec 2017)
Tensorflow (1.4.0)

**Code:**
```from keras.layers import Dense
from keras.layers import Activation
from keras.layers import Flatten
from keras.layers import LocallyConnected1D
from keras.layers import Dropout
from keras.models import Sequential
import time
from keras.utils import Sequence
import numpy as np

class SequenceGen(Sequence):
    def __init__(self, batch_size):
        self.batch_size = batch_size

    def __len__(self):
        return 10

    def __getitem__(self, idx):
        batch_x = np.zeros((self.batch_size, 100, 2))
        batch_y = np.zeros((self.batch_size, 1))
        time.sleep(0.1)
        return batch_x, batch_y

    def next(self):
        while True:
            for idx in range(len(self)):
                return self.__getitem__(idx)

data_generator = SequenceGen(batch_size=20000)
val_generator = SequenceGen(batch_size=20000)

model = Sequential()

model.add(LocallyConnected1D(
                filters=100,
                kernel_size=1,
                input_shape=(100, 2)))
model.add(Activation('linear'))
model.add(Dropout(0.25))
model.add(Flatten())
model.add(Dense(units=25))
model.add(Dense(units=1))
model.add(Activation('linear'))

model.compile(optimizer='rmsprop',loss='mae')
model.fit_generator(
                generator=data_generator, 
                steps_per_epoch=None, # Gets figured out from len(generator)
                epochs=6000, 
                verbose=1, 
                callbacks=[],
                validation_data=val_generator, 
                validation_steps=None, # Gets figured out from len(generator) 
                class_weight=None, 
                max_queue_size=10, 
                workers=10,
                use_multiprocessing=False, 
                shuffle=False, 
                initial_epoch=0)
```",BrashEndeavours,None,2017-12-02T21:44:03Z,2017-12-03T01:08:54Z
8616,"acgan: Add batch normalization to the Generator, etc","1. Add batch normalization to the Generator. This makes the example closer to the referenced paper and improves generated images. Adding batch normalization to the Discriminator breaks training so badly, that I suspect a bug (maybe https://github.com/fchollet/keras/pull/5647 is fixed incompletely or something). Not adding batch normalization to the Discriminator also side-steps the issue of correlation of samples within a batch (https://github.com/soumith/ganhacks#4-batchnorm)

2.  Use one-sided soft labels and a harder `soft_one=0.95` vs 0.9). The referenced paper says they don't need one-sided soft labels. This example also doesn't ""need"" them any more, but the generated images are better. Add reference to a paper.

3. Increase `epoch=100` from 50, as good images often appear between epochs 50 and 100. Note that the training time per epoch is half that of the original example, after https://github.com/fchollet/keras/pull/8482/commits/67cd3b09510643655998311d66f0e9b3475f32e5

4. Increase output precision of various losses from 2 decimal digits to 4. You can't really tell what is going on with just 2. 

@lukedeo , I see a lot of examples online which use embedding with Hadamard, but do you know of any paper(s) we can reference? I haven't seen it in any of the GAN papers. I really like embedding with Hadamard, as replacing them would require multiple (3-5?) additional layers, but to be thorough I did a half-hearted attempts to remove them (make closer to the acgan paper), just to see if I can, and failed (generated images are much worse).
",ozabluda,None,2017-11-28T21:38:02Z,2019-03-24T06:55:07Z
8588,Incorrect GRU prediction on small size data,"I have an issue with results in examples/image_ocr.py script.

Sample works perfect when I predict data of size equal to minibatch_size (32) or greater.
But if I run prediction of any small size data, e.g. 1, 2, or 3 images, I got absolutely strange and incorrect answers, like random.
Predicting 10-20 samples sometimes look good but with 20-30% errors.
Is it GRU's feature or bug? Or something else?
GRU layers in the example are not stateful and shouldn't depend on minibatch size.",stas-semenov,None,2017-11-25T22:52:41Z,2017-12-11T19:22:07Z
8552,Remove reshape() which has no effect,... since it's reshaping to the current shape.  Also fixes a non-triggered latent bug (no effect is exactly what we want) actual changes would have had to be done with `transpose()`.,ozabluda,None,2017-11-21T19:09:36Z,2017-11-21T20:21:15Z
8494,bug fix on pandas DataFrame support,"This PR will try to fix some pandas DataFrame related issues, including https://github.com/fchollet/keras/pull/8199 and https://github.com/fchollet/keras/pull/8290.

 - Pandas DataFrame check is moved, in order to make sure that keras will check `array`/`list`/`dict` first, then `numpy.ndarray`/`pandas.DataFrame`.
 - Add standalone `test_pandas_dataframe` unit test, covering `Model.fit`, `Model.predict`, `Model.predict_on_batch`, `Model.evaluate`, `Model.train_on_batch`, `Model.test_on_batch` functions, and `array`/`list`/`dict` inputs.",icyblade,None,2017-11-15T04:16:05Z,2017-11-16T04:29:32Z
8476,Replace erroneous num_classes with batch_size in examples/mnist_tfrecord.py,the bug was there from the very first commit of the file.,ozabluda,None,2017-11-14T05:07:03Z,2017-11-14T22:17:01Z
8473,Cannot improve the accuracy for SimpleRNN network,"I have a dataset C of 10,000 (binary) samples each of 64 features. The class label is binary ( either 1 or -1). For instance, a sample would look like this `c=[1,0,0,0,1,0, .... , 0,1]`,` r=[-1]`. My goal is to generate a classification model that is able to classify the samples based on the binary classes ( i.e., 1 or -1). I thought to try using Recurrent NN to generate a good model for classification. To do so, I have written the following code using Keras library:

```
    C = C.reshape((C.shape[0], C.shape[1], 1))
    tr_C, ts_C, tr_r, ts_r = train_test_split(C, r, train_size=.8)
    batch_size = 1000

    print('RNN model...')
    model = Sequential()
    model.add(Dense(64,
                    batch_input_shape=(batch_size, C.shape[1], 1),
                    activation='relu',
                    kernel_initializer='glorot_uniform',
                    bias_initializer='glorot_uniform',
                    )
              )

    model.add(SimpleRNN(64,
                        #batch_input_shape=(batch_size, C.shape[1], 1),
                        activation='relu',
                        kernel_initializer='glorot_uniform',
                        bias_initializer='glorot_uniform',
                        stateful=True,
                        return_sequences=True,
                        )
              )

    model.add(SimpleRNN(64,
                        activation='relu',
                        kernel_initializer='glorot_uniform',
                        bias_initializer='glorot_uniform',
                        )
              )

    model.add(Dense(1, activation='tanh'))

    print('>>> Training...')
    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])

    model.fit(tr_C, tr_r,
              batch_size=batch_size, epochs=2,
              shuffle=True, validation_data=(ts_C, ts_r))
```

The problem is that I keep getting only 50% accuracy. I tried different combinations of initial weights, number of layers, and etc but nothing helps. I start thinking that my code has a logical bug! Kindly, can someone verify my code if it is logically correct? Any other hints are appreciated ",ghost,None,2017-11-13T22:52:42Z,2017-11-14T15:51:31Z
8404,"Error when checking target: expected dense_1 to have shape (None, 1) but got array with shape (64, 120)","When running this code:

```
def create_dense_net(nb_classes, img_input, depth=40, nb_block=3, 
     growth_rate=12, nb_filter=16, bottleneck=False, compression=1.0, p=None, wd=0, activation='softmax'):
    
    assert activation == 'softmax' or activation == 'sigmoid'
    assert (depth - 4) % nb_block == 0
    nb_layers_per_block = int((depth - 4) / nb_block)
    nb_layers = [nb_layers_per_block] * nb_block

    x = Lambda(preprocess)(img_input)
    x = conv(x, nb_filter, 3, wd, 0)
    for i,block in enumerate(nb_layers):
        x = dense_block(x, block, growth_rate, bottleneck=bottleneck, p=p, wd=wd)
        if i != len(nb_layers)-1:
            x = transition_block(x, compression=compression, p=p, wd=wd)

    x = relu_bn(x)
    x = GlobalAveragePooling2D()(x)
    return Dense(nb_classes, activation=activation, kernel_regularizer=l2(wd))(x)

input_shape = (224,224,3)
img_input = Input(shape=input_shape)
x = create_dense_net(train_batches.num_class, img_input, depth=100, nb_filter=16, compression=0.5, 
                     bottleneck=True, p=0.2, wd=1e-4)
model = Model(img_input, x)
model.compile(loss='sparse_categorical_crossentropy', 
      optimizer=keras.optimizers.SGD(0.1, 0.9, nesterov=True), metrics=[""accuracy""])

nb_epoch = 1

model.fit_generator(train_batches, steps_per_epoch=int(train_batches.samples/train_batches.batch_size),
                    epochs=nb_epoch,
                    validation_data=val_batches, 
                    validation_steps=int(val_batches.samples/val_batches.batch_size)
                   )

```
I get this error:

`ValueError: Error when checking target: expected dense_1 to have shape (None, 1) but got array with shape (64, 120)
`
The number of classes in my batches are 120 and the batch size is 64 so the (64, 120) shape for the output array is correct. The final Dense layer is correctly initialized with 120 output classes as well as can be seen at the end of model.summary():

```
conv2d_99 (Conv2D)               (None, 56, 56, 12)    5196        activation_98[0][0]              
____________________________________________________________________________________________________
dropout_98 (Dropout)             (None, 56, 56, 12)    0           conv2d_99[0][0]                  
____________________________________________________________________________________________________
merge_48 (Merge)                 (None, 56, 56, 340)   0           merge_47[0][0]                   
                                                                   dropout_98[0][0]                 
____________________________________________________________________________________________________
batch_normalization_99 (BatchNor (None, 56, 56, 340)   1360        merge_48[0][0]                   
____________________________________________________________________________________________________
activation_99 (Activation)       (None, 56, 56, 340)   0           batch_normalization_99[0][0]     
____________________________________________________________________________________________________
global_average_pooling2d_1 (Glob (None, 340)           0           activation_99[0][0]              
____________________________________________________________________________________________________
dense_1 (Dense)                  (None, 120)           40920       global_average_pooling2d_1[0][0] 
====================================================================================================
Total params: 818,980
Trainable params: 795,468
Non-trainable params: 23,512

```
The model I use is based on this notebook: [densenet-keras](https://github.com/fastai/courses/blob/master/deeplearning2/densenet-keras.ipynb
), which I have only modified slightly to increase the number of output classes from 10 to 120 and to adapt to Keras 2. I'm using Keras 2.0.5 with a Tensorflow back-end.

Could this be caused by a known bug and if not, how to debug it further?

Thanks,
Robert


",hillenr14,None,2017-11-06T08:01:56Z,2020-04-16T06:05:18Z
8384,Bugs with ImageDataGenerator,"I am using model.predict_generator and ImageDataGenerator to predict my image label, my code is as follows:
    `valid_gen= ImageDataGenerator().flow_from_directory(""../input/valid/valid"", target_size=(input_size, input_size),shuffle=False, batch_size=1)`
   `pred = model.predict_generator(generator=valid_gen, steps = 1, verbose=1)` 

actually I put only one image into folder ""../input/valid/valid"", then I check the predict result, I found it is totally wrong. I test for many images, so I think this is a bug. Anyone got some idea about this?
",jamesben6688,None,2017-11-04T08:54:00Z,2017-11-04T13:22:16Z
8351,load_weights() not working,"so I wanna do some block-wise greedy pre-training (similar to stacked autoencoders), say I got 2 blocks, BlockA and BlockB, I'm gonna have to train BlockA alone first, then load BlockA's weights into a larger net that has both BlockA and BlockB in it, and mark BlockA untrainable in that net, then train the rest (BlockB) of that larger net, it sounds about right but I'm getting dimension errors like **ValueError: Dimension 0 in both shapes must be equal, but are 9 and 1 for 'Assign_6' (op: 'Assign') with input shapes: [9,9,128,1], [1,64,9,9].**

test code:

    from keras import models, layers, optimizers
    PatternSize = 159
    Margin = 36
    
    def GetBlockA():
        HiFreqGuess = layers.Input(shape=(PatternSize, PatternSize, 1))
        LowResBase = layers.Input(shape=(PatternSize - 2 * Margin, PatternSize - 2 * Margin, 1))
        
        Conv1a = layers.Conv2D(64, (3, 3), activation=None, padding='valid', name='c'+'1a')(HiFreqGuess)
        Conv1a = layers.advanced_activations.PReLU(shared_axes=[1, 2], name='r'+'1a')(Conv1a)
        Conv1b = layers.Conv2D(64, (3, 3), activation=None, padding='valid', name='c'+'1b')(Conv1a)
        Conv1b = layers.advanced_activations.PReLU(shared_axes=[1, 2], name='r'+'1b')(Conv1b)
        
        Ensemble = layers.Conv2D(1, (9, 9), activation=None, use_bias=False, padding='valid', name='Ensemble')(layers.convolutional.Cropping2D(30)(Conv1b))
        HighResolutionPatterns = layers.add([LowResBase, Ensemble])
        
        Model = models.Model(inputs=[HiFreqGuess, LowResBase], outputs=HighResolutionPatterns)
        Model.compile(loss='mse', optimizer=optimizers.Adam(lr=1e-4, decay=5e-4))
        return Model
    
    def GetBlockB():
        HiFreqGuess = layers.Input(shape=(PatternSize, PatternSize, 1))
        LowResBase = layers.Input(shape=(PatternSize - 2 * Margin, PatternSize - 2 * Margin, 1))
        
        Conv1a = layers.Conv2D(64, (3, 3), activation=None, padding='valid', name='c'+'1a', trainable=False)(HiFreqGuess)
        Conv1a = layers.advanced_activations.PReLU(shared_axes=[1, 2], name='r'+'1a', trainable=False)(Conv1a)
        Conv1b = layers.Conv2D(64, (3, 3), activation=None, padding='valid', name='c'+'1b', trainable=False)(Conv1a)
        Conv1b = layers.advanced_activations.PReLU(shared_axes=[1, 2], name='r'+'1b', trainable=False)(Conv1b)
    
        Conv2 = layers.Conv2D(128, (3, 3), activation=None, padding='valid', name='c'+'2a')(Conv1b)
        Conv2 = layers.advanced_activations.PReLU(shared_axes=[1, 2], name='r'+'2a')(Conv2)
        
        Ensemble = layers.Conv2D(1, (9, 9), activation=None, use_bias=False, padding='valid', name='Ensemble')(layers.convolutional.Cropping2D(29)(Conv2))
        HighResolutionPatterns = layers.add([LowResBase, Ensemble])
        
        Model = models.Model(inputs=[HiFreqGuess, LowResBase], outputs=HighResolutionPatterns)
        Model.load_weights('BlockA.h5', by_name=True)
        Model.compile(loss='mse', optimizer=optimizers.Adam(lr=1e-4, decay=5e-4))
        return Model

    ModelA = Model.GetBlockA()
    ModelA.fit([HiFreq, Base], Target, epochs=50)
    ModelA.save_weights('BlockA.h5')
    
    ModelB = Model.GetBlockB()
    ModelB.fit([HiFreq, Base], Target, epochs=50) #Error!

keras version: 2.0.8

keras.json:

    {
        ""floatx"": ""float32"",
        ""epsilon"": 1e-07,
        ""backend"": ""tensorflow"",
        ""image_data_format"": ""channels_last""
    }

Am I doing something wrong? or is it like... some kind of bug?, the error would disappear immediately if I comment out ""Model.load_weights('BlockA.h5', by_name=True)"" in GetBlockB()
",IFeelBloated,None,2017-11-02T11:16:58Z,2017-12-10T19:38:24Z
8343,TypeError: can't pickle _thread.lock objects,"Information:
- Keras version 2.0.8
- Tensorflow version 1.3.0
- Python 3.6

Minimal example to reproduce the error:
```
from keras.layers import Input, Lambda, Dense
from keras.models import Model
from keras.callbacks import ModelCheckpoint
from keras.optimizers import Adam
import tensorflow as tf
import numpy as np

x = Input(shape=(30,3))
low = tf.constant(np.random.rand(30, 3).astype('float32'))
high = tf.constant(1 + np.random.rand(30, 3).astype('float32'))
clipped_out_position = Lambda(lambda x, low, high: tf.clip_by_value(x, low, high),
                                      arguments={'low': low, 'high': high})(x)

model = Model(inputs=x, outputs=[clipped_out_position])
optimizer = Adam(lr=.1)
model.compile(optimizer=optimizer, loss=""mean_squared_error"")
checkpoint = ModelCheckpoint(""debug.hdf"", monitor=""val_loss"", verbose=1, save_best_only=True, mode=""min"")
training_callbacks = [checkpoint]
model.fit(np.random.rand(100, 30, 3), [np.random.rand(100, 30, 3)], callbacks=training_callbacks, epochs=50, batch_size=10, validation_split=0.33)
```

Error output:
```
Train on 67 samples, validate on 33 samples
Epoch 1/50
10/67 [===>..........................] - ETA: 0s - loss: 0.1627Epoch 00001: val_loss improved from inf to 0.17002, saving model to debug.hdf
Traceback (most recent call last):
  File ""debug_multitask_inverter.py"", line 19, in <module>
    model.fit(np.random.rand(100, 30, 3), [np.random.rand(100, 30, 3)], callbacks=training_callbacks, epochs=50, batch_size=10, validation_split=0.33)
  File ""/om/user/lnj/openmind_env/tensorflow-gpu/lib/python3.6/site-packages/keras/engine/training.py"", line 1631, in fit

▽
    validation_steps=validation_steps)
  File ""/om/user/lnj/openmind_env/tensorflow-gpu/lib/python3.6/site-packages/keras/engine/training.py"", line 1233, in _fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File ""/om/user/lnj/openmind_env/tensorflow-gpu/lib/python3.6/site-packages/keras/callbacks.py"", line 73, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File ""/om/user/lnj/openmind_env/tensorflow-gpu/lib/python3.6/site-packages/keras/callbacks.py"", line 414, in on_epoch_end
    self.model.save(filepath, overwrite=True)
  File ""/om/user/lnj/openmind_env/tensorflow-gpu/lib/python3.6/site-packages/keras/engine/topology.py"", line 2556, in save
    save_model(self, filepath, overwrite, include_optimizer)
  File ""/om/user/lnj/openmind_env/tensorflow-gpu/lib/python3.6/site-packages/keras/models.py"", line 107, in save_model
    'config': model.get_config()
  File ""/om/user/lnj/openmind_env/tensorflow-gpu/lib/python3.6/site-packages/keras/engine/topology.py"", line 2397, in get_config
    return copy.deepcopy(config)
  File ""/om/user/lnj/openmind_env/tensorflow-gpu/lib/python3.6/copy.py"", line 150, in deepcopy
    y = copier(x, memo)
  File ""/om/user/lnj/openmind_env/tensorflow-gpu/lib/python3.6/copy.py"", line 240, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
  File ""/om/user/lnj/openmind_env/tensorflow-gpu/lib/python3.6/copy.py"", line 150, in deepcopy
    y = copier(x, memo)
  File ""/om/user/lnj/openmind_env/tensorflow-gpu/lib/python3.6/copy.py"", line 215, in _deepcopy_list
    append(deepcopy(a, memo))
  File ""/om/user/lnj/openmind_env/tensorflow-gpu/lib/python3.6/copy.py"", line 150, in deepcopy
    y = copier(x, memo)
  File ""/om/user/lnj/openmind_env/tensorflow-gpu/lib/python3.6/copy.py"", line 240, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
  File ""/om/user/lnj/openmind_env/tensorflow-gpu/lib/python3.6/copy.py"", line 150, in deepcopy
    y = copier(x, memo)
  File ""/om/user/lnj/openmind_env/tensorflow-gpu/lib/python3.6/copy.py"", line 240, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
  File ""/om/user/lnj/openmind_env/tensorflow-gpu/lib/python3.6/copy.py"", line 150, in deepcopy
    y = copier(x, memo)
  File ""/om/user/lnj/openmind_env/tensorflow-gpu/lib/python3.6/copy.py"", line 240, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
  File ""/om/user/lnj/openmind_env/tensorflow-gpu/lib/python3.6/copy.py"", line 180, in deepcopy
    y = _reconstruct(x, memo, *rv)
  File ""/om/user/lnj/openmind_env/tensorflow-gpu/lib/python3.6/copy.py"", line 280, in _reconstruct
    state = deepcopy(state, memo)
  File ""/om/user/lnj/openmind_env/tensorflow-gpu/lib/python3.6/copy.py"", line 150, in deepcopy
    y = copier(x, memo)
  File ""/om/user/lnj/openmind_env/tensorflow-gpu/lib/python3.6/copy.py"", line 240, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
  File ""/om/user/lnj/openmind_env/tensorflow-gpu/lib/python3.6/copy.py"", line 180, in deepcopy
    y = _reconstruct(x, memo, *rv)
  File ""/om/user/lnj/openmind_env/tensorflow-gpu/lib/python3.6/copy.py"", line 280, in _reconstruct
    state = deepcopy(state, memo)
  File ""/om/user/lnj/openmind_env/tensorflow-gpu/lib/python3.6/copy.py"", line 150, in deepcopy
    y = copier(x, memo)
  File ""/om/user/lnj/openmind_env/tensorflow-gpu/lib/python3.6/copy.py"", line 240, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
  File ""/om/user/lnj/openmind_env/tensorflow-gpu/lib/python3.6/copy.py"", line 180, in deepcopy
    y = _reconstruct(x, memo, *rv)
  File ""/om/user/lnj/openmind_env/tensorflow-gpu/lib/python3.6/copy.py"", line 280, in _reconstruct
    state = deepcopy(state, memo)
  File ""/om/user/lnj/openmind_env/tensorflow-gpu/lib/python3.6/copy.py"", line 150, in deepcopy
    y = copier(x, memo)
  File ""/om/user/lnj/openmind_env/tensorflow-gpu/lib/python3.6/copy.py"", line 240, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
  File ""/om/user/lnj/openmind_env/tensorflow-gpu/lib/python3.6/copy.py"", line 169, in deepcopy
    rv = reductor(4)
TypeError: can't pickle _thread.lock objects
```

It seems like the error has occurred in the past in different contexts [here](https://github.com/tensorflow/tensorflow/issues/11157), but I'm not dumping the model directly -- I'm using the ModelCheckpoint callback. Any idea what could be going wrong?",jlin816,b'backend:tensorflow',2017-11-01T17:26:48Z,2019-11-14T12:02:04Z
8330,Sync naming convention and style in NLP datasets,Also fixes a possible bug with np.load()/f.close() pair not being exception-safe.,ozabluda,None,2017-10-31T22:03:23Z,2018-09-15T22:42:19Z
8327,Simplify reporthook-related logic,"Remove duplicate logic, reduce line count, fix potential bug if reporthook is convertible to bool by checking ""is not None"" - i.e. what PR https://github.com/fchollet/keras/pull/8320 title promised, but didn't really do :-)",ozabluda,None,2017-10-31T20:14:58Z,2017-11-01T20:06:53Z
8277,Increase file save hash size,"Issue #8249 runs into a problem where the max hash size is low, resulting in files being potentially overwritten.

The behavior of this functionality is as such:
As batch size increases, the probability that any given file will have a conflict in the hash reduces. However, when the author wants to save images with a batch size of one, the probability of a conflict increases since {index} is always 1. This seems to just be an unforeseen bug because a batch size of one is uncommon.",RitwikGupta,None,2017-10-28T00:08:51Z,2017-10-28T00:43:32Z
8253,[BUG]Some Errors : using multi_gpu : can't save_model,"Using multi_gpu to train model : 
def multi_gpu_test_simple_model():
    print('####### test simple model')
    num_samples = 1000
    input_dim = 10
    output_dim = 1
    hidden_dim = 10
    gpus = 2
    epochs = 8
    model = keras.models.Sequential()
    model.add(keras.layers.Dense(hidden_dim,
                                 input_shape=(input_dim,)))
    model.add(keras.layers.Dense(output_dim))

    x = np.random.random((num_samples, input_dim))
    y = np.random.random((num_samples, output_dim))
    parallel_model = multi_gpu_model(model, gpus=gpus)
    from keras.callbacks import ModelCheckpoint
    parallel_model.compile(loss='mse', optimizer='rmsprop')
    parallel_model.fit(x, y, epochs=epochs)

    from keras.models import save_model
    save_model(parallel_model, '1.h5', overwrite=True, include_optimizer=True)

Error : can't pickle NoImplementedType objects 
please solve this problem",Entonytang,None,2017-10-26T12:46:59Z,2018-11-02T21:39:44Z
8249, ImageDataGenerator save_to_dir command will lose some generating image due to filename conflict.,"Hello, when I want to generate 10000 images (batch size = 1), it will generate less than 10000 images, you can see the fllowing codes and result.
```
datagen = image.ImageDataGenerator()

gen_data = datagen.flow_from_directory(sample_path+'trn/', 
                                   batch_size=1, 
                                   shuffle=False, 
                                   save_to_dir=gen_path+'gen/',
                                   save_prefix='gen', 
                                   target_size=(224, 224))
for i in range(10000):
    gen_data.next()
```
![](http://ormr426d5.bkt.clouddn.com/17-10-26/77433386.jpg)

The more images you generate, the more images you'll lose.

Then I check the source code of keras.preprocessing.image.py , the DirectoryIterator class, line 1105:

```
fname = '{prefix}_{index}_{hash}.{format}'.format(prefix=self.save_prefix,
                                                                  index=j,
                                                                  hash=np.random.randint(1e4),
                                                                  format=self.save_format)
```

The 'hash' term is using np.random.randint, **that means the more images you want to generate , the higher probability you'll get the same hash number, that will cause filename conflict, the old one will be overwrite!**

In my data augmentation task, I have to generate the same number of images per class. If the image quantity per class doesn't equal, it'll cause the multi-input image pair mismatch. For example, the FaceNet model uses multi-input images (anchor -  positive -  nagative pair), we cannot lose any generating image.

My solution's here, I hack the keras.preprocessing.image.py, you can find 4 changes in line 1088 to lline 1135:

```
    def _get_batches_of_transformed_samples(self, index_array, index): # change 1: add the 'index' argurment
        batch_x = np.zeros((len(index_array),) + self.image_shape, dtype=K.floatx())
        grayscale = self.color_mode == 'grayscale'
        # build batch of image data
        for i, j in enumerate(index_array):
            fname = self.filenames[j]
            img = load_img(os.path.join(self.directory, fname),
                           grayscale=grayscale,
                           target_size=self.target_size)
            x = img_to_array(img, data_format=self.data_format)
            x = self.image_data_generator.random_transform(x)
            x = self.image_data_generator.standardize(x)
            batch_x[i] = x
        # optionally save augmented images to disk for debugging purposes
        if self.save_to_dir:
            for i, j in enumerate(index_array):
                img = array_to_img(batch_x[i], self.data_format, scale=True)
                fname = '{prefix}_{index}_{hash}.{format}'.format(prefix=self.save_prefix,
                                                                  index=j,
                                                                  hash=index, # change 2: hash using given index
                                                                  format=self.save_format)
                img.save(os.path.join(self.save_to_dir, fname))
        # build batch of labels
        if self.class_mode == 'input':
            batch_y = batch_x.copy()
        elif self.class_mode == 'sparse':
            batch_y = self.classes[index_array]
        elif self.class_mode == 'binary':
            batch_y = self.classes[index_array].astype(K.floatx())
        elif self.class_mode == 'categorical':
            batch_y = np.zeros((len(batch_x), self.num_classes), dtype=K.floatx())
            for i, label in enumerate(self.classes[index_array]):
                batch_y[i, label] = 1.
        else:
            return batch_x
        return batch_x, batch_y

    def next(self, index): # change 3: add the 'index' argurment
        """"""For python 2.x.
        # Returns
            The next batch.
        """"""
        with self.lock:
            index_array = next(self.index_generator)
        # The transformation of images is not under thread lock
        # so it can be done in parallel
        return self._get_batches_of_transformed_samples(index_array, index) # change 4: add the 'index' argurment
```
And then I modify my codes:
```
datagen = image.ImageDataGenerator()

gen_data = datagen.flow_from_directory(sample_path+'trn/', 
                                   batch_size=1, 
                                   shuffle=False, 
                                   save_to_dir=gen_path+'gen/',
                                   save_prefix='gen', 
                                   target_size=(224, 224))

order_list = list(np.random.permutation(10000)) # give an shuffled numpy permutation number list

for i in range(10000):
    gen_data.next(order_list[i])
```
It works fine! But I still suggest that this problem can be fixed,  thanks.

framework versions:
keras: 2.0.5
tensorflow: 1.3.0
python: 3.5.3
os: ubuntu 16.04

Please make sure that the boxes below are checked before you submit your issue. If your issue is an implementation question, please ask your question on [StackOverflow](http://stackoverflow.com/questions/tagged/keras) or [join the Keras Slack channel](https://keras-slack-autojoin.herokuapp.com/) and ask there instead of filing a GitHub issue.

Thank you!

- [x] Check that you are up-to-date with the master branch of Keras. You can update with:
pip install git+git://github.com/fchollet/keras.git --upgrade --no-deps

- [x] If running on TensorFlow, check that you are up-to-date with the latest version. The installation instructions can be found [here](https://www.tensorflow.org/get_started/os_setup).

- [ ] If running on Theano, check that you are up-to-date with the master branch of Theano. You can update with:
pip install git+git://github.com/Theano/Theano.git --upgrade --no-deps

- [ ] Provide a link to a GitHub Gist of a Python script that can reproduce your issue (or just copy the script here if it is short).
",JustinhoCHN,None,2017-10-26T06:32:42Z,2018-04-12T16:20:28Z
8212,ValueError: You are trying to load a weight file containing 3 layers into a model with 1 layers.,"I train a model with the following code:

    base_model = VGG19(...)
    ..............
    model.fit_generator(...., callbacks=[ModelCheckpoint(filepath=checkpoint_file, save_best_only=True,
                        save_weights_only=True)]....)

however, when I load the weights with the following code:

    from keras.utils.training_utils import multi_gpu_model
    model = load_vgg19(...)
    model = multi_gpu_model(model, gpus=3)
    model.load_weights(checkpoint_file)
    model.fit_generator(...........)

I got the error:   ValueError: You are trying to load a weight file containing 3 layers into a model with 1 layers and followed by AttributeError: 'NoneType' object has no attribute 'TF_DeleteStatus'. Is this a bug?",jamesben6688,None,2017-10-21T13:48:14Z,2018-12-19T21:42:21Z
8206,Simplify and fix count_params(),"also use existing abstraction get_variable_shape(x), instead of using .shape attribute directly. Also improve docstrings.

I think this fixes a bug in TF backend, because int_shape(x) returns x.get_shape() only if x._keras_shape is not set, for example if x is np.ndarray, or a sparse tensor/ndarray.",ozabluda,None,2017-10-20T21:15:36Z,2017-10-24T20:39:35Z
8183,"K.conv1d data_format default value is not ""channels_last""","I was trying to use `K.conv1d` from keras backend, and after having quite a few bugs, I went to inspect the code: https://github.com/fchollet/keras/blob/master/keras/backend/tensorflow_backend.py/#L3106

And I found out that the default value for `data_format` is `None`. This is making the code assume (in the if statement) that the default value is `channels_first`, which is not right. 

My problem gets solved by simply adding `data_format='channels_first'` in the call. And yes, I'm sure my default configuration in keras.json is channels_last. ",danmoller,None,2017-10-19T02:36:35Z,2017-10-19T19:15:44Z
8172,"Rewrite test_progbar(), and fix the triggered Python3 bug.","Increase coverage, and make better",ozabluda,None,2017-10-18T00:43:51Z,2018-01-12T00:00:07Z
8162,Fixing finite generator race condition,"I spotted a race condition on my previous PR https://github.com/fchollet/keras/pull/8104. The problem affects only the case of finite generators and has no effect on the infinite ones. This PR fixes the bug and updates the test to capture similar problems. 

Please check the github comments on the code where I explain where the problem was and how I fixed it. Feedback is always welcome! :)",datumbox,None,2017-10-17T11:06:21Z,2017-10-19T19:19:01Z
8124,fix topology.py __keras_shape bug,,gpernelle,None,2017-10-12T13:47:00Z,2017-10-12T18:58:59Z
8123,[BUG] Save Model with multi_gpu,"Hey guys,

the new multi_gpu feature seems to have a bug. If you want to save the model you get an error like the one below. To reproduce just run the test multi_gpu_test_simple_model() with parallel_model.save(""logs/model.h5"") at the end.

```python
def multi_gpu_test_simple_model():
    print('####### test simple model')
    num_samples = 1000
    input_dim = 10
    output_dim = 1
    hidden_dim = 10
    gpus = 4
    epochs = 2
    model = keras.models.Sequential()
    model.add(keras.layers.Dense(hidden_dim,
                                 input_shape=(input_dim,)))
    model.add(keras.layers.Dense(output_dim))

    x = np.random.random((num_samples, input_dim))
    y = np.random.random((num_samples, output_dim))
    parallel_model = multi_gpu_model(model, gpus=gpus)

    parallel_model.compile(loss='mse', optimizer='rmsprop')
    parallel_model.fit(x, y, epochs=epochs)

    parallel_model.save(""logs/model.h5"")


multi_gpu_test_simple_model()
```

> 1000/1000 [==============================] - ETA: 0s - loss: 0.4537  
> Epoch 2/2
> 1000/1000 [==============================] - ETA: 0s - loss: 0.2939
> Traceback (most recent call last):
>   File ""steps_kt/test.py"", line 43, in <module>
>     multi_gpu_test_simple_model()
>   File ""steps_kt/test.py"", line 40, in multi_gpu_test_simple_model
>     parallel_model.save(""logs/model.h5"")
>   File ""/home/y0052080/pyenv/lib/python3.6/site-packages/Keras-2.0.8-py3.6.egg/keras/engine/topology.py"", line 2555, in save
>   File ""/home/y0052080/pyenv/lib/python3.6/site-packages/Keras-2.0.8-py3.6.egg/keras/models.py"", line 107, in save_model
>   File ""/home/y0052080/pyenv/lib/python3.6/site-packages/Keras-2.0.8-py3.6.egg/keras/engine/topology.py"", line 2396, in get_config
>   File ""/cluster/tools/python3/lib/python3.6/copy.py"", line 150, in deepcopy
>     y = copier(x, memo)
>   File ""/cluster/tools/python3/lib/python3.6/copy.py"", line 240, in _deepcopy_dict
>     y[deepcopy(key, memo)] = deepcopy(value, memo)
>   File ""/cluster/tools/python3/lib/python3.6/copy.py"", line 150, in deepcopy
>     y = copier(x, memo)
>   File ""/cluster/tools/python3/lib/python3.6/copy.py"", line 215, in _deepcopy_list
>     append(deepcopy(a, memo))
>   File ""/cluster/tools/python3/lib/python3.6/copy.py"", line 150, in deepcopy
>     y = copier(x, memo)
>   File ""/cluster/tools/python3/lib/python3.6/copy.py"", line 240, in _deepcopy_dict
>     y[deepcopy(key, memo)] = deepcopy(value, memo)
>   File ""/cluster/tools/python3/lib/python3.6/copy.py"", line 150, in deepcopy
>     y = copier(x, memo)
>   File ""/cluster/tools/python3/lib/python3.6/copy.py"", line 240, in _deepcopy_dict
>     y[deepcopy(key, memo)] = deepcopy(value, memo)
>   File ""/cluster/tools/python3/lib/python3.6/copy.py"", line 150, in deepcopy
>     y = copier(x, memo)
>   File ""/cluster/tools/python3/lib/python3.6/copy.py"", line 220, in _deepcopy_tuple
>     y = [deepcopy(a, memo) for a in x]
>   File ""/cluster/tools/python3/lib/python3.6/copy.py"", line 220, in <listcomp>
>     y = [deepcopy(a, memo) for a in x]
>   File ""/cluster/tools/python3/lib/python3.6/copy.py"", line 150, in deepcopy
>     y = copier(x, memo)
>   File ""/cluster/tools/python3/lib/python3.6/copy.py"", line 220, in _deepcopy_tuple
>     y = [deepcopy(a, memo) for a in x]
>   File ""/cluster/tools/python3/lib/python3.6/copy.py"", line 220, in <listcomp>
>     y = [deepcopy(a, memo) for a in x]
>   File ""/cluster/tools/python3/lib/python3.6/copy.py"", line 169, in deepcopy
>     rv = reductor(4)
> TypeError: can't pickle module objects
> 


Please make sure that the boxes below are checked before you submit your issue. If your issue is an implementation question, please ask your question on [StackOverflow](http://stackoverflow.com/questions/tagged/keras) or [join the Keras Slack channel](https://keras-slack-autojoin.herokuapp.com/) and ask there instead of filing a GitHub issue.

Thank you!

- [ x] Check that you are up-to-date with the master branch of Keras. You can update with:
pip install git+git://github.com/fchollet/keras.git --upgrade --no-deps

- [ x] If running on TensorFlow, check that you are up-to-date with the latest version. The installation instructions can be found [here](https://www.tensorflow.org/get_started/os_setup).

",PBehr,None,2017-10-12T13:27:21Z,2019-11-08T11:46:37Z
8121,[BUG] Number of trainable weights seem to change after model compilation,"Consider the following scenario

```python
from keras.layers import Input, Dense
from keras.models import Model
from keras.optimizers import Adam

x = Input(shape=(100,))
y1 = Dense(units=32)(x)
model1 = Model(inputs=x, outputs=y1)
print(""MODEL 1"")
model1.summary()

model1.trainable = False
x = Input(shape=(100,))
y1 = model1(x)
y2 = Dense(units=64)(y1)
model2 = Model(inputs=x, outputs=y2)
model2.compile(optimizer=Adam(), loss='categorical_crossentropy')

print(""MODEL 2"")
model2.summary()

model1.trainable = True
print(""MODEL 2 after"")
model2.summary()
```

I would expect that, since `model2` has been compiled, the output of the two `model2.summary()` calls would be the same. However, after running the above code the actual output is

```
_________________________________________________________________
MODEL 2
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         (None, 100)               0         
_________________________________________________________________
model_1 (Model)              (None, 32)                3232      
_________________________________________________________________
dense_2 (Dense)              (None, 64)                2112      
=================================================================
Total params: 5,344
Trainable params: 2,112
Non-trainable params: 3,232
_________________________________________________________________
MODEL 2 after
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         (None, 100)               0         
_________________________________________________________________
model_1 (Model)              (None, 32)                3232      
_________________________________________________________________
dense_2 (Dense)              (None, 64)                2112      
=================================================================
Total params: 5,344
Trainable params: 5,344
Non-trainable params: 0
```

Is this the expected behavior? 

In addition, from other experiments I get the feeling that although the number of trainable weights reported by `summary()` differs in the two cases, the actual number of trainable weights is the expected one, that is, in the example above, even after setting `model1.trainable=True`, training will really update only 2,112 parameters and not 5,344. So, maybe this is just a reporting issue.",alpapado,None,2017-10-12T07:40:30Z,2017-10-25T22:05:06Z
8120,Rename num_class => num_classes,"Outside of tests/ directory ""num_class"" is used 10 times, ""num_classes"" is used 106 times. This makes it all consistent, and also fixes a docstring bug in test_util.get_test_data()

Inside tests/ directory, the score is 53:62 in favor of num_classes. I can do the renaming there as well, if there is interest.
",ozabluda,None,2017-10-12T05:53:38Z,2017-10-12T19:28:37Z
8106,Sync verbose=1 with verbose=2,... fixing (apparently) two bugs in verbose=2. verbose=1 logic was introduced in https://github.com/fchollet/keras/pull/704/ and https://github.com/fchollet/keras/commit/729f0765da577a4ebd879331f651b6d241a10632,ozabluda,None,2017-10-10T18:03:48Z,2018-01-25T02:33:10Z
8100,Fix off-by-one error in EarlyStopping callback,"`self.wait` should be incremented before the comparison with `self.patience`, as this comparison is made after the end of an epoch. I noticed the bug in this [StackOverflow question](https://stackoverflow.com/questions/46656948/earlystopping-callback-behaving-mysteriously-in-keras) and the test case I added is derived from that example.",nicolewhite,None,2017-10-10T04:19:45Z,2017-11-26T03:36:38Z
8071,Fix off-by-one bug in predict/evaluate progress bar,"Fix off-by-one bug in predict/evaluate progress bar
```
Before:
0/1 [..............................] - ETA: 0s
0/1 [..............................] - ETA: 0s

After:
1/1 [==============================] - ETA: 0s
1/1 [==============================] - ETA: 0s
```


Also sync (make identical) portions of the code in _predict_loop() and _test_loop()",ozabluda,None,2017-10-05T22:55:41Z,2017-10-06T17:28:49Z
8066,Fix bug where progress indicator doesn't always complete,"Before:
16256/17820 [==========================>...] - ETA: 0s
After:
17820/17820 [==============================] - ETA: 0s

Also improve code readability if => elif. No semantics change.",ozabluda,None,2017-10-05T18:59:40Z,2017-10-09T01:17:23Z
8052,Fix Sequence,"* Fix a bug where on_epoch_end would change the current epoch. (Added a test)
* Fix a bug where you couldn't have two Sequence at the same time. (Added a test)
* Fix a bug where Sequence wouldn't work on Windows (Need Fariz approval)

Integration test with https://gist.github.com/Dref360/82d42107e07d7a64b18ca079c91669c4 and get the good results.

@fchollet @farizrahman4u @konstantinberlin ",Dref360,None,2017-10-03T22:57:26Z,2017-11-23T22:00:32Z
8047,image_ocr bugfix: Add permute layer before RNN,"This fixes a bug introduced in https://github.com/fchollet/keras/pull/7908, where the width should be the time dimension when it gets fed into the RNN ",raelg,None,2017-10-03T10:49:36Z,2020-02-08T13:01:16Z
8034,"What are the differences between ""native keras"" and tensorflow keras""","I had to switch to native keras from tensorflow keras because of a bug fix that isn't yet included in tensorflow.

I experienced some issues when running the same code using the two different versions

The main issue was solved by suplying outputshape to a lambda layer calling a tensorflow function (einsum)

while this issue was solved, I want to know if there are other incompatibilities that may casue issues (errors, or different behaviour)

ther versions I used were tensorflow 1.3.0 and keras 2.0.8",ophiry,b'backend:tensorflow',2017-10-02T16:34:06Z,2018-11-02T21:15:14Z
8025,Bug fix: Models with shared layers shouldn't be considered Sequential like,"As of now, the following model is being considered as a ""Sequential-like"":

```python
from keras.layers import *
from keras.models import *

a = Input((5,))
dense = Dense(5)
b = dense(a)
c = dense(b)

model = Model(a, c)
model.summary()
```
",farizrahman4u,None,2017-09-30T00:46:25Z,2017-10-02T21:57:37Z
7985,Possible issue with metrics val_weighted_categorical_accuracy.,"Hi @fchollet . First of all let me thank you for your amazing work on **Keras**. 

I'm using keras=2.0.8 on the tensorflow-gpu=1.3.0 backend.

I'm trying to implement the use of `class_weight` on `model.fit` for a multi-label classification task with metrics `categorical accuracy` and `weighted categorical accuracy`.

I noticed that the output of `val_categorical_accuracy` is always equal to `val_weighted_categorical_accuracy`, which I guess is an incorrect behaviour.

![360](https://user-images.githubusercontent.com/22766463/30817715-e126c718-a219-11e7-84e7-0dd5f1632fb6.png)

My code looks roughly like this:

```
#This model has five classes which have an unbalanced representation of samples. I took the most represented and I rapported the others to it, having value 1
class_weight {0 : 1, 1 : 1.566, 2 : 22.34, 3 : 12.356, 4 : 29.981}


X_full, Y_full = full_set.as_matrix(columns=listColumnsInputs), full_set.as_matrix(columns=listColumnsOutputs)
X_train, Y_train = train_set.as_matrix(columns=listColumnsInputs), train_set.as_matrix(columns=listColumnsOutputs)
X_test, Y_test = test_set.as_matrix(columns=listColumnsInputs), test_set.as_matrix(columns=listColumnsOutputs)

X_full = X_full.reshape(len(X_full), len(listColumnsInputs))
X_train = X_train.reshape(len(X_train), len(listColumnsInputs))
X_test = X_test.reshape(len(X_test), len(listColumnsInputs))

batch_size = 128
nb_classes = len(listColumnsOutputs)

model = Sequential()
num_h = 100
numerolayers = 3
loss_function =  'mean_squared_logarithmic_error'
optimizer_function = 'SGD'

num_epoch = 1000
regularizerl2 = .0
regularizerl1 = .0

model.add(Dense(num_h, input_dim=len(listColumnsInputs), kernel_initializer='uniform', activation='relu', kernel_regularizer=regularizers.l2(regularizerl2), activity_regularizer=regularizers.l1(regularizerl1)))
for x in range(1, numerolayers): model.add(Dense(num_h, kernel_initializer='uniform', activation='relu', kernel_regularizer=regularizers.l2(regularizerl2), activity_regularizer=regularizers.l1(regularizerl1)))

model.add(Dense(len(listColumnsOutputs), kernel_initializer='uniform', activation='softmax'))

model.summary()

model.compile(loss=loss_function,  optimizer=optimizer_function, weighted_metrics=['categorical_accuracy'],  metrics=['categorical_accuracy'])

history = model.fit(X_train, Y_train, class_weight=class_weight, batch_size=batch_size, epochs=num_epoch, verbose=1, validation_data=(X_test, Y_test), callbacks=[TensorBoard(log_dir='./logs', histogram_freq=25, write_graph=True, write_images=False)])

score = model.evaluate(X_test, Y_test, verbose=0)
```


Is this a small bug? Am I wrong? 


Thanks a lot for your time.",kairosdojo,None,2017-09-25T16:00:39Z,2019-06-27T00:50:59Z
7975,Add option to specify resampling method in load_img,"Otherwise, nearest neighbor interpolation is used, which produces awful results. I consider this as a bug. In any case, the old behavior can be recovered using ``load_img(..., resample=PIL.Image.NEAREST)``.",ahojnnes,None,2017-09-24T10:01:39Z,2017-10-08T19:40:19Z
7930,ImageDataGenerator cval bug,"I'm doing binary classification on images with a simple CNN

When I use this code for my image data generator the model converges to about 90% accuracy after about 5 epochs:
```python
train_datagen=ImageDataGenerator(rescale=1.0/255, cval=0.0)
```

however with this code the model never converges:
```python
train_datagen=ImageDataGenerator(rescale=1.0/255, cval=0)
```



here is my full script for reference:
```python
import os
#os.environ['TF_CPP_MIN_LOG_LEVEL']='2'

import keras
from keras import metrics, optimizers
from keras.models import Model
from keras.layers import Activation, Input, Dense, Dropout, Flatten, Dense, Conv2D, MaxPooling2D
from keras.preprocessing import image
from keras.preprocessing.image import ImageDataGenerator
from keras.callbacks import TensorBoard, EarlyStopping, ModelCheckpoint
import numpy as np
import sklearn as skl

size_x, size_y = 1024, 1320
batch_size=6
num_epoch=25

input_img=Input(shape=(size_x, size_y, 3))

x=Conv2D(32, (3, 3), activation='relu')(input_img)
x=Conv2D(32, (3, 3), activation='relu')(x)
x=MaxPooling2D(pool_size=(2, 2))(x)

x=Conv2D(64, (3, 3), activation='relu')(x)
x=Conv2D(64, (3, 3), activation='relu')(x)
x=MaxPooling2D(pool_size=(2, 2))(x)

x=Conv2D(64, (3, 3), activation='relu')(x)
x=MaxPooling2D(pool_size=(2,2))(x)

x=Flatten()(x)
x=Dense(64, activation='relu')(x)
x=Dropout(0.5)(x)
x=Dense(1, activation='sigmoid')(x)

model=Model(inputs=input_img, outputs=x)

model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])

train_datagen=ImageDataGenerator(rescale=1.0/255, cval=0.0)

valid_datagen=ImageDataGenerator(rescale=1.0/255)

train_generator=train_datagen.flow_from_directory(
        'img/train',
        target_size=(size_x, size_y),
        batch_size=batch_size,
        class_mode='binary'
        )

valid_generator=valid_datagen.flow_from_directory(
        'img/valid'
        target_size=(size_x, size_y),
        batch_size=batch_size,
        class_mode='binary'
        )

weights=skl.utils.class_weight.compute_class_weight('balanced', np.unique(train_generator.classes), train_generator.classes)
class_weight = {0: weights[0], 1: weights[1]}

model.fit_generator(
        generator=train_generator,
        steps_per_epoch=train_generator.samples // train_generator.batch_size,
        epochs=num_epoch,
        validation_data=valid_generator,
        validation_steps=valid_generator.samples // valid_generator.batch_size,
        class_weight=class_weight
        )
```",bdwyer2,None,2017-09-19T18:29:02Z,2017-09-19T19:02:41Z
7903,Bug fix: Don't change original dict in from_config,,farizrahman4u,None,2017-09-15T18:39:46Z,2018-06-12T06:52:54Z
7892,"Train CNN on the ""green"" channel from RGB images","Hello everyone, I'm trying to train my model just on the G channel from my images and to compare the results with training on the entire RGB.

My images are located in 2 sub-directories so I'm using the ""flow_from_directory"" function to read them.

I've also defined a preprocessing function that should have done this ""Green extraction"" for me:
`def preprocess(x):
    return K.expand_dims(x[1,:,:],0)
`
and this is my model:

```
def get_model(input_shape=(3,256,256), classes = 2, lr=1e-4, channels=3):
model = Sequential([

        Lambda(preprocess, input_shape=input_shape, output_shape=(channels,)+ input_shape[1:]),

        BatchNormalization(axis=1),

        Convolution2D(32,3,3, activation='relu',border_mode='same'),

        BatchNormalization(axis=1), bla bla bla,...


        BatchNormalization(),

        Dense(1000, activation='relu'),

        BatchNormalization(),

        Dense(classes, activation='softmax')

        ])
    model.compile(Adam(lr=lr), loss='categorical_crossentropy', metrics=['accuracy'])
    return model

```
`def get_batches(dirname, gen=image.ImageDataGenerator(), shuffle=True, batch_size=8, class_mode='categorical',
                target_size=(256,256),color='rgb'):
    return gen.flow_from_directory(dirname, target_size=target_size,
            class_mode=class_mode, shuffle=shuffle, batch_size=batch_size, color_mode=color)
`

**this is my main code:**
```
path = '/home/ubuntu/images/'
test_batches = get_batches(path+'valid', target_size=(224,224))
model = get_model(input_shape=(3,224,224),channels=1)
model.fit_generator(test_batches, samples_per_epoch=test_batches.nb_sample, nb_epoch=1)

```
when I run it I get the following error:


ValueError: GpuDnnConv images and kernel must have the same stack size

Apply node that caused the error: GpuDnnConv{algo='small', inplace=True}(GpuContiguous.0, GpuContiguous.0, GpuAllocEmpty.0, GpuDnnConvDesc{border_mode='half', subsample=(1, 1), conv_mode='conv', precision='float32'}.0, Constant{1.0}, Constant{0.0})
Toposort index: 458
Inputs types: [CudaNdarrayType(float32, (True, False, False, False)), CudaNdarrayType(float32, 4D), CudaNdarrayType(float32, (True, False, False, False)), <theano.gof.type.CDataType object at 0x7f0b120ab090>, Scalar(float32), Scalar(float32)]
Inputs shapes: [(1, 3, 224, 224), (32, 1, 3, 3), (1, 32, 224, 224), 'No shapes', (), ()]
Inputs strides: [(0, 50176, 224, 1), (9, 0, 3, 1), (0, 50176, 224, 1), 'No strides', (), ()]
Inputs values: ['not shown', 'not shown', 'not shown', <capsule object NULL at 0x7f0afa9d46c0>, 1.0, 0.0]
Inputs name: ('image', 'kernel', 'output', 'descriptor', 'alpha', 'beta')

Outputs clients: [[GpuElemwise{add,no_inplace}(GpuDnnConv{algo='small', inplace=True}.0, GpuDimShuffle{x,0,x,x}.0)]]

HINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.
HINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.



How to fix it?
**Any help would be greatly appreciated.**
",Golbstein,None,2017-09-13T23:01:15Z,2019-11-10T18:34:53Z
7877,Fit_Generator and predict yielding different outputs,"I have 3 classes. Class 0 : 50% of data, 1:30% ,2:20%. Total examples are 800,400 train 200 val, 200 test. Each image belongs to only 1 class.

I am training a very simple convnet for multiple class classification
```
model = Sequential()
model.add(Conv2D(16, (3, 3), input_shape=input_shape))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Conv2D(32, (3, 3)))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Conv2D(64, (3, 3)))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))


model.add(Conv2D(128, (3, 3)))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Flatten())
model.add(Dense(64))
model.add(Activation('relu'))
model.add(Dropout(0.5))
model.add(Dense(32))
model.add(Activation('relu'))
model.add(Dropout(0.5))
model.add(Dense(3))
model.add(Activation('sigmoid'))

model.compile(loss='categorical_crossentropy',
              optimizer='rmsprop',
              metrics=['accuracy'])

```

I am using imagegenerator to augment images. Created dir structure correctly.

```
datagen = ImageDataGenerator(rotation_range= 0.360,
                                 horizontal_flip = True,
                                 vertical_flip = True,
                                 rescale=1. / 255) 

   
img_width, img_height = 350,350
batch_size = 16
generator = datagen.flow_from_directory(
    train_data_dir,
    target_size=(img_width, img_height),
    batch_size=batch_size)
val_generator = datagen.flow_from_directory(
    validation_data_dir,
    target_size=(img_width, img_height),
    batch_size=batch_size)
```

I get an accuracy of 65% training, 65% val at the end.

When i try to predict using my model, I get this output  on any data (test or train as well) for the imgs:

[[  1.00000000e+00   1.00000000e+00   2.31831675e-26]]
[[  1.00000000e+00   1.00000000e+00   4.62001088e-27]]
[[  1.00000000e+00   1.00000000e+00   1.61389520e-27]]
[[  1.00000000e+00   1.00000000e+00   2.85950715e-27]]
[[  1.00000000e+00   1.00000000e+00   4.34395772e-27]]
[[  1.00000000e+00   1.00000000e+00   6.68413629e-25]]
[[  1.00000000e+00   1.00000000e+00   5.57866408e-28]]
[[  1.00000000e+00   1.00000000e+00   2.55804569e-22]]
[[  1.00000000e+00   1.00000000e+00   9.38219268e-26]]
[[  1.00000000e+00   1.00000000e+00   2.81696856e-27]]
[[  1.00000000e+00   1.00000000e+00   3.03054745e-27]]
[[  1.00000000e+00   1.00000000e+00   5.63251077e-27]]
[[  1.00000000e+00   1.00000000e+00   2.44115877e-27]]
[[  1.00000000e+00   1.00000000e+00   3.06371315e-25]]
[[  1.00000000e+00   1.00000000e+00   4.67070906e-27]]
[[  1.00000000e+00   1.00000000e+00   9.45051359e-26]]
[[  1.00000000e+00   1.00000000e+00   1.16351225e-23]]
[[  1.00000000e+00   1.00000000e+00   1.19110686e-26]]

Essentially it predicts 1 for class 0 and class 1.

How is this happening? When i do evaluate generator, it gives me 65% accuracy. Is there a bug in using generators? This predict output is clearly wrong .",aditsanghvi94,b'stale',2017-09-12T15:00:45Z,2020-08-26T20:59:46Z
7864,Fixes a bug when num_words < MAX_NB_WORDS,"When a corpus has less than MAX_NB_WORDS it will default to len(word_index) . However, since the index is zero based it causes an IndexError. eg. When there are 57 total words in the corpus you get the error 'IndexError: index 57 is out of bounds for axis 0 with size 57' since the index should stop at 56 (zero based).",grzesir,None,2017-09-10T02:07:53Z,2017-09-10T02:09:20Z
7863,Fix HDF5Matrix.__getitem__ for validation_split,"There was a bug in the `__getitem__` method of `HDF5Matrix` class in keras/utils/io_utils.py (currently line 70) in which `stop` was set to `self.data.shape[0]`. This means that `stop` was be set to the total number of elements in the file rather than the artificial stopping point specified by `end`. This results in an IndexError when fitting a model with a validation_split. 

See https://github.com/fchollet/keras/issues/7862

The problem was solved by setting `stop` to `self.shape[0]` rather than `self.data.shape[0]`.

I could add a unit test for this, but it wasn't clear whether they should go in `test_model_methds` found in keras/tests/keras/engine/test_training.py or `test_io_utils` found in tests/keras/utils/io_utils_test.py.

Maybe it's worth merging the tests found in `test_io_utils` into test_training.py for maintence?",aeftimia,None,2017-09-09T22:05:58Z,2017-09-11T00:37:04Z
7855,fixed bug where horizontal flipping and vertical flipping was reversed.,,bdwyer2,None,2017-09-08T22:33:42Z,2017-11-20T21:21:02Z
7765,ZeroPadding2D,"I think there is a bug in the ZeroPadding2D layer:

```
from keras.models import Model
from keras.layers import Conv2D, MaxPool2D, Input, ZeroPadding2D

inputs = Input(shape=(224, 224, 3))
conv1 = Conv2D(filters=96, kernel_size=(7, 7), strides=2)(inputs)
conv1 = ZeroPadding2D(padding=1)(conv1)
pool1 = MaxPool2D((3, 3), strides=(2, 2))(conv1)
model = Model(inputs, pool1)

model.summary()
```

```
Layer (type)                 Output Shape              Param #   
=================================================================
input_10 (InputLayer)        (None, 224, 224, 3)       0         
_________________________________________________________________
conv2d_10 (Conv2D)           (None, 109, 109, 96)      14208     
_________________________________________________________________
zero_padding2d_4 (ZeroPaddin (None, 111, 111, 96)      0         
_________________________________________________________________
max_pooling2d_10 (MaxPooling (None, 55, 55, 96)        0         
=================================================================
Total params: 14,208
Trainable params: 14,208
Non-trainable params: 0
_________________________________________________________________
```

I think the output shape of zero_padding2d_4 should be  (None, 110, 110, 96).

By inspecting the source code :
https://github.com/fchollet/keras/blob/master/keras/layers/convolutional.py

in line 1536:

```
if isinstance(padding, int):
            self.padding = ((padding, padding), (padding, padding))
```
then in line 1570:

```
elif self.data_format == 'channels_last':
            if input_shape[1] is not None:
                rows = input_shape[1] + self.padding[0][0] + self.padding[0][1]
            else:
                rows = None
            if input_shape[2] is not None:
                cols = input_shape[2] + self.padding[1][0] + self.padding[1][1]
            else:
                cols = None
            return (input_shape[0],
                    rows,
                    cols,
                    input_shape[3])

```
which seems to add the dimension twice in the output shape.",MosMK,None,2017-08-29T13:34:27Z,2017-08-29T14:16:30Z
7756,VarianceScaling fails to handle Dimension() contained in Conv layer initializer shape,"I'm running a basic Inception module on MNIST data, and running into an incompatibility in the shape parameter that is built in order to pass to the initializer of a Conv2d layer.
I'm not sure if something in my usage is incorrect, or if this is genuinely a bug.

## TL;DR
```
initializers.py, line 204, in __call__
    scale /= max(1., float(fan_in + fan_out) / 2)
TypeError: float() argument must be a string or a number, not 'Dimension'
```

## Summary
1. My input is defined ```Tensor(""input_1:0"", shape=(?, 28, 28, 1), dtype=float32)```
2. ```Layer.__call__()``` uses the ```_keras_shape``` attribute of the tensor to form ```input_shapes = [(None, Dimension(28), Dimension(28), Dimension(1))]```, i.e. wrapping the integer dimensionalities with a ```Dimension``` :heavy_check_mark: 
3. Then ```_Conv.build()``` creates ```kernel_shape = (1, 1, Dimension(1), 64)``` :question:
4. Finally ```VarianceScaling.__call__()``` tries to use this shape in doing ```scale /= max(1., float(fan_in + fan_out) / 2)```, and fails :x: 

## Setup
Keras 2.0.8
Backend: Tensorflow 1.3.0

## Traceback
```
Using TensorFlow backend.
DEBUG:root:x_train[0].shape = (28, 28), y_train[0].shape = ()
Backend TkAgg is interactive backend. Turning interactive mode on.
Traceback (most recent call last):
  ...
  File ""...\testKerasFunctional.py"", line 70, in run
    inception = inception_module(input_img)
  File ""...\testKerasFunctional.py"", line 47, in inception_module
    return concatenate([tower_1(input_img), tower_2(input_img), tower_3(input_img)], axis=1)
  File ""...\testKerasFunctional.py"", line 30, in conv_tower
    first_layer = conv2d_of(1)(input_img)
  File ""...\keras\engine\topology.py"", line 575, in __call__
    self.build(input_shapes[0])
  File ""...\keras\layers\convolutional.py"", line 134, in build
    constraint=self.kernel_constraint)
  File ""...\keras\legacy\interfaces.py"", line 87, in wrapper
    return func(*args, **kwargs)
  File ""...\keras\engine\topology.py"", line 396, in add_weight
    weight = K.variable(initializer(shape),
  File ""...\keras\initializers.py"", line 204, in __call__
    scale /= max(1., float(fan_in + fan_out) / 2)
TypeError: float() argument must be a string or a number, not 'Dimension'
```

## Possibly related
#7687 ",InonS,None,2017-08-28T08:10:28Z,2017-09-03T18:35:40Z
7753,Add Inception-ResNet v2 to application,"Adds the Inception-ResNet v2 architecture to the application module, with weights extracted and converted from the [TF-slim implementation](https://github.com/tensorflow/models/tree/master/slim#pre-trained-models).

Brief summary:
- Add `keras.applications.inception_resnet_v2.InceptionResNetV2()`
- Update test for applications
- Update docs for applications

Possible issues:

1. Model weights: right now the .h5 weight files are in my own public repo.
Once the model is included into Keras, I think it's better to move the weight files here.
Is there any suggested way to do it?

2. Layer naming:
    Layer naming follows TF-slim because it's easier to debug when converting the weights.
    But it's not that critical once the code and weight files are included into Keras.
    Right now the solution is not so elegant, and makes the code look a bit cluttered.
    Is there a better way to do it, or should I remove the layer names?

3. The `dropout_keep_rate` argument:
    The original paper and TF-slim use keep rate, but Keras uses drop rate (`= 1 - dropout_keep_rate`) in the `Dropout` layer. Should I change the API to use drop rate?",yuyang-huang,None,2017-08-27T12:57:23Z,2017-10-08T13:41:31Z
7716,Remove requirement that batch_size divides len(x_train) in Variational Autoencoder examples.,"Copying almost verbatim from PR https://github.com/fchollet/keras/pull/7036 which addressed the issue without solving it.

Currently the Variational Autoencoder examples at `examples/variational_autoencoder.py` and `examples/variational_autoencoder_deconv.py` fail when the training set size is not a multiple of the batch size (related to #5255, and in a way to #3332).

This PR allows to use any batch size by computing the batch size in the `sampling` function at runtime.

Bug reproducibility steps:

- change the batch size (`examples/variational_autoencoder.py` at line 15 and `examples/variational_autoencoder_deconv.py` at line 24) to something that doesn't divide mnist train set size, for instance 51
- run `examples/variational_autoencoder.py` or `examples/variational_autoencoder_deconv.py`
",danielegrattarola,None,2017-08-22T15:32:12Z,2017-08-23T18:26:27Z
7714,"Fresh install, First run, Docs first example = fail","Installed per below output and followed the docs getting started first example here;
https://keras.io/getting-started/functional-api-guide/#first-example-a-densely-connected-network

```
~/keras$ git clone https://github.com/fchollet/keras/ && cd keras
~/keras$ sudo python setup.py install
running install
running bdist_egg
running egg_info
writing requirements to Keras.egg-info/requires.txt
writing Keras.egg-info/PKG-INFO
writing top-level names to Keras.egg-info/top_level.txt
writing dependency_links to Keras.egg-info/dependency_links.txt
reading manifest file 'Keras.egg-info/SOURCES.txt'
writing manifest file 'Keras.egg-info/SOURCES.txt'
installing library code to build/bdist.linux-x86_64/egg
running install_lib
running build_py
creating build/bdist.linux-x86_64/egg
creating build/bdist.linux-x86_64/egg/keras
copying build/lib.linux-x86_64-2.7/keras/activations.py -> build/bdist.linux-x86_64/egg/keras
copying build/lib.linux-x86_64-2.7/keras/metrics.py -> build/bdist.linux-x86_64/egg/keras
creating build/bdist.linux-x86_64/egg/keras/preprocessing
copying build/lib.linux-x86_64-2.7/keras/preprocessing/sequence.py -> build/bdist.linux-x86_64/egg/keras/preprocessing
copying build/lib.linux-x86_64-2.7/keras/preprocessing/__init__.py -> build/bdist.linux-x86_64/egg/keras/preprocessing
copying build/lib.linux-x86_64-2.7/keras/preprocessing/image.py -> build/bdist.linux-x86_64/egg/keras/preprocessing
copying build/lib.linux-x86_64-2.7/keras/preprocessing/text.py -> build/bdist.linux-x86_64/egg/keras/preprocessing
creating build/bdist.linux-x86_64/egg/keras/utils
copying build/lib.linux-x86_64-2.7/keras/utils/visualize_util.py -> build/bdist.linux-x86_64/egg/keras/utils
copying build/lib.linux-x86_64-2.7/keras/utils/layer_utils.py -> build/bdist.linux-x86_64/egg/keras/utils
copying build/lib.linux-x86_64-2.7/keras/utils/generic_utils.py -> build/bdist.linux-x86_64/egg/keras/utils
copying build/lib.linux-x86_64-2.7/keras/utils/io_utils.py -> build/bdist.linux-x86_64/egg/keras/utils
copying build/lib.linux-x86_64-2.7/keras/utils/np_utils.py -> build/bdist.linux-x86_64/egg/keras/utils
copying build/lib.linux-x86_64-2.7/keras/utils/__init__.py -> build/bdist.linux-x86_64/egg/keras/utils
copying build/lib.linux-x86_64-2.7/keras/utils/test_utils.py -> build/bdist.linux-x86_64/egg/keras/utils
copying build/lib.linux-x86_64-2.7/keras/utils/data_utils.py -> build/bdist.linux-x86_64/egg/keras/utils
copying build/lib.linux-x86_64-2.7/keras/constraints.py -> build/bdist.linux-x86_64/egg/keras
copying build/lib.linux-x86_64-2.7/keras/objectives.py -> build/bdist.linux-x86_64/egg/keras
copying build/lib.linux-x86_64-2.7/keras/__init__.py -> build/bdist.linux-x86_64/egg/keras
creating build/bdist.linux-x86_64/egg/keras/wrappers
copying build/lib.linux-x86_64-2.7/keras/wrappers/scikit_learn.py -> build/bdist.linux-x86_64/egg/keras/wrappers
copying build/lib.linux-x86_64-2.7/keras/wrappers/__init__.py -> build/bdist.linux-x86_64/egg/keras/wrappers
creating build/bdist.linux-x86_64/egg/keras/applications
copying build/lib.linux-x86_64-2.7/keras/applications/inception_v3.py -> build/bdist.linux-x86_64/egg/keras/applications
copying build/lib.linux-x86_64-2.7/keras/applications/xception.py -> build/bdist.linux-x86_64/egg/keras/applications
copying build/lib.linux-x86_64-2.7/keras/applications/imagenet_utils.py -> build/bdist.linux-x86_64/egg/keras/applications
copying build/lib.linux-x86_64-2.7/keras/applications/__init__.py -> build/bdist.linux-x86_64/egg/keras/applications
copying build/lib.linux-x86_64-2.7/keras/applications/music_tagger_crnn.py -> build/bdist.linux-x86_64/egg/keras/applications
copying build/lib.linux-x86_64-2.7/keras/applications/audio_conv_utils.py -> build/bdist.linux-x86_64/egg/keras/applications
copying build/lib.linux-x86_64-2.7/keras/applications/resnet50.py -> build/bdist.linux-x86_64/egg/keras/applications
copying build/lib.linux-x86_64-2.7/keras/applications/vgg16.py -> build/bdist.linux-x86_64/egg/keras/applications
copying build/lib.linux-x86_64-2.7/keras/applications/vgg19.py -> build/bdist.linux-x86_64/egg/keras/applications
creating build/bdist.linux-x86_64/egg/keras/backend
copying build/lib.linux-x86_64-2.7/keras/backend/__init__.py -> build/bdist.linux-x86_64/egg/keras/backend
copying build/lib.linux-x86_64-2.7/keras/backend/tensorflow_backend.py -> build/bdist.linux-x86_64/egg/keras/backend
copying build/lib.linux-x86_64-2.7/keras/backend/mxnet_backend.py -> build/bdist.linux-x86_64/egg/keras/backend
copying build/lib.linux-x86_64-2.7/keras/backend/theano_backend.py -> build/bdist.linux-x86_64/egg/keras/backend
copying build/lib.linux-x86_64-2.7/keras/backend/common.py -> build/bdist.linux-x86_64/egg/keras/backend
creating build/bdist.linux-x86_64/egg/keras/datasets
copying build/lib.linux-x86_64-2.7/keras/datasets/cifar10.py -> build/bdist.linux-x86_64/egg/keras/datasets
copying build/lib.linux-x86_64-2.7/keras/datasets/cifar100.py -> build/bdist.linux-x86_64/egg/keras/datasets
copying build/lib.linux-x86_64-2.7/keras/datasets/__init__.py -> build/bdist.linux-x86_64/egg/keras/datasets
copying build/lib.linux-x86_64-2.7/keras/datasets/reuters.py -> build/bdist.linux-x86_64/egg/keras/datasets
copying build/lib.linux-x86_64-2.7/keras/datasets/mnist.py -> build/bdist.linux-x86_64/egg/keras/datasets
copying build/lib.linux-x86_64-2.7/keras/datasets/cifar.py -> build/bdist.linux-x86_64/egg/keras/datasets
copying build/lib.linux-x86_64-2.7/keras/datasets/imdb.py -> build/bdist.linux-x86_64/egg/keras/datasets
copying build/lib.linux-x86_64-2.7/keras/callbacks.py -> build/bdist.linux-x86_64/egg/keras
copying build/lib.linux-x86_64-2.7/keras/optimizers.py -> build/bdist.linux-x86_64/egg/keras
creating build/bdist.linux-x86_64/egg/keras/layers
copying build/lib.linux-x86_64-2.7/keras/layers/local.py -> build/bdist.linux-x86_64/egg/keras/layers
copying build/lib.linux-x86_64-2.7/keras/layers/noise.py -> build/bdist.linux-x86_64/egg/keras/layers
copying build/lib.linux-x86_64-2.7/keras/layers/advanced_activations.py -> build/bdist.linux-x86_64/egg/keras/layers
copying build/lib.linux-x86_64-2.7/keras/layers/__init__.py -> build/bdist.linux-x86_64/egg/keras/layers
copying build/lib.linux-x86_64-2.7/keras/layers/wrappers.py -> build/bdist.linux-x86_64/egg/keras/layers
copying build/lib.linux-x86_64-2.7/keras/layers/embeddings.py -> build/bdist.linux-x86_64/egg/keras/layers
copying build/lib.linux-x86_64-2.7/keras/layers/convolutional_recurrent.py -> build/bdist.linux-x86_64/egg/keras/layers
copying build/lib.linux-x86_64-2.7/keras/layers/core.py -> build/bdist.linux-x86_64/egg/keras/layers
copying build/lib.linux-x86_64-2.7/keras/layers/normalization.py -> build/bdist.linux-x86_64/egg/keras/layers
copying build/lib.linux-x86_64-2.7/keras/layers/pooling.py -> build/bdist.linux-x86_64/egg/keras/layers
copying build/lib.linux-x86_64-2.7/keras/layers/convolutional.py -> build/bdist.linux-x86_64/egg/keras/layers
copying build/lib.linux-x86_64-2.7/keras/layers/recurrent.py -> build/bdist.linux-x86_64/egg/keras/layers
copying build/lib.linux-x86_64-2.7/keras/regularizers.py -> build/bdist.linux-x86_64/egg/keras
creating build/bdist.linux-x86_64/egg/keras/engine
copying build/lib.linux-x86_64-2.7/keras/engine/__init__.py -> build/bdist.linux-x86_64/egg/keras/engine
copying build/lib.linux-x86_64-2.7/keras/engine/topology.py -> build/bdist.linux-x86_64/egg/keras/engine
copying build/lib.linux-x86_64-2.7/keras/engine/training.py -> build/bdist.linux-x86_64/egg/keras/engine
copying build/lib.linux-x86_64-2.7/keras/initializations.py -> build/bdist.linux-x86_64/egg/keras
copying build/lib.linux-x86_64-2.7/keras/models.py -> build/bdist.linux-x86_64/egg/keras
byte-compiling build/bdist.linux-x86_64/egg/keras/activations.py to activations.pyc
byte-compiling build/bdist.linux-x86_64/egg/keras/metrics.py to metrics.pyc
byte-compiling build/bdist.linux-x86_64/egg/keras/preprocessing/sequence.py to sequence.pyc
byte-compiling build/bdist.linux-x86_64/egg/keras/preprocessing/__init__.py to __init__.pyc
byte-compiling build/bdist.linux-x86_64/egg/keras/preprocessing/image.py to image.pyc
byte-compiling build/bdist.linux-x86_64/egg/keras/preprocessing/text.py to text.pyc
byte-compiling build/bdist.linux-x86_64/egg/keras/utils/visualize_util.py to visualize_util.pyc
byte-compiling build/bdist.linux-x86_64/egg/keras/utils/layer_utils.py to layer_utils.pyc
byte-compiling build/bdist.linux-x86_64/egg/keras/utils/generic_utils.py to generic_utils.pyc
byte-compiling build/bdist.linux-x86_64/egg/keras/utils/io_utils.py to io_utils.pyc
byte-compiling build/bdist.linux-x86_64/egg/keras/utils/np_utils.py to np_utils.pyc
byte-compiling build/bdist.linux-x86_64/egg/keras/utils/__init__.py to __init__.pyc
byte-compiling build/bdist.linux-x86_64/egg/keras/utils/test_utils.py to test_utils.pyc
byte-compiling build/bdist.linux-x86_64/egg/keras/utils/data_utils.py to data_utils.pyc
byte-compiling build/bdist.linux-x86_64/egg/keras/constraints.py to constraints.pyc
byte-compiling build/bdist.linux-x86_64/egg/keras/objectives.py to objectives.pyc
byte-compiling build/bdist.linux-x86_64/egg/keras/__init__.py to __init__.pyc
byte-compiling build/bdist.linux-x86_64/egg/keras/wrappers/scikit_learn.py to scikit_learn.pyc
byte-compiling build/bdist.linux-x86_64/egg/keras/wrappers/__init__.py to __init__.pyc
byte-compiling build/bdist.linux-x86_64/egg/keras/applications/inception_v3.py to inception_v3.pyc
byte-compiling build/bdist.linux-x86_64/egg/keras/applications/xception.py to xception.pyc
byte-compiling build/bdist.linux-x86_64/egg/keras/applications/imagenet_utils.py to imagenet_utils.pyc
byte-compiling build/bdist.linux-x86_64/egg/keras/applications/__init__.py to __init__.pyc
byte-compiling build/bdist.linux-x86_64/egg/keras/applications/music_tagger_crnn.py to music_tagger_crnn.pyc
byte-compiling build/bdist.linux-x86_64/egg/keras/applications/audio_conv_utils.py to audio_conv_utils.pyc
byte-compiling build/bdist.linux-x86_64/egg/keras/applications/resnet50.py to resnet50.pyc
byte-compiling build/bdist.linux-x86_64/egg/keras/applications/vgg16.py to vgg16.pyc
byte-compiling build/bdist.linux-x86_64/egg/keras/applications/vgg19.py to vgg19.pyc
byte-compiling build/bdist.linux-x86_64/egg/keras/backend/__init__.py to __init__.pyc
byte-compiling build/bdist.linux-x86_64/egg/keras/backend/tensorflow_backend.py to tensorflow_backend.pyc
byte-compiling build/bdist.linux-x86_64/egg/keras/backend/mxnet_backend.py to mxnet_backend.pyc
byte-compiling build/bdist.linux-x86_64/egg/keras/backend/theano_backend.py to theano_backend.pyc
byte-compiling build/bdist.linux-x86_64/egg/keras/backend/common.py to common.pyc
byte-compiling build/bdist.linux-x86_64/egg/keras/datasets/cifar10.py to cifar10.pyc
byte-compiling build/bdist.linux-x86_64/egg/keras/datasets/cifar100.py to cifar100.pyc
byte-compiling build/bdist.linux-x86_64/egg/keras/datasets/__init__.py to __init__.pyc
byte-compiling build/bdist.linux-x86_64/egg/keras/datasets/reuters.py to reuters.pyc
byte-compiling build/bdist.linux-x86_64/egg/keras/datasets/mnist.py to mnist.pyc
byte-compiling build/bdist.linux-x86_64/egg/keras/datasets/cifar.py to cifar.pyc
byte-compiling build/bdist.linux-x86_64/egg/keras/datasets/imdb.py to imdb.pyc
byte-compiling build/bdist.linux-x86_64/egg/keras/callbacks.py to callbacks.pyc
byte-compiling build/bdist.linux-x86_64/egg/keras/optimizers.py to optimizers.pyc
byte-compiling build/bdist.linux-x86_64/egg/keras/layers/local.py to local.pyc
byte-compiling build/bdist.linux-x86_64/egg/keras/layers/noise.py to noise.pyc
byte-compiling build/bdist.linux-x86_64/egg/keras/layers/advanced_activations.py to advanced_activations.pyc
byte-compiling build/bdist.linux-x86_64/egg/keras/layers/__init__.py to __init__.pyc
byte-compiling build/bdist.linux-x86_64/egg/keras/layers/wrappers.py to wrappers.pyc
byte-compiling build/bdist.linux-x86_64/egg/keras/layers/embeddings.py to embeddings.pyc
byte-compiling build/bdist.linux-x86_64/egg/keras/layers/convolutional_recurrent.py to convolutional_recurrent.pyc
byte-compiling build/bdist.linux-x86_64/egg/keras/layers/core.py to core.pyc
byte-compiling build/bdist.linux-x86_64/egg/keras/layers/normalization.py to normalization.pyc
byte-compiling build/bdist.linux-x86_64/egg/keras/layers/pooling.py to pooling.pyc
byte-compiling build/bdist.linux-x86_64/egg/keras/layers/convolutional.py to convolutional.pyc
byte-compiling build/bdist.linux-x86_64/egg/keras/layers/recurrent.py to recurrent.pyc
byte-compiling build/bdist.linux-x86_64/egg/keras/regularizers.py to regularizers.pyc
byte-compiling build/bdist.linux-x86_64/egg/keras/engine/__init__.py to __init__.pyc
byte-compiling build/bdist.linux-x86_64/egg/keras/engine/topology.py to topology.pyc
byte-compiling build/bdist.linux-x86_64/egg/keras/engine/training.py to training.pyc
byte-compiling build/bdist.linux-x86_64/egg/keras/initializations.py to initializations.pyc
byte-compiling build/bdist.linux-x86_64/egg/keras/models.py to models.pyc
creating build/bdist.linux-x86_64/egg/EGG-INFO
copying Keras.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO
copying Keras.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO
copying Keras.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO
copying Keras.egg-info/requires.txt -> build/bdist.linux-x86_64/egg/EGG-INFO
copying Keras.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO
zip_safe flag not set; analyzing archive contents...
keras.backend.theano_backend: module MAY be using inspect.stack
creating 'dist/Keras-1.2.2-py2.7.egg' and adding 'build/bdist.linux-x86_64/egg' to it
removing 'build/bdist.linux-x86_64/egg' (and everything under it)
Processing Keras-1.2.2-py2.7.egg
removing '/usr/local/lib/python2.7/dist-packages/Keras-1.2.2-py2.7.egg' (and everything under it)
creating /usr/local/lib/python2.7/dist-packages/Keras-1.2.2-py2.7.egg
Extracting Keras-1.2.2-py2.7.egg to /usr/local/lib/python2.7/dist-packages
Keras 1.2.2 is already the active version in easy-install.pth

Installed /usr/local/lib/python2.7/dist-packages/Keras-1.2.2-py2.7.egg
Processing dependencies for Keras==1.2.2
Searching for scipy>=0.14
Best match: scipy 0.19.1
Adding scipy 0.19.1 to easy-install.pth file

Using /usr/local/lib/python2.7/dist-packages
Searching for numpy==1.13.1
Best match: numpy 1.13.1
Adding numpy 1.13.1 to easy-install.pth file

Using /usr/local/lib/python2.7/dist-packages
Finished processing dependencies for Keras==1.2.2
~/keras$ python
Python 2.7.13 (default, Jan 19 2017, 14:48:08) 
[GCC 6.3.0 20170118] on linux2
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import tensorflow as tf
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
ImportError: No module named tensorflow
>>> 
KeyboardInterrupt
~/keras$ sudo pip install tensorflow
Collecting tensorflow
  Downloading tensorflow-1.3.0-cp27-cp27mu-manylinux1_x86_64.whl (43.1MB)
    100% |████████████████████████████████| 43.1MB 17kB/s 
Collecting backports.weakref>=1.0rc1 (from tensorflow)
  Downloading backports.weakref-1.0rc1-py2-none-any.whl
Requirement already satisfied: wheel in /usr/lib/python2.7/dist-packages (from tensorflow)
Collecting protobuf>=3.3.0 (from tensorflow)
  Downloading protobuf-3.4.0-cp27-cp27mu-manylinux1_x86_64.whl (6.2MB)
    100% |████████████████████████████████| 6.2MB 119kB/s 
Collecting mock>=2.0.0 (from tensorflow)
  Downloading mock-2.0.0-py2.py3-none-any.whl (56kB)
    100% |████████████████████████████████| 61kB 2.3MB/s 
Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow)
Collecting tensorflow-tensorboard<0.2.0,>=0.1.0 (from tensorflow)
  Downloading tensorflow_tensorboard-0.1.4-py2-none-any.whl (2.2MB)
    100% |████████████████████████████████| 2.2MB 324kB/s 
Requirement already satisfied: six>=1.10.0 in /home/chris/.local/lib/python2.7/site-packages (from tensorflow)
Requirement already satisfied: setuptools in /usr/lib/python2.7/dist-packages (from protobuf>=3.3.0->tensorflow)
Collecting funcsigs>=1; python_version < ""3.3"" (from mock>=2.0.0->tensorflow)
  Downloading funcsigs-1.0.2-py2.py3-none-any.whl
Collecting pbr>=0.11 (from mock>=2.0.0->tensorflow)
  Downloading pbr-3.1.1-py2.py3-none-any.whl (99kB)
    100% |████████████████████████████████| 102kB 2.0MB/s 
Collecting markdown>=2.6.8 (from tensorflow-tensorboard<0.2.0,>=0.1.0->tensorflow)
Collecting bleach==1.5.0 (from tensorflow-tensorboard<0.2.0,>=0.1.0->tensorflow)
  Downloading bleach-1.5.0-py2.py3-none-any.whl
Collecting html5lib==0.9999999 (from tensorflow-tensorboard<0.2.0,>=0.1.0->tensorflow)
Collecting werkzeug>=0.11.10 (from tensorflow-tensorboard<0.2.0,>=0.1.0->tensorflow)
  Downloading Werkzeug-0.12.2-py2.py3-none-any.whl (312kB)
    100% |████████████████████████████████| 317kB 1.4MB/s 
Installing collected packages: backports.weakref, protobuf, funcsigs, pbr, mock, markdown, html5lib, bleach, werkzeug, tensorflow-tensorboard, tensorflow
  Found existing installation: html5lib 0.999999999
    Uninstalling html5lib-0.999999999:
      Successfully uninstalled html5lib-0.999999999
Successfully installed backports.weakref-1.0rc1 bleach-1.5.0 funcsigs-1.0.2 html5lib-0.9999999 markdown-2.6.9 mock-2.0.0 pbr-3.1.1 protobuf-3.4.0 tensorflow-1.3.0 tensorflow-tensorboard-0.1.4 werkzeug-0.12.2
~/keras$ python
Python 2.7.13 (default, Jan 19 2017, 14:48:08) 
[GCC 6.3.0 20170118] on linux2
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import tensorflow as tf
>>> node1 = tf.constant(0.1)
>>> node2 = tf.constant(0.2)
>>> sess = tf.Session()
>>> node3 = node1 + node2
>>> sess.run(node3)
0.30000001
>>> from keras.layers import Input, Dense
Using MXNet backend.
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""keras/__init__.py"", line 2, in <module>
    from . import backend
  File ""keras/backend/__init__.py"", line 70, in <module>
    from .mxnet_backend import *
  File ""keras/backend/mxnet_backend.py"", line 2, in <module>
    import mxnet as mx
ImportError: No module named mxnet
>>> 
KeyboardInterrupt
~/keras$ sudo pip install mxnet
Collecting mxnet
  Downloading mxnet-0.11.0-py2.py3-none-manylinux1_x86_64.whl (11.4MB)
    100% |████████████████████████████████| 11.4MB 64kB/s 
Collecting graphviz (from mxnet)
  Downloading graphviz-0.8-py2.py3-none-any.whl
Requirement already satisfied: numpy in /usr/local/lib/python2.7/dist-packages (from mxnet)
Installing collected packages: graphviz, mxnet
Successfully installed graphviz-0.8 mxnet-0.11.0
~/keras$ python
Python 2.7.13 (default, Jan 19 2017, 14:48:08) 
[GCC 6.3.0 20170118] on linux2
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> from keras.layers import Input, Dense
Using MXNet backend.
>>> from keras.models import Model
>>> inputs = Input(shape=(784,))
>>> x = Dense(64, activation='relu')(inputs)
>>> x = Dense(64, activation='relu')(x)
>>> predictions = Dense(10, activation='softmax')(x)
>>> model = Model(inputs=inputs, outputs=predictions)
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
TypeError: __init__() got an unexpected keyword argument 'outputs'

~/keras$ pip install git+git://github.com/fchollet/keras.git --upgrade --no-deps
Collecting git+git://github.com/fchollet/keras.git
  Cloning git://github.com/fchollet/keras.git to /tmp/pip-Gl6xOb-build
Installing collected packages: Keras
  Found existing installation: Keras 1.2.2
    Uninstalling Keras-1.2.2:
      Successfully uninstalled Keras-1.2.2
  Running setup.py install for Keras ... done
Successfully installed Keras-2.0.7
~/keras$ python
Python 2.7.13 (default, Jan 19 2017, 14:48:08) 
[GCC 6.3.0 20170118] on linux2
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> from keras.layers import Input, Dense
Using MXNet backend.
>>> from keras.models import Model
>>> inputs = Input(shape=(784,))
>>> x = Dense(64, activation='relu')(inputs)
>>> x = Dense(64, activation='relu')(x)
>>> predictions = Dense(10, activation='softmax')(x)
>>> model = Model(inputs=inputs, outputs=predictions)
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
TypeError: __init__() got an unexpected keyword argument 'outputs'
```
As you can see I did the following;

- cloned keras, ran setup
- tried to test tensorflow, errored
- installed tensorflow
- tested tensorflow, works
- tried to follow the keras example from the docs, saw a dependency `mxnet` was missing
- installed mxnet
- tried the same keras example, saw error about `outputs` arg missing
- made sure i was running latest keras, followed the provided command (listed here when i opened the issue) to update keras.
- tried again the same example after the update, still fails

As you can see, this is VERY far from usable. Either the docs are out of date or there is just simply a bug in the latest stable keras.. i honestly have no idea where to go from here.
",chrisdlangton,None,2017-08-22T13:22:59Z,2017-08-22T14:27:57Z
7691,Recurrent layer to treat 2nd and the rest of inputs as initial_states,"Hi. I'm submitting a PR for a bug reported in #7612. 

I think the Recurrent layer should treat a part of the inputs as `initial_states`. I think this is also what you want to do according to the API doc. If you have a different design, please suggest.",wanasit,None,2017-08-20T03:46:40Z,2017-08-25T02:57:27Z
7682,load_model: ValueError('Missing layer: ' + inbound_layer_name),"I accidentally managed to create a model that can be saved but not loaded.

Here is a minimal example to reproduce the problem:

```python
from keras.models import Model, load_model
from keras.layers import Input, Dense, concatenate

input_shape = (16, 9, 3)
input_layer = Input(shape=input_shape)

dense_A = Dense(3, name='dense_A')
dense_B = Dense(3, name='dense_B')
dense_C = Dense(3, name='dense_C')

x1 = dense_B(dense_A(input_layer))
x2 = dense_A(dense_C(input_layer))
x = concatenate([x1, x2])

model = Model(inputs=input_layer, outputs=x)

model.save('model.h5')
model = load_model('model.h5')
```

Output:

```
Traceback (most recent call last):
  File ""test.py"", line 21, in <module>
    model = load_model('model.h5')
  File ""/usr/local/lib/python3.5/dist-packages/keras/models.py"", line 233, in load_model
    model = model_from_config(model_config, custom_objects=custom_objects)
  File ""/usr/local/lib/python3.5/dist-packages/keras/models.py"", line 307, in model_from_config
    return layer_module.deserialize(config, custom_objects=custom_objects)
  File ""/usr/local/lib/python3.5/dist-packages/keras/layers/__init__.py"", line 54, in deserialize
    printable_module_name='layer')
  File ""/usr/local/lib/python3.5/dist-packages/keras/utils/generic_utils.py"", line 139, in deserialize_keras_object
    list(custom_objects.items())))
  File ""/usr/local/lib/python3.5/dist-packages/keras/engine/topology.py"", line 2450, in from_config
    process_layer(layer_data)
  File ""/usr/local/lib/python3.5/dist-packages/keras/engine/topology.py"", line 2437, in process_layer
    raise ValueError('Missing layer: ' + inbound_layer_name)
ValueError: Missing layer: dense_C
```

The model itself does not make a lot of sence of course, but as far as I understand, everything that can be serialized should also be deserializable. Is this a bug?

Keras version: 2.0.6
Python version: 3.5.2
Tensorflow version: 1.2.1",Dobiasd,None,2017-08-18T13:38:03Z,2017-08-20T18:44:09Z
7612,Recurrent layer's initial_state doesn't work with Saving/Loading model,"I have found an error when saving/loading `Recurrent` layers with `initial_state`

This is the code to reproduce the bug:
```python
from keras.layers import Input, Embedding, LSTM, TimeDistributed, Dense
from keras.models import Model, load_model

VEC_SIZE = 10
INPUT_LENTGH = 20

input_initial_state = Input(shape=(VEC_SIZE,))
input_x = Input(shape=(INPUT_LENTGH,VEC_SIZE))

# Create an RNN with initial_state
lstm = LSTM(VEC_SIZE, return_sequences=True)(input_x, initial_state=[input_initial_state, input_initial_state])
model = Model(inputs=[input_x, input_initial_state], outputs=[lstm])

# Save/Load the model
model.save('test.h5')
loaded_model = load_model('test.h5') 
```

Loading model back in the last line will throw following error.
```
Layer lstm_8 expects 1 inputs, but it received 3 input tensors. Input received: [<tf.Tensor 'input_16_1:0' shape=(?, 20, 10) dtype=float32>, <tf.Tensor 'input_15_1:0' shape=(?, 10) dtype=float32>, <tf.Tensor 'input_15_1:0' shape=(?, 10) dtype=float32>]
```

I have tracked the cause into `__call__` in `Recurrent` class. When initial_state is assignd the model treat will eventually treat it as an input and add them into graph. 
See. [recurrent.py line 283](https://github.com/fchollet/keras/blob/d687c6eda4d9cb58756822fd77402274db309da8/keras/layers/recurrent.py#L283)

So, when saving, the model will see **Recurrent layer with initial_state as having 3 inputs**. And then, when loading, the model will be initialized with 3 inputs (but no initial_state), the function will throw an error at [line 259](https://github.com/fchollet/keras/blob/d687c6eda4d9cb58756822fd77402274db309da8/keras/layers/recurrent.py#L259). 

One way to fix this is having Recurrent layer check and treat additional inputs as initial_state. Adding this code before line 259 fixed the problem for me.

```
if isinstance(inputs, (list, tuple)) and len(inputs) > 1 and initial_state is None:
    initial_state = inputs[1:]
    inputs = inputs[0]
```

   


",wanasit,b'stale',2017-08-12T04:29:06Z,2017-12-11T18:08:57Z
7593,cntk backend: fix the reversed rnn bug,"This pull request is to fix a bug in CNTK backend, current implementation for rnn with go_backwards = True is incorrect.",souptc,None,2017-08-10T17:56:20Z,2017-08-11T17:21:25Z
7579,Print the function output to debug,"Hi,

I am working with Keras on Tensorflow and would like to print the output of the function written in Keras before I put it into model in order to check if I wrote it correctly. Is there any way to do this?

Thanks in advance,
Rafał",PrinceJulian,b'stale',2017-08-09T14:23:07Z,2017-12-07T15:00:32Z
7541,epoch value in ModelCheckpoint is inconsistent,"Hi:
Keras offer a easy way to add epoch to the model name when saving 
https://github.com/fchollet/keras/blob/master/keras/callbacks.py#L400
`filepath = self.filepath.format(epoch=epoch, **logs)`

But with the code like below one, which is suppose to save model every 20 eopch:
```
checkpointer = ModelCheckpoint(filepath=""{epoch:03d}""+"".hdf5"", period=20)
```
It save the model every 20 epochs like:
019.hdf5
039.hdf5

The model saving operation does happen after 20, 40 epoch were finished.
Is there a bug, or I missed something(?

thanks for your review",SKb10,b'stale',2017-08-06T21:09:19Z,2017-12-09T02:07:15Z
7531,How does repetition of layer name get treated in Keras?,"This is a little basic question, but I couldn't find anything under the documentation, nor in the examples.
My question is how does following statement get interpreted in Keras?
`for numnodes in [10,20,30]:`
`    MyLayer1=Dense(numnodes)(MyLayer1)`

Is there a way I can freeze this layer from the Model level? I notice that I can run `model.get_layer('freezeThis').trainable=False` if I have 
`MyLayer1=Dense(10,name=""freezeThis"")(prev_layers)`
`for numnodes in [10,20,30]:`
`   MyLayer1=Dense(numnodes)(MyLayer1)`

I get error `keras all layer names should be unique` if I do 
`MyLayer1=Dense(10)(prev_layers)`
`for numnodes in [10,20,30]:`
`   MyLayer1=Dense(numnodes,name=""freezeThis"")(MyLayer1)`

Reason why I wondered about this question. Kindly reply! 

(Note: This is a reduced/simplified query. In the actual script, I have GRU, autoencoder, CNN and what not! Possible that I might have misunderstood something else. Is this a safe way to freeze the layers?)

UPDATE: Currently failing for the other alternative too. It cannot find the layer, debugging it, kindly ignore question for now..",vedhas,b'stale',2017-08-05T12:51:56Z,2017-12-09T16:37:15Z
7512,bug in sparse_categorical_crossentropy in theano backend,"theano `sparse_categorical_crossentropy` calls `categorical_crossentropy` on line 
https://github.com/fchollet/keras/blob/master/keras/backend/theano_backend.py#L1539
but the call is using the wrong order of parameters. should be 
```
    return categorical_crossentropy(target, output, from_logits)
```
",udibr,b'stale',2017-08-03T16:06:06Z,2017-12-01T17:07:41Z
7501,TensorBoard callback for grid search,"I'm using the Keras TensorBoard callback.
I would like to run a grid search and visualize the results of each single model in the tensor board.
The problem is that all results of the different runs are merged together and the loss plot is a mess like this:
![image](https://user-images.githubusercontent.com/11927903/28881325-0d95a48c-77a8-11e7-9688-20ebea6b06b0.png)


How can I rename each run to have something similar to this:
![image](https://user-images.githubusercontent.com/11927903/28881334-172533fa-77a8-11e7-895c-3f6488932d5c.png)

Here the code of the grid search:

   ```
 df = pd.read_csv('data/prepared_example.csv')
    
    df = time_series.create_index(df, datetime_index='DATE', other_index_list=['ITEM', 'AREA'])
    
    target = ['D']
    attributes = ['S', 'C', 'D-10','D-9', 'D-8', 'D-7', 'D-6', 'D-5', 'D-4',
           'D-3', 'D-2', 'D-1']
    
    input_dim = len(attributes)
    output_dim = len(target)
    
    x = df[attributes]
    y = df[target]
    
    param_grid = {'epochs': [10, 20, 50],
                  'batch_size': [10],
                  'neurons': [[10, 10, 10]],
                  'dropout': [[0.0, 0.0], [0.2, 0.2]],
                  'lr': [0.1]}
    
    estimator = KerasRegressor(build_fn=create_3_layers_model,
                               input_dim=input_dim, output_dim=output_dim)
    
    
    tbCallBack = TensorBoard(log_dir='./Graph', histogram_freq=0, write_graph=True, write_images=False)
    
    grid = GridSearchCV(estimator=estimator, param_grid=param_grid, n_jobs=-1, scoring=bug_fix_score,
                                cv=3, verbose=0, fit_params={'callbacks': [tbCallBack]})
    
    grid_result = grid.fit(x.as_matrix(), y.as_matrix())
```
",paolof89,b'stale',2017-08-02T15:31:16Z,2017-11-30T16:42:27Z
7494,LSTM Layer throws an exception when it is trained in distributed mode using Tensorflow,"I'm trying to train a LSTM model using Tensorflow in distributed mode. 

The model definition is quite simple right now:
```
model = Sequential()
model.add(Embedding(N, embedding_vector_length, input_length=max_sequence_length))
model.add(LSTM(512))
model.add(Dense(1024))
model.add(Dense(label.size, activation='softmax'))
optimizer = RMSprop(lr=0.001)
model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])
```

When I run the above model using Tensorflow, I got the following error:
```
InvalidArgumentError: Cannot assign a device for operation 'lstm/bias': Operation was explicitly assigned to /job:ps/task:0 but available devices are [ /job:localhost/replica:0/task:0/cpu:0 ]. Make sure the device specification refers to a valid device.
	 [[Node: lstm/bias = VariableV2[_class=[""loc:@lstm/bias""], container="""", dtype=DT_FLOAT, shape=[2048], shared_name="""", _device=""/job:ps/task:0""]()]]
```

But if I replace the model definition to:
```
model = Sequential()
model.add(Dense(100, input_shape(max_sequence_length,)))
model.add(Dense(1024))
model.add(Dense(label.size, activation='softmax'))
optimizer = RMSprop(lr=0.001)
model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])
```
It works fine. That is without the LSTM layer (and the embedding layer), the error goes away.

Is it a bug in the LSTM layer or there is something I miss to configure?
Thank you!",jerrypaytm,b'stale',2017-08-01T21:21:03Z,2018-04-11T15:09:41Z
7486,Fix doc example of models.py's method fit_generator(),This fix a minor bug in docstring. The file pointer closed in the iteration.,NeilRon,None,2017-08-01T07:18:56Z,2017-08-01T21:29:48Z
7440,"""bad marshal data"" when loading model that was saved with python 2.7 into python 3.4.","Please make sure that the boxes below are checked before you submit your issue. If your issue is an implementation question, please ask your question on [StackOverflow](http://stackoverflow.com/questions/tagged/keras) or [join the Keras Slack channel](https://keras-slack-autojoin.herokuapp.com/) and ask there instead of filing a GitHub issue.

Thank you!

- [x] Check that you are up-to-date with the master branch of Keras. You can update with:
pip install git+git://github.com/fchollet/keras.git --upgrade --no-deps

- [x] If running on TensorFlow, check that you are up-to-date with the latest version. The installation instructions can be found [here](https://www.tensorflow.org/get_started/os_setup).

- [ ] If running on Theano, check that you are up-to-date with the master branch of Theano. You can update with:
pip install git+git://github.com/Theano/Theano.git --upgrade --no-deps

- [x] Provide a link to a GitHub Gist of a Python script that can reproduce your issue (or just copy the script here if it is short).

I trained a model using python 2.7, and now I need to load it using python 3.4. The model includes a simple `Lambda` layer. The simplified script below reproduces the error:

```
from keras.models import Model, load_model
from keras.layers import Input, Lambda
import sys

if sys.version_info < (3,4):
    inp = Input(shape=(28,28,1))
    x = Lambda(lambda x: x + 1)(inp)
    model = Model(inp, x)
    model.save('lambdamodel.hdf5')
else:
    model = load_model('lambdamodel.hdf5') # Error here.
    model.summary()
```

The model gets created and saved fine in a python2.7 virtualenv:

```
(py2keras) kzh@otter:tmp$ python --version
Python 2.7.12
(py2keras) kzh@otter:tmp$ pip list
DEPRECATION: The default format will switch to columns in the future. You can use --format=(legacy|columns) (or define a format=(legacy|columns) in your pip.conf under the [list] section) to disable this warning.
backports.weakref (1.0rc1)
bleach (1.5.0)
funcsigs (1.0.2)
h5py (2.7.0)
html5lib (0.9999999)
Keras (2.0.6)
Markdown (2.6.8)
mock (2.0.0)
numpy (1.13.1)
pbr (3.1.1)
pip (9.0.1)
protobuf (3.3.0)
PyYAML (3.12)
scipy (0.19.1)
setuptools (36.2.3)
six (1.10.0)
tensorflow (1.2.1)
Theano (0.9.0)
Werkzeug (0.12.2)
wheel (0.29.0)
(py2keras) kzh@otter:tmp$ python lambdabug.py 
Using TensorFlow backend.
Done
```

The error comes up when loading in a python3 virtualenv:

```
(py3keras) kzh@otter:tmp$ python --version
Python 3.5.2
(py3keras) kzh@otter:tmp$ pip list
backports.weakref (1.0rc1)
bleach (1.5.0)
h5py (2.7.0)
html5lib (0.9999999)
Keras (2.0.6)
Markdown (2.6.8)
numpy (1.13.1)
pip (9.0.1)
protobuf (3.3.0)
PyYAML (3.12)
scipy (0.19.1)
setuptools (36.2.3)
six (1.10.0)
tensorflow (1.2.1)
Theano (0.9.0)
Werkzeug (0.12.2)
wheel (0.29.0)
(py3keras) kzh@otter:tmp$ python lambdabug.py 
Using TensorFlow backend.
Traceback (most recent call last):
  File ""lambdabug.py"", line 11, in <module>
    model = load_model('lambdamodel.hdf5')
  File ""/home/kzh/.envs/py3keras/lib/python3.5/site-packages/keras/models.py"", line 233, in load_model
    model = model_from_config(model_config, custom_objects=custom_objects)
  File ""/home/kzh/.envs/py3keras/lib/python3.5/site-packages/keras/models.py"", line 307, in model_from_config
    return layer_module.deserialize(config, custom_objects=custom_objects)
  File ""/home/kzh/.envs/py3keras/lib/python3.5/site-packages/keras/layers/__init__.py"", line 54, in deserialize
    printable_module_name='layer')
  File ""/home/kzh/.envs/py3keras/lib/python3.5/site-packages/keras/utils/generic_utils.py"", line 139, in deserialize_keras_object
    list(custom_objects.items())))
  File ""/home/kzh/.envs/py3keras/lib/python3.5/site-packages/keras/engine/topology.py"", line 2476, in from_config
    process_layer(layer_data)
  File ""/home/kzh/.envs/py3keras/lib/python3.5/site-packages/keras/engine/topology.py"", line 2462, in process_layer
    custom_objects=custom_objects)
  File ""/home/kzh/.envs/py3keras/lib/python3.5/site-packages/keras/layers/__init__.py"", line 54, in deserialize
    printable_module_name='layer')
  File ""/home/kzh/.envs/py3keras/lib/python3.5/site-packages/keras/utils/generic_utils.py"", line 139, in deserialize_keras_object
    list(custom_objects.items())))
  File ""/home/kzh/.envs/py3keras/lib/python3.5/site-packages/keras/layers/core.py"", line 697, in from_config
    function = func_load(config['function'], globs=globs)
  File ""/home/kzh/.envs/py3keras/lib/python3.5/site-packages/keras/utils/generic_utils.py"", line 200, in func_load
    code = marshal.loads(code.encode('raw_unicode_escape'))
ValueError: bad marshal data (unknown type code)
```

I've never used marshal directly myself and don't have time to dig much further into this. In the meantime I'll keep using python2.7 for the code I was planning to move to 3.4. Any tips or fixes are appreciated.
",alexklibisz,None,2017-07-26T17:36:56Z,2019-04-17T07:39:57Z
7433,Concatenation Issue with custom layer,"Hi,

I have created a custom layer and using it in my model on top of LSTM. But when I am trying to concatenate the output of two such custom layers, I am getting following error:

Epoch 1/1
 ** On entry to SGEMM  parameter number 10 had an illegal value
Traceback (most recent call last):
  File ""relation-classifier-model.py"", line 399, in <module>
    run_lstm_model(train_data, dev_data, best_model_file_name, out_file_name)
  File ""relation-classifier-model.py"", line 306, in run_lstm_model
    steps_per_epoch=train_steps, epochs=1, verbose=2)
  File ""/home/nayak/.local/lib/python2.7/site-packages/keras/legacy/interfaces.py"", line 87, in wrapper
    return func(*args, **kwargs)
  File ""/home/nayak/.local/lib/python2.7/site-packages/keras/engine/training.py"", line 1845, in fit_generator
    class_weight=class_weight)
  File ""/home/nayak/.local/lib/python2.7/site-packages/keras/engine/training.py"", line 1565, in train_on_batch
    outputs = self.train_function(ins)
  File ""/home/nayak/.local/lib/python2.7/site-packages/keras/backend/theano_backend.py"", line 1197, in __call__
    return self.function(*inputs)
  File ""/home/nayak/.local/lib/python2.7/site-packages/theano/compile/function_module.py"", line 897, in __call__
    storage_map=getattr(self.fn, 'storage_map', None))
  File ""/home/nayak/.local/lib/python2.7/site-packages/theano/gof/link.py"", line 325, in raise_with_op
    reraise(exc_type, exc_value, exc_trace)
  File ""/home/nayak/.local/lib/python2.7/site-packages/theano/compile/function_module.py"", line 883, in __call__
    self.fn() if output_subset is None else\
RuntimeError: cublasSgemmBatched: (cublas) Invalid value.
Apply node that caused the error: GpuGemmBatch{inplace=True}(GpuAllocEmpty{dtype='float32', context_name=None}.0, TensorConstant{1.0}, InplaceGpuDimShuffle{0,1,x}.0, InplaceGpuDimShuffle{0,x,1}.0, TensorConstant{0.0})
Toposort index: 552
Inputs types: [GpuArrayType<None>(float32, 3D), TensorType(float32, scalar), GpuArrayType<None>(float32, (False, False, True)), GpuArrayType<None>(float32, (False, True, False)), TensorType(float32, scalar)]
Inputs shapes: [(16, 300, 13), (), (16, 300, 1), (16, 1, 13), ()]
Inputs strides: [(15600, 52, 4), (), (2400, 4, 4), (52, 52, 4), ()]
Inputs values: ['not shown', array(1.0, dtype=float32), 'not shown', 'not shown', array(0.0, dtype=float32)]
Outputs clients: [[GpuReshape{3}(GpuGemmBatch{inplace=True}.0, MakeVector{dtype='int64'}.0)]]

HINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.
HINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.

I ran the code in CPU and it worked well for 'concatenation'.

But when I try to Add them it works.

Custom Layer
-----------------------------

class WeightedGlobalAverage(Layer):
    def __init__(self, output_dim, **kwargs):
        self.output_dim = output_dim
        super(WeightedGlobalAverage, self).__init__(**kwargs)

    def build(self, input_shape):
        # Create a trainable weight variable for this layer.
        self.kernel = self.add_weight(name='kernel',
                                      shape=(self.output_dim, 1),
                                      initializer='uniform',
                                      trainable=True)
        super(WeightedGlobalAverage, self).build(input_shape)

    def call(self, x):
        reduce_last_dim = Lambda(lambda x: x[:, :, 0], output_shape=lambda shape: (shape[0], shape[1]))
        y = reduce_last_dim(K.dot(x, self.kernel))
        weights = K.softmax(y)
        return K.batch_dot(x, weights, axes=[1, 1])

    def compute_output_shape(self, input_shape):
        return input_shape[0], self.output_dim

    def get_config(self):
        config = {'output_dim': self.output_dim}
        base_config = super(WeightedGlobalAverage, self).get_config()
        return dict(list(base_config.items()) + list(config.items()))


Model Code
-----------------------
arg1_input = Input(shape=(None, vec_dim), dtype='float32', name='arg1_ctx_input')
    arg2_input = Input(shape=(None, vec_dim), dtype='float32', name='arg2_ctx_input')
    arg1_output = LSTM(sent_vec_dim, return_sequences=True)(arg1_input)
    arg2_output = LSTM(sent_vec_dim, return_sequences=True)(arg2_input)
    arg1_output = WeightedGlobalAverage(sent_vec_dim)(arg1_output)
    arg2_output = WeightedGlobalAverage(sent_vec_dim)(arg2_output)
   # Following line is raising the error
    merge_output = Concatenate(axis=-1)([arg1_output, arg2_output])
    labels = Dense(units=len(relation_cls_label_map), activation='softmax', name='labels')(merge_output)

    lstm_model = Model(inputs=[arg1_input, arg2_input], outputs=[labels])

Note: If I change the 'theano' flag 'optimizer=None', then it is running.
Entire code is available here: https://github.com/nayakt/IE",nayakt,b'stale',2017-07-26T10:44:42Z,2017-11-25T07:53:49Z
7396,Possible duplication (bug) in ImageDataGenerator outputs?,"Please make sure that the boxes below are checked before you submit your issue. If your issue is an implementation question, please ask your question on [StackOverflow](http://stackoverflow.com/questions/tagged/keras) or [join the Keras Slack channel](https://keras-slack-autojoin.herokuapp.com/) and ask there instead of filing a GitHub issue.

Thank you!

- [ x] Check that you are up-to-date with the master branch of Keras. You can update with:
pip install git+git://github.com/fchollet/keras.git --upgrade --no-deps

- [x ] If running on TensorFlow, check that you are up-to-date with the latest version. The installation instructions can be found [here](https://www.tensorflow.org/get_started/os_setup).

- [ ] If running on Theano, check that you are up-to-date with the master branch of Theano. You can update with:
pip install git+git://github.com/Theano/Theano.git --upgrade --no-deps

- [ ] Provide a link to a GitHub Gist of a Python script that can reproduce your issue (or just copy the script here if it is short)

Below is my simple code to use ImageDataGenerator to do some data augmentation. Let's say I have 1000 input cat images, I want to use ImageDataGenerator to augment each image 20 times, so totally I should get 1000*20 = 20,000 augmented images. However, the following code only produces < 10,000 files. The output files have a 'cat_0_xxxx.jpeg' pattern in filenames where xxxx goes from  0 to 9999, does that mean ImageDataGenerator won't go beyond 10,000 files? I would expect it will save 'cat_1_xxxx.jpeg"" after saving cat_0_9999.jpeg but that did not happen. Is this a bug?

BTW, I installed Keras using pip: pip install keras, the installed version is keras-2.0.6.tar.gz.

from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img
import glob
import os, sys

datagen = ImageDataGenerator(
            rotation_range=40,
            width_shift_range=0.2,
            height_shift_range=0.2,
            shear_range=0.2,
            zoom_range=0.2,
            horizontal_flip=True,
            fill_mode='nearest')
            
path = 'test20170721/train/cats'
outPath = 'test20170721/augmentation/cats'
files = glob.glob(path + '/*.jpg')

for file in files:
  print file
  img = load_img(file)
  x = img_to_array(img)
  x = x.reshape((1,) + x.shape)
  
  i = 0
  for batch in datagen.flow(x, save_to_dir=outPath, save_prefix='cat', save_format='jpeg'):
    i += 1
    if i > 20:
      break",yliu7366,b'stale',2017-07-21T14:50:49Z,2018-04-19T20:46:55Z
7386,"In UpSampling2D, TypeError: ""unsupported operand type(s) for *: 'NoneType' and 'int'""","I am using UpSampling2D with Input height and width ""None"", since input image is variable size.
I am getting following error : 

> TypeError: ""unsupported operand type(s) for *: 'NoneType' and 'int'""

Below is snippet code, with keras 2.0 and 'channel_last'

```
    conv4 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv4)        
    conv4 = BatchNormalization(axis=-1, momentum=0.99, epsilon=1e-6, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones')(conv4)
    up1 = UpSampling2D(size=(2, 2))(conv4)
```
when I debug, found out its coming from call() of UpSampling2D class
```
1125     def call(self, inputs):                                                     
1126         return K.resize_images(inputs, self.size[0], self.size[1],              
1127                                self.data_format)
```",adigasu,None,2017-07-20T18:12:28Z,2017-07-20T18:55:09Z
7375,"LSTM text generation, increasing loss function","I was running the Nietzsche's LSTM text generator [script](https://github.com/fchollet/keras/blob/master/examples/lstm_text_generation.py) with slight modifications, and I the loss function showed strange behaviour after 70 iterations (it increased significantly), Is there a reason for this behaviour? or is it a bug?

[Here](https://gist.github.com/mostafa-mahmoud/b7058bb8e5b2079ad1cb45d0873de67d) is the code I used, and here is the loss output: (UPDATE: results of more iterations)

iteration 1 200285/200285 [==============================] - 433s - loss: 2.0411     
iteration 2 200285/200285 [==============================] - 433s - loss: 1.6363     
iteration 3 200285/200285 [==============================] - 441s - loss: 1.5480     
iteration 4 200285/200285 [==============================] - 457s - loss: 1.5036     
iteration 5 200285/200285 [==============================] - 437s - loss: 1.4742     
iteration 6 200285/200285 [==============================] - 484s - loss: 1.4563     
iteration 7 200285/200285 [==============================] - 459s - loss: 1.4406     
iteration 8 200285/200285 [==============================] - 418s - loss: 1.4286     
iteration 9 200285/200285 [==============================] - 412s - loss: 1.4175     
iteration 10 200285/200285 [==============================] - 406s - loss: 1.4061     
iteration 11 200285/200285 [==============================] - 440s - loss: 1.3981     
iteration 12 200285/200285 [==============================] - 454s - loss: 1.3910     
iteration 13 200285/200285 [==============================] - 437s - loss: 1.3848     
iteration 14 200285/200285 [==============================] - 430s - loss: 1.3789    
iteration 15 200285/200285 [==============================] - 482s - loss: 1.3745     
iteration 16 200285/200285 [==============================] - 472s - loss: 1.3688     
iteration 17 200285/200285 [==============================] - 471s - loss: 1.3643     
iteration 18 200285/200285 [==============================] - 453s - loss: 1.3595     
iteration 19 200285/200285 [==============================] - 423s - loss: 1.3565     
iteration 20 200285/200285 [==============================] - 344s - loss: 1.3532     
iteration 21 200285/200285 [==============================] - 343s - loss: 1.3495     
iteration 22 200285/200285 [==============================] - 338s - loss: 1.3473     
iteration 23 200285/200285 [==============================] - 338s - loss: 1.3442     
iteration 24 200285/200285 [==============================] - 337s - loss: 1.3410     
iteration 25 200285/200285 [==============================] - 335s - loss: 1.3396     
iteration 26 200285/200285 [==============================] - 333s - loss: 1.3379     
iteration 27 200285/200285 [==============================] - 336s - loss: 1.3346     
iteration 28 200285/200285 [==============================] - 336s - loss: 1.3338     
iteration 29 200285/200285 [==============================] - 333s - loss: 1.3307     
iteration 30 200285/200285 [==============================] - 333s - loss: 1.3300     
iteration 31 200285/200285 [==============================] - 333s - loss: 1.3293     
iteration 32 200285/200285 [==============================] - 333s - loss: 1.3279     
iteration 33 200285/200285 [==============================] - 340s - loss: 1.3273     
iteration 34 200285/200285 [==============================] - 334s - loss: 1.3273     
iteration 35 200285/200285 [==============================] - 380s - loss: 1.3270     
iteration 36 200285/200285 [==============================] - 419s - loss: 1.3246     
iteration 37 200285/200285 [==============================] - 396s - loss: 1.3248     
iteration 38 200285/200285 [==============================] - 368s - loss: 1.3238     
iteration 39 200285/200285 [==============================] - 349s - loss: 1.3222     
iteration 40 200285/200285 [==============================] - 490s - loss: 1.3215     
iteration 41 200285/200285 [==============================] - 477s - loss: 1.3205     
iteration 42 200285/200285 [==============================] - 474s - loss: 1.3225     
iteration 43 200285/200285 [==============================] - 513s - loss: 1.3311     
iteration 44 200285/200285 [==============================] - 522s - loss: 1.3389     
iteration 45 200285/200285 [==============================] - 502s - loss: 1.3728     
iteration 46 200285/200285 [==============================] - 484s - loss: 1.3313     
iteration 47 200285/200285 [==============================] - 494s - loss: 1.3233     
iteration 48 200285/200285 [==============================] - 550s - loss: 1.3226     
iteration 49 200285/200285 [==============================] - 664s - loss: 1.3202     
iteration 50 200285/200285 [==============================] - 490s - loss: 1.3228     
iteration 51 200285/200285 [==============================] - 404s - loss: 1.3187     
iteration 52 200285/200285 [==============================] - 349s - loss: 1.3200     
iteration 53 200285/200285 [==============================] - 347s - loss: 1.3195     
iteration 54 200285/200285 [==============================] - 402s - loss: 1.3245     
iteration 55 200285/200285 [==============================] - 413s - loss: 1.3203     
iteration 56 200285/200285 [==============================] - 393s - loss: 1.3164     
iteration 57 200285/200285 [==============================] - 370s - loss: 1.3190     
iteration 58 200285/200285 [==============================] - 442s - loss: 1.3536     
iteration 59 200285/200285 [==============================] - 408s - loss: 1.3241     
iteration 60 200285/200285 [==============================] - 356s - loss: 1.3184     
iteration 61 200285/200285 [==============================] - 388s - loss: 1.3224     
iteration 62 200285/200285 [==============================] - 395s - loss: 1.3196     
iteration 63 200285/200285 [==============================] - 415s - loss: 1.3429     
iteration 64 200285/200285 [==============================] - 413s - loss: 1.6466     
iteration 65 200285/200285 [==============================] - 401s - loss: 1.3339     
iteration 66 200285/200285 [==============================] - 443s - loss: 1.3263     
iteration 67 200285/200285 [==============================] - 430s - loss: 1.3607     
iteration 68 200285/200285 [==============================] - 393s - loss: 1.3696     
iteration 69 200285/200285 [==============================] - 460s - loss: 1.3275     
iteration 70 200285/200285 [==============================] - 443s - loss: 1.6963     
iteration 71 200285/200285 [==============================] - 449s - loss: 4.9700     
iteration 72 200285/200285 [==============================] - 473s - loss: 7.8267     
iteration 73 200285/200285 [==============================] - 441s - loss: 9.1923     
iteration 74 200285/200285 [==============================] - 422s - loss: 8.6638      
iteration 75 200285/200285 [==============================] - 423s - loss: 8.1039      
iteration 76 200285/200285 [==============================] - 403s - loss: 7.8252      
iteration 77 200285/200285 [==============================] - 416s - loss: 6.7547     
iteration 78 200285/200285 [==============================] - 436s - loss: 9.0915     
iteration 79 200285/200285 [==============================] - 450s - loss: 9.4587      
iteration 80 200285/200285 [==============================] - 498s - loss: 11.3355     
iteration 81 200285/200285 [==============================] - 453s - loss: 10.5768     
iteration 82 200285/200285 [==============================] - 471s - loss: 9.1803     
iteration 83 200285/200285 [==============================] - 454s - loss: 9.2897     
iteration 84 200285/200285 [==============================] - 439s - loss: 10.3444     
iteration 85 200285/200285 [==============================] - 460s - loss: 10.4792     
iteration 86 200285/200285 [==============================] - 454s - loss: 9.9937      
iteration 87 200285/200285 [==============================] - 470s - loss: 10.5900     
iteration 88 200285/200285 [==============================] - 459s - loss: 10.3293     
iteration 89 200285/200285 [==============================] - 470s - loss: 9.2961      
iteration 90 200285/200285 [==============================] - 457s - loss: 8.7879     
iteration 91 200285/200285 [==============================] - 475s - loss: 8.7853     
iteration 92 200285/200285 [==============================] - 471s - loss: 8.8662     
iteration 93 200285/200285 [==============================] - 456s - loss: 9.1475     
iteration 94 200285/200285 [==============================] - 453s - loss: 9.1911     
iteration 95 200285/200285 [==============================] - 453s - loss: 9.1089     
iteration 96 200285/200285 [==============================] - 412s - loss: 8.6581     
iteration 97 200285/200285 [==============================] - 440s - loss: 8.2222     
iteration 98 200285/200285 [==============================] - 427s - loss: 7.8420     
iteration 99 200285/200285 [==============================] - 456s - loss: 8.0445     
iteration 100 200285/200285 [==============================] - 475s - loss: 8.2455     
iteration 101 200285/200285 [==============================] - 408s - loss: 8.2646     
iteration 102 200285/200285 [==============================] - 480s - loss: 8.4509     
iteration 103 200285/200285 [==============================] - 487s - loss: 8.7179     
iteration 104 200285/200285 [==============================] - 517s - loss: 8.4393     
iteration 105 200285/200285 [==============================] - 578s - loss: 8.5690     
iteration 106 200285/200285 [==============================] - 510s - loss: 8.5140     
iteration 107 200285/200285 [==============================] - 493s - loss: 8.4314     
iteration 108 200285/200285 [==============================] - 481s - loss: 8.5455     
iteration 109 200285/200285 [==============================] - 436s - loss: 8.6509   
iteration 110 200285/200285 [==============================] - 568s - loss: 8.5100     
iteration 111 200285/200285 [==============================] - 410s - loss: 8.5536     
iteration 112 200285/200285 [==============================] - 430s - loss: 8.6331     
iteration 113 200285/200285 [==============================] - 330s - loss: 8.5045     
iteration 114 200285/200285 [==============================] - 331s - loss: 8.4348     
iteration 115 200285/200285 [==============================] - 329s - loss: 8.2595     
iteration 116 200285/200285 [==============================] - 328s - loss: 8.2419     
iteration 117 200285/200285 [==============================] - 326s - loss: 8.1802     
iteration 118 200285/200285 [==============================] - 326s - loss: 8.0493     
iteration 119 200285/200285 [==============================] - 329s - loss: 8.0187     
iteration 120 200285/200285 [==============================] - 324s - loss: 8.0077     
iteration 121 200285/200285 [==============================] - 325s - loss: 7.7659     
iteration 122 200285/200285 [==============================] - 328s - loss: 7.7752     
iteration 123 200285/200285 [==============================] - 324s - loss: 7.7003     
iteration 124 200285/200285 [==============================] - 325s - loss: 7.8265     
iteration 125 200285/200285 [==============================] - 322s - loss: nan        
iteration 126 200285/200285 [==============================] - 324s - loss: nan     
iteration 127 200285/200285 [==============================] - 323s - loss: nan     
iteration 128 200285/200285 [==============================] - 320s - loss: nan     
iteration 129 200285/200285 [==============================] - 321s - loss: nan     
iteration 130 200285/200285 [==============================] - 320s - loss: nan     
iteration 131 200285/200285 [==============================] - 320s - loss: nan     
iteration 132 200285/200285 [==============================] - 322s - loss: nan     
iteration 133 200285/200285 [==============================] - 324s - loss: nan     
iteration 134 200285/200285 [==============================] - 322s - loss: nan     
iteration 135 200285/200285 [==============================] - 322s - loss: nan     
iteration 136 200285/200285 [==============================] - 327s - loss: nan     
iteration 137 200285/200285 [==============================] - 322s - loss: nan     
iteration 138 200285/200285 [==============================] - 322s - loss: nan     
iteration 139 200285/200285 [==============================] - 322s - loss: nan     
iteration 140 200285/200285 [==============================] - 321s - loss: nan     
iteration 141 200285/200285 [==============================] - 355s - loss: nan     
iteration 142 200285/200285 [==============================] - 418s - loss: nan     
iteration 143 200285/200285 [==============================] - 400s - loss: nan     
iteration 144 200285/200285 [==============================] - 422s - loss: nan     
iteration 145 200285/200285 [==============================] - 427s - loss: nan     
iteration 146 200285/200285 [==============================] - 414s - loss: nan     
iteration 147 200285/200285 [==============================] - 435s - loss: nan     
iteration 148 200285/200285 [==============================] - 435s - loss: nan     
iteration 149 200285/200285 [==============================] - 430s - loss: nan     
iteration 150 200285/200285 [==============================] - 426s - loss: nan  ",mostafa-mahmoud,b'stale',2017-07-19T01:18:27Z,2018-06-13T14:10:04Z
7371,Fix TensorBoard callback for models with multiple inputs,- Fix bug #7247 ,javiercorrea,None,2017-07-18T18:35:09Z,2017-07-18T21:57:16Z
7352,One problem for examples/imdb_fasttext.py,"I found one small bug for function 'add_ngram' in the file examples/imdb_fasttext.py. When adding n grams, the grams with size of 1, 2,..., n-1 should be all added according to the original paper. However, this function cannot fully achieve this goal due to these two lines: ""for i in range(len(new_list) - ngram_range + 1):""; ""for ngram_value in range(2, ngram_range + 1):"". I think the positions of the two lines should be swapped so that it looks like this: ""for ngram_value in range(2, ngram_range + 1): for i in range(len(new_list) - ngram_value + 1):"". Please check on this issue to make updates. Thank you!",jind11,b'stale',2017-07-16T09:41:13Z,2017-11-13T10:45:56Z
7344,strange behavior for regularization when calling models,"I have an existing network I would like to call with new inputs.  If I do this several times with different inputs it seems to keep adding the regularization to the total loss.  Here is a simple script to demonstrate the issue:
```
import numpy as np
from keras.models import Model
from keras.regularizers import l1
from keras.layers import Input, Dense
from keras.optimizers import SGD

x1 = Input(shape=(5,), name='x1')
x2 = Input(shape=(5,), name='x2')
x3 = Input(shape=(5,), name='x3')

# create a linear regression model
# if you set the regularizer weight to zero you can see the model 
# makes perfect predictions for the selected input_vals
y = Dense(1, kernel_initializer='ones', kernel_regularizer=l1(1))(x1)

lin1 = Model(inputs=[x1],outputs=[y],name='lin1')
lin1.compile(loss='mse',optimizer=SGD())

lin2 = Model(inputs=[x1],outputs=[lin1(x1)],name='lin2')
lin2.compile(loss='mse',optimizer=SGD())

lin3 = Model(inputs=[x2],outputs=[lin1(x2)],name='lin3')
lin3.compile(loss='mse',optimizer=SGD())

lin4 = Model(inputs=[x3],outputs=[lin1(x3)],name='lin4')
lin4.compile(loss='mse',optimizer=SGD())

input_vals = np.ones((100,5))
target_vals = 5*np.ones((100,1))
print ""lin1 = "", lin1.evaluate(input_vals,target_vals,verbose=0)
print ""lin2 = "", lin2.evaluate(input_vals,target_vals,verbose=0)
print ""lin3 = "", lin3.evaluate(input_vals,target_vals,verbose=0)
print ""lin4 = "", lin4.evaluate(input_vals,target_vals,verbose=0)
```

I would expect each of these to output 5 (because the prediction is perfect and the L1 norm of kernel is 5). Here is the output I get:
```
lin1 =  5.0
lin2 =  5.0
lin3 =  10.0
lin4 =  15.0
```
Is this expected behavior?  Am I just misusing Keras or is it a bug?

This seems somewhat related to issue #5318.  I am using the latest Keras and the bug happens with the Theano and Tensorflow backends.",jacobsnoi,b'stale',2017-07-14T16:33:59Z,2017-11-11T18:25:39Z
7311,Allow Reshape to reduced it's dimensions: changed Reshape ValueError to UserWarning,"Reshape Layer does not allow for the reduction of dimensions. 
Example:
Reshape Input: `(None, first_dims, other_dims)`
Reshape Output: `(None * first_dims, other_dims)`
This example will lead to raised error the size of the total array does take into account the None dimension size and thinks it's and error. However, sometimes you do want this behavior.

It's a minor change to allow Reshape to behave closer to tf.reshape(). This behavior is already used inside of TimeDistributed, and will allow me and others to use Reshape directly without having to create a custom layer or TimeDistributed wrapper which leads to many bugs.

@fchollet let me know if the warning message is acceptable or should change it's jargon to something more specific.",avn3r,None,2017-07-11T20:22:01Z,2017-07-13T05:51:48Z
7273,Error in train_on_batch after upgrading Keras from 1.1.0 to 2.0.5,"I just upgrade Keras from 1.1.0 to 2.0.5:
`pip install git+git://github.com/fchollet/keras.git --upgrade --no-deps`

My program is running on Theano backend and GPU.
Theano: 0.9.0.dev2
numpy: 1.13.1
scipy: 0.18.1
Python: 3.4.4
Anaconda 2.4.1 
Run on Windows

The program runs fine before upgrading Keras. 
But after upgrading, it throws an error when train_on_batch is called:

 ```
****** Iterating over each batch of the training data ******
1 #include <Python.h>
2 #include <iostream>
3 #include ""theano_mod_helper.h""
4 #include ""cuda_ndarray.cuh""
5 //////////////////////
6 ////  Support Code
7 //////////////////////
8 
9 
10     namespace {
11     struct __struct_compiled_op_m9ba06c94983f27c76a27385a5df5c6b1 {
12         PyObject* __ERROR;
13 
14         PyObject* storage_V3;
15 PyObject* storage_V1;
16         
17 
18         __struct_compiled_op_m9ba06c94983f27c76a27385a5df5c6b1() {
19             // This is only somewhat safe because we:
20             //  1) Are not a virtual class
21             //  2) Do not use any virtual classes in the members
22             //  3) Deal with mostly POD and pointers
23 
24             // If this changes, we would have to revise this, but for
25             // now I am tired of chasing segfaults because
26             // initialization code had an error and some pointer has
27             // a junk value.
28             memset(this, 0, sizeof(*this));
29         }
30         ~__struct_compiled_op_m9ba06c94983f27c76a27385a5df5c6b1(void) {
31             cleanup();
32         }
33 
34         int init(PyObject* __ERROR, PyObject* storage_V3, PyObject* storage_V1) {
35             Py_XINCREF(storage_V3);
36 Py_XINCREF(storage_V1);
37             this->storage_V3 = storage_V3;
38 this->storage_V1 = storage_V1;
39             
40 
41 
42 
43             this->__ERROR = __ERROR;
44             return 0;
45         }
46         void cleanup(void) {
47             __label_1:
48 
49 double __DUMMY_1;
50 __label_3:
51 
52 double __DUMMY_3;
53 __label_6:
54 
55 double __DUMMY_6;
56 
57             Py_XDECREF(this->storage_V3);
58 Py_XDECREF(this->storage_V1);
59         }
60         int run(void) {
61             int __failure = 0;
62             
63     PyObject* py_V1;
64      CudaNdarray * V1;
65     PyObject* py_V3;
66      CudaNdarray * V3;
67 {
68 
69     py_V1 = PyList_GET_ITEM(storage_V1, 0);
70     {Py_XINCREF(py_V1);}
71     
72         if (py_V1 == Py_None)
73         {
74             V1 = NULL;
75         }
76         else
77         {
78             
79         assert(py_V1->ob_refcnt >= 2); // There should be at least one ref from the container object,
80         // and one ref from the local scope.
81 
82         if (CudaNdarray_Check(py_V1))
83         {
84             //fprintf(stderr, ""c_extract CNDA object w refcnt %p %i\n"", py_V1, (py_V1->ob_refcnt));
85             V1 = (CudaNdarray*)py_V1;
86             //std::cerr << ""c_extract "" << V1 << '\n';
87         
88 
89                 if (V1->nd != 3)
90                 {
91                     PyErr_Format(PyExc_RuntimeError,
92                                  ""c_extract: Some CudaNdarray has rank %i, it was supposed to have rank 3"",
93                                  V1->nd);
94                     V1 = NULL;
95                     {
96         __failure = 2;
97         if (!PyErr_Occurred()) {
98             PyErr_SetString(PyExc_RuntimeError,
99                 ""Unexpected error in an Op's C code. ""
100                 ""No Python exception was set."");
101             }
102         goto __label_2;};
103                 }
104                 //std::cerr << ""c_extract "" << V1 << "" nd check passed\n"";
105             
106 
107                 if (CudaNdarray_HOST_DIMS(V1)[2] != 1)
108                 {
109                     PyErr_Format(PyExc_RuntimeError,
110                                  ""c_extract: Some CudaNdarray has dim %i on broadcastable dimension %i"",
111                                  CudaNdarray_HOST_DIMS(V1)[2], 2);
112                     V1 = NULL;
113                     {
114         __failure = 2;
115         if (!PyErr_Occurred()) {
116             PyErr_SetString(PyExc_RuntimeError,
117                 ""Unexpected error in an Op's C code. ""
118                 ""No Python exception was set."");
119             }
120         goto __label_2;};
121                 }
122                 //std::cerr << ""c_extract "" << V1 << ""dim check 2 passed\n"";
123                 //std::cerr << ""c_extract "" << V1 << ""checking bcast 2 <"" << V1->str<< "">\n"";
124                 //std::cerr << ""c_extract "" << V1->str[2] << ""\n"";
125                 if (CudaNdarray_HOST_STRIDES(V1)[2])
126                 {
127                     //std::cerr << ""c_extract bad stride detected...\n"";
128                     PyErr_Format(PyExc_RuntimeError,
129                                  ""c_extract: Some CudaNdarray has a nonzero stride %i on a broadcastable dimension %i"",
130                                  CudaNdarray_HOST_STRIDES(V1)[2], 2);
131                     V1 = NULL;
132                     {
133         __failure = 2;
134         if (!PyErr_Occurred()) {
135             PyErr_SetString(PyExc_RuntimeError,
136                 ""Unexpected error in an Op's C code. ""
137                 ""No Python exception was set."");
138             }
139         goto __label_2;};
140                 }
141                 //std::cerr << ""c_extract "" << V1 << ""bcast check 2 passed\n"";
142                     
143 
144                 assert(V1);
145                 Py_INCREF(py_V1);
146             }
147             else if (py_V1 == Py_None)
148             {
149                 PyErr_SetString(PyExc_TypeError,
150                                 ""expected a CudaNdarray, not None"");
151                 V1 = NULL;
152                 {
153         __failure = 2;
154         if (!PyErr_Occurred()) {
155             PyErr_SetString(PyExc_RuntimeError,
156                 ""Unexpected error in an Op's C code. ""
157                 ""No Python exception was set."");
158             }
159         goto __label_2;};
160             }
161             else
162             {
163                 //fprintf(stderr, ""FAILING c_extract CNDA object w refcnt %p %i\n"", py_V1, (py_V1->ob_refcnt));
164                 PyErr_SetString(PyExc_TypeError, ""Argument not a CudaNdarray"");
165                 V1 = NULL;
166                 {
167         __failure = 2;
168         if (!PyErr_Occurred()) {
169             PyErr_SetString(PyExc_RuntimeError,
170                 ""Unexpected error in an Op's C code. ""
171                 ""No Python exception was set."");
172             }
173         goto __label_2;};
174             }
175             //std::cerr << ""c_extract done "" << V1 << '\n';
176             
177 
178         }
179         
180 {
181 
182     py_V3 = PyList_GET_ITEM(storage_V3, 0);
183     {Py_XINCREF(py_V3);}
184     
185         assert(py_V3->ob_refcnt >= 2); // There should be at least one ref from the container object,
186         // and one ref from the local scope.
187 
188         if (CudaNdarray_Check(py_V3))
189         {
190             //fprintf(stderr, ""c_extract CNDA object w refcnt %p %i\n"", py_V3, (py_V3->ob_refcnt));
191             V3 = (CudaNdarray*)py_V3;
192             //std::cerr << ""c_extract "" << V3 << '\n';
193         
194 
195                 if (V3->nd != 3)
196                 {
197                     PyErr_Format(PyExc_RuntimeError,
198                                  ""c_extract: Some CudaNdarray has rank %i, it was supposed to have rank 3"",
199                                  V3->nd);
200                     V3 = NULL;
201                     {
202         __failure = 4;
203         if (!PyErr_Occurred()) {
204             PyErr_SetString(PyExc_RuntimeError,
205                 ""Unexpected error in an Op's C code. ""
206                 ""No Python exception was set."");
207             }
208         goto __label_4;};
209                 }
210                 //std::cerr << ""c_extract "" << V3 << "" nd check passed\n"";
211             
212 
213                 if (CudaNdarray_HOST_DIMS(V3)[2] != 1)
214                 {
215                     PyErr_Format(PyExc_RuntimeError,
216                                  ""c_extract: Some CudaNdarray has dim %i on broadcastable dimension %i"",
217                                  CudaNdarray_HOST_DIMS(V3)[2], 2);
218                     V3 = NULL;
219                     {
220         __failure = 4;
221         if (!PyErr_Occurred()) {
222             PyErr_SetString(PyExc_RuntimeError,
223                 ""Unexpected error in an Op's C code. ""
224                 ""No Python exception was set."");
225             }
226         goto __label_4;};
227                 }
228                 //std::cerr << ""c_extract "" << V3 << ""dim check 2 passed\n"";
229                 //std::cerr << ""c_extract "" << V3 << ""checking bcast 2 <"" << V3->str<< "">\n"";
230                 //std::cerr << ""c_extract "" << V3->str[2] << ""\n"";
231                 if (CudaNdarray_HOST_STRIDES(V3)[2])
232                 {
233                     //std::cerr << ""c_extract bad stride detected...\n"";
234                     PyErr_Format(PyExc_RuntimeError,
235                                  ""c_extract: Some CudaNdarray has a nonzero stride %i on a broadcastable dimension %i"",
236                                  CudaNdarray_HOST_STRIDES(V3)[2], 2);
237                     V3 = NULL;
238                     {
239         __failure = 4;
240         if (!PyErr_Occurred()) {
241             PyErr_SetString(PyExc_RuntimeError,
242                 ""Unexpected error in an Op's C code. ""
243                 ""No Python exception was set."");
244             }
245         goto __label_4;};
246                 }
247                 //std::cerr << ""c_extract "" << V3 << ""bcast check 2 passed\n"";
248                     
249 
250                 assert(V3);
251                 Py_INCREF(py_V3);
252             }
253             else if (py_V3 == Py_None)
254             {
255                 PyErr_SetString(PyExc_TypeError,
256                                 ""expected a CudaNdarray, not None"");
257                 V3 = NULL;
258                 {
259         __failure = 4;
260         if (!PyErr_Occurred()) {
261             PyErr_SetString(PyExc_RuntimeError,
262                 ""Unexpected error in an Op's C code. ""
263                 ""No Python exception was set."");
264             }
265         goto __label_4;};
266             }
267             else
268             {
269                 //fprintf(stderr, ""FAILING c_extract CNDA object w refcnt %p %i\n"", py_V3, (py_V3->ob_refcnt));
270                 PyErr_SetString(PyExc_TypeError, ""Argument not a CudaNdarray"");
271                 V3 = NULL;
272                 {
273         __failure = 4;
274         if (!PyErr_Occurred()) {
275             PyErr_SetString(PyExc_RuntimeError,
276                 ""Unexpected error in an Op's C code. ""
277                 ""No Python exception was set."");
278             }
279         goto __label_4;};
280             }
281             //std::cerr << ""c_extract done "" << V3 << '\n';
282             
283 
284 {
285 // Op class GpuElemwise
286 
287         //std::cerr << ""C_CODE RoundHalfToEven START\n"";
288         //standard elemwise size checks
289             
290 
291             int dims[3] = {1,1,1};
292             
293 
294                 int broadcasts_V3[3] = {0, 0, 1};
295                 
296 
297         //std::cerr << ""C_CODE RoundHalfToEven checking input V3\n"";
298         if (3 != V3->nd)
299         {
300             PyErr_Format(PyExc_TypeError,
301                          ""need 3 dims, not %i"", V3->nd);
302             {
303         __failure = 5;
304         if (!PyErr_Occurred()) {
305             PyErr_SetString(PyExc_RuntimeError,
306                 ""Unexpected error in an Op's C code. ""
307                 ""No Python exception was set."");
308             }
309         goto __label_5;};
310         }
311         for (int i = 0; i< 3; ++i)
312         {
313             dims[i] = (dims[i] == 1) ? CudaNdarray_HOST_DIMS(V3)[i] : dims[i];
314             if ((!(broadcasts_V3[i] &&
315                  CudaNdarray_HOST_DIMS(V3)[i] == 1)) &&
316                 (dims[i] != CudaNdarray_HOST_DIMS(V3)[i]))
317             {
318                 //std::cerr << ""C_CODE RoundHalfToEven checking input V3 failed\n"";
319                 PyErr_Format(PyExc_ValueError,
320                              ""GpuElemwise. Input dimension mis-match. Input""
321                              "" 0 (indices start at 0) has shape[%i] == %i""
322                              "", but the output's size on that axis is %i."",
323                              i,
324                              CudaNdarray_HOST_DIMS(V3)[i],
325                              dims[i]
326                             );
327                 {
328         __failure = 5;
329         if (!PyErr_Occurred()) {
330             PyErr_SetString(PyExc_RuntimeError,
331                 ""Unexpected error in an Op's C code. ""
332                 ""No Python exception was set."");
333             }
334         goto __label_5;};
335             }
336         }
337             
338 
339         for (int i = 0; (i< 3) && (V1); ++i) {
340             if (dims[i] != CudaNdarray_HOST_DIMS(V1)[i])
341             {
342                 Py_DECREF(V1);
343                 V1 = NULL;
344             }
345         }
346         if (V1 && !CudaNdarray_is_c_contiguous(V1))
347         {
348             Py_XDECREF(V1);
349             V1 = NULL;
350         }
351         if (NULL == V1)
352         {
353             V1 = (CudaNdarray*)CudaNdarray_New();
354             if (!V1)
355             {
356                 //error string already set
357                 {
358         __failure = 5;
359         if (!PyErr_Occurred()) {
360             PyErr_SetString(PyExc_RuntimeError,
361                 ""Unexpected error in an Op's C code. ""
362                 ""No Python exception was set."");
363             }
364         goto __label_5;};
365             }
366             if (CudaNdarray_alloc_contiguous(V1, 3, dims))
367             {
368                 //error string already set
369                 Py_DECREF(V1);
370                 V1 = NULL;
371                 {
372         __failure = 5;
373         if (!PyErr_Occurred()) {
374             PyErr_SetString(PyExc_RuntimeError,
375                 ""Unexpected error in an Op's C code. ""
376                 ""No Python exception was set."");
377             }
378         goto __label_5;};
379             }
380         }
381         //std::cerr << ""ELEMWISE NEW V1 nd"" << V1->nd << ""\n"";
382         //std::cerr << ""ELEMWISE NEW V1 data"" << V1->devdata << ""\n"";
383         
384 
385         {
386             //new block so that failure gotos don't skip over variable initialization
387             //std::cerr << ""calling callkernel\n"";
388             if (callkernel_node_m9ba06c94983f27c76a27385a5df5c6b1_0(1, 0, dims
389             
390 
391                         , CudaNdarray_DEV_DATA(V3), CudaNdarray_HOST_STRIDES(V3)
392             
393 
394                         , CudaNdarray_DEV_DATA(V1), CudaNdarray_HOST_STRIDES(V1)
395             
396 
397                         ))
398             {
399                  // error
400             
401 
402                 Py_DECREF(V1);
403                 V1 = NULL;
404                 
405 
406                 {
407         __failure = 5;
408         if (!PyErr_Occurred()) {
409             PyErr_SetString(PyExc_RuntimeError,
410                 ""Unexpected error in an Op's C code. ""
411                 ""No Python exception was set."");
412             }
413         goto __label_5;};
414             }
415             else // no error
416             {
417             }
418         }
419         //std::cerr << ""C_CODE RoundHalfToEven END\n"";
420         
421 __label_5:
422 
423 double __DUMMY_5;
424 
425 }
426 __label_4:
427 
428         //std::cerr << ""cleanup "" << py_V3 << "" "" << V3 << ""\n"";
429         //fprintf(stderr, ""c_cleanup CNDA py_object w refcnt %p %i\n"", py_V3, (py_V3->ob_refcnt));
430         if (V3)
431         {
432             //fprintf(stderr, ""c_cleanup CNDA cn_object w refcnt %p %i\n"", V3, (V3->ob_refcnt));
433             Py_XDECREF(V3);
434         }
435         //std::cerr << ""cleanup done"" << py_V3 << ""\n"";
436         
437     {Py_XDECREF(py_V3);}
438     
439 double __DUMMY_4;
440 
441 }
442 __label_2:
443 
444     if (!__failure) {
445       
446         //std::cerr << ""sync\n"";
447         if (NULL == V1) {
448             // failure: sync None to storage
449             Py_XDECREF(py_V1);
450             py_V1 = Py_None;
451             Py_INCREF(py_V1);
452         }
453         else
454         {
455             if (py_V1 != (PyObject*)V1)
456             {
457                 Py_XDECREF(py_V1);
458                 py_V1 = (PyObject*)V1;
459                 Py_INCREF(py_V1);
460             }
461             assert(py_V1->ob_refcnt);
462         }
463         
464       PyObject* old = PyList_GET_ITEM(storage_V1, 0);
465       {Py_XINCREF(py_V1);}
466       PyList_SET_ITEM(storage_V1, 0, py_V1);
467       {Py_XDECREF(old);}
468     }
469     
470         //std::cerr << ""cleanup "" << py_V1 << "" "" << V1 << ""\n"";
471         //fprintf(stderr, ""c_cleanup CNDA py_object w refcnt %p %i\n"", py_V1, (py_V1->ob_refcnt));
472         if (V1)
473         {
474             //fprintf(stderr, ""c_cleanup CNDA cn_object w refcnt %p %i\n"", V1, (V1->ob_refcnt));
475             Py_XDECREF(V1);
476         }
477         //std::cerr << ""cleanup done"" << py_V1 << ""\n"";
478         
479     {Py_XDECREF(py_V1);}
480     
481 double __DUMMY_2;
482 
483 }
484 
485             
486         if (__failure) {
487             // When there is a failure, this code puts the exception
488             // in __ERROR.
489             PyObject* err_type = NULL;
490             PyObject* err_msg = NULL;
491             PyObject* err_traceback = NULL;
492             PyErr_Fetch(&err_type, &err_msg, &err_traceback);
493             if (!err_type) {err_type = Py_None;Py_INCREF(Py_None);}
494             if (!err_msg) {err_msg = Py_None; Py_INCREF(Py_None);}
495             if (!err_traceback) {err_traceback = Py_None; Py_INCREF(Py_None);}
496             PyObject* old_err_type = PyList_GET_ITEM(__ERROR, 0);
497             PyObject* old_err_msg = PyList_GET_ITEM(__ERROR, 1);
498             PyObject* old_err_traceback = PyList_GET_ITEM(__ERROR, 2);
499             PyList_SET_ITEM(__ERROR, 0, err_type);
500             PyList_SET_ITEM(__ERROR, 1, err_msg);
501             PyList_SET_ITEM(__ERROR, 2, err_traceback);
502             {Py_XDECREF(old_err_type);}
503             {Py_XDECREF(old_err_msg);}
504             {Py_XDECREF(old_err_traceback);}
505         }
506         // The failure code is returned to index what code block failed.
507         return __failure;
508         
509         }
510     };
511     }
512     
513 
514         static int __struct_compiled_op_m9ba06c94983f27c76a27385a5df5c6b1_executor(__struct_compiled_op_m9ba06c94983f27c76a27385a5df5c6b1 *self) {
515             return self->run();
516         }
517 
518         static void __struct_compiled_op_m9ba06c94983f27c76a27385a5df5c6b1_destructor(PyObject *capsule) {
519             __struct_compiled_op_m9ba06c94983f27c76a27385a5df5c6b1 *self = (__struct_compiled_op_m9ba06c94983f27c76a27385a5df5c6b1 *)PyCapsule_GetContext(capsule);
520             delete self;
521         }
522         
523 //////////////////////
524 ////  Functions
525 //////////////////////
526 static PyObject * instantiate(PyObject * self, PyObject *argtuple) {
527   assert(PyTuple_Check(argtuple));
528   if (3 != PyTuple_Size(argtuple)){ 
529      PyErr_Format(PyExc_TypeError, ""Wrong number of arguments, expected 3, got %i"", (int)PyTuple_Size(argtuple));
530      return NULL;
531   }
532   __struct_compiled_op_m9ba06c94983f27c76a27385a5df5c6b1* struct_ptr = new __struct_compiled_op_m9ba06c94983f27c76a27385a5df5c6b1();
533   if (struct_ptr->init( PyTuple_GET_ITEM(argtuple, 0),PyTuple_GET_ITEM(argtuple, 1),PyTuple_GET_ITEM(argtuple, 2) ) != 0) {
534     delete struct_ptr;
535     return NULL;
536   }
537     PyObject* thunk = PyCapsule_New((void*)(&__struct_compiled_op_m9ba06c94983f27c76a27385a5df5c6b1_executor), NULL, __struct_compiled_op_m9ba06c94983f27c76a27385a5df5c6b1_destructor);
538     if (thunk != NULL && PyCapsule_SetContext(thunk, struct_ptr) != 0) {
539         PyErr_Clear();
540         Py_DECREF(thunk);
541         thunk = NULL;
542     }
543 
544   return thunk; }
545 
546 //////////////////////
547 ////  Module init
548 //////////////////////
549 static PyMethodDef MyMethods[] = {
550 	{""instantiate"", instantiate, METH_VARARGS, ""undocumented""} ,
551 	{NULL, NULL, 0, NULL}
552 };
553 static struct PyModuleDef moduledef = {
554       PyModuleDef_HEAD_INIT,
555       ""m9ba06c94983f27c76a27385a5df5c6b1"",
556       NULL,
557       -1,
558       MyMethods,
559 };
560 
561 PyMODINIT_FUNC PyInit_m9ba06c94983f27c76a27385a5df5c6b1(void) {
562     PyObject *m = PyModule_Create(&moduledef);
563     return m;
564 }
565 
===============================
I:\Anaconda3\lib\site-packages\theano\sandbox\cuda\cuda_ndarray.cuh(17) : warning C4005: 'PyString_Check' : macro redefinition

        I:\Anaconda3\lib\site-packages\numpy\core\include\numpy/npy_3kcompat.h(63) : see previous definition of 'PyString_Check'

I:\Anaconda3\lib\site-packages\theano\sandbox\cuda\cuda_ndarray.cuh(18) : warning C4005: 'PyString_FromString' : macro redefinition

        I:\Anaconda3\lib\site-packages\numpy\core\include\numpy/npy_3kcompat.h(65) : see previous definition of 'PyString_FromString'

I:\Anaconda3\lib\site-packages\theano\sandbox\cuda\cuda_ndarray.cuh(19) : warning C4005: 'PyString_AsString' : macro redefinition

        I:\Anaconda3\lib\site-packages\numpy\core\include\numpy/npy_3kcompat.h(72) : see previous definition of 'PyString_AsString'

I:\Anaconda3\lib\site-packages\theano\sandbox\cuda\cuda_ndarray.cuh(20) : warning C4005: 'PyString_FromStringAndSize' : macro redefinition

        I:\Anaconda3\lib\site-packages\numpy\core\include\numpy/npy_3kcompat.h(66) : see previous definition of 'PyString_FromStringAndSize'

I:\Anaconda3\lib\site-packages\theano\sandbox\cuda\cuda_ndarray.cuh(21) : warning C4005: 'PyString_Size' : macro redefinition

        I:\Anaconda3\lib\site-packages\numpy\core\include\numpy/npy_3kcompat.h(74) : see previous definition of 'PyString_Size'













mod.cu(388): error: identifier ""callkernel_node_m9ba06c94983f27c76a27385a5df5c6b1_0"" is undefined









1 error detected in the compilation of ""C:/Users/Wang/AppData/Local/Temp/tmpxft_00000f40_00000000-10_mod.cpp1.ii"".

mod.cu


['nvcc', '-shared', '-O3', '--maxrregcount=32', '-LI:\\Anaconda3\\libs', '-arch=sm_61', '--compiler-bindir', 'C:\\Program Files (x86)\\Microsoft Visual Studio 12.0\\VC\\bin', '-Xlinker', '/DEBUG', '-D HAVE_ROUND', '-m64', '-Xcompiler', '-DCUDA_NDARRAY_CUH=m18715462c72ed6afcd7ca5d52813ce90,-DNPY_NO_DEPRECATED_API=NPY_1_7_API_VERSION,/Zi,/MD', '-I""C:\\Users\\Wang\\AppData\\Local\\Theano\\compiledir_Windows-8.1-6.3.9600-Intel64_Family_6_Model_60_Stepping_3_GenuineIntel-3.4.4-64\\cuda_ndarray""', '-I""I:\\Anaconda3\\lib\\site-packages\\numpy\\core\\include""', '-I""I:\\Anaconda3\\include""', '-I""I:\\Anaconda3\\lib\\site-packages\\theano\\gof""', '-I""I:\\Anaconda3\\lib\\site-packages\\theano\\sandbox\\cuda""', '-L""C:\\Users\\Wang\\AppData\\Local\\Theano\\compiledir_Windows-8.1-6.3.9600-Intel64_Family_6_Model_60_Stepping_3_GenuineIntel-3.4.4-64\\cuda_ndarray""', '-L""I:\\Anaconda3\\libs""', '-L""I:\\Anaconda3""', '-o', 'C:\\Users\\Wang\\AppData\\Local\\Theano\\compiledir_Windows-8.1-6.3.9600-Intel64_Family_6_Model_60_Stepping_3_GenuineIntel-3.4.4-64\\tmp28292v2v\\m9ba06c94983f27c76a27385a5df5c6b1.pyd', 'mod.cu', '-lcudart', '-lcublas', '-lcuda_ndarray', '-lpython34']
Traceback (most recent call last):
  File ""J:\git\DwellTimePrediction\DwellTimePrediction\Scenario3\models_training.py"", line 243, in <module>
    loss_lr = lr.train_on_batch(merge_Xs(X_batch_ctx, X_batch_dep), y_batch)
  File ""I:\Anaconda3\lib\site-packages\keras\models.py"", line 951, in train_on_batch
    class_weight=class_weight)
  File ""I:\Anaconda3\lib\site-packages\keras\engine\training.py"", line 1564, in train_on_batch
    self._make_train_function()
  File ""I:\Anaconda3\lib\site-packages\keras\engine\training.py"", line 944, in _make_train_function
    **self._function_kwargs)
  File ""I:\Anaconda3\lib\site-packages\keras\backend\theano_backend.py"", line 1206, in function
    return Function(inputs, outputs, updates=updates, **kwargs)
  File ""I:\Anaconda3\lib\site-packages\keras\backend\theano_backend.py"", line 1192, in __init__
    **kwargs)
  File ""I:\Anaconda3\lib\site-packages\theano\compile\function.py"", line 326, in function
    output_keys=output_keys)
  File ""I:\Anaconda3\lib\site-packages\theano\compile\pfunc.py"", line 484, in pfunc
    output_keys=output_keys)
  File ""I:\Anaconda3\lib\site-packages\theano\compile\function_module.py"", line 1789, in orig_function
    defaults)
  File ""I:\Anaconda3\lib\site-packages\theano\compile\function_module.py"", line 1653, in create
    input_storage=input_storage_lists, storage_map=storage_map)
  File ""I:\Anaconda3\lib\site-packages\theano\gof\link.py"", line 699, in make_thunk
    storage_map=storage_map)[:3]
  File ""I:\Anaconda3\lib\site-packages\theano\gof\vm.py"", line 1051, in make_all
    no_recycling))
  File ""I:\Anaconda3\lib\site-packages\theano\sandbox\cuda\__init__.py"", line 257, in make_thunk
    compute_map, no_recycling)
  File ""I:\Anaconda3\lib\site-packages\theano\gof\op.py"", line 932, in make_thunk
    no_recycling)
  File ""I:\Anaconda3\lib\site-packages\theano\gof\op.py"", line 833, in make_c_thunk
    output_storage=node_output_storage)
  File ""I:\Anaconda3\lib\site-packages\theano\gof\cc.py"", line 1190, in make_thunk
    keep_lock=keep_lock)
  File ""I:\Anaconda3\lib\site-packages\theano\gof\cc.py"", line 1131, in __compile__
    keep_lock=keep_lock)
  File ""I:\Anaconda3\lib\site-packages\theano\gof\cc.py"", line 1589, in cthunk_factory
    key=key, lnk=self, keep_lock=keep_lock)
  File ""I:\Anaconda3\lib\site-packages\theano\gof\cmodule.py"", line 1145, in module_from_key
    module = lnk.compile_cmodule(location)
  File ""I:\Anaconda3\lib\site-packages\theano\gof\cc.py"", line 1492, in compile_cmodule
    preargs=preargs)
  File ""I:\Anaconda3\lib\site-packages\theano\sandbox\cuda\nvcc_compiler.py"", line 405, in compile_str
    'for cmd', ' '.join(cmd))
Exception: ('The following error happened while compiling the node', GpuElemwise{RoundHalfToEven,no_inplace}(GpuElemwise{scalar_sigmoid,no_inplace}.0), '\n', 'nvcc return status', 2, 'for cmd', 'nvcc -shared -O3 --maxrregcount=32 -LI:\\Anaconda3\\libs -arch=sm_61 --compiler-bindir C:\\Program Files (x86)\\Microsoft Visual Studio 12.0\\VC\\bin -Xlinker /DEBUG -D HAVE_ROUND -m64 -Xcompiler -DCUDA_NDARRAY_CUH=m18715462c72ed6afcd7ca5d52813ce90,-DNPY_NO_DEPRECATED_API=NPY_1_7_API_VERSION,/Zi,/MD -I""C:\\Users\\Wang\\AppData\\Local\\Theano\\compiledir_Windows-8.1-6.3.9600-Intel64_Family_6_Model_60_Stepping_3_GenuineIntel-3.4.4-64\\cuda_ndarray"" -I""I:\\Anaconda3\\lib\\site-packages\\numpy\\core\\include"" -I""I:\\Anaconda3\\include"" -I""I:\\Anaconda3\\lib\\site-packages\\theano\\gof"" -I""I:\\Anaconda3\\lib\\site-packages\\theano\\sandbox\\cuda"" -L""C:\\Users\\Wang\\AppData\\Local\\Theano\\compiledir_Windows-8.1-6.3.9600-Intel64_Family_6_Model_60_Stepping_3_GenuineIntel-3.4.4-64\\cuda_ndarray"" -L""I:\\Anaconda3\\libs"" -L""I:\\Anaconda3"" -o C:\\Users\\Wang\\AppData\\Local\\Theano\\compiledir_Windows-8.1-6.3.9600-Intel64_Family_6_Model_60_Stepping_3_GenuineIntel-3.4.4-64\\tmp28292v2v\\m9ba06c94983f27c76a27385a5df5c6b1.pyd mod.cu -lcudart -lcublas -lcuda_ndarray -lpython34', '[GpuElemwise{RoundHalfToEven,no_inplace}(<CudaNdarrayType(float32, (False, False, True))>)]')
```

",munichong,b'stale',2017-07-07T17:51:20Z,2017-11-18T10:36:38Z
7260,Clearer wording in the Shared Layers Section,"*shrugs* mostly the typo ""of top"" -> ""on top"" was bugging me a bit.",n17r4m,None,2017-07-06T21:30:23Z,2017-07-08T10:10:53Z
7235,ImageDataGenerator object is not an iterator,"```
Using TensorFlow backend.
Epoch 1/10
Exception in thread Thread-1:
Traceback (most recent call last):
  File ""/usr/lib/python2.7/threading.py"", line 801, in __bootstrap_inner
    self.run()
  File ""/usr/lib/python2.7/threading.py"", line 754, in run
    self.__target(*self.__args, **self.__kwargs)
  File ""/usr/local/lib/python2.7/dist-packages/keras/engine/training.py"", line 606, in data_generator_task
    generator_output = next(self._generator)
TypeError: ImageDataGenerator object is not an iterator

Traceback (most recent call last):
  File ""/home/nikhil/workspace/data learning/test.py"", line 52, in <module>
    new_model.fit_generator(datagen, steps_per_epoch= len(x_train), epochs=10)    
  File ""/usr/local/lib/python2.7/dist-packages/keras/legacy/interfaces.py"", line 88, in wrapper
    return func(*args, **kwargs)
  File ""/usr/local/lib/python2.7/dist-packages/keras/models.py"", line 1097, in fit_generator
    initial_epoch=initial_epoch)
  File ""/usr/local/lib/python2.7/dist-packages/keras/legacy/interfaces.py"", line 88, in wrapper
    return func(*args, **kwargs)
  File ""/usr/local/lib/python2.7/dist-packages/keras/engine/training.py"", line 1851, in fit_generator
    str(generator_output))
ValueError: output of generator should be a tuple `(x, y, sample_weight)` or `(x, y)`. Found: None
```

Following is the code for the error. I am unable to debug this.

```
from keras.datasets import mnist
from keras.preprocessing.image import ImageDataGenerator
from keras.layers import Dropout
from keras.layers import Flatten
from keras.layers import Dense
from keras.layers.convolutional import Conv2D
from keras.layers.pooling import MaxPooling2D
from keras.utils import np_utils
from keras.models import Sequential

########## DATA PREPERATION ###########

# load data
(x_train, y_train), (x_test, y_test) = mnist.load_data()
# reshape to be [samples][width][height]
x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)
x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)
# convert from int to float
x_train = x_train.astype('float32')
x_test = x_test.astype('float32')
x_train/=255
x_test/=255
# data preprocessing
datagen = ImageDataGenerator(horizontal_flip=True)
test_datagen = ImageDataGenerator()
# fit parameters from data
datagen.fit(x_train)
test_datagen.fit(x_test)
# one hot encoding the output
y_train = np_utils.to_categorical(y_train)
y_test = np_utils.to_categorical(y_test)
no_of_class = y_test.shape[1]
############# model ###########

def create_model():
    model = Sequential()
    model.add(Conv2D(32, kernel_size=(5, 5),activation='relu',input_shape=(28,28,1)))
    model.add(MaxPooling2D(pool_size=(2, 2)))
    model.add(Conv2D(15, (3, 3), activation='relu'))
    model.add(MaxPooling2D(pool_size=(2,2)))
    model.add(Dropout(0.2))
    model.add(Flatten())
    model.add(Dense(128, activation='relu'))
    model.add(Dense(50, activation='relu'))
    model.add(Dense(no_of_class, activation='softmax'))
    # compiling the model
    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
    return model

new_model=create_model()
new_model.fit_generator(datagen, steps_per_epoch= len(x_train), epochs=10)
```  ",NikhilShaw,None,2017-07-04T17:52:43Z,2017-07-04T18:37:10Z
7222,Bug fix: Support multiple outputs in Lambda layer,#7221 ,farizrahman4u,None,2017-07-03T15:12:26Z,2017-10-11T17:46:49Z
7185,states in keras.backend().rnn,"I was reviewing the code of keras.backend().rnn for tensorflow backend and I think I may have found either a bug ~~in the code or~~ in the documentation. Specifically line# 2506 in the file https://github.com/fchollet/keras/blob/master/keras/backend/tensorflow_backend.py. 

```python
2502                for state, new_state in zip(states, new_states):
2503                    new_state.set_shape(state.get_shape())
2504                tiled_mask_t = tf.tile(mask_t,
2505                                       tf.stack([1, tf.shape(output)[1]]))
2506                output = tf.where(tiled_mask_t, output, states[0])
2507                new_states = [tf.where(tiled_mask_t, new_states[i], states[i]) for i in range(len(states))]
2508                output_ta_t = output_ta_t.write(time, output)
2509                return (time + 1, output_ta_t) + tuple(new_states)
```
~~`states[0]` on line 2506 should either be `new_states[0]` i.e.~~
```python
2506                output = tf.where(tiled_mask_t, output, new_states[0])
```
~~because the [definition of step_function](https://keras.io/backend/#rnn) requires `new_states[0]` at time `t` to contain the output at time `(t-1)`. Since `states` holds the previous state, i.e. state returned at time `t-1`, `states[0]` would contain the output at time `t-2`. But that's not what we want here; we want the previous output (i.e. at time `t-1`).~~

**Alternatively**, - and I think this is more appropriate - the definition of step_function should be changed to require `new_states[0]` at time `t` to contain the output at time `t` (not `t-1`). In other words the following snippet
```python
2469        if mask is not None:
2470            if not states:
2471                raise ValueError('No initial states provided! '
2472                                 'When using masking in an RNN, you should '
2473                                 'provide initial states '
2474                                 '(and your step function should return '
2475                                 'as its first state at time `t` '
2476                                 'the output at time `t-1`).')
```
should change to
```python
2469        if mask is not None:
2470            if not states:
2471                raise ValueError('No initial states provided! '
2472                                 'When using masking in an RNN, you should '
2473                                 'provide initial states '
2474                                 '(and your step function should return '
2475                                 'as its first state at time `t` '
2476                                 'the output at time `t`).')
```

I checked [SimpleRNN code](https://github.com/fchollet/keras/blob/master/keras/layers/recurrent.py) and it is consistent with the fix # 2 above (i.e. documentation/definition of new_states should require the first entry to contain the current output, not the previous one). See lines 566 and 576 below.

https://github.com/fchollet/keras/blob/master/keras/layers/recurrent.py
```python
555    def step(self, inputs, states):
556        if self.implementation == 0:
557            h = inputs
558        else:
559            if 0 < self.dropout < 1:
560                h = K.dot(inputs * states[1], self.kernel)
561            else:
562                h = K.dot(inputs, self.kernel)
563            if self.bias is not None:
564                h = K.bias_add(h, self.bias)
565
566        prev_output = states[0]
567        if 0 < self.recurrent_dropout < 1:
568            prev_output *= states[2]
569        output = h + K.dot(prev_output, self.recurrent_kernel)
570        if self.activation is not None:
571            output = self.activation(output)
572
573        # Properly set learning phase on output tensor.
574        if 0 < self.dropout + self.recurrent_dropout:
575            output._uses_learning_phase = True
576        return output, [output]
```

Please make sure that the boxes below are checked before you submit your issue. If your issue is an implementation question, please ask your question on [StackOverflow](http://stackoverflow.com/questions/tagged/keras) or [join the Keras Slack channel](https://keras-slack-autojoin.herokuapp.com/) and ask there instead of filing a GitHub issue.

Thank you!

- [*] Check that you are up-to-date with the master branch of Keras. You can update with:
pip install git+git://github.com/fchollet/keras.git --upgrade --no-deps

- [*] If running on TensorFlow, check that you are up-to-date with the latest version. The installation instructions can be found [here](https://www.tensorflow.org/get_started/os_setup).

- [*] If running on Theano, check that you are up-to-date with the master branch of Theano. You can update with:
pip install git+git://github.com/Theano/Theano.git --upgrade --no-deps

- [*] Provide a link to a GitHub Gist of a Python script that can reproduce your issue (or just copy the script here if it is short).
",untrix,None,2017-06-29T23:57:22Z,2017-06-30T01:18:51Z
7166,How to access output of layers in merged model?,"I want to have 2 parallel VGG models that share an input. I can do this with:
```
modelA = vgg16.VGG16(include_top=True,weights='imagenet')
modelB = vgg16.VGG16(include_top=True,weights='imagenet')
y = modelB(modelA.input)
modelC = Model(inputs=modelA.input,outputs=[modelA.output,y])
```
The top of the plotted model looks like:
![mergedvgg](https://user-images.githubusercontent.com/7025717/27660801-7f89bb10-5c1d-11e7-92ec-964f3c73907d.png)
The layers in the left-hand side behave as normal and can be accessed with modelC.layers[1] through modelC.layers[22].

The right-hand side treats the entire 2nd VGG model as being compressed into one layer, accessed in modelC.layers[23]. This seems okay because this layer 23 has its own array of layers, which seem accessible as normal, e.g. modelC.layers[23].layers[2].name will give 'block1_conv2'.

... eventually, I am using the mean output of a layer to compute a gradient. This works fine with the left VGG model:
```
loss = K.mean(modelC.layers[2].output[:,:,:,:])
```
but if I try to access a layer in the right VGG model:
```
loss = K.mean(modelC.layers[23].layers[2].output[:,:,:,:])
```
I get a 'Disconnected Input' error:
```
File ""C:\Users\Sam\Anaconda2\lib\site-packages\theano\gradient.py"", line 526, in handle_disconnected
    raise DisconnectedInputError(message)
DisconnectedInputError:  
```
I don't know if this is a bug because it seems like it should work. An alternative solution would be to be able to incorporate the 2nd VGG model without it being compressed, but I cannot find a way to do that with the functional API.",deltaz0,b'stale',2017-06-28T21:44:34Z,2017-10-27T23:21:31Z
7159,Error during batchnorm: CUDNN_STATUS_NOT_SUPPORTED,"I've just updated my system to Keras 2.0.5, Theano 0.9.0, and python 3.5 in a conda virtual environment. I've kept cuDNN 7.5 version 5005, which I have earlier used together with BatchNormalization without problems.

Now, when using a batch_size larger than 1024 together with BatchNormalization, an only slightly adjusted mnist_mlp script (from Keras examples, adjusted to include BatchNormalization, see  [mnist_mlp_bn.py.txt](https://github.com/fchollet/keras/files/1108904/mnist_mlp_bn.py.txt)) gives the error:
Error during batchnorm: CUDNN_STATUS_NOT_SUPPORTED. 




Reducing batch_size, or removing BatchNormalization layers fixes the problem. 

It looks like pytorch had the same issue, which was fixed: https://github.com/pytorch/pytorch/issues/1004. I'm not sure how they fixed it, but they refer to the 'cuDNN version we're shipping with the binaries' as if updating cuDNN may solve the problem. However, then I don't see how this issue showed up by updating Keras&Theano... (I'm hesitant to update cuDNN, because I'm running Ubuntu 15.10, which doesn't seem to be supported).

Full Traceback:
Traceback (most recent call last):
  File ""mnist_mlp_bn.py"", line 54, in <module>
    validation_data=(x_test, y_test))
  File ""/opt/anaconda/anaconda3/envs/myenv_1/lib/python3.5/site-packages/keras/models.py"", line 876, in fit
    initial_epoch=initial_epoch)
  File ""/opt/anaconda/anaconda3/envs/myenv_1/lib/python3.5/site-packages/keras/engine/training.py"", line 1419, in fit
    initial_epoch=initial_epoch)
  File ""/opt/anaconda/anaconda3/envs/myenv_1/lib/python3.5/site-packages/keras/engine/training.py"", line 1068, in _fit_loop
    outs = f(ins_batch)
  File ""/opt/anaconda/anaconda3/envs/myenv_1/lib/python3.5/site-packages/keras/backend/theano_backend.py"", line 1197, in __call__
    return self.function(*inputs)
  File ""/opt/anaconda/anaconda3/envs/myenv_1/lib/python3.5/site-packages/theano/compile/function_module.py"", line 898, in __call__
    storage_map=getattr(self.fn, 'storage_map', None))
  File ""/opt/anaconda/anaconda3/envs/myenv_1/lib/python3.5/site-packages/theano/gof/link.py"", line 325, in raise_with_op
    reraise(exc_type, exc_value, exc_trace)
  File ""/opt/anaconda/anaconda3/envs/myenv_1/lib/python3.5/site-packages/six.py"", line 685, in reraise
    raise value.with_traceback(tb)
  File ""/opt/anaconda/anaconda3/envs/myenv_1/lib/python3.5/site-packages/theano/compile/function_module.py"", line 884, in __call__
    self.fn() if output_subset is None else\
RuntimeError: Error during batchnorm: CUDNN_STATUS_NOT_SUPPORTED

Apply node that caused the error: GpuDnnBatchNormInference{mode='per-activation', inplace=False}(GpuContiguous.0, GpuContiguous.0, GpuContiguous.0, GpuContiguous.0, GpuContiguous.0, Constant{0.0010000000475})
Toposort index: 63
Inputs types: [GpuArrayType<None>(float32, (False, False, True, True)), GpuArrayType<None>(float32, (True, False, True, True)), GpuArrayType<None>(float32, (True, False, True, True)), GpuArrayType<None>(float32, (True, False, True, True)), GpuArrayType<None>(float32, (True, False, True, True)), Scalar(float64)]
Inputs shapes: [(1025, 512, 1, 1), (1, 512, 1, 1), (1, 512, 1, 1), (1, 512, 1, 1), (1, 512, 1, 1), ()]
Inputs strides: [(2048, 4, 4, 4), (4, 4, 2048, 2048), (4, 4, 2048, 2048), (4, 4, 2048, 2048), (4, 4, 2048, 2048), ()]
Inputs values: ['not shown', 'not shown', 'not shown', 'not shown', 'not shown', 0.0010000000474974513]
Outputs clients: [[GpuReshape{2}(GpuDnnBatchNormInference{mode='per-activation', inplace=False}.0, MakeVector{dtype='int64'}.0), Shape(GpuDnnBatchNormInference{mode='per-activation', inplace=False}.0)]]

HINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.
HINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.
Exception ignored in: <function WeakValueDictionary.__init__.<locals>.remove at 0x7f06c045c598>
Traceback (most recent call last):
  File ""/opt/anaconda/anaconda3/envs/myenv_1/lib/python3.5/weakref.py"", line 117, in remove
TypeError: 'NoneType' object is not callable",5ke,b'stale',2017-06-28T13:58:41Z,2017-10-27T10:08:10Z
7157,BatchNormalization layer NaN issue,"I made simple model for speech recognition on keras/theano + keras ctc loss function + LibreSpeech dataset. 
Following code is trained on just 2 .wav files and works fine on CPU. But on GPU it gives NaNs on learning loss. I found that removing of BatchNormalization layers removes NaNs from GPU and the model start learning, but I do not want to remove BatchNormalization layers it gives significant/crucial quality boost. So what recommendations you may give me to debug BatchNormalization layers (I tried bigger epsilon but with no help)? 

```
import os
import numpy
import scipy.io.wavfile
from scipy import signal
import matplotlib.pyplot as plt
from keras.layers import Input, Masking, LSTM, Dense, RepeatVector, TimeDistributed, Bidirectional
from keras.models import Model, Sequential
from keras.layers import Reshape, Lambda, Activation
from keras import backend as K
from keras.layers.normalization import BatchNormalization
from keras.optimizers import adam

def formMask(value=90, ingebitor=7):
    m = []
    ind = 0
    for i in range(value):
        start_ind = ind
        for j in range(1 + int(i/ingebitor)):
            ind += 1
        m.append((start_ind, ind))
    return m
m = formMask()

DIR = '/media/aaa/606d36ae-2e4e-4309-b51c-195f788d9111/audio/debug'

def getFiles(dir):
    audio_files = []
    text_files = []
    for root, dirs, files in os.walk(dir):
        for file in files:
            if file.endswith("".wav""):
                audio_files.append(os.path.join(root, file))
            if file.endswith("".trans.txt""):
                text_files.append(os.path.join(root, file))
    name2text = {}
    for file in text_files:
        for line in open(file):
            parts = line.rstrip().split(' ')
            name2text[parts[0]] = (' '.join(parts[1:])).lower()
    file2text = []
    for file in audio_files:
        fname = file.split('/')[-1]
        file2text.append((file, name2text[fname[:-4]]))
    file2text = sorted(file2text)
    return file2text

def produceX(fname, tick_p_sec=16, reduce=True, showplt=0):
    r, snd    = scipy.io.wavfile.read(fname)
    f, t, Zxx = signal.stft(snd, nperseg=r/tick_p_sec)
    Zxx = numpy.absolute(Zxx).astype('float32')
    if reduce:
        Zxx_red = numpy.zeros((90, Zxx.shape[1]), dtype='float32')
        for i in range(len(m)):
            if m[i][0] > Zxx.shape[0]: break
            Zxx_red[i] = numpy.sum(Zxx[m[i][0] : m[i][1]], axis=0) / (m[i][1] - m[i][0])
        Zxx = Zxx_red
        f = range(0, Zxx.shape[0])
    if showplt:
        plt.pcolormesh(t, f, Zxx, vmin=0, vmax=300)
        plt.title('STFT Magnitude')
        plt.ylabel('Frequency [Hz]')
        plt.xlabel('Time [sec]')
        plt.show()
    return Zxx.T

def produceY(text, char2num):
    Y = numpy.zeros(shape=len(text), dtype='int32')
    i = 0
    for c in text:
        if c in char2num:
            Y[i] = char2num[c]
            i += 1
    return Y

def sortData(X, Y, parts=1):
    Sx = []
    Sy = []
    for x, y in zip(X, Y):
        Sx.append(x.shape[0])
        Sy.append(y.shape[0])
    Sx = numpy.array(Sx)
    Sy = numpy.array(Sy)
    I = numpy.argsort(Sx).astype('int32')
    I_s = []
    for part in range(parts):
        a = int(I.shape[0]*part/parts)
        b = int(I.shape[0]*(part + 1)/parts)
        I_s.append(I[a:b])
    data = []
    for I in I_s:
        X_wave   = numpy.zeros(shape=(len(I), max(Sx[I]), X[0].shape[1]), dtype='float32')
        Y_labels = numpy.zeros(shape=(len(I), max(Sy[I])), dtype='int32')
        X_len = numpy.zeros(shape=(len(I)), dtype='int32')
        Y_len = numpy.zeros(shape=(len(I)), dtype='int32')
        for i in range(I.shape[0]):
            size = X[I[i]].shape[0]
            X_wave[i][0:size] = X[I[i]][0:size]
            X_len[i] = size
            size = len(Y[I[i]])
            Y_labels[i][0:size] = Y[I[i]]
            Y_len[i] = size
        data.append((X_wave, Y_labels, X_len, Y_len))
    return data

def DataGenerator(files, batch_size=2):
    X = []
    Y = []
    while(True):
        for batch_num, elem in enumerate(files):
            X.append(produceX(elem[0]))
            Y.append(produceY(elem[1], char2num))
            if (batch_num + 1) % batch_size == 0:
                xsize = numpy.array([x.shape[0] for x in X])
                ysize = numpy.array([y.shape[0] for y in Y])
                xmax = max([x.shape[0] for x in X])
                ymax = max([y.shape[0] for y in Y])
                X_b = numpy.zeros(shape=(batch_size, xmax, X[0].shape[1]))
                Y_b = numpy.zeros(shape=(batch_size, ymax))
                for i in range(X_b.shape[0]):
                    X_b[i][0:xsize[i]] = X[i][0:xsize[i]]
                    Y_b[i][0:ysize[i]] = Y[i][0:ysize[i]]
                yield [X_b, Y_b, xsize, ysize], Y_b
                X = []; Y = []

char2num = {}
num2char = []
for i, c in enumerate(' qwertyuiopasdfghjklzxcvbnm'):
    char2num[c] = i
    num2char.append(c)
num2char = numpy.array(num2char)
files = getFiles(DIR)
print(len(files))

X = []
Y = []
for elem in files:
    X.append(produceX(elem[0]))
    Y.append(produceY(elem[1], char2num))

MODEL_SZ = 600
CHAR_SZ  = len(char2num)
WAVE_SZ = X[0].shape[1]

if 1:
    data = sortData(X, Y)

# the actual loss calc occurs here despite it not being
# an internal Keras loss function

def ctc_loss(x):
    labels, pred, wlen, llen = x
    pred = pred[:, 2:, :]
    return K.ctc_batch_cost(labels, pred, wlen, llen)

inp_wave   = Input(name='INP_W', shape=(None, WAVE_SZ))
inp_labels = Input(name='INP_L', shape=(None, ), dtype='int32')
wave_len   = Input(name='INP_WL', shape=[1], dtype='int32')
labels_len = Input(name='INP_LL', shape=[1], dtype='int32')

inner = LSTM(MODEL_SZ, return_sequences=True)(inp_wave)
inner = BatchNormalization()(inner)
if 0:
    inner = LSTM(int(MODEL_SZ/2), return_sequences=True)(inner)
    inner = BatchNormalization()(inner)

inner  = TimeDistributed(Dense(CHAR_SZ * 3, activation='relu'))(inner)
inner = BatchNormalization()(inner)
inner  = TimeDistributed(Dense(CHAR_SZ, activation='tanh'))(inner)
inner = BatchNormalization()(inner)
y_pred = TimeDistributed(Activation(activation='softmax'))(inner)

y = Lambda(ctc_loss, output_shape=(1,))([inp_labels, y_pred, wave_len, labels_len])

model = Model(inputs=[inp_wave, inp_labels, wave_len, labels_len], outputs=y)
model.compile(loss=lambda y_true, y_pred: y_pred, optimizer='adam')

model_run = Model(inputs=inp_wave, outputs=y_pred)

if False: # Using full education
    for data_part in data:
        D_waves, D_labels, D_w_len, D_l_len = data_part
        print(D_waves.shape, D_labels.shape, D_w_len, D_l_len)
        model.fit(x=[D_waves, D_labels, D_w_len, D_l_len], y=D_w_len, validation_split=0.0, epochs=100)
else: # Using fit generator
    model.fit_generator(generator=DataGenerator(files), steps_per_epoch=len(files), epochs=20)

D_waves, D_labels = data[0][0 : 2]
P = model_run.predict(D_waves)

R_labels = numpy.argmax(P, axis=2)

print('AAAAA: ', R_labels.shape, D_labels.shape, R_labels.dtype, D_labels.dtype)

print(P)
print(R_labels)
print(num2char[R_labels])
print(num2char[D_labels])
```",MaratZakirov,None,2017-06-28T10:19:13Z,2017-07-06T12:54:20Z
7122,Theano TypeError with combination of LSTM and concatenate,"I get an error in `fit` when combining `LSTM`, `TimeDistributed`, and `concatenate` for time series prediction, but only when using only a single LSTM cell. Minimal example:

```
import numpy as np
from keras.models import Model
from keras.layers import Input, Dense, LSTM, TimeDistributed, concatenate

# dummy time series prediction data:
# batch size 32, 100 time steps, 3 inputs/outputs
x = np.random.randn(32, 100, 3)

# number of LSTM cells
N = 1   # it works with N > 1

# create a network for predicting the next time step
input = Input(shape=(99, 3))
lstm = LSTM(N, return_sequences=True)(input)
output = TimeDistributed(Dense(3, activation='softmax'))(concatenate([input, lstm]))
model = Model(inputs=input, outputs=output)
model.compile(loss='mse', optimizer='sgd')

# the following command fails:
model.fit(x[:, :-1, :], x[:, 1:, :], batch_size=1, epochs=1)
```
I get the following error report:
```
Using Theano backend.
Traceback (most recent call last):
  File ""minimal-example.py"", line 21, in <module>
    model.fit(x[:, :-1, :], x[:, 1:, :], batch_size=1, epochs=1)
  File ""/anaconda/lib/python3.6/site-packages/keras/engine/training.py"", line 1458, in fit
    self._make_train_function()
  File ""/anaconda/lib/python3.6/site-packages/keras/engine/training.py"", line 1002, in _make_train_function
    self.total_loss)
  File ""/anaconda/lib/python3.6/site-packages/keras/optimizers.py"", line 128, in get_updates
    grads = self.get_gradients(loss, params)
  File ""/anaconda/lib/python3.6/site-packages/keras/optimizers.py"", line 47, in get_gradients
    grads = K.gradients(loss, params)
  File ""/anaconda/lib/python3.6/site-packages/keras/backend/theano_backend.py"", line 1136, in gradients
    return T.grad(loss, variables)
  File ""/anaconda/lib/python3.6/site-packages/theano/gradient.py"", line 555, in grad
    grad_dict, wrt, cost_name)
  File ""/anaconda/lib/python3.6/site-packages/theano/gradient.py"", line 1317, in _populate_grad_dict
    rval = [access_grad_cache(elem) for elem in wrt]
  File ""/anaconda/lib/python3.6/site-packages/theano/gradient.py"", line 1317, in <listcomp>
    rval = [access_grad_cache(elem) for elem in wrt]
  File ""/anaconda/lib/python3.6/site-packages/theano/gradient.py"", line 1272, in access_grad_cache
    term = access_term_cache(node)[idx]
  File ""/anaconda/lib/python3.6/site-packages/theano/gradient.py"", line 967, in access_term_cache
    output_grads = [access_grad_cache(var) for var in node.outputs]
  File ""/anaconda/lib/python3.6/site-packages/theano/gradient.py"", line 967, in <listcomp>
    output_grads = [access_grad_cache(var) for var in node.outputs]
  File ""/anaconda/lib/python3.6/site-packages/theano/gradient.py"", line 1272, in access_grad_cache
    term = access_term_cache(node)[idx]
  File ""/anaconda/lib/python3.6/site-packages/theano/gradient.py"", line 967, in access_term_cache
    output_grads = [access_grad_cache(var) for var in node.outputs]
  File ""/anaconda/lib/python3.6/site-packages/theano/gradient.py"", line 967, in <listcomp>
    output_grads = [access_grad_cache(var) for var in node.outputs]
  File ""/anaconda/lib/python3.6/site-packages/theano/gradient.py"", line 1272, in access_grad_cache
    term = access_term_cache(node)[idx]
  File ""/anaconda/lib/python3.6/site-packages/theano/gradient.py"", line 967, in access_term_cache
    output_grads = [access_grad_cache(var) for var in node.outputs]
  File ""/anaconda/lib/python3.6/site-packages/theano/gradient.py"", line 967, in <listcomp>
    output_grads = [access_grad_cache(var) for var in node.outputs]
  File ""/anaconda/lib/python3.6/site-packages/theano/gradient.py"", line 1272, in access_grad_cache
    term = access_term_cache(node)[idx]
  File ""/anaconda/lib/python3.6/site-packages/theano/gradient.py"", line 967, in access_term_cache
    output_grads = [access_grad_cache(var) for var in node.outputs]
  File ""/anaconda/lib/python3.6/site-packages/theano/gradient.py"", line 967, in <listcomp>
    output_grads = [access_grad_cache(var) for var in node.outputs]
  File ""/anaconda/lib/python3.6/site-packages/theano/gradient.py"", line 1272, in access_grad_cache
    term = access_term_cache(node)[idx]
  File ""/anaconda/lib/python3.6/site-packages/theano/gradient.py"", line 967, in access_term_cache
    output_grads = [access_grad_cache(var) for var in node.outputs]
  File ""/anaconda/lib/python3.6/site-packages/theano/gradient.py"", line 967, in <listcomp>
    output_grads = [access_grad_cache(var) for var in node.outputs]
  File ""/anaconda/lib/python3.6/site-packages/theano/gradient.py"", line 1272, in access_grad_cache
    term = access_term_cache(node)[idx]
  File ""/anaconda/lib/python3.6/site-packages/theano/gradient.py"", line 967, in access_term_cache
    output_grads = [access_grad_cache(var) for var in node.outputs]
  File ""/anaconda/lib/python3.6/site-packages/theano/gradient.py"", line 967, in <listcomp>
    output_grads = [access_grad_cache(var) for var in node.outputs]
  File ""/anaconda/lib/python3.6/site-packages/theano/gradient.py"", line 1272, in access_grad_cache
    term = access_term_cache(node)[idx]
  File ""/anaconda/lib/python3.6/site-packages/theano/gradient.py"", line 967, in access_term_cache
    output_grads = [access_grad_cache(var) for var in node.outputs]
  File ""/anaconda/lib/python3.6/site-packages/theano/gradient.py"", line 967, in <listcomp>
    output_grads = [access_grad_cache(var) for var in node.outputs]
  File ""/anaconda/lib/python3.6/site-packages/theano/gradient.py"", line 1272, in access_grad_cache
    term = access_term_cache(node)[idx]
  File ""/anaconda/lib/python3.6/site-packages/theano/gradient.py"", line 967, in access_term_cache
    output_grads = [access_grad_cache(var) for var in node.outputs]
  File ""/anaconda/lib/python3.6/site-packages/theano/gradient.py"", line 967, in <listcomp>
    output_grads = [access_grad_cache(var) for var in node.outputs]
  File ""/anaconda/lib/python3.6/site-packages/theano/gradient.py"", line 1272, in access_grad_cache
    term = access_term_cache(node)[idx]
  File ""/anaconda/lib/python3.6/site-packages/theano/gradient.py"", line 1108, in access_term_cache
    new_output_grads)
  File ""/anaconda/lib/python3.6/site-packages/theano/scan_module/scan_op.py"", line 2555, in L_op
    outputs = local_op(*outer_inputs)
  File ""/anaconda/lib/python3.6/site-packages/theano/gof/op.py"", line 615, in __call__
    node = self.make_node(*inputs, **kwargs)
  File ""/anaconda/lib/python3.6/site-packages/theano/scan_module/scan_op.py"", line 463, in make_node
    check_broadcast(outer_seq, inner_seq)
  File ""/anaconda/lib/python3.6/site-packages/theano/scan_module/scan_op.py"", line 434, in check_broadcast
    raise TypeError(msg % (v1.type, v2.type, a1, b1, b2, a2))
TypeError: The broadcast pattern of the output of scan (TensorType(float32, 3D)) is inconsistent with the one provided in `output_info` (TensorType(float32, col)). The output on axis 1 is `False`, but it is `True` on axis 2 in `output_info`. This can happen if one of the dimension is fixed to 1 in the input, while it is still variable in the output, or vice-verca. You have to make them consistent, e.g. using theano.tensor.{patternbroadcast,unbroadcast,addbroadcast}.
```

Interestingly, using `SimpleRNN` or `GRU` instead of `LSTM` fixes the problem, and so does setting `N = 2` or higher. To me, this is a clear indication of a bug, but I don't know whom to blame, keras or theano :) I am using MacOS 10.12.5 (Sierra) and the Anaconda bundle for Python 3.6. Version numbers:
```
Python 3.6.0 |Anaconda 4.3.1 (x86_64)| (default, Dec 23 2016, 13:19:00)
>>> print(theano.__version__)
0.9.0
>>> print(keras.__version__)
2.0.3
```
",TGlas,b'stale',2017-06-25T08:06:26Z,2017-10-23T08:31:21Z
7116,Shared weights are duplicated after save/load model if layers are composed,"The issue appears because of composing the layers: `TimeDistributed(L)`

```python
import keras
from keras import backend as K
from keras.models import Model, load_model
from keras.layers import Input, Dense, Concatenate, Flatten
from keras.layers.wrappers import TimeDistributed
a = Input(shape=(784,5))
b = Input(shape=(784,5))

L = Dense(units=10)

u = TimeDistributed(L)(a)  # u = L(a) works correctly
v = L(b)

x = Concatenate() ([u, v])

model = Model(inputs=[a, b], outputs=x)

print model.count_params() # 120
model.summary() # 60

model.save('tmp.model')

###################################

loaded_model = load_model('tmp.model')

print loaded_model.count_params() # 120
loaded_model.summary() # 120
```

Note that `count_params()` always gives incorrect numbers. Is that another bug?",mahnerak,b'stale',2017-06-24T16:20:21Z,2018-03-04T13:32:52Z
7105,DImensions error in running image_ocr.py,"C:\Anaconda3\python.exe ""C:\Program Files\JetBrains\PyCharm Community Edition 2017.1.3\helpers\pydev\pydevd.py"" --multiproc --qt-support --client 127.0.0.1 --port 36966 --file E:/cliff/Programmer-related/GPU_related/keras学习/keras2.05_examples/image_ocr.py
warning: Debugger speedups using cython not found. Run '""C:\Anaconda3\python.exe"" ""C:\Program Files\JetBrains\PyCharm Community Edition 2017.1.3\helpers\pydev\setup_cython.py"" build_ext --inplace' to build.
pydev debugger: process 95728 is connecting

Connected to pydev debugger (build 171.4424.42)
Using TensorFlow backend.
Traceback (most recent call last):
  File ""C:\Anaconda3\lib\site-packages\tensorflow\python\framework\common_shapes.py"", line 671, in _call_cpp_shape_fn_impl
    input_tensors_as_shapes, status)
  File ""C:\Anaconda3\lib\contextlib.py"", line 89, in __exit__
    next(self.gen)
  File ""C:\Anaconda3\lib\site-packages\tensorflow\python\framework\errors_impl.py"", line 466, in raise_exception_on_not_ok_status
    pywrap_tensorflow.TF_GetCode(status))
tensorflow.python.framework.errors_impl.InvalidArgumentError: Dimensions must be equal, but are 32 and 28 for 'dense2/add' (op: 'Add') with input shapes: [?,32,28], [1,28,1].

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Program Files\JetBrains\PyCharm Community Edition 2017.1.3\helpers\pydev\pydevd.py"", line 1585, in <module>
    globals = debugger.run(setup['file'], None, None, is_module)
  File ""C:\Program Files\JetBrains\PyCharm Community Edition 2017.1.3\helpers\pydev\pydevd.py"", line 1015, in run
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File ""C:\Program Files\JetBrains\PyCharm Community Edition 2017.1.3\helpers\pydev\_pydev_imps\_pydev_execfile.py"", line 18, in execfile
    exec(compile(contents+""\n"", file, 'exec'), glob, loc)
  File ""E:/cliff/Programmer-related/GPU_related/keras学习/keras2.05_examples/image_ocr.py"", line 501, in <module>
    train(run_name, 0, 20, 128)
  File ""E:/cliff/Programmer-related/GPU_related/keras学习/keras2.05_examples/image_ocr.py"", line 464, in train
    name='dense2')(concatenate([gru_2, gru_2b]))
  File ""C:\Anaconda3\lib\site-packages\keras\engine\topology.py"", line 596, in __call__
    output = self.call(inputs, **kwargs)
  File ""C:\Anaconda3\lib\site-packages\keras\layers\core.py"", line 845, in call
    output = K.bias_add(output, self.bias)
  File ""C:\Anaconda3\lib\site-packages\keras\backend\tensorflow_backend.py"", line 3389, in bias_add
    x += reshape(bias, (1, bias_shape[0], 1))
  File ""C:\Anaconda3\lib\site-packages\tensorflow\python\ops\math_ops.py"", line 838, in binary_op_wrapper
    return func(x, y, name=name)
  File ""C:\Anaconda3\lib\site-packages\tensorflow\python\ops\gen_math_ops.py"", line 67, in add
    result = _op_def_lib.apply_op(""Add"", x=x, y=y, name=name)
  File ""C:\Anaconda3\lib\site-packages\tensorflow\python\framework\op_def_library.py"", line 767, in apply_op
    op_def=op_def)
  File ""C:\Anaconda3\lib\site-packages\tensorflow\python\framework\ops.py"", line 2508, in create_op
    set_shapes_for_outputs(ret)
  File ""C:\Anaconda3\lib\site-packages\tensorflow\python\framework\ops.py"", line 1873, in set_shapes_for_outputs
    shapes = shape_func(op)
  File ""C:\Anaconda3\lib\site-packages\tensorflow\python\framework\ops.py"", line 1823, in call_with_requiring
    return call_cpp_shape_fn(op, require_shape_fn=True)
  File ""C:\Anaconda3\lib\site-packages\tensorflow\python\framework\common_shapes.py"", line 610, in call_cpp_shape_fn
    debug_python_shape_fn, require_shape_fn)
  File ""C:\Anaconda3\lib\site-packages\tensorflow\python\framework\common_shapes.py"", line 676, in _call_cpp_shape_fn_impl
    raise ValueError(err.message)
ValueError: Dimensions must be equal, but are 32 and 28 for 'dense2/add' (op: 'Add') with input shapes: [?,32,28], [1,28,1].




---------------
##### As I can not pip install editdistance, I used python-Levenshtein  instead
    import Levenshtein  
##### and use Levenshtein.disntance() to replace editdistance.eval()
but i don't think this will cause the error above

",cliff007,None,2017-06-23T08:51:41Z,2017-07-05T09:14:43Z
7081,unexpected initialization of tensorflow variables in `Model.save()`,"Tensorflow variables which is not used in model are initialized when `model.save()` is called.

```python
def unexpected_initialization():
    sess = tf.Session()
    K.set_session(sess)

    var_global_step = tf.Variable(0, trainable=False)

    x = L.Input((8,))
    y = L.Dense(2)(x)
    model = Model(x, y)

    sess.run(tf.global_variables_initializer())

    step_initial = sess.run(var_global_step)
    print(' initial step: {}'.format(step_initial)) # -> outputs 0

    sess.run(var_global_step.assign(16))

    step_assigned = sess.run(var_global_step)
    print('assigned step: {}'.format(step_assigned)) # -> outputs 16 

    model.save('model.h5')

    step_saved = sess.run(var_global_step)
    print('   saved step: {}'.format(step_saved)) # -> outputs 0 !!!!!! expected 16
```

If the model have no layers, this unexpected initialization is not occurred.  (See [my gist](https://gist.github.com/cocuh/148a8b87f9693508d9b9d2a95efe1b61))

I sought cause of this bug, but I didn't find it....

Note: This keras and tensorflow combination technique is introduced in [official keras blog](https://blog.keras.io/keras-as-a-simplified-interface-to-tensorflow-tutorial.html). So I think this code is not tricky, and keras should fix this bug.",cocuh,b'stale',2017-06-21T16:33:52Z,2018-06-17T09:34:08Z
7075,mnist_tfrecord.py added,"This PR implements an mnist run via a TFRecord dataset.

This PR requires https://github.com/fchollet/keras/pull/7060 to be merged first.

Also see for details:

- #6928 yield_ops with `labels` param
- #7075/#7046 internal fixes to `Model()`

**Update:** Performance bug Fixed by defaulting `compile(loss=None)`

It seems with the current implementation, the **external loss version suffers from 20x performance degradation** compared to `mnist_tfrecord.py` in #6928 which has a more direct C++ backend pipeline.

- **internal_fixes_tfrecord #7075/#7046**
  - Test accuracy: 0.795400005609
  - Training time: 23:17.18 (m:s) total
  - `mnist_tfrecord.py` with external loss

- **yield_ops #6928**
  - Test accuracy: 0.967999995768
  - Training time: 1:22.24 (m:s) total
  - `mnist_tfrecord.py` with internal loss and no `K.placeholder()` objects

- **mnist_cnn.py**
  - Test accuracy: 0.9902
  - Training time: 1:13.12 (m:s) total

Note that the slightly lower performance of mnist_tfrecord.py #6928 is expected, because it is a pipeline designed for quickly loading large datasets that don't fit in memory, and writing the records and graph setup takes several extra seconds.

other relevant PRs: #7061, #7072, #6928, #7046

",ahundt,None,2017-06-21T07:34:09Z,2017-08-05T01:10:24Z
7072,"reorganize training.py, code is clearer and handles more corner cases…","This is the final item in the [PR chain](https://github.com/fchollet/keras/pull/7072#issuecomment-311174255) necessary to support input tensors. Here is an overview of what will be supported:

```python
# tf yield ops such as those created by the tf `RecordInput()` API
# which supply dataset images and labels
x_train_batch, y_train_batch = read_and_decode_recordinput(...)

# create a basic cnn
x_train_input = Input(tensor=x_train_batch)
x_train_out = cnn_layers(x_train_input)

# y label batch is input & output
# Perhaps this aspect of API usage can be improved?
y_train_in = Input(tensor=y_train_batch)

# ==bugfix==
# This call causes a crash without this patch because
# an invalid call is made that is equivalent to:
# K.placeholder(dtype=x_train_input)
train_model = Model(inputs=[x_train_in], outputs=[x_train_out])

# ==bugfix==
# This call will crash without this patch because
# it is assumed the parameters `x` and `y` are
# provided here and not via the ops
# x_train_batch and y_train_batch 
train_model.compile(optimizer='rmsprop',
                    loss='categorical_crossentropy',
                    metrics=['accuracy'])

# ==bugfix== + ==new param==
# This call will crash without this patch because
# the changes in tensor order caused by the
# constructor update, which accepts yield ops,
# were not previously accounted for.
#
# A new param steps_per_epoch is added
# which works just like in fit_generator()
train_model.fit(None, y_train_in, 
                batch_size=batch_size,
                epochs=epochs,
                steps_per_epoch=10000)
```

The combined version of these changes (with more detail) is in #6928.

Changes to `class Model(Container)`:
- relocate `_prepare_sample_weights()` to be a distinct function
- define `_make_ins()` so backend `Function()` params are created consistently
- add additional checks to `None` in many places
- raise errors in additional exceptional situations
- add `_make_function()` so all utilities that create an instance of `backend.Function()` behave consistently (modulo deliberate / correct differences)

Depends on:
#7067, #7066 

Additional fixes in:
#7064, #7067, #7068, #7069, #7071, #7072 

Tested by:
#7061 

Also see the comments by @Dref360 on the equivalent changes. https://github.com/fchollet/keras/pull/7046#pullrequestreview-45220368

**Note:** travis failure will be resolved once dependencies above are merged",ahundt,b'stale',2017-06-21T05:05:26Z,2017-10-31T22:41:31Z
7057,Feature proposal: detect dead ReLUs,"Some ReLU neurons never fire during entire training epoch due to their unlucky weights. Since they are flat on negative input, their gradient is zero. Hence, their weights are not updated. Hence, they are not trained and are essentially useless.
Additionally, too high learning rate can eventually push neuron's weights into the never-active zone, knocking it out from training.
This problem (often referenced as ""dead ReLU"") is very common but somewhat tricky to debug because internal state of NN is obscure.
I think it would be nice to have callback that will check for dead ReLU after each training epoch and warn user so he can change initialization scheme, reduce learning rate etc.

I have very crude implementation of the feature here:  https://github.com/fchollet/keras/pull/7056
If community and maintainers agree this makes sense I will finalize this PR",arodiss,None,2017-06-20T19:02:08Z,2018-05-28T20:44:58Z
7044,ConvLSTM2D: return_sequences=False returns a 5D tensor (should return 4D),"According to `ConvLSTM2D` documentation, when `return_sequences=False`, the `ConvLSTM2D` is supposed to only return the last element of the sequence.  Specifically:

```
     # Output shape
        - if `return_sequences`
             - if data_format='channels_first'
                5D tensor with shape:
                `(samples, time, filters, output_row, output_col)`
             - if data_format='channels_last'
                5D tensor with shape:
                `(samples, time, output_row, output_col, filters)`
        - else
            - if data_format ='channels_first'
                4D tensor with shape:
                `(samples, filters, output_row, output_col)`
            - if data_format='channels_last'
                4D tensor with shape:
                `(samples, output_row, output_col, filters)`
            where o_row and o_col depend on the shape of the filter and
            the padding
```

But setting `return_sequences=False` seem to have no effect and the layer continues to return a 5-d tensor.

Is this a bug?  Is there a workaround?

Here is my code:

```
def create_model(input_shape):

    num_filters = 15
    model = Sequential()
    model.add(ConvLSTM2D(filters=num_filters, kernel_size=(3, 3),
                         # input_shape=(None, 40, 40, 1),
                         input_shape=input_shape,
                         padding='same', return_sequences=True))
    model.add(BatchNormalization())

    model.add(ConvLSTM2D(filters=num_filters/2, kernel_size=(3, 3),
                         padding='same', return_sequences=True))
    model.add(BatchNormalization())

    model.add(ConvLSTM2D(filters=num_filters, kernel_size=(3, 3),
                         padding='same', return_sequences=False))
    model.add(BatchNormalization())

    model.add(Conv2D(filters=1, kernel_size=(3, 3),
                     activation='sigmoid',
                     padding='same', data_format='channels_last'))

    opt = optimizers.Adam(lr=1e-4)
    model.compile(loss='mae', optimizer=opt, metrics=[metrics.mae])

    return model
```
",rawmean,None,2017-06-19T23:30:06Z,2018-01-31T10:52:15Z
7041,Loading models with shared layers,"Fixed a problem that occurs when trying to load a model with shared layers that are connected with themselves in the calling order.

I've also added a test for this case.

This fixes Bug #6481",javiercorrea,None,2017-06-19T15:12:34Z,2017-08-07T15:21:47Z
7040,Fixed default header in RemoteMonitor callback.,"When using the `RemoteMonitor` callback the headers sent with the request to the remote server defaulted to `{'Accept': 'application/json', 'Content-Type': 'application/json'}`. However, the request sent is not of type `application/json` but rather `application/x-www-form-urlencoded`. This led to some confusion when implementing a custom remote server.

Also, the [hualos](https://github.com/fchollet/hualos/) project breaks because of this bug.

This PR changes the default `Content-Type` header to `application/x-www-form-urlencoded`.",sebastianbk,None,2017-06-19T12:47:34Z,2017-06-20T17:20:29Z
7039,Using Keras to write my own Layer,"When I use Keras to write my own Layer as follows:

    def call(self, inputs):
    out = K.variable(np.zeros(shape=(1,self.output_dim),
                      dtype='float32'))
    for i in range(K.int_shape(inputs)[-1]):
        dui_jiao_c = np.zeros(shape=(K.int_shape(inputs)[-1],K.int_shape(inputs)[-1]),
                             dtype='float32')
        dui_jiao_o = np.eye(N=K.int_shape(inputs)[-1],
                             dtype='float32')
        dui_jiao_c[i,i] = 1
        dui_jiao_o[i,i] = 0

        out += T.mul(K.dot(K.dot(inputs,dui_jiao_c),self.kernel),
                     K.dot(K.dot(inputs,dui_jiao_o),self.kernel))


    return out
    
After compiling model,I try to fit data:           `model.fit(train,label,batch_size=10,epochs=20,verbose=1,shuffle=True)`  
and it raises error:
  
    ValueError: Input dimension mis-match. (input[0].shape[0] = 10,input[18].shape[0] = 1)
    Apply node that caused the error: Elemwise{Composite{((i0 * i1) + (i2 * i3) + (i4 * i5) + (i6 * i7) + (i8 * i9) + (i10 * i11) + (i12 * i13) + (i14* i15) + (i16 * i17) + i18 + (i19 * i20))}}(Dot22.0, Dot22.0, Dot22.0, Dot22.0,Dot22.0, Dot22.0, Dot22.0, Dot22.0, Dot22.0, Dot22.0, Dot22.0, Dot22.0, Dot22.0, Dot22.0, Dot22.0, Dot22.0, Dot22.0, Dot22.0, pair_wise_layer_1/variable, Dot22.0, Dot22.0)
    Toposort index: 75
    Inputs types: [TensorType(float32, matrix), TensorType(float32, matrix),TensorType(float32, matrix), TensorType(float32, matrix), TensorType(float32, matrix), TensorType(float32, matrix), TensorType(float32, matrix), TensorType(float32, matrix), TensorType(float32, matrix), TensorType(float32, matrix), TensorType(float32, matrix), TensorType(float32, matrix), TensorType(float32, matrix), TensorType(float32, matrix), TensorType(float32, matrix), TensorType(float32, matrix), TensorType(float32, matrix), TensorType(float32, matrix), TensorType(float32, matrix), TensorType(float32, matrix), TensorType(float32, matrix)]
    Inputs shapes: [(10L, 4L), (10L, 4L), (10L, 4L), (10L, 4L), (10L, 4L), (10L, 4L), (10L, 4L), (10L, 4L), (10L, 4L), (10L, 4L), (10L, 4L), (10L, 4L), (10L, 4L), (10L, 4L), (10L, 4L), (10L, 4L), (10L, 4L), (10L, 4L), (1L, 4L), (10L, 4L), (10L, 4L)]
    Inputs strides: [(16L, 4L), (16L, 4L), (16L, 4L), (16L, 4L), (16L, 4L), (16L, 4L), (16L, 4L), (16L, 4L), (16L, 4L), (16L, 4L), (16L, 4L), (16L, 4L), (16L, 4L), (16L, 4L), (16L, 4L), (16L, 4L), (16L, 4L), (16L, 4L), (16L, 4L), (16L, 4L), (16L, 4L)]
    Inputs values: ['not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', array([[ 0.,  0.,  0.,  0.]], dtype=float32), 'not shown', 'not shown']
    Outputs clients: [[InplaceDimShuffle{1,0}(Elemwise{Composite{((i0 * i1) + (i2 * i3) + (i4 * i5) + (i6 * i7) + (i8 * i9) + (i10 * i11) + (i12 * i13) + (i14 * i15) + (i16 * i17) + i18 + (i19 * i20))}}.0), Gemm{no_inplace}(/dense_1_target, TensorConstant{1.0}, Elemwise{Composite{((i0 * i1) + (i2 * i3) + (i4 * i5) + (i6 * i7) + (i8 * i9) + (i10 * i11) + (i12 * i13) + (i14 * i15) + (i16 * i17) + i18 + (i19 * i20))}}.0, dense_1/kernel, TensorConstant{-1.0})]]

    HINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.
    HINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.
If the pramater `batch_size=1` it could work.  
I am confused,what should I do",Holy-Shine,None,2017-06-19T12:16:28Z,2017-06-20T15:44:28Z
7038,"throw an error when receiving empty batch, instead of returning nans","Currently, when `evaluate_generator` receives an empty batch, it will return nans because of the `np.average` at the end.

When I encountered a bug in my code that triggered this, I thought that my network was overflowing somewhere, resulting in hours of debugging the network.

I therefore propose throwing an exception when this happens.

",gewoonrik,None,2017-06-19T11:59:32Z,2017-06-19T18:23:42Z
7036,Remove requirement that batch_size divides len(x_train) in VAE example,"Currently the Variational Auto Encoder example fails when the training set size is not a multiple of the batch size (related to #5255, and in a way to #3332).

This PR changes the input shape of the layers where batch_size was explicit, to allow any number of examples thus removing the problem.

The [blog quoting this code](https://blog.keras.io/building-autoencoders-in-keras.html) should probably also be updated.

Bug reproducibility steps:
- change the batch size (examples/variational_autoencoder.py line 15) to something that doesn't divide mnist train set size, for instance 51
- run examples/variational_autoencoder.py

",Raphael-Manakin,None,2017-06-19T08:26:11Z,2017-08-08T17:42:35Z
7033,wrappers_test.py TimeDistributed may be buggy,"This adds a test that illustrates a bug in TimeDistributed, where dropout does not appear to match the expected behavior for inputs with large dimensions. The following test fails:

```python
@keras_test
@pytest.mark.skipif((K.backend() == 'cntk'),
                    reason='cntk does not support dropout yet')
def test_TimeDistributed_learning_phase():
    # test layers that need learning_phase to be set
    np.random.seed(1234)
    width = 105
    height = 101
    time = 102
    x = Input(shape=(width, height))
    y = wrappers.TimeDistributed(core.Dropout(.999))(x, training=True)
    model = Model(x, y)
    y = model.predict(np.random.random((time, width, height)))
    np.testing.assert_allclose(np.mean(y), 0., atol=1e-1, rtol=1e-1)
```

This PR was originally created for the following flaky test:
https://github.com/fchollet/keras/commit/a625fcde5cb6a1a170a51690d21b575c0e7884c1#diff-a60adf725df8a5eed11441fb09ae7fb0R98",ahundt,None,2017-06-19T04:48:56Z,2017-08-17T00:22:12Z
7027,Add FAQ section for creating reproducible results,"Based on the outcome of a recent github conversation about reproducibility, a section of python code was developed that illustrate how to get reproducible results from run-to-run, which can help debugging and comparisons during development.  I summarized the most recent code example from the github thread and added some commentary text in the FAQ to explain it.  The discussion thread is here:  https://github.com/fchollet/keras/issues/2280#issuecomment-306959926

Thanks.",td2014,None,2017-06-18T21:07:10Z,2017-07-11T02:31:49Z
6989,Setting image_dim_ordering or image_data_format explicitly as per Theano requirements while using Theano Backend gives error,"I'm using Keras on a CPU with 8GB RAM in anaconda.

Here's what I was trying to do.
I have simple script that reads an image, runs it through VGG16 and extracts features from the 'fc1' layer. I decided to time this wrt Tensorflow and Theano backend.

Tensorflow Backend on running `$ python extractvgg.py`
```
{
  ""image_data_format"": ""channels_last"",
  ""predict time"": 1.0201201179997952,
  ""preprocessing time"": 0.012538709999716957,
  ""load time"": 2.1383959619997768,
  ""image_dim_ordering"": ""tf""
}
```
Theano Backend on running `$ KERAS_BACKEND=""theano"" python extractvgg.py `
```
{
  ""image_data_format"": ""channels_last"",
  ""predict time"": 3.185495815000195,
  ""preprocessing time"": 0.016582568000103493,
  ""load time"": 8.029607248000048,
  ""image_dim_ordering"": ""tf""
}
```

Theano was slower, but this was contrary to what I read on other issues. I figured this could be because the image_dim_ordering was still set to 'tf' so I explicitly set these values.
```
from keras import backend as K
K.set_image_data_format(""channels_first"")
K.set_image_dim_ordering(""th"")
```
Now on running 

`$ KERAS_BACKEND=""theano"" python extractvgg.py `

Which gives me the error (The model loads fine, the error occurs upon prediction).

```
/home/kaushiksk/miniconda2/envs/tf/lib/python3.5/site-packages/keras/legacy/interfaces.py:86: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=/input_1, outputs=Elemwise{m...)`
  '` call to the Keras 2 API: ' + signature)
Load time:  22.938760344000002
Preprocess time:  0.016467333000036888
Traceback (most recent call last):
  File ""/home/kaushiksk/miniconda2/envs/tf/lib/python3.5/site-packages/theano/compile/function_module.py"", line 884, in __call__
    self.fn() if output_subset is None else\
ValueError: Input dimension mis-match. (input[1].shape[1] = 3, input[2].shape[1] = 64)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""extractvgg.py"", line 32, in <module>
    features = model.predict(x)
  File ""/home/kaushiksk/miniconda2/envs/tf/lib/python3.5/site-packages/keras/engine/training.py"", line 1572, in predict
    batch_size=batch_size, verbose=verbose)
  File ""/home/kaushiksk/miniconda2/envs/tf/lib/python3.5/site-packages/keras/engine/training.py"", line 1202, in _predict_loop
    batch_outs = f(ins_batch)
  File ""/home/kaushiksk/miniconda2/envs/tf/lib/python3.5/site-packages/keras/backend/theano_backend.py"", line 1071, in __call__
    return self.function(*inputs)
  File ""/home/kaushiksk/miniconda2/envs/tf/lib/python3.5/site-packages/theano/compile/function_module.py"", line 898, in __call__
    storage_map=getattr(self.fn, 'storage_map', None))
  File ""/home/kaushiksk/miniconda2/envs/tf/lib/python3.5/site-packages/theano/gof/link.py"", line 325, in raise_with_op
    reraise(exc_type, exc_value, exc_trace)
  File ""/home/kaushiksk/miniconda2/envs/tf/lib/python3.5/site-packages/six.py"", line 685, in reraise
    raise value.with_traceback(tb)
  File ""/home/kaushiksk/miniconda2/envs/tf/lib/python3.5/site-packages/theano/compile/function_module.py"", line 884, in __call__
    self.fn() if output_subset is None else\
ValueError: Input dimension mis-match. (input[1].shape[1] = 3, input[2].shape[1] = 64)
Apply node that caused the error: Elemwise{Composite{(i0 * ((i1 + i2) + Abs((i1 + i2))))}}[(0, 1)](TensorConstant{(1, 1, 1, 1) of 0.5}, CorrMM{half, (1, 1), (1, 1)}.0, InplaceDimShuffle{x,0,x,x}.0)
Toposort index: 43
Inputs types: [TensorType(float32, (True, True, True, True)), TensorType(float32, 4D), TensorType(float32, (True, False, True, True))]
Inputs shapes: [(1, 1, 1, 1), (1, 3, 224, 225), (1, 64, 1, 1)]
Inputs strides: [(4, 4, 4, 4), (604800, 201600, 900, 4), (256, 4, 4, 4)]
Inputs values: [array([[[[ 0.5]]]], dtype=float32), 'not shown', 'not shown']
Outputs clients: [[CorrMM{half, (1, 1), (1, 1)}(Elemwise{Composite{(i0 * ((i1 + i2) + Abs((i1 + i2))))}}[(0, 1)].0, Subtensor{::, ::, ::int64, ::int64}.0)]]

HINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.
HINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.

```
[Here](https://gist.github.com/kaushiksk/e6975b9afdff5bbe73e7a703c715b8c6) is the link to the Github Gist containing both scripts

- [x] Check that you are up-to-date with the master branch of Keras. You can update with:
pip install git+git://github.com/fchollet/keras.git --upgrade --no-deps
- [x] If running on Theano, check that you are up-to-date with the master branch of Theano. You can update with:
pip install git+git://github.com/Theano/Theano.git --upgrade --no-deps
- [x] Provide a link to a GitHub Gist of a Python script that can reproduce your issue (or just copy the script here if it is short).
",kaushiksk,b'stale',2017-06-14T17:02:36Z,2017-10-17T05:58:09Z
6986,Need a small change in code of ltm_text_generation,"I run this code on my local machine and also on the cloud. and it says unknown keyword argument. I think this is a bug.


`Corpus length: 600893
total chars: 57
nb sequences: 200285
Vectorization...
Build model...

--------------------------------------------------
Iteration 1
---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
<ipython-input-11-ad0b8c227f95> in <module>()
     73     model.fit(X, y,
     74               batch_size=128,
---> 75               epochs=1)
     76 
     77     start_index = random.randint(0, len(text) - maxlen - 1)


/usr/local/lib/python3.5/site-packages/keras/models.py in fit(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)
    659         if kwargs:
    660             raise TypeError('Received unknown keyword arguments: ' +
--> 661                             str(kwargs))
    662         return self.model.fit(x, y,
    663                               batch_size=batch_size,

TypeError: Received unknown keyword arguments: {'epochs': 1}`",prakritidev,b'stale',2017-06-14T13:45:40Z,2017-10-12T14:28:54Z
6983,Strange training behaviour using categorical_crossentropy on output from softmax,"I'm using `keras==2.04` and `tensorflow==1.1.0` and I'm experiencing following problem.

When I am plying with custom ResNet50 for semantic segmentation that ends by the softmax activation that goes straight to the `losses.categorical_crossentropy()` function, then following things are  happening to me (multiple times on different types of datasets):
![image](https://user-images.githubusercontent.com/1810839/27129889-3fe6f8c0-5104-11e7-8906-448ae1909c3a.png)
![image](https://user-images.githubusercontent.com/1810839/27129904-4b4a054a-5104-11e7-86ac-2473af1c0db6.png)
![image](https://user-images.githubusercontent.com/1810839/27129918-57ad847e-5104-11e7-966b-0ace35e97f02.png)


I have managed to fix this thing by 2 different approaches:

1. ~~This seems to me rather as a hack, use clipvalue for gradient => but the training does not goes well (loss and accuracy are still pretty much the same)~~
2. **Have ""raw"" logits as the output from the ResNet50 and use basically else condition from `losses. categorical_crossentropy()`, so `tf.nn.softmax_cross_entropy_with_logits()`, here everything seems to be working as expected**

eg.
experiment on dataset1:
![screen shot 2017-06-14 at 09 50 34](https://user-images.githubusercontent.com/1810839/27130665-8a5813d2-5107-11e7-8b34-81e5a31b63c8.png)
![screen shot 2017-06-14 at 09 50 49](https://user-images.githubusercontent.com/1810839/27130678-92dbaa50-5107-11e7-82a6-18bee68e4996.png)
![screen shot 2017-06-14 at 09 51 02](https://user-images.githubusercontent.com/1810839/27130684-98a25a7e-5107-11e7-93b5-bf14ba4466a4.png)

experiment on dataset2:
![screen shot 2017-06-14 at 13 40 55](https://user-images.githubusercontent.com/1810839/27130687-9f56b7e8-5107-11e7-812c-540943e49322.png)
![screen shot 2017-06-14 at 13 41 07](https://user-images.githubusercontent.com/1810839/27130694-a43ec9b2-5107-11e7-9cce-fd4d487f3570.png)
![screen shot 2017-06-14 at 13 41 18](https://user-images.githubusercontent.com/1810839/27130701-aa9af358-5107-11e7-9a53-413dea6f50b9.png)



I assume that there is some bug somewhere here https://github.com/fchollet/keras/blob/master/keras/backend/tensorflow_backend.py#L2745 I'd expect that there might be performed division by 0 here or loss becomes negative at some time?

",ziky90,b'stale',2017-06-14T11:59:06Z,2017-10-12T12:28:55Z
6960,Fix bug in `preprocess_weights_for_loading` ,"Function `preprocess_weights_for_loading` enumerate different types of layers before converting weights from Keras-1 format to Keras-2 format. However, it misses a case that `Model` (or `Sequential`) can also be a layer and fails to handle the inner layers of layer of type `Model`.

I also report an issue in https://github.com/fchollet/keras/issues/6952",Shaofanl,None,2017-06-12T10:13:00Z,2017-06-20T17:21:15Z
6928,Input Tensors: High Performance Large Datasets via TFRecords,"Implements the Input Tensor API detailed in https://github.com/fchollet/keras/issues/7102#issuecomment-310809267

**Update (2017-08-08):** Two supported use cases based on reviews:

```python

# API 2

model = # on top of a tensor input
model.add_loss()  # involving y_tensor
model.fit(epochs=10, steps_per_epoch=1000)

# API 3

model = # on top of a tensor input
model.compile()
model.fit(y=y_tensor, epochs=10, steps_per_epoch=1000)
```

API usage, with [working mnist_tfrecord.py implementation](https://github.com/ahundt/keras/blob/tfrecord/examples/mnist_tfrecord.py#L176).


### Summary 

This PR adds support for yield ops to Keras plus an example utilizing TFRecords. Correct support for yield ops in `Model` adds valuable functionality not currently supported by Keras for the reasons detailed below. 

It re-compiles on demand when tensors are passed to `y` in `model.fit()`.

#### Yield ops

Yield ops aka data tensors, such as [RecordInput](https://github.com/tensorflow/tensorflow/blob/833252af72af56661aefb0541163109132f9d4a6/tensorflow/python/ops/data_flow_ops.py#L2137) ([test code](https://github.com/tensorflow/tensorflow/blob/833252af72af56661aefb0541163109132f9d4a6/tensorflow/python/kernel_tests/record_input_test.py#L70)), are different from `tf.Variable` because they provide data entirely on the C++ side when run without `fetches` or `feed_dict`, and are thus extremely efficient for large data like images. 

#### Changes

Here are the changes, marked with ==bugfix== and ==new param== in the comments below:

```python
# tf yield ops that supply dataset images and labels
x_train_batch, y_train_batch = read_and_decode_recordinput(...)

# create a basic cnn
x_train_input = Input(tensor=x_train_batch)
x_train_out = cnn_layers(x_train_input)

# y label batch is input & output
# Perhaps this aspect of API usage can be improved?
y_train_in = Input(tensor=y_train_batch)

# ==bugfix==
# This call causes a crash without this patch because
# an invalid call is made that is equivalent to:
# K.placeholder(dtype=x_train_input)
train_model = Model(inputs=[x_train_in], outputs=[x_train_out])

# ==bugfix==
# This call will crash without this patch because
# it is assumed the parameters `x` and `y` are
# provided here and not via the ops
# x_train_batch and y_train_batch 
train_model.compile(optimizer='rmsprop',
                    loss='categorical_crossentropy',
                    metrics=['accuracy'])

# ==bugfix== + ==new param==
# This call will crash without this patch because
# the changes in tensor order caused by the
# constructor update, which accepts yield ops,
# were not previously accounted for.
#
# A new param steps_per_epoch is added
# which works just like in fit_generator()
train_model.fit(None, y_train_in, 
                batch_size=batch_size,
                epochs=epochs,
                steps_per_epoch=10000)
```

There are extended unit tests and support for Input Tensors with each of the following APIs given an Input Tensor (aka yield op) `x` and `y`:

```python

    # train_on_batch
    out = model.train_on_batch(x, y)

    # test_on_batch
    out = model.test_on_batch(x, y)

    # predict_on_batch
    out = model.predict_on_batch(x)

    # fit
    out = model.fit(x, y, epochs=1, batch_size=batch_size,
                    steps_per_epoch=steps_per_epoch)

    # evaluate
    out = model.evaluate(x, y, batch_size=batch_size,
                         steps=steps_per_epoch)

    # predict
    out = model.predict(x, batch_size=batch_size,
                        steps=steps_per_epoch)
```

#### TFRecord

TFRecord support is a side effect and key motivator of yield op support, and [examples/mnist_tfrecord.py](https://github.com/ahundt/keras/blob/b7d44a54ffee3391135abd3a3566a9c0d20a2fa8/examples/mnist_tfrecord.py) demonstrates usage.


**Update:** I've moved the `fetches` and `feed_dict` public API design into #6974. This PR now focuses more narrowly on supporting an input tensor `yield_op` as a parameter.

### Performance Update

This latest version runs mnist_tfrecord.py twice as fast as it did previously!",ahundt,b'stale',2017-06-10T10:02:35Z,2017-11-23T03:06:38Z
6923,add a tensorflow check_numerics operation,"I would like to hunt for nans in my custom loss function.
In tensorflow there is an operation to raise an error on the first encounter of nan: 

https://www.tensorflow.org/api_docs/python/tf/add_check_numerics_ops
https://stackoverflow.com/questions/34046048/debugging-nans-in-the-backward-pass

According to SO, it is to be used like this:

```
train_op = ...
check_op = tf.add_check_numerics_ops()

sess = tf.Session()
sess.run([train_op, check_op])  # Runs training and checks for NaNs
```

How do I integrate this into a Keras loss function?

I checked the sourcecode. The update step is executed here: https://github.com/fchollet/keras/blob/master/keras/engine/training.py

There is a function called `_make_train_function `where an operation to compute the loss and apply updates is created. This is later called to train the network.

I could change the code like this (always assuming that we're running on a tf backend):

```
check_op = tf.add_check_numerics_ops()

self.train_function = K.function(inputs, 
    [self.total_loss] + self.metrics_tensors + [check_op],
    updates=updates, name='train_function', **self._function_kwargs)
```
I'm currently trying to set this up properly and not sure whether the code above actually works. Maybe there is an easier way ?",lhk,b'stale',2017-06-09T16:49:08Z,2017-12-10T21:26:09Z
6916,Fix a bug when training with sparse matrices,"model.fit assumes it can figure out the size of the input.

A broader question: maybe I should replace all those `len(x[0])` in the file with `x[0].shape[0]`?",maximsch2,None,2017-06-09T00:07:07Z,2017-06-09T04:44:07Z
6903,multi-output models not binarized,"I have a functional model that takes one input and has two output layers, as follows:

```
input_img= Input(shape=input_s, name='patch_input', dtype='float')
common_rep = modelVGG(image_input_shape)

tower_d = Convolution2D(64, 3, 3, border_mode='same', activation='relu')(common_rep)
tower_d = Convolution2D(64, 3, 3, border_mode='same', activation='relu')(tower_d)
tower_d = Flatten()(tower_d)
tower_d = Dropout(0.5)(tower_d)
tower_d = Dense(output_dim=43)(tower_d)
tower_d = Activation('softmax', name='output_1')(tower_d)

tower_s = Convolution2D(64, 3, 3, border_mode='same', activation='relu')(common_rep)
tower_s = Convolution2D(64, 3, 3, border_mode='same', activation='relu')(tower_s)
tower_s = Flatten()(tower_s)
tower_s = Dropout(0.5)(tower_s)
tower_s = Dense(output_dim=25)(tower_s)
tower_s = Activation('softmax', name='output_2')(tower_s)

model = Model(input=input_img, output=[tower_d, tower_s])
```

The model compiles correctly

```
adam = Adam(lr=0.001, decay=0.1)
model.compile(loss={'output_1': 'categorical_crossentropy', 'output_2': 'categorical_crossentropy'},
			optimizer=adam,
			metrics=['fbeta_score'])
```

In the custom data generator i am using the following: 

```
def createGenerator(X, D, S,batch_size=8):
	while True:
			datagen = ImageDataGenerator(
				rescale=1./255,
				samplewise_center=True,
				samplewise_std_normalization=True)

		batches = datagen.flow(X[idx], D[idx], batch_size, shuffle=False)
		idx0 = 0
		for batch in batches:
			idx1 = idx0 + batch[0].shape[0]
			# print ""idx inside function "", idx1
			print 'before yield', batch[0].shape,  batch[1].shape
			print batch[1]
			yield batch[0], {'output_1':  D[idx[idx0:idx1]], 'output_2': S[idx[idx0:idx1]]]}

			idx0 = idx1
			if idx1 >= X.shape[0]:
				break
````

The model.fit_generator puts out the error that ""output_1"" tensor expects (None, 43) but found (8, 1). Implying that the individual outputs are not being converted to one-hot vectors. Is this a bug in fit?

EDIT: Can confirm that the code works when the output_1 and output_2 labels are vectorized in the datagenerator code using `from sklearn.preprocessing import LabelBinarizer`",samarth-b,b'stale',2017-06-08T10:22:54Z,2017-10-08T03:03:14Z
6891,Fix the ordering bugs when using pickle_safe=True,"This PR is to fix the multiples problems with GeneratorEnqueuer. When `pickle_safe=True`, the order is not preserved which can be annoying for `predict_generator`. The structure is like Pytorch's Dataset http://pytorch.org/docs/data.html. 

This PR guarantee that the order will be preserved at no cost.

While GeneratorEnqueuer is still supported, it should be deprecated in favour of this new feature.

I would really appreciate your thoughts on this.

Work to do :
[ ] -  Default Dataset for folder, hdf5
[ ] - Validate Windows behaviour",Dref360,None,2017-06-07T16:53:00Z,2017-07-02T18:16:19Z
6889,model.evaluate() in Keras do not cover all datapoints,"I am running `theano.__version__ = 0.9.0.dev-c697eeab84e5b8a74908da654b66ec9eca4f1291` and `keras.__version__ = 2.0.2` on conda environment with Python 3.6.1. OS in Windows Server 2012 R2 with Graphics Card Nvidia Quadro K6000. Cuda 7.5 installed with Nvidia Driver 354.56.

`model.evaluate()` is not covering all data points. I have total 768 data points, but `model.evaluate()` is evaluating only 32 data points and give the accuracy of 75.52%. I also tried batch sizes of 100, 50, 20, 10 & 1, but it does not cover all the data points but the accuracy remains unchanged.

You can check my Jupyter Notebook file if the implementation [here](https://github.com/thepunitsingh/keras_tutorials/blob/master/pima-indians-diabetes-categorization.ipynb)

I tried to discuss this on [StackExchange](https://stackoverflow.com/q/44384924/6701627), and I was suggested by experience people that it could be a bug in keras or the progress bar might have broken. I don't know how to check if the progress bar is broken, so I am posting the issue here.",thepunitsingh,b'stale',2017-06-07T16:06:42Z,2017-10-05T16:48:57Z
6880,sequence.pad_sequences causes different performances in Keras 1.0.3 and Keras 2.0.3,"Hello!

I'm using Keras to learn models to automatically score essays. When I use **sequence.pad_sequences(data, maxlen=maxlen, padding='pre', truncating='pre')** to pad the word index sequences of each essay, I got **much worse performance** using _Keras 2.0.3_ than using _Keras 1.0.3_. But if I pad the sequences post using **pad_sequences(data, maxlen=maxlen, padding='post', truncating='post')**, I got similar performance. So is there any **bug** in the **RNN** (LSTM) layer(s) of **Keras 2.0.3** when handling pre-padded input?",jinfengfeng,b'stale',2017-06-07T07:53:10Z,2017-10-05T08:48:56Z
6866,Keras+Theano VGG16 issue,"I tried to use VGG16 model from [applications](https://keras.io/applications/#vgg16). My script

```
from keras.applications.vgg16 import VGG16
from keras.preprocessing import image
from keras.applications.vgg16 import preprocess_input
import numpy as np

model = VGG16(weights='imagenet', include_top=False)

img_path = 'cat.324.jpg'

img = image.load_img(img_path, target_size=(224, 224))
x = image.img_to_array(img)
x = np.expand_dims(x, axis=0)
x = preprocess_input(x)

features = model.predict(x) 
```

As input image I used image from CatsAndDogs dataset. On line `features = model.predict(x)` I got following error:

> ---------------------------------------------------------------------------
> ValueError                                Traceback (most recent call last)
> /home/konstantin/frameworks/anaconda3/lib/python3.6/site-packages/theano/compile/function_module.py in __call__(self, *args, **kwargs)
>     883             outputs =\
> --> 884                 self.fn() if output_subset is None else\
>     885                 self.fn(output_subset=output_subset)
> 
> ValueError: GpuElemwise. Input dimension mis-match. Input 2 (indices start at 0) has shape[1] == 64, but the output's size on that axis is 3.
> 
> During handling of the above exception, another exception occurred:
> 
> ValueError                                Traceback (most recent call last)
> <ipython-input-26-4279fa6fed56> in <module>()
>       4 x = preprocess_input(x)
>       5 
> ----> 6 features = model.predict(x)
> 
> /home/konstantin/frameworks/anaconda3/lib/python3.6/site-packages/keras/engine/training.py in predict(self, x, batch_size, verbose)
>    1570         f = self.predict_function
>    1571         return self._predict_loop(f, ins,
> -> 1572                                   batch_size=batch_size, verbose=verbose)
>    1573 
>    1574     def train_on_batch(self, x, y,
> 
> /home/konstantin/frameworks/anaconda3/lib/python3.6/site-packages/keras/engine/training.py in _predict_loop(self, f, ins, batch_size, verbose)
>    1200                 ins_batch = _slice_arrays(ins, batch_ids)
>    1201 
> -> 1202             batch_outs = f(ins_batch)
>    1203             if not isinstance(batch_outs, list):
>    1204                 batch_outs = [batch_outs]
> 
> /home/konstantin/frameworks/anaconda3/lib/python3.6/site-packages/keras/backend/theano_backend.py in __call__(self, inputs)
>    1092     def __call__(self, inputs):
>    1093         assert isinstance(inputs, (list, tuple))
> -> 1094         return self.function(*inputs)
>    1095 
>    1096 
> 
> /home/konstantin/frameworks/anaconda3/lib/python3.6/site-packages/theano/compile/function_module.py in __call__(self, *args, **kwargs)
>     896                     node=self.fn.nodes[self.fn.position_of_error],
>     897                     thunk=thunk,
> --> 898                     storage_map=getattr(self.fn, 'storage_map', None))
>     899             else:
>     900                 # old-style linkers raise their own exceptions
> 
> /home/konstantin/frameworks/anaconda3/lib/python3.6/site-packages/theano/gof/link.py in raise_with_op(node, thunk, exc_info, storage_map)
>     323         # extra long error message in that case.
>     324         pass
> --> 325     reraise(exc_type, exc_value, exc_trace)
>     326 
>     327 
> 
> /home/konstantin/frameworks/anaconda3/lib/python3.6/site-packages/six.py in reraise(tp, value, tb)
>     683             value = tp()
>     684         if value.__traceback__ is not tb:
> --> 685             raise value.with_traceback(tb)
>     686         raise value
>     687 
> 
> /home/konstantin/frameworks/anaconda3/lib/python3.6/site-packages/theano/compile/function_module.py in __call__(self, *args, **kwargs)
>     882         try:
>     883             outputs =\
> --> 884                 self.fn() if output_subset is None else\
>     885                 self.fn(output_subset=output_subset)
>     886         except Exception:
> 
> ValueError: GpuElemwise. Input dimension mis-match. Input 2 (indices start at 0) has shape[1] == 64, but the output's size on that axis is 3.
> Apply node that caused the error: GpuElemwise{Composite{(i0 * ((i1 + i2) + Abs((i1 + i2))))}}[(0, 1)](CudaNdarrayConstant{[[[[ 0.5]]]]}, GpuDnnConv{algo='small', inplace=True}.0, GpuDimShuffle{x,0,x,x}.0)
> Toposort index: 176
> Inputs types: [CudaNdarrayType(float32, (True, True, True, True)), CudaNdarrayType(float32, 4D), CudaNdarrayType(float32, (True, False, True, True))]
> Inputs shapes: [(1, 1, 1, 1), (1, 3, 224, 225), (1, 64, 1, 1)]
> Inputs strides: [(0, 0, 0, 0), (0, 50400, 225, 1), (0, 1, 0, 0)]
> Inputs values: [b'CudaNdarray([[[[ 0.5]]]])', 'not shown', 'not shown']
> Outputs clients: [[GpuContiguous(GpuElemwise{Composite{(i0 * ((i1 + i2) + Abs((i1 + i2))))}}[(0, 1)].0)]]
> 
> HINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.
> HINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.

OS Ubuntu 14.04
CUDA 8.0
CuDNN 5.105
Python 3.6.1
Keras 2.0.4
Theano 0.9.0",KonstV,b'stale',2017-06-05T18:41:56Z,2017-10-03T19:18:08Z
6852,Invalid `output_shape` of a model,"Consider the following example:

```python
seq_len = 5
seq_of_int = Input((seq_len,))
seq_of_3vec = Embedding(10, 3)(seq_of_int)
seq_of_1vec = Flatten()(Embedding(10, 1)(seq_of_int))
out = Dot((0,0))([seq_of_1vec, seq_of_3vec])
m = Model(seq_of_int, out)

print(m.output_shape)
# Outputs (5,3)

print(m.predict(np.arange(5).reshape(1,-1)).shape)
# Outputs (1,3)
```

This seems to cause confusing bugs downstream:
```python
other = concatenate([m(seq_of_int), Input((3,))])
# ValueError: `Concatenate` layer requires inputs with matching
#     shapes except for the concat axis. Got inputs shapes: [(5, 3), (None, 3)]
```

The concatenation problem occurs without using an intermediate model:
```python
other = concatenate([out, Input((3,))])
# `Concatenate` layer requires inputs with matching shapes 
#   except for the concat axis. Got inputs shapes: [(5, 3), (None, 3)]
```

However if we just examine the size of `out` all seems fine:
```python
out.get_shape()
# TensorShape([Dimension(None), Dimension(3)])
```
",konstantint,b'stale',2017-06-04T20:23:01Z,2017-10-02T22:13:06Z
6847,Invariant prediction,"I used batch to train a conv neural network, however when I used:
`result = model.predict(x=data, batch_size=batch_size, verbose=True)`
to predict results based on data, the results(has the shape of (18000,  4)) are just 18000 same tuples(shape (4,)).

What's odd is that, data fed to the neural network consists of different images,
and when I inspected the weights of the network, there are no NaNs, meaning it should be impossible for the network to produce same results.

Any idea what could be wrong?
Or how to debug it?

Edit:
I used softmax as the last activation function and binary_crossentropy as the loss function.",zeka0,None,2017-06-04T03:05:51Z,2017-06-05T13:28:45Z
6843,'TensorVariable' object has no attribute '_keras_shape' - Reshape and batch_shape,"Just wondering if someone could shed some light on the following error I get:
```
Traceback (most recent call last):
  File ""/home/hayden/.PyCharm2017.1/config/scratches/scratch_5.py"", line 29, in <module>
    x = TimeDistributed(inner_model, input_shape=(10,))(outer_input)
  File ""/usr/local/lib/python3.4/dist-packages/keras/engine/topology.py"", line 585, in __call__
    output = self.call(inputs, **kwargs)
  File ""/usr/local/lib/python3.4/dist-packages/keras/layers/wrappers.py"", line 166, in call
    unroll=False)
  File ""/usr/local/lib/python3.4/dist-packages/keras/backend/theano_backend.py"", line 1335, in rnn
    go_backwards=go_backwards)
  File ""/usr/local/lib/python3.4/dist-packages/theano/scan_module/scan.py"", line 773, in scan
    condition, outputs, updates = scan_utils.get_updates_and_outputs(fn(*args))
  File ""/usr/local/lib/python3.4/dist-packages/keras/backend/theano_backend.py"", line 1323, in _step
    output, new_states = step_function(input, states)
  File ""/usr/local/lib/python3.4/dist-packages/keras/layers/wrappers.py"", line 160, in step
    output = self.layer.call(x)
  File ""/usr/local/lib/python3.4/dist-packages/keras/engine/topology.py"", line 2027, in call
    output_tensors, _, _ = self.run_internal_graph(inputs, masks)
  File ""/usr/local/lib/python3.4/dist-packages/keras/engine/topology.py"", line 2259, in run_internal_graph
    input_shapes = [x._keras_shape for x in inputs]
  File ""/usr/local/lib/python3.4/dist-packages/keras/engine/topology.py"", line 2259, in <listcomp>
    input_shapes = [x._keras_shape for x in inputs]
AttributeError: 'TensorVariable' object has no attribute '_keras_shape'
```
My versions are:
Python 3.4.3
Keras 2.0.4
Theano 0.9.0

My (simplified) model spec is:
```
from keras.layers import Dense, Input, TimeDistributed, Reshape, Lambda, Flatten
from keras.layers.recurrent import GRU
from keras.models import Model

seq_len = 20
batch_size = 4

####### INNER MODEL #######
# since TimeDist layer cant take multiple inputs needed to merge into one
inner_input = Input(shape=(10,), batch_shape=(batch_size, 10), name='INNER_INPUT')

a = Lambda(lambda a: a[:, :6], output_shape=(6,), name='INNER_SPLIT_A')(inner_input)
b = Lambda(lambda a: a[:, 6:], output_shape=(4,), name='INNER_SPLIT_B')(inner_input)  # b used elsewhere

ar = Reshape(target_shape=(2, 3), name='INNER_A_RESHAPED')(a)

a = Flatten()(ar)  # If comment out to disconnect ar = Reshape(), model works fine
x = Dense(3)(a)

inner_model = Model(inputs=inner_input, outputs=x, name='INNER_MODEL')
inner_model.summary()
###### END INNER MODEL #######

###### OUTER MODEL #######
outer_input = Input(shape=(seq_len, 10)) # OR if remove batch_shape also works
# outer_input = Input(shape=(seq_len, 10), batch_shape=(batch_size, seq_len, 10))
x = TimeDistributed(inner_model, input_shape=(10,))(outer_input)

x = GRU(8, return_sequences=False)(x)
sm = Dense(5, activation='softmax', name='PRED')(x)

model = Model(inputs=outer_input, outputs=sm, name='OUTER_MODEL')
###### END OUTER MODEL #######

model.summary()
```
Producing summaries for the inner and outer models:
```
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
INNER_INPUT (InputLayer)     (4, 10)                   0         
_________________________________________________________________
INNER_SPLIT_A (Lambda)       (4, 6)                    0         
_________________________________________________________________
INNER_A_RESHAPED (Reshape)   (4, 2, 3)                 0         
_________________________________________________________________
flatten_1 (Flatten)          (4, 6)                    0         
_________________________________________________________________
dense_1 (Dense)              (4, 3)                    21        
=================================================================
Total params: 21
Trainable params: 21
Non-trainable params: 0
_________________________________________________________________
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 20, 10)            0         
_________________________________________________________________
time_distributed_1 (TimeDist (None, 20, 3)             21        
_________________________________________________________________
gru_1 (GRU)                  (None, 8)                 288       
_________________________________________________________________
PRED (Dense)                 (None, 5)                 45        
=================================================================
Total params: 354
Trainable params: 354
Non-trainable params: 0
_________________________________________________________________
```

As commented in the code, it only occurs if the Reshape() layers are included AND the batch_shape is specified in the outer_input.

Does anyone know why this is happening and if it's meant to happen or some sort of bug? I would like to specify the batch_size of the outer input and still have a reshape layer inside.

Thanks in advance :)
",HaydenFaulkner,b'stale',2017-06-03T17:12:01Z,2017-10-01T18:19:34Z
6827,Model deserialization failure with shared inputs layers,"**_(See the comments below for a simpler repro case.)_**

A model with shared inputs, LSTM, and Lambda layers fails to deserialize. A minimal repro case is here.

```python
from keras.engine import Input, Model
from keras.layers import Lambda, concatenate, Dense, LSTM
from keras.models import save_model, load_model

input_shape = (20, 300)

input_1 = Input(input_shape)
input_2 = Input(input_shape)

lstm = LSTM(32)
e1 = lstm(input_1)
e2 = lstm(input_2)

negative_e1 = Lambda(lambda x: -x)(e1)
hidden = concatenate([e1, e2, negative_e1])

logistic_regression = Dense(1, activation=""sigmoid"")(hidden)
model = Model(inputs=[input_1, input_2], outputs=logistic_regression)
model.compile(optimizer=""adam"", loss=""binary_crossentropy"", metrics=[""accuracy""])
print(""Original model %s"" % model)

name = ""model.hd5""
save_model(model, name)

restored_model = load_model(name)
print(""Restored model %s"" % restored_model)
```

(This model is a simplification of a strategy used for textual semantic equivalence detection. The actual strategy takes the square of `e2 - e1` which exhibits the same problem.)

The `restore_model` fails with the exception `ValueError: Missing layer: input_2`.

This is as simple as I have been able to make the repro case.
Changing the model in the following ways makes the bug go away:
- Not using multiple inputs
- Not putting the inputs through a shared LSTM. (It works if you either omit the LSTM or use a separate LSTM for each input.)
- Not using a Lambda layer. (It works if you omit the Lambda layer, or replace it with a non-lambda function, e.g. `keras.layers.add([e1, e2])`)

This looks similar to #4160, but doesn't have the nested layers that issue has, so I'm not sure if it's the same bug.

This is the full stack trace.

```python
Traceback (most recent call last):
  File ""/Users/billmcn/src/keras_serialization_bug/keras_serialization_bug.py"", line 28, in <module>
    restored_model = load_model(name)
  File ""/Users/billmcn/anaconda/envs/keras-serialization-bug/lib/python3.5/site-packages/keras/models.py"", line 232, in load_model
    model = model_from_config(model_config, custom_objects=custom_objects)
  File ""/Users/billmcn/anaconda/envs/keras-serialization-bug/lib/python3.5/site-packages/keras/models.py"", line 293, in model_from_config
    return layer_module.deserialize(config, custom_objects=custom_objects)
  File ""/Users/billmcn/anaconda/envs/keras-serialization-bug/lib/python3.5/site-packages/keras/layers/__init__.py"", line 46, in deserialize
    printable_module_name='layer')
  File ""/Users/billmcn/anaconda/envs/keras-serialization-bug/lib/python3.5/site-packages/keras/utils/generic_utils.py"", line 140, in deserialize_keras_object
    list(custom_objects.items())))
  File ""/Users/billmcn/anaconda/envs/keras-serialization-bug/lib/python3.5/site-packages/keras/engine/topology.py"", line 2374, in from_config
    process_layer(layer_data)
  File ""/Users/billmcn/anaconda/envs/keras-serialization-bug/lib/python3.5/site-packages/keras/engine/topology.py"", line 2361, in process_layer
    raise ValueError('Missing layer: ' + inbound_layer_name)
ValueError: Missing layer: input_2
```

_Keras version 2.0.4 with TensorFlow backend, Python 3.5.3_

## Checklist

- [x] Check that you are up-to-date with the master branch of Keras. You can update with:
pip install git+git://github.com/fchollet/keras.git --upgrade --no-deps

- [x] If running on TensorFlow, check that you are up-to-date with the latest version. The installation instructions can be found [here](https://www.tensorflow.org/get_started/os_setup).

- [x] If running on Theano, check that you are up-to-date with the master branch of Theano. You can update with:
pip install git+git://github.com/Theano/Theano.git --upgrade --no-deps

- [x] Provide a link to a GitHub Gist of a Python script that can reproduce your issue (or just copy the script here if it is short).

",wpm,None,2017-06-01T21:47:38Z,2017-06-08T19:09:16Z
6824,bug in cosine similarity computation of Keras version 2.0.4,"First, let's compare the dot product and cosine similarity in a toy data:
`Dot Product:`
`import numpy as np`
`tensor_a = Input(shape=(4,6,))`
`tensor_b = Input(shape=(4,6,))`
`merged_tensor = merge([tensor_a, tensor_b], mode='dot',dot_axes=-1)`
`m = Model([tensor_a, tensor_b], [merged_tensor])`
`input_a=np.ones((2,4,6))`
`input_b=np.ones((2,4,6))`
`input_a[0][0][0]=0`
`m.predict([input_a, input_b])`

The output is as following, which is **correct**: 
       
         array([[[ 5.,  5.,  5.,  5.],
         [ 6.,  6.,  6.,  6.],
         [ 6.,  6.,  6.,  6.],
         [ 6.,  6.,  6.,  6.]],

       [[ 6.,  6.,  6.,  6.],
        [ 6.,  6.,  6.,  6.],
        [ 6.,  6.,  6.,  6.],
        [ 6.,  6.,  6.,  6.]]], dtype=float32)`

Then simple change the dot similarity to cosine similarity:
`merged_tensor = merge([tensor_a, tensor_b], mode='cos',dot_axes=-1)`
`m = Model([tensor_a, tensor_b], [merged_tensor])`
`m.predict([input_a, input_b])`

The output is as follows, which is **incorrect.** (how can a cosine similarity greater than 1?!):

       array([[[[ 0.91287088,  0.91287088,  0.91287088,  0.91287088],
         [ 1.09544504,  1.        ,  1.        ,  1.        ],
         [ 1.09544504,  1.        ,  1.        ,  1.        ],
         [ 1.09544504,  1.        ,  1.        ,  1.        ]]],


       [[[ 1.        ,  1.        ,  1.        ,  1.        ],
         [ 1.        ,  1.        ,  1.        ,  1.        ],
         [ 1.        ,  1.        ,  1.        ,  1.        ],
         [ 1.        ,  1.        ,  1.        ,  1.        ]]]], dtype=float32)",jinfengr,None,2017-06-01T19:54:55Z,2018-01-13T21:44:05Z
6819,"""Layers"" member contains a model object when concatenating two Keras models","When creating a new Keras model by concatenating two existing models, the _layers_ member collapses the layers of the second model, making the structure somewhat obfuscated. It doesn't affect the model's behavior during training/inference, but it makes it harder to work with. Is this by design?

For example, consider the summaries below. _model_3_ is comprised of _model_1_ and _model_2._ The last (softmax) layer of _model_1_ is removed, and _model_2_ receives the output of the ""headless"" _model_1_ ([the code can be found here](https://gist.github.com/psgl/6831463a5873bc9b57a987bb65f348bc)). The last entry in the summary of _model_3_ has all the layers of _model_2_ collapsed into a single line:


```
model 1: summary
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
net_1_input (InputLayer)     (None, 28, 28, 1)         0         
_________________________________________________________________
net_1_conv1 (Conv2D)         (None, 24, 24, 16)        416       
_________________________________________________________________
net_1_pool1 (MaxPooling2D)   (None, 12, 12, 16)        0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 2304)              0         
_________________________________________________________________
net_1_dense (Dense)          (None, 1024)              2360320   
_________________________________________________________________
net_1_softmax (Dense)        (None, 10)                10250     
=================================================================
Total params: 2,370,986
Trainable params: 2,370,986
Non-trainable params: 0
_________________________________________________________________


model 2: summary
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
net_2_input (InputLayer)     (None, 1024)              0         
_________________________________________________________________
net_2_dense1 (Dense)         (None, 40)                41000     
_________________________________________________________________
net_2_dropout (Dropout)      (None, 40)                0         
_________________________________________________________________
net_2_softmax (Dense)        (None, 10)                410       
=================================================================
Total params: 41,410
Trainable params: 41,410
Non-trainable params: 0
_________________________________________________________________


model 3: summary
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
net_1_input (InputLayer)     (None, 28, 28, 1)         0         
_________________________________________________________________
net_1_conv1 (Conv2D)         (None, 24, 24, 16)        416       
_________________________________________________________________
net_1_pool1 (MaxPooling2D)   (None, 12, 12, 16)        0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 2304)              0         
_________________________________________________________________
net_1_dense (Dense)          (None, 1024)              2360320   
_________________________________________________________________
net_2_model (Model)          (None, 10)                41410     
=================================================================
Total params: 2,402,146
Trainable params: 2,402,146
Non-trainable params: 0
_________________________________________________________________
```

Here is the view of _model_3.layers_ during debugging. **Notice the last entry being of type _{model}_**:
```
layers = {list} <type 'list'>: [<keras.engine.topology.InputLayer object at 0x7f472d258250>, <keras.layers.convolutional.Conv2D object at 0x7f472d258290>, <keras.layers.pooling.MaxPooling2D object at 0x7f472d258550>, <keras.layers.core.Flatten object at 0x7f472d2582d0>, <
 __len__ = {int} 6
 0 = {InputLayer} <keras.engine.topology.InputLayer object at 0x7f472d258250>
 1 = {Conv2D} <keras.layers.convolutional.Conv2D object at 0x7f472d258290>
 2 = {MaxPooling2D} <keras.layers.pooling.MaxPooling2D object at 0x7f472d258550>
 3 = {Flatten} <keras.layers.core.Flatten object at 0x7f472d2582d0>
 4 = {Dense} <keras.layers.core.Dense object at 0x7f472d258b90>
 5 = {Model} <keras.engine.training.Model object at 0x7f46d24efad0>
```
The _{model}_ item can be further investigated, and indeed contains a _layers_ member with all the layers of _model_2_.

I used:
Keras 2.0.4
TF 1.0.1
",psgl,b'stale',2017-06-01T13:31:42Z,2017-09-29T14:43:24Z
6818,Trainable variable bug in BatchNormalization layer with tensorflow backend,"I use BatchNormalization layer with the tensorflow backend, and I found a issue that when i call tf.trainable_variables(), the moving_mean and the moving_variance appear in the trainable variables.

Is it a bug?
",LynnHo,b'stale',2017-06-01T10:13:04Z,2017-09-29T10:43:24Z
6811,Dimension mis-match in image_ocr.py,"Example file image_ocr.py is giving me the mis-match dimension error below, after compilation.  I've browsed the code but see nothing wrong.  I'm using updated versions of theano, keras, and cuda. Maybe @mbhenry can help?

Epoch 1/20
Traceback (most recent call last):
  File ""image_ocr.py"", line 489, in <module>
    train(run_name, 0, 20, 128)
  File ""image_ocr.py"", line 484, in train
    callbacks=[viz_cb, img_gen], initial_epoch=start_epoch)
  File ""/usr/local/lib/python2.7/dist-packages/Keras-2.0.4-py2.7.egg/keras/legacy/interfaces.py"", line 88, in wrapper
    return func(*args, **kwargs)
  File ""/usr/local/lib/python2.7/dist-packages/Keras-2.0.4-py2.7.egg/keras/engine/training.py"", line 1899, in fit_generator
    class_weight=class_weight)
  File ""/usr/local/lib/python2.7/dist-packages/Keras-2.0.4-py2.7.egg/keras/engine/training.py"", line 1639, in train_on_batch
    outputs = self.train_function(ins)
  File ""/usr/local/lib/python2.7/dist-packages/Keras-2.0.4-py2.7.egg/keras/backend/theano_backend.py"", line 1196, in __call__
    return self.function(*inputs)
  File ""/usr/local/lib/python2.7/dist-packages/theano/compile/function_module.py"", line 898, in __call__
    storage_map=getattr(self.fn, 'storage_map', None))
  File ""/usr/local/lib/python2.7/dist-packages/theano/gof/link.py"", line 325, in raise_with_op
    reraise(exc_type, exc_value, exc_trace)
  File ""/usr/local/lib/python2.7/dist-packages/theano/compile/function_module.py"", line 884, in __call__
    self.fn() if output_subset is None else\
ValueError: GpuElemwise. Input dimension mis-match. Input 1 (indices start at 0) has shape[1] == 28, but the output's size on that axis is 32.
Apply node that caused the error: GpuElemwise{add,no_inplace}(GpuReshape{3}.0, InplaceGpuDimShuffle{x,0,x}.0)
Toposort index: 523
Inputs types: [GpuArrayType<None>(float32, (False, False, False)), GpuArrayType<None>(float32, (True, False, True))]
Inputs shapes: [(32, 32, 28), (1, 28, 1)]
Inputs strides: [(3584, 112, 4), (112, 4, 4)]
Inputs values: ['not shown', 'not shown']
Outputs clients: [[GpuElemwise{Composite{exp((i0 - i1))}}[]<gpuarray>(GpuElemwise{add,no_inplace}.0, InplaceGpuDimShuffle{0,1,x}.0), GpuElemwise{Composite{(i0 + (i1 * EQ(i2, i3) * i4))}}[]<gpuarray>(GpuElemwise{Composite{(((i0 / i1) + i2) * i3)}}[]<gpuarray>.0, GpuArrayConstant{[[[-1.]]]}, InplaceGpuDimShuffle{0,1,x}.0, GpuElemwise{add,no_inplace}.0, InplaceGpuDimShuffle{0,1,x}.0), GpuCAReduceCuda{maximum}{2}(GpuElemwise{add,no_inplace}.0)]]

HINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.
HINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.

",mattroos,b'stale',2017-06-01T00:07:14Z,2017-09-29T13:43:24Z
6786,Bugfix: GeneratorEnqueuer should not change the generated batches' order when workers > 1,"This is a proposed fix for the erroneous behaviour described in #6745.
I ran tests on Ubuntu 16.04 with python 3.5 and 2.7, all tests pass.
I also ran tests on Windows with python 3.5 (Tensorflow currently does not support python 2.7 on Windows) and all tests except those using multiprocessing pass.
The tests that fail are affected by the error mentioned in #5071.

**Description of the bug fix**: The idea is to exploit `multiprocessing`'s `Pool.apply_asynch` which does not block and immediately returns a `multiprocessing.pool.ApplyResult` object that is put in the queue.
The generator's batches order is kept by using a lock that guarantees that no thread can get a new batch until the last batch's `ApplyResult` object has been put in the queue.
Note that to keep the `GeneratorEnqueuer`'s external interface the same, I had to define two ""private"" classes that redefine the queues' `get()` method to actually return `ApplyResult.get()` (which may block if the result is not ready yet).

**NOTE**: Incidentally, fixing the original bug also led to the discovery and subsequent fix of a second bug.

**TL;DR**: The second bug would cause a `GeneratorEnqueuer` instance to stall potentially causing a deadlock. Now this cannot happen anymore.

**Second bug explanation:**
If:
1) the queue is full
2) a thread tries to `put()` and blocks until the queue has space again
3) the `GeneratorEnqueuer` instance calls `stop()`.

the thread calling `stop()` would block waiting for the thread waiting on `put()` to unblock. This would happen only if some thread calls `pop()` on the queue. This might lead to deadlock if the only thread popping from the queue is the thread calling `stop()`.

This behaviour is now prevented by the lock before the test on the queue length, which ensures no thread will ever try to `put()` when the queue is full.
",GPhilo,None,2017-05-29T10:01:09Z,2017-05-29T11:13:36Z
6783,Error in using keras lambda layer for operations(multiply) with constant tensor,"I need a mask of [K.ones_like(x), np.zeros_like(x)] to be multiplied (element-wise) to the output of a convolutional layer in keras, I have tried implementing this functionality in a Lambda layer. This has to be executed in a for loop for 5 layers. Debugging shows that it has computed the product properly for 5 times and mistakingly it does for 6th time and reports the following error: ValueError: Dimensions must be equal, but are 28 and 348 for 'model_6/lambda_25/mul' (op: 'Mul') with input shapes: [?,16,16,28], [?,1,1,348].

This functionality is not intended. Following is the code and the total error message.

```
import keras
from keras import backend as K
from keras import losses
from keras.models import Model, load_model
from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D, add, concatenate, Lambda

L = 5
Fc = [16, 32, 64, 128, 256] 
Fn = [12, 24, 48, 96, 92] 

clean_encs = []
clean_enc_inp = Input(shape = (32, 32, 3))
clean_enc = clean_enc_inp
for i in range(L):
    clean_enc = Conv2D(Fc[i]+Fn[i] , (3, 3), activation='relu', padding='same', strides=(2, 2))(clean_enc)
    ones = K.ones_like(clean_enc)[:, :, :, : Fc[i]]
    zeros = K.zeros_like(clean_enc)[:, :, :, : Fn[i]]
    clean_mask = K.concatenate((ones, zeros), axis=-1)
    clean_enc = Lambda(lambda x: x*clean_mask)(clean_enc)
    clean_encs.append(clean_enc)

clean_encoder = Model(inputs=[clean_enc_inp], outputs=clean_encs)
clean_encoder.compile(optimizer='adadelta', loss='mean_squared_error')

clean_input = Input(shape = (32, 32, 3))
clean = clean_encoder(clean_input)
```
![screen shot 2017-05-29 at 6 14 51 am](https://cloud.githubusercontent.com/assets/19821962/26533445/c7bc0a18-4436-11e7-9e80-2b32afd963be.png)",rajeev595,None,2017-05-29T00:51:09Z,2017-05-29T01:32:04Z
6779,Debugging Keras function,"Hello, I would be most grateful, if you could give me some help.

I wrote a simple function in Keras and I still want to test it whether it works properly or not. How can I do that? 

def cos_sim (inputs):
    i1,i2=inputs
    numerator = K.sum(i1*i2)
    denominator = K.sqrt(K.sum(i1**2)*K.sum(i2**2))
    return numerator/denominator


x = np.array([2,3,1,0])
y = np.array([0,8,6,9])

P.S I expected to get something like “0.595961149897”  but  with “print(model.predict([x,y],verbose=0))” I’ve got  [ 1.  1.  1.  1.]
",LN5user,b'stale',2017-05-28T13:03:35Z,2017-11-03T20:31:42Z
6777,Undefined output shape in Conv2DTranspose,"
If we use keras with tensorflow, the output shape of a Conv2DTranspose is undefined even if the input shape is fixed. This problem doesn't happen with Conv2D . This is probably due to a bug in the implementation of   Conv2DTranspose.

```
import tensorflow as tf

config = tf.ConfigProto()
config.gpu_options.allow_growth=True
sess = tf.Session(config=config)

from keras.layers.convolutional import Conv2DTranspose , Conv2D

layer1 = Conv2DTranspose( 8  , (4 , 4) , strides=(1, 1)  , data_format='channels_first'  , input_shape=(3,64,64) )
layer2 = Conv2D( 8 , (4, 4) , strides=(1, 1), input_shape=(3, 64, 64) , data_format='channels_first'  )

BATCH_SIZE = 32
x = tf.placeholder(tf.float32, shape=( BATCH_SIZE , 3, 64 , 64 ))
          
o1 = layer1( x )
o2 = layer2( x )


print o1.get_shape() # Prints (?, 8, ?, ?) , why???
print o2.get_shape() # Prints (32, 8, 61, 61) , which is correct 
```",divamgupta,None,2017-05-28T08:46:08Z,2020-02-15T13:59:29Z
6774,TensorBoard Callback doesn't close file - max file descriptors(re),"Max file description error occurred and I found this:  #4533.
I've checked the keras version and it's 2.0.4.
The 'self.writer.close()' is being called properly but the file descriptor has not been closed.

For every loop a new writer is created and to prevent this, I temporarily avoid it like this:
```
if self.write_graph:
    if hasattr(self, 'writer'):
        self.writer.reopen()
    else:
        self.writer = tf.summary.FileWriter(self.log_dir, self.sess.graph)
else:
    if hasattr(self, 'writer'):
        self.writer.reopen()
    else:
        self.writer = tf.summary.FileWriter(self.log_dir)
```

I think this problem needs of further debugging.",ghost,b'stale',2017-05-27T17:14:57Z,2017-09-24T18:31:09Z
6770,K.ctc_decode() memory not released ,"memory not released bug with tf.python.ops.gen_ctc_ops (both with ctc_greedy_decoder and ctc_beam_search_decoder) ...

```python
import time
from keras import backend as K

start_time = time.time()
while True:
     y_pred  = K.ctc_decode(args)
     cost_time = time.time()-start_time
     print 'cost time', cost_time   # time cost more and more with the same input args. memory cost bigger as well, why ??!! 
#  ...
```

when using K.ctc_decode() in a large loop, time cost longer loop become larger, why?
please help , thank you!!
",jkmiao,b'stale',2017-05-26T13:33:54Z,2019-05-09T12:56:11Z
6746,All input dimensions must explicited if dropout enabled in a TimeDistributed(LSTM) layer,"I am trying to avoid to specify all the dimensions of my network in order to reduce the computational
costs. What I have noticed is that network implemented in  model_not_learning_due_to_dropout()
raises an exception.

 Raises:
  raise MissingInputError(error_msg, variable=r)
  theano.gof.fg.MissingInputError: Input 0 of the graph (indices start from 0), used to compute if{}(keras_learning_phase, Elemwise{mul,no_inplace}.0, Reshape{3}.0), was not provided and not given a value. Use the Theano flag exception_verbosity='high', for more information on this error. 

If I specify the complete Input shape or I omit the dropout value, i am able to fit the network. 
Is it a bug in Keras? I am using the Theano backend.
Here attached is the testcase.


```python
from keras.layers import Input, LSTM, Dense
from keras.layers.wrappers import TimeDistributed
from keras.models import Model
from keras.utils import to_categorical
import numpy


data = numpy.random.random((32, 10, 10, 10))
labels = numpy.array([0 for x in range(0, 32)])
one_hot_labels = to_categorical(labels, num_classes=10)


def model_not_learning_due_to_dropout():
  doc_input = Input(shape=(None, 10,  10)) # This input does not work if dropout is enabled in LSTM
  doc_output = TimeDistributed(LSTM(64, dropout=0.3))(doc_input)
  lstm_aux = LSTM(32)(doc_output)
  out_dense = Dense(10, activation='softmax')(lstm_aux)
  doc_model = Model(inputs=doc_input, outputs=out_dense)
  doc_model.compile(loss='categorical_crossentropy', optimizer=""rmsprop"",
                    metrics=['accuracy'])
  doc_model.fit(data, one_hot_labels)
 # Raises 
 # raise MissingInputError(error_msg, variable=r)
 # theano.gof.fg.MissingInputError: Input 0 of the graph (indices start from 0), used to compute if{}
 # (keras_learning_phase, Elemwise{mul,no_inplace}.0, Reshape{3}.0), was not provided and not given 
 # a value. Use the Theano flag exception_verbosity='high', for more information on this error. 
 #Backtrace when that variable is created:

def model_learning_with_dropout_added_dimension():
  doc_input = Input(shape=(10, 10,  10))  # This input works (extra dimension None -> 10) added
  doc_output = TimeDistributed(LSTM(64, dropout=0.3))(doc_input)
  lstm_aux = LSTM(32)(doc_output)
  out_dense = Dense(10, activation='softmax')(lstm_aux)
  doc_model = Model(inputs=doc_input, outputs=out_dense)
  doc_model.compile(loss='categorical_crossentropy', optimizer=""rmsprop"",
                    metrics=['accuracy'])
  doc_model.fit(data, one_hot_labels)


def model_learning_without_dropout():
  doc_input = Input(shape=(None, 10,  10))
  doc_output = TimeDistributed(LSTM(64))(doc_input)# This input works (no dropout in LSTM)
  lstm_aux = LSTM(32)(doc_output)
  out_dense = Dense(10, activation='softmax')(lstm_aux)
  doc_model = Model(inputs=doc_input, outputs=out_dense)
  doc_model.compile(loss='categorical_crossentropy', optimizer=""rmsprop"",
                    metrics=['accuracy'])
  doc_model.fit(data, one_hot_labels)

model_learning_without_dropout()
model_learning_with_dropout_added_dimension()
model_not_learning_due_to_dropout()

```",andreacimino,b'stale',2017-05-24T15:45:56Z,2018-08-23T13:55:54Z
6713,Keras kernel function core dump error,"Hi, everyone. I find a core dump error when I want to use keras model to do prediction on test data. I have successfully trained a keras model whose input is a sentence and output is a scalar score. Then I define a prediction method as below:

```
model = load_model(model_path)
pred = K.function([model.input], [model.output])
scores = pred([input_data])
```

The scores can be successfully computed, but after all the scripts are done Python throws core dump error. Although it does not affect the result, I use shell script to judge whether the process is successful and it will exit since an error is thrown. 

Has anyone come across a similar problem? I think it might be a destruction bug.",fromradio,None,2017-05-22T07:08:58Z,2017-05-22T13:05:15Z
6670,get_file() progbar fix,"Includes fix get_file download progress bar #6535 with improvement to scoping clarity.

Additionally fixes bug in python 2.7 where `get_file()` crashes when downloading files where the response does not supply `'Content-Length'`:
```python
    from keras.utils import get_file
    listing_url = 'https://sites.google.com/site/brainrobotdata/home/grasping-dataset/grasp_listing.txt'
    grasp_listing_path = get_file('grasp_listing.txt', listing_url)
```",ahundt,None,2017-05-17T22:26:31Z,2017-05-22T19:15:21Z
6668,Fix depth calculation for shared layers,"This PR fixes a bug where model serialization and loading is broken when a shared layer is used at several different depths in a model (issue found here: https://github.com/allenai/deep_qa/pull/357).  I first added a test that failed on master, then fixed the test.  Hopefully the test and the comments around the test and the fix are enough to explain what's going on.",matt-gardner,None,2017-05-17T20:41:13Z,2019-08-17T20:29:07Z
6642,Error in model.load_weights using Keras 2.0.4,"Build model...
2017-05-15 23:00:29.615498: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2017-05-15 23:00:29.615533: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
deepnet_predict.py:92: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(activation=""relu"", padding=""valid"", strides=1, filters=64, kernel_size=5)`
  subsample_length=1))
deepnet_predict.py:99: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(activation=""relu"", padding=""valid"", strides=1, filters=64, kernel_size=5)`
  subsample_length=1))
deepnet_predict.py:118: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(activation=""relu"", padding=""valid"", strides=1, filters=64, kernel_size=5)`
  subsample_length=1))
deepnet_predict.py:125: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(activation=""relu"", padding=""valid"", strides=1, filters=64, kernel_size=5)`
  subsample_length=1))
deepnet_predict.py:134: UserWarning: The `dropout` argument is no longer support in `Embedding`. You can apply a `keras.layers.SpatialDropout1D` layer right after the `Embedding` layer to get the same behavior.
  model5.add(Embedding(len(word_index) + 1, 300, input_length=40, dropout=0.2))
deepnet_predict.py:135: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(300, dropout=0.2, recurrent_dropout=0.2)`
  model5.add(LSTM(300, dropout_W=0.2, dropout_U=0.2))
deepnet_predict.py:138: UserWarning: The `dropout` argument is no longer support in `Embedding`. You can apply a `keras.layers.SpatialDropout1D` layer right after the `Embedding` layer to get the same behavior.
  model6.add(Embedding(len(word_index) + 1, 300, input_length=40, dropout=0.2))
deepnet_predict.py:139: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(300, dropout=0.2, recurrent_dropout=0.2)`
  model6.add(LSTM(300, dropout_W=0.2, dropout_U=0.2))
deepnet_predict.py:142: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.
  merged_model.add(Merge([model1, model2, model3, model4, model5, model6], mode='concat'))
Traceback (most recent call last):
  File ""deepnet_predict.py"", line 179, in <module>
    merged_model.load_weights('weights.h5')
  File ""/home/anurag/anaconda2/lib/python2.7/site-packages/keras/models.py"", line 717, in load_weights
    topology.load_weights_from_hdf5_group(f, layers)
  File ""/home/anurag/anaconda2/lib/python2.7/site-packages/keras/engine/topology.py"", line 2970, in load_weights_from_hdf5_group
    K.batch_set_value(weight_value_tuples)
  File ""/home/anurag/anaconda2/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py"", line 2148, in batch_set_value
    assign_op = x.assign(assign_placeholder)
  File ""/home/anurag/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/variables.py"", line 512, in assign
    return state_ops.assign(self._variable, value, use_locking=use_locking)
  File ""/home/anurag/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/state_ops.py"", line 270, in assign
    validate_shape=validate_shape)
  File ""/home/anurag/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/gen_state_ops.py"", line 47, in assign
    use_locking=use_locking, name=name)
  File ""/home/anurag/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py"", line 768, in apply_op
    op_def=op_def)
  File ""/home/anurag/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 2338, in create_op
    set_shapes_for_outputs(ret)
  File ""/home/anurag/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 1719, in set_shapes_for_outputs
    shapes = shape_func(op)
  File ""/home/anurag/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 1669, in call_with_requiring
    return call_cpp_shape_fn(op, require_shape_fn=True)
  File ""/home/anurag/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/common_shapes.py"", line 610, in call_cpp_shape_fn
    debug_python_shape_fn, require_shape_fn)
  File ""/home/anurag/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/common_shapes.py"", line 676, in _call_cpp_shape_fn_impl
    raise ValueError(err.message)
ValueError: Dimension 0 in both shapes must be equal, but are 57526 and 79197 for 'Assign_24' (op: 'Assign') with input shapes: [57526,300], [79197,300].",bigdata2,None,2017-05-16T06:22:00Z,2018-02-28T05:31:09Z
6639,Feature idea: callbacks should also receive the model output(s) for the current batch,"Currently `Callback.on_batch_end` only gets passed the current batch index and the loss values. If we also had access to the model's output(s) we could perform some more powerful custom actions here, e.g. if the network's output is an image (such as a segmentation mask etc.) we could visualize it. If the output is a set of bounding box coords, we could visualize that.

Seeing what the network currently does is very valuable for debugging and inspection. Currently this can only be done using an explicit TensorFlow training loop if I'm not mistaken.",isarandi,b'stale',2017-05-15T15:28:34Z,2017-09-14T15:41:01Z
6607,Setting trainable to false change the order in which the layers of a sub-model are serialized,"When using a model within another model and setting some layers with `trainable=False` change the way the model is serialized.

Then, it is not possible to use `load_weights`.

Here's an example which results in error:
```
from keras.models import Model
from keras.layers import Dense, Input, Add 

def create_model(frozen=True):
    x = Input(shape=(100,))
    y = Dense(20)(x)
    y = Dense(5, trainable=frozen)(y)
    y = Dense(10)(y)
    model1 = Model(x, y)

    X = Input(shape=(100,))
    Y = model1(X)
    model2 = Model(X, Y)

    return model2

m1 = create_model(True)
m1.save_weights('test.h5')

m2 = create_model(False)
m2.load_weights('test.h5')
```
which results in this error:
```
Traceback (most recent call last):
  File ""test.py"", line 21, in <module>
    m2.load_weights('test.h5')
  File ""/home/javier/.local/lib/python3.5/site-packages/keras/engine/topology.py"", line 2538, in load_weights
    load_weights_from_hdf5_group(f, self.layers)
  File ""/home/javier/.local/lib/python3.5/site-packages/keras/engine/topology.py"", line 2970, in load_weights_from_hdf5_group
    K.batch_set_value(weight_value_tuples)
  File ""/home/javier/.local/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py"", line 2148, in batch_set_value
    assign_op = x.assign(assign_placeholder)
  File ""/home/javier/.local/lib/python3.5/site-packages/tensorflow/python/ops/variables.py"", line 512, in assign
    return state_ops.assign(self._variable, value, use_locking=use_locking)
  File ""/home/javier/.local/lib/python3.5/site-packages/tensorflow/python/ops/state_ops.py"", line 271, in assign
    validate_shape=validate_shape)
  File ""/home/javier/.local/lib/python3.5/site-packages/tensorflow/python/ops/gen_state_ops.py"", line 47, in assign
    use_locking=use_locking, name=name)
  File ""/home/javier/.local/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py"", line 768, in apply_op
    op_def=op_def)
  File ""/home/javier/.local/lib/python3.5/site-packages/tensorflow/python/framework/ops.py"", line 2338, in create_op
    set_shapes_for_outputs(ret)
  File ""/home/javier/.local/lib/python3.5/site-packages/tensorflow/python/framework/ops.py"", line 1719, in set_shapes_for_outputs
    shapes = shape_func(op)
  File ""/home/javier/.local/lib/python3.5/site-packages/tensorflow/python/framework/ops.py"", line 1669, in call_with_requiring
    return call_cpp_shape_fn(op, require_shape_fn=True)
  File ""/home/javier/.local/lib/python3.5/site-packages/tensorflow/python/framework/common_shapes.py"", line 610, in call_cpp_shape_fn
    debug_python_shape_fn, require_shape_fn)
  File ""/home/javier/.local/lib/python3.5/site-packages/tensorflow/python/framework/common_shapes.py"", line 676, in _call_cpp_shape_fn_impl
    raise ValueError(err.message)
ValueError: Dimension 0 in both shapes must be equal, but are 5 and 20 for 'Assign_2' (op: 'Assign') with input shapes: [5,10], [20,5].
```

Even when using `load_weights(..., by_name=True)` the problem persist.",javiercorrea,b'stale',2017-05-12T20:40:25Z,2019-03-20T14:53:02Z
6603,Is it a bug?,"When I run this code:
```
from keras.layers import Input, Dense
from keras.models import Model
from keras import backend as K
import tensorflow as tf
import numpy as np

session = tf.Session()
K.set_session(session)

x = tf.placeholder('float32', [None, 1])
x0 = Input(shape = (1,))
y0 = Dense(1)(x0)
model = Model(x0, y0)
y = model(x)
init = tf.global_variables_initializer()

init.run(session = session)
for i in model.layers:
    print(i.get_weights())
print(y.eval(session = session, feed_dict = {x : np.array([[1.]])}))
# for i in model.layers:
#     print(i.get_weights())
```
the result is correct.
```
[]
[array([[-0.1085484]], dtype=float32), array([ 0.], dtype=float32)]
[[-0.1085484]]
```
the weight equals to y.

But When I run this code:
```
from keras.layers import Input, Dense
from keras.models import Model
from keras import backend as K
import tensorflow as tf
import numpy as np

session = tf.Session()
K.set_session(session)

x = tf.placeholder('float32', [None, 1])
x0 = Input(shape = (1,))
y0 = Dense(1)(x0)
model = Model(x0, y0)
y = model(x)
init = tf.global_variables_initializer()

init.run(session = session)
# for i in model.layers:
#     print(i.get_weights())
print(y.eval(session = session, feed_dict = {x : np.array([[1.]])}))
for i in model.layers:
    print(i.get_weights())
```
the result is wrong
```
[[-0.18571448]]
[]
[array([[ 0.15062749]], dtype=float32), array([ 0.], dtype=float32)]
```

And When I run this code:
```
from keras.layers import Input, Dense
from keras.models import Model
from keras import backend as K
import tensorflow as tf
import numpy as np

session = tf.Session()
K.set_session(session)

x = tf.placeholder('float32', [None, 1])
x0 = Input(shape = (1,))
y0 = Dense(1)(x0)
model = Model(x0, y0)
y = model(x)
init = tf.global_variables_initializer()

init.run(session = session)
for i in model.layers:
    print(i.get_weights())
print(y.eval(session = session, feed_dict = {x : np.array([[1.]])}))
for i in model.layers:
    print(i.get_weights())
```
the result is correct too.
```
[]
[array([[ 1.25365579]], dtype=float32), array([ 0.], dtype=float32)]
[[ 1.25365579]]
[]
[array([[ 1.25365579]], dtype=float32), array([ 0.], dtype=float32)]
```
What's happened?",gauss-clb,b'stale',2017-05-12T14:15:52Z,2017-09-11T14:11:27Z
6601,[bug] Many operation in theano_backend do not pass '_uses_learning_phase',"For example, tile operation. 

",rudaoshi,None,2017-05-12T10:29:14Z,2017-05-12T18:20:30Z
6591,Fix bug in EarlyStopping to reset stopped_epoch,"Fix bug in EarlyStopping to reset stopped_epoch in on_train_begin to allow it to be re-used. This code change allows me to know check EarlyStopping.stopped_epoch after each train to figure out if this callback triggered and at which epoch.

My exact use case is I have created a custom callback which may also trigger self.model.stop_training, just like EarlyStopping . If my custom callback triggers self.model.stop_training then the EarlyStopping callback will have stopped_epoch set to some value from a previous train.",meberstein,None,2017-05-11T18:38:46Z,2017-05-11T21:32:50Z
6581,Bug fix: convolutional recurrent (again),,farizrahman4u,None,2017-05-10T20:56:56Z,2017-05-15T11:20:52Z
6574,Bug fix in ZeroPadding3D,,Danielhiversen,None,2017-05-10T09:53:01Z,2017-05-11T15:53:15Z
6564,Bug fix + test : Initializing states for ConvLSTM2D,,farizrahman4u,None,2017-05-09T19:50:24Z,2017-05-10T00:32:38Z
6562,Bug : Specifying initial state for ConvLSTM2D layers,"I encountered an error when try to input the initial_state to the ConvLSTM2D layer.

```
lstm_input = Input(shape=(None,) + (32, 32, 3)) 
initial_state_input = Input(shape=(32, 32, 3)) 
x = ConvLSTM2D(128, (3,3), initial_state=initial_state_input, name='lstm')(lstm_input)
```

It gives me an error message: TypeError: ('Keyword argument not understood:', 'initial_state')

Probably ""initial_state"" has not been implemented for ConvLSTM2D layer? If so, what else method I could use to set the hidden state of the ConvLSTM2D layer? #6142 

Thanks!",xn8812,b'stale',2017-05-09T17:20:23Z,2017-09-11T14:11:58Z
6539,Incorrect weights' shape and questions about get_layer in example/mnist_net2net.py,"In Keras 1: the shape of weight in Conv2D layer is of (filters,channels,height,weight), but in Keras 2: the shape is (kw,kh,num_channel,filters). I have fixed this bug, please ref `mnist_net2net_fixed.py` in gist:

https://gist.github.com/luzai/3336bd582650ff2c8c4ff97b1186afcd

Meanwhile, I find that `model.get_layer(name)` returns a `None` even if `model.layers` contain this layer. Please ref to `get_layer_bug.py` in gist.
Temporarily, I fix this bug by some tricks shown below, but may I ask why  `model.get_layer(name)` returns a `None`? 
```
if model.get_layer(name='conv2-deeper') is None:
	names2ind = {layer.name: ind for ind, layer in enumerate(model.layers)}
	ind = names2ind['conv2-deeper']
	model.layers[ind].set_weights(new_weights)
else:
	model.get_layer(name='conv2-deeper').set_weights(new_weights)
```
",luzai,b'stale',2017-05-08T03:10:21Z,2017-09-11T14:11:48Z
6538,"Dense Prediction API Design, Including Segmentation and Fully Convolutional Networks","# Dense Prediction API Design, Including Segmentation and Fully Convolutional Networks

This issue is to develop an API design for dense prediction tasks such as Segmentation, which includes Fully Convolutional Networks (FCN), and was based on the discussion at https://github.com/fchollet/keras/pull/5228#issuecomment-299611150. The goal is to ensure Keras incorporates best practices by default for this sort of problem. Community input, volunteers, and implementations will be very welcome.  #6655 is where preprocessing layers can be discussed.


## Motivating Tasks and Datasets

  - [Pascal VOC 2012 Single Label Segmentation](http://host.robots.ox.ac.uk:8080/leaderboard/displaylb.php?challengeid=11&compid=6)
  - [MSCOCO Multi Label Segmentation](http://mscoco.org/explore/?id=180169)
  - Unambiguously refer to a particular person or object in image with [refcoco](https://github.com/lichengunc/refer)
  - Reinforcement Learning with [OpenAI Gym](https://gym.openai.com/)
  - [mscoco.org/external](http://mscoco.org/external/) has additional examples
     
## Reference Materials

  - [Fully Convolutional Networks for Semantic Segmentation](https://arxiv.org/abs/1605.06211)
  - [U-Net](https://arxiv.org/abs/1505.04597)
  - [Multi-Scale Context Aggregation by Dilated Convolutions](https://arxiv.org/abs/1511.07122)
  - [ResNet](http://arxiv.org/abs/1512.03385) and [Resnetv2](https://arxiv.org/abs/1603.05027)
  - [Wider or Deeper: Revisiting the ResNet Model for Visual Recognition](https://arxiv.org/abs/1611.10080)
  - [Fully Convolutional DenseNets](https://arxiv.org/abs/1611.09326)
  - Daniil's Blog (highly detailed, but for tensorflow)
      - [FCN for Image Segmentation](http://warmspringwinds.github.io/tensorflow/tf-slim/2017/01/23/fully-convolutional-networks-(fcns)-for-image-segmentation/)
      - [Image Segmentation with Tensorflow using CNNs and Conditional Random Fields](http://warmspringwinds.github.io/tensorflow/tf-slim/2016/12/18/image-segmentation-with-tensorflow-using-cnns-and-conditional-random-fields/)
      - [Upsampling and Image Segmentation with Tensorflow and TF-Slim](http://warmspringwinds.github.io/tensorflow/tf-slim/2016/11/22/upsampling-and-image-segmentation-with-tensorflow-and-tf-slim/)
      - [tf-image-segmentation](https://github.com/warmspringwinds/tf-image-segmentation) companion repository (tf only)
      

## Feature Requests

These are ideas rather than a finalized proposal so input is welcome!

 - Input data: Support one or more Images as input + Supplemental data (ex: image + vector)
 - Augmentation of Input Data and Dense Labels
    - Example: Both image and label must be zoomed & translated equally in Pascal VOC
 - Input image dimensions should be able to vary
    - Ideally by height, width & number of channels
 - Loss function ""2D"" support, such as single and multi label results for each pixel in an image
 - [class_weight](https://keras.io/models/sequential/) support for dense labels
    - Example: Single class weight value for each class in an image segmentation task such as in Pascal VOC 2012.
 - Sparse to Dense Prediction weight transfer
    - [Conversion of ImageNet weights from pre-trained models](https://github.com/tensorflow/models/tree/master/slim#pre-trained-models) for segmentation tasks
    - [Keras-FCN example](https://github.com/aurora95/Keras-FCN/blob/master/utils/transfer_FCN.py)
    - [Locking of batch normalization layers](https://github.com/tensorflow/tensorflow/issues/1122), often used during transfer process
 - Automatic Sparse to Dense Model conversion (advanced)
   - configuration at each downsampling stage
   - remove pooling layers and apply an equivalent atrous dilation in the next convolution layer
   - add an upsampling layer for each downsampling stage
 - SegmentationTop Layer?
   - Sigmoid single class predictions
   - Spatial Softmax argmax multi class predictions
   - Multi Label Predictions (sigmoid?)
 - ""Upsample"" Layer?
   - like ""Activation"" layer, where reasonable upsampling approaches can be defined with a simple string parameter
 - Example implementation training & testing on [MSCOCO](https://github.com/farizrahman4u/keras-contrib/pull/81) & [Pascal VOC 2012 + extended berkeley labels](https://github.com/farizrahman4u/keras-contrib/pull/80)
    - (advanced) pretrain pascal voc on coco then VOC
 - COCO [pycocotools](https://github.com/pdollar/coco/tree/master/PythonAPI/pycocotools) json format dataset support [used by several datasets](mscoco.org/external/)
    - supports multi-label segmentation, keypoint data, image descriptions, and more
 - TFRecord dataset support (probably TensorFlow only, maybe only in tensorflow implementation of keras)
 - flow_from_directory & Segmentation Data Generator
   - [Keras-FCN](https://github.com/ahundt/Keras-FCN/blob/master/utils/SegDataGenerator.py), 
   - Single class label support
   - Multi class label support
 - mean Intesection Over Union (mIOU) utility [Keras-FCN](https://github.com/ahundt/Keras-FCN/blob/master/evaluate.py) 
 - Image and label masks
 - Proper [palette handling for png based labels](https://github.com/nicolov/segmentation_keras/issues/14)
 - sparse label format for multi-label data?
 - debugging utilities
     - save predictions to file
 - Iterative training of partial networks at varying strides, as described in the FCN paper (advanced, may not be necessary as per Keras-FCN performance)
 
## Existing Keras Utilities with compatible license

 - [keras-contrib](https://github.com/farizrahman4u/keras-contrib) has:
     - [DensenetFCN](https://github.com/farizrahman4u/keras-contrib/blob/master/keras_contrib/applications/densenet.py) implementation
     - [MSCOCO](https://github.com/farizrahman4u/keras-contrib/pull/81)
     - [Pascal VOC 2012 + extended berkeley labels](https://github.com/farizrahman4u/keras-contrib/pull/80)
     - a couple of upsampling approaches
     - https://github.com/farizrahman4u/keras-contrib/issues/47 incorporating coco + voc 2012
 - [Keras-FCN](https://github.com/aurora95/Keras-FCN)
    - I've been working on this one, current basis for design suggestions
 - [segmentation_keras](https://github.com/nicolov/segmentation_keras)
     - includes example using caffe weight conversion utilties
     - fairly clean
 - [enet-keras](https://github.com/PavlosMelissinos/enet-keras)
     - includes work towards mscoco support
 - https://github.com/azavea/raster-vision/ 
    - is apache v2 compatible? I think so if keras is in tf now
 -  https://github.com/JihongJu/keras-fcn

## Questions

 - Is something as clear as [30 seconds to keras segmentation possible]((https://keras.io/#getting-started-30-seconds-to-keras))?
 - Is anything above missing, redundant, or out of date compared to the state of the art?
 - Should the current ImageDataGenerator be extended or is a separate class like [Keras-FCN's SegDataGenerator](https://github.com/ahundt/Keras-FCN/blob/master/utils/SegDataGenerator.py) clearer?
 - Should there be a guide of some sort?
 - What will make for useful training progress and debugging data? (sparse mIOU?, something else?)
 - What is needed to handle large datasets quickly and efficiently? (should this be out of scope?)",ahundt,b'Enhancement stat:contributions welcome',2017-05-08T03:01:09Z,2018-10-11T18:21:53Z
6529,Fix failture of loading custom activation function with `keras.models.load_models(custom_objects=*)`,"Custom activation functon can't load with `keras.models.load_models(custom_objects=*)`, because given`custom_objects` doesn't bypass to `deserialize_keras_object()` through `keras.activations.get()`.

In initialization of layer (`Layer.__init__()`), the custom activation function is given as an `activation` argument as a string identifier, and deserialize it by calling `keras.activations.get()`. However, layers and `keras.activations.get()` don't take `custom_objects` as an argument. The deserialization of custom activation function is failed with `Unknown activation function` error.

To fix this bug,  use `CustomObjectScope` in `keras.models.load_models()`. By doing so, bypassing `custom_objects` over many function is not required.

Test code:
```python
import keras
import keras.backend as K
import keras.layers as L
import keras.engine import Input, Model

x = Input((28,))
y = L.Dense(10, activation=K.sin)(x)
model = Model(x, y)
model.save('model.h5')
```

Failed code
```python
import keras
import keras.backend as K

keras.models.load_models('model.h5', custom_objects={'sin': K.sin})
```
```
ValueError: ('Unknown activation function', ':sin')
```

Succeeded code
```python
import keras
import keras.backend as K
from keras.genetic_utils import CustomObjectScope

with CustomObjectScope({'sin': K.sin}):
  keras.models.load_models('model.h5')
```",cocuh,None,2017-05-07T00:52:06Z,2017-05-23T18:30:46Z
6528,keras.preprocessing.image is using float32 instead of uint8,"I was using 
```
from keras.preprocessing import image
img_path = ""/root/.../tmpImage.png""
img = image.load_img(img_path, target_size=(224, 224))
img = image.img_to_array(img)
```
to get the an array from that image and then save it. I quickly ran out of space, because img_to_array is retruning dtype of float32. 

```
print(type(img))
print(img.shape, img.dtype)
<class 'numpy.ndarray'>
(224, 224, 3) float32
```

For this part I will switch to scipy because they are using unit8. This is a minor bug but can be anoying to trace down.
Cheers!",Pavel-Konarik,b'stale',2017-05-06T22:23:11Z,2017-09-11T14:11:38Z
6522,Different behaviours between MacOS and Amazon EC2 g2.2 (Building powerful... blog),"Hello everyone, 

I scratch my head since yesterday on a strange bug. I copy/paste the code from the Building powerful image classification blog post (https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html). For the first example, when I tried on my MacOS, it works well (using the CPU), but when I try the same code, same images (cats and dogs) on Amazon EC2 g2x2 instance with the same install:
Python 2.7.13
Keras 2.0.4
Theano 0.9.0
I got this error:
ValueError: ('The specified size contains a dimension with value <= 0', (-2176, 64))

The only difference is I am using CPU on MacOSX and GPU on Amazon EC2

Obviously, I checked keras.json and both backend and image_dim_ordering are set to theano and th. 

I don't understand where the problem is, if somebody has clues. Thanks in advance

mph
",mphuget,b'stale',2017-05-05T13:01:37Z,2017-09-02T16:51:35Z
6521,Epoch is not working properly for KerasRegressor,"I'm just getting start with Keras using tensorflow, In the code code I have specified **nb_epoch=100** but it's not running for 100 epoch, instead it's executing only for 10 epoch. I wonder is there any bug in my code. Also attaching the output in the bottom

**Code:**

```python

import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
import sklearn.metrics as metrics
from utils import encode_numeric_zscore, to_xy

dataset = pd.read_csv('data/boston-housing.csv', dtype=np.float32)

for col in dataset.columns:
    if col != 'medv':
        encode_numeric_zscore(dataset, col)

features, target = to_xy(dataset, 'medv')

X_train, X_test, Y_train, Y_test = train_test_split(features, target, test_size=0.25, random_state=42)


def chart_regression(pred, y):
    t = pd.DataFrame({'pred': pred, 'y': Y_test.flatten()})
    t.sort_values(by=['y'], inplace=True)
    a = plt.plot(t['y'].tolist(), label='expected')
    b = plt.plot(t['pred'].tolist(), label='prediction')
    plt.ylabel('output')
    plt.legend()
    plt.show()


from tensorflow.contrib.keras.api.keras.models import Sequential
from tensorflow.contrib.keras.api.keras.layers import Dense, Dropout


def build_nn():
    model = Sequential()
    model.add(Dense(75, input_shape=(13,), activation=""relu"", kernel_initializer=""glorot_uniform""))
    model.add(Dense(55, activation=""relu""))
    model.add(Dropout(0.005))
    model.add(Dense(35, activation=""relu""))
    model.add(Dropout(0.005))
    model.add(Dense(11, activation=""relu""))
    model.add(Dropout(0.005))
    model.add(Dense(1, activation='relu', kernel_initializer=""normal""))
    model.compile(loss='mean_squared_error', optimizer='adam')
    return model


seed = 7
np.random.seed(seed)

from tensorflow.contrib.keras.api.keras.wrappers.scikit_learn import KerasRegressor

regressor = KerasRegressor(build_fn=build_nn, nb_epoch=100, batch_size=1, verbose=1)

regressor.fit(X_train, Y_train)

prediction = regressor.predict(X_test, batch_size=1)

score = metrics.mean_squared_error(Y_test, prediction)

print('\n')

print(""Final score (MSE): {}"".format(score))

print('\n')

score = np.sqrt(metrics.mean_squared_error(prediction, Y_test))
print(""Final score (RMSE): {}"".format(score))

chart_regression(prediction, Y_test)
```

**Output:**

```
Epoch 1/10
2017-05-05 15:30:37.711608: W c:\tf_jenkins\home\workspace\release-win\device\cpu\os\windows\tensorflow\core\platform\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE instructions, but these are available on your machine and could speed up CPU computations.
2017-05-05 15:30:37.711981: W c:\tf_jenkins\home\workspace\release-win\device\cpu\os\windows\tensorflow\core\platform\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE2 instructions, but these are available on your machine and could speed up CPU computations.
2017-05-05 15:30:37.712355: W c:\tf_jenkins\home\workspace\release-win\device\cpu\os\windows\tensorflow\core\platform\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE3 instructions, but these are available on your machine and could speed up CPU computations.
2017-05-05 15:30:37.712721: W c:\tf_jenkins\home\workspace\release-win\device\cpu\os\windows\tensorflow\core\platform\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2017-05-05 15:30:37.713094: W c:\tf_jenkins\home\workspace\release-win\device\cpu\os\windows\tensorflow\core\platform\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2017-05-05 15:30:37.713463: W c:\tf_jenkins\home\workspace\release-win\device\cpu\os\windows\tensorflow\core\platform\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2017-05-05 15:30:37.713839: W c:\tf_jenkins\home\workspace\release-win\device\cpu\os\windows\tensorflow\core\platform\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2017-05-05 15:30:37.714213: W c:\tf_jenkins\home\workspace\release-win\device\cpu\os\windows\tensorflow\core\platform\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
  1/379 [..............................] - ETA: 107s - loss: 492.8400
 60/379 [===>..........................] - ETA: 1s - loss: 669.9998  
109/379 [=======>......................] - ETA: 0s - loss: 625.8113
172/379 [============>.................] - ETA: 0s - loss: 461.0169
233/379 [=================>............] - ETA: 0s - loss: 353.9863
286/379 [=====================>........] - ETA: 0s - loss: 294.3637
336/379 [=========================>....] - ETA: 0s - loss: 254.4181
379/379 [==============================] - 0s - loss: 230.0349     
Epoch 2/10
  1/379 [..............................] - ETA: 0s - loss: 8.0337
 55/379 [===>..........................] - ETA: 0s - loss: 26.7809
104/379 [=======>......................] - ETA: 0s - loss: 22.0314
171/379 [============>.................] - ETA: 0s - loss: 25.4361
219/379 [================>.............] - ETA: 0s - loss: 28.0947
285/379 [=====================>........] - ETA: 0s - loss: 26.3540
338/379 [=========================>....] - ETA: 0s - loss: 26.1902
379/379 [==============================] - 0s - loss: 24.4095     
Epoch 3/10
  1/379 [..............................] - ETA: 0s - loss: 9.8365
 42/379 [==>...........................] - ETA: 0s - loss: 20.2841
108/379 [=======>......................] - ETA: 0s - loss: 16.0308
161/379 [===========>..................] - ETA: 0s - loss: 18.4792
225/379 [================>.............] - ETA: 0s - loss: 18.9558
288/379 [=====================>........] - ETA: 0s - loss: 16.6939
379/379 [==============================] - 0s - loss: 18.3086     
Epoch 4/10
  1/379 [..............................] - ETA: 0s - loss: 13.7463
 59/379 [===>..........................] - ETA: 0s - loss: 12.0900
115/379 [========>.....................] - ETA: 0s - loss: 18.4202
181/379 [=============>................] - ETA: 0s - loss: 16.6087
244/379 [==================>...........] - ETA: 0s - loss: 15.0061
302/379 [======================>.......] - ETA: 0s - loss: 13.2268
379/379 [==============================] - 0s - loss: 16.0613     
Epoch 5/10
  1/379 [..............................] - ETA: 0s - loss: 25.8912
 65/379 [====>.........................] - ETA: 0s - loss: 28.8039
123/379 [========>.....................] - ETA: 0s - loss: 21.3528
199/379 [==============>...............] - ETA: 0s - loss: 17.8586
256/379 [===================>..........] - ETA: 0s - loss: 19.4171
327/379 [========================>.....] - ETA: 0s - loss: 17.9864
379/379 [==============================] - 0s - loss: 18.2714     
Epoch 6/10
  1/379 [..............................] - ETA: 0s - loss: 2.0872
 61/379 [===>..........................] - ETA: 0s - loss: 18.4408
115/379 [========>.....................] - ETA: 0s - loss: 16.9127
184/379 [=============>................] - ETA: 0s - loss: 16.9419
247/379 [==================>...........] - ETA: 0s - loss: 16.2630
314/379 [=======================>......] - ETA: 0s - loss: 14.9947
379/379 [==============================] - 0s - loss: 13.5761     
Epoch 7/10
  1/379 [..............................] - ETA: 0s - loss: 0.3704
 59/379 [===>..........................] - ETA: 0s - loss: 15.2191
118/379 [========>.....................] - ETA: 0s - loss: 11.8381
188/379 [=============>................] - ETA: 0s - loss: 10.9623
247/379 [==================>...........] - ETA: 0s - loss: 10.0409
313/379 [=======================>......] - ETA: 0s - loss: 12.4478
379/379 [==============================] - 0s - loss: 13.8573     
Epoch 8/10
  1/379 [..............................] - ETA: 0s - loss: 1.2173
 44/379 [==>...........................] - ETA: 0s - loss: 12.5116
 96/379 [======>.......................] - ETA: 0s - loss: 10.2578
170/379 [============>.................] - ETA: 0s - loss: 11.9057
227/379 [================>.............] - ETA: 0s - loss: 12.1961
287/379 [=====================>........] - ETA: 0s - loss: 14.4951
341/379 [=========================>....] - ETA: 0s - loss: 13.7772
379/379 [==============================] - 0s - loss: 13.2340     
Epoch 9/10
  1/379 [..............................] - ETA: 0s - loss: 0.1982
 53/379 [===>..........................] - ETA: 0s - loss: 9.8250
124/379 [========>.....................] - ETA: 0s - loss: 9.8112
175/379 [============>.................] - ETA: 0s - loss: 10.9075
238/379 [=================>............] - ETA: 0s - loss: 11.3589
303/379 [======================>.......] - ETA: 0s - loss: 13.8970
379/379 [==============================] - 0s - loss: 14.5469     
Epoch 10/10
  1/379 [..............................] - ETA: 0s - loss: 3.7164
 49/379 [==>...........................] - ETA: 0s - loss: 14.6596
116/379 [========>.....................] - ETA: 0s - loss: 15.5960
172/379 [============>.................] - ETA: 0s - loss: 13.6525
223/379 [================>.............] - ETA: 0s - loss: 12.9588
275/379 [====================>.........] - ETA: 0s - loss: 12.4905
347/379 [==========================>...] - ETA: 0s - loss: 13.5629
379/379 [==============================] - 0s - loss: 13.1696     
  1/127 [..............................] - ETA: 1s

Final score (MSE): 11.964310646057129


Final score (RMSE): 3.458946466445923

```",ghost,None,2017-05-05T10:24:43Z,2017-05-08T05:56:45Z
6483,Fix for weight loading bug with `channels_first`,"@fchollet This is the start of a fix for the `channels_first` weight loading bug. The bug is due to loading weights from Keras 1 models that used the Tensorflow backend. The current weight loading code assumes all Keras 1 models have Theano dim ordering and so things get messed up. Also the `original_backend` is not found automatically in the old models and so is set to `None`, which makes it difficult or impossible to always convert correctly. Thus I made it so the user can specify the `original_backend` so things can be appropriately converted. Note that I removed `layer_utils.convert_all_kernels_in_model(model)` from the vgg16 example since the weight loading code takes care of the kernel flipping already.

TODO:
1) Properly handle `Conv1D ` and `Conv2DTranspose`. I wasn't sure exactly what to do here so I left it alone, but the same issues probably apply.
2) Fix other applications where weight loading is a problem.",the-moliver,None,2017-05-03T01:21:02Z,2017-05-23T21:15:26Z
6481,Bug loading a model with an add layer,"I created a model with some shared layers (a `Dense` in the example) and use an `add` layer, it fails to `load_model`. This is an example:

    from keras.models import Model, load_model
    from keras.layers import Dense, Input, add 
    x = Input(shape=(100,))
    y = x 
    weights = Dense(100)
    for _ in range(5):
        yp = weights(y)
        y = add([yp, y]) 
    model = Model(x, y)
    model.save('test.h5')
    model2 = load_model('test.h5')

that fails with:
```
Using TensorFlow backend.
Traceback (most recent call last):
  File ""test.py"", line 16, in <module>
    model2 = load_model('test.h5')
  File ""/home/javier/.local/lib/python3.5/site-packages/keras/models.py"", line 240, in load_model
    model = model_from_config(model_config, custom_objects=custom_objects)
  File ""/home/javier/.local/lib/python3.5/site-packages/keras/models.py"", line 304, in model_from_config
    return layer_module.deserialize(config, custom_objects=custom_objects)
  File ""/home/javier/.local/lib/python3.5/site-packages/keras/layers/__init__.py"", line 54, in deserialize
    printable_module_name='layer')
  File ""/home/javier/.local/lib/python3.5/site-packages/keras/utils/generic_utils.py"", line 140, in deserialize_keras_object
    list(custom_objects.items())))
  File ""/home/javier/.local/lib/python3.5/site-packages/keras/engine/topology.py"", line 2416, in from_config
    process_layer(layer_data)
  File ""/home/javier/.local/lib/python3.5/site-packages/keras/engine/topology.py"", line 2403, in process_layer
    raise ValueError('Missing layer: ' + inbound_layer_name)}
 ValueError: Missing layer: add_1
```",javiercorrea,b'stale',2017-05-02T21:07:19Z,2017-12-05T16:22:07Z
6448,Layer Reshape along the sample axis,"Hi, I wonder is that possible to reshape a keras tensor along a sample axis? For example, something looks like

```
from keras.layers import Input
from keras.layers.core import Reshape

input_shape = (5,32,32,1) # the batch size is 5
tensor = Input(batch_shape=input_shape)
new_tensor = Reshape((1,)+tensor._keras_shape)(tensor)	# the new tensor should be (1,5,32,32,1)
```

I have a bug when trying the above code: ValueError: total size of new array must be unchanged

It seems that keras does not allow to change the size of sample axis, it this true? Is there any solution to this problem?

Thanks!
",xn8812,b'stale type:support',2017-04-30T02:30:15Z,2017-08-29T16:18:01Z
6442,Bug with saving the model,"I want to rescale the outputs of my model, so I do the following.

```python
state_in = ...
h = ...
scale_vector = K.variable(value=np_scale_vector) # np_scale_vector is a numpy array
out = Lambda(lambda x: x * scale_vector, output_shape=(n_out,))(h)

model = Model(inputs=[state_in], outputs=[out])
model.save(filename)
```
I get:
```
  File ""/usr/local/lib/python2.7/dist-packages/keras/engine/topology.py"", line 2434, in save
    save_model(self, filepath, overwrite, include_optimizer)
  File ""/usr/local/lib/python2.7/dist-packages/keras/models.py"", line 102, in save_model
    'config': model.get_config()
  File ""/usr/local/lib/python2.7/dist-packages/keras/engine/topology.py"", line 2311, in get_config
    return copy.deepcopy(config)
  File ""/usr/lib/python2.7/copy.py"", line 163, in deepcopy
    y = copier(x, memo)
  File ""/usr/lib/python2.7/copy.py"", line 182, in deepcopy
    rv = reductor(2)
TypeError: can't pickle NotImplementedType objects
```

If I, on the other hand do

```python
out = Lambda(lambda x: x * np_scale_vector, output_shape=(n_out,))(h)
```

I get:
```
  File ""/usr/local/lib/python2.7/dist-packages/keras/engine/topology.py"", line 2434, in save
    save_model(self, filepath, overwrite, include_optimizer)
  File ""/usr/local/lib/python2.7/dist-packages/keras/models.py"", line 103, in save_model
    }, default=get_json_type).encode('utf8')
  File ""/usr/lib/python2.7/json/__init__.py"", line 251, in dumps
    sort_keys=sort_keys, **kw).encode(obj)
  File ""/usr/lib/python2.7/json/encoder.py"", line 207, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File ""/usr/lib/python2.7/json/encoder.py"", line 270, in iterencode
    return _iterencode(o, 0)
  File ""/usr/local/lib/python2.7/dist-packages/keras/models.py"", line 77, in get_json_type
    return obj.item()
ValueError: can only convert an array of size 1 to a Python scalar
```

I want to emphasize that the model compiles, works, I can see that I am getting proper outputs, but the save fails.",hamzamerzic,None,2017-04-29T13:34:29Z,2017-05-01T07:58:50Z
6405,Possible bug in `self._collected_trainable_weights` with effects on GAN training,"Hi,
I was going over the source code to try to understand why changing a model's `Trainable` property failed to update the model parameters after calling `fit()` (even though they would appear in `model.trainable_weights`). I found that the property `self._collected_trainable_weights` is set only once in Model's `compile`:
https://github.com/fchollet/keras/blob/master/keras/engine/training.py#L995
and never updates afterwards, even if `self.trainable_weights` changes.
Then, when we call `fit()` for the first time, `_make_train_function` is called, which uses the old (and out of date) `self._collected_trainable_weights`. 
This might be caused from a code addition of `trainable_weights.sort` in `compile`, which makes a local variable instead of setting `self._collected_trainable_weights` to be a reference to  `self.trainable_weights`.
Is this intended behavior or a bug with updating model `Trainable` flag?
Many thanks,
Yarin",yaringal,None,2017-04-26T08:52:56Z,2017-04-27T01:46:10Z
6403,Merging (concat) with theano and tensorflow gives different tensor,"Hello,
So I have been using theano till recently for my backend. During the merge operations when I would use concat the dimensions on one axis would double. Eg is my two tensors were 50x50 and 50x50 the resultant merged tensor would be 50x100,
However now that I am using tensorflow, on combining two tensors 50x50 and 50x50 using concat the output tensor is 50x50. 
Is that normal? Or is there a bug in my code somewhere while using tensorflow.
Thank you!

- [ -] Check that you are up-to-date with the master branch of Keras. You can update with:
pip install git+git://github.com/fchollet/keras.git --upgrade --no-deps

- [- ] If running on TensorFlow, check that you are up-to-date with the latest version. The installation instructions can be found [here](https://www.tensorflow.org/get_started/os_setup).

- [- ] If running on Theano, check that you are up-to-date with the master branch of Theano. You can update with:
pip install git+git://github.com/Theano/Theano.git --upgrade --no-deps

- [ ] Provide a link to a GitHub Gist of a Python script that can reproduce your issue (or just copy the script here if it is short).
",raun1,None,2017-04-26T03:05:07Z,2017-08-04T02:18:18Z
6393,Bug fix in recurrent layer,"The variable `values` is not defined in the file, 

@Joshua-Chin: Could you check that this is correct?",Danielhiversen,None,2017-04-25T08:47:11Z,2017-04-25T18:05:53Z
6391,TimeDistributed(Dense) learns differently depending on sequence length,"I have a sequence of 2-dimensional vector which is fed into a simple model which has TimeDistributed(Dense) layers. The 2D vectors are sliced in chunks of sequence_length.

My model:
```python
x = Input(shape=(sequence_length, 2,), name='input')

y = TimeDistributed(Dense(128, activation='relu', name='fc1'))(x)
y = TimeDistributed(Dense(128, activation='relu', name='fc2'))(y)
y = TimeDistributed(Dense(6, activation='softmax', name='predictions'))(y)

Model = Model(input=x, output=y)
```

The model does not learn anything (constant output regardless of input) when the sequence_length is set to 1, but the model is able to learn something when sequence_length is set to something bigger.

My understanding of TimeDistributed was that it applies the underlying layer independently to dimension one (in my case sequence_length dimension), so it should not matter how long the sequence is. In other words, my understanding of TimeDistributed was that it would effectively apply the following model to 2D vector at each timestep along sequence_length:

```python
x = Input(shape=(2,), name='input')

y = Dense(128, activation='relu', name='fc1')(x)
y = Dense(128, activation='relu', name='fc2')(y)
y = Dense(6, activation='softmax', name='predictions')(y)

Model = Model(input=x, output=y)
```

Is this a bug? Thank you for your help.

I am using the latest version of Keras 2.0.3 with Tensorflow-GPU 1.0.1.",se210,b'stale',2017-04-25T03:25:18Z,2017-08-24T14:24:15Z
6390,Add a term in the cell function of LSTM,"I want to modify the computing functions of the LSTM layer, just as following formulas:
![image](https://cloud.githubusercontent.com/assets/13865086/25366962/9330befc-29a5-11e7-9d36-761ed64fcaca.png)
where the equations are the same as in standard LSTM networks except that equation 14 has an extra term about y.
I have tried to modify the source code of LSTM layer, but it seems not easy to achieve my expectation:
```
class AttentionLSTM(Recurrent):
        def __init__(self, output_dim, y,
                 init='glorot_uniform', inner_init='orthogonal',
                 forget_bias_init='one', activation='tanh',
                 inner_activation='hard_sigmoid',
                 W_regularizer=None, U_regularizer=None, b_regularizer=None,
                 dropout_W=0., dropout_U=0., **kwargs):
                 self.y = y
       def build(self, input_shape):
                 self.U_m = self.inner_init((self.output_dim, self.output_dim),
                                   name='{}_U_m'.format(self.name))
       def step(self, x, states):
                 h_tm1 = states[0]
                 c_tm1 = states[1]
                 B_U = states[2]
                 B_W = states[3]
                 y = states[4]

                if self.consume_less == 'cpu':
                     x_i = x[:, :self.output_dim]
                     x_f = x[:, self.output_dim: 2 * self.output_dim]
                     x_c = x[:, 2 * self.output_dim: 3 * self.output_dim]
                     x_o = x[:, 3 * self.output_dim:]
               else:
                     x_i = K.dot(x * B_W[0], self.W_i) + self.b_i
                     x_f = K.dot(x * B_W[1], self.W_f) + self.b_f
                     x_c = K.dot(x * B_W[2], self.W_c) + self.b_c
                     x_o = K.dot(x * B_W[3], self.W_o) + self.b_o

                     i = self.inner_activation(x_i + K.dot(h_tm1 * B_U[0], self.U_i))
                     f = self.inner_activation(x_f + K.dot(h_tm1 * B_U[1], self.U_f))
#Here I want to add a term, I do not know if the formula I gave is correct.
                     c = f * c_tm1 + i * self.activation(x_c + K.dot(h_tm1 * B_U[2], self.U_c)) + K.tanh(K.dot(y,self.U_m))
                     o = self.inner_activation(x_o + K.dot(h_tm1 * B_U[3], self.U_o))

                h = o * self.activation(c)
                return h, [h, c]
```
But the error is: 
```
ValueError: dimension mismatch in args to gemm (50,1)x(128,128)->(50,128)
Apply node that caused the error: GpuDot22(GpuFromHost.0, attentionlstm_20_U_m)
Toposort index: 94
Inputs types: [CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix)]
Inputs shapes: [(50, 1), (128, 128)]
Inputs strides: [(1, 0), (128, 1)]
Inputs values: ['not shown', 'not shown']
Outputs clients: [[GpuDot22(GpuDot22.0, attentionlstm_20_U_m)]]

HINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.
HINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.
```
Where is the mistake? Please give me some advice.",Imorton-zd,None,2017-04-25T03:03:08Z,2017-04-28T01:33:58Z
6384,Deconv2D under theano backend not working properly,"The following gist (https://gist.github.com/izikgo/c381812b4eca2f05f0fe18bfecf561f8) contains a very simple code which breaks under Theano and works fine under TF.
The error I get:
```ValueError: impossible convolution output dim: expected 1x1x8x8 but received gradient with shape 1x1x7x7
Apply node that caused the error: GpuDnnConvGradI{algo='none', inplace=True}(GpuContiguous.0, GpuContiguous.0, GpuAllocEmpty.0, GpuDnnConvDesc{border_mode='half', subsample=(2, 2), conv_mode='conv', precision='float32'}.0, Constant{1.0}, Constant{0.0})
Toposort index: 29
Inputs types: [CudaNdarrayType(float32, 4D), CudaNdarrayType(float32, 4D), CudaNdarrayType(float32, 4D), <theano.gof.type.CDataType object at 0x7fb349630400>, Scalar(float32), Scalar(float32)]
Inputs shapes: [(1, 256, 4, 4), (1, 1, 7, 7), (1, 256, 14, 14), 'No shapes', (), ()]
Inputs strides: [(0, 16, 4, 1), (0, 0, 7, 1), (0, 196, 14, 1), 'No strides', (), ()]
Inputs values: ['not shown', 'not shown', 'not shown', <capsule object NULL at 0x7fb3495ff720>, 1.0, 0.0]
Inputs name: ('kernel', 'grad', 'output', 'descriptor', 'alpha', 'beta')

Outputs clients: [[GpuSubtensor{int64:int64:int8, int64:int64:int8, int64:int64:int8, :int64:}(GpuDnnConvGradI{algo='none', inplace=True}.0, ScalarFromTensor.0, ScalarFromTensor.0, Constant{1}, ScalarFromTensor.0, ScalarFromTensor.0, Constant{1}, ScalarFromTensor.0, ScalarFromTensor.0, Constant{1}, ScalarFromTensor.0)]]

HINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.
HINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.```",izikgo,None,2017-04-24T14:53:22Z,2017-04-25T08:44:36Z
6367,Trainable property bugs,"The trainable properties is not clear currently.

There are two properties related to trainable:
* ```trainable_weight``` which is a accumulation of the trainable weights in each layer so it depends on the current trainable property of each layer
* ```_collected_trainable_weights``` which is the property which is used in fact during the update. It is decided during compilation

So in fact Keras supports sharing layers with different trainable property in different models. But somehow this two concept is quite confused. 

Also I noticed that in the model ***summary*** ```trainable_weight``` is used which is not correct.",bobchennan,None,2017-04-22T19:18:32Z,2017-04-22T19:47:54Z
6344,UpSampling1D not able to handle sequences of unknown length,"The code below throws error for unknown dimension. Since UpSampling1D is repeating each element 'size' times along axis 1, I thought it should be able to handle unknown length sequences.

I have a time sequence of 2D vector with an unknown length. I wanted to perform a time convolution on the sequence to extract some features over the 2D vector's time trajectory, and classify based on these features. Since the classification needs to be done on a per-sample basis, I upsample back to the original length via UpSampling1D.

Is there something wrong with the way I am using this or is there a bug? Thank you for an amazing platform.

I am using the latest version of Keras from GitHub, and Tensorflow-GPU 1.0.1.

```python
x = Input(shape=(None, 2,))

y = x
y = Conv1D(32, 3, activation='relu', padding='causal')(y)
y = Conv1D(32, 3, activation='relu', padding='causal')(y)
y = MaxPooling1D(pool_size=2, strides=2)(y)

# Upsample back so output length matches input length
y = UpSampling1D(size=8)(y)

# Classification
y = TimeDistributed(Dense(128, activation='relu'))(y)
y = TimeDistributed(Dense(6, activation='softmax', name='predictions'))(y)

model = Model(inputs=x, outputs=y)
```

ValueError: Axis 1 of input tensor should have a defined dimension, but is None. Full tensor shape: (None, None, 32). Typically you need to pass a fully-defined `input_shape` argument to your first layer.""",se210,None,2017-04-21T01:43:19Z,2017-04-21T23:16:33Z
6340,Keras 1.1.0 Documentation?,"Because of  Bug [#6339](https://github.com/fchollet/keras/issues/6339), I need to use Keras 1.1.0, but the old documentation is no longer on the site. Is there an old version of the documentation available?",mjs-wpi,None,2017-04-20T23:08:11Z,2017-04-21T00:01:03Z
6339,Large Differences in Performance between Keras 2.0.3 and Keras 1.1.0 – Potential Bug?,"I’ve upgraded to the new verison of Keras and I’m noticing a huge a drop in the performance: from 200 seconds per epoch on the old Keras to 40,000 seconds per epoch on the new Keras.

Attached are two shots showing training on the old Keras and on the new. The models have same architecture are confirmed to both be utilizing the same GPU during training. They are both coded with the functional API. The problem does not change when using different tensorflow backends (0.12 and 1.0). 

After doing these side-by-side tests, I’m thinking this may be a bug with Keras.

Training Output of Keras 1.1.0 (270 sec/epoch):
![kerasold](https://cloud.githubusercontent.com/assets/25262161/25255979/b878359e-25fb-11e7-857a-2c37d7be4561.png)

Training Output of Keras 2.0.3 (38000 sec/epoch):

![kerasnew](https://cloud.githubusercontent.com/assets/25262161/25256006/d7bdf786-25fb-11e7-8df3-93f0bdbf1ea3.png)

",mjs-wpi,None,2017-04-20T23:05:08Z,2017-04-23T00:41:58Z
6308,Bug in Babi MemNN Example in Attention Mechanism,"Please make sure that the boxes below are checked before you submit your issue. If your issue is an implementation question, please ask your question on [StackOverflow](http://stackoverflow.com/questions/tagged/keras) or [join the Keras Slack channel](https://keras-slack-autojoin.herokuapp.com/) and ask there instead of filing a GitHub issue.

Thank you!

- [x] Check that you are up-to-date with the master branch of Keras. You can update with:
pip install git+git://github.com/fchollet/keras.git --upgrade --no-deps

- [x] If running on TensorFlow, check that you are up-to-date with the latest version. The installation instructions can be found [here](https://www.tensorflow.org/get_started/os_setup).

- [ ] If running on Theano, check that you are up-to-date with the master branch of Theano. You can update with:
pip install git+git://github.com/Theano/Theano.git --upgrade --no-deps

- [x] Provide a link to a GitHub Gist of a Python script that can reproduce your issue (or just copy the script here if it is short). (NA)

I was looking at the Keras example for the MemNN model for the babi single supporting task. The paper is here: https://arxiv.org/pdf/1503.08895.pdf (relevant equations/figures are on page 2 in section 2.1)

I believe there is a bug in the implementation here: https://github.com/fchollet/keras/blob/master/examples/babi_memnn.py#L210

`match` is attention over a set of memory vectors represented as `input_encoded_c`. In the paper these are referenced as `p_i` and `c_i` respectively where `p_i` is a scalar and `c_i`is a vector. The formula from the paper broadcasts `p_i` to `c_i` in the sum `o=sum_i p_i*c_i` to produce the final output which in the code is `response`.

The implementation in the models repo uses `response = add([match, input_encoded_c])`. I think this should be something like `response = multiply([match, input_encoded_c])` instead since the current implementation seems to incorrectly correspond to `o=sum_i p_i + c_i`. Perhaps this is also the reason that there is a difference of performance with the paper result of 98.6% vs 100%?

If this does seem like a bug I would be happy to make the change, run the model to make sure it works, and submit a pull request.",EntilZha,b'stale',2017-04-18T18:28:50Z,2017-10-12T06:28:52Z
6273,Keras > 1.1.1 breaks convergence on a net,"Please make sure that the boxes below are checked before you submit your issue. If your issue is an implementation question, please ask your question on [StackOverflow](http://stackoverflow.com/questions/tagged/keras) or [join the Keras Slack channel](https://keras-slack-autojoin.herokuapp.com/) and ask there instead of filing a GitHub issue.

Thank you!

- [X] Check that you are up-to-date with the master branch of Keras. You can update with:
pip install git+git://github.com/fchollet/keras.git --upgrade --no-deps

- [X] If running on TensorFlow, check that you are up-to-date with the latest version. The installation instructions can be found [here](https://www.tensorflow.org/get_started/os_setup).

- [X] If running on Theano, check that you are up-to-date with the master branch of Theano. You can update with:
pip install git+git://github.com/Theano/Theano.git --upgrade --no-deps

- [X] Provide a link to a GitHub Gist of a Python script that can reproduce your issue (or just copy the script here if it is short).

Hi team,

I have been experimenting with this implementation of a convnet:
https://github.com/johnb30/py_crepe

The dataset is available from this link:
https://drive.google.com/drive/folders/0Bz8a_Dbh9Qhbfll6bVpmNUtUcFdjYmF2SEpmZUZUcVNiMUw1TWN6RDV3a0JHT3kxLVhVR2M?usp=sharing (ag_news_csv.tar.gz)

I have found that when using Keras 1.1.1 (or earlier), on both TF and TH backends, this model will start converging and learning (start at 25% and after 9 epochs is >90%). 

Trying on the latest versions of Keras, I will not get any convergence. I iteratively tried different versions of Keras and found that the update from version 1.1.1 to version 1.1.2 is the one that makes the difference. I made no other modifications to the code other than upgrading the Keras package.

Would anyone have any idea what is going on? 

I'd like to be able to experiment with this network on the latest versions of Keras and TF if possible. I would also like to verify if there was a bug that was fixed post 1.1.1 (which then caused the net to break), or if there was a bug that was introduced post 1.1.1 (which then caused the net to break). :)",qichaozhao,None,2017-04-16T18:04:51Z,2017-04-17T19:29:54Z
6248,Adding backwards compatibility for old models by converting input_dtype to dtype,"On Keras 2, loading ResNet50 models saved with Keras 1.2.2 throws a ""got an unexpected keyword argument 'input_dtype'"" exception. Possibly the same problem appears with other models. This is because we are missing a legacy support interface for the input layer. This PR fixes the problem by adding a new legacy support interface that converts the input_dtype parameter to dtype.

Here is how to reproduce the bug:
```
$ pip install keras==1.2.2 tensorflow==0.12.1
$ python
>>> import keras.applications
>>> model = keras.applications.resnet50.ResNet50()
>>> model.save(""model.h5"")
>>> exit()
$ pip install -U keras tensorflow
$ python
>>> from keras.models import load_model
>>> model = load_model(""model.h5"")
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/usr/local/lib/python2.7/dist-packages/keras/models.py"", line 240, in load_model
    model = model_from_config(model_config, custom_objects=custom_objects)
  File ""/usr/local/lib/python2.7/dist-packages/keras/models.py"", line 301, in model_from_config
    return layer_module.deserialize(config, custom_objects=custom_objects)
  File ""/usr/local/lib/python2.7/dist-packages/keras/layers/__init__.py"", line 46, in deserialize
    printable_module_name='layer')
  File ""/usr/local/lib/python2.7/dist-packages/keras/utils/generic_utils.py"", line 140, in deserialize_keras_object
    list(custom_objects.items())))
  File ""/usr/local/lib/python2.7/dist-packages/keras/engine/topology.py"", line 2378, in from_config
    process_layer(layer_data)
  File ""/usr/local/lib/python2.7/dist-packages/keras/engine/topology.py"", line 2347, in process_layer
    custom_objects=custom_objects)
  File ""/usr/local/lib/python2.7/dist-packages/keras/layers/__init__.py"", line 46, in deserialize
    printable_module_name='layer')
  File ""/usr/local/lib/python2.7/dist-packages/keras/utils/generic_utils.py"", line 141, in deserialize_keras_object
    return cls.from_config(config['config'])
  File ""/usr/local/lib/python2.7/dist-packages/keras/engine/topology.py"", line 1210, in from_config
    return cls(**config)
TypeError: __init__() got an unexpected keyword argument 'input_dtype'
```",datumbox,None,2017-04-14T10:38:30Z,2017-04-15T23:11:18Z
6234,Test Generator Filenames: Not shuffled when shuffle=True,"Normal Behavior:
```    
test_generator = test_datagen.flow_from_directory(test_data_dir,
                                                      target_size=(img_height, img_width),
                                                      batch_size=batch_size,
                                                      shuffle=False)
y_probabilities = model.predict_generator(test_generator,
                                              val_samples=test_generator.nb_sample)
y_predictions = probas_to_classes(y_probabilities)

```
True: `y_predictions[0] == test_generator.classes[0]`

Because `shuffle=False` I can map `test_generator.filenames` or `test_generator.classes` to the output predictions without any problems. `y_predictions[0] == test_generator.classes[0]`

However, I have an edge case where I need/want to make `shuffle=True`, but I cannot map `test_generator.filenames` and `test_generator.classes` to the out predictions. This is because `test_generator.filenames` returns the list before shuffling and the `y_probabilities` return the list are shuffling. 

Error/Bug:
```
test_generator = test_datagen.flow_from_directory(test_data_dir,
                                                      target_size=(img_height, img_width),
                                                      batch_size=batch_size,
                                                      shuffle=True)
y_probabilities = model.predict_generator(test_generator,
                                              val_samples=test_generator.nb_sample)
y_predictions = probas_to_classes(y_probabilities)
```
False: `y_predictions[0] == test_generator.classes[0]`

Please, someone, help me solve this bug.
Thanks.",avn3r,b'stale',2017-04-12T23:05:02Z,2017-09-29T18:43:25Z
6219,Bug fix: K.batch_dot(); tf backend,#6173 ,farizrahman4u,None,2017-04-10T20:50:42Z,2017-04-10T23:12:09Z
6210,legacy_generator_methods_support: Legacy parameter convertion bug,"In legacy generator convertor, I'm sure that `val_samples` in ver. 1 is not equavalent to 'steps' in ver. 2. I suggest divede by batch_size when converting.

Howerver, it seems not able to get batch_size from generator interface. Can you guys suggest a way to fix this? I'm willing to contribute code.

    gen = ImageDataGenerator()
    train_batches = gen.flow_from_directory(""data/train"", model.input_shape[1:3], shuffle=False, batch_size=16)

    train_bottleneck = model.predict_generator(train_batches, train_batches.samples)

    # This predict_generator will iterate over dataset for N times where N is `train_batch.batch_size`.

while...

    train_bottleneck = model.predict_generator(train_batches, -(-train_batches.samples // train_batches.batch_size))  
    
    # This yeilds the right thing.
",SolessChong,b'stale',2017-04-10T10:26:03Z,2017-08-12T13:15:36Z
6195,Some errors when running variational_autoencoder_deconv example.,"The variational_autoencoder_deconv example is from keras version 1.2.2 
The errors:
```
RuntimeError: GpuDnnConvGradI: error getting worksize: CUDNN_STATUS_BAD_PARAM
Apply node that caused the error: GpuDnnConvGradI{algo='none', inplace=True}(GpuContiguous.0, GpuContiguous.0, GpuAllocEmpty.0, GpuDnnConvDesc{border_mode='half', subsample=(1, 1), conv_mode='conv', precision='float32'}.0, Constant{1.0}, Constant{0.0})
Toposort index: 356
Inputs types: [CudaNdarrayType(float32, 4D), CudaNdarrayType(float32, 4D), CudaNdarrayType(float32, 4D), <theano.gof.type.CDataType object at 0x000000018E212B00>, Scalar(float32), Scalar(float32)]
Inputs shapes: [(64, 64, 3, 3), (100, 64, 14, 14), (100, 64, 14, 64), 'No shapes', (), ()]
Inputs strides: [(576, 9, 3, 1), (12544, 196, 14, 1), (57344, 896, 64, 1), 'No strides', (), ()]
Inputs values: ['not shown', 'not shown', 'not shown', <PyCObject object at 0x00000001A9FB39B8>, 1.0, 0.0]
Inputs name: ('kernel', 'grad', 'output', 'descriptor', 'alpha', 'beta')

Outputs clients: [[GpuDimShuffle{0,2,3,1}(GpuDnnConvGradI{algo='none', inplace=True}.0)]]

HINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.
HINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.
```
Please give me some suggestions. If possible, is there some code snippets for semi-supervised learning with VAE. Thanks.",Imorton-zd,None,2017-04-09T02:06:33Z,2017-11-28T17:17:40Z
6193,"Deconvolution layer not supported, while converting caffemodel weight into keras.","HI, I am trying to load caffe_weights .caffemodel file into keras. But getting some errors...

Converting model...
CREATING MODEL
Traceback (most recent call last):
  File ""caffe2keras.py"", line 43, in <module>
    main(args)
  File ""caffe2keras.py"", line 32, in main
    model = convert.caffe_to_keras(args.load_path+'/'+args.prototxt, args.load_path+'/'+args.caffemodel, debug=args.debug)
  File ""/home/rajeev/nabila/keras/keras/caffe/convert.py"", line 43, in caffe_to_keras
    debug)
  File ""/home/rajeev/nabila/keras/keras/caffe/convert.py"", line 305, in create_model
    raise RuntimeError('layer type', type_of_layer, 'used in this model is not currently supported')
RuntimeError: ('layer type', 'deconvolution', 'used in this model is not currently supported')
 
Is deconvulation layer is not supported till now??
Any help please.

Thanks in Advance.
",rajeev-cmi,b'stale',2017-04-08T18:51:49Z,2017-08-12T13:15:46Z
6176,ImportError even though module is imported,"Anyone ever came across this bug: 
```
---------------------------------------------------------------------------
ImportError                               Traceback (most recent call last)
<ipython-input-23-cbcfc17289ab> in <module>()
      2 print('Done!')
      3 model_loaded = get_custom_CNN()
----> 4 model_loaded.load_weights('mdl.h5')

/usr/local/lib/python2.7/dist-packages/keras/models.pyc in load_weights(self, filepath, by_name)
    691     def load_weights(self, filepath, by_name=False):
    692         if h5py is None:
--> 693             raise ImportError('`load_weights` requires h5py.')
    694         f = h5py.File(filepath, mode='r')
    695         if 'layer_names' not in f.attrs and 'model_weights' in f:

ImportError: `load_weights` requires h5py.

```
after running this:
```
import h5py # version 2.7.0
print('Done!')
model_loaded = get_custom_CNN()  #this can really be any network that fits mdl.h5
model_loaded.load_weights('mdl.h5')
```
I even checked the exact condition (`h5py is None` is `False`) after seeing the actual code here:
https://github.com/fchollet/keras/blob/master/keras/models.py

Keras `2.0.2`, tf (`1.0.0`) backend. 
Tried:
* Checking for mismatching environments
* Importing h5py from scratch 
* Some old GH tickets suggested installing cython so i did that
* Searching online",jakubLangr,None,2017-04-06T11:11:22Z,2019-04-11T06:29:15Z
6173,K.batch_dot() doc example fails w/ Tensorflow backend,"From the batch_dot section of the Backend docs (https://keras.io/backend/):

> Shape inference: Let x's shape be (100, 20) and y's shape be (100, 30, 20). If axes is (1, 2), to find the output shape of resultant tensor, loop through each dimension in x's shape and y's shape:
> 
>     x.shape[0] : 100 : append to output shape
>     x.shape[1] : 20 : do not append to output shape, dimension 1 of x has been summed over. (dot_axes[0] = 1)
>     y.shape[0] : 100 : do not append to output shape, always ignore first dimension of y
>     y.shape[1] : 30 : append to output shape
>     y.shape[2] : 20 : do not append to output shape, dimension 2 of y has been summed over. (dot_axes[1] = 2) output_shape = (100, 30)
> 

Actually running this (see below code) produces errors when using the newest Tensorflow.  Seems to be ok with Theano.


Please make sure that the boxes below are checked before you submit your issue. If your issue is an implementation question, please ask your question on [StackOverflow](http://stackoverflow.com/questions/tagged/keras) or [join the Keras Slack channel](https://keras-slack-autojoin.herokuapp.com/) and ask there instead of filing a GitHub issue.

Thank you!

- [x] Check that you are up-to-date with the master branch of Keras. You can update with:
pip install git+git://github.com/fchollet/keras.git --upgrade --no-deps

- [x] If running on TensorFlow, check that you are up-to-date with the latest version. The installation instructions can be found [here](https://www.tensorflow.org/get_started/os_setup).

- [x] If running on Theano, check that you are up-to-date with the master branch of Theano. You can update with:
pip install git+git://github.com/Theano/Theano.git --upgrade --no-deps

- [x] Provide a link to a GitHub Gist of a Python script that can reproduce your issue (or just copy the script here if it is short).
```
from keras import backend as K

x = K.ones(shape=(100,20))
y = K.ones(shape=(100,30,20))
xy = K.batch_dot(x,y,axes=(1,2))
```

Fails with...
Using TensorFlow backend.
Traceback (most recent call last):
  File ""/opt/anaconda/envs/py35/lib/python3.5/site-packages/tensorflow/python/framework/common_shapes.py"", line 671, in _call_cpp_shape_fn_impl
    input_tensors_as_shapes, status)
  File ""/opt/anaconda/envs/py35/lib/python3.5/contextlib.py"", line 66, in __exit__
    next(self.gen)
  File ""/opt/anaconda/envs/py35/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py"", line 466, in raise_exception_on_not_ok_status
    pywrap_tensorflow.TF_GetCode(status))
tensorflow.python.framework.errors_impl.InvalidArgumentError: Shape must be rank 2 but is rank 3 for 'MatMul' (op: 'MatMul') with input shapes: [100,20], [100,30,20].

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""batch_dot_test.py"", line 6, in <module>
    xy = K.batch_dot(x,y,axes=(1,2))
  File ""/opt/anaconda/envs/py35/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py"", line 917, in batch_dot
    out = tf.matmul(x, y, adjoint_a=adj_x, adjoint_b=adj_y)
  File ""/opt/anaconda/envs/py35/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py"", line 1801, in matmul
    a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)
  File ""/opt/anaconda/envs/py35/lib/python3.5/site-packages/tensorflow/python/ops/gen_math_ops.py"", line 1263, in _mat_mul
    transpose_b=transpose_b, name=name)
  File ""/opt/anaconda/envs/py35/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py"", line 768, in apply_op
    op_def=op_def)
  File ""/opt/anaconda/envs/py35/lib/python3.5/site-packages/tensorflow/python/framework/ops.py"", line 2338, in create_op
    set_shapes_for_outputs(ret)
  File ""/opt/anaconda/envs/py35/lib/python3.5/site-packages/tensorflow/python/framework/ops.py"", line 1719, in set_shapes_for_outputs
    shapes = shape_func(op)
  File ""/opt/anaconda/envs/py35/lib/python3.5/site-packages/tensorflow/python/framework/ops.py"", line 1669, in call_with_requiring
    return call_cpp_shape_fn(op, require_shape_fn=True)
  File ""/opt/anaconda/envs/py35/lib/python3.5/site-packages/tensorflow/python/framework/common_shapes.py"", line 610, in call_cpp_shape_fn
    debug_python_shape_fn, require_shape_fn)
  File ""/opt/anaconda/envs/py35/lib/python3.5/site-packages/tensorflow/python/framework/common_shapes.py"", line 676, in _call_cpp_shape_fn_impl
    raise ValueError(err.message)
ValueError: Shape must be rank 2 but is rank 3 for 'MatMul' (op: 'MatMul') with input shapes: [100,20], [100,30,20].

When using Theano, no output appears at all, indicating success.",drscotthawley,b'type:bug/performance',2017-04-06T04:39:47Z,2017-04-10T22:56:11Z
6170,[Not a bug] Bugfix: mistakes in 2 Glorot initializers,"In 2 Glorot initializers `glorot_uniform()` and `glorot_normal()`, `VarianceScaling` object is returned. 
Parameter `scale` passed to create `VarianceScaling` object in function . 

When `distribution` is `normal`, `stddev` of `VarianceScaling` object is `sqrt(scale / n)`. 
But for Glorot normal initializer, `stddev` equals to  `sqrt(2 / n)`. So scale should be `2.` at L322.

When `distribution` is `uniform`, `limit` of `VarianceScaling` object is `sqrt(3 * scale / n)`. 
But for Glorot uniform initializer, `stddev` equals to  `sqrt(6 / n)`. So scale should be `2.` at L346.",tony-hong,None,2017-04-05T21:41:48Z,2017-04-23T09:26:12Z
6169,Embedding layer w/ mask in a nested model,"The following code raises an error on the last line (when attempting to fit the model). However it works fine if mask_zero is set to False. It also works if base_model is added to a Sequential model.

```
import numpy as np

from keras.models import Model
from keras.layers import Input, Embedding, SimpleRNN, Dense


# Base model
base_inputs = Input(shape=(10, ))
embeddings = Embedding(input_dim=100,
                       output_dim=16,
                       mask_zero=True)(base_inputs)
base_out = SimpleRNN(32)(embeddings)
base_model = Model(base_inputs, base_out)

# Using the base model in another model, with the Functional API.
inputs = Input(shape=(10, ))
processed_inputs = base_model(inputs)
out = Dense(1)(processed_inputs)

model = Model(inputs, out)
model.compile(loss='mse', optimizer='rmsprop')

x = np.random.randint(0, 100, (1000, 10))
y = np.random.rand(1000)

model.fit(x, y, epochs=10)
```

Traceback using Tensorflow:
```
Traceback (most recent call last):
  File ""/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1022, in _do_call
    return fn(*args)
  File ""/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1004, in _run_fn
    status, run_metadata)
  File ""/usr/local/Cellar/python3/3.6.0_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/contextlib.py"", line 89, in __exit__
    next(self.gen)
  File ""/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py"", line 469, in raise_exception_on_not_ok_status
    pywrap_tensorflow.TF_GetCode(status))
tensorflow.python.framework.errors_impl.InvalidArgumentError: You must feed a value for placeholder tensor 'input_1' with dtype float
	 [[Node: input_1 = Placeholder[dtype=DT_FLOAT, shape=[], _device=""/job:localhost/replica:0/task:0/cpu:0""]()]]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""temp.py"", line 26, in <module>
    model.fit(x, y, epochs=10)
  File ""/usr/local/lib/python3.6/site-packages/keras/engine/training.py"", line 1486, in fit
    initial_epoch=initial_epoch)
  File ""/usr/local/lib/python3.6/site-packages/keras/engine/training.py"", line 1141, in _fit_loop
    outs = f(ins_batch)
  File ""/usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py"", line 2102, in __call__
    feed_dict=feed_dict)
  File ""/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 767, in run
    run_metadata_ptr)
  File ""/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 965, in _run
    feed_dict_string, options, run_metadata)
  File ""/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1015, in _do_run
    target_list, options, run_metadata)
  File ""/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1035, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.InvalidArgumentError: You must feed a value for placeholder tensor 'input_1' with dtype float
	 [[Node: input_1 = Placeholder[dtype=DT_FLOAT, shape=[], _device=""/job:localhost/replica:0/task:0/cpu:0""]()]]

Caused by op 'input_1', defined at:
  File ""temp.py"", line 8, in <module>
    base_inputs = Input(shape=(10, ))
  File ""/usr/local/lib/python3.6/site-packages/keras/engine/topology.py"", line 1391, in Input
    input_tensor=tensor)
  File ""/usr/local/lib/python3.6/site-packages/keras/engine/topology.py"", line 1302, in __init__
    name=self.name)
  File ""/usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py"", line 350, in placeholder
    x = tf.placeholder(dtype, shape=shape, name=name)
  File ""/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py"", line 1520, in placeholder
    name=name)
  File ""/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py"", line 2149, in _placeholder
    name=name)
  File ""/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py"", line 763, in apply_op
    op_def=op_def)
  File ""/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 2395, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 1264, in __init__
    self._traceback = _extract_stack()

InvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'input_1' with dtype float
	 [[Node: input_1 = Placeholder[dtype=DT_FLOAT, shape=[], _device=""/job:localhost/replica:0/task:0/cpu:0""]()]]
```

Traceback using Theano:
```
Traceback (most recent call last):
  File ""temp.py"", line 26, in <module>
    model.fit(x, y, epochs=10)
  File ""/usr/local/lib/python3.6/site-packages/keras/engine/training.py"", line 1458, in fit
    self._make_train_function()
  File ""/usr/local/lib/python3.6/site-packages/keras/engine/training.py"", line 1008, in _make_train_function
    **self._function_kwargs)
  File ""/usr/local/lib/python3.6/site-packages/keras/backend/theano_backend.py"", line 1132, in function
    return Function(inputs, outputs, updates=updates, **kwargs)
  File ""/usr/local/lib/python3.6/site-packages/keras/backend/theano_backend.py"", line 1118, in __init__
    **kwargs)
  File ""/usr/local/lib/python3.6/site-packages/theano/compile/function.py"", line 326, in function
    output_keys=output_keys)
  File ""/usr/local/lib/python3.6/site-packages/theano/compile/pfunc.py"", line 486, in pfunc
    output_keys=output_keys)
  File ""/usr/local/lib/python3.6/site-packages/theano/compile/function_module.py"", line 1808, in orig_function
    output_keys=output_keys).create(
  File ""/usr/local/lib/python3.6/site-packages/theano/compile/function_module.py"", line 1446, in __init__
    accept_inplace)
  File ""/usr/local/lib/python3.6/site-packages/theano/compile/function_module.py"", line 177, in std_fgraph
    update_mapping=update_mapping)
  File ""/usr/local/lib/python3.6/site-packages/theano/gof/fg.py"", line 174, in __init__
    self.__import_r__(output, reason=""init"")
  File ""/usr/local/lib/python3.6/site-packages/theano/gof/fg.py"", line 345, in __import_r__
    self.__import__(variable.owner, reason=reason)
  File ""/usr/local/lib/python3.6/site-packages/theano/gof/fg.py"", line 390, in __import__
    raise MissingInputError(error_msg, variable=r)
theano.gof.fg.MissingInputError: Input 0 of the graph (indices start from 0), used to compute Elemwise{neq,no_inplace}(/input_1, InplaceDimShuffle{x,x}.0), was not provided and not given a value. Use the Theano flag exception_verbosity='high', for more information on this error.
 
Backtrace when that variable is created:

  File ""temp.py"", line 8, in <module>
    base_inputs = Input(shape=(10, ))
  File ""/usr/local/lib/python3.6/site-packages/keras/engine/topology.py"", line 1391, in Input
    input_tensor=tensor)
  File ""/usr/local/lib/python3.6/site-packages/keras/engine/topology.py"", line 1302, in __init__
    name=self.name)
  File ""/usr/local/lib/python3.6/site-packages/keras/backend/theano_backend.py"", line 184, in placeholder
    x = T.TensorType(dtype, broadcast)(name)
```

OS: Mac OS X
Keras: 2.0.2
Tensorflow (cpu): 1.0.0
Theano: 0.9.0",jpraymond,b'type:bug/performance',2017-04-05T20:48:20Z,2017-04-05T21:41:23Z
6155,"Bug: Input layer with an Input layer as input_tensor results in empty _feed_input_names when building a Model, which makes the model unable to train ","Environment:
```
Ubuntu 16.04,
Python 3.5.3, 
Keras 2.0.2 from pypi, 
Backend: Tensorflow 1.1.0rc0 (with CUDA, self-compiled)
```

Code to reproduce this issue:
```
from keras.engine.topology import get_source_inputs
from keras.layers import Input, Dense
from keras.models import Model

input_shape = (512, 512, 3)

input_tensor = Input(shape = input_shape)
print (input_tensor._keras_history[0].is_placeholder) # True
x_1 = Dense(16)(input_tensor)
model_1 = Model(input_tensor, x_1)
print (len(model_1. _feed_input_names)>0)  #  True

img_input = Input(tensor = input_tensor, shape = input_shape) # <-- Bug here, digested from ./applications/inception_v3.py Line 160

print (img_input._keras_history[0].is_placeholder) # False 
print (input_tensor._keras_history[0].is_placeholder) # False <-- Somehow input_tensor is also modified
x_2 = Dense(16)(img_input)
inputs = get_source_inputs(img_input) # digested from ./applications/inception_v3.py Line 353
model_2 = Model(inputs, x_2) 
print (len(model_2. _feed_input_names)>0)  #  False

# model_2.fit(x, y) will result in 'ValueError: The model expects 0 input arrays', which renders this model untrainable.
```

This bug was originally found when I tried mitigating my code to Keras 2.x utilizing built-in inception-v3 framework. `fit_on_generator` wouldn't start and complained  `ValueError: The model expects 0 input arrays, but only received one array.` A little bit digging into inception-v3 code revealed this bug.

A temporary workaround is to change Line 160 in inception_v3.py into `img_input = input_tensor`.",turtleizzy,b'stale',2017-04-05T06:13:45Z,2017-10-04T12:25:43Z
6148,save bug,"```
In [3]: n.save('keras0')
---------------------------------------------------------------------------
RuntimeError                              Traceback (most recent call last)
<ipython-input-3-3059a54d88ac> in <module>()
----> 1 n.save('keras0')

/home/wenjian/anaconda3/lib/python3.5/site-packages/keras/engine/topology.py in save(self, filepath, overwrite)
   2414         """"""
   2415         from ..models import save_model
-> 2416         save_model(self, filepath, overwrite)
   2417 
   2418     def save_weights(self, filepath, overwrite=True):

/home/wenjian/anaconda3/lib/python3.5/site-packages/keras/models.py in save_model(model, filepath, overwrite)
    157                         name,
    158                         val.shape,
--> 159                         dtype=val.dtype)
    160                     if not val.shape:
    161                         # scalar

/home/wenjian/anaconda3/lib/python3.5/site-packages/h5py/_hl/group.py in create_dataset(self, name, shape, dtype, data, **kwds)
    106             dset = dataset.Dataset(dsid)
    107             if name is not None:
--> 108                 self[name] = dset
    109             return dset
    110 

h5py/_objects.pyx in h5py._objects.with_phil.wrapper (/home/ilan/minonda/conda-bld/work/h5py/_objects.c:2696)()

h5py/_objects.pyx in h5py._objects.with_phil.wrapper (/home/ilan/minonda/conda-bld/work/h5py/_objects.c:2654)()

/home/wenjian/anaconda3/lib/python3.5/site-packages/h5py/_hl/group.py in __setitem__(self, name, obj)
    275 
    276         if isinstance(obj, HLObject):
--> 277             h5o.link(obj.id, self.id, name, lcpl=lcpl, lapl=self._lapl)
    278 
    279         elif isinstance(obj, SoftLink):

h5py/_objects.pyx in h5py._objects.with_phil.wrapper (/home/ilan/minonda/conda-bld/work/h5py/_objects.c:2696)()

h5py/_objects.pyx in h5py._objects.with_phil.wrapper (/home/ilan/minonda/conda-bld/work/h5py/_objects.c:2654)()

h5py/h5o.pyx in h5py.h5o.link (/home/ilan/minonda/conda-bld/work/h5py/h5o.c:3743)()

RuntimeError: Unable to create link (Name already exists)

```",fayeshine,b'stale',2017-04-04T17:24:50Z,2017-08-12T13:15:28Z
6146,Debugging Multiple GPU Model,"I am trying to reproduce a multiple GPU implementation of my keras model using some of the code from [this blog post](https://medium.com/@kuza55/transparent-multi-gpu-training-on-tensorflow-with-keras-8b0016fd9012).  I have slightly modified it to take a list of GPUs (in case I want to specify which GPUs I am using).  I am using the Tensorflow backend of Keras, and they are both up to date.  I have four NVIDIA Titan X GPUs.  Below is a small example using MNIST.

```
from keras.layers import concatenate
from keras.layers.core import Lambda
from keras.models import Model

import tensorflow as tf

def make_parallel(model, gpu_list):
    def get_slice(data, idx, parts):
        shape = tf.shape(data)
        size = tf.concat([ shape[:1] // parts, shape[1:] ], axis=0)
        stride = tf.concat([ shape[:1] // parts, shape[1:]*0 ], axis=0)
        start = stride * idx
        return tf.slice(data, start, size)

    outputs_all = []
    for i in range(len(model.outputs)):
        outputs_all.append([])

    #Place a copy of the model on each GPU, each getting a slice of the batch
    gpu_count = len(gpu_list)
    for i in range(gpu_count):
        with tf.device('/gpu:%d' % gpu_list[i]):
            with tf.name_scope('tower_%d' % gpu_list[i]) as scope:

                inputs = []
                #Slice each input into a piece for processing on this GPU
                for x in model.inputs:
                    input_shape = tuple(x.get_shape().as_list())[1:]
                    slice_n = Lambda(get_slice, output_shape=input_shape, arguments={'idx':i,'parts':gpu_count})(x)
                    inputs.append(slice_n)                

                outputs = model(inputs)
                
                if not isinstance(outputs, list):
                    outputs = [outputs]
                
                #Save all the outputs for merging back together later
                for l in range(len(outputs)):
                    outputs_all[l].append(outputs[l])

    # merge outputs on CPU
    with tf.device('/cpu:0'):
        merged = []
        for outputs in outputs_all:
            merged.append(concatenate(outputs, axis=0))
            
        return Model(inputs=model.inputs, outputs=merged)

if __name__ == ""__main__"":
    from keras.models import Sequential
    from keras.layers import Dense
    from keras.datasets import mnist
    from keras.utils import to_categorical
    
    (x_train, y_train), (x_test, y_test) = mnist.load_data()
    x_train = x_train.reshape(60000, -1)
    x_test = x_test.reshape(10000, -1)
    model = Sequential()
    model.add(Dense(64, input_shape=(784,), activation='relu'))
    model.add(Dense(10, activation='softmax'))
    
    parallel_model = make_parallel(model , [0,1,2,3])
    
    y_train = to_categorical(y_train, 10)
    y_test = to_categorical(y_test, 10)
    
    parallel_model.compile(optimizer='nadam', loss='categorical_crossentropy',
                           metrics=['accuracy'])
    
    parallel_model.fit(x_train, y_train, batch_size=128,
                       validation_data=(x_test, y_test))
```

This code works when I select two or four GPUs; but when I select three GPUs, I get the following error:

```
Using TensorFlow backend.
Train on 60000 samples, validate on 10000 samples
Epoch 1/1
Traceback (most recent call last):

  File ""<ipython-input-1-524a8053f5a2>"", line 1, in <module>
    runfile('/home/rmk6217/Documents/kemker/machine_learning/multi_gpu.py', wdir='/home/rmk6217/Documents/kemker/machine_learning')

  File ""/home/rmk6217/anaconda3/lib/python3.5/site-packages/spyder/utils/site/sitecustomize.py"", line 866, in runfile
    execfile(filename, namespace)

  File ""/home/rmk6217/anaconda3/lib/python3.5/site-packages/spyder/utils/site/sitecustomize.py"", line 102, in execfile
    exec(compile(f.read(), filename, 'exec'), namespace)

  File ""/home/rmk6217/Documents/kemker/machine_learning/multi_gpu.py"", line 71, in <module>
    validation_data=(x_test, y_test))

  File ""/home/rmk6217/anaconda3/lib/python3.5/site-packages/Keras-2.0.2-py3.5.egg/keras/engine/training.py"", line 1485, in fit
    initial_epoch=initial_epoch)

  File ""/home/rmk6217/anaconda3/lib/python3.5/site-packages/Keras-2.0.2-py3.5.egg/keras/engine/training.py"", line 1140, in _fit_loop
    outs = f(ins_batch)

  File ""/home/rmk6217/anaconda3/lib/python3.5/site-packages/Keras-2.0.2-py3.5.egg/keras/backend/tensorflow_backend.py"", line 2102, in __call__
    feed_dict=feed_dict)

  File ""/home/rmk6217/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 767, in run
    run_metadata_ptr)

  File ""/home/rmk6217/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 965, in _run
    feed_dict_string, options, run_metadata)

  File ""/home/rmk6217/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 1015, in _do_run
    target_list, options, run_metadata)

  File ""/home/rmk6217/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 1035, in _do_call
    raise type(e)(node_def, op, message)

InvalidArgumentError: Incompatible shapes: [128] vs. [126]
	 [[Node: Equal = Equal[T=DT_INT64, _device=""/job:localhost/replica:0/task:0/cpu:0""](ArgMax, ArgMax_1)]]

Caused by op 'Equal', defined at:
  File ""/home/rmk6217/anaconda3/lib/python3.5/site-packages/spyder/utils/ipython/start_kernel.py"", line 227, in <module>
    main()
  File ""/home/rmk6217/anaconda3/lib/python3.5/site-packages/spyder/utils/ipython/start_kernel.py"", line 223, in main
    kernel.start()
  File ""/home/rmk6217/anaconda3/lib/python3.5/site-packages/ipykernel/kernelapp.py"", line 474, in start
    ioloop.IOLoop.instance().start()
  File ""/home/rmk6217/anaconda3/lib/python3.5/site-packages/zmq/eventloop/ioloop.py"", line 177, in start
    super(ZMQIOLoop, self).start()
  File ""/home/rmk6217/anaconda3/lib/python3.5/site-packages/tornado/ioloop.py"", line 831, in start
    self._run_callback(callback)
  File ""/home/rmk6217/anaconda3/lib/python3.5/site-packages/tornado/ioloop.py"", line 604, in _run_callback
    ret = callback()
  File ""/home/rmk6217/anaconda3/lib/python3.5/site-packages/tornado/stack_context.py"", line 275, in null_wrapper
    return fn(*args, **kwargs)
  File ""/home/rmk6217/anaconda3/lib/python3.5/site-packages/ipykernel/kernelbase.py"", line 258, in enter_eventloop
    self.eventloop(self)
  File ""/home/rmk6217/anaconda3/lib/python3.5/site-packages/ipykernel/eventloops.py"", line 93, in loop_qt5
    return loop_qt4(kernel)
  File ""/home/rmk6217/anaconda3/lib/python3.5/site-packages/ipykernel/eventloops.py"", line 87, in loop_qt4
    start_event_loop_qt4(kernel.app)
  File ""/home/rmk6217/anaconda3/lib/python3.5/site-packages/IPython/lib/guisupport.py"", line 144, in start_event_loop_qt4
    app.exec_()
  File ""/home/rmk6217/anaconda3/lib/python3.5/site-packages/ipykernel/eventloops.py"", line 39, in process_stream_events
    kernel.do_one_iteration()
  File ""/home/rmk6217/anaconda3/lib/python3.5/site-packages/ipykernel/kernelbase.py"", line 291, in do_one_iteration
    stream.flush(zmq.POLLIN, 1)
  File ""/home/rmk6217/anaconda3/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py"", line 352, in flush
    self._handle_recv()
  File ""/home/rmk6217/anaconda3/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py"", line 472, in _handle_recv
    self._run_callback(callback, msg)
  File ""/home/rmk6217/anaconda3/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py"", line 414, in _run_callback
    callback(*args, **kwargs)
  File ""/home/rmk6217/anaconda3/lib/python3.5/site-packages/tornado/stack_context.py"", line 275, in null_wrapper
    return fn(*args, **kwargs)
  File ""/home/rmk6217/anaconda3/lib/python3.5/site-packages/ipykernel/kernelbase.py"", line 276, in dispatcher
    return self.dispatch_shell(stream, msg)
  File ""/home/rmk6217/anaconda3/lib/python3.5/site-packages/ipykernel/kernelbase.py"", line 228, in dispatch_shell
    handler(stream, idents, msg)
  File ""/home/rmk6217/anaconda3/lib/python3.5/site-packages/ipykernel/kernelbase.py"", line 390, in execute_request
    user_expressions, allow_stdin)
  File ""/home/rmk6217/anaconda3/lib/python3.5/site-packages/ipykernel/ipkernel.py"", line 196, in do_execute
    res = shell.run_cell(code, store_history=store_history, silent=silent)
  File ""/home/rmk6217/anaconda3/lib/python3.5/site-packages/ipykernel/zmqshell.py"", line 501, in run_cell
    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)
  File ""/home/rmk6217/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py"", line 2717, in run_cell
    interactivity=interactivity, compiler=compiler, result=result)
  File ""/home/rmk6217/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py"", line 2827, in run_ast_nodes
    if self.run_code(code, result):
  File ""/home/rmk6217/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py"", line 2881, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File ""<ipython-input-1-524a8053f5a2>"", line 1, in <module>
    runfile('/home/rmk6217/Documents/kemker/machine_learning/multi_gpu.py', wdir='/home/rmk6217/Documents/kemker/machine_learning')
  File ""/home/rmk6217/anaconda3/lib/python3.5/site-packages/spyder/utils/site/sitecustomize.py"", line 866, in runfile
    execfile(filename, namespace)
  File ""/home/rmk6217/anaconda3/lib/python3.5/site-packages/spyder/utils/site/sitecustomize.py"", line 102, in execfile
    exec(compile(f.read(), filename, 'exec'), namespace)
  File ""/home/rmk6217/Documents/kemker/machine_learning/multi_gpu.py"", line 68, in <module>
    metrics=['accuracy'])
  File ""/home/rmk6217/anaconda3/lib/python3.5/site-packages/Keras-2.0.2-py3.5.egg/keras/engine/training.py"", line 952, in compile
    append_metric(i, 'acc', masked_fn(y_true, y_pred, mask=masks[i]))
  File ""/home/rmk6217/anaconda3/lib/python3.5/site-packages/Keras-2.0.2-py3.5.egg/keras/engine/training.py"", line 479, in masked
    score_array = fn(y_true, y_pred)
  File ""/home/rmk6217/anaconda3/lib/python3.5/site-packages/Keras-2.0.2-py3.5.egg/keras/metrics.py"", line 25, in categorical_accuracy
    K.argmax(y_pred, axis=-1)),
  File ""/home/rmk6217/anaconda3/lib/python3.5/site-packages/Keras-2.0.2-py3.5.egg/keras/backend/tensorflow_backend.py"", line 1347, in equal
    return tf.equal(x, y)
  File ""/home/rmk6217/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/gen_math_ops.py"", line 721, in equal
    result = _op_def_lib.apply_op(""Equal"", x=x, y=y, name=name)
  File ""/home/rmk6217/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py"", line 763, in apply_op
    op_def=op_def)
  File ""/home/rmk6217/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/ops.py"", line 2327, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""/home/rmk6217/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/ops.py"", line 1226, in __init__
    self._traceback = _extract_stack()

InvalidArgumentError (see above for traceback): Incompatible shapes: [128] vs. [126]
	 [[Node: Equal = Equal[T=DT_INT64, _device=""/job:localhost/replica:0/task:0/cpu:0""](ArgMax, ArgMax_1)]]
```

I have dug through the debugger for a while now, but I can seem to track the issue.  I can't help feeling that I am doing something stupid, so I was hoping another set of eyes might see things I didn't  Any assistance would be appreciated.  Thanks!
",rmkemker,b'stale',2017-04-04T16:46:02Z,2017-09-11T14:11:51Z
6145,VGG16.py does not work with Keras 2.02 (https://github.com/fchollet/keras/blob/master/keras/applications/vgg16.py),"New version of Keras does not allow to use ""state of art"" Keras script like VGG16.py
With Keras 2.02 there are some warning and also error trying to execute VGG16.py 
(maxpooling error).

Other issues,

Using model.layers.pop() to remove the last layer work properly. But when i try to add some other layers following the tutorial in  https://keras.io/  (using model2 = Model(input=model.input, output=predictions  ...) the command model2.summary() does not show any new layers and the model.fit()seems to work not properly which let me think that the command summary() really show that the new model2 does not receive the extra layers.

Here is the code, i whish to know what 's wrong in that code: (There is no errors)
#----------------------------------------------
model = VGG16(weights='imagenet')
#-----------------------------------------------------------
model.summary()  
#---------------------------------------------------------------  
 for layer in model.layers:
    layer.trainable = False
# load the weights
#model.load_weights('vgg16_weights.h5')

# pop last layer, insert my own
model.layers.pop()
model.layers.pop()
model.layers.pop()
#-----------------------------------------------------------
model.summary()  # 
#---------------------------------------------------------------  
 #model.add(Flatten())# flatten is still in model since we remove 3 layers (flatten is a problem....)
x=Dense(64, activation='relu')(model.output)
x=Dropout(0.5)(x)
predictions=Dense(8, activation='softmax')(x)
model2 = Model(input=model.input, output=predictions)
#-----------------------------------------------------------
model2.summary()  # == model.summary()
#---------------------------------------------------------------  

For all of that i was thinking of using Keras vs tensorflow but i am thinking return to tensorflow because debugging is much more tractable.


Thank you!

- [x] Check that you are up-to-date with the master branch of Keras. You can update with:
pip install git+git://github.com/fchollet/keras.git --upgrade --no-deps

- [x] If running on TensorFlow, check that you are up-to-date with the latest version. The installation instructions can be found [here](https://www.tensorflow.org/get_started/os_setup).

- [ ] If running on Theano, check that you are up-to-date with the master branch of Theano. You can update with:
pip install git+git://github.com/Theano/Theano.git --upgrade --no-deps

- [x] Provide a link to a GitHub Gist of a Python script that can reproduce your issue (or just copy the script here if it is short).
",ptisseur,None,2017-04-04T15:13:43Z,2017-04-06T09:17:24Z
6142,Bug : Specifying initial state for Recurrent layers,"There are 2 issues:

```python
rnn = SimpleRNN(10)  # Layer not built yet. So state_spec is None
x = Input((7, 5))
h_tm1 = Input((10,))
y = rnn(x, initial_state=h_tm1)  # >> Error
```

Another issue is at : https://github.com/fchollet/keras/blob/master/keras/layers/recurrent.py#L236

```python
if hasattr(initial_state, '_keras_history')
```

Doesn't take into account when `initial_state` is a list. (Such as in LSTM, which has multiple states).
",farizrahman4u,None,2017-04-04T11:31:16Z,2019-10-12T11:44:54Z
6135,Bugfix to ConvLSTM2D in channels_first image_data_format mode.,"### Problem

In Keras master (`3382c0bb894b2ecaac2562238f34c2a46bf413c9`), when using `ConvLSTM2D` with `image_data_format == channels_first` mode, the wrong axis is selected as the channel axis.

```python
>>> import keras as K, keras.layers as KL, keras.engine as KE, keras.backend as KB, numpy as np
Using Theano backend.
NVIDIA: no NVIDIA devices found
>>> input = KL.Input(shape=(100,1,32,1))                                   
>>> convlayer = KL.ConvLSTM2D(32, (3,1), activation=""relu"", padding=""same"")
>>> fseq = convlayer(input)
>>> model = KE.Model(inputs=input, outputs=fseq)        
>>> model.predict(np.random.normal(size=(5,100,1,32,1)))
Traceback (most recent call last):

[snip]

Apply node that caused the error: CorrMM{half, (1, 1), (1, 1)}(Alloc.0, Subtensor{::, ::, ::int64, ::int64}.0)
Toposort index: 37
Inputs types: [TensorType(float32, 4D), TensorType(float32, 4D)]
Inputs shapes: [(5, 1, 32, 1), (32, 100, 3, 1)]
Inputs strides: [(128, 9223372036854775807, 4, 9223372036854775807), (4, 128, -12800, -4)]
Inputs values: ['not shown', 'not shown']
Outputs clients: [[InplaceDimShuffle{x,0,1,2,3}(CorrMM{half, (1, 1), (1, 1)}.0)]]

[snip]
```

### Solution

The cause of the problem is that in `keras/layers/convolutional_recurrent.py:342`, when `self.data_format == 'channels_first'`, the channel axis selected is 1 instead of 2. The solution is simple:

```diff
diff --git a/keras/layers/convolutional_recurrent.py b/keras/layers/convolutional_recurrent.py
index e95b7918..00b69c6d 100644
--- a/keras/layers/convolutional_recurrent.py
+++ b/keras/layers/convolutional_recurrent.py
@@ -340,7 +340,7 @@ class ConvLSTM2D(ConvRecurrent2D):
             self.states = [None, None]
 
         if self.data_format == 'channels_first':
-            channel_axis = 1
+            channel_axis = 2
         else:
             channel_axis = -1
         if input_shape[channel_axis] is None:
```",obilaniu,None,2017-04-03T23:20:54Z,2017-04-04T00:00:35Z
6129,Bug: error when using Activation('linear') as first layer,"Keras throws an error when the first layer is an `Activation` layer with `mode='linear'` (this is a pretty unusual use case, but it should work). This seems to be because the definition of that layer is simply:

    def linear(x):
        return x

So the topology is not properly created.
Here's a simple script to reproduce the error:


	from keras.models import Sequential
	from keras.layers import Dense, Activation
	import numpy as np

	def build_net_bug(activation):
		model = Sequential()
		model.add(Activation(activation,input_shape=(12,)))
		model.add(Dense(2))
		model.compile(loss='categorical_crossentropy', optimizer='sgd')
		return model

	model = build_net_bug('linear')
	model.train_on_batch(np.zeros((32,12)),np.zeros((32,2)))
	print('Ok')

Producted the following error:

    /path/experimental/keras/keras/engine/topology.py:1516: UserWarning: Model inputs must come from a Keras Input layer, they cannot be the output of a previous non-Input layer. Here, a tensor specified as input to ""sequential_1_model"" was not an Input tensor, it was generated by layer activation_1.
    Note that input tensors are instantiated via `tensor = Input(shape)`.
    The tensor that caused the issue was: activation_1_input:0
      str(x.name))
    Traceback (most recent call last):
      File ""test_keras_bug_2.py"", line 12, in <module>
        model = build_net_bug('linear')
      File ""test_keras_bug_2.py"", line 9, in build_net_bug
        model.compile(loss='categorical_crossentropy', optimizer='sgd')
      File ""/path/experimental/keras/keras/models.py"", line 761, in compile
        self.build()
      File ""/path/experimental/keras/keras/models.py"", line 520, in build
        name=self.name + '_model')
      File ""/path/experimental/keras/keras/legacy/interfaces.py"", line 88, in wrapper
        return func(*args, **kwargs)
      File ""/path/experimental/keras/keras/engine/topology.py"", line 1569, in __init__
        if layer.is_placeholder:
    AttributeError: 'Activation' object has no attribute 'is_placeholder'


Replacting `'linear'` with any other activation fixes the issue.
Any suggestions on the best way to fix this (preferably without impacting the performance of `Activation('linear')` ? ",yhenon,None,2017-04-03T17:28:14Z,2017-04-13T17:18:00Z
6120,Deconvolution2D problem on GPU,"Hi,

I built a CNN A that generates images using Deconvolution2D layer. This layer is re-used later in another CNN B.  The following code illustrates this idea. 

```
    A = Sequential()
    A.add( Deconvolution2D(10, 10,10, border_mode='valid', bias=False, input_shape=(1,1,1), output_shape=(None,10,10,10)) )
    A.add( Convolution2D(1, 3,3, border_mode='same', bias=False) )
    A.compile(loss='mean_squared_error', optimizer='adam')

    I = np.random.random((100,1,1,1))
    O = np.random.random((100,1,10,10))
    A.fit( I, O, batch_size=5, nb_epoch=10)

    B = Sequential()
    B.add( Convolution2D(1, 1,1, border_mode='same', bias=False, input_shape=(1,1,1)) )
    l = len(A.layers)
    for i in range(l):
        B.add( A.layers[i] )
    B.compile(loss='mean_squared_error', optimizer='adam')    
    B.fit( I, O, batch_size=5, nb_epoch=10)
```

This code works fine on CPU but when I switch to GPU it produces the following error:[
```
Traceback (most recent call last):
  File ""test.py"", line 36, in <module>
    B.fit( I, O, batch_size=5, nb_epoch=10)
  File ""/usr/local/lib/python2.7/dist-packages/keras/models.py"", line 627, in fit
    sample_weight=sample_weight)
  File ""/usr/local/lib/python2.7/dist-packages/keras/engine/training.py"", line 1124, in fit
    callback_metrics=callback_metrics)
  File ""/usr/local/lib/python2.7/dist-packages/keras/engine/training.py"", line 842, in _fit_loop
    outs = f(ins_batch)
  File ""/usr/local/lib/python2.7/dist-packages/keras/backend/theano_backend.py"", line 792, in __call__
    return self.function(*inputs)
  File ""/usr/local/lib/python2.7/dist-packages/theano/compile/function_module.py"", line 871, in __call__
    storage_map=getattr(self.fn, 'storage_map', None))
  File ""/usr/local/lib/python2.7/dist-packages/theano/gof/link.py"", line 314, in raise_with_op
    reraise(exc_type, exc_value, exc_trace)
  File ""/usr/local/lib/python2.7/dist-packages/theano/compile/function_module.py"", line 859, in __call__
    outputs = self.fn()
ValueError: GpuElemwise. Output dimension mis-match. Output 0 (indices start at 0), working inplace on input 1, has shape[0] == 1, but the output's size on that axis is 10.
Apply node that caused the error: GpuElemwise{Composite{((i0 * i1) + (i2 * i3))}}[(0, 1)](GpuDimShuffle{x,x,x,x}.0, <CudaNdarrayType(float32, 4D)>, GpuElemwise{sub,no_inplace}.0, GpuDnnConvGradW{alg
o='none', inplace=True}.0)
Toposort index: 113
Inputs types: [CudaNdarrayType(float32, (True, True, True, True)), CudaNdarrayType(float32, 4D), CudaNdarrayType(float32, (True, True, True, True)), CudaNdarrayType(float32, 4D)]
Inputs shapes: [(1, 1, 1, 1), (1, 1, 3, 3), (1, 1, 1, 1), (10, 1, 3, 3)]
Inputs strides: [(0, 0, 0, 0), (0, 0, 3, 1), (0, 0, 0, 0), (9, 0, 3, 1)]
Inputs values: [CudaNdarray([[[[ 0.89999998]]]]), 'not shown', CudaNdarray([[[[ 0.10000002]]]]), 'not shown']
Outputs clients: [['output', GpuElemwise{Composite{(i0 - ((i1 * i2) / (i3 + sqrt(clip(i4, i5, i6)))))}}[(0, 0)](convolution2d_2_W, GpuElemwise{Composite{((i0 * sqrt(clip((i1 - (i2 ** i3)), i4, i5)))
 / (i1 - (i6 ** i3)))},no_inplace}.0, GpuElemwise{Composite{((i0 * i1) + (i2 * i3))}}[(0, 1)].0, CudaNdarrayConstant{[[[[  9.99999994e-09]]]]}, GpuElemwise{Composite{((i0 * i1) + (i2 * sqr(i3)))}}[(
0, 1)].0, CudaNdarrayConstant{[[[[ 0.]]]]}, CudaNdarrayConstant{[[[[ inf]]]]})]]
```

This error can be fixed by inserting a 'Reshape' layer right after the 'Deconvolution2D' layer:
```
    B = Sequential()
    B.add( Convolution2D(1, 1,1, border_mode='same', bias=False, input_shape=(1,1,1)) )
    B.add( Reshape(1,1,1) )
```
The input to the Reshape layer is also (1,1,1) so it quite strange that this layer is needed here.
I believe there could be some bug in the Deconvolution2D layer.
I used Theano backend and Keras version is 1.1.1 (unfortunately, I am not an admin on this machine so I cannot update it myself).

Regards,
Sanparith
",peune,b'stale',2017-04-03T07:12:40Z,2017-08-04T02:10:12Z
6104,val_acc KeyError using ModelCheckpoint.,"Hi, i am using ModelCheckpoint callback to monitor 'val_acc' and I get this error
  File ""/usr/local/lib/python2.7/dist-packages/keras/engine/training.py"", line 1485, in fit
    initial_epoch=initial_epoch)
  File ""/usr/local/lib/python2.7/dist-packages/keras/engine/training.py"", line 1160, in _fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File ""/usr/local/lib/python2.7/dist-packages/keras/callbacks.py"", line 75, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File ""/usr/local/lib/python2.7/dist-packages/keras/callbacks.py"", line 383, in on_epoch_end
    filepath = self.filepath.format(epoch=epoch, **logs)
KeyError: 'val_acc'
Looked at Keras codebase but could not debug it, why is this error coming?",codemukul95,b'stale',2017-04-01T11:54:25Z,2020-10-01T00:02:44Z
6100,BugFix: Num of params should be int,"Num of params should be int

np.sum([]) returns  0.0.
So if one layer has zero parameters the total number of params will be a float.
",Danielhiversen,None,2017-04-01T09:24:03Z,2017-04-01T20:43:38Z
6099,Keras tensorboard showing nothing but the code runs well,"I am using tensorflow 1.0.1 keras 2.0 and python 3.4
When I run my code, it shows no error. However tensorboard show that ""No graph definition files were found. ""

My tensorboard debug is as follows:

INFO:tensorflow:TensorBoard is in debug mode.
INFO:tensorflow:Starting TensorBoard in directory /home/swx/lk
**INFO:tensorflow:TensorBoard path_to_run is: {'/home/swx/lk/=': None}**
INFO:tensorflow:Event Multiplexer initializing.
INFO:tensorflow:Event Multiplexer done initializing
INFO:tensorflow:TensorBoard reload process beginning
INFO:tensorflow:Starting AddRunsFromDirectory: /home/swx/lk/=
INFO:tensorflow:Done with AddRunsFromDirectory: /home/swx/lk/=
INFO:tensorflow:TensorBoard reload process: Reload the whole Multiplexer
**INFO:tensorflow:Beginning EventMultiplexer.Reload()
INFO:tensorflow:Finished with EventMultiplexer.Reload()**
INFO:tensorflow:TensorBoard done reloading. Load took 0.002 secs
INFO:tensorflow:TensorBoard is tag: b'41'


can any one offer some help?









Please make sure that the boxes below are checked before you submit your issue. If your issue is an implementation question, please ask your question on [StackOverflow](http://stackoverflow.com/questions/tagged/keras) or [join the Keras Slack channel](https://keras-slack-autojoin.herokuapp.com/) and ask there instead of filing a GitHub issue.

Thank you!

- [ ] Check that you are up-to-date with the master branch of Keras. You can update with:
pip install git+git://github.com/fchollet/keras.git --upgrade --no-deps

- [ ] If running on TensorFlow, check that you are up-to-date with the latest version. The installation instructions can be found [here](https://www.tensorflow.org/get_started/os_setup).

- [ ] If running on Theano, check that you are up-to-date with the master branch of Theano. You can update with:
pip install git+git://github.com/Theano/Theano.git --upgrade --no-deps

- [ ] Provide a link to a GitHub Gist of a Python script that can reproduce your issue (or just copy the script here if it is short).
",lk1983823,b'stale',2017-04-01T01:15:00Z,2017-08-29T16:18:00Z
6094,"Recurrent ""Cannot infer num from shape (?, ?, :)"" - tensorflow backend.","This seems like a very specific bug, but the following script fails with tensorflow backend.

    from keras.layers import LSTM
    from keras.models import Sequential
    model = Sequential()
    model.add(LSTM(units=8, return_sequences=True, input_shape=(10, 100), unroll=False))
    model.add(LSTM(units=11, return_sequences=False, implementation=2, unroll=True))

with error message:
```Traceback (most recent call last):
  File ""../test.py"", line 23, in <module>
    model.add(LSTM(units=11, return_sequences=False, implementation=2, unroll=True))
  File ""/Users/fnogueira/venvs/general/lib/python3.6/site-packages/keras/models.py"", line 455, in add
    output_tensor = layer(self.outputs[0])
  File ""/Users/fnogueira/venvs/general/lib/python3.6/site-packages/keras/layers/recurrent.py"", line 252, in __call__
    return super(Recurrent, self).__call__(inputs, **kwargs)
  File ""/Users/fnogueira/venvs/general/lib/python3.6/site-packages/keras/engine/topology.py"", line 556, in __call__
    output = self.call(inputs, **kwargs)
  File ""/Users/fnogueira/venvs/general/lib/python3.6/site-packages/keras/layers/recurrent.py"", line 298, in call
    input_length=input_shape[1])
  File ""/Users/fnogueira/venvs/general/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py"", line 2227, in rnn
    input_list = tf.unstack(inputs)
  File ""/Users/fnogueira/venvs/general/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py"", line 960, in unstack
    raise ValueError(""Cannot infer num from shape %s"" % value_shape)
ValueError: Cannot infer num from shape (?, ?, 8)
```

While it is definitely an odd choice of `unroll` and `implementation` combination, I thought it was worth pointing out. It works if both unroll are set to true, of ir implementation is set to 0.",fmfn,b'stale',2017-03-31T15:23:14Z,2017-07-30T14:56:29Z
6082,The validation generator is resetting the model?,"Hey, guys. I am training a regression model by fit_generator. I find something wired. 

In the first epoch of training, the loss decreased from about 30 to about 1; but at the beginning of next epoch, the loss goes back to 30 again. Then the training process continues from that 30. I trained the model for 10 epochs, and found that at the end of every epoch, the loss does not decrease, they more seems like random values. Can anybody help me to find the bug. I have been struggling with this for two days. 
The code is here

```
from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, CSVLogger
from keras.optimizers import Adam
from HistoryUtlisCopy2 import CreateModel, Supplier, Evaluator, SupplierSteps, EvaluatorSteps
import os


# ***→→→ History Experiment ←←←***
Scale = 0.25
TimeLen = 10
print(""The time length is: %d"" % TimeLen)
BatchSize = 16

model = CreateModel(TimeLen=TimeLen, Scale=Scale)
print(""The number of parameters is: %d"" % model.count_params())
model.compile(loss='mean_squared_error', optimizer=Adam(lr=0.00002))

FileDirt = ""./CheckPoint"" + str(TimeLen)
if not os.path.exists(FileDirt):
    os.mkdir(FileDirt)

saver = ModelCheckpoint(filepath=FileDirt + ""/Weights-{epoch:02d}-{loss:.4f}.hdf5"",
                        monitor='loss',
                        save_best_only=False,
                        save_weights_only=True,
                        period=1)
stopper = EarlyStopping(monitor='loss', patience=10)
logger = CSVLogger(filename=FileDirt + '/TrainLog.csv')
boarder = TensorBoard(log_dir=FileDirt + '/Logs')
callbacks = [saver, stopper, logger, boarder]

model.fit_generator(generator=Supplier(BatchSize=BatchSize, TimeLen=TimeLen, Scale=Scale),
                    steps_per_epoch=1000,#SupplierSteps(BatchSize=BatchSize, TimeLen=TimeLen),
                    validation_data=Evaluator(BatchSize=BatchSize, TimeLen=TimeLen, Scale=Scale),
                    validation_steps=10,#EvaluatorSteps(BatchSize=BatchSize, TimeLen=TimeLen),
                    epochs=10,
                    verbose=1,
                    callbacks=callbacks)
```",ghost,None,2017-03-31T02:07:52Z,2017-03-31T21:08:37Z
6064,Calling call method of Layer class in topology.py with wrong parameters,"On [line 556](https://github.com/fchollet/keras/blob/master/keras/engine/topology.py#L556) of topology.py call method of Layer class is called with `output = self.call(inputs, **kwargs)`.

But [call method](https://github.com/fchollet/keras/blob/master/keras/engine/topology.py#L470) accepts only one parameter and returns the same without doing anything.
 If I am right this call method is implemented either for future feature implementation or a leftover from past feature.
Also on [line 556](https://github.com/fchollet/keras/blob/master/keras/engine/topology.py#L556) passing keyword arguments as parameter is implemented by `**kwargs`. It is wrong. It should be passed by `kwargs`.
This bug can be fixed using different ways.

1. Removing `**kwargs` from call method call. 
This way [line 556](https://github.com/fchollet/keras/blob/master/keras/engine/topology.py#L556) should look like `output = self.call(inputs)`
2. Accepting `kwargs` as keyword arguments in call method and returning inputs only in call method.
This way [line 556](https://github.com/fchollet/keras/blob/master/keras/engine/topology.py#L556) should look like `output = self.call(inputs, **kwargs)` and [line 470](https://github.com/fchollet/keras/blob/master/keras/engine/topology.py#L470) should look like `def call(self, inputs, **kwargs):`.
3. Accepting `kwargs` as keyword arguments in call method and returning both inputs and kwargs in call method.
This ways [line 556](https://github.com/fchollet/keras/blob/master/keras/engine/topology.py#L556) should look like `output, returned_kwargs = self.call(inputs, **kwargs)`, [line 470](https://github.com/fchollet/keras/blob/master/keras/engine/topology.py#L470) should look like `def call(self, inputs, **kwargs):` and [line 479](https://github.com/fchollet/keras/blob/master/keras/engine/topology.py#L479) should look like `return inputs, kwargs`.

So, Please let me know which way should be implemented. I like to fix it myself and I want to create a pull request for the fix. This way I can contribute to keras a little.",kumaranvpl,None,2017-03-30T10:12:19Z,2017-04-02T15:04:31Z
6060,Bug fix: ocr example; python 3,,farizrahman4u,None,2017-03-30T08:42:51Z,2017-03-30T11:25:49Z
6057,"bug fix, cast batch_sizes as a list to support indexing","Cannot index a set, so batch_sizes must be cast back as a list or a tuple.",slaterb1,None,2017-03-29T19:33:39Z,2017-03-30T17:09:03Z
6035,Bug fix : Error when applying layer recursively on a list in Keras 2,"Simple script to reproduce:

```python
from keras.layers import*
from keras.models import *

a = Input((None, None))
x = [a, a]
b = concatenate(x, 1)
x += [b]  # This changes b._keras_history[0].input
b = concatenate(x, 1)
model = Model(a, b)
```

Works with legacy merge layer. See #5972
",farizrahman4u,None,2017-03-28T20:20:05Z,2017-06-03T00:27:18Z
6034,"bugfix: recursive layers, merge_test.py reproduces bug (#5972)","**Update:** I merged #6035 directly here, so the test should now succeed if #5972 is fixed.

Reproduces #5972, a bug in the new keras-2 function `concatenate()`. 
If the unit test fails the bug has been reproduced correctly.

To run the test from keras directory:

```
py.test tests/keras/layers/merge_test.py
```

This pull request reproduces the keras-2 concatenate() bug detailed in #5972. 

Edits are allowed for maintainers so a patch fixing the bug could potentially be added directly to this pull request. Here is the error:

```
                            raise RuntimeError(
                                'Graph disconnected: '
                                'cannot obtain value for tensor ' +
                                str(x) + ' at layer ""' + layer.name + '"". '
                                'The following previous layers '
                                'were accessed without issue: ' +
>                               str(layers_with_complete_input))
E                           RuntimeError: Graph disconnected: cannot obtain value for tensor Tensor(""concatenate_3/concat:0"", shape=(?, ?, ?), dtype=float32) at layer ""concatenate_3"". The following previous layers were accessed without issue: ['input_3']
```

While the pull request contents fail, the following keras-1 API code succeeds:

```python
import numpy as np
from numpy.testing import assert_allclose
from keras import layers
from keras import models
from keras import backend as K
from keras.utils.test_utils import layer_test
from keras.utils.test_utils import keras_test
from keras.layers import merge

x3 = np.random.random((1, 1, 1))
nb_layers = 4
x_i = layers.Input(shape=(None, None))
x_list = [x_i]
x = x_i
for i in range(nb_layers):
    x_list.append(x)
    # The concatenate line fails if uncommented + comment merge line
    # x = layers.concatenate(x_list)
    x = layers.merge(x_list, mode='concat', concat_axis=1)
concat_model = models.Model(x_i, x)
concat_out = concat_model.predict([x3])
x3 = np.repeat(x3, 16, axis=1)
assert concat_out.shape == (1, 16, 1)
assert_allclose(concat_out, x3)
```",ahundt,None,2017-03-28T18:48:21Z,2017-06-22T00:38:05Z
6026,pygpu.gpuarray.GpuArrayException: Unaligned array,"Using the new gpuarray backend, the following error occured:
```python
Traceback (most recent call last):
  File ""CNN_approach.py"", line 56, in <module>
    model.fit( X_train.astype('float32'), y_train.astype('float32'), epochs=1, batch_size=256, validation_data=(X_test,y_test))
  File ""/usr/local/lib/python2.7/dist-packages/keras/models.py"", line 845, in fit
    initial_epoch=initial_epoch)
  File ""/usr/local/lib/python2.7/dist-packages/keras/engine/training.py"", line 1485, in fit
    initial_epoch=initial_epoch)
  File ""/usr/local/lib/python2.7/dist-packages/keras/engine/training.py"", line 1140, in _fit_loop
    outs = f(ins_batch)
  File ""/usr/local/lib/python2.7/dist-packages/keras/backend/theano_backend.py"", line 1094, in __call__
    return self.function(*inputs)
  File ""/usr/local/lib/python2.7/dist-packages/theano/compile/function_module.py"", line 898, in __call__
    storage_map=getattr(self.fn, 'storage_map', None))
  File ""/usr/local/lib/python2.7/dist-packages/theano/gof/link.py"", line 325, in raise_with_op
    reraise(exc_type, exc_value, exc_trace)
  File ""/usr/local/lib/python2.7/dist-packages/theano/compile/function_module.py"", line 884, in __call__
    self.fn() if output_subset is None else\
  File ""pygpu/gpuarray.pyx"", line 683, in pygpu.gpuarray.pygpu_copy (pygpu/gpuarray.c:9990)
  File ""pygpu/gpuarray.pyx"", line 396, in pygpu.gpuarray.array_copy (pygpu/gpuarray.c:7083)
pygpu.gpuarray.GpuArrayException: Unaligned array
Apply node that caused the error: GpuContiguous(InplaceGpuDimShuffle{3,2,0,1}.0)
Toposort index: 70
Inputs types: [GpuArrayType<None>(float32, (False, False, False, False))]
Inputs shapes: [(4, 1, 11, 11)]
Inputs strides: [(4, 9223372036854775807, 176, 16)]
Inputs values: ['not shown']
Outputs clients: [[Shape(GpuContiguous.0), Shape_i{3}(GpuContiguous.0), Shape_i{2}(GpuContiguous.0), Shape_i{0}(GpuContiguous.0), GpuDnnConv{algo='small', inplace=True}(GpuContiguous.0, GpuContiguous.0, GpuAllocEmpty{dtype='float32', context_name=None}.0, GpuDnnConvDesc{border_mode='half', subsample=(1, 1), conv_mode='conv', precision='float32'}.0, Constant{1.0}, Constant{0.0})]]

HINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.
HINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.
```

Code:
```python
model = Sequential([
	Conv2D( 4, (11,11), activation='relu', padding='same', input_shape=X_train.shape[1:]),
	MaxPooling2D( (2,2)),
	Conv2D( 8, (7,7), activation='relu', padding='same'),
	MaxPooling2D( (2,2)),
	Conv2D( 16, (5,5), activation='relu', padding='same'),
	MaxPooling2D( (2,2)),
	Conv2D( 32, (3,3), activation='relu', padding='same'),
	MaxPooling2D( (2,2)),
	Conv2D( 64, (3,3), activation='relu', padding='same'),
	MaxPooling2D( (2,2)),
	Conv2D( 128, (3,3), activation='relu', padding='same'),
	MaxPooling2D( (2,2)),
	Conv2D( 256, (3,3), activation='relu', padding='same'),
	MaxPooling2D( (2,2)),
	Flatten(),
	Dropout(0.05),
	Dense(128, activation='relu'),
	Dropout(0.05),
	Dense(11, activation='softmax')
])
print(model.summary())
model.compile( loss='categorical_crossentropy', optimizer='adadelta', metrics=['accuracy'])

print('fit model')
model.fit( X_train.astype('float32'), y_train.astype('float32'), epochs=1, batch_size=256, validation_data=(X_test.astype('float32'),y_test.astype('float32')))
```",jagiella,b'stale',2017-03-28T11:26:35Z,2017-07-27T13:56:53Z
6021,ValueError:MissingLayer when loading model from h5 file (missing layer that is sum of layers),"Hello, I am implementing a ResNet with keras functional API. I am saving the model to h5 file via the `Model.save()` method. 
When try to load the saved model I got an error that says that specific layer is missing. By the name of that layer I understand that it is the layer created by the ""shortcut connection"" of the residual block. 
I provided the code below to explain further the bug and how to reproduce it:

```python
from keras.engine import Model
from keras.layers import Dense, BatchNormalization, Activation, Input
from keras.layers import add as sum_layers
from keras.models import load_model


def residual_block(input_t, output_dim, scopename, params):
    input_dim = input_t.get_shape().as_list()[-1]

    fc1 = Dense(units=input_dim,
                bias_initializer=params['bias_init'],
                kernel_initializer=params['weights_init'],
                name='%s/fc1' % scopename)

    fc2 = Dense(units=output_dim,
                bias_initializer=params['bias_init'],
                kernel_initializer=params['weights_init'],
                name='%s/fc2' % scopename)

    bn1 = BatchNormalization(momentum=params['batch_norm'],
                             name='%s/batch_norm1' % scopename)
    bn2 = BatchNormalization(momentum=params['batch_norm'],
                             name='%s/batch_norm2' % scopename)
    activation = Activation(params['activation'], name='%s/activation' % scopename)
    shortcut = input_t if input_dim == output_dim else Dense(units=output_dim,
                                                             bias_initializer=params['bias_init'],
                                                             kernel_initializer=params['weights_init'],
                                                             name='%s/shortcut_projection' % scopename)(input_t)

    x = fc1(input_t)
    x = bn1(x)
    x = activation(x)
    x = fc2(x)
    x = bn2(x)
    x = sum_layers([x, shortcut], name='%s/shortcut_connection' % scopename)
    x = activation(x)
    return x


in_dim, resblock_out_dim = 10, 5

in_tensor = Input([in_dim], name='inputs')
hidden = residual_block(in_tensor, resblock_out_dim, 'ResBlock1', {
    'activation': 'relu',
    'bias_init': 'zeros',
    'weights_init': 'he_normal',
    'batch_norm': 0.9
})
output = Dense(1)(hidden)

model = Model(inputs=in_tensor, outputs=output)
model.save('test.h5')
model2 = load_model('test.h5')
```

My settings are: 
Linux, keras 2.0.2

The exception is the following: `ValueError: Missing layer: ResBlock1/shortcut_connection` which is created with the function `sum_layers` (2 rows before the end of the function `residual_block`)",eranamar,b'stale',2017-03-28T07:57:51Z,2017-08-12T13:15:12Z
6007,`unboundlocalerror: local variable 'class_name' referenced before assignment`,"BUG report  ^.^

I have re-define the top_k_categorical_accuracy to 
`def top_k_categorical_accuracy(y_true, y_pred):
    return metrics.top_k_categorical_accuracy(y_true, y_pred, 1)`

And as the model training finished, I saved it to my local disk by `mode.save(mypath)`, but I have got this exception while I load model to other process:

`unboundlocalerror: local variable 'class_name' referenced before assignment`

It was from:
`File ""<PYTHONPATH>/local/lib/python2.7/site-packages/keras/utils/generic_utils.py"", line 157, in deserialize_keras_object`

Absolutely, it a variable which not been assign before using it. In the exception code block, the unit-test may not cover it or the code's static check issue?

Thanks for read",Mr8,b'stale',2017-03-27T11:42:05Z,2017-12-18T15:50:09Z
6004,Inconsistency for decreasing loss,"- [x] Check that you are up-to-date with the master branch of Keras. You can update with:
pip install git+git://github.com/fchollet/keras.git --upgrade --no-deps

- [x] If running on TensorFlow, check that you are up-to-date with the latest version. The installation instructions can be found [here](https://www.tensorflow.org/get_started/os_setup).

- [x] Provide a link to a GitHub Gist of a Python script that can reproduce your issue (or just copy the script here if it is short).

Hello everyone, I have been using this script [Python script](https://github.com/etai83/lstm_stock_prediction/blob/master/.ipynb_checkpoints/GOOGLE%20stock%20prediction-checkpoint.ipynb) 
The problem is that I am unable to produce similar result everytime. 
Sometimes, I can produce a similar result (loss of 0.3~ within 500 epochs) but sometimes I still get a loss of 3.x after 1500epochs. I am not sure if this is a bug or this is because the algorithm just stuck at a minimum local.",BenjiKCF,None,2017-03-27T10:43:45Z,2017-04-23T17:15:47Z
5972,Keras 2 bug in `concatenate()` in a loop appending to a tensor list (ex: densenet),"I've got code that works in the keras-1 compatibility layer of keras-2, but fails when I use the new `concatenate()` API.

Key lines:
```python
    concat_axis = 1 if K.image_data_format() == 'channels_first' else -1

    x_list = [x]

    for i in range(nb_layers):
        x = __conv_block(x, growth_rate, bottleneck,
                         dropout_rate, weight_decay)
        x_list.append(x)

        # commenting merge() and uncommenting concatenate() fails
        x = merge(x_list, mode='concat', concat_axis=concat_axis)
        # x = concatenate(x_list, concat_axis)

        if grow_nb_filters:
            nb_filter += growth_rate

    if return_concat_list:
        return x, nb_filter, x_list
    else:
        return x, nb_filter
```


Error:
```
Traceback (most recent call last):
  File ""/Users/athundt/source/keras-contrib/keras_contrib/applications/densenet.py"", line 712, in <module>
    dn = DenseNet()
  File ""/Users/athundt/source/keras-contrib/keras_contrib/applications/densenet.py"", line 136, in DenseNet
    model = Model(inputs, x, name='densenet')
  File ""/usr/local/lib/python2.7/site-packages/Keras-2.0.1-py2.7.egg/keras/legacy/interfaces.py"", line 87, in wrapper
    return func(*args, **kwargs)
  File ""/usr/local/lib/python2.7/site-packages/Keras-2.0.1-py2.7.egg/keras/engine/topology.py"", line 1704, in __init__
    str(layers_with_complete_input))
RuntimeError: Graph disconnected: cannot obtain value for tensor Tensor(""conv2d_2/convolution:0"", shape=(?, 32, 32, 12), dtype=float32) at layer ""concatenate_1"". The following previous layers were accessed without issue: ['input_1', 'initial_conv2D', 'batch_normalization_1', 'activation_1', 'conv2d_1']
```

The full code is in https://github.com/farizrahman4u/keras-contrib/pull/46/commits/bf95474bdd48a85df1c443db0fa108bf28dcf86a

Thank you!

- [x] Check that you are up-to-date with the master branch of Keras. You can update with:
pip install git+git://github.com/fchollet/keras.git --upgrade --no-deps

- [x] If running on TensorFlow, check that you are up-to-date with the latest version. The installation instructions can be found [here](https://www.tensorflow.org/get_started/os_setup).


- [x] Provide a link to a GitHub Gist of a Python script that can reproduce your issue (or just copy the script here if it is short).
",ahundt,None,2017-03-24T22:15:29Z,2017-03-29T16:50:26Z
5971,[Seq2Seq] Specifying tensor as initial state in GRU,"Hello,

I’m trying to build a seq2seq Model as in [this paper.](https://arxiv.org/pdf/1406.1078.pdf) I want to use a bidirectional GRU as Encoder and an unidirectional GRU as Decoder. The decoder receives the correct labels y_t-1 as input for training (Teacher Forcing). The loss is computed via time distributed softmax over a large vocabulary.

In the model the encoders hidden state represents a summary of the input data. The last hidden state of the encoder is transferred to the decoder and used as initial hidden state. With #5559 included in 2.0.2  I think it should be possible, to build such a model with keras. My model currently is:

```
main_input = Input(shape=(SEQ_LEN,), name=""main_input"", dtype=""int32"")
forced_input = Input(shape=(TARGET_LEN,), name=""forced_input"", dtype=""int32"")
encoder=Embedding(INPUT_VOC_SIZE,EMBEDDING_SIZE,input_length=SEQ_LEN,mask_zero=True)(main_input)
encoder=Bidirectional(GRU(return_sequences=False,units=HIDDEN))(encoder)
target_embedding=Embedding(TARGET_VOC_SIZE + 2, EMBEDDING_SIZE, input_length=TARGET_LEN, mask_zero=True)(forced_input)
decoder=GRU(units=HIDDEN,return_sequences=True)(target_embedding,initial_state=[encoder])
output=TimeDistributed(Dense(TARGET_VOC_SIZE,activation=""softmax""))(decoder)
model = Model(inputs=[main_input, forced_input], outputs=[output])
```

The encoder should be connected to the decoder only by the transfer of the last hidden state (which is the output of the BGRU encoder) from encoder to decoder. The model trains, but as it turns out, the encoder is not connected to the decoder and doesn’t get trained. This can be seen when using tensorboard. There are no connections from gradients to the encoder or from encoder to decoder. This happens, because the specification of the initial state as list is incorrect in this case. I tried the specification as list because it was suggested in this PR #5559. However, when I try to specify the initial hidden state of the decoder by`initial_state=encoder` (without brackets) I get the Exception:
```
Layer gru_2 expects 1 inputs, but it received 2 input tensors. Input received: <built-in function input>
```
I believe that happens because internally, in the class recurrent in \__call__, the initial state is then treated as an additional input. When specifying initial state as list (with brackets) the state is not treated as additional input and therefore the model compiles, but the encoder is not connected to the decoder.

Is this a bug or intended behavior? What is the correct way to specify the initial hidden state in such a way that the layer which generates it, is connected to the graph and gets trained? I believe this is related to PR #5795.

Thank you for your help.
",smodlich,b'stale',2017-03-24T20:04:34Z,2017-09-23T22:39:23Z
5963,Bug in Siamese Example Accuracy Calculation,"The siamese network example for mnist (https://github.com/fchollet/keras/blob/master/examples/mnist_siamese_graph.py) uses the following function to compute accuracy

```
def compute_accuracy(predictions, labels):
    '''Compute classification accuracy with a fixed threshold on distances.
    '''
    return labels[predictions.ravel() < 0.5].mean()
```

This seems flawed to me. For example:
```
import numpy as np
labs = np.array([0,0,0,0,0,1,1,1,1,1])
pred = np.array([1,1,1,1,1,0,0,0,0,0])
print(compute_accuracy(pred, labs))
# >>> 1.0
```

Surely the order of the predictions is important? In the example above, all of the predictions are different from the labels, and yet the compute_accuracy returns 100%. 

Am I missing something obvious, or is this a mistake.




- [X] Check that you are up-to-date with the master branch of Keras. You can update with:
pip install git+git://github.com/fchollet/keras.git --upgrade --no-deps

- [x] If running on TensorFlow, check that you are up-to-date with the latest version. The installation instructions can be found [here](https://www.tensorflow.org/get_started/os_setup).

- [X] If running on Theano, check that you are up-to-date with the master branch of Theano. You can update with:
pip install git+git://github.com/Theano/Theano.git --upgrade --no-deps

- [X] Provide a link to a GitHub Gist of a Python script that can reproduce your issue (or just copy the script here if it is short).
",sixhobbits,b'stale',2017-03-24T13:33:44Z,2017-08-12T13:15:53Z
5950,Custom merge() function that returns the cosin of two vectors,"I am trying to play around with custom merge functions. I am trying to merge two layers such that the output is e.g. the cosine of the two input layers:

```python
def _cosine_similarity(x):
    import tensorflow as tf
    a = x[0]
    b = x[1]
    norm_a = tf.sqrt(tf.reduce_sum(tf.square(a), 1, keep_dims=True))
    norm_b = tf.sqrt(tf.reduce_sum(tf.square(b), 1, keep_dims=True))
    dot = tf.matmul(a, tf.transpose(b))
    norm = tf.mul(norm_a, norm_b)
    cosine = tf.divide(dot, norm)
    return cosine
```


However, there appears to be a problem with the shapes.. `dot` after `tf.matmul(a, tf.transpose(b))` has a shape of `(?, ?)` - could that be the problem here?

The two input tensors should have the dimensions `(?, 64)`. This is the network:

```python
in_a = Input(shape=(nb_dimensions,), name='in_a')
reduced_a = Dense(nb_reduced, activation='relu')(in_a)

in_b = Input(shape=(nb_dimensions,), name='in_b')
reduced_b = Dense(nb_reduced, activation='relu')(in_b)

cos_similarity = merge(inputs=[reduced_a, reduced_b], output_shape=(1,), 
                       mode=_cosine_similarity)

output = Dense(1, activation='linear', trainable=False)(cos_similarity)
```

In case you want to see everything in debug mode:

![screenshot from 2017-03-23 21-07-26](https://cloud.githubusercontent.com/assets/1429426/24268093/ccd14008-100c-11e7-99f6-8f3e53f8fdc6.png)


Any idea what I can do to fix this?

```
I tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0)
Traceback (most recent call last):
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py"", line 1021, in _do_call
    return fn(*args)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py"", line 1003, in _run_fn
    status, run_metadata)
  File ""/usr/lib/python3.5/contextlib.py"", line 66, in __exit__
    next(self.gen)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/errors_impl.py"", line 469, in raise_exception_on_not_ok_status
    pywrap_tensorflow.TF_GetCode(status))
tensorflow.python.framework.errors_impl.InvalidArgumentError: Matrix size-incompatible: In[0]: [25,25], In[1]: [1,1]
	 [[Node: MatMul_3 = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=""/job:localhost/replica:0/task:0/gpu:0""](Divide/truediv, dense_3_W/read)]]
	 [[Node: mul_1/_39 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device_incarnation=1, tensor_name=""edge_410_mul_1"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/cpu:0""]()]]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/media/Data/workspaces/git/master-thesis/python/thesis/absa/slot1/constrained/cosine_encoder.py"", line 121, in <module>
    loss = ae.model.train_on_batch(x, y_batch)
  File ""/usr/local/lib/python3.5/dist-packages/keras/engine/training.py"", line 1320, in train_on_batch
    outputs = self.train_function(ins)
  File ""/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py"", line 1943, in __call__
    feed_dict=feed_dict)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py"", line 766, in run
    run_metadata_ptr)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py"", line 964, in _run
    feed_dict_string, options, run_metadata)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py"", line 1014, in _do_run
    target_list, options, run_metadata)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py"", line 1034, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.InvalidArgumentError: Matrix size-incompatible: In[0]: [25,25], In[1]: [1,1]
	 [[Node: MatMul_3 = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=""/job:localhost/replica:0/task:0/gpu:0""](Divide/truediv, dense_3_W/read)]]
	 [[Node: mul_1/_39 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device_incarnation=1, tensor_name=""edge_410_mul_1"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/cpu:0""]()]]

Caused by op 'MatMul_3', defined at:
  File ""/media/Data/workspaces/git/master-thesis/python/thesis/absa/slot1/constrained/cosine_encoder.py"", line 83, in <module>
    ae = CosineEncoder(nb_dimensions=len(vocabulary), nb_reduced=64)
  File ""/media/Data/workspaces/git/master-thesis/python/thesis/absa/slot1/constrained/cosine_encoder.py"", line 57, in __init__
    output = Dense(1, activation='linear', trainable=False)(cos_similarity)
  File ""/usr/local/lib/python3.5/dist-packages/keras/engine/topology.py"", line 572, in __call__
    self.add_inbound_node(inbound_layers, node_indices, tensor_indices)
  File ""/usr/local/lib/python3.5/dist-packages/keras/engine/topology.py"", line 635, in add_inbound_node
    Node.create_node(self, inbound_layers, node_indices, tensor_indices)
  File ""/usr/local/lib/python3.5/dist-packages/keras/engine/topology.py"", line 166, in create_node
    output_tensors = to_list(outbound_layer.call(input_tensors[0], mask=input_masks[0]))
  File ""/usr/local/lib/python3.5/dist-packages/keras/layers/core.py"", line 814, in call
    output = K.dot(x, self.W)
  File ""/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py"", line 827, in dot
    out = tf.matmul(x, y)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py"", line 1729, in matmul
    a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gen_math_ops.py"", line 1442, in _mat_mul
    transpose_b=transpose_b, name=name)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py"", line 759, in apply_op
    op_def=op_def)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py"", line 2240, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py"", line 1128, in __init__
    self._traceback = _extract_stack()

InvalidArgumentError (see above for traceback): Matrix size-incompatible: In[0]: [25,25], In[1]: [1,1]
	 [[Node: MatMul_3 = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=""/job:localhost/replica:0/task:0/gpu:0""](Divide/truediv, dense_3_W/read)]]
	 [[Node: mul_1/_39 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device_incarnation=1, tensor_name=""edge_410_mul_1"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/cpu:0""]()]]
```",silentsnooc,b'stale',2017-03-23T20:05:41Z,2017-10-15T18:53:17Z
5938,Change batch size back to None in reshape,"When doing `K.reshape()`, you need to use `-1` instead of `None` for dimensions with unknown length.  The rest of the Keras code expects the shape to be `None` if the dimension has unknown length, and so setting `_keras_shape` without converting `-1` back to `None` leads to some bugs.  This fixes that.",matt-gardner,None,2017-03-23T04:11:24Z,2017-03-23T14:27:39Z
5915,Input dimension mis-match. Pre-trained weights vgg16 Keras 1.2 and 2.0,"Please make sure that the boxes below are checked before you submit your issue. If your issue is an implementation question, please ask your question on [StackOverflow](http://stackoverflow.com/questions/tagged/keras) or [join the Keras Slack channel](https://keras-slack-autojoin.herokuapp.com/) and ask there instead of filing a GitHub issue.

Thank you!

- [x] Check that you are up-to-date with the master branch of Keras. You can update with:
pip install git+git://github.com/fchollet/keras.git --upgrade --no-deps

- [ ] If running on TensorFlow, check that you are up-to-date with the latest version. The installation instructions can be found [here](https://www.tensorflow.org/get_started/os_setup).

- [x] (url) ] If running on Theano, check that you are up-to-date with the master branch of Theano. You can update with:
pip install git+git://github.com/Theano/Theano.git --upgrade --no-deps

- [x] Provide a link to a GitHub Gist of a Python script that can reproduce your issue (or just copy the script here if it is short).


Error:
Every time I run this, in Keras 2.0.1 or Keras 1.2, with VGG16, VGG19, InceptionV3, a custom model, and with pre-resized images to 224. I can debug through other errors and am always left with this one. Same with Theano and Tensorflow.
The code runs without the weights, but with the weights of a pre-trained model I always get this error, [full code in gist](https://gist.github.com/bauer1331/3dab46ace692e42ccd5bad96c6b3e969). Please help.

```python
model_vgg16_conv = VGG16(include_top=False)
input = Input(shape=(3,224,224),name = ‘image_input’)
output_vgg16_conv = model_vgg16_conv(input)
x = Flatten(name='flatten')(output_vgg16_conv)
x = Dense(4096, activation='relu', name='fc1')(x)
x = Dense(4096, activation='relu', name='fc2')(x)
x = Dense(3, activation='softmax', name='predictions')(x)
my_model = Model(input=input, output=x)

my_model.compile(loss='categorical_crossentropy',
              optimizer='rmsprop',
              metrics=['accuracy’])

my_model.fit_generator(
        train_generator,
        samples_per_epoch=32,
        nb_epoch=50,
        validation_data=validation_generator,
        nb_val_samples=32)


ValueError: Input dimension mis-match. (input[0].shape[1] = 3, input[1].shape[1] = 64)
Apply node that caused the error: Elemwise{Add}[(0, 0)](CorrMM{half, (1, 1), (1, 1)}.0, InplaceDimShuffle{x,0,x,x}.0)
Toposort index: 144
Inputs types: [TensorType(float32, 4D), TensorType(float32, (True, False, True, True))]
Inputs shapes: [(17, 3, 224, 225), (1, 64, 1, 1)]
Inputs strides: [(604800, 201600, 900, 4), (256, 4, 4, 4)]
Inputs values: ['not shown', 'not shown']
Outputs clients: [[Elemwise{Composite{(i0 * (i1 + Abs(i1)))}}(TensorConstant{(1, 1, 1, 1) of 0.5}, Elemwise{Add}[(0, 0)].0), Elemwise{Composite{((i0 * i1) + (i0 * i1 * sgn(i2)))}}[(0, 1)](TensorConstant{(1, 1, 1, 1) of 0.5}, CorrMM_gradInputs{half, (1, 1), (1, 1)}.0, Elemwise{Add}[(0, 0)].0)]]

```


",bauer1331,b'stale',2017-03-21T22:15:12Z,2017-09-01T16:39:41Z
5900,None is not supported in input_shape [bug],"In the new release v2.0.1, `None` is not supported in input_shape, while `None` is must-have for a fully-convolutional network. Below is an example

```
>>> model = Sequential()
model = Sequential()
>>> model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(3, None, None)))
)
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/models.py"", line 422, in add
    layer(x)
  File ""/nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/engine/topology.py"", line 528, in __call__
    self.build(input_shapes[0])
  File ""/nfs/isicvlnas01/share/anaconda/lib/python2.7/site-packages/keras/layers/convolutional.py"", line 125, in build
    raise ValueError('The channel dimension of the inputs '
ValueError: The channel dimension of the inputs should be defined. Found `None`.
>>> print keras.__version__
print keras.__version__
2.0.1
```",rex-yue-wu,None,2017-03-21T02:17:08Z,2017-03-22T04:44:01Z
5896,Cannot use Keras in threads,"I'm using Ubuntu 16.04, Python 3.5.2, Keras 2.0.1 and Tensorflow 1.01. 

Keras/tensorflow crash when using threads. The following code is a simplified version of what I am trying to do but recreates the crash.

https://gist.github.com/eyesonlyhack/c43dea734f872a9c45da8587eefec581

I found a way to get around this issue but think this is probably a bug in Keras. My workaround is:
https://gist.github.com/eyesonlyhack/2f0b20f1e73aaf5e9b83f49415f3601a

",grantwwoodford,b'stale',2017-03-20T22:17:35Z,2019-06-16T18:54:42Z
5885,preprocess_weights_for_loading [bug],"When converting weights (InceptionV3 for instance), if the backend is switched, loading crashes with an error pointing to h5py. It looks like since the conv2d layers are usually included last in any h5 file they are the only ones who have their indexes checked but h5py expects the index to be > 0 as it is not the first layer in the file. 

**How to reproduce**:

1. Change your backend to 'theano' in the keras.json config file
2. Run this script:
```
from keras.applications.inception_v3 import *
from keras.preprocessing import image
from keras.applications.imagenet_utils import decode_predictions
from keras import backend as K
import numpy as np

model = InceptionV3(weights='imagenet')

img_path = 'elephant.jpg'
img = image.load_img(img_path, target_size=(299, 299))
x = image.img_to_array(img)
x = np.expand_dims(x, axis=0)
x = preprocess_input(x)

preds = model.predict(x)
print('Predicted:', decode_predictions(preds))
```

With the Tensorflow backend this works fine and outputs the following:
```
[[(u'n02504458', u'African_elephant', 0.90738213)]]
````

However, if the backend is switched to Theano you get the following error (full traceback):
```
Using Theano backend.
Traceback (most recent call last):
  File ""test.py"", line 7, in <module>
    model = InceptionV3(weights='imagenet')
  File ""/home/kent/.virtualenvs/keras2/local/lib/python2.7/site-packages/keras/applications/inception_v3.py"", line 383, in InceptionV3
    model.load_weights(weights_path)
  File ""/home/kent/.virtualenvs/keras2/local/lib/python2.7/site-packages/keras/engine/topology.py"", line 2491, in load_weights
    load_weights_from_hdf5_group(f, self.layers)
  File ""/home/kent/.virtualenvs/keras2/local/lib/python2.7/site-packages/keras/engine/topology.py"", line 2893, in load_weights_from_hdf5_group
    original_backend)
  File ""/home/kent/.virtualenvs/keras2/local/lib/python2.7/site-packages/keras/engine/topology.py"", line 2833, in preprocess_weights_for_loading
    weights[0] = conv_utils.convert_kernel(weights[0])
  File ""/home/kent/.virtualenvs/keras2/local/lib/python2.7/site-packages/keras/utils/conv_utils.py"", line 86, in convert_kernel
    return np.copy(kernel[slices])
  File ""h5py/_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper (/tmp/pip-nCYoKW-build/h5py/_objects.c:2840)
  File ""h5py/_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper (/tmp/pip-nCYoKW-build/h5py/_objects.c:2798)
  File ""/home/kent/.virtualenvs/keras2/local/lib/python2.7/site-packages/h5py/_hl/dataset.py"", line 474, in __getitem__
    selection = sel.select(self.shape, args, dsid=self.id)
  File ""/home/kent/.virtualenvs/keras2/local/lib/python2.7/site-packages/h5py/_hl/selections.py"", line 90, in select
    sel[args]
  File ""/home/kent/.virtualenvs/keras2/local/lib/python2.7/site-packages/h5py/_hl/selections.py"", line 363, in __getitem__
    raise TypeError(""Indexing elements must be in increasing order"")
TypeError: Indexing elements must be in increasing order
```

This is definitely unexpected behavior, however, I'm unable to see an obvious issue anywhere in the Keras-2 changes which is why I'm posting it here. 

- [x] Check that you are up-to-date with the master branch of Keras. You can update with:
pip install git+git://github.com/fchollet/keras.git --upgrade --no-deps

- [x] If running on TensorFlow, check that you are up-to-date with the latest version. The installation instructions can be found [here](https://www.tensorflow.org/get_started/os_setup).

- [x] If running on Theano, check that you are up-to-date with the master branch of Theano. You can update with:
pip install git+git://github.com/Theano/Theano.git --upgrade --no-deps

- [x] Provide a link to a GitHub Gist of a Python script that can reproduce your issue (or just copy the script here if it is short).
",kentsommer,b'stale',2017-03-20T10:24:37Z,2017-08-20T12:52:26Z
5829,MissingErrorInput when calling a model containing a layer with masking on new inputs,"Please make sure that the boxes below are checked before you submit your issue. If your issue is an implementation question, please ask your question on [StackOverflow](http://stackoverflow.com/questions/tagged/keras) or [join the Keras Slack channel](https://keras-slack-autojoin.herokuapp.com/) and ask there instead of filing a GitHub issue.

Thank you!

- [x] Check that you are up-to-date with the master branch of Keras. You can update with:
pip install git+git://github.com/fchollet/keras.git --upgrade --no-deps

- [ ] If running on TensorFlow, check that you are up-to-date with the latest version. The installation instructions can be found [here](https://www.tensorflow.org/get_started/os_setup).

- [x] If running on Theano, check that you are up-to-date with the master branch of Theano. You can update with:
pip install git+git://github.com/Theano/Theano.git --upgrade --no-deps

- [x] Provide a link to a GitHub Gist of a Python script that can reproduce your issue (or just copy the script here if it is short).

https://gist.github.com/around1991/cb6e8b7d17c3d1d0362e16e5a91e0dbb reliably reproduces the bug.

The issue is in line 2131 of topology.py: if mask is one of the kwargs when the layer was originally called in the inner model, then the mask kwarg is stored in layer.call, and isn't refreshed when model.call() is called.
",around1991,b'stale',2017-03-16T22:24:01Z,2017-07-15T09:23:00Z
5827,Bug fixes : Theano shape inference,,farizrahman4u,None,2017-03-16T19:43:15Z,2017-03-19T19:27:58Z
5825,Writing my own cost function,"Hello,
I am trying to write my own objective (cost function) which should do that:

I have vector shaped to (None, 88) and I need to proceed over it loss algorithm of my own.

I have tried to convert the y_pred and y_true params to numpy arrays but I failed because the shape of the tensors is Shape.0 - also I have noticed that the loss function runs (while debugging or printing in it) only once while the model defined.

Please help me how to use numpy in my loss function (K.eval didn't work because the shape is Shape.0) and how to debug it to see if it works.

Thanks!!


edit:

I wrote this loss function:
```
def my_loss(y_true, y_pred):
    # run over the sequence, jump by 3
    # calc the lable
    # if the lable uncorrect punish

    y_pred = K.reshape(y_pred, (1, 88, 3))

    y_pred = K.argmax(y_pred, axis=1)

    zero_count = K.sum(K.clip(y_pred, 0, 0))
    one_count = K.sum(K.clip(y_pred, 1, 1))
    two_count = K.sum(K.clip(y_pred, 2, 2))

    zero_punish = 1 - zero_count / K.count_params(y_true)
    one_punish = 1- one_count/ K.count_params(y_true)
    two_punish = 1- two_count/ K.count_params(y_true)

    false_arr = K.not_equal(y_true, y_pred)

    mask0 = K.equal(y_true, K.zeros_like(y_pred))
    mask0_miss = K.dot(false_arr, mask0) * zero_punish

    mask1 = K.equal(y_true, K.ones_like(y_pred))
    mask1_miss = K.dot(false_arr, mask1) * one_punish

    mask2 = K.equal(y_true, K.zeros_like(y_pred)+2)
    mask2_miss = K.dot(false_arr, mask2) * two_punish

    return K.sum(mask0_miss) + K.sum(mask1_miss) + K.sum(mask2_miss)

```
It fails on:
```
theano.gof.fg.MissingInputError: A variable that is an input to the graph was neither provided as an input to the function nor given a value. A chain of variables leading from this input to an output is [/dense_1_target, Shape.0]. This chain may not be unique
Backtrace when the variable is created:
```

How can I fix it?
thanks!",Moshewiner,b'stale',2017-03-16T18:09:43Z,2018-04-17T07:21:17Z
5819,a small bug in keras.preprocessing.text of keras1.2.0,"in the function 'sequences_to_matrix':
`for j, c in list(counts.items()):
                if mode == 'count':
                    X[i][j] = c
                elif mode == 'freq':
                    X[i][j] = c / len(seq)
                elif mode == 'binary':
                    X[i][j] = 1
                elif mode == 'tfidf':
                    # Use weighting scheme 2 in
                    #   https://en.wikipedia.org/wiki/Tf%E2%80%93idf
                    tf = 1 + np.log(c)
                    idf = np.log(1 + self.document_count / (1 + self.index_docs.get(j, 0)))
                    X[i][j] = tf * idf
                else:
                    raise ValueError('Unknown vectorization mode:', mode)`

‘X[i][j]‘ will result the first column of the output matrix is all zero. Because `0` is a reserved index that won't be assigned to any word, j must >=1. So they all  should be X[i][j-1]. Thus the last column of the output matrix is all zero ,because the code 'i>= nb_words'. It should be 'i>nb_words'. So delete the '=' in two code lines 152 and 197.
Because I use keras1.2.0 , I don't know whether other versions have fixed the bug.
Thanks .

",xidongbo,b'stale',2017-03-16T12:23:05Z,2017-07-15T09:22:52Z
5815,custom_objects argument dropped on layer loading when calling model_from_config,"After switching to keras 2.0.0 and progressively migrating our code base (containing various custom layers and losses) it seemed that there were a bug in the way models are now created from a config. More specifically, the ```custom_objects``` arguments passed to ```model_from_config``` is lost in the back and forth between the ```deserialize_keras_object``` defined in ```generics_utils``` and the ```from_config``` method in ```models``` resulting in an error ```ValueError: Unknown layer: ...```.

The only solution that I've found is to introduce two simple modifications in the ```Model.from_config``` method:

- Add a ```custom_objects={}``` argument
- Pass this argument to each ```layer_module.deserialize``` call in the layer loop.

Did I miss something or is it indeed a problem with this new version? If it is should I submit a pull request?

Anis",alreadytaikeune,b'stale',2017-03-16T11:31:19Z,2017-07-25T21:14:30Z
5792,small bugs in local.py on LocallyConnected2D?,"Hello, 

I'm wondering if the line 411-413 is correct ?
https://github.com/fchollet/keras/blob/master/keras/layers/local.py#L412-L413

output = K.reshape(output, (self.output_row, self.output_col, -1, filters))

output is of dimension :  output_row x output_col x batch_size x filters

output = K.permute_dimensions(output, (2, 0, 1, 3))

should this be (1,2,0,3) ?

Thanks !
",WeidiXie,None,2017-03-15T13:19:42Z,2017-03-15T14:17:48Z
5773,Cast sparse placeholder shape to int64 to avoid tensorflow bug,casting the shape to int64 resolves issue [5225](https://github.com/fchollet/keras/issues/5225) with a workaround to avoid tensorflow issue [6749](https://github.com/tensorflow/tensorflow/issues/6749).,michaelosthege,None,2017-03-15T01:08:51Z,2018-03-18T21:02:19Z
5762,"keras_v2+python3, `load_weights_from_hdf5_group` character type bug ","Forgetting to decode bytes strings in `keras.engine.topology.load_weights_from_hdf5_group` and `load_weights_from_hdf5_group_by_name`.
`h5py` returns string as `bytes` object in Python3.   `load_weights_from_hdf5_group()` call `preprocess_weights_for_loading()` with `original_backend` as bytes string.

https://github.com/fchollet/keras/blob/master/keras/engine/topology.py#L2879-L2882

 Unnecessary weight preprocessing will be called, because string comparison between bytes and string is always false in python3.

```py
>>> b'youjo' == 'youjo'
False
```
https://github.com/fchollet/keras/blob/master/keras/engine/topology.py#L2817

## test case
```py
import keras

x = keras.layers.Input(shape=(32, 32, 3))
h = keras.layers.Conv2D(10, (10, 10))(x)
model = keras.models.Model(x, h)
model.save('conv2d.h5')

del model

model = keras.models.load_model('./conv2d.h5')
```

In python2, no error. However in python3, following error occurs.
```
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE3 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
Using TensorFlow backend.
Traceback (most recent call last):
  File ""/home/cocuh/.virtualenvs/keras2/lib/python3.6/site-packages/h5py/_hl/selections.py"", line 85, in select
    int(a)
TypeError: int() argument must be a string, a bytes-like object or a number, not 'list'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""hoge.py"", line 10, in <module>
    model = keras.models.load_model('./conv2d.h5')
  File ""/home/cocuh/.virtualenvs/keras2/lib/python3.6/site-packages/keras/models.py"", line 235, in load_model
    topology.load_weights_from_hdf5_group(f['model_weights'], model.layers)
  File ""/home/cocuh/.virtualenvs/keras2/lib/python3.6/site-packages/keras/engine/topology.py"", line 2882, in load_weights_from_hdf5_group
    original_backend)
  File ""/home/cocuh/.virtualenvs/keras2/lib/python3.6/site-packages/keras/engine/topology.py"", line 2823, in preprocess_weights_for_loading
    weights[0] = conv_utils.convert_kernel(weights[0])
  File ""/home/cocuh/.virtualenvs/keras2/lib/python3.6/site-packages/keras/utils/conv_utils.py"", line 86, in convert_kernel
    return np.copy(kernel[slices])
  File ""h5py/_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper (/tmp/pip-tnf92dft-build/h5py/_objects.c:2853)
  File ""h5py/_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper (/tmp/pip-tnf92dft-build/h5py/_objects.c:2811)
  File ""/home/cocuh/.virtualenvs/keras2/lib/python3.6/site-packages/h5py/_hl/dataset.py"", line 462, in __getitem__
    selection = sel.select(self.shape, args, dsid=self.id)
  File ""/home/cocuh/.virtualenvs/keras2/lib/python3.6/site-packages/h5py/_hl/selections.py"", line 88, in select
    sel[args]
  File ""/home/cocuh/.virtualenvs/keras2/lib/python3.6/site-packages/h5py/_hl/selections.py"", line 356, in __getitem__
    if sorted(arg) != list(arg):
TypeError: '<' not supported between instances of 'NoneType' and 'int'
```",cocuh,None,2017-03-14T13:16:19Z,2017-03-14T23:18:21Z
5758,Documentation required: explain all the numbers,"I'm relatively new to Keras - have had some simple Dense() networks working previously but on using it to explore CNNs I find the documentation intractable.

Please can we have one webpage that lists the meaning of all the parameters:
samples
channels
nb_filter
filter_length
batch_size
input_shape

and in particular, the relationships of requirements between them all with examples of how one should reshape a 2D numpy array to make it suitable?

I have managed to create a 1-layer CNN that does something but a) I can't be confident what it does and b) having fudged the nb_filter parameter to make it work as the first layer, attempts to daisy-chain a second layer give shape mismatch errors. To debug this, I need a simple page that explains the terms Keras uses.

Thanks",spodzone,b'stale',2017-03-14T10:22:48Z,2017-07-13T02:02:47Z
5754,Bug in time_distributed_dense when in tensorflow backend because of set_shape?,"Hi, 

the code below is:

```
#encoding=utf-8

import tensorflow as tf
import os
os.environ[""KERAS_BACKEND""] = ""tensorflow""
from keras import initializations
from keras.models import Model
from keras.layers.recurrent import LSTM, Recurrent, SimpleRNN, time_distributed_dense, GRU
from keras import backend as K

w_c = K.random_normal_variable((2,7), mean=0, scale=1)
x = K.random_normal_variable((1, 2, 2), mean=0, scale=1)
# q = time_distributed_dense(x, w_c, output_dim=7, input_dim=2)
q = time_distributed_dense(x, w_c)

sess = tf.Session()
gini = tf.global_variables_initializer()
sess.run(gini)

qv = sess.run(q)
print(qv.shape)
```
Error is:
```
  File ""E:/project/learn_test/test.py"", line 18, in <module>
    q = time_distributed_dense(x, w_c)
  File ""e:\project\keras\keras\layers\recurrent.py"", line 52, in time_distributed_dense
    x.set_shape([None, None, output_dim])
  File ""D:\Anaconda3\lib\site-packages\tensorflow\python\framework\ops.py"", line 419, in set_shape
    self._shape = self._shape.merge_with(shape)
  File ""D:\Anaconda3\lib\site-packages\tensorflow\python\framework\tensor_shape.py"", line 573, in merge_with
    other = as_shape(other)
  File ""D:\Anaconda3\lib\site-packages\tensorflow\python\framework\tensor_shape.py"", line 821, in as_shape
    return TensorShape(shape)
  File ""D:\Anaconda3\lib\site-packages\tensorflow\python\framework\tensor_shape.py"", line 457, in __init__
    self._dims = [as_dimension(d) for d in dims_iter]
  File ""D:\Anaconda3\lib\site-packages\tensorflow\python\framework\tensor_shape.py"", line 457, in <listcomp>
    self._dims = [as_dimension(d) for d in dims_iter]
  File ""D:\Anaconda3\lib\site-packages\tensorflow\python\framework\tensor_shape.py"", line 378, in as_dimension
    return Dimension(value)
  File ""D:\Anaconda3\lib\site-packages\tensorflow\python\framework\tensor_shape.py"", line 33, in __init__
    self._value = int(value)
TypeError: int() argument must be a string, a bytes-like object or a number, not 'Tensor'
```

But when I set  time_distributed_dense(x, w_c, output_dim=7, input_dim=2), it run ok; 
So what's up here? tf.set_shape can't pass tensor or ? Thanks",liyi193328,None,2017-03-14T06:18:23Z,2017-03-14T15:05:21Z
5751,"A bug related to 3D CNN, possibly the supplied true label gets modified inside the engine?","Hi folks. I was trying to do some classification using 3D CNN.
The loss is decreasing gradually, but the predictions are not in sync with the loss (even on the train data).
After some long debugging I found that, the model seems to be modifying the supplied true labels also.

I tested even after upgrading both Tensorflow and Keras.

For a quick example, I could reproduce with the fallowing synthetic model and data ( random data).

`import numpy as np

from keras.models import Model
from keras.layers import Input,  Convolution3D, MaxPooling3D, BatchNormalization, Activation, Dense, Flatten
from keras.optimizers import Adam
from keras import backend as K
from keras.metrics import binary_crossentropy, categorical_crossentropy
import tensorflow as tf
import os

K.set_image_dim_ordering('th')  # Theano dimension ordering in this code

# this returns a truth label for each batch
def GT(y_true, y_pred):
    return y_true[0,0] #y_pred[0,0]


# Basic synthetic 3D CNN network for classification
def test_net():
    inputs = Input((1,32,64,64))
    conv = Convolution3D(8,3, 3, 3, activation='relu', border_mode='same')(inputs)
    conv = BatchNormalization(axis=1)(conv)
    pool = MaxPooling3D(pool_size=(4,4,4))(conv)

    conv = Convolution3D(16,3, 3, 3, activation='relu', border_mode='same')(pool)
    conv = BatchNormalization(axis=1)(conv)
    conv = Convolution3D(16,3, 3, 3, activation='relu', border_mode='same')(conv)
    conv = BatchNormalization(axis=1)(conv)
    pool = MaxPooling3D(pool_size=(4,4,4))(conv)

    dense = Flatten()(pool)

    dense = Dense(512,activation='relu')(dense)
    dense = Dense(1024,activation='relu')(dense)
    dense = Dense(512,activation='relu')(dense)
    dense = Dense(100,activation='relu')(dense)

    prediction = Dense(1,activation='sigmoid')(dense)
    
    model = Model(input=inputs, output=prediction)
    model.compile(optimizer=Adam(lr=1.0e-5), loss=binary_crossentropy,metrics=[GT])
    return model

def train_test_net(gpuID):
    os.environ[""CUDA_VISIBLE_DEVICES""] = gpuID

    # basic synthetic random data generation
    def flip_generator(batch_size):
        alt_i = 0
        inputs = np.ndarray((100,1,32,64,64), dtype=np.float32)
        output = np.ndarray((100,1), dtype=np.float32)
        for samp_i in range(100):
            inputs[samp_i,:,:] = np.random.random((1,32,64,64))
            output[samp_i] = float(samp_i%2)

        while 1:
            alt_i += batch_size
            if alt_i >= 100:
                alt_i = batch_size
            yield inputs[alt_i-batch_size:alt_i], output[alt_i-batch_size:alt_i]


    # train for some epochs
    model = test_net()
    nb_epoch = 50
    samples_per_epoch=50
    lr = 0.1

    print('training for lr: ', lr)
    model.optimizer.lr.assign(lr)
    model.fit_generator(flip_generator(5), samples_per_epoch=samples_per_epoch,nb_epoch=nb_epoch, verbose=1,max_q_size=16, nb_worker=1)

train_test_net('1')`


In the metrics I am returning one of the true label of each batch.
The output looks like this,

` 5/50 [==>...........................] - ETA: 17s - loss: 0.6826 - GT: 0.0000e+010/50 [=====>........................] - ETA: 9s - loss: 0.7981 - GT: 0.5000    50/50 [==============================] - 5s - loss: 0.7710 - GT: 0.5000     
Epoch 2/50
50/50 [==============================] - 3s - loss: 0.6882 - GT: 0.4000         
Epoch 3/50
50/50 [==============================] - 3s - loss: 0.6749 - GT: 0.5000     
Epoch 4/50
`

Eventually the model tries to learn random data also :).
Please correct me if I am doing anything wrong in my model architecture (though I doubt if any mistakes).

Right direction to the issue is greatly appreciated, thanks. ",gmrhub,b'stale',2017-03-13T21:32:27Z,2017-07-13T02:02:53Z
5750,Possible bug in latest dev Theano install with nvidia driver 378.13,"Greetings all!

I don't know if this is coming from Theano or Keras, but I will be posting this on their Issues page as well.

Forcing driver 378.13 for Theano causes softmax not to normalize on the GPU.  Here's the code

```
import numpy as np
import keras
from keras.models import Sequential, Model
from keras.layers import Input, Dense, Convolution2D, MaxPooling2D, UpSampling2D, Cropping2D, Flatten
from keras.regularizers import l2, l1, l1l2
from keras import backend as K

def atariPolicyModel(state, actions):
  model = Sequential()
  model.add(Convolution2D(16,8,8,subsample=(4,4), input_shape=state,  border_mode='same', activation='relu'))
  model.add(Convolution2D(32,4,4,subsample=(2,2), border_mode='same', activation='relu'))
  model.add(Flatten())
  model.add(Dense(256, activation='relu'))
  model.add(Dense(actions, activation='softmax'))
  return model
  
state = (4,210,160)
actions = 8

In = np.random.rand(1,4,210,160)

model1 = atariPolicyModel(state, actions)

print np.sum(model1.predict(In))

```

In Ubuntu 16.04...

```
mpgussert@Cthulhu:KerasAC$ THEANO_FLAGS=device=cuda0 ipython -i Tests.py 
Python 2.7.12 (default, Nov 19 2016, 06:48:10) 
Type ""copyright"", ""credits"" or ""license"" for more information.

IPython 5.1.0 -- An enhanced Interactive Python.
?         -> Introduction and overview of IPython's features.
%quickref -> Quick reference.
help      -> Python's own help system.
object?   -> Details about 'object', use 'object??' for extra details.
Using Theano backend.
WARNING: loading blacklisted driver because the load was forced.
Using cuDNN version 5105 on context None
Mapped name None to device cuda0: Quadro GP100 (0000:02:00.0)
1.63243

In [1]: exit
mpgussert@Cthulhu:KerasAC$ ipython -i Tests.py 
Python 2.7.12 (default, Nov 19 2016, 06:48:10) 
Type ""copyright"", ""credits"" or ""license"" for more information.

IPython 5.1.0 -- An enhanced Interactive Python.
?         -> Introduction and overview of IPython's features.
%quickref -> Quick reference.
help      -> Python's own help system.
object?   -> Details about 'object', use 'object??' for extra details.
Using Theano backend.
1.0

In [1]: exit

```

can anyone else verify this behavior?

Thanks!",mpgussert,None,2017-03-13T21:21:17Z,2017-03-13T23:15:37Z
5730,Bug fix : Model.from_config,"The function pops item from the original `dict` passed to the function. This causes an error when building multiple models from the same config:

```python

config = model.get_config()
model1 = Model.from_config(config) # OK
model2 = Model.from_config(config) # error
```",farizrahman4u,None,2017-03-12T13:31:04Z,2017-03-12T18:29:09Z
5729,Add merge mode 'max' where it was missing (fixes #3486),"When 'max' was added to the possible merge modes, some places were apparently missed.

TBH, the merge modes could use a bit less hard coding, since all the checks seem to group into element-wise operations (sum, mul, ave, max), reductions (dot, cos) and concatenation. (Except for [one line](https://github.com/fchollet/keras/blob/master/keras/engine/topology.py#L1330), which might be a bug.)",Yorwba,None,2017-03-12T10:59:02Z,2017-03-15T11:53:49Z
5710,Reproducibility not given after setting np.random.seed(42),"I've started with a simple example where I convolute a simple image. If I am using `np.random.seed(42)` the image will always be convoluted exactly the same. If not, the convolution result will look different after each run as expected:

```python
import numpy as np
import matplotlib.pyplot as plt

from keras.engine import Input
from keras.engine import Model
from keras.engine import merge
from keras.layers import Convolution2D, MaxPooling2D, Activation


def invert_input(x):
    return -x


class MaxPoolTests:

    def __init__(self, ctx_window_sizes, in_nb_row, in_nb_col):

        in_x = Input(shape=(in_nb_row, in_nb_col, 1), name='in_x')
        convolutions = list()

        for window_size in ctx_window_sizes:

            in_x_invert = Activation(invert_input)(in_x)

            left = Convolution2D(nb_filter=1, nb_row=window_size, nb_col=in_nb_col,
                                 border_mode='same',
                                 activation='relu',
                                 name='l_conv_{:d}'.format(window_size))(in_x)

            right = Convolution2D(nb_filter=1, nb_row=window_size, nb_col=in_nb_col,
                                  border_mode='same',
                                  activation='relu',
                                  name='r_conv_{:d}'.format(window_size))(in_x_invert)

            l_max_pool = MaxPooling2D(name='l_maxpool_{:d}'.format(window_size),
                                      # pool_size=(2, nb_col),
                                      border_mode='valid')(left)

            r_max_pool = MaxPooling2D(name='r_maxpool_{:d}'.format(window_size),
                                      # pool_size=(2, nb_col),
                                      border_mode='valid')(right)

            r_max_pool = Activation(invert_input)(r_max_pool)

            merged = merge([l_max_pool, r_max_pool], name='merge_{:d}'.format(window_size), mode='sum')

            convolutions.append(merged)

        self.model = Model(input=[in_x], output=convolutions)


if __name__ == '__main__':

    np.random.seed(42)

    m = 10; n = 10

    nn = MaxPoolTests([2, 3], in_nb_row=m, in_nb_col=n)
    nn.model.compile(optimizer='adam', loss='mse')

    x = np.zeros((1, m, n, 1))

    for i,v in enumerate(np.linspace(-1, 1, m)):
        x[0, i, i, 0] = v

    y = nn.model.predict(x)

    plt.figure()
    plt.imshow((y[0][0, :, :, 0]))
    plt.show()
    
    print('All done.')
```

However, if I do the same for a convolutional neural network that I am using for NLP, the results are not reproducible anymore. If I look at the error / loss what I see is that these values develop completely different on each run **except** when I am using the debugger!

Using the debugger I will see the same loss number on each session but not if I run the script normally. 

I am not sure why this is the case. My only guess would be multi-threading so I added a `print(text)` to the sample generator. At least from there it looks like all the samples are getting produced in the same order so - again I don't know what causes this issue.

Any idea how I can make my results reproducible?

As always, I've posted this where it actually belongs too: [stackoverflow](http://stackoverflow.com/questions/42734301/reproducibility-not-given-after-setting-np-random-seed42) :P",silentsnooc,b'stale',2017-03-11T10:49:27Z,2017-07-10T01:01:58Z
5687,Bug Applying TimeDistributed to a Model,"The TimeDistributed wrapper does not appear to be able to be applied to a model because of a conflict with Tensorflow. I am trying to construct something similar to the video question answering model given in the function API guide. I think it may be related to using the latest release of Tensorflow. 

I get the following error:

> InvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'convolution2d_input_1' with dtype float
> 	 [[Node: convolution2d_input_1 = Placeholder[dtype=DT_FLOAT, shape=[], _device=""/job:localhost/replica:0/task:0/gpu:0""]()]]
> 	 [[Node: moments_5/sufficient_statistics/Gather/_99 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device_incarnation=1, tensor_name=""edge_3882_moments_5/sufficient_statistics/Gather"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/cpu:0""]()]]

when running the code bellow. The fullInputShape is (5000, 4, 256, 128, 1)

```python 

def funcMakesCNN(inputDim):

    model = Sequential()
    model.add(Convolution2D(4, 3, 3, activation='relu', init='he_uniform',
                            border_mode='same', W_regularizer=weightReg, input_shape=inputDim))
    model.add(BatchNormalization())
    model.add(AveragePooling2D(strides=(2, 2)))

    model.add(Convolution2D(6, 3, 3, activation='relu', init='he_uniform',
                            border_mode='same', W_regularizer=weightReg))
    model.add(BatchNormalization())
    model.add(AveragePooling2D(strides=(2, 2)))

    model.add(Flatten())
    return model

fullInput = Input(fullInputShape)
frameModel = funcMakesCNNt(frameInputShape)
lagModel = TimeDistributed(frameModel)(fullInput)
gruOut = GRU(256)(lagModel)
finalOut = Dense(lagOutputShape, activation='relu', name='regOut')(gruOut)
fullModel = Model(input=fullInput, output=finalOut)
fullModel.compile(loss='mse', optimizer=Adam(lr=0.005, decay=0.008))
```

Thanks!",gdj0nes,None,2017-03-10T06:09:22Z,2020-02-27T05:59:01Z
5670,Fix bug in use of pydot.find_graphviz(),"pydot.find_graphviz() is deprecated, so bug appear while invoking it. Instead use imp to check if graphviz is imported",sirius27,None,2017-03-09T05:06:06Z,2017-03-15T22:53:58Z
5669,Fix bug in checking existence of graphviz ,"pydot_ng is no longer maintained so removed lines that import pydot_ng
pydot.find_graphviz() is deprecated in pydot so error is reported while using 
it to check the existence of graphviz",sirius27,None,2017-03-09T03:21:01Z,2017-03-09T05:05:04Z
5665,GaussianDropout Bugfix,Noise should be multiplicative for GaussianDropout,the-moliver,None,2017-03-09T01:22:48Z,2017-03-09T01:24:43Z
5648,Lambda layer runs twice even though called only once,"I'm trying to run a tensorflow tf.nn.max_pool_with_argmax in order to use in an unpooling layer. I used a Lambda layer to run the tensorflow function. But it seems that even though I'm calling the Lambda layer only once, the function runs twice and outputs two argmax layers. Not sure if I'm doing something incorrectly or whether this is a bug. Also, I'm not an expert in python so probably the code could be written better. The inputs used come from google's notMNist 28x28 dataset.

import numpy as np
import tensorflow as tf
import os
from keras.layers import Convolution2D, Dense, Flatten, Input, Lambda
from keras.models import Model
from keras.optimizers import SGD

from tensorflow.python.framework import ops
from tensorflow.python.ops import gen_nn_ops
@ops.RegisterGradient(""MaxPoolWithArgmax"")
def _MaxPoolWithArgmaxGrad(op, grad, some_other_arg):
  return gen_nn_ops._max_pool_grad(op.inputs[0],
                                   op.outputs[0],
                                   grad,
                                   op.get_attr(""ksize""),
                                   op.get_attr(""strides""),
                                   padding=op.get_attr(""padding""),
                                   data_format='NHWC')

def keras_max_pool_with_argmax(input):
    global argmaxlayers
    (maxpoolout, maxpoolargmax) = tf.nn.max_pool_with_argmax(input, [1, 2, 2, 1], strides = [1, 2, 2, 1], padding = ""SAME"")
    print (""adding"")
    argmaxlayers.append(maxpoolargmax)
    return maxpoolout

argmaxlayers = []

os.environ['CUDA_VISIBLE_DEVICES'] = '0'
inputs = Input(batch_shape=(100,28,28,1))
conv1 = Convolution2D(4, 3, 3, init='he_normal', activation = 'relu', border_mode='same', bias=True)(inputs)
maxpoolout1 = Lambda(keras_max_pool_with_argmax)(conv1)
flat = Flatten()(maxpoolout1)
predictions = Dense(10, init='he_normal', bias = True, activation = 'softmax', name='predictions')(flat)
model = Model(input=inputs, output=predictions)
sgd = SGD(lr=0.03, decay=0.0, momentum=0.0)
model.compile(loss='categorical_crossentropy', optimizer=sgd)
model.fit(train_dataset[0:100000], train_labels[0:100000], batch_size=100, nb_epoch=1, callbacks=[], 
          validation_data=(valid_dataset, valid_labels))
print (argmaxlayers)

In the output I see

adding
adding
Train on 100000 samples, validate on 10000 samples
Epoch 1/1
100000/100000 [==============================] - 2s - loss: 0.7490 - val_loss: 0.6428
[<tf.Tensor 'MaxPoolWithArgmax:1' shape=(100, 14, 14, 4) dtype=int64>, <tf.Tensor 'MaxPoolWithArgmax_1:1' shape=(100, 14, 14, 4) dtype=int64>]

So ""adding"" is outputted twice indicating the function keras_max_pool_with_argmax was called twice, and additionally I have two separate tensors that were created instead of just one.

Thanks,

Guy",guyeng0,None,2017-03-08T06:38:48Z,2017-03-09T06:25:34Z
5647,Add tests exposing BatchNormalization bug(s)? when used in GANs.,"Reproducing:

- https://github.com/fchollet/keras/issues/5644
- https://github.com/fchollet/keras/issues/5644

Both tests fail due to bug. They will pass if `batch_normalization` flag is set to `False` in `generator` and `discriminator` for their respective tests.",mjdietzx,None,2017-03-08T06:30:30Z,2017-04-06T03:14:31Z
5645,Add tests exposing BatchNormalization bug(s)? when used in GANs.,"Reproducing:

- https://github.com/fchollet/keras/issues/5644
- https://github.com/fchollet/keras/issues/5644

Both tests fail due to bug. They will pass if `batch_normalization` flag is set to `False` in `generator` and `discriminator` for their respective tests.",mjdietzx,None,2017-03-08T06:22:30Z,2017-03-08T06:30:43Z
5644,BatchNormalization bug when used in generator of a GAN,"Easy to reproduce this bug when training GANs but probably occurs in other use cases as well. When `BatchNormalization` is used in the `generator` of a GAN, `combined.train_on_batch` fails. It's really weird but for some reason `combined.train_on_batch` does not calculate the loss correctly when batch norm is used in the generator. I tested the loss by hand doing something like:

```python
loss = combined.train_on_batch(x, y)
combined_pred = combined.predict(x)
loss_check = K.eval(custom_loss(y, combined_pred))
>>> loss != loss_check
```

You can reproduce this in `wGAN` branch here: https://github.com/wayaai/GAN-Sandbox and uncomment the BatchNorm layer in the generator.",mjdietzx,b'stale',2017-03-08T03:02:57Z,2018-07-16T12:24:13Z
5643,BatchNormalization bug when used in discriminator of GAN,"This bug is easy to reproduce when training GANs but probably occurs in other cases as well. In GANs, batch normalization cannot be used in the discriminator. If BN is used in discriminator you will get errors like:

```bash
W tensorflow/core/framework/op_kernel.cc:993] Invalid argument: You must feed a value for placeholder tensor 'input_1' with dtype float
         [[Node: input_1 = Placeholder[dtype=DT_FLOAT, shape=[], _device=""/job:localhost/replica:0/task:0/cpu:0""]()]]
Traceback (most recent call last):
  File ""/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 1022, in _do_call
    return fn(*args)
  File ""/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 1004, in _run_fn
    status, run_metadata)
  File ""/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/contextlib.py"", line 66, in __exit__
    next(self.gen)
  File ""/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py"", line 469, in raise_exception_on_not_ok_status
    pywrap_tensorflow.TF_GetCode(status))
tensorflow.python.framework.errors_impl.InvalidArgumentError: You must feed a value for placeholder tensor 'input_1' with dtype float
         [[Node: input_1 = Placeholder[dtype=DT_FLOAT, shape=[], _device=""/job:localhost/replica:0/task:0/cpu:0""]()]]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""gan.py"", line 329, in <module>
    main(sys.argv[1], gen_model_path, disc_model_path)
  File ""gan.py"", line 321, in main
    adversarial_training(data_dir, generator_model_path, discriminator_model_path)
  File ""gan.py"", line 262, in adversarial_training
    loss_real, loss_generated = train_discriminator_step()
  File ""gan.py"", line 246, in train_discriminator_step
    l_r = discriminator_model.train_on_batch(x, -np.ones(batch_size))
  File ""/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/keras/engine/training.py"", line 1610, in train_on_batch
    outputs = self.train_function(ins)
  File ""/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py"", line 2065, in __call__
    feed_dict=feed_dict)
  File ""/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 767, in run
    run_metadata_ptr)
  File ""/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 965, in _run
    feed_dict_string, options, run_metadata)
  File ""/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 1015, in _do_run
    target_list, options, run_metadata)
  File ""/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 1035, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.InvalidArgumentError: You must feed a value for placeholder tensor 'input_1' with dtype float
         [[Node: input_1 = Placeholder[dtype=DT_FLOAT, shape=[], _device=""/job:localhost/replica:0/task:0/cpu:0""]()]]

Caused by op 'input_1', defined at:
  File ""gan.py"", line 329, in <module>
    main(sys.argv[1], gen_model_path, disc_model_path)
  File ""gan.py"", line 321, in main
    adversarial_training(data_dir, generator_model_path, discriminator_model_path)
  File ""gan.py"", line 155, in adversarial_training
    generator_input_tensor = layers.Input(shape=(rand_dim, ))
  File ""/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/keras/engine/topology.py"", line 1373, in Input
    input_tensor=tensor)
  File ""/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/keras/engine/topology.py"", line 1284, in __init__
    name=self.name)
  File ""/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py"", line 346, in placeholder
    x = tf.placeholder(dtype, shape=shape, name=name)
  File ""/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/python/ops/array_ops.py"", line 1520, in placeholder
    name=name)
  File ""/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/python/ops/gen_array_ops.py"", line 2149, in _placeholder
    name=name)
  File ""/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py"", line 763, in apply_op
    op_def=op_def)
  File ""/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/python/framework/ops.py"", line 2395, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/python/framework/ops.py"", line 1264, in __init__
    self._traceback = _extract_stack()

InvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'input_1' with dtype float
         [[Node: input_1 = Placeholder[dtype=DT_FLOAT, shape=[], _device=""/job:localhost/replica:0/task:0/cpu:0""]()]]
```

What seems to be happening is the computational graphs are separate between `generator` and `discriminator` but once you defined `combined` (something like this):

```python
combined_output = discriminator_model(generator_model(generator_input_tensor))
combined_model = models.Model(inputs=[generator_input_tensor], outputs=[combined_output], name='combined')
```

things get kinda messed up somehow. basically trying to train a batch on the `discriminator` will fail b/c now the batch norm layers think a placeholder tensor must be fed for the generators input. although training the generator and combined model will work fine.

You can reproduce this in keras 1 and 2 (try `cGAN` branch for keras 1 and `wGAN` branch for keras 2) https://github.com/wayaai/GAN-Sandbox",mjdietzx,None,2017-03-08T02:57:14Z,2017-07-13T01:01:45Z
5640,Keras models do not seem to be thread safe.,"After loading a Keras model, you might expect to be able to pass this model around to multiple threads to do inference. When trying this with the Python flask web server I ran into trouble. 

If I load the model on each thread all runs smoothly. Except loading the model takes 1sec or 2/3rds of my runtime.  I'd like to move the model loading out of the hot-path into the startup code then share this model among threads. I've attached a gist (a little incomplete) which illuminates the problem.

https://gist.github.com/sshack/f086aa4bd6932346895e280b8060ea6a

Below is an example of the output I get. It seems Keras is calling the tensor flow backend to create a session in a non-threadsafe way?

Using TensorFlow backend.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
Starting emotion detection service.
 * Running on http://0.0.0.0:5000/ (Press CTRL+C to quit)
 * Restarting with stat
Using TensorFlow backend.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
Starting emotion detection service.
 * Debugger is active!
 * Debugger pin code: 195-322-222
init.
Model config: [{'class_name': 'Merge', 'config': {'layers': [{'class_name': 'Sequential', 'config': [{'class_name': 'LSTM', 'config': {'inner_activation': 'sigmoid', 'trainable': True, 'inner_init': 'uniform', 'output_dim': 10, 'unroll': False, 'consume_less': u'cpu', 'init': 'uniform', 'dropout_U': 0.0, 'input_dtype': u'float32', 'b_regularizer': None, 'input_length': None, 'dropout_W': 0.0, 'activation': 'tanh', 'stateful': False, 'batch_input_shape': (None, None, 29), 'U_regularizer': None, 'name': u'lstm_1', 'go_backwards': False, 'input_dim': 29, 'return_sequences': True, 'W_regularizer': None, 'forget_bias_init': 'one'}}]}, {'class_name': 'Sequential', 'config': [{'class_name': 'LSTM', 'config': {'inner_activation': 'sigmoid', 'trainable': True, 'inner_init': 'uniform', 'output_dim': 10, 'unroll': False, 'consume_less': u'cpu', 'init': 'uniform', 'dropout_U': 0.0, 'input_dtype': u'float32', 'b_regularizer': None, 'input_length': None, 'dropout_W': 0.0, 'activation': 'tanh', 'stateful': False, 'batch_input_shape': (None, None, 29), 'U_regularizer': None, 'name': u'lstm_2', 'go_backwards': True, 'input_dim': 29, 'return_sequences': True, 'W_regularizer': None, 'forget_bias_init': 'one'}}]}], 'name': u'merge_1', 'concat_axis': -1, 'arguments': {}, 'mode_type': 'raw', 'dot_axes': -1, 'output_mask_type': 'raw', 'output_shape_type': 'raw', 'output_mask': None, 'output_shape': None, 'mode': u'sum'}}, {'class_name': 'Dropout', 'config': {'p': 0.2, 'trainable': True, 'name': u'dropout_1'}}, {'class_name': 'Dense', 'config': {'W_constraint': None, 'b_constraint': None, 'name': u'dense_1', 'output_dim': 9, 'activity_regularizer': None, 'trainable': True, 'init': 'glorot_uniform', 'bias': True, 'input_dtype': u'float32', 'input_dim': 10, 'b_regularizer': None, 'W_regularizer': None, 'activation': 'linear', 'batch_input_shape': (None, 10)}}, {'class_name': 'Activation', 'config': {'activation': 'softmax', 'trainable': True, 'name': u'activation_1'}}]
Load model data time: 0.6279296875
Inference input data shape (1, 397, 29)
127.0.0.1 - - [07/Mar/2017 16:17:09] ""PUT / HTTP/1.1"" 500 -
Traceback (most recent call last):
  File ""/Users/sshack/IdeaProjects/emotiondetection/venv/lib/python2.7/site-packages/flask/app.py"", line 1994, in __call__
    return self.wsgi_app(environ, start_response)
  File ""/Users/sshack/IdeaProjects/emotiondetection/venv/lib/python2.7/site-packages/flask/app.py"", line 1985, in wsgi_app
    response = self.handle_exception(e)
  File ""/Users/sshack/IdeaProjects/emotiondetection/venv/lib/python2.7/site-packages/flask_restful/__init__.py"", line 271, in error_router
    return original_handler(e)
  File ""/Users/sshack/IdeaProjects/emotiondetection/venv/lib/python2.7/site-packages/flask/app.py"", line 1540, in handle_exception
    reraise(exc_type, exc_value, tb)
  File ""/Users/sshack/IdeaProjects/emotiondetection/venv/lib/python2.7/site-packages/flask_restful/__init__.py"", line 268, in error_router
    return self.handle_error(e)
  File ""/Users/sshack/IdeaProjects/emotiondetection/venv/lib/python2.7/site-packages/flask/app.py"", line 1982, in wsgi_app
    response = self.full_dispatch_request()
  File ""/Users/sshack/IdeaProjects/emotiondetection/venv/lib/python2.7/site-packages/flask/app.py"", line 1614, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File ""/Users/sshack/IdeaProjects/emotiondetection/venv/lib/python2.7/site-packages/flask_restful/__init__.py"", line 271, in error_router
    return original_handler(e)
  File ""/Users/sshack/IdeaProjects/emotiondetection/venv/lib/python2.7/site-packages/flask/app.py"", line 1517, in handle_user_exception
    reraise(exc_type, exc_value, tb)
  File ""/Users/sshack/IdeaProjects/emotiondetection/venv/lib/python2.7/site-packages/flask_restful/__init__.py"", line 268, in error_router
    return self.handle_error(e)
  File ""/Users/sshack/IdeaProjects/emotiondetection/venv/lib/python2.7/site-packages/flask/app.py"", line 1612, in full_dispatch_request
    rv = self.dispatch_request()
  File ""/Users/sshack/IdeaProjects/emotiondetection/venv/lib/python2.7/site-packages/flask/app.py"", line 1598, in dispatch_request
    return self.view_functions[rule.endpoint](**req.view_args)
  File ""/Users/sshack/IdeaProjects/emotiondetection/venv/lib/python2.7/site-packages/flask_restful/__init__.py"", line 477, in wrapper
    resp = resource(*args, **kwargs)
  File ""/Users/sshack/IdeaProjects/emotiondetection/venv/lib/python2.7/site-packages/flask/views.py"", line 84, in view
    return self.dispatch_request(*args, **kwargs)
  File ""/Users/sshack/IdeaProjects/emotiondetection/venv/lib/python2.7/site-packages/flask_restful/__init__.py"", line 587, in dispatch_request
    resp = meth(*args, **kwargs)
  File ""/Users/sshack/IdeaProjects/emotiondetection/serving/service.py"", line 49, in put
    (valance, arousal) = emotionInference.doEmotionInference(features, gmodel)
  File ""/Users/sshack/IdeaProjects/emotiondetection/serving/emotionInference.py"", line 84, in doEmotionInference
    preds = predmodel.predict([dataset, dataset], verbose=0)
  File ""/Users/sshack/IdeaProjects/emotiondetection/venv/lib/python2.7/site-packages/keras/models.py"", line 724, in predict
    return self.model.predict(x, batch_size=batch_size, verbose=verbose)
  File ""/Users/sshack/IdeaProjects/emotiondetection/venv/lib/python2.7/site-packages/keras/engine/training.py"", line 1269, in predict
    self._make_predict_function()
  File ""/Users/sshack/IdeaProjects/emotiondetection/venv/lib/python2.7/site-packages/keras/engine/training.py"", line 798, in _make_predict_function
    **kwargs)
  File ""/Users/sshack/IdeaProjects/emotiondetection/venv/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py"", line 1961, in function
    return Function(inputs, outputs, updates=updates)
  File ""/Users/sshack/IdeaProjects/emotiondetection/venv/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py"", line 1919, in __init__
    with tf.control_dependencies(self.outputs):
  File ""/Users/sshack/IdeaProjects/emotiondetection/venv/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 3651, in control_dependencies
    return get_default_graph().control_dependencies(control_inputs)
  File ""/Users/sshack/IdeaProjects/emotiondetection/venv/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 3382, in control_dependencies
    c = self.as_graph_element(c)
  File ""/Users/sshack/IdeaProjects/emotiondetection/venv/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 2473, in as_graph_element
    return self._as_graph_element_locked(obj, allow_tensor, allow_operation)
  File ""/Users/sshack/IdeaProjects/emotiondetection/venv/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 2552, in _as_graph_element_locked
    raise ValueError(""Tensor %s is not an element of this graph."" % obj)
ValueError: Tensor Tensor(""div:0"", shape=(?, ?, 9), dtype=float32) is not an element of this graph.
^C⏎                                                                                            (venv) %                                        <~/IdeaProjects/emotiondetection/serving@Anubis
(venv) % python service.py                      <~/IdeaProjects/emotiondetection/serving@Anubis
Using TensorFlow backend.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
Starting emotion detection service.
 * Running on http://0.0.0.0:5000/ (Press CTRL+C to quit)
 * Restarting with stat
Using TensorFlow backend.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
Starting emotion detection service.
 * Debugger is active!
 * Debugger pin code: 195-322-222
init.
Model config: [{'class_name': 'Merge', 'config': {'layers': [{'class_name': 'Sequential', 'config': [{'class_name': 'LSTM', 'config': {'inner_activation': 'sigmoid', 'trainable': True, 'inner_init': 'uniform', 'output_dim': 10, 'unroll': False, 'consume_less': u'cpu', 'init': 'uniform', 'dropout_U': 0.0, 'input_dtype': u'float32', 'b_regularizer': None, 'input_length': None, 'dropout_W': 0.0, 'activation': 'tanh', 'stateful': False, 'batch_input_shape': (None, None, 29), 'U_regularizer': None, 'name': u'lstm_1', 'go_backwards': False, 'input_dim': 29, 'return_sequences': True, 'W_regularizer': None, 'forget_bias_init': 'one'}}]}, {'class_name': 'Sequential', 'config': [{'class_name': 'LSTM', 'config': {'inner_activation': 'sigmoid', 'trainable': True, 'inner_init': 'uniform', 'output_dim': 10, 'unroll': False, 'consume_less': u'cpu', 'init': 'uniform', 'dropout_U': 0.0, 'input_dtype': u'float32', 'b_regularizer': None, 'input_length': None, 'dropout_W': 0.0, 'activation': 'tanh', 'stateful': False, 'batch_input_shape': (None, None, 29), 'U_regularizer': None, 'name': u'lstm_2', 'go_backwards': True, 'input_dim': 29, 'return_sequences': True, 'W_regularizer': None, 'forget_bias_init': 'one'}}]}], 'name': u'merge_1', 'concat_axis': -1, 'arguments': {}, 'mode_type': 'raw', 'dot_axes': -1, 'output_mask_type': 'raw', 'output_shape_type': 'raw', 'output_mask': None, 'output_shape': None, 'mode': u'sum'}}, {'class_name': 'Dropout', 'config': {'p': 0.2, 'trainable': True, 'name': u'dropout_1'}}, {'class_name': 'Dense', 'config': {'W_constraint': None, 'b_constraint': None, 'name': u'dense_1', 'output_dim': 9, 'activity_regularizer': None, 'trainable': True, 'init': 'glorot_uniform', 'bias': True, 'input_dtype': u'float32', 'input_dim': 10, 'b_regularizer': None, 'W_regularizer': None, 'activation': 'linear', 'batch_input_shape': (None, 10)}}, {'class_name': 'Activation', 'config': {'activation': 'softmax', 'trainable': True, 'name': u'activation_1'}}]
Load model data time: 0.632080078125
Inference input data shape (1, 397, 29)
127.0.0.1 - - [07/Mar/2017 16:25:59] ""PUT / HTTP/1.1"" 500 -
Traceback (most recent call last):
  File ""/Users/sshack/IdeaProjects/emotiondetection/venv/lib/python2.7/site-packages/flask/app.py"", line 1994, in __call__
    return self.wsgi_app(environ, start_response)
  File ""/Users/sshack/IdeaProjects/emotiondetection/venv/lib/python2.7/site-packages/flask/app.py"", line 1985, in wsgi_app
    response = self.handle_exception(e)
  File ""/Users/sshack/IdeaProjects/emotiondetection/venv/lib/python2.7/site-packages/flask_restful/__init__.py"", line 271, in error_router
    return original_handler(e)
  File ""/Users/sshack/IdeaProjects/emotiondetection/venv/lib/python2.7/site-packages/flask/app.py"", line 1540, in handle_exception
    reraise(exc_type, exc_value, tb)
  File ""/Users/sshack/IdeaProjects/emotiondetection/venv/lib/python2.7/site-packages/flask_restful/__init__.py"", line 268, in error_router
    return self.handle_error(e)
  File ""/Users/sshack/IdeaProjects/emotiondetection/venv/lib/python2.7/site-packages/flask/app.py"", line 1982, in wsgi_app
    response = self.full_dispatch_request()
  File ""/Users/sshack/IdeaProjects/emotiondetection/venv/lib/python2.7/site-packages/flask/app.py"", line 1614, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File ""/Users/sshack/IdeaProjects/emotiondetection/venv/lib/python2.7/site-packages/flask_restful/__init__.py"", line 271, in error_router
    return original_handler(e)
  File ""/Users/sshack/IdeaProjects/emotiondetection/venv/lib/python2.7/site-packages/flask/app.py"", line 1517, in handle_user_exception
    reraise(exc_type, exc_value, tb)
  File ""/Users/sshack/IdeaProjects/emotiondetection/venv/lib/python2.7/site-packages/flask_restful/__init__.py"", line 268, in error_router
    return self.handle_error(e)
  File ""/Users/sshack/IdeaProjects/emotiondetection/venv/lib/python2.7/site-packages/flask/app.py"", line 1612, in full_dispatch_request
    rv = self.dispatch_request()
  File ""/Users/sshack/IdeaProjects/emotiondetection/venv/lib/python2.7/site-packages/flask/app.py"", line 1598, in dispatch_request
    return self.view_functions[rule.endpoint](**req.view_args)
  File ""/Users/sshack/IdeaProjects/emotiondetection/venv/lib/python2.7/site-packages/flask_restful/__init__.py"", line 477, in wrapper
    resp = resource(*args, **kwargs)
  File ""/Users/sshack/IdeaProjects/emotiondetection/venv/lib/python2.7/site-packages/flask/views.py"", line 84, in view
    return self.dispatch_request(*args, **kwargs)
  File ""/Users/sshack/IdeaProjects/emotiondetection/venv/lib/python2.7/site-packages/flask_restful/__init__.py"", line 587, in dispatch_request
    resp = meth(*args, **kwargs)
  File ""/Users/sshack/IdeaProjects/emotiondetection/serving/service.py"", line 49, in put
    (valance, arousal) = emotionInference.doEmotionInference(features, gmodel)
  File ""/Users/sshack/IdeaProjects/emotiondetection/serving/emotionInference.py"", line 84, in doEmotionInference
    preds = predmodel.predict([dataset, dataset], verbose=0)
  File ""/Users/sshack/IdeaProjects/emotiondetection/venv/lib/python2.7/site-packages/keras/models.py"", line 724, in predict
    return self.model.predict(x, batch_size=batch_size, verbose=verbose)
  File ""/Users/sshack/IdeaProjects/emotiondetection/venv/lib/python2.7/site-packages/keras/engine/training.py"", line 1269, in predict
    self._make_predict_function()
  File ""/Users/sshack/IdeaProjects/emotiondetection/venv/lib/python2.7/site-packages/keras/engine/training.py"", line 798, in _make_predict_function
    **kwargs)
  File ""/Users/sshack/IdeaProjects/emotiondetection/venv/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py"", line 1961, in function
    return Function(inputs, outputs, updates=updates)
  File ""/Users/sshack/IdeaProjects/emotiondetection/venv/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py"", line 1919, in __init__
    with tf.control_dependencies(self.outputs):
  File ""/Users/sshack/IdeaProjects/emotiondetection/venv/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 3651, in control_dependencies
    return get_default_graph().control_dependencies(control_inputs)
  File ""/Users/sshack/IdeaProjects/emotiondetection/venv/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 3382, in control_dependencies
    c = self.as_graph_element(c)
  File ""/Users/sshack/IdeaProjects/emotiondetection/venv/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 2473, in as_graph_element
    return self._as_graph_element_locked(obj, allow_tensor, allow_operation)
  File ""/Users/sshack/IdeaProjects/emotiondetection/venv/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 2552, in _as_graph_element_locked
    raise ValueError(""Tensor %s is not an element of this graph."" % obj)
ValueError: Tensor Tensor(""div:0"", shape=(?, ?, 9), dtype=float32) is not an element of this graph.

",ghost,b'stale',2017-03-08T00:27:19Z,2019-08-10T03:07:07Z
5619,Too slow at runtime with TensorFlow backend,"Hi all,

I have the following model. It is the implementation of the human model of [this paper](https://www.google.ch/url?sa=t&rct=j&q=&esrc=s&source=web&cd=12&cad=rja&uact=8&ved=0ahUKEwjcrcm8r8LSAhWqCJoKHRjnD84QFghKMAs&url=https%3A%2F%2Farxiv.org%2Fabs%2F1511.05298&usg=AFQjCNH4_Eju2x6SXmi6JEMBnnb8wkznSQ&sig2=RoKH1DoVcvd9OF0Ei2AXyg&bvm=bv.148747831,d.bGs) 

This model has about 25M parameters but is around 10 times slower with a model that has 38M parmas. This is where I am confused. Any idea how might I debug this? or why this is legit?

`def getSRNN(batch_input_shape, W_regularizer_val, stateful, output_data_shape,
            spine_idx, l_arm_idx, r_arm_idx, l_leg_idx, r_leg_idx):

    def getNodeRnn(node_name, batch_input_shape, out_shape):
        I = Input(batch_shape=batch_input_shape, dtype='float32', name='input_'+ node_name)
        node = LSTM(512, return_sequences=True, inner_init='orthogonal',
                     batch_input_shape=batch_input_shape, stateful=False,
                     W_regularizer=l2(W_regularizer_val), name=""LSTM_"" + node_name)(I)
        node = SimpleRNN(256, return_sequences=True, inner_init='orthogonal',
                          batch_input_shape=batch_input_shape, stateful=False,
                          W_regularizer=l2(W_regularizer_val), name=""FC_"" + node_name)(node)
        node = SimpleRNN(256, return_sequences=True, inner_init='orthogonal',
                          batch_input_shape=batch_input_shape, stateful=False,
                          W_regularizer=l2(W_regularizer_val), name=""FC_"" + node_name + '1')(node)
        node = SimpleRNN(100, return_sequences=True, inner_init='orthogonal',
                          batch_input_shape=batch_input_shape, stateful=False,
                          W_regularizer=l2(W_regularizer_val), name=""FC_"" + node_name + '2')(node)
        node = SimpleRNN(out_shape, return_sequences=True, inner_init='orthogonal',
                          batch_input_shape=batch_input_shape, stateful=False,
                          W_regularizer=l2(W_regularizer_val), name=""FC_"" + node_name + '3')(node)

        return Model(I, node, name=node_name + '_node')

    def getEdgeRnn(edge_name, batch_input_shape):
        I = Input(batch_shape=batch_input_shape, dtype='float32', name='input_' + edge_name)
        edge = SimpleRNN(256, return_sequences=True, inner_init='orthogonal',
                         batch_input_shape=batch_input_shape, stateful=False,
                         W_regularizer=l2(W_regularizer_val), name=""FC_"" + edge_name)(I)
        edge = SimpleRNN(256, return_sequences=True, inner_init='orthogonal',
                         batch_input_shape=batch_input_shape, stateful=False,
                         W_regularizer=l2(W_regularizer_val), name=""FC_"" + edge_name + '1')(edge)
        edge = LSTM(512, return_sequences=True, inner_init='orthogonal',
                    batch_input_shape=batch_input_shape, stateful=False,
                    W_regularizer=l2(W_regularizer_val), name=""LSTM_"" + edge_name)(edge)
        return Model(I, edge, name=edge_name)

    def selectIndices(x, indices):
        out = x[:, :, 0:1]
        for i in range(len(indices)-1):
            out = K.concatenate([out, x[:, :, indices[i + 1]:indices[i + 1] + 1]], axis=-1)
        return out
        # return x[:, :, K.variable(indices, dtype='int32')]

    def getReverseMap(forward_map):
        reverse_map = []
        for i in range(66):
            for j in range(len(forward_map)):
                if i == forward_map[j]:
                    reverse_map.append(j)
                    break

        return reverse_map

    I = Input(batch_shape=batch_input_shape, dtype='float32', name='current_pose_input')

    samples = batch_input_shape[0]
    time_steps = batch_input_shape[1]
    left_arm_feature_num = len(l_arm_idx)
    right_arm_feature_num = len(r_arm_idx)

    if left_arm_feature_num != right_arm_feature_num:
        print ""Fatal ERROR: Both hands have to have same number of features associated""
        exit(16)

    left_leg_feature_num = len(l_leg_idx)
    right_leg_feature_num = len(r_leg_idx)

    if left_leg_feature_num != right_leg_feature_num:
        print ""Fatal ERROR: Both legs have to have same number of features associated""
        exit(17)

    spine_feature_num = len(spine_idx)

    # Node inputs
    left_arm_in = Lambda(selectIndices, arguments={'indices': l_arm_idx}, name='l_arm')(I)
    right_arm_in = Lambda(selectIndices, arguments={'indices': l_arm_idx}, name='r_arm')(I)
    left_leg_in = Lambda(selectIndices, arguments={'indices': l_leg_idx}, name='l_leg')(I)
    right_leg_in = Lambda(selectIndices, arguments={'indices': r_leg_idx}, name='r_leg')(I)
    spine_in = Lambda(selectIndices, arguments={'indices': spine_idx}, name='Spine')(I)

    # Node RNNs
    spine_node = getNodeRnn('spine', batch_input_shape=[samples, time_steps, spine_feature_num + 512 * 3],
                            out_shape=spine_feature_num)
    arm_node = getNodeRnn('arm', batch_input_shape=[samples, time_steps, left_arm_feature_num + 512 * 3],
                          out_shape=left_arm_feature_num)
    leg_node = getNodeRnn('leg', batch_input_shape=[samples, time_steps, right_leg_feature_num + 512 * 2],
                          out_shape=right_leg_feature_num)

    # Edge RNNs
    l_arm_r_arm_edge = getEdgeRnn('l_arm_r_arm_edge',
                                  batch_input_shape=[samples, time_steps, left_arm_feature_num*2])
    l_leg_r_leg_edge = getEdgeRnn('l_leg_r_leg_edge',
                                  batch_input_shape=[samples, time_steps, left_leg_feature_num * 2])
    leg_spine_edge = getEdgeRnn('leg_spine_edge',
                                batch_input_shape=[samples, time_steps, left_leg_feature_num + spine_feature_num])
    arm_spine_edge = getEdgeRnn('arm_spine_edge',
                                batch_input_shape=[samples, time_steps, left_arm_feature_num + spine_feature_num])
    spine_spine_edge = getEdgeRnn('spine_spine_edge',
                                  batch_input_shape=[samples, time_steps, spine_feature_num])
    arm_arm_edge = getEdgeRnn('arm_arm_edge', batch_input_shape=[samples, time_steps, left_arm_feature_num])
    leg_leg_edge = getEdgeRnn('leg_leg_edge', batch_input_shape=[samples, time_steps, left_leg_feature_num])

    # Connecting everything together
    # edge_connections
    spine_spine_edge = spine_spine_edge(spine_in)
    l_arm_l_arm_edge = arm_arm_edge(left_arm_in)
    r_arm_r_arm_edge = arm_arm_edge(right_arm_in)
    l_arm_r_arm_edge = l_arm_r_arm_edge(merge([left_arm_in, right_arm_in], mode='concat', concat_axis=-1))
    l_leg_l_leg_edge = leg_leg_edge(left_leg_in)
    r_leg_r_leg_edge = leg_leg_edge(right_leg_in)
    l_leg_r_leg_edge = l_leg_r_leg_edge(merge([left_leg_in, right_leg_in], mode='concat', concat_axis=-1))
    spine_l_arm_edge = arm_spine_edge(merge([spine_in, left_arm_in], mode='concat', concat_axis=-1))
    spine_r_arm_edge = arm_spine_edge(merge([spine_in, right_arm_in], mode='concat', concat_axis=-1))
    spine_l_leg_edge = leg_spine_edge(merge([spine_in, left_leg_in], mode='concat', concat_axis=-1))
    spine_r_leg_edge = leg_spine_edge(merge([spine_in, right_leg_in], mode='concat', concat_axis=-1))


    # node connections
    left_arm = arm_node(merge([left_arm_in, spine_l_arm_edge, l_arm_l_arm_edge, l_arm_r_arm_edge],
                              mode='concat', concat_axis=-1))
    right_arm = arm_node(merge([right_arm_in, spine_r_arm_edge, r_arm_r_arm_edge, l_arm_r_arm_edge],
                               mode='concat', concat_axis=-1))

    both_hand = merge([spine_l_arm_edge, spine_r_arm_edge], mode='sum', concat_axis=-1)
    both_legs = merge([spine_l_leg_edge, spine_r_leg_edge], mode='sum', concat_axis=-1)
    spine = spine_node(merge([spine_in, spine_spine_edge, both_hand, both_legs], mode='concat', concat_axis=-1))

    left_leg = leg_node(merge([left_leg_in, l_leg_l_leg_edge, l_leg_r_leg_edge], mode='concat', concat_axis=-1))
    right_leg = leg_node(merge([right_leg_in, r_leg_r_leg_edge, l_leg_r_leg_edge], mode='concat', concat_axis=-1))

    output = merge([spine, left_arm, right_arm, left_leg, right_leg], mode='concat', concat_axis=-1)

    # This order hs to match the previous merge order
    forward_map = spine_idx + l_arm_idx + r_arm_idx + l_leg_idx + r_leg_idx
    reverse_map = getReverseMap(forward_map)
    output = Lambda(selectIndices, arguments={'indices': reverse_map}, name='Output_rearrange')(output)

    # output = SimpleRNN(output_data_shape, return_sequences=True, inner_init='orthogonal',
    #                    batch_input_shape=batch_input_shape, stateful=stateful,
    #                    W_regularizer=l2(W_regularizer_val), name=""FC_output"")(output)

    model = Model(input=I, output=output)

    if stateful:
        for layer_idx in range(len(model.layers)):
            if hasattr(model.layers, 'stateful'):
                model.layers.stateful = True

    return model`


",ParthaEth,b'stale',2017-03-06T17:26:25Z,2017-07-09T00:09:29Z
5576,Weird thing when using functional API with BatchNorm.,"Hi, I'm trying to build a model with functional API. But I got some error only when I use BatchNorm layer . A toy example: 

```
import numpy as np
from keras.layers import Input, BatchNormalization, Dense
from keras.models import Model

# model1:
input1 = Input((10,))
bn1 = BatchNormalization()(input1)
out1 = Dense(2, activation='softmax')(bn1)
model1 = Model(input1, out1)

# model2:
input2 = Input((10,))
out2 = Dense(10, activation='relu')(input2)
model2 = Model(input2, out2)

# model3 is just a simple stack of model1 and model2:
input3 = Input((10,))
out3 = model1(model2(input3))
model3 = Model(input3, out3)

# compile and train:
model1.compile(loss='categorical_crossentropy',
               optimizer='adam',
               metrics=['accuracy'])
y = np.zeros((10, 2))
x = np.zeros((10, 10))
model1.train_on_batch(x, y)
```
Then I get  `InvalidArgumentError: You must feed a value for placeholder tensor 'input_3' with dtype float`. But model1 has nothing to do with input3 if I train it separately. The weird thing is that if I remove bn1 of model1 or change it to layers like Dense, this error will disappear.

 I use tensorflow backend and both tensorflow and keras are updated. Do I use functional API in the wrong way or it is a potential bug?
",JeffDong,None,2017-03-02T11:24:48Z,2017-03-03T04:38:39Z
5564,Strange behaviour for Adam optimizer when using different keras syntax,"Hi there!

I noticed a very strange behaviour in a simple classification task depending on the keras syntax I use.
In my classification task I have two groups and therefore put a Dense(2) Keras layer plus a softmax activation at the end of my model. If I compile the model, there are two different syntaxes from which one can choose. Strangely, I noticed that for one version the model does learn something (I don't care if the model is just fitting noise at this point) and for one it doesn't. Down below you can see the two versions. They are almost identical except for the way the optimizer is passed to the compile() method. 
This only happens with my data, the Adam optimizer and the softmax layer at the end of the model. Very strange.

Does anyone have even the slightest idea what's going on there? I don't have any explanation for that behaviour but now have developed some mistrust in the analyses I did before. 
Thanks a lot for your help!

You can download my data from: https://drive.google.com/open?id=0B_3vtX0VzrOMVEIwdFo2U2FsU0E


```python
import numpy as np
from keras.optimizers import Adam
from keras.models import Sequential
from keras.layers import Dense
from keras.layers.core import Activation
import matplotlib.pyplot as plt
%matplotlib inline


# Load data
data = np.load('/YOUR-PATH-TO-DATA/data_keras_bug.npy')
labels = np.load('/YOUR-PATH-TO-DATA/labels_keras_bug.npy')
input_dim = data.shape[1]


# Create first model
model1 = Sequential()
model1.add(Dense(1500, input_dim=input_dim))
model1.add(Activation('relu'))
model1.add(Dense(2))
model1.add(Activation('softmax'))
# declare the optimizer within the compile() method 
model1.compile(loss='categorical_crossentropy', optimizer='adam', lr=0.01, metrics=['accuracy'])


# Create second equivalent model
model2 = Sequential()
model2.add(Dense(1500, input_dim=input_dim))
model2.add(Activation('relu'))
model2.add(Dense(2))
model2.add(Activation('softmax'))
# declare the optimizer explicitly before passing it to the compile() method
optimizer = Adam(lr=0.01)
model2.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])


# fit both models the same way
results1 = model1.fit(data, labels, batch_size=32, nb_epoch=500, verbose=0)
results2 = model2.fit(data, labels, batch_size=32, nb_epoch=500, verbose=0)

# plot the training accuracies
plt.plot(results1.history['acc'])
plt.plot(results2.history['acc'],'k')
plt.show()
```
![output_5_0](https://cloud.githubusercontent.com/assets/17763631/23469891/423f48f4-fea5-11e6-8b18-444fcca3cf4b.png)

",NilsWinter,None,2017-03-01T16:49:16Z,2019-09-18T18:28:19Z
5489,Causal Dilated Convolutions ,"Adds a boolean causal flag to Conv1D which results in Causal (Dilated) Convolutions as suggested in the Wavenet paper. See #5297. 

Additionally, this PR fixes a bug in temporal_padding for theano, an issues with using input_data for layer_test, and an issue with test_convolution_1d where dilated convolutions where tested for only one padding type. All these are in commit d1e4ef8 which can be cherry-picked.",basveeling,None,2017-02-23T15:02:14Z,2017-12-08T01:58:34Z
5469,tf.while_loop hangs when Dropout layer is used,"Simply put, `tf.while_loop` hangs when `Dropout` layer is used.  Keras version `2.0.2` <s>`1.2.2`</s>, Tensorflow version `1.0.1` <s>`1.0.0`</s>.

Please see the [gist](https://gist.github.com/gongzhitaao/e56ba03607eccafc616ca9677f8d9ba6) to reproduce this error.

1. Basically If you remove (comment out) the `Dropout(0.5)` layer **OR** change the total iteration to less than 10, the program correctly runs and terminates.
2. Otherwise, the program hangs.

It seems to me like a race condition.  And it seems to be a bug within keras since tensorflow alone does not  have this bug.",gongzhitaao,b'stale',2017-02-21T14:49:07Z,2018-02-02T15:20:03Z
5454,"Hidden activations retrievable as input tensor, but not as output tensor","I built a small LSTM model with multiple outputs using the Theano backend and functional API. The dimensions of the inputs are not in the right order for the LSTM, which is why the inputs have to be permuted before being passed on to the LSTM layer. The model construction looks like this:

```python
from keras.models import Model, Sequential
from keras.layers import  Dense, LSTM, Permute, Input
from keras import backend as K

main_input = Input(shape=(3,100))

lstm = Sequential()
lstm.add(Permute(dims=(1,2), input_shape=(3,100)))
lstm.add(LSTM(output_dim=512, consume_less=""gpu""))

lstm_out = lstm(main_input)

out1 = Dense(5, activation=""softmax"")(lstm_out)
out2 = Dense(5, activation=""softmax"")(lstm_out)

model = Model(input=main_input, output=[out1, out2])

model.compile(loss=""categorical_crossentropy"", optimizer=""sgd"")
```

The model compiles without errors and also works in training and prediction. However, when I wanted to assess the hidden activations of the LSTM layer with

```python
get_lstm_activations = K.function([model.input, K.learning_phase()], [model.layers[1].layers[1].output])
```

I get the following error:

```
MissingInputError: (""An input of the graph, used to compute DimShuffle{0,1,2}(permute_input_2), was not provided and not given a value.Use the Theano flag exception_verbosity='high',for more information on this error."", permute_input_2)
```

If I try to get the same tensor not as the output of the LSTM layer, but as the input of the next layer, like

```python
get_lstm_activations = K.function([model.input, K.learning_phase()], [model.layers[2].input])
```

I don't get any errors and it indeed seems to work. That seems really counterintuitive to me and I came up with this alternative approach mostly by chance. Can anyone explain why the intermediate output tensor cannot be obtained and whether this is a bug in the functional API or the consequence of an intended behavior?",fortuin,b'stale',2017-02-20T11:45:50Z,2017-06-22T21:14:52Z
5446,Get Gradients wrt Feature Maps,"Hello,

I want to get the gradients after every convolution layer wrt the feature maps with:
```
model = ... # trained model with input shape (1, 1, 32, 32)

# get conv layers outputs
conv_output_tensor = [model.layers[i].output for i in range(1, len(model.layers)) if 'conv' in model.layers[i].name]
# output of two conv layers are of shape (1, 32, 26, 26) and (1, 32, 24, 24)
get_conv_layer_output = K.function([model.layers[0].input], conv_output_tensor)

# calculate gradient wrt feature maps
grads_wrt_feature_map = model.optimizer.get_gradients(model.total_loss, conv_output_tensor)

input_tensors = [model.inputs[0], # input data
                 model.sample_weights[0], # sample weights
                 model.targets[0], # labels
                 K.learning_phase(), # train/test
]

f_get_grad_wrt_feature_map = K.function(inputs=input_tensors, outputs=grads_wrt_feature_map)

inputs = [ X, # input, shape (1, 1, 32, 32)
          [1], # sample weights
          [[2]], # y
          0] # test mode
get_gradients = f_get_grad_wrt_feature_map(inputs)
```
But somehow I got input dimension mis-match error in Theano:
```
ValueError: Input dimension mis-match. (input[0].shape[1] = 10, input[3].shape[1] = 1)
Apply node that caused the error: Elemwise{Composite{((i0 * i1 * i2 * i3 * i4) / (i5 * i6 * i7 * i8 * i8))}}(Elemwise{Composite{AND(GE(i0, i1), LE(i0, i2))}}.0, Elemwise{Cast{float32}}.0, InplaceDimShuffle{0,x}.0, activation_4_target, SoftmaxWithBias.0, Elemwise{Cast{float32}}.0, InplaceDimShuffle{x,x}.0, Elemwise{Clip}[(0, 0)].0, InplaceDimShuffle{0,x}.0)
Toposort index: 60
Inputs types: [TensorType(int8, matrix), TensorType(float32, (True, True)), TensorType(float32, col), TensorType(float32, matrix), TensorType(float32, matrix), TensorType(float32, (True, True)), TensorType(float32, (True, True)), TensorType(float32, matrix), TensorType(float32, col)]
Inputs shapes: [(1, 10), (1, 1), (1, 1), (1, 1), (1, 10), (1, 1), (1, 1), (1, 10), (1, 1)]
Inputs strides: [(10, 1), (4, 4), (4, 4), (4, 4), (40, 4), (4, 4), (4, 4), (40, 4), (4, 4)]
Inputs values: ['not shown', array([[ 1.]], dtype=float32), array([[ 1.]], dtype=float32), array([[ 2.]], dtype=float32), 'not shown', array([[ 1.]], dtype=float32), array([[ 1.]], dtype=float32), 'not shown', array([[ 1.]], dtype=float32)]
Outputs clients: [[Sum{axis=[1], acc_dtype=float64}(Elemwise{Composite{((i0 * i1 * i2 * i3 * i4) / (i5 * i6 * i7 * i8 * i8))}}.0)]]

HINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.
HINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.
```
Any ideas?",KlaymenGC,None,2017-02-19T22:09:46Z,2017-02-20T08:33:14Z
5433,"Potential Batch Normailzation Bug - crashing on mode 0, not on mode 2","Model.add(BatchNormalization(mode=0)) causes crashing on gpu cluster, but does not on Model.add(BatchNormalization(mode=2))

Is this an error with TensorFlow on the cluster on Keras?

> Epoch 1/1
Traceback (most recent call last):
  File ""/cm/local/apps/slurm/var/spool/job03176/slurm_script"", line 104, in <module>
    validation_data = (xVal, yVal))
  File ""/usr/lib/python2.7/site-packages/keras/models.py"", line 874, in fit_generator
    pickle_safe=pickle_safe)
  File ""/usr/lib/python2.7/site-packages/keras/engine/training.py"", line 1443, in fit_generator
    class_weight=class_weight)
  File ""/usr/lib/python2.7/site-packages/keras/engine/training.py"", line 1221, in train_on_batch
    outputs = self.train_function(ins)
  File ""/usr/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py"", line 1013, in __call__
    updated = session.run(self.outputs + [self.updates_op], feed_dict=feed_dict)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 766, in run
    run_metadata_ptr)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 964, in _run
    feed_dict_string, options, run_metadata)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 1014, in _do_run
    target_list, options, run_metadata)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 1034, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.FailedPreconditionError: Attempting to use uninitialized value batchnormalization_1_running_mean/biased
	 [[Node: batchnormalization_1_running_mean/biased/read = Identity[T=DT_FLOAT, _class=[""loc:@batchnormalization_1_running_mean""], _device=""/job:localhost/replica:0/task:0/gpu:0""](batchnormalization_1_running_mean/biased)]]
	 [[Node: moments/sufficient_statistics/Shape/_11 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device_incarnation=1, tensor_name=""edge_2903_moments/sufficient_statistics/Shape"", tensor_type=DT_INT32, _device=""/job:localhost/replica:0/task:0/cpu:0""]()]]

> Caused by op u'batchnormalization_1_running_mean/biased/read', defined at:
  File ""/cm/local/apps/slurm/var/spool/job03176/slurm_script"", line 30, in <module>
    model.add(BatchNormalization(mode=0))
  File ""/usr/lib/python2.7/site-packages/keras/models.py"", line 308, in add
    output_tensor = layer(self.outputs[0])
  File ""/usr/lib/python2.7/site-packages/keras/engine/topology.py"", line 514, in __call__
    self.add_inbound_node(inbound_layers, node_indices, tensor_indices)
  File ""/usr/lib/python2.7/site-packages/keras/engine/topology.py"", line 572, in add_inbound_node
    Node.create_node(self, inbound_layers, node_indices, tensor_indices)
  File ""/usr/lib/python2.7/site-packages/keras/engine/topology.py"", line 149, in create_node
    output_tensors = to_list(outbound_layer.call(input_tensors[0], mask=input_masks[0]))
  File ""/usr/lib/python2.7/site-packages/keras/layers/normalization.py"", line 140, in call
    self.updates = [K.moving_average_update(self.running_mean, mean, self.momentum),
  File ""/usr/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py"", line 327, in moving_average_update
    variable, value, momentum)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/training/moving_averages.py"", line 70, in assign_moving_average
    update_delta = _zero_debias(variable, value, decay)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/training/moving_averages.py"", line 177, in _zero_debias
    trainable=False)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py"", line 1024, in get_variable
    custom_getter=custom_getter)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py"", line 850, in get_variable
    custom_getter=custom_getter)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py"", line 346, in get_variable
    validate_shape=validate_shape)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py"", line 331, in _true_getter
    caching_device=caching_device, validate_shape=validate_shape)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py"", line 677, in _get_single_variable
    expected_shape=shape)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/ops/variables.py"", line 224, in __init__
    expected_shape=expected_shape)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/ops/variables.py"", line 370, in _init_from_args
    self._snapshot = array_ops.identity(self._variable, name=""read"")
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/ops/gen_array_ops.py"", line 1424, in identity
    result = _op_def_lib.apply_op(""Identity"", input=input, name=name)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py"", line 759, in apply_op
    op_def=op_def)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 2240, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 1128, in __init__
    self._traceback = _extract_stack()

FailedPreconditionError (see above for traceback): Attempting to use uninitialized value batchnormalization_1_running_mean/biased
	 [[Node: batchnormalization_1_running_mean/biased/read = Identity[T=DT_FLOAT, _class=[""loc:@batchnormalization_1_running_mean""], _device=""/job:localhost/replica:0/task:0/gpu:0""](batchnormalization_1_running_mean/biased)]]
	 [[Node: moments/sufficient_statistics/Shape/_11 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device_incarnation=1, tensor_name=""edge_2903_moments/sufficient_statistics/Shape"", tensor_type=DT_INT32, _device=""/job:localhost/replica:0/task:0/cpu:0""]()]]


",mjs-wpi,b'stale',2017-02-18T06:17:21Z,2017-06-22T19:10:02Z
5429,NVCC Compilation Errors with Theano Backend and Binary Accuracy Metric,"I'm getting some lengthy compilation errors from NVCC when I try to fit some simple networks using the Theano backend.  These are not an issue when running on the CPU or with the Tensorflow backend.  However I am using the latest stable release of Theano.  I am using CUDA 7, though. Python 2.7.11 with GTX Titan X.

Curiously, as far as I can tell, I only get these issues when using the `accuracy` metric in combination with the `binary_crossentropy` loss function.  I can build and run fine (on GPU with Theano) using e.g. categorical crossentropy with accuracy, or binary_crossentropy with different metrics such as MSE (even if nonsensical).  Therefore maybe there is some Keras weirdness here.

Short example code with lengthy error output (including some cuda code.)

```
import keras
from keras.models import Sequential
from keras.layers import Dense, Activation
import numpy as np
import os
import theano
import sys



print(sys.version)
print(keras.__version__)
print(theano.__version__)

model = Sequential()
model.add(Dense(output_dim=64, input_dim=100))
model.add(Activation('relu'))
model.add(Dense(output_dim=1))
model.add(Activation('softmax'))
model.compile(loss='binary_crossentropy', optimizer='sgd', metrics=['accuracy'])

X_train = np.random.rand(100,100)
Y_train = np.ones([100])

model.fit(X_train, Y_train, nb_epoch=5, batch_size=32)
```

Outputs:
<details>
    <summary>Verbose Error</summary>

```
Using Theano backend.
Using gpu device 1: GeForce GTX TITAN X (CNMeM is enabled with initial size: 30.0% of memory, cuDNN 4007)

2.7.11 |Anaconda custom (64-bit)| (default, Dec  6 2015, 18:08:32) 
[GCC 4.4.7 20120313 (Red Hat 4.4.7-1)]
1.2.2
0.8.2
```

`['nvcc', '-shared', '-O3', '--maxrregcount=32', '-use_fast_math', '-arch=sm_52', '-m64', '-Xcompiler', '-fno-math-errno,-Wno-unused-label,-Wno-unused-variable,-Wno-write-strings,-DCUDA_NDARRAY_CUH=c72d035fdf91890f3b36710688069b2e,-DNPY_NO_DEPRECATED_API=NPY_1_7_API_VERSION,-fPIC,-fvisibility=hidden', '-Xlinker', '-rpath,/home/dlavery/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-centos-7.0.1406-Core-x86_64-2.7.11-64/cuda_ndarray', '-I/home/dlavery/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-centos-7.0.1406-Core-x86_64-2.7.11-64/cuda_ndarray', '-I/usr/local/cuda-7.0/include', '-I/opt/anaconda/lib/python2.7/site-packages/numpy/core/include', '-I/opt/anaconda/include/python2.7', '-I/opt/anaconda/lib/python2.7/site-packages/theano/gof', '-I/opt/anaconda/lib/python2.7/site-packages/theano/sandbox/cuda', '-o', '/home/dlavery/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-centos-7.0.1406-Core-x86_64-2.7.11-64/tmpRVfVZt/97a71e38254d70d6a35005e736217b06.so', 'mod.cu', '-L/home/dlavery/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-centos-7.0.1406-Core-x86_64-2.7.11-64/cuda_ndarray', '-L/opt/anaconda/lib', '-lcudart', '-lcublas', '-lcuda_ndarray', '-lpython2.7']`

```
 #include <Python.h>
2 #include <iostream>
3 #include ""theano_mod_helper.h""
4 #include ""cuda_ndarray.cuh""
5 //////////////////////
6 ////  Support Code
7 //////////////////////
8 
9 
10     namespace {
11     struct __struct_compiled_op_97a71e38254d70d6a35005e736217b06 {
12         PyObject* __ERROR;
13 
14         PyObject* storage_V3;
15 PyObject* storage_V1;
16         
17 
18         __struct_compiled_op_97a71e38254d70d6a35005e736217b06() {
19             // This is only somewhat safe because we:
20             //  1) Are not a virtual class
21             //  2) Do not use any virtual classes in the members
22             //  3) Deal with mostly POD and pointers
23 
24             // If this changes, we would have to revise this, but for
25             // now I am tired of chasing segfaults because
26             // initialization code had an error and some pointer has
27             // a junk value.
28             memset(this, 0, sizeof(*this));
29         }
30         ~__struct_compiled_op_97a71e38254d70d6a35005e736217b06(void) {
31             cleanup();
32         }
33 
34         int init(PyObject* __ERROR, PyObject* storage_V3, PyObject* storage_V1) {
35             Py_XINCREF(storage_V3);
36 Py_XINCREF(storage_V1);
37             this->storage_V3 = storage_V3;
38 this->storage_V1 = storage_V1;
39             
40 
41 
42 
43             this->__ERROR = __ERROR;
44             return 0;
45         }
46         void cleanup(void) {
47             __label_1:
48 
49 double __DUMMY_1;
50 __label_3:
51 
52 double __DUMMY_3;
53 __label_6:
54 
55 double __DUMMY_6;
56 
57             Py_XDECREF(this->storage_V3);
58 Py_XDECREF(this->storage_V1);
59         }
60         int run(void) {
61             int __failure = 0;
62             
63     PyObject* py_V1;
64      CudaNdarray * V1;
65     PyObject* py_V3;
66      CudaNdarray * V3;
67 {
68 
69     py_V1 = PyList_GET_ITEM(storage_V1, 0);
70     {Py_XINCREF(py_V1);}
71     
72         if (py_V1 == Py_None)
73         {
74             V1 = NULL;
75         }
76         else
77         {
78             
79         assert(py_V1->ob_refcnt >= 2); // There should be at least one ref from the container object,
80         // and one ref from the local scope.
81 
82         if (CudaNdarray_Check(py_V1))
83         {
84             //fprintf(stderr, ""c_extract CNDA object w refcnt %p %i\n"", py_V1, (py_V1->ob_refcnt));
85             V1 = (CudaNdarray*)py_V1;
86             //std::cerr << ""c_extract "" << V1 << '\n';
87         
88 
89                 if (V1->nd != 2)
90                 {
91                     PyErr_Format(PyExc_RuntimeError,
92                                  ""c_extract: Some CudaNdarray has rank %i, it was supposed to have rank 2"",
93                                  V1->nd);
94                     V1 = NULL;
95                     {
96         __failure = 2;
97         if (!PyErr_Occurred()) {
98             PyErr_SetString(PyExc_RuntimeError,
99                 ""Unexpected error in an Op's C code. ""
100                 ""No Python exception was set."");
101             }
102         goto __label_2;};
103                 }
104                 //std::cerr << ""c_extract "" << V1 << "" nd check passed\n"";
105             
106 
107                 assert(V1);
108                 Py_INCREF(py_V1);
109             }
110             else if (py_V1 == Py_None)
111             {
112                 PyErr_SetString(PyExc_TypeError,
113                                 ""expected a CudaNdarray, not None"");
114                 V1 = NULL;
115                 {
116         __failure = 2;
117         if (!PyErr_Occurred()) {
118             PyErr_SetString(PyExc_RuntimeError,
119                 ""Unexpected error in an Op's C code. ""
120                 ""No Python exception was set."");
121             }
122         goto __label_2;};
123             }
124             else
125             {
126                 //fprintf(stderr, ""FAILING c_extract CNDA object w refcnt %p %i\n"", py_V1, (py_V1->ob_refcnt));
127                 PyErr_SetString(PyExc_TypeError, ""Argument not a CudaNdarray"");
128                 V1 = NULL;
129                 {
130         __failure = 2;
131         if (!PyErr_Occurred()) {
132             PyErr_SetString(PyExc_RuntimeError,
133                 ""Unexpected error in an Op's C code. ""
134                 ""No Python exception was set."");
135             }
136         goto __label_2;};
137             }
138             //std::cerr << ""c_extract done "" << V1 << '\n';
139             
140 
141         }
142         
143 {
144 
145     py_V3 = PyList_GET_ITEM(storage_V3, 0);
146     {Py_XINCREF(py_V3);}
147     
148         assert(py_V3->ob_refcnt >= 2); // There should be at least one ref from the container object,
149         // and one ref from the local scope.
150 
151         if (CudaNdarray_Check(py_V3))
152         {
153             //fprintf(stderr, ""c_extract CNDA object w refcnt %p %i\n"", py_V3, (py_V3->ob_refcnt));
154             V3 = (CudaNdarray*)py_V3;
155             //std::cerr << ""c_extract "" << V3 << '\n';
156         
157 
158                 if (V3->nd != 2)
159                 {
160                     PyErr_Format(PyExc_RuntimeError,
161                                  ""c_extract: Some CudaNdarray has rank %i, it was supposed to have rank 2"",
162                                  V3->nd);
163                     V3 = NULL;
164                     {
165         __failure = 4;
166         if (!PyErr_Occurred()) {
167             PyErr_SetString(PyExc_RuntimeError,
168                 ""Unexpected error in an Op's C code. ""
169                 ""No Python exception was set."");
170             }
171         goto __label_4;};
172                 }
173                 //std::cerr << ""c_extract "" << V3 << "" nd check passed\n"";
174             
175 
176                 assert(V3);
177                 Py_INCREF(py_V3);
178             }
179             else if (py_V3 == Py_None)
180             {
181                 PyErr_SetString(PyExc_TypeError,
182                                 ""expected a CudaNdarray, not None"");
183                 V3 = NULL;
184                 {
185         __failure = 4;
186         if (!PyErr_Occurred()) {
187             PyErr_SetString(PyExc_RuntimeError,
188                 ""Unexpected error in an Op's C code. ""
189                 ""No Python exception was set."");
190             }
191         goto __label_4;};
192             }
193             else
194             {
195                 //fprintf(stderr, ""FAILING c_extract CNDA object w refcnt %p %i\n"", py_V3, (py_V3->ob_refcnt));
196                 PyErr_SetString(PyExc_TypeError, ""Argument not a CudaNdarray"");
197                 V3 = NULL;
198                 {
199         __failure = 4;
200         if (!PyErr_Occurred()) {
201             PyErr_SetString(PyExc_RuntimeError,
202                 ""Unexpected error in an Op's C code. ""
203                 ""No Python exception was set."");
204             }
205         goto __label_4;};
206             }
207             //std::cerr << ""c_extract done "" << V3 << '\n';
208             
209 
210 {
211 // Op class GpuElemwise
212 
213         //std::cerr << ""C_CODE RoundHalfToEven START\n"";
214         //standard elemwise size checks
215             
216 
217             int dims[2] = {1,1};
218             
219 
220                 int broadcasts_V3[2] = {0, 0};
221                 
222 
223         //std::cerr << ""C_CODE RoundHalfToEven checking input V3\n"";
224         if (2 != V3->nd)
225         {
226             PyErr_Format(PyExc_TypeError,
227                          ""need 2 dims, not %i"", V3->nd);
228             {
229         __failure = 5;
230         if (!PyErr_Occurred()) {
231             PyErr_SetString(PyExc_RuntimeError,
232                 ""Unexpected error in an Op's C code. ""
233                 ""No Python exception was set."");
234             }
235         goto __label_5;};
236         }
237         for (int i = 0; i< 2; ++i)
238         {
239             dims[i] = (dims[i] == 1) ? CudaNdarray_HOST_DIMS(V3)[i] : dims[i];
240             if ((!(broadcasts_V3[i] &&
241                  CudaNdarray_HOST_DIMS(V3)[i] == 1)) &&
242                 (dims[i] != CudaNdarray_HOST_DIMS(V3)[i]))
243             {
244                 //std::cerr << ""C_CODE RoundHalfToEven checking input V3 failed\n"";
245                 PyErr_Format(PyExc_ValueError,
246                              ""GpuElemwise. Input dimension mis-match. Input""
247                              "" 0 (indices start at 0) has shape[%i] == %i""
248                              "", but the output's size on that axis is %i."",
249                              i,
250                              CudaNdarray_HOST_DIMS(V3)[i],
251                              dims[i]
252                             );
253                 {
254         __failure = 5;
255         if (!PyErr_Occurred()) {
256             PyErr_SetString(PyExc_RuntimeError,
257                 ""Unexpected error in an Op's C code. ""
258                 ""No Python exception was set."");
259             }
260         goto __label_5;};
261             }
262         }
263             
264 
265         for (int i = 0; (i< 2) && (V1); ++i) {
266             if (dims[i] != CudaNdarray_HOST_DIMS(V1)[i])
267             {
268                 Py_DECREF(V1);
269                 V1 = NULL;
270             }
271         }
272         if (V1 && !CudaNdarray_is_c_contiguous(V1))
273         {
274             Py_XDECREF(V1);
275             V1 = NULL;
276         }
277         if (NULL == V1)
278         {
279             V1 = (CudaNdarray*)CudaNdarray_New();
280             if (!V1)
281             {
282                 //error string already set
283                 {
284         __failure = 5;
285         if (!PyErr_Occurred()) {
286             PyErr_SetString(PyExc_RuntimeError,
287                 ""Unexpected error in an Op's C code. ""
288                 ""No Python exception was set."");
289             }
290         goto __label_5;};
291             }
292             if (CudaNdarray_alloc_contiguous(V1, 2, dims))
293             {
294                 //error string already set
295                 Py_DECREF(V1);
296                 V1 = NULL;
297                 {
298         __failure = 5;
299         if (!PyErr_Occurred()) {
300             PyErr_SetString(PyExc_RuntimeError,
301                 ""Unexpected error in an Op's C code. ""
302                 ""No Python exception was set."");
303             }
304         goto __label_5;};
305             }
306         }
307         //std::cerr << ""ELEMWISE NEW V1 nd"" << V1->nd << ""\n"";
308         //std::cerr << ""ELEMWISE NEW V1 data"" << V1->devdata << ""\n"";
309         
310 
311         {
312             //new block so that failure gotos don't skip over variable initialization
313             //std::cerr << ""calling callkernel\n"";
314             if (callkernel_node_97a71e38254d70d6a35005e736217b06_0(1, 0, dims
315             
316 
317                         , CudaNdarray_DEV_DATA(V3), CudaNdarray_HOST_STRIDES(V3)
318             
319 
320                         , CudaNdarray_DEV_DATA(V1), CudaNdarray_HOST_STRIDES(V1)
321             
322 
323                         ))
324             {
325                  // error
326             
327 
328                 Py_DECREF(V1);
329                 V1 = NULL;
330                 
331 
332                 {
333         __failure = 5;
334         if (!PyErr_Occurred()) {
335             PyErr_SetString(PyExc_RuntimeError,
336                 ""Unexpected error in an Op's C code. ""
337                 ""No Python exception was set."");
338             }
339         goto __label_5;};
340             }
341             else // no error
342             {
343             }
344         }
345         //std::cerr << ""C_CODE RoundHalfToEven END\n"";
346         
347 __label_5:
348 
349 double __DUMMY_5;
350 
351 }
352 __label_4:
353 
354         //std::cerr << ""cleanup "" << py_V3 << "" "" << V3 << ""\n"";
355         //fprintf(stderr, ""c_cleanup CNDA py_object w refcnt %p %i\n"", py_V3, (py_V3->ob_refcnt));
356         if (V3)
357         {
358             //fprintf(stderr, ""c_cleanup CNDA cn_object w refcnt %p %i\n"", V3, (V3->ob_refcnt));
359             Py_XDECREF(V3);
360         }
361         //std::cerr << ""cleanup done"" << py_V3 << ""\n"";
362         
363     {Py_XDECREF(py_V3);}
364     
365 double __DUMMY_4;
366 
367 }
368 __label_2:
369 
370     if (!__failure) {
371       
372         //std::cerr << ""sync\n"";
373         if (NULL == V1) {
374             // failure: sync None to storage
375             Py_XDECREF(py_V1);
376             py_V1 = Py_None;
377             Py_INCREF(py_V1);
378         }
379         else
380         {
381             if (py_V1 != (PyObject*)V1)
382             {
383                 Py_XDECREF(py_V1);
384                 py_V1 = (PyObject*)V1;
385                 Py_INCREF(py_V1);
386             }
387             assert(py_V1->ob_refcnt);
388         }
389         
390       PyObject* old = PyList_GET_ITEM(storage_V1, 0);
391       {Py_XINCREF(py_V1);}
392       PyList_SET_ITEM(storage_V1, 0, py_V1);
393       {Py_XDECREF(old);}
394     }
395     
396         //std::cerr << ""cleanup "" << py_V1 << "" "" << V1 << ""\n"";
397         //fprintf(stderr, ""c_cleanup CNDA py_object w refcnt %p %i\n"", py_V1, (py_V1->ob_refcnt));
398         if (V1)
399         {
400             //fprintf(stderr, ""c_cleanup CNDA cn_object w refcnt %p %i\n"", V1, (V1->ob_refcnt));
401             Py_XDECREF(V1);
402         }
403         //std::cerr << ""cleanup done"" << py_V1 << ""\n"";
404         
405     {Py_XDECREF(py_V1);}
406     
407 double __DUMMY_2;
408 
409 }
410 
411             
412         if (__failure) {
413             // When there is a failure, this code puts the exception
414             // in __ERROR.
415             PyObject* err_type = NULL;
416             PyObject* err_msg = NULL;
417             PyObject* err_traceback = NULL;
418             PyErr_Fetch(&err_type, &err_msg, &err_traceback);
419             if (!err_type) {err_type = Py_None;Py_INCREF(Py_None);}
420             if (!err_msg) {err_msg = Py_None; Py_INCREF(Py_None);}
421             if (!err_traceback) {err_traceback = Py_None; Py_INCREF(Py_None);}
422             PyObject* old_err_type = PyList_GET_ITEM(__ERROR, 0);
423             PyObject* old_err_msg = PyList_GET_ITEM(__ERROR, 1);
424             PyObject* old_err_traceback = PyList_GET_ITEM(__ERROR, 2);
425             PyList_SET_ITEM(__ERROR, 0, err_type);
426             PyList_SET_ITEM(__ERROR, 1, err_msg);
427             PyList_SET_ITEM(__ERROR, 2, err_traceback);
428             {Py_XDECREF(old_err_type);}
429             {Py_XDECREF(old_err_msg);}
430             {Py_XDECREF(old_err_traceback);}
431         }
432         // The failure code is returned to index what code block failed.
433         return __failure;
434         
435         }
436     };
437     }
438     
439 
440         static int __struct_compiled_op_97a71e38254d70d6a35005e736217b06_executor(__struct_compiled_op_97a71e38254d70d6a35005e736217b06* self) {
441             return self->run();
442         }
443 
444         static void __struct_compiled_op_97a71e38254d70d6a35005e736217b06_destructor(void* executor, void* self) {
445             delete ((__struct_compiled_op_97a71e38254d70d6a35005e736217b06*)self);
446         }
447         
448 //////////////////////
449 ////  Functions
450 //////////////////////
451 static PyObject * instantiate(PyObject * self, PyObject *argtuple) {
452   assert(PyTuple_Check(argtuple));
453   if (3 != PyTuple_Size(argtuple)){ 
454      PyErr_Format(PyExc_TypeError, ""Wrong number of arguments, expected 3, got %i"", (int)PyTuple_Size(argtuple));
455      return NULL;
456   }
457   __struct_compiled_op_97a71e38254d70d6a35005e736217b06* struct_ptr = new __struct_compiled_op_97a71e38254d70d6a35005e736217b06();
458   if (struct_ptr->init( PyTuple_GET_ITEM(argtuple, 0),PyTuple_GET_ITEM(argtuple, 1),PyTuple_GET_ITEM(argtuple, 2) ) != 0) {
459     delete struct_ptr;
460     return NULL;
461   }
462   PyObject* thunk = PyCObject_FromVoidPtrAndDesc((void*)(&__struct_compiled_op_97a71e38254d70d6a35005e736217b06_executor), struct_ptr, __struct_compiled_op_97a71e38254d70d6a35005e736217b06_destructor);
463   return thunk; }
464 
465 //////////////////////
466 ////  Module init
467 //////////////////////
468 static PyMethodDef MyMethods[] = {
469 	{""instantiate"", instantiate, METH_VARARGS, ""undocumented""} ,
470 	{NULL, NULL, 0, NULL}
471 };
472 PyMODINIT_FUNC init97a71e38254d70d6a35005e736217b06(void){
473    (void) Py_InitModule(""97a71e38254d70d6a35005e736217b06"", MyMethods);
474 }
475 
```
```
===============================
In file included from /opt/anaconda/include/python2.7/Python.h:8:0,
                 from mod.cu:1:
/opt/anaconda/include/python2.7/pyconfig.h:1194:0: warning: ""_POSIX_C_SOURCE"" redefined [enabled by default]
 #define _POSIX_C_SOURCE 200112L
 ^
In file included from /usr/local/cuda-7.0/include/host_config.h:151:0,
                 from /usr/local/cuda-7.0/include/cuda_runtime.h:62,
                 from <command-line>:0:
/usr/include/features.h:168:0: note: this is the location of the previous definition
 # define _POSIX_C_SOURCE 200809L
 ^
In file included from /opt/anaconda/include/python2.7/Python.h:8:0,
                 from mod.cu:1:
/opt/anaconda/include/python2.7/pyconfig.h:1216:0: warning: ""_XOPEN_SOURCE"" redefined [enabled by default]
 #define _XOPEN_SOURCE 600
 ^
In file included from /usr/local/cuda-7.0/include/host_config.h:151:0,
                 from /usr/local/cuda-7.0/include/cuda_runtime.h:62,
                 from <command-line>:0:
/usr/include/features.h:170:0: note: this is the location of the previous definition
 # define _XOPEN_SOURCE 700
 ^
mod.cu(314): error: identifier ""callkernel_node_97a71e38254d70d6a35005e736217b06_0"" is undefined
1 error detected in the compilation of ""/tmp/tmpxft_00001761_00000000-9_mod.cpp1.ii"".
---------------------------------------------------------------------------
Exception                                 Traceback (most recent call last)
<ipython-input-1-9f66711ca133> in <module>()
     23 Y_train = np.ones([100])
     24 
---> 25 model.fit(X_train, Y_train, nb_epoch=5, batch_size=32)

/opt/anaconda/lib/python2.7/site-packages/keras/models.pyc in fit(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)
    670                               class_weight=class_weight,
    671                               sample_weight=sample_weight,
--> 672                               initial_epoch=initial_epoch)
    673 
    674     def evaluate(self, x, y, batch_size=32, verbose=1,

/opt/anaconda/lib/python2.7/site-packages/keras/engine/training.pyc in fit(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch)
   1166         else:
   1167             ins = x + y + sample_weights
-> 1168         self._make_train_function()
   1169         f = self.train_function
   1170 

/opt/anaconda/lib/python2.7/site-packages/keras/engine/training.pyc in _make_train_function(self)
    765                                              [self.total_loss] + self.metrics_tensors,
    766                                              updates=updates,
--> 767                                              **self._function_kwargs)
    768 
    769     def _make_test_function(self):

/opt/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.pyc in function(inputs, outputs, updates, **kwargs)
    967                 msg = 'Invalid argument ""%s"" passed to K.function' % key
    968                 raise ValueError(msg)
--> 969     return Function(inputs, outputs, updates=updates, **kwargs)
    970 
    971 

/opt/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.pyc in __init__(self, inputs, outputs, updates, **kwargs)
    953                                         allow_input_downcast=True,
    954                                         on_unused_input='ignore',
--> 955                                         **kwargs)
    956 
    957     def __call__(self, inputs):

/opt/anaconda/lib/python2.7/site-packages/theano/compile/function.pyc in function(inputs, outputs, mode, updates, givens, no_default_updates, accept_inplace, name, rebuild_strict, allow_input_downcast, profile, on_unused_input)
    318                    on_unused_input=on_unused_input,
    319                    profile=profile,
--> 320                    output_keys=output_keys)
    321     # We need to add the flag check_aliased inputs if we have any mutable or
    322     # borrowed used defined inputs

/opt/anaconda/lib/python2.7/site-packages/theano/compile/pfunc.pyc in pfunc(params, outputs, mode, updates, givens, no_default_updates, accept_inplace, name, rebuild_strict, allow_input_downcast, profile, on_unused_input, output_keys)
    477                          accept_inplace=accept_inplace, name=name,
    478                          profile=profile, on_unused_input=on_unused_input,
--> 479                          output_keys=output_keys)
    480 
    481 

/opt/anaconda/lib/python2.7/site-packages/theano/compile/function_module.pyc in orig_function(inputs, outputs, mode, accept_inplace, name, profile, on_unused_input, output_keys)
   1775                    on_unused_input=on_unused_input,
   1776                    output_keys=output_keys).create(
-> 1777             defaults)
   1778 
   1779     t2 = time.time()

/opt/anaconda/lib/python2.7/site-packages/theano/compile/function_module.pyc in create(self, input_storage, trustme, storage_map)
   1639             theano.config.traceback.limit = 0
   1640             _fn, _i, _o = self.linker.make_thunk(
-> 1641                 input_storage=input_storage_lists, storage_map=storage_map)
   1642         finally:
   1643             theano.config.traceback.limit = limit_orig

/opt/anaconda/lib/python2.7/site-packages/theano/gof/link.pyc in make_thunk(self, input_storage, output_storage, storage_map)
    688         return self.make_all(input_storage=input_storage,
    689                              output_storage=output_storage,
--> 690                              storage_map=storage_map)[:3]
    691 
    692     def make_all(self, input_storage, output_storage):

/opt/anaconda/lib/python2.7/site-packages/theano/gof/vm.pyc in make_all(self, profiler, input_storage, output_storage, storage_map)
   1001                                                  storage_map,
   1002                                                  compute_map,
-> 1003                                                  no_recycling))
   1004                 if not hasattr(thunks[-1], 'lazy'):
   1005                     # We don't want all ops maker to think about lazy Ops.

/opt/anaconda/lib/python2.7/site-packages/theano/sandbox/cuda/__init__.pyc in make_thunk(self, node, storage_map, compute_map, no_recycling)
    254                 enable_cuda=False)
    255         return super(GpuOp, self).make_thunk(node, storage_map,
--> 256                                              compute_map, no_recycling)
    257 
    258 theano.compile.debugmode.default_make_thunk.append(

/opt/anaconda/lib/python2.7/site-packages/theano/gof/op.pyc in make_thunk(self, node, storage_map, compute_map, no_recycling)
    968             try:
    969                 return self.make_c_thunk(node, storage_map, compute_map,
--> 970                                          no_recycling)
    971             except (NotImplementedError, utils.MethodNotDefined):
    972                 logger.debug('Falling back on perform')

/opt/anaconda/lib/python2.7/site-packages/theano/gof/op.pyc in make_c_thunk(self, node, storage_map, compute_map, no_recycling)
    877         logger.debug('Trying CLinker.make_thunk')
    878         outputs = cl.make_thunk(input_storage=node_input_storage,
--> 879                                 output_storage=node_output_storage)
    880         fill_storage, node_input_filters, node_output_filters = outputs
    881 

/opt/anaconda/lib/python2.7/site-packages/theano/gof/cc.pyc in make_thunk(self, input_storage, output_storage, storage_map, keep_lock)
   1198         cthunk, in_storage, out_storage, error_storage = self.__compile__(
   1199             input_storage, output_storage, storage_map,
-> 1200             keep_lock=keep_lock)
   1201 
   1202         res = _CThunk(cthunk, init_tasks, tasks, error_storage)

/opt/anaconda/lib/python2.7/site-packages/theano/gof/cc.pyc in __compile__(self, input_storage, output_storage, storage_map, keep_lock)
   1141                                     output_storage,
   1142                                     storage_map,
-> 1143                                     keep_lock=keep_lock)
   1144         return (thunk,
   1145                 [link.Container(input, storage) for input, storage in

/opt/anaconda/lib/python2.7/site-packages/theano/gof/cc.pyc in cthunk_factory(self, error_storage, in_storage, out_storage, storage_map, keep_lock)
   1593         else:
   1594             module = get_module_cache().module_from_key(
-> 1595                 key=key, lnk=self, keep_lock=keep_lock)
   1596 
   1597         vars = self.inputs + self.outputs + self.orphans

/opt/anaconda/lib/python2.7/site-packages/theano/gof/cmodule.pyc in module_from_key(self, key, lnk, keep_lock)
   1140             try:
   1141                 location = dlimport_workdir(self.dirname)
-> 1142                 module = lnk.compile_cmodule(location)
   1143                 name = module.__file__
   1144                 assert name.startswith(location)

/opt/anaconda/lib/python2.7/site-packages/theano/gof/cc.pyc in compile_cmodule(self, location)
   1504                 lib_dirs=self.lib_dirs(),
   1505                 libs=libs,
-> 1506                 preargs=preargs)
   1507         except Exception as e:
   1508             e.args += (str(self.fgraph),)

/opt/anaconda/lib/python2.7/site-packages/theano/sandbox/cuda/nvcc_compiler.pyc in compile_str(module_name, src_code, location, include_dirs, lib_dirs, libs, preargs, rpaths, py_module, hide_symbols)
    397             print(cmd)
    398             raise Exception('nvcc return status', p.returncode,
--> 399                             'for cmd', ' '.join(cmd))
    400         elif config.cmodule.compilation_warning and nvcc_stdout:
    401             print(nvcc_stdout)

Exception: ('The following error happened while compiling the node', GpuElemwise{RoundHalfToEven,no_inplace}(GpuSoftmaxWithBias.0), '\n', 'nvcc return status', 2, 'for cmd', 'nvcc -shared -O3 --maxrregcount=32 -use_fast_math -arch=sm_52 -m64 -Xcompiler -fno-math-errno,-Wno-unused-label,-Wno-unused-variable,-Wno-write-strings,-DCUDA_NDARRAY_CUH=c72d035fdf91890f3b36710688069b2e,-DNPY_NO_DEPRECATED_API=NPY_1_7_API_VERSION,-fPIC,-fvisibility=hidden -Xlinker -rpath,/home/dlavery/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-centos-7.0.1406-Core-x86_64-2.7.11-64/cuda_ndarray -I/home/dlavery/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-centos-7.0.1406-Core-x86_64-2.7.11-64/cuda_ndarray -I/usr/local/cuda-7.0/include -I/opt/anaconda/lib/python2.7/site-packages/numpy/core/include -I/opt/anaconda/include/python2.7 -I/opt/anaconda/lib/python2.7/site-packages/theano/gof -I/opt/anaconda/lib/python2.7/site-packages/theano/sandbox/cuda -o /home/dlavery/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-centos-7.0.1406-Core-x86_64-2.7.11-64/tmpRVfVZt/97a71e38254d70d6a35005e736217b06.so mod.cu -L/home/dlavery/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-centos-7.0.1406-Core-x86_64-2.7.11-64/cuda_ndarray -L/opt/anaconda/lib -lcudart -lcublas -lcuda_ndarray -lpython2.7', '[GpuElemwise{RoundHalfToEven,no_inplace}(<CudaNdarrayType(float32, matrix)>)]')
```
</details>
",dplaniel,b'stale',2017-02-17T17:20:15Z,2017-08-28T15:16:40Z
5422,Cleanup training.py generator fncs. Cleanup & fix bugs in test_multiprocessing.py,"Code in `keras.engine.training.py` was just cleaned up a bit. Then i noticed `tests/test_multiprocessing.py` was buggy. Fixed an np.random.randint() bug https://github.com/fchollet/keras/compare/master...wayaai:cleanup-fit-generator?expand=1#diff-ed7c4d0cc3c2c1334a8e80ec07781927L190 for the fncs, then fixed this bug https://github.com/fchollet/keras/compare/master...wayaai:cleanup-fit-generator?expand=1#diff-ed7c4d0cc3c2c1334a8e80ec07781927L271 where it seems they thought they were passing in `nb_epoch` but really `predict_generator` and `evaluate_generator` dont have this option so it was setting `max_q_size=1` and causing tests to fail",mjdietzx,None,2017-02-17T04:51:21Z,2017-02-20T19:19:21Z
5406,flow_from_directory produces batches of varying size,"I'm using the builtin image preprocessing to produce a stream of batches.
In the directory, there is one subfolder (=class) with a total of 8 pictures.

If I specify a `batch_size` >= 8, every batch has the same size.
But if the `batch_size` is <8, then the batch_sizes will be:
 - `batch_size`
 - `8%batch_size`
 - `batch_size`
 - `8%batch_size`
 - ...

so for example: 6, 2, 6, 2, 6

This seems like a bug to me.
It might make sense, if Keras is internally keeping track of the images it has already visited.
But even then, this behaviour should be documented.",lhk,b'stale',2017-02-15T15:52:02Z,2017-09-23T14:39:26Z
5403,help to understand nvcc error for GPU on Theano,"newbie to GPUs so bare with me!

importing keras modules, everything looks good:
```
Using Theano backend.
Using gpu device 0: Tesla M60 (CNMeM is disabled, cuDNN not available)
```
however when I call `.fit `I get the following (very long) error which I struggle to understand (there is an exception towards the end). nvcc version 8

['nvcc', '-shared', '-O3', '-arch=sm_52', '--compiler-bindir', 'C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\bin', '-Xlinker', '/DEBUG', '-D HAVE_ROUND', '-m64', '-Xcompiler', '-DCUDA_NDARRAY_CUH=c72d035fdf91890f3b36710688069b2e,-DNPY_NO_DEPRECATED_API=NPY_1_7_API_VERSION,/Zi,/MD', '-IC:\\Users\\...\\AppData\\Local\\Theano\\compiledir_Windows-10-10.0.14393-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-2.7.13-64\\cuda_ndarray', '-IC:\\ProgramData\\Anaconda2\\lib\\site-packages\\numpy\\core\\include', '-IC:\\ProgramData\\Anaconda2\\include', '-IC:\\ProgramData\\Anaconda2\\lib\\site-packages\\theano\\gof', '-IC:\\ProgramData\\Anaconda2\\lib\\site-packages\\theano\\sandbox\\cuda', '-o', 'C:\\Users\\...\\AppData\\Local\\Theano\\compiledir_Windows-10-10.0.14393-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-2.7.13-64\\tmp9gptot\\fc0a77fd0d7a0a0c610947f403047873.pyd', 'mod.cu', '-LC:\\Users\\...\\AppData\\Local\\Theano\\compiledir_Windows-10-10.0.14393-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-2.7.13-64\\cuda_ndarray', '-LC:\\ProgramData\\Anaconda2\\libs', '-LC:\\ProgramData\\Anaconda2', '-lcudart', '-lcublas', '-lcuda_ndarray', '-lpython27']
1 #include <Python.h>
2 #include <iostream>
3 #include ""theano_mod_helper.h""
4 #include ""cuda_ndarray.cuh""
5 //////////////////////
6 ////  Support Code
7 //////////////////////
8 
9 
10     namespace {
11     struct __struct_compiled_op_fc0a77fd0d7a0a0c610947f403047873 {
12         PyObject* __ERROR;
13 
14         PyObject* storage_V3;
15 PyObject* storage_V1;
16         
17 
18         __struct_compiled_op_fc0a77fd0d7a0a0c610947f403047873() {
19             // This is only somewhat safe because we:
20             //  1) Are not a virtual class
21             //  2) Do not use any virtual classes in the members
22             //  3) Deal with mostly POD and pointers
23 
24             // If this changes, we would have to revise this, but for
25             // now I am tired of chasing segfaults because
26             // initialization code had an error and some pointer has
27             // a junk value.
28             memset(this, 0, sizeof(*this));
29         }
30         ~__struct_compiled_op_fc0a77fd0d7a0a0c610947f403047873(void) {
31             cleanup();
32         }
33 
34         int init(PyObject* __ERROR, PyObject* storage_V3, PyObject* storage_V1) {
35             Py_XINCREF(storage_V3);
36 Py_XINCREF(storage_V1);
37             this->storage_V3 = storage_V3;
38 this->storage_V1 = storage_V1;
39             
40 
41 
42 
43             this->__ERROR = __ERROR;
44             return 0;
45         }
46         void cleanup(void) {
47             __label_1:
48 
49 double __DUMMY_1;
50 __label_3:
51 
52 double __DUMMY_3;
53 __label_6:
54 
55 double __DUMMY_6;
56 
57             Py_XDECREF(this->storage_V3);
58 Py_XDECREF(this->storage_V1);
59         }
60         int run(void) {
61             int __failure = 0;
62             
63     PyObject* py_V1;
64      CudaNdarray * V1;
65     PyObject* py_V3;
66      CudaNdarray * V3;
67 {
68 
69     py_V1 = Py_None;
70     {Py_XINCREF(py_V1);}
71     V1 = NULL;
72 {
73 
74     py_V3 = PyList_GET_ITEM(storage_V3, 0);
75     {Py_XINCREF(py_V3);}
76     
77         assert(py_V3->ob_refcnt >= 2); // There should be at least one ref from the container object,
78         // and one ref from the local scope.
79 
80         if (CudaNdarray_Check(py_V3))
81         {
82             //fprintf(stderr, ""c_extract CNDA object w refcnt %p %i\n"", py_V3, (py_V3->ob_refcnt));
83             V3 = (CudaNdarray*)py_V3;
84             //std::cerr << ""c_extract "" << V3 << '\n';
85         
86 
87                 if (V3->nd != 1)
88                 {
89                     PyErr_Format(PyExc_RuntimeError,
90                                  ""c_extract: Some CudaNdarray has rank %i, it was supposed to have rank 1"",
91                                  V3->nd);
92                     V3 = NULL;
93                     {
94         __failure = 4;
95         if (!PyErr_Occurred()) {
96             PyErr_SetString(PyExc_RuntimeError,
97                 ""Unexpected error in an Op's C code. ""
98                 ""No Python exception was set."");
99             }
100         goto __label_4;};
101                 }
102                 //std::cerr << ""c_extract "" << V3 << "" nd check passed\n"";
103             
104 
105                 assert(V3);
106                 Py_INCREF(py_V3);
107             }
108             else if (py_V3 == Py_None)
109             {
110                 PyErr_SetString(PyExc_TypeError,
111                                 ""expected a CudaNdarray, not None"");
112                 V3 = NULL;
113                 {
114         __failure = 4;
115         if (!PyErr_Occurred()) {
116             PyErr_SetString(PyExc_RuntimeError,
117                 ""Unexpected error in an Op's C code. ""
118                 ""No Python exception was set."");
119             }
120         goto __label_4;};
121             }
122             else
123             {
124                 //fprintf(stderr, ""FAILING c_extract CNDA object w refcnt %p %i\n"", py_V3, (py_V3->ob_refcnt));
125                 PyErr_SetString(PyExc_TypeError, ""Argument not a CudaNdarray"");
126                 V3 = NULL;
127                 {
128         __failure = 4;
129         if (!PyErr_Occurred()) {
130             PyErr_SetString(PyExc_RuntimeError,
131                 ""Unexpected error in an Op's C code. ""
132                 ""No Python exception was set."");
133             }
134         goto __label_4;};
135             }
136             //std::cerr << ""c_extract done "" << V3 << '\n';
137             
138 
139 {
140 // Op class GpuDimShuffle
141 
142         if (V3->nd != 1)
143         {
144             PyErr_Format(PyExc_TypeError,
145                          ""required nd=1, got nd=%i"", V3->nd);
146             {
147         __failure = 5;
148         if (!PyErr_Occurred()) {
149             PyErr_SetString(PyExc_RuntimeError,
150                 ""Unexpected error in an Op's C code. ""
151                 ""No Python exception was set."");
152             }
153         goto __label_5;};
154         }
155         
156 
157         if (V1 && (V1->nd == 2))
158         {
159             //re-use previously-allocated cnda
160         }
161         else
162         {
163             if (V1)
164             {
165                 if (CudaNdarray_set_nd(V1, 2))
166                 {
167                     Py_DECREF(V1);
168                     V1 = NULL;
169                     {
170         __failure = 5;
171         if (!PyErr_Occurred()) {
172             PyErr_SetString(PyExc_RuntimeError,
173                 ""Unexpected error in an Op's C code. ""
174                 ""No Python exception was set."");
175             }
176         goto __label_5;};
177                 }
178             }
179             else
180             {
181                 V1 = (CudaNdarray*) CudaNdarray_New(2);
182                 if (NULL == V1)
183                 {
184                     {
185         __failure = 5;
186         if (!PyErr_Occurred()) {
187             PyErr_SetString(PyExc_RuntimeError,
188                 ""Unexpected error in an Op's C code. ""
189                 ""No Python exception was set."");
190             }
191         goto __label_5;};
192                 }
193             }
194         }
195         
196 
197         if (CudaNdarray_set_device_data(V1,
198                                         CudaNdarray_DEV_DATA(V3),
199                                         V3))
200         {
201             // err message set
202             Py_DECREF(V1);
203             V1 = NULL;
204             {
205         __failure = 5;
206         if (!PyErr_Occurred()) {
207             PyErr_SetString(PyExc_RuntimeError,
208                 ""Unexpected error in an Op's C code. ""
209                 ""No Python exception was set."");
210             }
211         goto __label_5;};
212         }
213         
214 
215         CudaNdarray_set_dim(V1, 0, 1);
216         CudaNdarray_set_stride(V1, 0, 0);
217                 
218 
219         CudaNdarray_set_dim(V1, 1,
220                             CudaNdarray_HOST_DIMS(V3)[0]);
221         CudaNdarray_set_stride(V1, 1,
222                                CudaNdarray_HOST_STRIDES(V3)[0]);
223                 
224 
225     //std::cerr << ""GpuDimShuffle "" << V1 << "" str[0] = "" << V1->str[0] << ""\n"";
226             
227 
228     //std::cerr << ""GpuDimShuffle "" << V1 << "" str[1] = "" << V1->str[1] << ""\n"";
229             
230 __label_5:
231 
232 double __DUMMY_5;
233 
234 }
235 __label_4:
236 
237         //std::cerr << ""cleanup "" << py_V3 << "" "" << V3 << ""\n"";
238         //fprintf(stderr, ""c_cleanup CNDA py_object w refcnt %p %i\n"", py_V3, (py_V3->ob_refcnt));
239         if (V3)
240         {
241             //fprintf(stderr, ""c_cleanup CNDA cn_object w refcnt %p %i\n"", V3, (V3->ob_refcnt));
242             Py_XDECREF(V3);
243         }
244         //std::cerr << ""cleanup done"" << py_V3 << ""\n"";
245         
246     {Py_XDECREF(py_V3);}
247     
248 double __DUMMY_4;
249 
250 }
251 __label_2:
252 
253     if (!__failure) {
254       
255         //std::cerr << ""sync\n"";
256         if (NULL == V1) {
257             // failure: sync None to storage
258             Py_XDECREF(py_V1);
259             py_V1 = Py_None;
260             Py_INCREF(py_V1);
261         }
262         else
263         {
264             if (py_V1 != (PyObject*)V1)
265             {
266                 Py_XDECREF(py_V1);
267                 py_V1 = (PyObject*)V1;
268                 Py_INCREF(py_V1);
269             }
270             assert(py_V1->ob_refcnt);
271         }
272         
273       PyObject* old = PyList_GET_ITEM(storage_V1, 0);
274       {Py_XINCREF(py_V1);}
275       PyList_SET_ITEM(storage_V1, 0, py_V1);
276       {Py_XDECREF(old);}
277     }
278     
279         //std::cerr << ""cleanup "" << py_V1 << "" "" << V1 << ""\n"";
280         //fprintf(stderr, ""c_cleanup CNDA py_object w refcnt %p %i\n"", py_V1, (py_V1->ob_refcnt));
281         if (V1)
282         {
283             //fprintf(stderr, ""c_cleanup CNDA cn_object w refcnt %p %i\n"", V1, (V1->ob_refcnt));
284             Py_XDECREF(V1);
285         }
286         //std::cerr << ""cleanup done"" << py_V1 << ""\n"";
287         
288     {Py_XDECREF(py_V1);}
289     
290 double __DUMMY_2;
291 
292 }
293 
294             
295         if (__failure) {
296             // When there is a failure, this code puts the exception
297             // in __ERROR.
298             PyObject* err_type = NULL;
299             PyObject* err_msg = NULL;
300             PyObject* err_traceback = NULL;
301             PyErr_Fetch(&err_type, &err_msg, &err_traceback);
302             if (!err_type) {err_type = Py_None;Py_INCREF(Py_None);}
303             if (!err_msg) {err_msg = Py_None; Py_INCREF(Py_None);}
304             if (!err_traceback) {err_traceback = Py_None; Py_INCREF(Py_None);}
305             PyObject* old_err_type = PyList_GET_ITEM(__ERROR, 0);
306             PyObject* old_err_msg = PyList_GET_ITEM(__ERROR, 1);
307             PyObject* old_err_traceback = PyList_GET_ITEM(__ERROR, 2);
308             PyList_SET_ITEM(__ERROR, 0, err_type);
309             PyList_SET_ITEM(__ERROR, 1, err_msg);
310             PyList_SET_ITEM(__ERROR, 2, err_traceback);
311             {Py_XDECREF(old_err_type);}
312             {Py_XDECREF(old_err_msg);}
313             {Py_XDECREF(old_err_traceback);}
314         }
315         // The failure code is returned to index what code block failed.
316         return __failure;
317         
318         }
319     };
320     }
321     
322 
323         static int __struct_compiled_op_fc0a77fd0d7a0a0c610947f403047873_executor(__struct_compiled_op_fc0a77fd0d7a0a0c610947f403047873* self) {
324             return self->run();
325         }
326 
327         static void __struct_compiled_op_fc0a77fd0d7a0a0c610947f403047873_destructor(void* executor, void* self) {
328             delete ((__struct_compiled_op_fc0a77fd0d7a0a0c610947f403047873*)self);
329         }
330         
331 //////////////////////
332 ////  Functions
333 //////////////////////
334 static PyObject * instantiate(PyObject * self, PyObject *argtuple) {
335   assert(PyTuple_Check(argtuple));
336   if (3 != PyTuple_Size(argtuple)){ 
337      PyErr_Format(PyExc_TypeError, ""Wrong number of arguments, expected 3, got %i"", (int)PyTuple_Size(argtuple));
338      return NULL;
339   }
340   __struct_compiled_op_fc0a77fd0d7a0a0c610947f403047873* struct_ptr = new __struct_compiled_op_fc0a77fd0d7a0a0c610947f403047873();
341   if (struct_ptr->init( PyTuple_GET_ITEM(argtuple, 0),PyTuple_GET_ITEM(argtuple, 1),PyTuple_GET_ITEM(argtuple, 2) ) != 0) {
342     delete struct_ptr;
343     return NULL;
344   }
345   PyObject* thunk = PyCObject_FromVoidPtrAndDesc((void*)(&__struct_compiled_op_fc0a77fd0d7a0a0c610947f403047873_executor), struct_ptr, __struct_compiled_op_fc0a77fd0d7a0a0c610947f403047873_destructor);
346   return thunk; }
347 
348 //////////////////////
349 ////  Module init
350 //////////////////////
351 static PyMethodDef MyMethods[] = {
352     {""instantiate"", instantiate, METH_VARARGS, ""undocumented""} ,
353     {NULL, NULL, 0, NULL}
354 };
355 PyMODINIT_FUNC initfc0a77fd0d7a0a0c610947f403047873(void){
356    (void) Py_InitModule(""fc0a77fd0d7a0a0c610947f403047873"", MyMethods);
357 }
358 
===============================
Traceback (most recent call last):

  File ""<ipython-input-1-f1a208d8a305>"", line 19, in <module>
    model.fit(data, labels, nb_epoch=10, batch_size=32)

  File ""C:\ProgramData\Anaconda2\lib\site-packages\keras\models.py"", line 672, in fit
    initial_epoch=initial_epoch)

  File ""C:\ProgramData\Anaconda2\lib\site-packages\keras\engine\training.py"", line 1168, in fit
    self._make_train_function()

  File ""C:\ProgramData\Anaconda2\lib\site-packages\keras\engine\training.py"", line 767, in _make_train_function
    **self._function_kwargs)

  File ""C:\ProgramData\Anaconda2\lib\site-packages\keras\backend\theano_backend.py"", line 969, in function
    return Function(inputs, outputs, updates=updates, **kwargs)

  File ""C:\ProgramData\Anaconda2\lib\site-packages\keras\backend\theano_backend.py"", line 955, in __init__
    **kwargs)

  File ""C:\ProgramData\Anaconda2\lib\site-packages\theano\compile\function.py"", line 320, in function
    output_keys=output_keys)

  File ""C:\ProgramData\Anaconda2\lib\site-packages\theano\compile\pfunc.py"", line 479, in pfunc
    output_keys=output_keys)

  File ""C:\ProgramData\Anaconda2\lib\site-packages\theano\compile\function_module.py"", line 1777, in orig_function
    defaults)

  File ""C:\ProgramData\Anaconda2\lib\site-packages\theano\compile\function_module.py"", line 1641, in create
    input_storage=input_storage_lists, storage_map=storage_map)

  File ""C:\ProgramData\Anaconda2\lib\site-packages\theano\gof\link.py"", line 690, in make_thunk
    storage_map=storage_map)[:3]

  File ""C:\ProgramData\Anaconda2\lib\site-packages\theano\gof\vm.py"", line 1003, in make_all
    no_recycling))

  File ""C:\ProgramData\Anaconda2\lib\site-packages\theano\sandbox\cuda\__init__.py"", line 256, in make_thunk
    compute_map, no_recycling)

  File ""C:\ProgramData\Anaconda2\lib\site-packages\theano\gof\op.py"", line 970, in make_thunk
    no_recycling)

  File ""C:\ProgramData\Anaconda2\lib\site-packages\theano\gof\op.py"", line 879, in make_c_thunk
    output_storage=node_output_storage)

  File ""C:\ProgramData\Anaconda2\lib\site-packages\theano\gof\cc.py"", line 1200, in make_thunk
    keep_lock=keep_lock)

  File ""C:\ProgramData\Anaconda2\lib\site-packages\theano\gof\cc.py"", line 1143, in __compile__
    keep_lock=keep_lock)

  File ""C:\ProgramData\Anaconda2\lib\site-packages\theano\gof\cc.py"", line 1595, in cthunk_factory
    key=key, lnk=self, keep_lock=keep_lock)

  File ""C:\ProgramData\Anaconda2\lib\site-packages\theano\gof\cmodule.py"", line 1142, in module_from_key
    module = lnk.compile_cmodule(location)

  File ""C:\ProgramData\Anaconda2\lib\site-packages\theano\gof\cc.py"", line 1506, in compile_cmodule
    preargs=preargs)

  File ""C:\ProgramData\Anaconda2\lib\site-packages\theano\sandbox\cuda\nvcc_compiler.py"", line 399, in compile_str
    'for cmd', ' '.join(cmd))

Exception: ('The following error happened while compiling the node', GpuDimShuffle{x,0}(dense_1_b), '\n', 'nvcc return status', 2, 'for cmd', 'nvcc -shared -O3 -arch=sm_52 --compiler-bindir C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\bin -Xlinker /DEBUG -D HAVE_ROUND -m64 -Xcompiler -DCUDA_NDARRAY_CUH=c72d035fdf91890f3b36710688069b2e,-DNPY_NO_DEPRECATED_API=NPY_1_7_API_VERSION,/Zi,/MD -IC:\\Users\\...\\AppData\\Local\\Theano\\compiledir_Windows-10-10.0.14393-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-2.7.13-64\\cuda_ndarray -IC:\\ProgramData\\Anaconda2\\lib\\site-packages\\numpy\\core\\include -IC:\\ProgramData\\Anaconda2\\include -IC:\\ProgramData\\Anaconda2\\lib\\site-packages\\theano\\gof -IC:\\ProgramData\\Anaconda2\\lib\\site-packages\\theano\\sandbox\\cuda -o C:\\Users\\...\\AppData\\Local\\Theano\\compiledir_Windows-10-10.0.14393-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-2.7.13-64\\tmp9gptot\\fc0a77fd0d7a0a0c610947f403047873.pyd mod.cu -LC:\\Users\\...\\AppData\\Local\\Theano\\compiledir_Windows-10-10.0.14393-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-2.7.13-64\\cuda_ndarray -LC:\\ProgramData\\Anaconda2\\libs -LC:\\ProgramData\\Anaconda2 -lcudart -lcublas -lcuda_ndarray -lpython27', '[GpuDimShuffle{x,0}(dense_1_b)]')",lorenzori,None,2017-02-15T09:34:53Z,2017-02-15T16:10:00Z
5395,Graph Model executes ops on CPU when asked to execute on GPU,"Hi,

I've been following this [Keras tutorial](https://blog.keras.io/keras-as-a-simplified-interface-to-tensorflow-tutorial.html) for training a model on a Multi-GPU setting. This works fine and the ops are executed on the GPU as long as the models are defined using a **sequential** container. But when I define the same model using **graphical** operations as shown here in this [Gist](https://gist.github.com/kvrd18/d14f9a28c8d73a31300540b1b5d8e8c8), _the ops are being executed on the CPU._

To run the Gist and reproduce the bug, download the script and execute `python kerasSetGPU.py` on the terminal.

When I ran some benchmarks for a fully convolutional network with an input batch size of `4x512x512x1` with around 12 convolutional layers, I found that the sequential model took around **0.7s** per batch on a TITANx card and the graphical model took around **2.2s** per batch.

What's going wrong here? Why are the ops defined by the graphical model being executed on the CPU even if I call it under `with tf.device('/gpu:0'):`?",kiranvaidhya,b'stale',2017-02-14T12:12:08Z,2017-06-22T20:12:36Z
5386,NameError:  the name CVM is not defined,"Please make sure that the boxes below are checked before you submit your issue. If your issue is an implementation question, please ask your question on [StackOverflow](http://stackoverflow.com/questions/tagged/keras) or [join the Keras Slack channel](https://keras-slack-autojoin.herokuapp.com/) and ask there instead of filing a GitHub issue.

Thank you!

- [x] Check that you are up-to-date with the master branch of Keras. You can update with:
pip install git+git://github.com/fchollet/keras.git --upgrade --no-deps

- [ ] If running on TensorFlow, check that you are up-to-date with the latest version. The installation instructions can be found [here](https://www.tensorflow.org/get_started/os_setup).

- [x] If running on Theano, check that you are up-to-date with the master branch of Theano. You can update with:
pip install git+git://github.com/Theano/Theano.git --upgrade --no-deps

- [x] Provide a link to a GitHub Gist of a Python script that can reproduce your issue (or just copy the script here if it is short).

I'm getting a NameError:  the name CVM is not defined on a program that ran last week.  The only thing I think I've done since then was to install quandl through Anaconda Navigator.  I removed quandl, but I'm still getting the error.

I understand this is more likely something I screwed up, rather than a ""bug"", but I'd appreciate any help you can give me to get things back up and running.

Here is the full exception report:

> runfile('E:/Python Files/Accuracy Error Demo.py', wdir='E:/Python Files')
> Traceback (most recent call last):
> 
>   File ""<ipython-input-6-cb7fda660588>"", line 1, in <module>
>     runfile('E:/Python Files/Accuracy Error Demo.py', wdir='E:/Python Files')
> 
>   File ""C:\Anaconda3\lib\site-packages\spyder\utils\site\sitecustomize.py"", line 866, in runfile
>     execfile(filename, namespace)
> 
>   File ""C:\Anaconda3\lib\site-packages\spyder\utils\site\sitecustomize.py"", line 102, in execfile
>     exec(compile(f.read(), filename, 'exec'), namespace)
> 
>   File ""E:/Python Files/Accuracy Error Demo.py"", line 45, in <module>
>     model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=100)
> 
>   File ""C:\Anaconda3\lib\site-packages\keras\models.py"", line 672, in fit
>     initial_epoch=initial_epoch)
> 
>   File ""C:\Anaconda3\lib\site-packages\keras\engine\training.py"", line 1168, in fit
>     self._make_train_function()
> 
>   File ""C:\Anaconda3\lib\site-packages\keras\engine\training.py"", line 767, in _make_train_function
>     **self._function_kwargs)
> 
>   File ""C:\Anaconda3\lib\site-packages\keras\backend\theano_backend.py"", line 969, in function
>     return Function(inputs, outputs, updates=updates, **kwargs)
> 
>   File ""C:\Anaconda3\lib\site-packages\keras\backend\theano_backend.py"", line 955, in __init__
>     **kwargs)
> 
>   File ""C:\Anaconda3\lib\site-packages\theano\compile\function.py"", line 326, in function
>     output_keys=output_keys)
> 
>   File ""C:\Anaconda3\lib\site-packages\theano\compile\pfunc.py"", line 486, in pfunc
>     output_keys=output_keys)
> 
>   File ""C:\Anaconda3\lib\site-packages\theano\compile\function_module.py"", line 1795, in orig_function
>     defaults)
> 
>   File ""C:\Anaconda3\lib\site-packages\theano\compile\function_module.py"", line 1661, in create
>     input_storage=input_storage_lists, storage_map=storage_map)
> 
>   File ""C:\Anaconda3\lib\site-packages\theano\gof\link.py"", line 699, in make_thunk
>     storage_map=storage_map)[:3]
> 
>   File ""C:\Anaconda3\lib\site-packages\theano\gof\vm.py"", line 1063, in make_all
>     impl=impl))
> 
>   File ""C:\Anaconda3\lib\site-packages\theano\scan_module\scan_op.py"", line 892, in make_thunk
>     on_unused_input='ignore')
> 
>   File ""C:\Anaconda3\lib\site-packages\theano\compile\function.py"", line 326, in function
>     output_keys=output_keys)
> 
>   File ""C:\Anaconda3\lib\site-packages\theano\compile\pfunc.py"", line 486, in pfunc
>     output_keys=output_keys)
> 
>   File ""C:\Anaconda3\lib\site-packages\theano\compile\function_module.py"", line 1795, in orig_function
>     defaults)
> 
>   File ""C:\Anaconda3\lib\site-packages\theano\compile\function_module.py"", line 1661, in create
>     input_storage=input_storage_lists, storage_map=storage_map)
> 
>   File ""C:\Anaconda3\lib\site-packages\theano\gof\link.py"", line 699, in make_thunk
>     storage_map=storage_map)[:3]
> 
>   File ""C:\Anaconda3\lib\site-packages\theano\gof\vm.py"", line 1114, in make_all
>     self.updated_vars,
> 
>   File ""C:\Anaconda3\lib\site-packages\theano\gof\vm.py"", line 968, in make_vm
>     vm = CVM(
> 
> NameError: ('The following error happened while compiling the node', forall_inplace,cpu,scan_fn}(TensorConstant{2}, InplaceDimShuffle{1,0,2}.0, IncSubtensor{InplaceSet;:int64:}.0, DeepCopyOp.0, TensorConstant{1}, lstm_6_U_o, lstm_6_U_f, lstm_6_U_i, lstm_6_U_c), '\n', ""name 'CVM' is not defined"")

And here is a sample program which generates the error (from my first bug report):

```
import numpy as np
from numpy.random import choice
from keras.layers import Dense
from keras.layers import LSTM
from keras.models import Sequential

batch_size = 2 
N_train = 100
N_test = 10

# CREATE SOME RANDOM DATA
X_train = np.ones((N_train, 2))
X_test = np.ones((N_test, 2))
y_train = np.ones((N_train, 1))
y_test = np.ones((N_test, 1))
one_indexes = choice(a=N_train, size=int(N_train / 2), replace=False)
X_train[one_indexes, 0] = -1
y_train[one_indexes] = -1
one_indexes = choice(a=N_test, size=int(N_test / 2), replace=False)
X_test[one_indexes, 0] = -1
y_test[one_indexes] = -1

# NORM THE DATA IN THE RANGE OF  -0.25 to 0.25      
### THIS IS WHAT CAUSES THE PROBLEM ###      
X_train *= 0.25
y_train *= 0.25
X_test *= 0.25
y_test *= 0.25      

X_train = np.expand_dims(X_train, axis=2)
X_test = np.expand_dims(X_test, axis=2)

# CREATE THE MODEL
model = Sequential()
model.add(LSTM(8, input_shape=(2, 1), return_sequences=False))
model.add(Dense(1, activation='tanh'))

model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['accuracy'])

model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=100)

# EVALUATE THE MODEL ON THE TEST DATA
score, acc = model.evaluate(X_test, y_test, batch_size=batch_size, verbose=0)
print()
print('Evaluate accuracy:', acc)
print()

# PREDICT THE MODEL ON THE TEST DATA
yFit = model.predict(X_test, batch_size=batch_size)

error = 0    
print('Prediction/Actual')
for c in range(X_test.shape[0]):
    error += yFit[c, 0] - y_test[c, 0]
    print(str(yFit[c]) + '  ' + str(y_test[c]))

error = abs(error)
print()
print('Predict error: ', error)
print('Predict accuracy: ', (1 - error))
```

",Panache1,None,2017-02-13T17:02:40Z,2017-02-13T18:34:02Z
5371,"Missed ""classes_"" and ""n_classes_"" attributes in KerasClassifier","Some of ensembling models in sklearn expect attributes ""classes_"" and ""n_classes_"" in used classifiers. But KerasClassifier don't have these attributes, so ensembles raise errors.
For example, when I've tried to use BaggingCassifier from sklearn with KerasClassifier I received an error:
```
Traceback (most recent call last):
  File ""keras_sklearn_bug.py"", line 19, in <module>
    print(ensemble.predict(X))
  File ""virtualenvs/kaggle/lib/python3.6/site-packages/sklearn/ensemble/bagging.py"", line 641, in predict
    predicted_probabilitiy = self.predict_proba(X)
  File ""virtualenvs/kaggle/lib/python3.6/site-packages/sklearn/ensemble/bagging.py"", line 687, in predict_proba
    for i in range(n_jobs))
  File ""virtualenvs/kaggle/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py"", line 758, in __call__
    while self.dispatch_one_batch(iterator):
  File ""virtualenvs/kaggle/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py"", line 608, in dispatch_one_batch
    self._dispatch(tasks)
  File ""virtualenvs/kaggle/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py"", line 571, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File ""virtualenvs/kaggle/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py"", line 109, in apply_async
    result = ImmediateResult(func)
  File ""virtualenvs/kaggle/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py"", line 326, in __init__
    self.results = batch()
  File ""virtualenvs/kaggle/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py"", line 131, in __call__
    return [func(*args, **kwargs) for func, args, kwargs in self.items]
  File ""virtualenvs/kaggle/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py"", line 131, in <listcomp>
    return [func(*args, **kwargs) for func, args, kwargs in self.items]
  File ""virtualenvs/kaggle/lib/python3.6/site-packages/sklearn/ensemble/bagging.py"", line 134, in _parallel_predict_proba
    if n_classes == len(estimator.classes_):
AttributeError: 'KerasClassifier' object has no attribute 'classes_'
```

There is way to reproduce:
https://gist.github.com/diswest/8a92d317192726694d3fdd8373201211",diswest,None,2017-02-12T18:43:10Z,2017-04-10T23:21:42Z
5358,Keras 2 requests for contribution,"There is an early draft branch available for Keras 2: https://github.com/fchollet/keras/tree/keras-2
Note that the codebase will keep evolving *a lot*. Support for backwards compatibility with Keras 1 will only be added once the new codebase is finalized.

In this thread I will be posting very specific requests for contribution.

## [DONE] Fix Theano Conv2DTranspose layer

~~The `Deconvolution` layer has become `Conv2DTranspose`, with a simplified API that does not require users to specify an output shape (that was a big issue with the previous API). The new implementation works fine with TensorFlow, but appears to be broken with Theano (most likely the backend function `conv2d_tranpose`). I haven't had time to look into it, feel free to check it out and fix it.~~

## [MOSTLY DONE] Unit tests

~~The API is changing and the previous unit tests all need to be ported to the new API. I haven't started to look into this. Feel free to pick any unit test file and update it.~~

## Update examples to the new API

Likewise.

----

If you have feedback, bugs to report, or if you're opening PRs against the keras-2 branch, post in this thread.",fchollet,b'stat:contributions welcome',2017-02-11T01:47:53Z,2018-10-07T18:26:50Z
5352,Container._output_tensor_cache can cause subtle bugs in conjunction with tensorflow context managers,"Since [295bfe4e3ae7e98655b3630a9f83b2df4a82234f](https://github.com/fchollet/keras/commit/295bfe4e3ae7e98655b3630a9f83b2df4a82234f), output tensors in the `Container` class (from which `Model` inherits) are [cached to prevent rebuilding the graph](https://github.com/fchollet/keras/blame/master/keras/engine/topology.py#L1776). However, this cache does not respect the tensorflow context managers under which the `Container` object is being called. A minimal working example follows:

```python
import tensorflow as tf
import keras

x = keras.layers.Input(shape=[1, 1, 1])
y = keras.layers.Conv2D(1, 1, 1)(x)

foo = keras.models.Model(input=x, output=y)

with tf.device('/cpu'):
    a = tf.placeholder(tf.float32)

with tf.device('/cpu'):
    b_cpu = foo(a)

with tf.device('/gpu:0'):
    b_gpu = foo(a)

print(a.device)
print(b_cpu.device)
print(b_gpu.device)
```
prints the following:
```
/device:CPU:*
/device:CPU:*
/device:CPU:*
```
What's happening is [this line](https://github.com/fchollet/keras/blame/master/keras/engine/topology.py#L2245) reading from the cache instead of running the internal graph anew. Indeed, when we add the following line:

```python
# ...

with tf.device('/cpu'):
    b_cpu = foo(a)
    foo._output_tensor_cache = {}

# ...
```
the result is as expected:
```
/device:CPU:*
/device:CPU:*
/device:GPU:0
```

The present behaviour may stall e.g. multi-gpu training/inference, when there is e.g. one dequeue op `a` on which the model `foo` operates multiple times under different device context managers. Possible solutions include: 
- get rid of the cache. 
- give users the option of deactivating the cache (e.g. a `disable_cache=True` keyword arg).",nasimrahaman,b'stale',2017-02-10T12:32:34Z,2017-06-22T20:11:58Z
5345,How to remove stale models from GPU memory,"**Update (2018/08/01):** I would like to provide an update as when I posted the question I was new to Keras. Currently only TensorFlow backend supports proper cleaning up of the session. This can be done by calling `K.clear_session()`. This will remove EVERYTHING from memory (models, optimizer objects and anything that has tensors internally). So there is no way to remove a specific stale model. This is not a bug of Keras but a limitation of the backends.

--------

I am working on a pipeline that takes a pre-trained model, splits it, caches the intermediate results of the bottom layers, fine-tunes the top and merges bottom & top back. I do 2 passes of the above using different splits & optimizers. This helps me speed up the training by a factor of 3x instead of freezing the bottom layers.

As you understand the above process initializes many models which are later discarded. Unfortunately though it seems that their weights remain in GPU memory and after a couple of steps I get an out of memory exception ""ResourceExhaustedError (see above for traceback): OOM when allocating tensor"".

Is there a way to remove stale models from GPU memory? I tried ""del"" and calling Python's gc but did not work. Closing/clearing the session is not possible as this is part of a single pipeline. My backend is Tensorflow.

Here is a simplified pseudo-code of the process:
```python
model = load_pretrained_model()
bottom, top = split_model(model) #bottom and top have a fresh copy of the weights
del model
gc.collect()

intermediate_results = bottom.predit(data)
top.fit(intermediate_results)
del intermediate_results, data

model = merge_model(top, bottom) #Exception happens here
del top, bottom
gc.collect()
```

",datumbox,b'stale',2017-02-09T17:52:02Z,2020-04-16T14:22:42Z
5318,Regularization Not taken into account when composing Models,"```
def BuggyReg():
    inp = Input( batch_shape=(None,10))
    out = ActivityRegularization(100000.0,100000.0)( Dense(100)(inp))
    model= Model([inp],[out])

    #This WORKS fine and takes regularization into account
    #model.compile(""adam"", ""mse"")
    #return model

    inp = Input(batch_shape=(None, 10))
    out2 = model(inp)
    model2 = Model([inp],[out2])

    #This doesn't work correctly : regularization is not taken into account
    model2.compile(""adam"",""mse"")
    return model2`


m= BuggyReg()
keras/engine/topology.py:379: UserWarning: The `regularizers` property of layers/models is deprecated. Regularization losses are now managed via the `losses` layer/model property.
  warnings.warn('The `regularizers` property of layers/models '

In [4]: m.fit(np.random.randn(10000,10), np.ones((10000,100)))
10000/10000 [==============================] - 0s - loss: 0.7956   SHOULD BE in order of 1000000
```

 
A quick search of the warning (which just appeared) points to the previous release note :
https://github.com/fchollet/keras/pull/4703
The refactorization of regularization is quite fresh, and I couldn't find any more information to how to obtain the correct behaviour.

I need to be able to compose model, and at the same time apply some regularization.
This bug was quite tricky to catch because some regularization layers like batchNormalization works fine, and inner models worked fine, but combined model was insensitive to regularization.

Can you please advise.

Thank you!

- [X] Check that you are up-to-date with the master branch of Keras. You can update with:
pip install git+git://github.com/fchollet/keras.git --upgrade --no-deps

- [X] If running on Theano, check that you are up-to-date with the master branch of Theano. You can update with:
pip install git+git://github.com/Theano/Theano.git --upgrade --no-deps",unrealwill,b'stale',2017-02-07T22:59:06Z,2017-06-22T20:12:03Z
5294,"LocallyConnected2D fails on [N, 1, x,y] type tensor","**Expected behaviour:**
As signalized in the Keras 1.2.1 manual, **LocallyConnected2D** layer should behave in the same way as the **Convolution2D**. I have successfully built and trained networks with **Convolution2D** layers operating on `[N, 1, x, y]` type tensors. **LocallyConnected2D** works without any problems with `[N, 3, x, y]` type tensors (e.g. RGB images).


**Observed behaviour:**
```
Traceback (most recent call last):
  File ""tmp_keras_issue.py"", line 23, in <module>
    Activation('relu'),
  File ""/Users/kamil/anaconda2/lib/python2.7/site-packages/keras/models.py"", line 273, in __init__
    self.add(layer)
  File ""/Users/kamil/anaconda2/lib/python2.7/site-packages/keras/models.py"", line 299, in add
    layer.create_input_layer(batch_input_shape, input_dtype)
  File ""/Users/kamil/anaconda2/lib/python2.7/site-packages/keras/engine/topology.py"", line 401, in create_input_layer
    self(x)
  File ""/Users/kamil/anaconda2/lib/python2.7/site-packages/keras/engine/topology.py"", line 546, in __call__
    self.build(input_shapes[0])
  File ""/Users/kamil/anaconda2/lib/python2.7/site-packages/keras/layers/local.py"", line 317, in build
    constraint=self.W_constraint)
  File ""/Users/kamil/anaconda2/lib/python2.7/site-packages/keras/engine/topology.py"", line 418, in add_weight
    weight = initializer(shape, name=name)
  File ""/Users/kamil/anaconda2/lib/python2.7/site-packages/keras/initializations.py"", line 66, in glorot_uniform
    return uniform(shape, s, name=name)
  File ""/Users/kamil/anaconda2/lib/python2.7/site-packages/keras/initializations.py"", line 33, in uniform
    return K.random_uniform_variable(shape, -scale, scale, name=name)
  File ""/Users/kamil/anaconda2/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py"", line 622, in random_uniform_variable
    low, high, dtype=tf_dtype, seed=seed)(shape)
  File ""/Users/kamil/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/init_ops.py"", line 171, in _initializer
    return random_ops.random_uniform(shape, minval, maxval, dtype, seed=seed)
  File ""/Users/kamil/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/random_ops.py"", line 245, in random_uniform
    seed2=seed2)
  File ""/Users/kamil/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/gen_random_ops.py"", line 220, in _random_uniform
    seed=seed, seed2=seed2, name=name)
  File ""/Users/kamil/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py"", line 759, in apply_op
    op_def=op_def)
  File ""/Users/kamil/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 2242, in create_op
    set_shapes_for_outputs(ret)
  File ""/Users/kamil/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 1617, in set_shapes_for_outputs
    shapes = shape_func(op)
  File ""/Users/kamil/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 1568, in call_with_requiring
    return call_cpp_shape_fn(op, require_shape_fn=True)
  File ""/Users/kamil/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/common_shapes.py"", line 610, in call_cpp_shape_fn
    debug_python_shape_fn, require_shape_fn)
  File ""/Users/kamil/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/common_shapes.py"", line 660, in _call_cpp_shape_fn_impl
    s = tensor_util.constant_value_as_shape(op.inputs[idx])
  File ""/Users/kamil/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/tensor_util.py"", line 742, in constant_value_as_shape
    [d if d != -1 else None for d in value]))
  File ""/Users/kamil/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/tensor_shape.py"", line 457, in __init__
    self._dims = [as_dimension(d) for d in dims_iter]
  File ""/Users/kamil/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/tensor_shape.py"", line 378, in as_dimension
    return Dimension(value)
  File ""/Users/kamil/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/tensor_shape.py"", line 38, in __init__
    raise ValueError(""Dimension %d must be >= 0"" % self._value)
ValueError: Dimension -126 must be >= 0
```


**Code to reproduce:**
```
# -*- coding: utf-8 -*-
""""""
    Keras | LocallyConnected2D Failure on [1, 128, 128] input tensor
""""""

__author__ = 'Kamil Tamiola'

import numpy as np
from keras.models import Sequential
from keras.layers import Dense, Activation, Flatten, LocallyConnected2D

if __name__ == '__main__':

    X = np.ones((4096, 1, 128, 128))
    Y = np.ones((4096, 128))

    batch_size = 128

    model = Sequential([
        LocallyConnected2D(16, 3, 3, input_shape=(1, 128, 128)),
        Flatten(),
        Dense(128),
        Activation('relu'),
    ])

    model.compile(optimizer='adam', loss='mse')
    model.fit(X, Y, nb_epoch=1000, verbose=1,
              batch_size=batch_size, validation_split=0.1)
```",ktamiola,None,2017-02-06T18:03:51Z,2017-02-06T19:01:18Z
5284,Problems using fit_generator with a custom generator,"```
f = h5py.File(path+'results/precomp.h5', 'r')
conv_trn_feat = f['train_features'][:]
trn_labels = np.tile(f['train_labels'][:], reps=(2,1))

def myGenerator():
    while True:
        for i in range(0, len(conv_trn_feat), batch_size):
            yield conv_trn_feat[i:i+batch_size], trn_labels[i:i+batch_size]

train_datagen = myGenerator()

bn_model = Sequential(get_bn_layers(0, num=num_hidden))
bn_model.compile(Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])
bn_model.optimizer.lr = 1e-3
bn_model.fit_generator(train_datagen, samples_per_epoch=len(conv_trn_feat), nb_epoch=4)
bn_model = Sequential(get_bn_layers(0, num=num_hidden))
bn_model.compile(Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])
bn_model.optimizer.lr = 1e-3
bn_model.fit(conv_trn_feat, trn_labels, nb_epoch=4)`

```

I am precomputing the features of a convolutional layer and training fully connected layers using them. I have to use hdf5 file and a custom generator because the size of dataset is quite large.

Following is the output:
<img width=""544"" alt=""screen shot 2017-02-06 at 11 36 13 am"" src=""https://cloud.githubusercontent.com/assets/6660192/22636432/0c2d05a4-ec61-11e6-9193-1a8bd0ac64df.png"">

**The loss when using fit decreases much more quickly then using fit_generator with a custom generator.**
Am I doing something wrong? To me it looks like some bug in fit_generator. 
",singlasahil14,None,2017-02-06T06:11:05Z,2017-02-06T15:46:17Z
5228,Bug Fix in Image Generator - Now Allows FCN's to be used,"I needed FCN's so have altered this preprocessing step, I can also make a gist for the tutorials if anyone else prefers to learn through a simple example.

This does not allow for no sizes to be set if max poolings are used. In that case, the sizes can be none-square but have to be multiple of 2^m - where m is the number of max pooling layers.

In the future it might be possible to auto-resize to the nearest factor, but another variable will need adding to ensure we can disentangle the model from the preprocessing.


Made minor changes to allow for FCN's:
  - Target Size is now a tuple of (None, None) as only this can propagate through the directory iterator
  - Altered batch_x to be created in the loop, as you should only use a batch size of 1 for FCN of shape (None, None, Channels)
  - Allowed the directory iterator to use the folder it is passed if it finds no subfolders for classes (Usual use case in FCN)

Allowed BGR to be specified (for when using caffe converted models).",joeyearsley,None,2017-01-30T17:20:20Z,2017-06-10T03:22:05Z
5225,sparse placeholder initialization fails due to tensorflow bug,"~~Sparse placeholder initialization by `K.placeholder` does not specify the `shape` parameter in either [tensorflow](https://github.com/fchollet/keras/blob/master/keras/backend/tensorflow_backend.py#L309) or [theano](https://github.com/fchollet/keras/blob/master/keras/backend/theano_backend.py#L108) backends.~~

~~According to the [tensorflow API docs](https://www.tensorflow.org/api_docs/python/io_ops/placeholders#sparse_placeholder) the `shape` parameter is optional. (If the shape is not specified, you can feed a sparse tensor of any shape.)
But since Tensor shapes are tracked (through the _keras_shape) attribute, this leads to problems in the computation graph.
I noticed this when `K.sum(t_sparse*t_dense)` in a metric lead to unexpected behaviour.~~

The solution to this issue:

[tensorflow_backend.py:347](https://github.com/fchollet/keras/blob/master/keras/backend/tensorflow_backend.py#L347) ~~and [theano_backend.py:182](https://github.com/fchollet/keras/blob/master/keras/backend/theano_backend.py#L182)~~
```python
tf.sparse_placeholder(dtype, name=name, shape=numpy.array(shape).astype(""int64""))
```
Note that the `numpy.array` type conversion to `int64` is a workaround for [tensorflow issue #6749](https://github.com/tensorflow/tensorflow/issues/6749)

Note that the theano backend does not specify a shape/broadcast parameter.
~~Was the `shape` left out on purpose? If not I'll open a PR to fix it.~~

cheers",michaelosthege,b'stale',2017-01-30T07:59:38Z,2017-07-13T02:02:54Z
5223,"TF/threads: Must call train_on_batch and predict_on_batch before starting threads, get errors otherwise","If I use models in other threads I get errors. If I run them first (call train_on_batch and predict_on_batch) it works. But I cannot do that for my real models because I only get train data after I eval a few times (simulation stuff).

I tried ""tfGraph.as_default()"" and ""global/local_variables_initializer()"", that things just give different errors for all combinations, see 4 examples:

Just spawning threads:
```ValueError: Tensor(""Const:0"", shape=(), dtype=float32) must be from the same graph as Tensor(""sub_3:0"", shape=(), dtype=float32).```

Using: with tfGraph.as_default()
```IndexError: pop from empty list```

Using: tfGraph.as_default() and global/local_variables_initializer()
```InvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'keras_learning_phase' with dtype bool```

Using: tfGraph.as_default() and global/local_variables_initializer() and K.manual_variable_initialization(True) [not shown in 2nd Gist]:
```FailedPreconditionError (see above for traceback): Attempting to use uninitialized value dense_1_W```


Gist: test.py (run without arguments, could also test sequential or processes, commented out atm to show the bug. If you remove the comment on line 209 it works (calls warmup(), which calls train_on_batch and predict_on_batch, before starting the threads):
https://gist.github.com/droid666/eebf14dc8e92f3c4bccb92a1c0fd4279

Same with ""tfGraph.as_default()"" and ""global/local_variables_initializer()"" at lines 134-143:
https://gist.github.com/droid666/3353c8f1f225a1245fab59f4d1570e89

Sorry if I just do it wrong (global/local_variables_initializer() is used wrong, I am rather sure).

Edit: also I cannot just do the following because I have complex custom loss functions, so y_predict and y_train are very different in size and content:
```
for m in myModels:
        x = np.zeros((1,m.inSize))
        y = m.model.predict_on_batch(x)
        m.model.train_on_batch(x, y)
```",droid666,b'stale',2017-01-29T19:36:54Z,2020-01-09T11:27:45Z
5179,KeyError when saving model with dangling inputs,"I get an unexpected KeyError when saving a model with several inputs where some of the inputs are  not used in the computation graph, as in the following minimal example (A):

(A)
```python
from keras.layers import Input, merge
from keras.models import Model
input1 = Input((10,))
input2 = Input((10,))
#create output that only uses input1
output = merge([input1, input1])
model = Model(input=[input1, input2], output=[output])

#this works
model.save_weights(""weights.hdf5"")
#this raises an error
model.save(""weights.hdf5"")
```
```
KeyError: 'input_2_ib-0'
```
   
when changing the code to incorporate ""input2"" into the model, everything works as expected 
(B)
```python
#...
output = merge([input1, input2])
#...
```

The underlying reason seems to be that for (A) the dangling input layer is pruned from `model.layers` at build stage yet still present in `model.input_layers` raising the error in  `model.get_config()`:
(A)
```python
print([lay.name for lay in  model.layers])
Out[4]: ['input_1', 'merge_1']

print([lay.name for lay in  model.input_layers])
Out[5]: ['input_1', 'input_2']
```

As I would not necessarily call that a bug (I could just change the inputs of the model to only those that actually get used) I find that behaviour a bit unintuitive:

- the compiling and fitting and generally all computations of models like (A) work as expected, yet the saving throws an error 
- it makes the saving of stacks of submodels harder each having fixed inputs/outputs yet which might decide not to use certain inputs in their computation graph 

Maybe I'm missing something or is there an easy workaround?

Thanks!
 
OSX 10.11.6, keras 1.2.1 master, theano backend, GeForce GT 750M (CNMeM is disabled, cuDNN 5105)

-------------
- [x] Check that you are up-to-date with the master branch of Keras. You can update with:
pip install git+git://github.com/fchollet/keras.git --upgrade --no-deps

- [ ] If running on TensorFlow, check that you are up-to-date with the latest version. The installation instructions can be found [here](https://www.tensorflow.org/get_started/os_setup).

- [x] If running on Theano, check that you are up-to-date with the master branch of Theano. You can update with:
pip install git+git://github.com/Theano/Theano.git --upgrade --no-deps

- [x] Provide a link to a GitHub Gist of a Python script that can reproduce your issue (or just copy the script here if it is short).
",maweigert,b'stale',2017-01-25T15:05:23Z,2018-11-05T06:15:52Z
5153,Bugfix: Fix issue in deep dream example,"The expression of  pictures should be (img_height, img_width, 3) or (3, img_height, img_width), not (img_width, img_height, 3) or (3, img_width, img_height).",mohanson,None,2017-01-24T07:56:36Z,2017-01-24T17:39:26Z
5143,"Bugfix CSVLogger Callback separator and append parameters, added tests","CSVLogger callback did not regard separator value and prepended header to existing files although append argument was specified.
Also, added tests to confirm functionality.",ExpectationMax,None,2017-01-23T21:38:11Z,2017-01-24T17:43:58Z
5121,Fix Sckit-learn API get_parameters bug,"Add **params to BaseWrapper.get_params(self,_) to fix TypeError to fix issues #5103 ",bottydim,None,2017-01-21T15:23:46Z,2017-02-27T14:19:52Z
5103,Scikit-learn API bug,"Keras 1.2.1 introduces a small bug in the sckit-learn API on line:
https://github.com/fchollet/keras/blob/master/keras/wrappers/scikit_learn.py#L87
def get_params(self, _):
Since the base.py calls the function with an explicit parameter name
https://github.com/scikit-learn/scikit-learn/blob/0.18.1/sklearn/base.py#L67
 new_object_params = estimator.get_params(deep=False)

TypeError: get_params() got an unexpected keyword argument 'deep' is thrown
",bottydim,None,2017-01-20T16:44:18Z,2017-02-23T16:07:39Z
5093,fix deconv2d None error,"there is a common bug that occurs in the Deconvolution2D class when you use None for the batch size w/ the output_shape argument, which originates from tf.nn.deconv2d but can easily be alleviated in keras. It errors out saying: ""TypeError: Expected binary or unicode string, got None""

The fix is to add the tf.stack() line in keras/backend/tensorflow_backend.py on line 2472:
```
def _preprocess_deconv_output_shape(x, shape, dim_ordering):
    if dim_ordering == 'th':
        shape = (shape[0], shape[2], shape[3], shape[1])

    if shape[0] is None:
        shape = (tf.shape(x)[0], ) + tuple(shape[1:])
        shape = tf.stack(list(shape))
    return shape
```
Example issue from TF that carries over to keras: https://groups.google.com/a/tensorflow.org/forum/#!topic/discuss/vf8eH9YMwVA",ncullen93,None,2017-01-20T03:44:34Z,2017-01-20T19:00:33Z
5086,How to make one Embedding for two LSTMs?,"Suppose we have simple example (taken from keras documentation) with one shared LSTM how could I introduce one shared Embedding here? Sorry If my question is already answered but I read this topics and found them a bit confusing. I tried to simply make one Embedding and put it in different sequential models but model.fit failed with assert ""You are only have one one input but give two"".  Then I took this example below and tried to put shared Embedding.

This is original
```
from keras.layers import Input, LSTM, Dense, merge
from keras.models import Model

tweet_a = Input(shape=(140, 256))
tweet_b = Input(shape=(140, 256))

# this layer can take as input a matrix
# and will return a vector of size 64
shared_lstm = LSTM(64)

# when we reuse the same layer instance
# multiple times, the weights of the layer
# are also being reused
# (it is effectively *the same* layer)
encoded_a = shared_lstm(tweet_a)
encoded_b = shared_lstm(tweet_b)

# we can then concatenate the two vectors:
merged_vector = merge([encoded_a, encoded_b], mode='concat', concat_axis=-1)

# and add a logistic regression on top
predictions = Dense(1, activation='sigmoid')(merged_vector)

# we define a trainable model linking the
# tweet inputs to the predictions
model = Model(input=[tweet_a, tweet_b], output=predictions)

model.compile(optimizer='rmsprop',
              loss='binary_crossentropy',
              metrics=['accuracy'])
model.fit([data_a, data_b], labels, nb_epoch=10)
```

This refactored with shared embeding
```

# -*- coding: utf-8 -*-
from keras.layers import Input, LSTM, Dense, merge, Embedding
from keras.models import Model
import numpy

tweet_a = Input(shape=(140, ), dtype='int32')
tweet_b = Input(shape=(140, ), dtype='int32')

emb = Embedding(input_dim=100, output_dim=10, input_length=20)

em_1 = emb(tweet_a)
em_2 = emb(tweet_b)

# this layer can take as input a matrix
# and will return a vector of size 64
shared_lstm = LSTM(64)

# when we reuse the same layer instance
# multiple times, the weights of the layer
# are also being reused
# (it is effectively *the same* layer)
encoded_a = shared_lstm(em_1)
encoded_b = shared_lstm(em_2)

# we can then concatenate the two vectors:
merged_vector = merge([encoded_a, encoded_b], mode='concat')

# and add a logistic regression on top
predictions = Dense(1, activation='sigmoid')(merged_vector)

# we define a trainable model linking the
# tweet inputs to the predictions
model = Model(input=[tweet_a, tweet_b], output=predictions)

model.compile(optimizer='rmsprop', loss='binary_crossentropy')

print 'Number of model parameters: ', model.count_params()

data_a = numpy.zeros(shape=(223, 140), dtype='int32')
data_b = numpy.zeros(shape=(223, 140), dtype='int32')
labels = numpy.zeros(shape=(223, 1), dtype='float32')

model.fit([data_a, data_b], labels, nb_epoch=10)
```

But got:

```
Traceback (most recent call last):
  File ""/home/zakirov/proj/semantic/plm/wt-em-lstm-4-neg.py"", line 45, in <module>
    model.fit([data_a, data_b], labels, nb_epoch=10)
  File ""/usr/local/lib/python2.7/dist-packages/keras/engine/training.py"", line 1111, in fit
    initial_epoch=initial_epoch)
  File ""/usr/local/lib/python2.7/dist-packages/keras/engine/training.py"", line 826, in _fit_loop
    outs = f(ins_batch)
  File ""/usr/local/lib/python2.7/dist-packages/keras/backend/theano_backend.py"", line 811, in __call__
    return self.function(*inputs)
  File ""/usr/local/lib/python2.7/dist-packages/theano/compile/function_module.py"", line 871, in __call__
    storage_map=getattr(self.fn, 'storage_map', None))
  File ""/usr/local/lib/python2.7/dist-packages/theano/gof/link.py"", line 314, in raise_with_op
    reraise(exc_type, exc_value, exc_trace)
  File ""/usr/local/lib/python2.7/dist-packages/theano/compile/function_module.py"", line 859, in __call__
    outputs = self.fn()
  File ""/usr/local/lib/python2.7/dist-packages/theano/scan_module/scan_op.py"", line 951, in rval
    r = p(n, [x[0] for x in i], o)
  File ""/usr/local/lib/python2.7/dist-packages/theano/scan_module/scan_op.py"", line 940, in <lambda>
    self, node)
  File ""theano/scan_module/scan_perform.pyx"", line 405, in theano.scan_module.scan_perform.perform (/home/zakirov/.theano/compiledir_Linux-3.19--generic-x86_64-with-Ubuntu-15.04-vivid-x86_64-2.7.9-64/scan_perform/mod.cpp:4316)
  File ""/usr/local/lib/python2.7/dist-packages/theano/gof/link.py"", line 314, in raise_with_op
    reraise(exc_type, exc_value, exc_trace)
  File ""theano/scan_module/scan_perform.pyx"", line 397, in theano.scan_module.scan_perform.perform (/home/zakirov/.theano/compiledir_Linux-3.19--generic-x86_64-with-Ubuntu-15.04-vivid-x86_64-2.7.9-64/scan_perform/mod.cpp:4193)
ValueError: Input dimension mis-match. (input[0].shape[0] = 224, input[1].shape[0] = 32)
Apply node that caused the error: Elemwise{add,no_inplace}(Subtensor{::, int64::}.0, dot.0)
Toposort index: 35
Inputs types: [TensorType(float32, matrix), TensorType(float32, matrix)]
Inputs shapes: [(224, 64), (32, 64)]
Inputs strides: [(20480, 4), (256, 4)]
Inputs values: ['not shown', 'not shown']
Outputs clients: [[Elemwise{mul,no_inplace}(Elemwise{add,no_inplace}.0, DimShuffle{x,x}.0)]]

Backtrace when the node is created(use Theano flag traceback.limit=N to make it longer):
  File ""/usr/local/lib/python2.7/dist-packages/keras/engine/topology.py"", line 517, in __call__
    self.add_inbound_node(inbound_layers, node_indices, tensor_indices)
  File ""/usr/local/lib/python2.7/dist-packages/keras/engine/topology.py"", line 571, in add_inbound_node
    Node.create_node(self, inbound_layers, node_indices, tensor_indices)
  File ""/usr/local/lib/python2.7/dist-packages/keras/engine/topology.py"", line 155, in create_node
    output_tensors = to_list(outbound_layer.call(input_tensors[0], mask=input_masks[0]))
  File ""/usr/local/lib/python2.7/dist-packages/keras/layers/recurrent.py"", line 227, in call
    input_length=input_shape[1])
  File ""/usr/local/lib/python2.7/dist-packages/keras/backend/theano_backend.py"", line 981, in rnn
    go_backwards=go_backwards)
  File ""/usr/local/lib/python2.7/dist-packages/theano/scan_module/scan.py"", line 745, in scan
    condition, outputs, updates = scan_utils.get_updates_and_outputs(fn(*args))
  File ""/usr/local/lib/python2.7/dist-packages/keras/backend/theano_backend.py"", line 973, in _step
    output, new_states = step_function(input, states)
  File ""/usr/local/lib/python2.7/dist-packages/keras/layers/recurrent.py"", line 825, in step
    o = self.inner_activation(x_o + K.dot(h_tm1 * B_U[3], self.U_o))

HINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.
Apply node that caused the error: for{cpu,scan_fn}(Subtensor{int64}.0, Subtensor{:int64:}.0, IncSubtensor{Set;:int64:}.0, IncSubtensor{Set;:int64:}.0, Subtensor{int64}.0, lstm_1_U_o, lstm_1_U_f, lstm_1_U_i, lstm_1_U_c)
Toposort index: 401
Inputs types: [TensorType(int64, scalar), TensorType(float32, 3D), TensorType(float32, 3D), TensorType(float32, 3D), TensorType(int64, scalar), TensorType(float32, matrix), TensorType(float32, matrix), TensorType(float32, matrix), TensorType(float32, matrix)]
Inputs shapes: [(), (20, 224, 256), (21, 32, 64), (21, 32, 64), (), (64, 64), (64, 64), (64, 64), (64, 64)]
Inputs strides: [(), (1024, 20480, 4), (8192, 256, 4), (8192, 256, 4), (), (256, 4), (256, 4), (256, 4), (256, 4)]
Inputs values: [array(20), 'not shown', 'not shown', 'not shown', array(20), 'not shown', 'not shown', 'not shown', 'not shown']
Outputs clients: [[], [], [DimShuffle{0,1,2}(for{cpu,scan_fn}.2)]]

Backtrace when the node is created(use Theano flag traceback.limit=N to make it longer):
  File ""/home/zakirov/proj/semantic/plm/wt-em-lstm-4-neg.py"", line 24, in <module>
    encoded_a = shared_lstm(em_1)
  File ""/usr/local/lib/python2.7/dist-packages/keras/engine/topology.py"", line 517, in __call__
    self.add_inbound_node(inbound_layers, node_indices, tensor_indices)
  File ""/usr/local/lib/python2.7/dist-packages/keras/engine/topology.py"", line 571, in add_inbound_node
    Node.create_node(self, inbound_layers, node_indices, tensor_indices)
  File ""/usr/local/lib/python2.7/dist-packages/keras/engine/topology.py"", line 155, in create_node
    output_tensors = to_list(outbound_layer.call(input_tensors[0], mask=input_masks[0]))
  File ""/usr/local/lib/python2.7/dist-packages/keras/layers/recurrent.py"", line 227, in call
    input_length=input_shape[1])
  File ""/usr/local/lib/python2.7/dist-packages/keras/backend/theano_backend.py"", line 981, in rnn
    go_backwards=go_backwards)

HINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.
```

What I am doing wrong?",MaratZakirov,b'stale',2017-01-19T14:36:35Z,2017-06-22T19:09:34Z
5083,Bug on the save/load mechanism of version 1.2.0,"I believe there is a bug on the save/load mechanism of version 1.2.0. The problem did not exist on version 1.1.2.

To reproduce the bug I'll be using the following code snippet taken from the Keras documentation: [Fine-tune InceptionV3 on a new set of classes](https://keras.io/applications/)

```python
from keras.preprocessing import image
generator = image.ImageDataGenerator().flow_from_directory('./data/cifar2-train', target_size=(224, 224), batch_size=32, class_mode='categorical', shuffle=True)

# ==== Start of Code Snippet from Keras Documentation: https://keras.io/applications/ ====
from keras.applications.inception_v3 import InceptionV3
from keras.preprocessing import image
from keras.models import Model
from keras.layers import Dense, GlobalAveragePooling2D
from keras import backend as K

base_model = InceptionV3(weights='imagenet', include_top=False)

x = base_model.output
x = GlobalAveragePooling2D()(x)
x = Dense(1024, activation='relu')(x)
predictions = Dense(2, activation='softmax')(x)

model = Model(input=base_model.input, output=predictions)

for layer in base_model.layers:
    layer.trainable = False

model.compile(optimizer='rmsprop', loss='categorical_crossentropy')

model.fit_generator(generator, samples_per_epoch=1000, nb_epoch=1)

for i, layer in enumerate(base_model.layers):
   print(i, layer.name)

for layer in model.layers[:172]:
   layer.trainable = False
for layer in model.layers[172:]:
   layer.trainable = True

from keras.optimizers import SGD
model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='categorical_crossentropy')

model.fit_generator(generator, samples_per_epoch=1000, nb_epoch=1)
# ==== End of Code Snippet ====

model.save('./data/tempModel')
del model
from keras.models import load_model
model = load_model('./data/tempModel')
```
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/usr/local/lib/python2.7/dist-packages/keras/models.py"", line 143, in load_model
    model.load_weights_from_hdf5_group(f['model_weights'])
  File ""/usr/local/lib/python2.7/dist-packages/keras/engine/topology.py"", line 2753, in load_weights_from_hdf5_group
    str(len(flattened_layers)) + ' layers.')
ValueError: You are trying to load a weight file containing 190 layers into a model with 2 layers.",datumbox,None,2017-01-19T12:36:38Z,2017-01-27T22:37:09Z
5063,Defining Keras Layers in a Loop,"Please make sure that the boxes below are checked before you submit your issue. If your issue is an implementation question, please ask your question on [StackOverflow](http://stackoverflow.com/questions/tagged/keras) or [join the Keras Slack channel](https://keras-slack-autojoin.herokuapp.com/) and ask there instead of filing a GitHub issue.

Thank you!

- [x] Check that you are up-to-date with the master branch of Keras. You can update with:
pip install git+git://github.com/fchollet/keras.git --upgrade --no-deps

- [ ] If running on TensorFlow, check that you are up-to-date with the latest version. The installation instructions can be found [here](https://www.tensorflow.org/get_started/os_setup).

- [x] If running on Theano, check that you are up-to-date with the master branch of Theano. You can update with:
pip install git+git://github.com/Theano/Theano.git --upgrade --no-deps

- [x] Provide a link to a GitHub Gist of a Python script that can reproduce your issue (or just copy the script here if it is short).


I need to define layers in a loop for generating class specific attention models. (Loop as number of classes can vary)
I have tried something similar to the following:

```python
models = [{}]*num_classes

for i in range(num_classes):
    model[i]['input_layer'] = Input(shape=(max_sentences, img_h,), dtype='int32', name='input_layer')
    model[i]['attention'] = AttentionLayer(name='attention_'+str(i))(model[i]['input_layer'])
    .......
    model[i]['model'] = Model(input=[model[i]['input_layer']], output=[model[i]['softmax_layer']], name=""model_""+str(i))
```
Here AttentionLayer is a custom layer.

Assume that there are 6 classes.
When I print the summary for model[0], it shows the name of the AttentionLayer to be 'attention_5' instead of 'attention_0' (as the value of i when the loop finishes will be 5). However the memory allocations are different for each AttentionLayer. 

Is this a bug?
Please let me know.

Thanks",siddheshk,None,2017-01-17T11:35:18Z,2017-03-28T12:59:27Z
5049,Model generators: Make sure all threads finish when stop is requested,"Beforehand, slow generators could have caused race conditions and crashes with `ValueError: generator already executing`, e.g. if a validation generator filling up the queue took longer than a single epoch that elapsed meanwhile.

This sounds exotic but this happened to me in a generator that rendered PDF files and in the initial testing, epoch size was just a small multiply of batch size (and similar to validation set size).  Of course this is not optimal usage, but nevertheless it was frustrating to debug this issue in initial model experiments.",pasky,None,2017-01-16T00:59:55Z,2017-01-17T01:14:16Z
5046,Error with Cosine Proximity as target for loss function (with merge layer),"Hi I'm trying to build a simple LSTM for a sentence similarity task. I'm using Glove word embeddings going into the LSTMs, and padding my sentences to 50. I then go into a merge layer on axis 1 using 'cos'. Whenever I fit and compile I get a nan for loss, immediately. I've tried to keep it simple for easy debugging. Any help would be appreciated.  Model summary and code below (left out data preprocessing)


total training data = 1184
X1.shape = (1184, 50)
X2.shape = (1184, 50)
Y.shape = (1184, 1)
____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
____________________________________________________________________________________________________
embedding_1 (Embedding)          (None, 50, 100)       310200      embedding_input_1[0][0]          
____________________________________________________________________________________________________
lstm_1 (LSTM)                    (None, 128)           117248      embedding_1[0][0]                
____________________________________________________________________________________________________
embedding_2 (Embedding)          (None, 50, 100)       310200      embedding_input_2[0][0]          
____________________________________________________________________________________________________
lstm_2 (LSTM)                    (None, 128)           117248      embedding_2[0][0]                
____________________________________________________________________________________________________
activation_1 (Activation)        (None, 1)             0           merge_1[0][0]                    
____________________________________________________________________________________________________
Total params: 854,896
Trainable params: 234,496
Non-trainable params: 620,400


```
embedding_layer_a = Embedding(len(word_index) + 1,
                            EMBEDDING_DIM,
                            weights=[embedding_matrix],
                            input_length=50,
                            trainable=False)

embedding_layer_b = Embedding(len(word_index) + 1,
                            EMBEDDING_DIM,
                            weights=[embedding_matrix],
                            input_length=50,
                            trainable=False)

s1rnn = Sequential()
s1rnn.add(embedding_layer_a)
s1rnn.add(LSTM(128, input_shape=(100, 1), dropout_W=0.2, dropout_U=0.2))


s2rnn = Sequential()
s2rnn.add(embedding_layer_b)
s2rnn.add(LSTM(128, input_shape=(100, 1), dropout_W=0.2, dropout_U=0.2))


model = Sequential()
merged = Merge([s1rnn, s2rnn], mode='cos', dot_axes=1)
model.add(merged)
model.add(Activation('relu'))

model.summary()

model.compile(optimizer='rmsprop', loss='cosine_proximity', metrics=['accuracy'])

model.fit([X1, X2], Y, batch_size=32, nb_epoch=500, validation_split=0.10)

```",pchowdhry,b'stale',2017-01-15T19:28:44Z,2017-06-22T19:09:08Z
5044,`ZeroDivisionError` when using `class_mode=None` with `ImageDataGenerator.flow_from_directory()`,"[Here's the script][1] to run to see the exception. One can run it like `python imggen_reproduce.py /tmp/somedir_that_you_donot_care_about`. After a quick glance at the source, it seems like `class_mode` is not used in the `DirectoryIterator` constructor to prevent `self.nb_sample` from being set to `0`, which ultimately becomes `self.n` in the base `Iterator`.

Some reporters of a previous bug (#4699) have reported that this ""works"" when you create an additional directory under the directory passed to `flow_from_directory()`. However, I don't think this is ideal, for semantically, there _is_ no class/label when dealing with test images.

My proposal to fix this is to set self.nb_sample = number of valid image files in the input directory when `self.class_mode is None and not self.classes`, in `DirectoryIterator::__init__`. The second clause in the condition will help prevent breakage of code that has hacked its way around this issue by creating an additional directory (or we don't have to be afraid of breaking, it's up to you). Please let me know if you are okay with this, and if you have any ideas (including calling this issue a non-issue :)), and I can accordingly prepare a quick PR (or not).

[1]: https://gist.github.com/yati-sagade/ff309678a6d6ec849c488b1f9a5fa6b3",yati-sagade,b'stale',2017-01-15T13:30:27Z,2017-08-12T13:15:50Z
5034,ImageDataGenerator.flow_from_directory() is outputting the wrong shape data,"From the flow_from_directory tuple output of X_batch and Y_batch, the Y_batch is outputting as a shape that is not one-hot encoding.  The model.fit_generator seems to need one-hot encoding for the labels.  How do you make this in the correct, compatible shape?  This seems to be a bug.


```
datagen = kerasim.ImageDataGenerator(
		        width_shift_range=.1, height_shift_range=.1,  # randomly shift images vertically (fraction of total height)
		        shear_range=0, zoom_range=.15,
		        rescale=None, fill_mode='constant', cval=0.,
		        horizontal_flip=True, vertical_flip=True)

valdatagen = kerasim.ImageDataGenerator(
		        width_shift_range=.1, height_shift_range=.1,  # randomly shift images vertically (fraction of total height)
		        shear_range=0, zoom_range=.15,
		        rescale=None, fill_mode='constant', cval=0.,
		        horizontal_flip=True, vertical_flip=True)
			
train_generator = datagen.flow_from_directory('...', target_size=(256,256), batch_size=batch_size, class_mode='binary')
validation_generator = valdatagen.flow_from_directory('...', target_size=(256,256), batch_size=batch_size, class_mode='binary')
model.fit_generator(train_generator, samples_per_epoch=2*Nimages, nb_epoch=nb_epoch, 
				validation_data=validation_generator, callbacks=callbacks_list, nb_val_samples=100, verbose=1)

```

For my image folders, I have data/train/0, data/train/1, data/validation/0, data/validation/1.  

Error in shape:

```
Epoch 1/50000
Traceback (most recent call last):
  File ""DR.py"", line 286, in train
    validation_data=validation_generator, callbacks=callbacks_list, nb_val_samples=100, verbose=1)
  File ""/home/sysop/anaconda2/envs/tf/lib/python2.7/site-packages/keras/models.py"", line 935, in fit_generator
    initial_epoch=initial_epoch)
  File ""/home/sysop/anaconda2/envs/tf/lib/python2.7/site-packages/keras/engine/training.py"", line 1518, in fit_generator
    class_weight=class_weight)
  File ""/home/sysop/anaconda2/envs/tf/lib/python2.7/site-packages/keras/engine/training.py"", line 1271, in train_on_batch
    check_batch_axis=True)
  File ""/home/sysop/anaconda2/envs/tf/lib/python2.7/site-packages/keras/engine/training.py"", line 995, in _standardize_user_data
    exception_prefix='model target')
  File ""/home/sysop/anaconda2/envs/tf/lib/python2.7/site-packages/keras/engine/training.py"", line 124, in standardize_input_data
    str(array.shape))
ValueError: Error when checking model target: expected predictions to have shape (None, 2) but got array with shape (64, 1)
Exception in thread Thread-2:

```

I am running the latest versions of keras and tensorflow as of today.",alphamupsiomega,b'stale',2017-01-13T20:07:53Z,2017-06-22T22:15:04Z
5021,Fix bug introduced in commit: https://github.com/fchollet/keras/commi…,"…t/f6b804263a6e1d3ce6d2131cb9d758e1d7e57888.

```python
callbacks.ModelCheckpoint(MODEL_CHECKPOINT_FILE_PATH, monitor='val_acc', save_best_only=True, verbose=1)
```

This no longer worked with change introduced in above commit.",mjdietzx,None,2017-01-12T19:57:45Z,2017-01-12T21:20:59Z
5012,Fix custom_objects for regularizers and other issues,"Hi everybody!

Please let me know your thoughts regarding this quick fix and slight quality-of-life for custom_objects.

* Instead of copying custom objects into globals(), they are copied into a separate dictionary.
* get_from_module checks that dictionary before checking the requested module.
* users can clear the custom objects or otherwise manipulate the dictionary if they want to

This also means that custom_objects work for custom regularizers. 

A side effect of the code is that you now can do something like:
```python
get_custom_objects()[""CustomRegularizer""]=CustomRegularizer
d = Dense(dim, activity_regularizer='CustomRegularizer')
```

Below code is broken currently but works with this PR.

https://github.com/fchollet/keras/issues/4990

```python
level_1_dim = 256
level_2_dim = 64
encoding_dim = 16

from keras import regularizers
from keras.layers import Input, Dense
from keras.models import Model, model_from_json

class CustomRegularizer (regularizers.ActivityRegularizer):
  def __call__ (self, x):
    # this is just for purposes of demonstrating a bug
    return super(CustomRegularizer, self).__call__(x)

input_img = Input(shape=(784,))
encoded = Dense(level_1_dim, activation='relu')(input_img)
encoded = Dense(level_2_dim, activation='relu')(encoded)
encoded = Dense(encoding_dim, activation='relu', activity_regularizer=CustomRegularizer(1e-6))(encoded)
decoded = Dense(level_2_dim, activation='relu')(encoded)
decoded = Dense(level_1_dim, activation='relu')(decoded)
decoded = Dense(784, activation='sigmoid')(decoded)

autoencoder = Model(input=input_img, output=decoded)

encoder = Model(input=input_img, output=encoded)

with open('auto.encoder.model', 'w') as outfile:
  outfile.write(encoder.to_json())

""""""
# This was the workaround, no longer required
import keras.regularizers
keras.regularizers.CustomRegularizer=CustomRegularizer
""""""

with open('auto.encoder.model', 'r') as infile:
  encoder = model_from_json(infile.read(), custom_objects={""CustomRegularizer"":CustomRegularizer})

```

As a side note, I think
```python
for cls_key in custom_objects:
            globals()[cls_key] = custom_objects[cls_key]
```
could be replaced by `globals().update(custom_objects)`

There are some places in the code that are accessing globals directly instead of through get_from_module. If we use get_from_module consistently then there is a consistent place we can deal with customizations. I didn't make those fixes yet but I could based on discussion.

Cheers,
Ben

",bstriner,None,2017-01-12T12:35:25Z,2017-01-21T21:03:16Z
4999,Potential deconv model saving fix?,"I think model serialization with a deconv layer + tf backend causes a bug. I think adding this tuple cast fixes it.

This script reproduces the bug for me with the latest keras/tensorflow
```python
from keras.models import Sequential, load_model
from keras.layers import Deconvolution2D
model = Sequential()
model.add(Deconvolution2D(3, 3, 3, output_shape=(None, 14, 14, 3), input_shape=(12, 12, 3)))
model.save('tmp.model')
del model
model = load_model('tmp.model')
```",jmhessel,None,2017-01-12T03:52:12Z,2017-01-12T07:10:21Z
4997,Deconvolution2D padding,"Hi, I think there is a bug in Deconvolution2D.

I run the example code in the tutorial, 
----
model = Sequential()
model.add(Deconvolution2D(3, 3, 3, output_shape=(None, 3, 14, 14), border_mode='valid', input_shape=(3, 12, 12)))
-----
The output shape is equal to (3, 14, 14). according to the formula,
s (i - 1) + a + k - 2p = 1 (12 - 1) + 0 + 3 - 0 = 14 (s = stride, i = input size, a = user -defined, p = padding)

However, If I add padding layer, 
----
model = Sequential()
model.add(ZeroPadding2D((1,1), input_shape=(3, 12, 12)))
model.add(Deconvolution2D(3, 3, 3, output_shape=(None, 3, 14, 14))
-----

The output shape should s (i - 1) + a + k - 2p = 1 (14 - 1) + 0 + 3 - 2 = 14

However, keras produces an error, ""ValueError: impossible convolution output dim: expected 32x3x12x12 but received gradient with shape 32x3x14x14""

I think that Deconvolution2D does not count pad for calculating output shape. 

Do you what happens?

The error can be resolved if I use moder_mode = 'full', and I don't understand this one too.

Thanks,




Please make sure that the boxes below are checked before you submit your issue. If your issue is an implementation question, please ask your question on [StackOverflow](http://stackoverflow.com/questions/tagged/keras) or [join the Keras Slack channel](https://keras-slack-autojoin.herokuapp.com/) and ask there instead of filing a GitHub issue.

Thank you!

- [o ] Check that you are up-to-date with the master branch of Keras. You can update with:
pip install git+git://github.com/fchollet/keras.git --upgrade --no-deps

- [ o] If running on TensorFlow, check that you are up-to-date with the latest version. The installation instructions can be found [here](https://www.tensorflow.org/get_started/os_setup).

- [o] If running on Theano, check that you are up-to-date with the master branch of Theano. You can update with:
pip install git+git://github.com/Theano/Theano.git --upgrade --no-deps

- [o] Provide a link to a GitHub Gist of a Python script that can reproduce your issue (or just copy the script here if it is short).
",DonghyunK,b'stale',2017-01-12T01:14:49Z,2017-06-22T19:09:04Z
4996,What are some pressing Keras bugs that I am not aware of?,"We will soon be cutting a final Keras v1 in preparation for upcoming development on Keras v2.

What are some pressing issues that you want to see addressed in Keras v1 before we freeze it? Anything I have been missing? No feature requests, only bugs.",fchollet,b'stat:contributions welcome',2017-01-12T01:05:39Z,2018-10-07T18:29:48Z
4993,Use non-daemon threading for generators,"*Fix #4392*

> One step of [the daemon thread tear-down process] appears to be to set the values inside globals() to None, meaning that any module resolution results in an AttributeError attempting to dereference NoneType.
> 
> This is Python bug 1856. It was fixed in Python 3.2.1 and 3.3, but the fix was never backported to 2.x.
https://joeshaw.org/python-daemon-threads-considered-harmful/

@tdeboissiere, was there any particular reason you chose to set `thread.daemon = True` in https://github.com/fchollet/keras/pull/3049?

/cc @joeshaw",lukeyeager,None,2017-01-11T19:33:21Z,2017-01-17T03:29:33Z
4977,Documentation uses the 'th' image dimension ordering while the default is 'tf'   ,"This is confusing, especially for a new user. I might be an idea to provide some information or warning to the user that the documentation uses 'th' convention. 

For example the example of VGG in the sequential introduction part of the documentation returns an error if the ordering of the dimension is not adjusted from the default. 

```
from keras.models import Sequential
from keras.layers import Dense, Dropout, Activation, Flatten
from keras.layers import Convolution2D, MaxPooling2D
from keras.optimizers import SGD

model = Sequential()
# input: 100x100 images with 3 channels -> (3, 100, 100) tensors.
# this applies 32 convolution filters of size 3x3 each.
model.add(Convolution2D(32, 3, 3, border_mode='valid', input_shape=(3, 100, 100)))
model.add(Activation('relu'))
model.add(Convolution2D(32, 3, 3))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.25))

model.add(Convolution2D(64, 3, 3, border_mode='valid'))
model.add(Activation('relu'))
model.add(Convolution2D(64, 3, 3))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.25))

model.add(Flatten())
# Note: Keras does automatic shape inference.
model.add(Dense(256))
model.add(Activation('relu'))
model.add(Dropout(0.5))

model.add(Dense(10))
model.add(Activation('softmax')   

```
---------------------------------------------------------------------------
InvalidArgumentError                      Traceback (most recent call last)
/home/christopher/.local/lib/python3.5/site-packages/tensorflow/python/framework/common_shapes.py in call_cpp_shape_fn(op, input_tensors_needed, debug_python_shape_fn)
    593                                                              input_tensors,
--> 594                                                              status)
    595   except errors.InvalidArgumentError as err:

/opt/modules/python/anaconda3/lib/python3.5/contextlib.py in __exit__(self, type, value, traceback)
     65             try:
---> 66                 next(self.gen)
     67             except StopIteration:

/home/christopher/.local/lib/python3.5/site-packages/tensorflow/python/framework/errors.py in raise_exception_on_not_ok_status()
    462           compat.as_text(pywrap_tensorflow.TF_Message(status)),
--> 463           pywrap_tensorflow.TF_GetCode(status))
    464   finally:

InvalidArgumentError: Negative dimension size caused by subtracting 3 from 1
",cbonnett,b'stale',2017-01-10T11:04:31Z,2017-06-22T19:08:35Z
4958,Possible bug in sign function,"Hello, I'm trying to build a custom loss function that's using indicators. It seems that the sign function is broken and returns values other than -1,0,+1.

For example, the following function when used as a metric returns arbitrary values between 0 and 1.

def zubby: return 0.5 * (1 + K.sign(K.mean(y_pred-y_true)))

I'm using Python 3.5.2 with Keras 1.2.0 and TensorFlow 0.12.0 on 64-bit Windows 10.

Here's an example output:

batch_size= 5000  nb_epoch= 500
Train on 701728 samples, validate on 431685 samples
Epoch 1/500
6s - loss: 0.0485 - zubby: 0.5226 - val_loss: 0.0357 - val_zubby: 0.0000e+00
Epoch 2/500
5s - loss: 0.0240 - zubby: 0.4560 - val_loss: 0.0384 - val_zubby: 0.0000e+00
Epoch 3/500
5s - loss: 0.0209 - zubby: 0.4941 - val_loss: 0.0421 - val_zubby: 0.0000e+00
Epoch 4/500
5s - loss: 0.0191 - zubby: 0.4774 - val_loss: 0.0390 - val_zubby: 0.0000e+00
Epoch 5/500
5s - loss: 0.0181 - zubby: 0.4727 - val_loss: 0.0404 - val_zubby: 0.0000e+00
Epoch 6/500
5s - loss: 0.0174 - zubby: 0.4988 - val_loss: 0.0417 - val_zubby: 0.0000e+00
Epoch 7/500
5s - loss: 0.0167 - zubby: 0.4870 - val_loss: 0.0382 - val_zubby: 0.0000e+00
Epoch 8/500
5s - loss: 0.0163 - zubby: 0.4988 - val_loss: 0.0364 - val_zubby: 0.0116
Epoch 9/500
5s - loss: 0.0159 - zubby: 0.4988 - val_loss: 0.0422 - val_zubby: 0.0000e+00
Epoch 10/500
5s - loss: 0.0156 - zubby: 0.4703 - val_loss: 0.0394 - val_zubby: 0.0000e+00
Epoch 11/500
5s - loss: 0.0152 - zubby: 0.4703 - val_loss: 0.0408 - val_zubby: 0.0000e+00
Epoch 12/500
5s - loss: 0.0150 - zubby: 0.4870 - val_loss: 0.0389 - val_zubby: 0.0000e+00
Epoch 13/500
5s - loss: 0.0147 - zubby: 0.5725 - val_loss: 0.0407 - val_zubby: 0.0000e+00
Epoch 14/500
5s - loss: 0.0144 - zubby: 0.5130 - val_loss: 0.0398 - val_zubby: 0.0116
Epoch 15/500
5s - loss: 0.0143 - zubby: 0.4988 - val_loss: 0.0404 - val_zubby: 0.0000e+00
Epoch 16/500
5s - loss: 0.0140 - zubby: 0.4845 - val_loss: 0.0407 - val_zubby: 0.1042
Epoch 17/500
5s - loss: 0.0139 - zubby: 0.4845 - val_loss: 0.0398 - val_zubby: 0.0116
Epoch 18/500
5s - loss: 0.0137 - zubby: 0.4916 - val_loss: 0.0408 - val_zubby: 0.0000e+00
Epoch 19/500
5s - loss: 0.0135 - zubby: 0.4133 - val_loss: 0.0407 - val_zubby: 0.3514
Epoch 20/500
5s - loss: 0.0133 - zubby: 0.5012 - val_loss: 0.0403 - val_zubby: 0.1892
Epoch 21/500
5s - loss: 0.0133 - zubby: 0.4941 - val_loss: 0.0383 - val_zubby: 0.5135
Epoch 22/500
5s - loss: 0.0131 - zubby: 0.4941 - val_loss: 0.0408 - val_zubby: 0.2240",HackerzWorkshop,b'stale',2017-01-07T16:05:23Z,2017-06-22T19:08:27Z
4953,"loss is redefined, but get errors!","```
def simple_autoencode_test3p():
    input_size = max_features
    encoding_size = 1000

    x = Input(shape=(input_size,))
    z = Dense(encoding_size*2, activation='relu',name='z')(x)
    x_reconstruction = Dense(input_size, activation='sigmoid',name='reconstruction')(z)  
    
    out = Dense(1, activation='sigmoid', name='classification')(z)
    
    def ae_loss(x, out):
        xent_loss = objectives.binary_crossentropy(x, out)
        xrec_loss = objectives.binary_crossentropy(x, x_reconstruction)
        return xent_loss + xrec_loss

    test_model = Model(input=[x], output=[out])
    test_model.compile(optimizer='rmsprop',
                  loss = ae_loss, metrics=['accuracy'])   
    
    return test_model
```
`ae_loss` is the new definition of loss, including reconstruction loss and classification loss, as the final total loss, but return some errors!

```
ValueError: GpuElemwise. Input dimension mis-match. Input 2 (indices start at 0) has shape[1] == 1, but the output's size on that axis is 8000.
Apply node that caused the error: GpuElemwise{Composite{((i0 * log(i1)) + (i2 * log(i3)))},no_inplace}(GpuFromHost.0, GpuElemwise{clip,no_inplace}.0, GpuElemwise{sub,no_inplace}.0, GpuElemwise{sub,no_inplace}.0)
Toposort index: 76
Inputs types: [CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix)]
Inputs shapes: [(32, 1), (32, 8000), (32, 1), (32, 8000)]
Inputs strides: [(1, 0), (8000, 1), (1, 0), (8000, 1)]
Inputs values: ['not shown', 'not shown', 'not shown', 'not shown']
Outputs clients: [[GpuCAReduce{add}{0,1}(GpuElemwise{Composite{((i0 * log(i1)) + (i2 * log(i3)))},no_inplace}.0)]]

HINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.
HINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node. 
```",Imorton-zd,b'stale',2017-01-07T11:21:55Z,2017-06-22T19:08:25Z
4928,Support shape inference for Reshape layer,"This fixes #4916,  #4302 and probably #2487.

I wonder why the proposed shape inference tests in #1354 (see [here](https://github.com/fchollet/keras/pull/1354/files#diff-d18baa60672b585020f4939ef179ee21)) were removed later? That way unit tests would have detected the bug earlier.

thanks to @linxihui for the patch proposal

",faroit,None,2017-01-05T17:08:18Z,2017-01-06T17:23:23Z
4915,fixes #3859 clip_norm works with Embedding layer," - made clip_norm implementation backend-specific
 - it now works when gradients are TensorFlow IndexedSlices
 - added test to confirm that it works
 - code to reproduce the bug (small change from #3859's code because that had other bugs as well):
```
import numpy as np
from keras.layers import Input, Embedding
from keras.optimizers import Adam
from keras.models import Model

input_layer = Input(shape = (1,) )

embedding = Embedding(input_dim = 1,
                              output_dim = 1)(input_layer)

model = Model(input = input_layer, output = embedding)

model.compile(optimizer = Adam(clipnorm = 1.0), loss = 'mse')

X = np.array([[0]])
Y = np.array([[[0.5]]])
model.fit(X, Y, nb_epoch = 1)

```",kracwarlock,None,2017-01-04T21:47:31Z,2017-05-30T17:40:26Z
4863,bug in model.save() ,"Hi
i'm having a problem with using model.save or load_model. i ran this script using theano backend on mac os x 10.11.6 

```
import os
os.environ[""KERAS_BACKEND""] = ""theano""

from keras.models import Sequential, Model, load_model
from keras.layers import Convolution2D
from keras.layers import Dense, Dropout,Flatten,BatchNormalization,Reshape,Input, Activation,UpSampling2D
from keras.optimizers import *
from keras.datasets import mnist
from theano import tensor as T
import matplotlib.pyplot as plt
import numpy as np

g_opt = Adam(lr=1e-4)
noise_W = 4
noise_H = 4
BATCH_SIZE = 200
def build_gen1():

    inp_g = Input(shape=[noise_W*noise_H])

    #g = Dense(14, activation='relu')(inp_g)
    g = Dense(256 * 14 * 14)(inp_g)
    g = BatchNormalization(mode=2)(g)
    g = Activation('relu')(g)
    g = Reshape([256,14,14])(g)
    g = UpSampling2D(dim_ordering='th')(g)
    g = Convolution2D(123,3,3,border_mode='same',dim_ordering='th')(g)
    g = BatchNormalization(mode=2)(g)
    g = Activation('relu')(g)
    g = Convolution2D(61,3,3,border_mode='same',dim_ordering='th')(g)
    g = BatchNormalization(mode=2)(g)
    g = Activation('relu')(g)
    g_out = Convolution2D(1,1,1,activation='sigmoid',border_mode='same',dim_ordering='th')(g)

    return Model(inp_g, g_out)

gen = build_gen1()
gen.compile(loss='binary_crossentropy', optimizer=g_opt)
gen.summary()
gen.save(""ex_gen.h5"")

load_gen = load_model(""/Users/anastasia/PycharmProjects/pro/ex_gen.h5"")
load_gen.summary()
```
this is what returns gen.summary():

```
____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
input_2 (InputLayer)             (None, 16)            0                                            
____________________________________________________________________________________________________
dense_3 (Dense)                  (None, 50176)         852992      input_2[0][0]                    
____________________________________________________________________________________________________
batchnormalization_1 (BatchNorma (None, 50176)         200704      dense_3[0][0]                    
____________________________________________________________________________________________________
activation_1 (Activation)        (None, 50176)         0           batchnormalization_1[0][0]       
____________________________________________________________________________________________________
reshape_1 (Reshape)              (None, 256, 14, 14)   0           activation_1[0][0]               
____________________________________________________________________________________________________
upsampling2d_1 (UpSampling2D)    (None, 256, 28, 28)   0           reshape_1[0][0]                  
____________________________________________________________________________________________________
convolution2d_5 (Convolution2D)  (None, 123, 28, 28)   283515      upsampling2d_1[0][0]             
____________________________________________________________________________________________________
batchnormalization_2 (BatchNorma (None, 123, 28, 28)   112         convolution2d_5[0][0]            
____________________________________________________________________________________________________
activation_2 (Activation)        (None, 123, 28, 28)   0           batchnormalization_2[0][0]       
____________________________________________________________________________________________________
convolution2d_6 (Convolution2D)  (None, 61, 28, 28)    67588       activation_2[0][0]               
____________________________________________________________________________________________________
batchnormalization_3 (BatchNorma (None, 61, 28, 28)    112         convolution2d_6[0][0]            
____________________________________________________________________________________________________
activation_3 (Activation)        (None, 61, 28, 28)    0           batchnormalization_3[0][0]       
____________________________________________________________________________________________________
convolution2d_7 (Convolution2D)  (None, 1, 28, 28)     62          activation_3[0][0]               
====================================================================================================
Total params: 1,405,085
Trainable params: 1,304,621
Non-trainable params: 100,464
```
and this is ex_gen summary

```
____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
input_2 (InputLayer)             (None, 16)            0                                            
____________________________________________________________________________________________________
dense_3 (Dense)                  (None, 50176)         852992      input_2[0][0]                    
____________________________________________________________________________________________________
batchnormalization_1 (BatchNorma (None, 50176)         200704      dense_3[0][0]                    
____________________________________________________________________________________________________
activation_1 (Activation)        (None, 50176)         0           batchnormalization_1[0][0]       
____________________________________________________________________________________________________
reshape_1 (Reshape)              (None, 256, 14, 14)   0           activation_1[0][0]               
____________________________________________________________________________________________________
upsampling2d_1 (UpSampling2D)    (None, 512, 28, 14)   0           reshape_1[0][0]                  
____________________________________________________________________________________________________
convolution2d_5 (Convolution2D)  (None, 123, 28, 14)   283515      upsampling2d_1[0][0]             
____________________________________________________________________________________________________
batchnormalization_2 (BatchNorma (None, 123, 28, 14)   112         convolution2d_5[0][0]            
____________________________________________________________________________________________________
activation_2 (Activation)        (None, 123, 28, 14)   0           batchnormalization_2[0][0]       
____________________________________________________________________________________________________
convolution2d_6 (Convolution2D)  (None, 61, 28, 14)    67588       activation_2[0][0]               
____________________________________________________________________________________________________
batchnormalization_3 (BatchNorma (None, 61, 28, 14)    112         convolution2d_6[0][0]            
____________________________________________________________________________________________________
activation_3 (Activation)        (None, 61, 28, 14)    0           batchnormalization_3[0][0]       
____________________________________________________________________________________________________
convolution2d_7 (Convolution2D)  (None, 1, 28, 14)     62          activation_3[0][0]               
====================================================================================================
Total params: 1,405,085
Trainable params: 1,304,621
Non-trainable params: 100,464
____________________________________________________________________________________________________

```

it looks like model was saved with tensorflow backend instead of theano
Thanks",aurum408,None,2016-12-28T16:25:34Z,2017-04-01T21:51:24Z
4862,`K.int_shape` bug,"It looks like commit https://github.com/fchollet/keras/commit/2a3d4722c21d99d882b2cbc2da451108147fe1c4 introduced a bug in (at least) `examples/mnist_hierarchical_rnn.py`.  

Rolling back the commit fixes this problem, but I'm not sure whether this breaks something somewhere else.",bkj,b'stale',2016-12-28T15:30:38Z,2017-06-22T21:13:20Z
4855,Fix for Issue #4851,"I didn't catch when my original documentation was changed by @fchollet (overall for the better) but introducing this bug: https://github.com/fchollet/keras/issues/4851

My original docs only included the dimensions of the parameters (no batch dim) and were correct, but I think its better to change the functions to reflect the current docs.
My original docs were:
```
shared_axes: the axes along with to share parameters for
                      the activation function. For example if the
                      incoming feature maps from a 2D convolution
                      has dimensions 16x32x32 and you wish to share
                      parameters across space so that each feature
                      maps only has one set of parameters, set
                      shared_axes = [1, 2]
```",the-moliver,None,2016-12-27T16:54:54Z,2016-12-30T09:18:09Z
4812,"Pretrained_word_embeddings.py: inconsistency in `set_weights(weights)`  vs Provided weight at layer ""embedding_1""","I have downloaded the the raw code on  pretrained_word_embeddings.py to try out. I can't run it since the provided weight is not the same as the set weights, here is what I see, any way to fix this bug?

Using TensorFlow backend.
Indexing word vectors.
Found 400000 word vectors.
Processing text dataset
Found 19997 texts.
Found 214873 unique tokens.
Shape of data tensor: (19997, 1000)
Shape of label tensor: (19997, 20)
Preparing embedding matrix.
Training model.
Traceback (most recent call last):
  File ""[the path]/pretrained_word_embeddings.py"", line 126, in <module>
    embedded_sequences = embedding_layer(sequence_input)
  File ""/usr/local/lib/python3.5/dist-packages/keras/engine/topology.py"", line 543, in __call__
    self.build(input_shapes[0])
  File ""/usr/local/lib/python3.5/dist-packages/keras/layers/embeddings.py"", line 101, in build
    self.set_weights(self.initial_weights)
  File ""/usr/local/lib/python3.5/dist-packages/keras/engine/topology.py"", line 966, in set_weights
    str(weights)[:50] + '...')
ValueError: You called `set_weights(weights)` on layer ""embedding_1"" with a  weight list of length 1, but the layer was expecting 0 weights. Provided weights: [array([[ 0.        ,  0.        ,  0.        , .....",jeffreynghm,b'stale',2016-12-23T08:02:18Z,2019-02-25T17:30:41Z
4798,Can't do 'load_model' on custom loss function which uses tensor from out of the loss function,"Please make sure that the boxes below are checked before you submit your issue. If your issue is an implementation question, please ask your question on [StackOverflow](http://stackoverflow.com/questions/tagged/keras) or [join the Keras Slack channel](https://keras-slack-autojoin.herokuapp.com/) and ask there instead of filing a GitHub issue.

Thank you!

- [ x] Check that you are up-to-date with the master branch of Keras. You can update with:
pip install git+git://github.com/fchollet/keras.git --upgrade --no-deps

- [ ] If running on TensorFlow, check that you are up-to-date with the latest version. The installation instructions can be found [here](https://www.tensorflow.org/get_started/os_setup).

- [x ] If running on Theano, check that you are up-to-date with the master branch of Theano. You can update with:
pip install git+git://github.com/Theano/Theano.git --upgrade --no-deps

- [ x] Provide a link to a GitHub Gist of a Python script that can reproduce your issue (or just copy the script here if it is short).
gist codes : https://gist.github.com/calanchue/424cb03d3f205817e282249b4f1f50c6
Keras + theano + window

It is somewhat related to capability of the keras, I'm posting here.

What i try to do is that load and save variational autoencoder which is presented at example of the keras. I made little change for sampling to save the sampling layer(wrote arguments field). but except that, All other model things are intact.

But it gives me weird theano error(posted below). It seems that it can't find input tensor when it recreate model from saved file. After little experiments, my guess is that this bug comes from that vae_loss function use outer tensor which is not provided as the function input.  it seems that Keras can't find those tensor after load it. Other custom loss functions which only use only input tensor works fine.

Are there any way to load those kind of loss function with Keras? 

Error message when the code try to load
```
load
Traceback (most recent call last):

File ""<ipython-input-19-49e8c8795740>"", line 109, in <module>
vae_loaded = load_model(""test_vae"", custom_objects={""vae_loss"":vae_loss})

File ""C:\Users\user\Anaconda2\lib\site-packages\keras\models.py"", line 163, in load_model
model._make_train_function()

File ""C:\Users\user\Anaconda2\lib\site-packages\keras\engine\training.py"", line 723, in _make_train_function
**self._function_kwargs)

File ""C:\Users\user\Anaconda2\lib\site-packages\keras\backend\theano_backend.py"", line 787, in function
return Function(inputs, outputs, updates=updates, **kwargs)

File ""C:\Users\user\Anaconda2\lib\site-packages\keras\backend\theano_backend.py"", line 773, in __init__
**kwargs)

File ""C:\Users\user\Anaconda2\lib\site-packages\theano\compile\function.py"", line 322, in function
output_keys=output_keys)

File ""C:\Users\user\Anaconda2\lib\site-packages\theano\compile\pfunc.py"", line 480, in pfunc
output_keys=output_keys)

File ""C:\Users\user\Anaconda2\lib\site-packages\theano\compile\function_module.py"", line 1783, in orig_function
output_keys=output_keys).create(

File ""C:\Users\user\Anaconda2\lib\site-packages\theano\compile\function_module.py"", line 1435, in __init__
accept_inplace)

File ""C:\Users\user\Anaconda2\lib\site-packages\theano\compile\function_module.py"", line 176, in std_fgraph
update_mapping=update_mapping)

File ""C:\Users\user\Anaconda2\lib\site-packages\theano\gof\fg.py"", line 181, in __init__
self.__import_r__(output, reason=""init"")

File ""C:\Users\user\Anaconda2\lib\site-packages\theano\gof\fg.py"", line 376, in __import_r__
self.__import__(variable.owner, reason=reason)

File ""C:\Users\user\Anaconda2\lib\site-packages\theano\gof\fg.py"", line 418, in __import__
variable=r)

MissingInputError: An input of the graph, used to compute dot(input_12, HostFromGpu.0), was not provided and not given a value.Use the Theano flag exception_verbosity='high',for more information on this error.

Backtrace when the variable is created:
File ""C:\Users\user\Anaconda2\lib\site-packages\ipykernel\zmqshell.py"", line 501, in run_cell
return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)
File ""C:\Users\user\Anaconda2\lib\site-packages\IPython\core\interactiveshell.py"", line 2705, in run_cell
interactivity=interactivity, compiler=compiler, result=result)
File ""C:\Users\user\Anaconda2\lib\site-packages\IPython\core\interactiveshell.py"", line 2809, in run_ast_nodes
if self.run_code(code, result):
File ""C:\Users\user\Anaconda2\lib\site-packages\IPython\core\interactiveshell.py"", line 2869, in run_code
exec(code_obj, self.user_global_ns, self.user_ns)
File ""<ipython-input-19-49e8c8795740>"", line 23, in <module>
x = Input(batch_shape=(batch_size, original_dim))
File ""C:\Users\user\Anaconda2\lib\site-packages\keras\engine\topology.py"", line 1091, in Input
input_tensor=tensor)
File ""C:\Users\user\Anaconda2\lib\site-packages\keras\engine\topology.py"", line 1010, in __init__
name=self.name)
File ""C:\Users\user\Anaconda2\lib\site-packages\keras\backend\theano_backend.py"", line 84, in placeholder
x = T.TensorType(dtype, broadcast)(name)
```


It seems that it can't calculate ",calanchue,b'stale',2016-12-22T08:08:50Z,2018-05-10T05:20:08Z
4784,Accuracy not changing across the epochs,"`from keras import regularizers
from keras.layers import Input, Dense, Activation, Dropout
from keras.models import Model, Sequential
from keras.utils import np_utils
from keras.optimizers import SGD
import numpy
import pandas
from sklearn import preprocessing
from sklearn.model_selection import GridSearchCV
from keras.models import Sequential
from keras.layers import Dense

dataset = numpy.loadtxt(""Train.txt"", delimiter=""\t"")

# split into input (X) and output (Y) variables
X = dataset[:,0:106]
Y = dataset[:,106]

model = Sequential()
model.add(Dense(64, input_dim=106, init='uniform', activation='relu'))
model.add(Dense(32, init='uniform', activation='tanh'))
model.add(Dense(12, init='uniform', activation='relu'))
model.add(Dense(8, init='uniform', activation='sigmoid'))
model.add(Dense(1, init='uniform', activation='relu'))
# Compile model
optimizer = SGD(lr=0.0001, momentum=0.4)
model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])

# Fit the model
model.fit(X, Y, nb_epoch=100, batch_size=300, verbose=1)

# evaluate the model
scores = model.evaluate(X, Y, verbose=0)
print(""%s: %.2f%%"" % (model.metrics_names[1], scores[1]*100))
 
# serialize model to JSON
model_json = model.to_json()
with open(""model.json"", ""w"") as json_file:
    json_file.write(model_json)
# serialize weights to HDF5
model.save_weights(""model.h5"")
print(""Saved model to disk"")`


For the above training, the accuracy remains the same across all the epochs.
Using Theano backend.
DEBUG: nvcc STDOUT mod.cu
   Creating library D:/tmp/xyz/theano.NOBACKUP/compiledir_Windows-8.1-6.3.9600-Intel64

Using gpu device 0: Quadro K2200 (CNMeM is disabled, cuDNN not available)
DEBUG: nvcc STDOUT mod.cu
   Creating library D:/tmp/xyz/theano.NOBACKUP/compiledir_Windows-8.1-6.3.9600-Intel64

DEBUG: nvcc STDOUT mod.cu
   Creating library D:/tmp/xyz/theano.NOBACKUP/compiledir_Windows-8.1-6.3.9600-Intel64

DEBUG: nvcc STDOUT mod.cu
   Creating library D:/tmp/xyz/theano.NOBACKUP/compiledir_Windows-8.1-6.3.9600-Intel64

DEBUG: nvcc STDOUT mod.cu
   Creating library D:/tmp/xyz/theano.NOBACKUP/compiledir_Windows-8.1-6.3.9600-Intel64

DEBUG: nvcc STDOUT mod.cu
   Creating library D:/tmp/xyz/theano.NOBACKUP/compiledir_Windows-8.1-6.3.9600-Intel64

DEBUG: nvcc STDOUT mod.cu
   Creating library D:/tmp/xyz/theano.NOBACKUP/compiledir_Windows-8.1-6.3.9600-Intel64

DEBUG: nvcc STDOUT mod.cu
   Creating library D:/tmp/xyz/theano.NOBACKUP/compiledir_Windows-8.1-6.3.9600-Intel64

DEBUG: nvcc STDOUT mod.cu
   Creating library D:/tmp/xyz/theano.NOBACKUP/compiledir_Windows-8.1-6.3.9600-Intel64

DEBUG: nvcc STDOUT mod.cu
   Creating library D:/tmp/xyz/theano.NOBACKUP/compiledir_Windows-8.1-6.3.9600-Intel64

DEBUG: nvcc STDOUT mod.cu
   Creating library D:/tmp/xyz/theano.NOBACKUP/compiledir_Windows-8.1-6.3.9600-Intel64

DEBUG: nvcc STDOUT mod.cu
   Creating library D:/tmp/xyz/theano.NOBACKUP/compiledir_Windows-8.1-6.3.9600-Intel64

DEBUG: nvcc STDOUT mod.cu
   Creating library D:/tmp/xyz/theano.NOBACKUP/compiledir_Windows-8.1-6.3.9600-Intel64

DEBUG: nvcc STDOUT mod.cu
   Creating library D:/tmp/xyz/theano.NOBACKUP/compiledir_Windows-8.1-6.3.9600-Intel64

DEBUG: nvcc STDOUT mod.cu
   Creating library D:/tmp/xyz/theano.NOBACKUP/compiledir_Windows-8.1-6.3.9600-Intel64

DEBUG: nvcc STDOUT mod.cu
   Creating library D:/tmp/xyz/theano.NOBACKUP/compiledir_Windows-8.1-6.3.9600-Intel64

DEBUG: nvcc STDOUT mod.cu
   Creating library D:/tmp/xyz/theano.NOBACKUP/compiledir_Windows-8.1-6.3.9600-Intel64

DEBUG: nvcc STDOUT mod.cu
   Creating library D:/tmp/xyz/theano.NOBACKUP/compiledir_Windows-8.1-6.3.9600-Intel64

DEBUG: nvcc STDOUT mod.cu
   Creating library D:/tmp/xyz/theano.NOBACKUP/compiledir_Windows-8.1-6.3.9600-Intel64

DEBUG: nvcc STDOUT mod.cu
   Creating library D:/tmp/xyz/theano.NOBACKUP/compiledir_Windows-8.1-6.3.9600-Intel64

DEBUG: nvcc STDOUT mod.cu
   Creating library D:/tmp/xyz/theano.NOBACKUP/compiledir_Windows-8.1-6.3.9600-Intel64

DEBUG: nvcc STDOUT mod.cu
   Creating library D:/tmp/xyz/theano.NOBACKUP/compiledir_Windows-8.1-6.3.9600-Intel64

DEBUG: nvcc STDOUT mod.cu
   Creating library D:/tmp/xyz/theano.NOBACKUP/compiledir_Windows-8.1-6.3.9600-Intel64

DEBUG: nvcc STDOUT mod.cu
   Creating library D:/tmp/xyz/theano.NOBACKUP/compiledir_Windows-8.1-6.3.9600-Intel64

DEBUG: nvcc STDOUT mod.cu
   Creating library D:/tmp/xyz/theano.NOBACKUP/compiledir_Windows-8.1-6.3.9600-Intel64

DEBUG: nvcc STDOUT mod.cu
   Creating library D:/tmp/xyz/theano.NOBACKUP/compiledir_Windows-8.1-6.3.9600-Intel64

DEBUG: nvcc STDOUT mod.cu
   Creating library D:/tmp/xyz/theano.NOBACKUP/compiledir_Windows-8.1-6.3.9600-Intel64

DEBUG: nvcc STDOUT mod.cu
   Creating library D:/tmp/xyz/theano.NOBACKUP/compiledir_Windows-8.1-6.3.9600-Intel64

DEBUG: nvcc STDOUT mod.cu
   Creating library D:/tmp/xyz/theano.NOBACKUP/compiledir_Windows-8.1-6.3.9600-Intel64

DEBUG: nvcc STDOUT mod.cu
   Creating library D:/tmp/xyz/theano.NOBACKUP/compiledir_Windows-8.1-6.3.9600-Intel64

DEBUG: nvcc STDOUT mod.cu
   Creating library D:/tmp/xyz/theano.NOBACKUP/compiledir_Windows-8.1-6.3.9600-Intel64

DEBUG: nvcc STDOUT mod.cu
   Creating library D:/tmp/xyz/theano.NOBACKUP/compiledir_Windows-8.1-6.3.9600-Intel64

DEBUG: nvcc STDOUT mod.cu
   Creating library D:/tmp/xyz/theano.NOBACKUP/compiledir_Windows-8.1-6.3.9600-Intel64

DEBUG: nvcc STDOUT mod.cu
   Creating library D:/tmp/xyz/theano.NOBACKUP/compiledir_Windows-8.1-6.3.9600-Intel64

DEBUG: nvcc STDOUT mod.cu
   Creating library D:/tmp/xyz/theano.NOBACKUP/compiledir_Windows-8.1-6.3.9600-Intel64

DEBUG: nvcc STDOUT mod.cu
   Creating library D:/tmp/xyz/theano.NOBACKUP/compiledir_Windows-8.1-6.3.9600-Intel64

DEBUG: nvcc STDOUT mod.cu
   Creating library D:/tmp/xyz/theano.NOBACKUP/compiledir_Windows-8.1-6.3.9600-Intel64

Epoch 1/100
10131566/10131566 [==============================] - 338s - loss: 4.4380 - acc: 0.7247
Epoch 2/100
10131566/10131566 [==============================] - 341s - loss: 4.4380 - acc: 0.7247
Epoch 3/100
10131566/10131566 [==============================] - 340s - loss: 4.4380 - acc: 0.7247
Epoch 4/100
10131566/10131566 [==============================] - 350s - loss: 4.4380 - acc: 0.7247
Epoch 5/100
10131566/10131566 [==============================] - 343s - loss: 4.4380 - acc: 0.7247
Epoch 6/100
10131566/10131566 [==============================] - 336s - loss: 4.4380 - acc: 0.7247
Epoch 7/100
10131566/10131566 [==============================] - 346s - loss: 4.4380 - acc: 0.7247
Epoch 8/100
10131566/10131566 [==============================] - 349s - loss: 4.4380 - acc: 0.7247
Epoch 9/100
10131566/10131566 [==============================] - 345s - loss: 4.4380 - acc: 0.7247
Epoch 10/100
10131566/10131566 [==============================] - 345s - loss: 4.4380 - acc: 0.7247
Epoch 11/100
10131566/10131566 [==============================] - 349s - loss: 4.4380 - acc: 0.7247
Epoch 12/100
10131566/10131566 [==============================] - 349s - loss: 4.4380 - acc: 0.7247
Epoch 13/100
10131566/10131566 [==============================] - 344s - loss: 4.4380 - acc: 0.7247
Epoch 14/100
10131566/10131566 [==============================] - 341s - loss: 4.4380 - acc: 0.7247
Epoch 15/100
10131566/10131566 [==============================] - 344s - loss: 4.4380 - acc: 0.7247
Epoch 16/100
10131566/10131566 [==============================] - 344s - loss: 4.4380 - acc: 0.7247
Epoch 17/100
10131566/10131566 [==============================] - 353s - loss: 4.4380 - acc: 0.7247
Epoch 18/100
10131566/10131566 [==============================] - 349s - loss: 4.4380 - acc: 0.7247
Epoch 19/100
10131566/10131566 [==============================] - 343s - loss: 4.4380 - acc: 0.7247
Epoch 20/100
10131566/10131566 [==============================] - 272s - loss: 4.4380 - acc: 0.7247
Epoch 21/100
10131566/10131566 [==============================] - 270s - loss: 4.4380 - acc: 0.7247
Epoch 22/100
10131566/10131566 [==============================] - 268s - loss: 4.4380 - acc: 0.7247
Epoch 23/100
10131566/10131566 [==============================] - 269s - loss: 4.4380 - acc: 0.7247
Epoch 24/100
10131566/10131566 [==============================] - 270s - loss: 4.4380 - acc: 0.7247
Epoch 25/100
10131566/10131566 [==============================] - 269s - loss: 4.4380 - acc: 0.7247
Epoch 26/100
10131566/10131566 [==============================] - 268s - loss: 4.4380 - acc: 0.7247
Epoch 27/100
10131566/10131566 [==============================] - 270s - loss: 4.4380 - acc: 0.7247
Epoch 28/100
10131566/10131566 [==============================] - 268s - loss: 4.4380 - acc: 0.7247
Epoch 29/100
10131566/10131566 [==============================] - 270s - loss: 4.4380 - acc: 0.7247
Epoch 30/100
10131566/10131566 [==============================] - 271s - loss: 4.4380 - acc: 0.7247
Epoch 31/100
10131566/10131566 [==============================] - 268s - loss: 4.4380 - acc: 0.7247
Epoch 32/100
10131566/10131566 [==============================] - 274s - loss: 4.4380 - acc: 0.7247
Epoch 33/100
10131566/10131566 [==============================] - 268s - loss: 4.4380 - acc: 0.7247
Epoch 34/100
10131566/10131566 [==============================] - 272s - loss: 4.4380 - acc: 0.7247
Epoch 35/100
10131566/10131566 [==============================] - 271s - loss: 4.4380 - acc: 0.7247
Epoch 36/100
10131566/10131566 [==============================] - 271s - loss: 4.4380 - acc: 0.7247
Epoch 37/100
10131566/10131566 [==============================] - 342s - loss: 4.4380 - acc: 0.7247
Epoch 38/100
10131566/10131566 [==============================] - 337s - loss: 4.4380 - acc: 0.7247
Epoch 39/100
10131566/10131566 [==============================] - 336s - loss: 4.4380 - acc: 0.7247
Epoch 40/100
10131566/10131566 [==============================] - 351s - loss: 4.4380 - acc: 0.7247
Epoch 41/100
10131566/10131566 [==============================] - 387s - loss: 4.4380 - acc: 0.7247
Epoch 42/100
10131566/10131566 [==============================] - 388s - loss: 4.4380 - acc: 0.7247
Epoch 43/100
10131566/10131566 [==============================] - 364s - loss: 4.4380 - acc: 0.7247

.. this remains the same till 100 epochs?",KushalDave,b'stale',2016-12-21T06:41:53Z,2017-06-22T21:13:10Z
4780,K.set_session() doesn't work on using Keras as part of a TensorFlow workflow,"Hi, 

Following the workflow [Keras as a simplified interface to TensorFlow: tutorial](https://blog.keras.io/keras-as-a-simplified-interface-to-tensorflow-tutorial.html)

When I try to run this code:
```
import tensorflow as tf
from keras import backend as K
from keras.layers import Dense
from keras.objectives import categorical_crossentropy
from tensorflow.examples.tutorials.mnist import input_data

sess = tf.Session()
K.set_session(sess)

img = tf.placeholder(tf.float32, shape=(None, 784))
labels = tf.placeholder(tf.float32, shape=(None, 10))

x = Dense(128, activation='relu')(img)
x = Dense(128, activation='relu')(x)
preds = Dense(10, activation='softmax')(x)

loss = tf.reduce_mean(categorical_crossentropy(labels, preds))

mnist_data = input_data.read_data_sets('MNIST_data', one_hot=True)

train_step = tf.train.GradientDescentOptimizer(0.5).minimize(loss)

#sess.run(tf.global_variables_initializer())

with sess.as_default():
    for i in range(100):
        batch = mnist_data.train.next_batch(50)
        train_step.run(feed_dict={img: batch[0],
                                  labels: batch[1]})
```
I got the error:
```
tensorflow.python.framework.errors_impl.FailedPreconditionError: Attempting to use uninitialized value dense_1_W
```

If I uncomment `sess.run(tf.global_variables_initializer())`, it works.

So, I think the error is caused because of `K.set_session(sess)` not working.
Is this the bug or just the miss? 

Thank you!
",makora9143,b'stale',2016-12-21T02:05:11Z,2019-11-23T05:39:28Z
4725,K.switch works with Theano backend but not Tensorflow,"Hello,

I am implementing a layer in Keras. It is working for Theano but when I test it with a Tensorflow backend, it breaks on the following line:

`k = K.switch(is_up, phi/on_mid, K.switch(is_down, (on_end-phi)/on_mid, off_slope*phi))`

The line is part of a` def step() `function of a layer inheriting from the `Recurrent` class.

The error is:
```
/Users/Francesco/anaconda/lib/python2.7/site-packages/tensorflow/python/framework/common_shapes.pyc in _call_cpp_shape_fn_impl(op, input_tensors_needed, input_tensors_as_shapes_needed, debug_python_shape_fn, require_shape_fn)
    673       missing_shape_fn = True
    674     else:
--> 675       raise ValueError(err.message)
    676 
    677   if missing_shape_fn:

ValueError: Shape must be rank 0 but is rank 2 for 'while_2/cond/Switch' (op: 'Switch') with input shapes: [?,10], [?,10].
```

Any ideas? I am not very familiar with Tensorflow.

Best,
Francesco",fferroni,b'stale',2016-12-15T09:44:35Z,2017-06-22T23:13:17Z
4697,"BatchNormalization layer fails when using Theano back-end together with ""tf"" image dimension ordering.","Hi,

I don't know whether I'm supposed to use Theano back-end together with the ""tf"" image dimension ordering, the BatchNormalization layer will fail in this case.

It will pass the shape check when building the network, and `modal.summary()` will give the correct shape like

```
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
convolution2d_1 (Convolution2D)  (20, 98, 98, 32)      896         convolution2d_input_1[0][0]      
____________________________________________________________________________________________________
batchnormalization_1 (BatchNorma (20, 98, 98, 32)      128         convolution2d_1[0][0]            
____________________________________________________________________________________________________
activation_1 (Activation)        (20, 98, 98, 32)      0           batchnormalization_1[0][0]       
____________________________________________________________________________________________________
convolution2d_2 (Convolution2D)  (20, 96, 96, 64)      18496       activation_1[0][0]               
```

but Theano will give the following error when running

```
ValueError: GpuDnnConv images and kernel must have the same stack size

Apply node that caused the error: GpuDnnConv{algo='time_once', inplace=True}(GpuContiguous.0, GpuContiguous.0, GpuAllocEmpty.0, GpuDnnConvDesc{border_mode='valid', subsample=(1, 1), conv_mode='conv', precision='float32'}.0, Constant{1.0}, Constant{0.0})
Toposort index: 707
Inputs types: [CudaNdarrayType(float32, 4D), CudaNdarrayType(float32, 4D), CudaNdarrayType(float32, 4D), <theano.gof.type.CDataType object at 0x7f59985c7c10>, Scalar(float32), Scalar(float32)]
Inputs shapes: [(20, 98, 32, 98), (64, 32, 3, 3), (20, 64, 30, 96), 'No shapes', (), ()]
Inputs strides: [(307328, 3136, 98, 1), (288, 9, 3, 1), (184320, 2880, 96, 1), 'No strides', (), ()]
Inputs values: ['not shown', 'not shown', 'not shown', <PyCObject object at 0x7f59827fa378>, 1.0, 0.0]
Inputs name: ('image', 'kernel', 'output', 'descriptor', 'alpha', 'beta')

Outputs clients: [[GpuDimShuffle{0,2,3,1}(GpuDnnConv{algo='time_once', inplace=True}.0)]]

HINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.
HINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.
```

Here're some code snippets

```python
{
    ""image_dim_ordering"": ""tf"", 
    ""epsilon"": 1e-07, 
    ""floatx"": ""float32"", 
    ""backend"": ""theano""
}
...

img_rows, img_cols, im_chnls = 100, 100, 3
input_shape = (img_rows, img_cols, im_chnls)
bn_axis = -1
...

x = Input(shape=input_shape)
y = Convolution2D(32, kernel_size[0], kernel_size[1], border_mode='valid')(x)
y = BatchNormalization(axis=bn_axis)(y)
y = Activation('relu')(y)
y = Convolution2D(64, kernel_size[0], kernel_size[1], border_mode='valid')(y)
y = BatchNormalization(axis=bn_axis)(y)
y = Activation('relu')(y)
y = MaxPooling2D(pool_size=pool_size)(y)
...

model = Model(x, y)
model.compile(loss='categorical_crossentropy',
              optimizer=Adam(lr=0.001, decay=1e-5),
              metrics=['accuracy'])
model.summary()
...
```
Best regards",dontloo,None,2016-12-13T12:29:52Z,2017-02-05T09:29:59Z
4694,examples/mnist_swwae.py tensorflow support,"- [x] Check that you are up-to-date with the master branch of Keras. You can update with:
pip install git+git://github.com/fchollet/keras.git --upgrade --no-deps

- [x] If running on Theano,... (I'm running on tensorflow)

- [x] Provide a link to a GitHub Gist of a Python script that can reproduce your issue (or just copy the script here if it is short).


I successfully ran `python mnist_cnn.py` from 7e2e7a5e5a43443122df0b497f88dd77fd3bfc7c on my GTX1080 with a TensorFlow R0.12rc0 backend. I then ran `python mnist_swwae.py` and got the following failure:

```bash
~/src/keras/examples on master
± python mnist_swwae.py
Using TensorFlow backend.
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcublas.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcudnn.so.5 locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcufft.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcurand.so.8.0 locally
X_train shape: (60000, 1, 28, 28)
60000 train samples
10000 test samples
Traceback (most recent call last):
  File ""mnist_swwae.py"", line 136, in <module>
    y = MaxPooling2D(pool_size=(pool_sizes[i], pool_sizes[i]))(y_prepool)
  File ""/usr/local/lib/python2.7/dist-packages/Keras-1.1.2-py2.7.egg/keras/engine/topology.py"", line 517, in __call__
    self.add_inbound_node(inbound_layers, node_indices, tensor_indices)
  File ""/usr/local/lib/python2.7/dist-packages/Keras-1.1.2-py2.7.egg/keras/engine/topology.py"", line 571, in add_inbound_node
    Node.create_node(self, inbound_layers, node_indices, tensor_indices)
  File ""/usr/local/lib/python2.7/dist-packages/Keras-1.1.2-py2.7.egg/keras/engine/topology.py"", line 155, in create_node
    output_tensors = to_list(outbound_layer.call(input_tensors[0], mask=input_masks[0]))
  File ""/usr/local/lib/python2.7/dist-packages/Keras-1.1.2-py2.7.egg/keras/layers/pooling.py"", line 158, in call
    dim_ordering=self.dim_ordering)
  File ""/usr/local/lib/python2.7/dist-packages/Keras-1.1.2-py2.7.egg/keras/layers/pooling.py"", line 207, in _pooling_function
    border_mode, dim_ordering, pool_mode='max')
  File ""/usr/local/lib/python2.7/dist-packages/Keras-1.1.2-py2.7.egg/keras/backend/tensorflow_backend.py"", line 1853, in pool2d
    x = tf.nn.max_pool(x, pool_size, strides, padding=padding)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/nn_ops.py"", line 1617, in max_pool
    name=name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_nn_ops.py"", line 1598, in _max_pool
    data_format=data_format, name=name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py"", line 759, in apply_op
    op_def=op_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 2242, in create_op
    set_shapes_for_outputs(ret)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 1617, in set_shapes_for_outputs
    shapes = shape_func(op)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 1568, in call_with_requiring
    return call_cpp_shape_fn(op, require_shape_fn=True)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/common_shapes.py"", line 610, in call_cpp_shape_fn
    debug_python_shape_fn, require_shape_fn)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/common_shapes.py"", line 675, in _call_cpp_shape_fn_impl
    raise ValueError(err.message)
ValueError: Negative dimension size caused by subtracting 2 from 1 for 'MaxPool' (op: 'MaxPool') with input shapes: [?,1,32,8].
-> [1]
```

Help or feedback from anyone is welcome, @antonmbk you may be interested in this because you contributed the example. Thanks!",ahundt,b'type:bug/performance',2016-12-13T03:08:02Z,2017-03-29T17:31:51Z
4693,bug in pool2d,"The padding size in `pool2d` is problematic in the sense that  the pixels before and after pooling is NOT aligned.

Below is the code to decide the padding size of `pool2d`
```
def pool2d(x, pool_size, strides=(1, 1), border_mode='valid', dim_ordering='default', pool_mode='max'):
    if dim_ordering == 'default':
        dim_ordering = image_dim_ordering()
    if dim_ordering not in {'th', 'tf'}:
        raise Exception('Unknown dim_ordering ' + str(dim_ordering))
    assert pool_size[0] >= 1 and pool_size[1] >= 1

    if border_mode == 'same':
        w_pad = pool_size[0] - 2 if pool_size[0] > 2 and pool_size[0] % 2 == 1 else pool_size[0] - 1
        h_pad = pool_size[1] - 2 if pool_size[1] > 2 and pool_size[1] % 2 == 1 else pool_size[1] - 1
        padding = (w_pad, h_pad)
```
This setting of `w_pad` and `h_pad` works OK if `strides = pool_size`, but cause a center-shift if `strides = (1,1)`. Below is a fix to ensure the pixels before and after pooling are aligned.
```
        w_pad = pool_size[0] // 2
        h_pad = pool_size[1] // 2
```


",rex-yue-wu,b'stale',2016-12-13T02:05:29Z,2017-06-22T20:10:20Z
4689,Possible bug with shared batch normalization + sequential model? [Script inside],"When trying to share batch normalization layers, it looks like you can't use the sequential container as a function. For example, when `crash` is False in the following script, it runs fine. Otherwise, you get a theano/tensorflow error about variable naming.

```
import numpy as np
from keras.layers import Input, Dropout
from keras.layers.normalization import BatchNormalization
from keras.models import Sequential, Model

crash = True

x = np.random.normal(loc=5.0, scale=10.0, size=(2, 10))

x1 = Input(shape=(10,))
x2 = Input(shape=(10,))

# Test within sequential model
seq = Sequential()
if crash:
    seq.add(BatchNormalization(input_shape = (10,)))
if not crash:
    seq.add(Dropout(.5, input_shape = (10,)))
y3 = seq(x1)
y4 = seq(x2)

model = Model([x1,x2], [y3,y4])
model.compile('sgd','mse')
model.train_on_batch([x,x],[x,x])
```

For tensorflow the error is:
```
ValueError: Variable batchnormalization_1_running_mean/biased already exists, disallowed. Did you mean to set reuse=True in VarScope?
```
For theano the error is:
```
ValueError: ('this shared variable already has an update expression', (batchnormalization_1_running_mean, Elemwise{add,no_inplace}.0))
```

- [x] Check that you are up-to-date with the master branch of Keras. You can update with:
pip install git+git://github.com/fchollet/keras.git --upgrade --no-deps

- [x] If running on Theano, check that you are up-to-date with the master branch of Theano. You can update with:
pip install git+git://github.com/Theano/Theano.git --upgrade --no-deps

- [x] Provide a link to a GitHub Gist of a Python script that can reproduce your issue (or just copy the script here if it is short).",jmhessel,None,2016-12-12T20:01:44Z,2018-02-27T06:04:44Z
4683,Fix for issue #4640: Bug in theano_backend for _Pooling1D,"MaxPooling1D with border_mode='same' caused `h_pad` to take illegal value -1 in theano_backend:pool2d.
Added test case.",sunil-at-gh,None,2016-12-11T21:43:55Z,2016-12-12T22:08:04Z
4655,"ValueError: GpuReshape: cannot reshape input of shape (1472, 1000) to shape (1, 1000, 1000)","https://github.com/baidu-research/ba-dls-deepspeech

I was trying to train the model here for speech recognition. It runs fine when I train it using just a CPU, but gives the above error on GPU.

<img width=""979"" alt=""b6c9a140-bc94-11e6-9553-c36871e347a0"" src=""https://cloud.githubusercontent.com/assets/6660192/21033979/6ff34d10-bdda-11e6-91dc-a97a0b5949c6.png"">

Am I doing something wrong? Or is it a bug?",singlasahil14,b'stale',2016-12-09T01:11:25Z,2017-11-24T08:37:07Z
4640,Bug in theano_backend for _Pooling1D?,"From **_Pooling1D** subclasses, **K.pool2d** is called with `pool_size = (pool_length, 1)`.
In **theano_backend.pool2d**, when `border_mode = ""same""`, the following line:

`h_pad = pool_size[1] - 2 if pool_size[1] % 2 == 1 else pool_size[1] - 1`

causes h_pad to get the value -1, which results in the following error on my machine:

> WARNING: probably bad CudaNdarray_set_dim arguments: self->ndim=4, idx=3 stride=-1
> Traceback (most recent call last):
>  File ""/opt/anaconda3/lib/python3.5/site-packages/theano/compile/function_module.py"", line 866, in __call__
>    self.fn() if output_subset is None else\
> AssertionError: Can't store in size_t for the bytes requested 18446744073709551615 * 4

I believe the correct value for `h_pad` in this case is `0`, suggesting the following fix:

`h_pad = pool_size[1] - 2 if pool_size[1] > 2 and pool_size[1] % 2 == 1 else pool_size[1] - 1`


Please make sure that the boxes below are checked before you submit your issue. Thank you!

- [x] Check that you are up-to-date with the master branch of Keras. You can update with:
pip install git+git://github.com/fchollet/keras.git --upgrade --no-deps

- [x] If running on Theano, check that you are up-to-date with the master branch of Theano. You can update with:
pip install git+git://github.com/Theano/Theano.git --upgrade --no-deps

- [ ] Provide a link to a GitHub Gist of a Python script that can reproduce your issue (or just copy the script here if it is short).",sunil-at-gh,b'stale',2016-12-08T04:03:30Z,2017-06-22T20:10:11Z
4632,fixed bug in tensorflow dot when multiple dims are dynamic,"fixed failure at `K.dot` when `shape(x) = (None, None, 9)` (could appear in `recurrent`).",linxihui,None,2016-12-07T17:50:32Z,2016-12-19T22:20:29Z
4609,from keras import backend -- fails when reloading model,"When keras models using backend are saved, the json (de)serialization cannot find ""backend"". This may be due to the use of the Lambda layer, as it appears that the name ""backend"" is saved in the json and then the loader cannot find it (because ""backend"" is not in its namespace). If it is imported as ""K"", then it works properly, because the loader imports backend as K. 

Possible Quick Fix: Update the documentation both in backend and Lambda that backend *must* be imported as ""K"". The current doc only has a note under backend, and seems to be just a suggestion: ""You can import the backend module via: from keras import backend as K"". Given standard python convention, it is unintuitive that ""from keras import backend"", ""import keras.backend"", or ""from keras import backend as somethingelse"" should function differently. 
    Another workaround is to have the user add ""from keras import backend"" in their user-defined Lambda function.

Best,
David

Here's a script that demonstrates working and non-working cases. 
theano.__version__ = '0.9.0dev4.dev-ad1310c88830ed96119194c4f2da22b9b37c7622'
keras.__version__ = '1.1.2'
```
from keras import backend as K
from keras.layers.convolutional import Convolution1D
from keras.layers import Lambda, Dense
from keras.models import Sequential, model_from_json

print 'Works'
model = Sequential()
model.add(Convolution1D(nb_filter=128, filter_length=5, input_shape=(4096, 16), border_mode='same', activation='relu'))
model.add(Lambda(lambda x: K.sum(x, axis=1), output_shape=(128,)))
model.add(Dense(10, activation='sigmoid'))
model.compile(loss='binary_crossentropy', optimizer='Nadam')
model2 = model_from_json(model.to_json())

from keras import backend

print 'Fails'
model = Sequential()
model.add(Convolution1D(nb_filter=128, filter_length=5, input_shape=(4096, 16), border_mode='same', activation='relu'))
model.add(Lambda(lambda x: backend.sum(x, axis=1), output_shape=(128,)))
model.add(Dense(10, activation='sigmoid'))
model.compile(loss='binary_crossentropy', optimizer='Nadam')
model2 = model_from_json(model.to_json())
```

The second model load fails with this stack trace:
```
Traceback (most recent call last):
  File ""keras_bug.py"", line 23, in <module>
    model2 = model_from_json(model.to_json())
  File ""/Users/davidslater/.virtualenvs/davidslater/lib/python2.7/site-packages/keras/models.py"", line 209, in model_from_json
    return layer_from_config(config, custom_objects=custom_objects)
  File ""/Users/davidslater/.virtualenvs/davidslater/lib/python2.7/site-packages/keras/utils/layer_utils.py"", line 34, in layer_from_config
    return layer_class.from_config(config['config'])
  File ""/Users/davidslater/.virtualenvs/davidslater/lib/python2.7/site-packages/keras/models.py"", line 1061, in from_config
    model.add(layer)
  File ""/Users/davidslater/.virtualenvs/davidslater/lib/python2.7/site-packages/keras/models.py"", line 324, in add
    output_tensor = layer(self.outputs[0])
  File ""/Users/davidslater/.virtualenvs/davidslater/lib/python2.7/site-packages/keras/engine/topology.py"", line 517, in __call__
    self.add_inbound_node(inbound_layers, node_indices, tensor_indices)
  File ""/Users/davidslater/.virtualenvs/davidslater/lib/python2.7/site-packages/keras/engine/topology.py"", line 571, in add_inbound_node
    Node.create_node(self, inbound_layers, node_indices, tensor_indices)
  File ""/Users/davidslater/.virtualenvs/davidslater/lib/python2.7/site-packages/keras/engine/topology.py"", line 155, in create_node
    output_tensors = to_list(outbound_layer.call(input_tensors[0], mask=input_masks[0]))
  File ""/Users/davidslater/.virtualenvs/davidslater/lib/python2.7/site-packages/keras/layers/core.py"", line 592, in call
    return self.function(x, **arguments)
  File ""keras_bug.py"", line 20, in <lambda>
    model.add(Lambda(lambda x: backend.sum(x, axis=1), output_shape=(128,)))
NameError: global name 'backend' is not defined
```

---
Please make sure that the boxes below are checked before you submit your issue. Thank you!

- [X] Check that you are up-to-date with the master branch of Keras. You can update with:
pip install git+git://github.com/fchollet/keras.git --upgrade --no-deps

- [X] If running on Theano, check that you are up-to-date with the master branch of Theano. You can update with:
pip install git+git://github.com/Theano/Theano.git --upgrade --no-deps

- [X] Provide a link to a GitHub Gist of a Python script that can reproduce your issue (or just copy the script here if it is short).
",davidslater,b'stale',2016-12-05T16:42:01Z,2020-06-10T19:17:41Z
4584,Keras Programmer Guide for Dummies - anyone interested in helping write one?,"Hi,

The documentation for keras is very good and helps a lot if one is using existing layers and tools.  There are also a lot of examples on how to piece those tools together to reproduce larger nets and different kinds of nets.  I am a dummy however and am having difficulty in finding step by step explanations (not just instructions) of how to write custom classes.  fchollet in the slack group said some of the things I want to do are easy in keras and yet I can't find examples of them, some posts say one of them (change number of filters in a conv net during training) are not possible, and it is not clear where certain changes should be made (thankfully patyork is pointing me to regularizers in another post for changing weights).

It would be nice to have more of a programmers guide and not just a users guide for writing custom objects with explanations of even things like what order the optimizations/regularizations/objectives/callbacks/metrics are calculated, what the limits are of each, and most importantly, how to debug and follow data through them on the fly.

Maybe I've missed some resources but I can't find that level of detail.

Is there such a guide out there and if not is there any interest in developing one?

Please make sure that the boxes below are checked before you submit your issue. Thank you!

- [x ] Check that you are up-to-date with the master branch of Keras. You can update with:
pip install git+git://github.com/fchollet/keras.git --upgrade --no-deps

- [ x] If running on Theano, check that you are up-to-date with the master branch of Theano. You can update with:
pip install git+git://github.com/Theano/Theano.git --upgrade --no-deps

- [ x] Provide a link to a GitHub Gist of a Python script that can reproduce your issue (or just copy the script here if it is short).",mustgoplay,None,2016-12-03T16:03:46Z,2016-12-03T19:29:02Z
4583,Bug fix: InputLayer is ignoring _keras_shape,"`Input()` is asking for `input_shape` even if a Keras tensor is provided as input tensor.
",farizrahman4u,None,2016-12-03T10:40:03Z,2017-06-03T00:27:30Z
4576,Cannot stack models in Model Class API,"I cannot stack a classifier model on top of a (partly) pre-trained VGG16 model in Model Class API. There are several threads with people having the same problem [Google Groups](https://groups.google.com/forum/#!topic/keras-users/szAvryNqHqU) and [StackoverFlow](http://stackoverflow.com/questions/40277327/keras-connecting-functional-api-models-together). I have tried all variants, but I keep getting a Graph disconnect error: 

> Exception: Graph disconnected: cannot obtain value for tensor input_2 at layer ""

My last attempt:
```
from keras.applications.vgg16 import VGG16
from keras.models import Model
from keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D
from keras.layers import Dropout, Flatten, Dense, Input

img_width, img_height = 150, 150

input_1 = Input(shape=(3, img_width, img_height))

vgg16_model = VGG16(include_top=False, weights='imagenet', input_tensor=input_1)

input_2 = Input(shape=vgg16_model.output_shape[1:])
x = GlobalAveragePooling2D()(input_2)
x = Dense(256, activation='relu')(x)
x = Dropout(0.5)(x)
predict = Dense(1, activation='sigmoid')(x)
top_model = Model(input=input_2, output=predict)

# load the best saved weights
#top_model.load_weights(os.path.join(data_path, 'VGG16Classifier.hdf5'))  
# add the model on top of the convolutional base

model = Model(input=input_1, output=top_model.output)
```
For info I am trying to re-create this [Keras Blog](https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html) , but with the Model Class API in order to later modify the VGG16 model.
Is there a bug that is preventing this from working? Thanks, Jan

Oh, and I am totally thrilled about Keras!!! Really impressive!",jdelange,None,2016-12-02T15:50:01Z,2016-12-04T18:00:13Z
4570,"Backwards LSTM + Embedding + Mask + Tensorflow backend produces ""ValueError: Shape must be rank 2 but is rank 3 for 'Reverse' (op: 'Reverse') with input shapes:"" ","When I create a model that contains an Embedding layer with masking and a backwards LSTM and using the Tensorflow backend, I get the following error: 

> ValueError: Shape must be rank 2 but is rank 3 for 'Reverse' (op: 'Reverse') with input shapes: [3,2,40], [2].


I've created a [gist](https://gist.github.com/stefanthaler/6120be321431cb8506429d4c635d530b) that reproduces the error. 

I suspect it has something to do with these two lines in the tensorflow_backend.py, where one time ndim-1 is used and the other time ndim-2 is used.   
https://github.com/fchollet/keras/blob/master/keras/backend/tensorflow_backend.py#L1248
https://github.com/fchollet/keras/blob/master/keras/backend/tensorflow_backend.py#L1273

The complete stacktrace is:

 > File ""stateful_lstm_embedding_butg.py"", line 18, in <module>
    model.add(LSTM(10,  batch_input_shape=(batch_size,time_steps,embedding_size), return_sequences=False, go_backwards=True))
  File ""/usr/local/lib/python2.7/dist-packages/keras/models.py"", line 324, in add
    output_tensor = layer(self.outputs[0])
  File ""/usr/local/lib/python2.7/dist-packages/keras/engine/topology.py"", line 517, in __call__
    self.add_inbound_node(inbound_layers, node_indices, tensor_indices)
  File ""/usr/local/lib/python2.7/dist-packages/keras/engine/topology.py"", line 571, in add_inbound_node
    Node.create_node(self, inbound_layers, node_indices, tensor_indices)
  File ""/usr/local/lib/python2.7/dist-packages/keras/engine/topology.py"", line 155, in create_node
    output_tensors = to_list(outbound_layer.call(input_tensors[0], mask=input_masks[0]))
  File ""/usr/local/lib/python2.7/dist-packages/keras/layers/recurrent.py"", line 227, in call
    input_length=input_shape[1])
  File ""/usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py"", line 1249, in rnn
    inputs = tf.reverse(inputs, [True] + [False] * (ndim - 2))
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_array_ops.py"", line 2513, in reverse
    name=name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py"", line 759, in apply_op
    op_def=op_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 2242, in create_op
    set_shapes_for_outputs(ret)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 1617, in set_shapes_for_outputs
    shapes = shape_func(op)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 1568, in call_with_requiring
    return call_cpp_shape_fn(op, require_shape_fn=True)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/common_shapes.py"", line 610, in call_cpp_shape_fn
    debug_python_shape_fn, require_shape_fn)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/common_shapes.py"", line 675, in _call_cpp_shape_fn_impl
    raise ValueError(err.message)
ValueError: Shape must be rank 2 but is rank 3 for 'Reverse' (op: 'Reverse') with input shapes: [3,2,40], [2].


",stefanthaler,None,2016-12-01T16:08:52Z,2018-02-22T09:51:50Z
4569,GPU initialization error with subprocesses depending on location of keras import,"I get an error

```
Error when trying to find the memory information on the GPU: initialization error
Error allocating 8 bytes of device memory (initialization error). Driver report 0 bytes free and 0 bytes total
```

when I try to execute this python script

```
from keras.layers import Input

def main_theano():
    import theano
    import theano.tensor as T
    import numpy as np

    x = T.matrix()
    f = theano.function(inputs=[x], outputs=T.mean(x))
    print f(np.random.rand(3, 3))

def main_keras():
    #from keras.layers import Input
    ip = Input((32, ))

from multiprocessing import Process

# runs ok
p = Process(target=main_theano)
p.start()
p.join()

# throws exception
p = Process(target=main_keras)
p.start()
p.join()
```

on my Ubuntu 16.04 machine with GeForce GTX TITAN X gpu device using the following command line command:

```
THEANO_FLAGS=device=gpu python script.py
```

Interestingly, if I move import of input layer (`from keras.layers import Input`) inside the 'main_keras' function, gpu initialization error disappears. It seems as if keras or modules it imports acquires some resources in the main script process, which cannot be used then in created subprocesses. 

Could you reproduce the error? If so, is this intended behavior or a bug?

I checked to be up-to-date with keras and theano.",iaroslav-ai,None,2016-12-01T15:23:26Z,2016-12-01T16:20:28Z
4562,Load weight mismatch,"This reports the layer, where the mismatch is, so the user can debug it
more easily.",jlombacher,None,2016-12-01T08:58:35Z,2017-03-15T21:42:12Z
4556,Multiple layers variational autoencoder,"I modified the example from the documentation for variational autoencoder in the website:

https://blog.keras.io/building-autoencoders-in-keras.html, 

hoping to use more layers. 

But it completely doesn't work with theano backend, and works with batch size 1 wiht tensorflow and throw out errors with batch size larger than 1. Here is the code:

```
from keras.models import Model
from keras.layers import Input, Dense, Activation, Lambda
import numpy as np
from keras import backend as K
from keras.datasets import mnist
from keras.callbacks import ModelCheckpoint

batch_size =1 
original_dim = 784 

n_h1 = 300
n_h2 = 50
n_z = 10
epsilon_std = 1.0
nb_epoch = 100

x = Input(shape=(original_dim,))
h = Dense(n_h1, activation='relu')(x)
h = Dense(n_h2, activation='relu')(h)

z_mean = Dense(n_z)(h)
z_log_sigma = Dense(n_z)(h)


def sampling(args):
    z_mean, z_log_sigma = args
    epsilon = K.random_normal(K.shape(z_mean),
                              mean=0., std=epsilon_std)
    return z_mean + K.exp(z_log_sigma) * epsilon

z = Lambda(sampling, output_shape=(n_z,))([z_mean, z_log_sigma])

d = Dense(n_h2, activation='relu')(z)
d = Dense(n_h1, activation='relu')(d)
x_decoded_mean = Dense(original_dim, activation='sigmoid')(d)

# end-to-end autoencoder
vae = Model(x, x_decoded_mean)

# encoder, from inputs to latent space
encoder = Model(x, z_mean)

def vae_loss(x, x_decoded_mean):
    xent_loss = K.binary_crossentropy(x, x_decoded_mean)
    kl_loss = - 0.5 * K.mean(1 + z_log_sigma - K.square(z_mean) - K.exp(z_log_sigma), axis=-1)
    return xent_loss + kl_loss

vae.compile(optimizer='rmsprop', loss=vae_loss)

(x_train, y_train), (x_test, y_test) = mnist.load_data()

x_train = x_train.astype('float32') / 255.
x_test = x_test.astype('float32') / 255.
x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))
x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))


model_path = ""weights.hdf5""
checkpointer = ModelCheckpoint(filepath=model_path, verbose=1)

vae.fit(x_train, x_train,
        shuffle=True,
        nb_epoch=nb_epoch,
        batch_size=batch_size,
        validation_data=(x_test, x_test),
        callbacks=[checkpointer])
```

The error info with theano backend is:
```
Using Theano backend.
Train on 60000 samples, validate on 10000 samples
Epoch 1/100
Traceback (most recent call last):
  File ""variational_autoencoder_v2.py"", line 66, in <module>
    callbacks=[checkpointer])
  File ""/usr/local/lib/python2.7/dist-packages/keras/engine/training.py"", line 1111, in fit
    initial_epoch=initial_epoch)
  File ""/usr/local/lib/python2.7/dist-packages/keras/engine/training.py"", line 826, in _fit_loop
    outs = f(ins_batch)
  File ""/usr/local/lib/python2.7/dist-packages/keras/backend/theano_backend.py"", line 811, in __call__
    return self.function(*inputs)
  File ""/usr/local/lib/python2.7/dist-packages/theano/compile/function_module.py"", line 886, in __call__
    storage_map=getattr(self.fn, 'storage_map', None))
  File ""/usr/local/lib/python2.7/dist-packages/theano/gof/link.py"", line 325, in raise_with_op
    reraise(exc_type, exc_value, exc_trace)
  File ""/usr/local/lib/python2.7/dist-packages/theano/compile/function_module.py"", line 873, in __call__
    self.fn() if output_subset is None else\
ValueError: Input dimension mis-match. (input[0].shape[1] = 784, input[4].shape[1] = 1)
Apply node that caused the error: Elemwise{Composite{((-((i0 * i1) + (i2 * i3))) + i4)}}(Elemwise{Composite{scalar_sigmoid((i0 + i1))}}[(0, 0)].0, Elemwise{log,no_inplace}.0, Elemwise{sub,no_inplace}.0, Elemwise{Composite{log1p((-i0))}}[(0, 0)].0, Elemwise{Composite{(i0 * (i1 / i2))}}[(0, 1)].0)
Toposort index: 96
Inputs types: [TensorType(float32, matrix), TensorType(float32, matrix), TensorType(float32, matrix), TensorType(float32, matrix), TensorType(float32, row)]
Inputs shapes: [(1, 784), (1, 784), (1, 784), (1, 784), (1, 1)]
Inputs strides: [(3136, 4), (3136, 4), (3136, 4), (3136, 4), (4, 4)]
Inputs values: ['not shown', 'not shown', 'not shown', 'not shown', array([[ 0.16387774]], dtype=float32)]
Outputs clients: [[Sum{axis=[1], acc_dtype=float64}(Elemwise{Composite{((-((i0 * i1) + (i2 * i3))) + i4)}}.0)]]

HINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.
HINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.
```

Could anyone help me out? Thanks!





Please make sure that the boxes below are checked before you submit your issue. Thank you!

- [X ] Check that you are up-to-date with the master branch of Keras. You can update with:
pip install git+git://github.com/fchollet/keras.git --upgrade --no-deps

- [ X] If running on Theano, check that you are up-to-date with the master branch of Theano. You can update with:
pip install git+git://github.com/Theano/Theano.git --upgrade --no-deps

- [X ] Provide a link to a GitHub Gist of a Python script that can reproduce your issue (or just copy the script here if it is short).",ruanxt,None,2016-11-30T21:54:53Z,2016-12-01T01:06:45Z
4542,"calling MaxoutDense layer on (None,512)-shaped tensor fails on tensorflow CPU (but works with theano)","I have a Dropout layer that produces an output of shape `(None,512)`.
I can create a MaxoutDense layer:
`md = keras.layers.MaxoutDense(32,4, W_regularizer=keras.regularizers.WeightRegularizer(l1,l2))`

But when I call it on the tensor of my Dropout layer:

`md_t = md(drop1)`

then it fails with

`Expected int32, got None of type '_Message' instead.`

The full stack trace:

`  File "".../src/networks.py"", line 117, in NetworkBuilder
    md_t = md(drop1)
  File "".../venv35/lib/python3.5/site-packages/keras/engine/topology.py"", line 517, in __call__
    self.add_inbound_node(inbound_layers, node_indices, tensor_indices)
  File "".../venv35/lib/python3.5/site-packages/keras/engine/topology.py"", line 571, in add_inbound_node
    Node.create_node(self, inbound_layers, node_indices, tensor_indices)
  File "".../venv35/lib/python3.5/site-packages/keras/engine/topology.py"", line 155, in create_node
    output_tensors = to_list(outbound_layer.call(input_tensors[0], mask=input_masks[0]))
  File "".../venv35/lib/python3.5/site-packages/keras/layers/core.py"", line 934, in call
    output = K.dot(x, self.W)
  File "".../venv35/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py"", line 380, in dot
    xt = tf.reshape(x, [-1, x_shape[-1]])
  File "".../venv35/lib/python3.5/site-packages/tensorflow/python/ops/gen_array_ops.py"", line 1383, in reshape
    name=name)
  File "".../venv35/lib/python3.5/site-packages/tensorflow/python/ops/op_def_library.py"", line 455, in apply_op
    as_ref=input_arg.is_ref)
  File "".../venv35/lib/python3.5/site-packages/tensorflow/python/framework/ops.py"", line 620, in convert_to_tensor
    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
  File "".../venv35/lib/python3.5/site-packages/tensorflow/python/ops/constant_op.py"", line 179, in _constant_tensor_conversion_function
    return constant(v, dtype=dtype, name=name)
  File "".../venv35/lib/python3.5/site-packages/tensorflow/python/ops/constant_op.py"", line 162, in constant
    tensor_util.make_tensor_proto(value, dtype=dtype, shape=shape))
  File "".../venv35/lib/python3.5/site-packages/tensorflow/python/framework/tensor_util.py"", line 353, in make_tensor_proto
    _AssertCompatible(values, dtype)
  File "".../venv35/lib/python3.5/site-packages/tensorflow/python/framework/tensor_util.py"", line 290, in _AssertCompatible
    (dtype.name, repr(mismatch), type(mismatch).__name__))
TypeError: Expected int32, got None of type '_Message' instead.`


This exception is only thrown with the TensorFlow backend, but not with Theano. I tested it on CPU only (because that machine doesn't have a supported GPU yet)

The exception is meaningless to me. I'm not blocked because I can work with Theano backend for now, but it looks like a bug nevertheless.",michaelosthege,b'stale',2016-11-29T14:30:57Z,2017-06-22T20:11:01Z
4522,Fix Bidirectional Compute Mask Issue,"Use the `compute_mask` function to compute the bidirectional masks
Fix bug when wrapper the custom layers which have special processing on `compute_mask`",KaidongYu,None,2016-11-28T08:09:23Z,2017-03-15T21:42:05Z
4513,Bug fix: model.summary is ignoring model.trainable,,farizrahman4u,None,2016-11-27T00:07:36Z,2017-06-03T00:27:31Z
4504,merge function with Lambda appears to produce wrong ndim,"I defined the following merge:

```python
def MatchScore(left, right):
    return merge(
        [left, right],
        mode=lambda l_r:
            1. /
            (
                1. +
                K.sqrt(K.dot(l_r[0], l_r[0].T) - 2. * K.dot(l_r[0], l_r[1].T) + K.dot(l_r[1], l_r[1].T))
            ),
        output_shape=(left._keras_shape[1], right._keras_shape[1])
    )

# calling like this:
left_input = Input(shape=(left_seq_len,))
right_input = Input(shape=(right_seq_len,))
left_embed = Embedding(input_dim=vocab_size, output_dim=embed_dimensions, dropout=dropout)(left_input)
right_embed = Embedding(input_dim=vocab_size, output_dim=embed_dimensions, dropout=dropout)(right_input)

match_score = MatchScore(left_embed, right_embed)
```

This should compute a score based on pairwise euclidean distances of the rows of two matrices, thus have output shape (num_samples_left, num_samples_right) as manually specified in the output_shape argument - however, Keras gives the resulting TensorVariable an `ndim` of 4, this it's not compatible with e.g. a TimeDistributed(Dense(...)) as expected.

Is this a possible bug in Keras or am I missing something?

EDIT: Okay, seems that this is Theano doing this, not Keras, and that the output of that lambda really is 4-dimensional (forgot about the num_samples dimension). I guess my question now becomes: how can I use Keras to ""broadcast"" the above function for each sample in my two inputs?",phdowling,None,2016-11-25T08:43:44Z,2016-11-25T19:38:41Z
4502,Bug Fix : Sequential model is ignoring trainable argument of child containers,"Found this issue while writing a vanilla GAN: Discriminator weights are changing even when trainable=False. Issue only when the final model is Sequential. 

```python
discriminator = Sequential()
discriminator.add(Dense(1, input_dim=10, activation='sigmoid'))

generator = Sequential()
generator.add(Dense(10, input_dim=10))

GAN = Sequential()
GAN.add(generator)

discriminator.trainable = False

GAN.add(discriminator)
GAN.compile(loss='mse', optimizer='sgd')

x = np.random.random((100, 10))
y = np.ones((100, 1))

discriminator_initial_weights = discriminator.get_weights()
GAN.fit(x, y)
assert np.all(discriminator.get_weights()[0] == discriminator_initial_weights[0]), 'Discriminator weights changed!'
```",farizrahman4u,None,2016-11-25T04:22:23Z,2016-11-25T19:23:22Z
4486,"ImageDataGenerator's load_img() forcing conversion to PIL mode ""L"" loses bit depth on 16bit grayscale .png","Please make sure that the boxes below are checked before you submit your issue. Thank you!

- [X ] Check that you are up-to-date with the master branch of Keras. You can update with:
pip install git+git://github.com/fchollet/keras.git --upgrade --no-deps

- [ X] If running on Theano, check that you are up-to-date with the master branch of Theano. You can update with:
pip install git+git://github.com/Theano/Theano.git --upgrade --no-deps

- [X ] Provide a link to a GitHub Gist of a Python script that can reproduce your issue (or just copy the script here if it is short).

### Summary:
I believe it would be helpful to allow toggling off of the forced conversion to 8bit: 
```python
def load_img(path, grayscale=False, target_size=None):
    from PIL import Image
    img = Image.open(path)
    if grayscale:
        img = img.convert('L')
    else:  # Ensure 3 channel even when loaded image is grayscale
        img = img.convert('RGB')
    return img
```
This is causing issues with, in my case, higher depth 16bit, grayscale images. And in the future, I can only imagine images getting more complex as processing power and the complexity demand size grows.

### Expected behavior: 
```python
from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img

img = Image.open('./toy/foo.png')  # this image is 16bit grayscale, PIL.Image autoloads as mode ""I"" 
#img = load_img('./toy/foo.png')  # keras hardcodes PIL.Image.convert to mode ""L"", which is acting as a low-pass filter, truncating all values above 255
x = img_to_array(img)  # this is a Numpy array with shape (101, 101, 3)
x
```
Clearly, the values are quite diverse. 
```
array([[[ 26947.],
        [ 26367.],
        [ 26429.],
        ..., 
        [ 38390.],
        [ 40277.],
        [ 39516.]],

       [[ 27135.],
        [ 27470.],
        [ 26532.],
        ..., 
        [ 39014.],
        [ 39567.],
        [ 39516.]],

       [[ 27723.],
        [ 27323.],
        [ 26781.],
        ..., 
        [ 39972.],
        [ 39491.],
        [ 39063.]],

       ..., 
       [[ 27533.],
        [ 28660.],
        [ 28660.],
        ..., 
        [ 42340.],
        [ 41147.],
        [ 41948.]],

       [[ 27893.],
        [ 27744.],
        [ 29005.],
        ..., 
        [ 42521.],
        [ 41457.],
        [ 41250.]],

       [[ 27914.],
        [ 26532.],
        [ 27366.],
        ..., 
        [ 43681.],
        [ 41897.],
        [ 40684.]]], dtype=float32)
```

### BUG: 
```python
from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img

#img = Image.open('./toy/foo.png')  # this image is 16bit grayscale, PIL.Image autoloads as mode ""I"" 
img = load_img('./toy/foo.png')  # keras hardcodes PIL.Image.convert to mode ""L"", which is acting as a low-pass filter, truncating all values above 255
x = img_to_array(img)  # this is a Numpy array with shape (101, 101, 3)
x
```
Now, the values are all ""whitened""
```
array([[[ 255.,  255.,  255.],
        [ 255.,  255.,  255.],
        [ 255.,  255.,  255.],
        ..., 
        [ 255.,  255.,  255.],
        [ 255.,  255.,  255.],
        [ 255.,  255.,  255.]],

       [[ 255.,  255.,  255.],
        [ 255.,  255.,  255.],
        [ 255.,  255.,  255.],
        ..., 
        [ 255.,  255.,  255.],
        [ 255.,  255.,  255.],
        [ 255.,  255.,  255.]],

       [[ 255.,  255.,  255.],
        [ 255.,  255.,  255.],
        [ 255.,  255.,  255.],
        ..., 
        [ 255.,  255.,  255.],
        [ 255.,  255.,  255.],
        [ 255.,  255.,  255.]],

       ..., 
       [[ 255.,  255.,  255.],
        [ 255.,  255.,  255.],
        [ 255.,  255.,  255.],
        ..., 
        [ 255.,  255.,  255.],
        [ 255.,  255.,  255.],
        [ 255.,  255.,  255.]],

       [[ 255.,  255.,  255.],
        [ 255.,  255.,  255.],
        [ 255.,  255.,  255.],
        ..., 
        [ 255.,  255.,  255.],
        [ 255.,  255.,  255.],
        [ 255.,  255.,  255.]],

       [[ 255.,  255.,  255.],
        [ 255.,  255.,  255.],
        [ 255.,  255.,  255.],
        ..., 
        [ 255.,  255.,  255.],
        [ 255.,  255.,  255.],
        [ 255.,  255.,  255.]]], dtype=float32)
```

### Sample images
illustrating the difference between de facto `load_img()` behavior and manually calling `PIL.open()`, letting it stick with mode ""I"". 

```python
from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img
datagen = ImageDataGenerator(
        rotation_range=40,
        width_shift_range=0.2,
        height_shift_range=0.2,
        shear_range=0.2,
        zoom_range=0.2,
        horizontal_flip=True,
        fill_mode='nearest')
#img = Image.open('./toy/foo.png')  # this image is 16bit grayscale, PIL.Image autoloads as mode ""I"" 
img = load_img('./toy/foo.png')  # keras hardcodes PIL.Image.convert to mode ""L"" 8bit, which is acting as a low-pass filter, truncating all values above 255
x = img_to_array(img)  # this is a Numpy array with shape (101, 101, 3)
i = 0
for batch in datagen.flow(x, batch_size=1, save_to_dir='./toy', save_prefix='bug', save_format='png'):
    i += 1
    if i > 20:
        break
```
Original image:  
![foo](https://cloud.githubusercontent.com/assets/20694664/20558173/cbd08c24-b13c-11e6-88ef-dc9b8f2d6248.png) 
Expected ImageDataGenerator sample:
![foo_0_277](https://cloud.githubusercontent.com/assets/20694664/20558186/dbe77bcc-b13c-11e6-99d4-59d66dc7086a.png) 
Actual ImageDataGenerator:
![bug_0_439](https://cloud.githubusercontent.com/assets/20694664/20558192/e079028c-b13c-11e6-846d-cdc6ba9e60b2.png)
",jfx319,None,2016-11-23T10:33:48Z,2019-02-21T09:19:41Z
4464,does keras support array broadcasting?,"i'm writing custom elementwise multiplication layers in keras using theano backend with GPU computing. i found that broadcasting rules supported by numpy are not supported by keras. for example:
numpy supports:   numpy.random.random(1,25,26)*numpy.random.random(3,25,26) ->output shape: (3,25,26)
but in keras custom layer, i can't do that in this structure:
input layer:  shape ->(3,25,26)
custom layer:  do elementwise multiplication :   w×input       where w's shape is (1,25,26)

can anyone knows is this a bug or limitation of keras theano backend?as i mentioned in #4454 
many thanks!



Please make sure that the boxes below are checked before you submit your issue. Thank you!

- [ ] Check that you are up-to-date with the master branch of Keras. You can update with:
pip install git+git://github.com/fchollet/keras.git --upgrade --no-deps

- [ ] If running on Theano, check that you are up-to-date with the master branch of Theano. You can update with:
pip install git+git://github.com/Theano/Theano.git --upgrade --no-deps

- [ ] Provide a link to a GitHub Gist of a Python script that can reproduce your issue (or just copy the script here if it is short).",cbdbdd,b'stale',2016-11-22T11:33:54Z,2017-11-27T21:16:13Z
4454,seems to be a bug when using merge layer,"i made a elementwise multiplication merge layer with shape (10,2) as the last layer, where the input layer shape is (10,2), the reshape layer shape is (10,1). following is the code which works fine.
`
import numpy as np

from keras.layers import  Reshape, merge,Input,Flatten,Dense
from keras.models import Model
inputs = Input(shape=(10,2),name='input')
x = Flatten()(inputs)
x = Dense(10*1,activation='sigmoid',name='dense')(x)
x = Reshape((10,1),name='reshape')(x)
y =  merge([ inputs,x],  mode=lambda x: x[0] * x[1],output_shape=lambda x:x[1],name='merge')#, output_shape=lambda x: x[0]
mo=Model(input=inputs,output=y)
mo.summary()
mo.predict(np.random.random((1,10,2)))`

but if i switch the shape of the input and the reshape layer, i.e. change the input layer shape to (10,1), and the reshape layer shape to (10,1),maintaining the elementwise multiplication merge layer with shape (10,2) as the last layer, issues generated as follows:
ValueError: GpuElemwise. Output dimension mis-match. Output 0 (indices start at 0), working inplace on input 0, has shape[2] == 1, but the output's size on that axis is 2.
code is:
`inputs = Input(shape=(10,1),name='input')

x = Flatten()(inputs)
x = Dense(10*2,activation='sigmoid',name='dense')(x)
x = Reshape((10,2),name='reshape')(x)
y =  merge([ inputs,x],  mode=lambda x: x[0] * x[1],output_shape=lambda x:x[1],name='merge')#, output_shape=lambda x: x[0]
mo=Model(input=inputs,output=y)
mo.summary()
mo.predict(np.random.random((1,10,1)))`

anybody knows the problem ? is this a bug since the only change is the switching of shapes of the two layers.@fchollet",cbdbdd,b'stale',2016-11-21T13:59:31Z,2017-06-23T00:11:39Z
4453,"Memory allocation bug - 250k parameters runs ok, 25k parameters crashes.","Memory allocation seems pretty arbitrary. I am able to train a network with 250k parameters no problem, and another with 25k parameters hangs (for a looong time) and eventually crashes. They are tested on the same data. Here are the two implementations:

The 25k parameter model:

```
def dense_gradient_model(X_train, y_train, epochs=5000):
    n_samples, n_timesteps, n_feat = X_train.shape
    main_input = Input(shape=(n_timesteps, n_feat), name='main_input')
    lstms_1 = [Bidirectional(LSTM(2, return_sequences=True))(main_input) for _ in range(20)]
    lstms_2 = [Bidirectional(LSTM(2, return_sequences=True))(lstm_1) for lstm_1 in lstms_1]
    merge_l = merge(lstms_2, mode='concat')
    outputs = TimeDistributed(Dense(7))(merge_l)
    model = Model(input=main_input, output=outputs)
    model.compile(optimizer='rmsprop', loss='mse')
    history = model.fit(X_train, y_train, nb_epoch=epochs, 
        validation_split=0.1)
    return history, model
```

And here is the 250k parameter model:

```
def dense_gradient_model(X_train, y_train, epochs=5000):
    n_samples, n_timesteps, n_feat = X_train.shape
    main_input = Input(shape=(n_timesteps, n_feat), name='main_input')
    lstm_1 = Bidirectional(LSTM(80, return_sequences=True))(main_input)
    lstm_2 = Bidirectional(LSTM(80, return_sequences=True))(lstm_1)
    outputs = TimeDistributed(Dense(7))(lstm_2)
    model = Model(input=main_input, output=outputs)
    model.compile(optimizer='rmsprop', loss='mse')
    history = model.fit(X_train, y_train, nb_epoch=epochs, 
        validation_split=0.1)
    return history, model
```

The smaller model gives the following error:

```
Problem occurred during compilation with the command line below:
/usr/bin/g++ -shared -g -O3 -fno-math-errno -Wno-unused-label -Wno-unused-variable -Wno-write-strings -march=core-avx2 -mcx16 -msahf -mmovbe -maes -mpclmul -mpopcnt -mabm -mno-lwp -mfma -mno-fma4 -mno-xop -mbmi -mbmi2 -mno-tbm -mavx -mavx2 -msse4.2 -msse4.1 -mlzcnt -mno-rtm -mno-hle -mrdrnd -mf16c -mfsgsbase -mno-rdseed -mno-prfchw -mno-adx -mfxsr -mxsave -mxsaveopt --param l1-cache-size=32 --param l1-cache-line-size=64 --param l2-cache-size=3072 -mtune=core-avx2 -DNPY_NO_DEPRECATED_API=NPY_1_7_API_VERSION -m64 -fPIC -I/home/hristo/mlenv/local/lib/python2.7/site-packages/numpy/core/include -I/usr/include/python2.7 -I/home/hristo/mlenv/local/lib/python2.7/site-packages/theano/gof -L/usr/lib -fvisibility=hidden -o /home/hristo/.theano/compiledir_Linux-3.19--generic-x86_64-with-Ubuntu-14.04-trusty-x86_64-2.7.6-64/tmpD8_C2b/268803646968696c28ad22885423a5e1.so /home/hristo/.theano/compiledir_Linux-3.19--generic-x86_64-with-Ubuntu-14.04-trusty-x86_64-2.7.6-64/tmpD8_C2b/mod.cpp -lpython2.7
ERROR (theano.gof.cmodule): [Errno 12] Cannot allocate memory
ERROR (theano.gof.opt): Optimization failure due to: constant_folding
ERROR (theano.gof.opt): node: MakeVector{dtype='int64'}(TensorConstant{4}, TensorConstant{4}, TensorConstant{4}, TensorConstant{4}, TensorConstant{4}, TensorConstant{4}, TensorConstant{4}, TensorConstant{4}, TensorConstant{4}, TensorConstant{4}, TensorConstant{4}, TensorConstant{4}, TensorConstant{4}, TensorConstant{4}, TensorConstant{4}, TensorConstant{4}, TensorConstant{4}, TensorConstant{4}, TensorConstant{4}, TensorConstant{4})
ERROR (theano.gof.opt): TRACEBACK:
ERROR (theano.gof.opt): Traceback (most recent call last):
  File ""/home/hristo/mlenv/local/lib/python2.7/site-packages/theano/gof/opt.py"", line 1922, in process_node
    replacements = lopt.transform(node)
  File ""/home/hristo/mlenv/local/lib/python2.7/site-packages/theano/tensor/opt.py"", line 6387, in constant_folding
    no_recycling=[], impl=impl)
  File ""/home/hristo/mlenv/local/lib/python2.7/site-packages/theano/gof/op.py"", line 924, in make_thunk
    no_recycling)
  File ""/home/hristo/mlenv/local/lib/python2.7/site-packages/theano/gof/op.py"", line 828, in make_c_thunk
    output_storage=node_output_storage)
  File ""/home/hristo/mlenv/local/lib/python2.7/site-packages/theano/gof/cc.py"", line 1190, in make_thunk
    keep_lock=keep_lock)
  File ""/home/hristo/mlenv/local/lib/python2.7/site-packages/theano/gof/cc.py"", line 1131, in __compile__
    keep_lock=keep_lock)
  File ""/home/hristo/mlenv/local/lib/python2.7/site-packages/theano/gof/cc.py"", line 1589, in cthunk_factory
    key=key, lnk=self, keep_lock=keep_lock)
  File ""/home/hristo/mlenv/local/lib/python2.7/site-packages/theano/gof/cmodule.py"", line 1155, in module_from_key
    module = lnk.compile_cmodule(location)
  File ""/home/hristo/mlenv/local/lib/python2.7/site-packages/theano/gof/cc.py"", line 1492, in compile_cmodule
    preargs=preargs)
  File ""/home/hristo/mlenv/local/lib/python2.7/site-packages/theano/gof/cmodule.py"", line 2301, in compile_str
    p_out = output_subprocess_Popen(cmd)
  File ""/home/hristo/mlenv/local/lib/python2.7/site-packages/theano/misc/windows.py"", line 77, in output_subprocess_Popen
    p = subprocess_Popen(command, **params)
  File ""/home/hristo/mlenv/local/lib/python2.7/site-packages/theano/misc/windows.py"", line 43, in subprocess_Popen
    proc = subprocess.Popen(command, startupinfo=startupinfo, **params)
  File ""/usr/lib/python2.7/subprocess.py"", line 710, in __init__
    errread, errwrite)
  File ""/usr/lib/python2.7/subprocess.py"", line 1223, in _execute_child
    self.pid = os.fork()
OSError: [Errno 12] Cannot allocate memory

```

- [x] Check that you are up-to-date with the master branch of Keras. You can update with:
pip install git+git://github.com/fchollet/keras.git --upgrade --no-deps

- [x] If running on Theano, check that you are up-to-date with the master branch of Theano. You can update with:
pip install git+git://github.com/Theano/Theano.git --upgrade --no-deps

- [x] Provide a link to a GitHub Gist of a Python script that can reproduce your issue (or just copy the script here if it is short).",HristoBuyukliev,b'stale',2016-11-21T13:51:37Z,2017-06-23T00:11:29Z
4441,Bugfix: K.rnn() is ignoring theano.scan() updates,"Currently, `K.rnn()` is ignoring `theano.scan()` `updates`.
This should not be ignored.
If you ignore this, you cannot use random numbers inside `K.rnn()`.

What I modified:

1. Add the 4th return value to `K.rnn()`. This is `theano.scan()` `updates`. But this change breaks compatibility.
2. Add `updates` argument to `K.eval()`.
3. Add `rnn_updates` to `Layer`. I split `updates` and `rnn_updates` because `rnn_updates` needs for training, testing and predicting phase. `Recurrent` and `TimeDistributed` uses `K.rnn()`, and I passed `updates` to `Layer.add_rnn_updates()`.

By this fix, I can run this code on Theano.
`TimeDistributed` uses `K.rnn()` and `Dropout` uses random numbers.

```python
import numpy as np
from keras.layers import Input, TimeDistributed, Dropout
from keras.models import Model

x = Input(batch_shape=(1, 1, 1))
y = TimeDistributed(Dropout(0.5))(x)
model = Model(input=[x], output=[y])
model.compile(optimizer=""sgd"", loss=""mse"")
model.fit(np.zeros([1, 1, 1], np.float32), np.zeros([1, 1, 1], np.float32), batch_size=1)
```


",yukoba,None,2016-11-20T08:57:27Z,2016-11-24T07:04:45Z
4440,fit_generator/flow_from_directory shape bug,"When I run the code in the link at the bottom of this post I get the following error:
Exception: Error when checking model input: expected input_1 to have shape (None, 3, 227, 227) but got array with shape (32, 3, 277, 277)

I specified batch_size=32 in flow_from_directory so fit_generator shouldn't expect 'None' as the batch size. 

I tried changing line 48 from:
inputs = Input(shape=(3,227,227))
to:
inputs = Input(batch_shape=(32,3,227,227))

If I do this I get the following error:
Exception: Error when checking model input: expected input_2 to have shape (32, 3, 227, 227) but got array with shape (32, 3, 277, 277)

This looks like a bug.

Could there be a problem with the way fit_generator reads batch info from the flow_from_directory generator?

I have updated Keras and Theano to the newest releases.


https://gist.github.com/ssieges/61952bf5f0071cc4c8bf23515fc440cc
",snsie,None,2016-11-20T03:41:58Z,2016-11-20T22:27:11Z
4427,Small hack for instantiating a layer from its configuration using layer_from_config.,"Hello,

I'm working with Keras 1.1.1 with python 2.7 on ubuntu 14.04.

According to the documentation [here](https://keras.io/layers/about-keras-layers/), the following snippet should instantiate a layer from its configuration.

```python
from keras.models import Sequential
from keras.layers import Dense
from keras.utils.layer_utils import layer_from_config

model = Sequential()
model.add(Dense(output_dim=64, input_dim=100))

config = model.layers[0].get_config()
layer = layer_from_config(config)
```


However, I the following error



```python 
---------------------------------------------------------------------------
KeyError                                  Traceback (most recent call last)
<ipython-input-4-4a5a56c3cd16> in <module>()
      7 
      8 config = model.layers[0].get_config()
----> 9 layer = layer_from_config(config)
     10 
     11 # config_correct = {}

/home/rahul/anaconda2/lib/python2.7/site-packages/keras/utils/layer_utils.pyc in layer_from_config(config, custom_objects)
     23         globals()[cls_key] = custom_objects[cls_key]
     24 
---> 25     class_name = config['class_name']
     26 
     27     if class_name == 'Sequential':

KeyError: 'class_name'
```


After spending some hours debugging, here is how I got around this issue.



```python
from keras.models import Sequential
from keras.layers import Dense
from keras.utils.layer_utils import layer_from_config

model = Sequential()
model.add(Dense(output_dim=64, input_dim=100))

config = model.layers[0].get_config()
config_correct = {}
config_correct['class_name'] = type(model.layers[0])
config_correct['config'] = config
layer_correct = layer_from_config(config_correct)
```

It would be easier to update this in the documentation meanwhile the get_config method is corrected for every layer type.

Thanks,
Rahul Duggal",duggalrahul,b'stale',2016-11-18T18:06:31Z,2017-06-23T00:11:23Z
4426,Bugfix: Don't add another header line to CSV logfile when appending to an existing file,"Currently when using the `CSVLogger` callback with `append=True`, at the beginning of a new training run which appends to an existing file the header file will be rewritten to the output

e.g. if training is resumed after epoch 2, the output would be:

```
epoch,categorical_accuracy,loss,val_categorical_accuracy,val_loss
0,0.130208333333,2.32610692581,0.154399999142,2.26858918381
1,0.173394097222,2.17767716779,0.196799999881,2.10534226418
2,0.186197916667,2.07855245802,0.177600000429,2.06805825005
epoch,categorical_accuracy,loss,val_categorical_accuracy,val_loss
3,0.201605902778,2.03062710166,0.199999999762,2.03451372261
4,0.204427083333,1.96939406792,0.229799997854,1.94915147133
```

This PR prevents the writing of the additional header line in the middle of the CSV file, so the output is instead:

```
epoch,categorical_accuracy,loss,val_categorical_accuracy,val_loss
0,0.130208333333,2.32610692581,0.154399999142,2.26858918381
1,0.173394097222,2.17767716779,0.196799999881,2.10534226418
2,0.186197916667,2.07855245802,0.177600000429,2.06805825005
3,0.201605902778,2.03062710166,0.199999999762,2.03451372261
4,0.204427083333,1.96939406792,0.229799997854,1.94915147133
```",kencoken,None,2016-11-18T17:44:09Z,2016-11-25T22:49:50Z
4425,Keras: How to know the network model being currently used is what I intend?,"I modified the LSTM architecture a little bit in the recurrent.py and then save it as recurrent_m1.py. Then I import the modified LSTM for my work as follows:

     from keras.layers.recurrent_m1 import LSTM 

Run the training code using the modified LSTM as follows:
 
    model.add(LSTM())   #I omit the contents in the ()
    model.fit()  #I have omitted some other irrelevant codes for creating a sequential model

Training the model does not show much difference from that using the original LSTM. So I am wondering if the model is really implementing the modified LSTM in the recurrent_m1.py.

I want to know some debug ways to show that the program being running is implementing the modified LSTM class? I have tried to add some print codes in the section of class LSTM(Recurrent) in the recurrent_m1.py as follows: 

    print ('Modified LSTM is being used...') 
    # the code is added following the '''.... class explanation and arguments stuff...'''

However, running the mode.fit() does not show the printing results. 










Please make sure that the boxes below are checked before you submit your issue. Thank you!

- [x] Check that you are up-to-date with the master branch of Keras. You can update with:
pip install git+git://github.com/fchollet/keras.git --upgrade --no-deps

- [x] If running on Theano, check that you are up-to-date with the master branch of Theano. You can update with:
pip install git+git://github.com/Theano/Theano.git --upgrade --no-deps

- [x] Provide a link to a GitHub Gist of a Python script that can reproduce your issue (or just copy the script here if it is short).",jingweimo,b'stale',2016-11-18T15:04:31Z,2017-06-23T01:11:20Z
4424,"Bug fix of Bidirectional(LSTM(..., stateful=True))",Please see https://github.com/fchollet/keras/issues/4421,yukoba,None,2016-11-18T14:14:28Z,2016-11-18T20:19:42Z
4417,Tensorboard with histogram_freq param causes error,"- [x] Check that you are up-to-date with the master branch of Keras. You can update with:
pip install git+git://github.com/fchollet/keras.git --upgrade --no-deps

- [ ] If running on Theano, check that you are up-to-date with the master branch of Theano. You can update with:
pip install git+git://github.com/Theano/Theano.git --upgrade --no-deps

- [ ] Provide a link to a GitHub Gist of a Python script that can reproduce your issue (or just copy the script here if it is short).

I'm using Keras 1.1.1 (cloned from github) + Tensorflow 0.11.0 (from [here](https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.11.0-cp27-none-linux_x86_64.whl)) now.
Everything was right until I started using Tensorboard callback.
The problem is that `TensorBoard(log_dir='/foo/bar/')` is fine, but `TensorBoard(log_dir='/foo/bar/', histogram_freq=1)` raises such error in the exact SECOND RUN:

> Traceback (most recent call last):
  File ""test.py"", line 42, in <module>
    m.fit(x.values, y.values, nb_epoch=1, verbose=0)
  File ""/data/ycdai/pms-forecaster-clairvoyant/model/dnn.py"", line 122, in fit
    callbacks=self.callbacks
  File ""/usr/lib64/python2.7/site-packages/keras/models.py"", line 627, in fit
    sample_weight=sample_weight)
  File ""/usr/lib64/python2.7/site-packages/keras/engine/training.py"", line 1124, in fit
    callback_metrics=callback_metrics)
  File ""/usr/lib64/python2.7/site-packages/keras/engine/training.py"", line 862, in _fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File ""/usr/lib64/python2.7/site-packages/keras/callbacks.py"", line 42, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File ""/usr/lib64/python2.7/site-packages/keras/callbacks.py"", line 534, in on_epoch_end
    result = self.sess.run([self.merged], feed_dict=feed_dict)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 717, in run
    run_metadata_ptr)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 915, in _run
    feed_dict_string, options, run_metadata)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 965, in _do_run
    target_list, options, run_metadata)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 985, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors.InvalidArgumentError: You must feed a value for placeholder tensor 'dense_input_2' with dtype float
	 \[\[Node: dense_input_2 = Placeholder\[dtype=DT_FLOAT, shape=[], _device=""/job:localhost/replica:0/task:0/cpu:0""\]()\]\]

> Caused by op u'dense_input_2', defined at:
  File ""test.py"", line 40, in <module>
    batchnormalization=bn)
  File ""/data/ycdai/pms-forecaster-clairvoyant/model/dnn.py"", line 57, in build_model
    input_dim=self.input_dim,
  File ""/usr/lib64/python2.7/site-packages/keras/models.py"", line 280, in add
    layer.create_input_layer(batch_input_shape, input_dtype)
  File ""/usr/lib64/python2.7/site-packages/keras/engine/topology.py"", line 366, in create_input_layer
    dtype=input_dtype, name=name)
  File ""/usr/lib64/python2.7/site-packages/keras/engine/topology.py"", line 1091, in Input
    input_tensor=tensor)
  File ""/usr/lib64/python2.7/site-packages/keras/engine/topology.py"", line 1010, in __init__
    name=self.name)
  File ""/usr/lib64/python2.7/site-packages/keras/backend/tensorflow_backend.py"", line 193, in placeholder
    x = tf.placeholder(dtype, shape=shape, name=name)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/ops/array_ops.py"", line 1332, in placeholder
    name=name)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/ops/gen_array_ops.py"", line 1748, in _placeholder
    name=name)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py"", line 749, in apply_op
    op_def=op_def)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 2380, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 1298, in __init__
    self._traceback = _extract_stack()

> InvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'dense_input_2' with dtype float
	 \[\[Node: dense_input_2 = Placeholder\[dtype=DT_FLOAT, shape=[], _device=""/job:localhost/replica:0/task:0/cpu:0""\]()\]\]

My code basically does something like this:
```python
for activation in ['sigmoid', 'sigmoid']:
    m = Sequential()
    m.add(Dense(100, activation=activation, input_dim=10))
    # blahblah
    m.compile('rmsprop', 'mse')
    m.fit(x, y, nb_epoch=10, callbacks=[Tensorboard(log_dir='/foo/bar'), histogram_freq=1])
```
The first loop(sigmoid) works fine, but the second loop(the other sigmoid) raises the error above. In other words, the same script cannot pass the second run.
I'm sure it's not because of my coeffs, and model is redefined with `m = Sequential()`.

Google told me it's because of [something summaries in my graph depend on my placeholders](http://stackoverflow.com/questions/35720595/tensorflow-issue-with-placeholder-and-summaries). I tried to figure it out but I failed. I think the buggy part is that keras should ""refresh"" some part(session, etc) of Tensorflow, so the Tensorboard won't use the ""old"" summaries.

I can post my code if you like, but it's nearly 700 lines of code, and most of them are business logics of my company :-(

Thanks in advance!

References:
http://stackoverflow.com/questions/35720595/tensorflow-issue-with-placeholder-and-summaries
http://stackoverflow.com/questions/33772833/error-while-merging-summaries-for-tensorboard
https://github.com/tensorflow/tensorflow/issues/225",icyblade,b'stale',2016-11-18T03:27:48Z,2019-03-31T17:51:52Z
4411,Error int LSTM model evaluation,"I have the most popular problem with LSTm I suppose: I can't understand why this part (it is very simple for debugging):
def build_model():
```
    model = Sequential()
    layers = [1, 50, 100, 1]

    model.add(LSTM(128, input_shape=(10,1)))
    model.add(Dense(1))
    model.add(Activation('sigmoid'))

    start = time.time()
    model.compile(loss=""mse"", optimizer=""rmsprop"")
    print ""Compilation Time : "", time.time() - start
    return model

x_train2 = np.reshape(x_train, (3900, 10,1))
y_target = np.ones(shape= (3900))
model2 = build_model()
model2.fit(x_train2, y_target, validation_split = 0.05)
```
works fine, but when I start evaluating the model, I get the following error:
```
y_test = np.ones(shape = len(x_test))
pred = model.evaluate(x_test, y_test)

Error when checking model input: expected dense_input_20 to have 2 dimensions, but got array with shape (121, 10, 1)

```
Please make sure that the boxes below are checked before you submit your issue. Thank you!

I don't understand this error at all, as the training examples had the same dimensions. ",skotti,b'stale',2016-11-17T15:06:41Z,2017-06-22T20:11:03Z
4404,too low accuracy in the example of mnist_cnn,"Hello,

I run the example of mnist_cnn by CPU on my win7. The result is very bad, with fixed test accuracy of 0.098 even after 12 epochs. 
I am new in keras, and want to know how to debug it.
Thx for any suggestion.

The packages have been updated to latest version:
Keras version: 1.1.1
Theano version: 0.8.2

Here is the log
Train on 60000 samples, validate on 10000 samples
Epoch 1/12
60000/60000 [==============================] - 5584s - loss: nan - acc: 0.0988 - val_loss: nan - val_acc: 0.0980
Epoch 2/12
60000/60000 [==============================] - 5578s - loss: nan - acc: 0.0987 - val_loss: nan - val_acc: 0.0980
Epoch 3/12
60000/60000 [==============================] - 5577s - loss: nan - acc: 0.0987 - val_loss: nan - val_acc: 0.0980
Epoch 4/12
60000/60000 [==============================] - 5556s - loss: nan - acc: 0.0987 - val_loss: nan - val_acc: 0.0980
Epoch 5/12
60000/60000 [==============================] - 5559s - loss: nan - acc: 0.0987 - val_loss: nan - val_acc: 0.0980
Epoch 6/12
60000/60000 [==============================] - 5549s - loss: nan - acc: 0.0987 - val_loss: nan - val_acc: 0.0980
Epoch 7/12
60000/60000 [==============================] - 5550s - loss: nan - acc: 0.0987 - val_loss: nan - val_acc: 0.0980
Epoch 8/12
60000/60000 [==============================] - 5546s - loss: nan - acc: 0.0987 - val_loss: nan - val_acc: 0.0980
Epoch 9/12
60000/60000 [==============================] - 5548s - loss: nan - acc: 0.0987 - val_loss: nan - val_acc: 0.0980
Epoch 10/12
60000/60000 [==============================] - 5550s - loss: nan - acc: 0.0987 - val_loss: nan - val_acc: 0.0980
Epoch 11/12
60000/60000 [==============================] - 5549s - loss: nan - acc: 0.0987 - val_loss: nan - val_acc: 0.0980
Epoch 12/12
60000/60000 [==============================] - 5565s - loss: nan - acc: 0.0987 - val_loss: nan - val_acc: 0.0980
Test score: nan
Test accuracy: 0.098",kingaza,None,2016-11-17T03:52:33Z,2017-02-23T13:29:17Z
4402,TensorFlow initialization needs to collect local variables,"Bug in `tensorflow_backend.py`, lines 186-188:

```python
def _initialize_variables():
    variables = tf.all_variables()
    uninitialized_variables = []
```

Some code, e.g.:

```python
def auc_metric(labels, predictions):
  auc, _ = tf.contrib.metrics.streaming_auc(predictions, labels)
  return auc
```

Will fail because local variables are created, but not initialized.

Lines 187 needs to be:

```python
    variables = tf.all_variables() + tf.local_variables()
```",rgobbel,b'stale',2016-11-16T22:19:11Z,2017-06-22T19:09:46Z
4389,Keras: ValueError: operands could not be broadcast together with shapes ,"I am using LSTM in keras on top of theaon that is running in a desktop to train MINIST data. I post the mod.fit code: 

     hist1 = model.fit(X_train, Y_train, 
                  batch_size=batch_size, 
                  nb_epoch=nb_epochs,
                  verbose=1, 
                  validation_data=(X_test, Y_test), callbacks=[earlystopper, lrate])


Implementing the code leads to the error message as follows: 

Traceback (most recent call last):

  File ""<ipython-input-13-411a4ac8a654>"", line 5, in <module>
    validation_data=(X_test, Y_test), callbacks=[earlystopper, lrate])

  File ""C:\Users\user\Anaconda2\lib\site-packages\keras\models.py"", line 620, in fit
    raise Exception('The model needs to be compiled before being used.')

  File ""C:\Users\user\Anaconda2\lib\site-packages\keras\engine\training.py"", line 1104, in fit

  File ""C:\Users\user\Anaconda2\lib\site-packages\keras\engine\training.py"", line 822, in _fit_loop
    for epoch in range(nb_epoch):

  File ""C:\Users\user\Anaconda2\lib\site-packages\keras\backend\theano_backend.py"", line 672, in __call__
    input_shape[2] + top_pad + bottom_pad,

  File ""C:\Users\user\Anaconda2\lib\site-packages\theano\compile\function_module.py"", line 871, in __call__
    storage_map=getattr(self.fn, 'storage_map', None))

  File ""C:\Users\user\Anaconda2\lib\site-packages\theano\gof\link.py"", line 314, in raise_with_op
    reraise(exc_type, exc_value, exc_trace)

  File ""C:\Users\user\Anaconda2\lib\site-packages\theano\compile\function_module.py"", line 859, in __call__
    outputs = self.fn()

    ValueError: operands could not be broadcast together with shapes (195,100) (32,100) (195,100) 
Apply node that caused the error: IncSubtensor{InplaceInc;int64}(Alloc.0, Dot22.0, Constant{-1})
Toposort index: 143
Inputs types: [TensorType(float32, 3D), TensorType(float32, matrix), Scalar(int64)]
Inputs shapes: [(784L, 195L, 100L), (32L, 100L), ()]
Inputs strides: [(78000L, 400L, 4L), (400L, 4L), ()]
Inputs values: ['not shown', 'not shown', -1]
Outputs clients: [[InplaceDimShuffle{0,1,2}(IncSubtensor{InplaceInc;int64}.0)]]

Backtrace when the node is created(use Theano flag traceback.limit=N to make it longer):
  File ""C:\Users\user\Anaconda2\lib\site-packages\theano\gradient.py"", line 561, in grad
    grad_dict, wrt, cost_name)
  File ""C:\Users\user\Anaconda2\lib\site-packages\theano\gradient.py"", line 1324, in _populate_grad_dict
    rval = [access_grad_cache(elem) for elem in wrt]
  File ""C:\Users\user\Anaconda2\lib\site-packages\theano\gradient.py"", line 1279, in access_grad_cache
    term = access_term_cache(node)[idx]
  File ""C:\Users\user\Anaconda2\lib\site-packages\theano\gradient.py"", line 973, in access_term_cache
    output_grads = [access_grad_cache(var) for var in node.outputs]
  File ""C:\Users\user\Anaconda2\lib\site-packages\theano\gradient.py"", line 1279, in access_grad_cache
    term = access_term_cache(node)[idx]
  File ""C:\Users\user\Anaconda2\lib\site-packages\theano\gradient.py"", line 973, in access_term_cache
    output_grads = [access_grad_cache(var) for var in node.outputs]
  File ""C:\Users\user\Anaconda2\lib\site-packages\theano\gradient.py"", line 1279, in access_grad_cache
    term = access_term_cache(node)[idx]
  File ""C:\Users\user\Anaconda2\lib\site-packages\theano\gradient.py"", line 1113, in access_term_cache
    input_grads = node.op.grad(inputs, new_output_grads)

HINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.


Please make sure that the boxes below are checked before you submit your issue. Thank you!

- [x] Check that you are up-to-date with the master branch of Keras. You can update with:
pip install git+git://github.com/fchollet/keras.git --upgrade --no-deps

- [x] If running on Theano, check that you are up-to-date with the master branch of Theano. You can update with:
pip install git+git://github.com/Theano/Theano.git --upgrade --no-deps

- [x] Provide a link to a GitHub Gist of a Python script that can reproduce your issue (or just copy the script here if it is short).",jingweimo,b'stale',2016-11-15T20:01:34Z,2017-06-23T00:12:32Z
4377,Minor logic bug in reuter.py ,"A minor bug in reuter.py line 75.
Normal path won't run this line, so current codes is safe.

Correct logic should be **(w <= nb_words or w > skip_top)**",vash2017,b'stale',2016-11-14T09:03:30Z,2017-06-23T00:12:23Z
4373,fix using val_samples < batch_size in predict_generator,"Recently I custom a data_generator for experiment and sometimes I want to see elaborate predictions of a few examples by using method `model.predict_generator()` for debugging my model.
However, when the parameter `val_examples` is smaller than batch_size in generator, it would raise an error as follows:
>  File ""test.py"", line 221, in <module>
    history = aux_model.predict_generator(test_data_generator, 10, max_q_size=10, nb_worker=nb_worker, pickle_safe=True)
  File ""/home/gds/gds/dl_modules/keras/keras/engine/training.py"", line 1690, in predict_generator
    all_outs[i][processed_samples:(processed_samples + nb_samples)] = out
ValueError: could not broadcast input array from shape (100,20) into shape (10,20)

Here I set val_samples as 10 and batch_size is set as 100 in generator for consideration of processing speed.
Thus I recommend small changes to the code.
",happygds,None,2016-11-14T01:09:55Z,2016-11-22T13:47:09Z
4362,Can't use GPU in Windows10,"windows10，cuda8.0，cudnn5.1
LINK : fatal error LNK1104: 无法打开文件“uuid.lib”

['nvcc', '-shared', '-O3', '-use_fast_math', '-Xlinker', '/DEBUG', '-D HAVE_ROUND', '-m64', '-Xcompiler', '-DCUDA_NDARRA
Y_CUH=c72d035fdf91890f3b36710688069b2e,-DNPY_NO_DEPRECATED_API=NPY_1_7_API_VERSION,/Zi,/MD', '-IC:\\Users\\Quantum Liu\\
Anaconda2\\lib\\site-packages\\theano\\sandbox\\cuda', '-IC:\\Users\\Quantum Liu\\Anaconda2\\lib\\site-packages\\numpy\\
core\\include', '-IC:\\Users\\Quantum Liu\\Anaconda2\\include', '-IC:\\Users\\Quantum Liu\\Anaconda2\\lib\\site-packages
\\theano\\gof', '-o', 'C:\\Users\\Quantum Liu\\AppData\\Local\\Theano\\compiledir_Windows-10-10.0.14393-Intel64_Family_6
_Model_60_Stepping_3_GenuineIntel-2.7.12-64\\cuda_ndarray\\cuda_ndarray.pyd', 'mod.cu', '-LC:\\Users\\Quantum Liu\\Anaco
nda2\\libs', '-LC:\\Users\\Quantum Liu\\Anaconda2', '-lcublas', '-lpython27', '-lcudart']
ERROR (theano.sandbox.cuda): Failed to compile cuda_ndarray.cu: ('nvcc return status', 2, 'for cmd', 'nvcc -shared -O3 -
use_fast_math -Xlinker /DEBUG -D HAVE_ROUND -m64 -Xcompiler -DCUDA_NDARRAY_CUH=c72d035fdf91890f3b36710688069b2e,-DNPY_NO
_DEPRECATED_API=NPY_1_7_API_VERSION,/Zi,/MD -IC:\\Users\\Quantum Liu\\Anaconda2\\lib\\site-packages\\theano\\sandbox\\cu
da -IC:\\Users\\Quantum Liu\\Anaconda2\\lib\\site-packages\\numpy\\core\\include -IC:\\Users\\Quantum Liu\\Anaconda2\\in
clude -IC:\\Users\\Quantum Liu\\Anaconda2\\lib\\site-packages\\theano\\gof -o C:\\Users\\Quantum Liu\\AppData\\Local\\Th
eano\\compiledir_Windows-10-10.0.14393-Intel64_Family_6_Model_60_Stepping_3_GenuineIntel-2.7.12-64\\cuda_ndarray\\cuda_n
darray.pyd mod.cu -LC:\\Users\\Quantum Liu\\Anaconda2\\libs -LC:\\Users\\Quantum Liu\\Anaconda2 -lcublas -lpython27 -lcu
dart')
WARNING (theano.sandbox.cuda): CUDA is installed, but device gpu is not available  (error: cuda unavailable)",QuantumLiu,None,2016-11-12T11:40:39Z,2016-11-13T06:43:16Z
4361,the weights file will not be closed after called load_weights function.,"hi, 
I find that if I load weights from a h5 file, the file will not be closed after called load_weights function, so if I want to save the weights to this file again, it will throw an IO error like follows:

 ```
 File ""g:\Anaconda\lib\site-packages\keras\engine\training.py"", line 1124, in fit
    callback_metrics=callback_metrics)
  File ""g:\Anaconda\lib\site-packages\keras\engine\training.py"", line 862, in _fit_loop
    callbacks.on_epoch_end(epoch, epoch_logs)
  File ""g:\Anaconda\lib\site-packages\keras\callbacks.py"", line 42, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File ""g:\Anaconda\lib\site-packages\keras\callbacks.py"", line 298, in on_epoch_end
    self.model.save(filepath, overwrite=True)
  File ""g:\Anaconda\lib\site-packages\keras\engine\topology.py"", line 2423, in save
    save_model(self, filepath, overwrite)
  File ""g:\Anaconda\lib\site-packages\keras\models.py"", line 48, in save_model
    f = h5py.File(filepath, 'w')
  File ""g:\Anaconda\lib\site-packages\h5py\_hl\files.py"", line 222, in __init__
    fid = make_fid(name, mode, userblock_size, fapl)
  File ""g:\Anaconda\lib\site-packages\h5py\_hl\files.py"", line 85, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File ""h5f.pyx"", line 90, in h5py.h5f.create (h5py\h5f.c:1998)
IOError: Unable to create file (Unable to truncate a file which is already open)
```

I check the load_weights function code in keras\engine\topology.py  is like follows:
```
    def load_weights(self, filepath, by_name=False):
        import h5py
        f = h5py.File(filepath, mode='r')
        if 'layer_names' not in f.attrs and 'model_weights' in f:
            f = f['model_weights']
        if by_name:
            self.load_weights_from_hdf5_group_by_name(f)
        else:
            self.load_weights_from_hdf5_group(f)

        if hasattr(f, 'close'):
            f.close()
```
it will call f = f['model_weights'] if 'model_weights' in f and change f to a HDF5 group, which have no 'close' attribute. I think this is a bug.





",lazyCoderX,None,2016-11-12T04:21:30Z,2019-07-02T09:03:09Z
4357,fix new_p,Fixing the bug in RMSProp,fatemi,None,2016-11-11T17:16:04Z,2016-11-11T18:06:33Z
4345,Custom loss function for sampling loss area,"Hello,

I have an end-to-end network (like FCN), which has the input shape: 
```(batch_size, channel, img_col, img_row)```

and the output shape:
```(batch_size, img_col, img_row, num_class)```

the labels are one-hot-encoded and have the shape:
```(batch_size, img_col, img_row, num_class)```

When computing the loss, I don´t want to compute the loss for the whole output but just compute on the randomly sampling part of the whole region. The custom loss function is like:
```python
def custom_loss_fun(y_true, y_pred)

      from theano.tensor.shared_randomstreams import RandomStreams

      # reshape to (batch_size*img_col*img_row, n_class)
      y_pred = y_pred.dimshuffle(3, 0, 1, 2).flatten(2).dimshuffle(1, 0)
      y_true = y_true.dimshuffle(3, 0, 1, 2).flatten(2).dimshuffle(1, 0)
      
      # sampling
      mask_size = y_true.shape[0]
      rs = RandomStreams(seed=234)
      # make mask for sampling
      mask = rs.binomial(n=1, p=0.8, size=mask_size)
      # get the indices
      label_idx = (mask > 0).nonzero()
     
      y_pred = y_pred[label_idx] # size has changed
      y_true = y_true[label_idx] # size has changed
      
      return keras.objectives.categorical_crossentropy(y_true, y_pred)
```
The error is as follows: 

Note: ```batch_size = 2, batch_size * img_col * img_row = 921600```

```python
Traceback (most recent call last):
  File ""C:\lib\site-packages\theano\compile\function_module.py"", line 859, in __call__
    outputs = self.fn()
ValueError: Input dimension mis-match. (input[0].shape[0] = 921600, input[1].shape[0] = 2)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
.......
  File ""C:\lib\site-packages\theano\compile\function_module.py"", line 859, in __call__
    outputs = self.fn()
ValueError: Input dimension mis-match. (input[0].shape[0] = 921600, input[1].shape[0] = 2)
Apply node that caused the error: Elemwise{mul,no_inplace}(mean, reshape_2_sample_weights)
Toposort index: 1709
Inputs types: [TensorType(float32, vector), TensorType(float32, vector)]
Inputs shapes: [(921600,), (2,)]   
Inputs strides: [(4,), (4,)]
Inputs values: ['not shown', array([ 1.,  1.], dtype=float32)]
Outputs clients: [[Elemwise{true_div,no_inplace}(Elemwise{mul,no_inplace}.0, DimShuffle{x}.0)]]

Backtrace when the node is created(use Theano flag traceback.limit=N to make it longer):
 .....
  File ""C:/.....py"", line 436, in train_model
    model.compile(loss=self.sampled_loss_CE, optimizer='adam', metrics=[keras.metrics.categorical_accuracy])
  File ""C:\lib\site-packages\keras\engine\training.py"", line 625, in compile
    sample_weight, mask)
  File ""C:\lib\site-packages\keras\engine\training.py"", line 344, in weighted
    score_array *= weights

HINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.
```

any ideas?",KlaymenGC,None,2016-11-10T13:28:42Z,2016-11-13T20:25:14Z
4338,Fix the load_model() bug by sorting weights by names,"Weights must be sorted by names for save_model() and load_model() work properly.

This pull request fixes https://github.com/fchollet/keras/issues/3964 , https://github.com/fchollet/keras/issues/4044 and https://github.com/fchollet/keras/issues/4143 .
The discussion is https://github.com/fchollet/keras/issues/4044 .",yukoba,None,2016-11-10T03:40:20Z,2016-11-10T04:36:45Z
4336,Accuracy calculation is incorrect?,"Hi,
I have been experimenting with using `model.predict()` to run some predictions manually rather than evaluating them directly with `model.evaluate()` because I need the predicted values and not just the overall accuracy.

When computing the accuracy manually I noticed that the accuracy keras' calculates in `evaluate()` is not correct. Is there a bug in the accuracy calculation?

Below a self-contained runnable minimal example that shows the difference (the example tests on the training data):
```
import numpy as np
from keras.preprocessing import sequence
from keras.models import Sequential
from keras.layers import Dense, Activation, Embedding, TimeDistributed, Bidirectional
from keras.layers import LSTM
import json
from keras.utils import np_utils

np.set_printoptions(threshold=np.nan)

def mapWords2Integer(input, startIdx=0):
    map = {}
    for s in input:
        for w in s:
            if w not in map:
               map[w]=startIdx
               startIdx+=1

    out = []
    for s in input:
        out_s = []
        for w in s:
            out_s.append(map[w])
        out.append(out_s)
    return map, out

tokens = [
    ['Great', 'Western', 'said', 'it', 'had', 'a', 'sharp', 'increase', 'in', 'margins', 'in', 'the', 'recent', 'third', 'quarter', '.'],
    ['Margins', 'are', 'the', 'difference', 'between', 'the', 'yield', 'on', 'the', 'company', 's', 'earning', 'assets', 'and', 'its', 'own', 'cost', 'of', 'funds', '.'],
    ['But', 'a', 'reduction', 'in', 'one-time', 'gains', 'on', 'the', 'sale', 'of', 'various', 'assets', 'and', 'an', 'increase', 'in', 'the', 'company', 's', 'provision', 'for ', 'loan', 'losses', 'held', 'down', 'the', 'earnings', 'gain', ', ', 'the', 'company', 'said', '.']
]

labels = [
    ['NNP', 'NNP', 'VBD', 'PRP', 'VBD', 'DT', 'JJ', 'NN', 'IN', 'NNS', 'IN', 'DT', 'JJ', 'JJ', 'NN', '.'],
    ['NNS', 'VBP', 'DT', 'NN', 'IN', 'DT', 'NN', 'IN', 'DT', 'NN', 'POS', 'VBG', 'NNS', 'CC', 'PRP$', 'JJ', 'NN', 'IN', 'NNS', '.'],
    ['CC', 'DT', 'NN', 'IN', 'JJ', 'NNS', 'IN', 'DT', 'NN', 'IN', 'JJ', 'NNS', 'CC', 'DT', 'NN', 'IN', 'DT', 'NN', 'POS', 'NN', 'IN', 'NN', 'NNS', 'VBD', 'RP', 'DT', 'NNS', 'NN', ',', 'DT', 'NN', 'VBD', '.']
]


longest_sequence = max(len(s) for s in (tokens))

valMap, valInt = mapWords2Integer(tokens,1)
labMap, labelInt = mapWords2Integer(labels,1)

vocabSize=len(valMap)

padValInt = sequence.pad_sequences(valInt, maxlen=longest_sequence)
padLabInt = sequence.pad_sequences(labelInt, maxlen=longest_sequence)

maximal_value = max([ys for sent in padLabInt for ys in sent])+1

train_label = np.array([np_utils.to_categorical(seq, maximal_value) for seq in padLabInt])

EMBEDDING_DIM=100

model = Sequential()
model.add(Embedding(vocabSize+1, EMBEDDING_DIM,mask_zero=True))
model.add(Bidirectional(LSTM(EMBEDDING_DIM, return_sequences=True)))
model.add(TimeDistributed(Dense(maximal_value)))
model.add(Activation('relu'))

# try using different optimizers and different optimizer configs
model.compile(loss='categorical_crossentropy',
              optimizer='adam',
              metrics=['accuracy'])

model.fit(padValInt, train_label, nb_epoch=1)
score, acc = model.evaluate(padValInt, train_label)
print('Accuracy calculated by Keras:', acc*100)

#########################
##### Manual Accuracy ###
#########################
correct=0.0
incorrect=0.0
inversed_label_map = {v: k for k, v in labMap.items()}
for k in range(0, len(padValInt)):
    s = padValInt[k]
    out = model.predict(s)
    predLabels = []
    for e in out:
        for c in e:
            x = np.argmax(c)
            pl = inversed_label_map.get(x)
            predLabels.append(pl)

    #throw away the padded, leading zeros
    fromIdx = (len(predLabels)-len(labels[k]))
    predLabels = predLabels[fromIdx:]

    for i in range(0, len(labels[k])):

        if labels[k][i] == predLabels[i]:
            correct+=1
        else:
            incorrect+=1

acc = correct / (correct+incorrect) * 100
print(""Manually calculated accuracy: "", acc)
```",Horsmann,None,2016-11-09T21:08:02Z,2016-12-05T16:31:20Z
4330,Fix recurrent.py dropout_W bug of Theano K.tile(),"Theano expects Python int for the argument of tile().
https://github.com/Theano/Theano/blob/rel-0.8.2/theano/tensor/basic.py#L4918

However, input_dim is numpy.int32.
It have to cast to Python int.
",yukoba,None,2016-11-09T12:23:45Z,2016-11-10T00:23:22Z
4319,Bugfix to CIFAR pickle reading code in Python 3,"The following code for reading in CIFAR batches is currently used in Python 3:

```python
d = cPickle.load(f, encoding=""bytes"")
# decode utf8
print(""keys are: {}"".format(d.keys())  # debug output
for k, v in d.items():
    print(""key is: {}"".format(k))      # debug output
    del(d[k])
    d[k.decode(""utf8"")] = v
```

This errors out with the following (running under Python 3.6b2):

```
keys are: dict_keys([b'batch_label', b'labels', b'data', b'filenames'])
key is: b'batch_label'
key is: b'labels'
key is: batch_label
Traceback (most recent call last):
  File ""run.py"", line 78, in <module>
    main()
  File ""run.py"", line 67, in main
    (X_train, y_train), (X_test, y_test) = cifar10.load_data()
  File ""/usr/local/lib/python3.6/site-packages/keras/datasets/cifar10.py"", line 21, in load_data
    data, labels = load_batch(fpath)
  File ""/usr/local/lib/python3.6/site-packages/keras/datasets/cifar.py"", line 19, in load_batch
    d[k.decode(""utf8"")] = v
AttributeError: 'str' object has no attribute 'decode'
```

So seems like there is a bug due to the modification if the dictionary in the iteration loop. This PR fixes this.",kencoken,None,2016-11-08T12:01:51Z,2016-11-10T01:14:36Z
4315,Add documentation to set self.built = True in MyLayer.build(),"We ran into some really odd errors in an advanced usage of keras due to not setting `self.built = True` in one of our custom layers.  This PR is an attempt to help others avoid the pain that we experienced due to this bug.

In case you're curious, the place where this happened was in trying to use `tf.while_loop` to do an adaptive computation step, similar to [this paper](https://www.semanticscholar.org/paper/Adaptive-Computation-Time-for-Recurrent-Neural-Graves/4b2c003b7eb683476f96b2e653676c6cfcb8da28) by Alex Graves.  We had a layer that was trying to be built twice, which caused some funny errors when combined with `tf.while_loop`.",matt-gardner,None,2016-11-08T00:58:38Z,2016-11-08T02:19:27Z
4283,Convert an activity recognitoin model to keras,"I'm trying to covert this model :
https://github.com/yjxiong/caffe/tree/action_recog/models/action_recognition
which is in caffe to keras
to do that as small experimen I download  prototxt
https://github.com/yjxiong/caffe/blob/action_recog/models/action_recognition/cuhk_action_spatial_vgg_16_deploy.prototxt
and the model file :
http://mmlab.siat.ac.cn/very_deep_two_stream_model/cuhk_action_spatial_vgg_16_split1.caffemodel
I'm try to convert using @MarcBS 
https://github.com/MarcBS/keras
here is the command line:

python caffe2keras.py -load_path 'TSN/' -prototxt 'cuhk_action_spatial_vgg_16_deploy.prototxt' -caffemodel 'cuhk_action_spatial_vgg_16_split1.caffemodel'

**But I got that IndexError: list index out of range**
____________________
drop7 (Dropout)                  (None, 4096)          0           relu7[0][0]                      
____________________________________________________________________________________________________
fc8-1 (Dense)                    (None, 101)           413797      drop7[0][0]                      
====================================================================================================
Total params: 134637413
____________________________________________________________________________________________________

LOADING WEIGHTS
Traceback (most recent call last):
  File ""caffe2keras.py"", line 45, in <module>
    main(args)
  File ""caffe2keras.py"", line 34, in main
    model = convert.caffe_to_keras(args.load_path+'/'+args.prototxt, args.load_path+'/'+args.caffemodel, debug=args.debug)
  File ""/usr/local/lib/python2.7/dist-packages/Keras-1.1.0-py2.7.egg/keras/caffe/convert.py"", line 62, in caffe_to_keras
    weights = convert_weights(param_layers, v, debug)
  File ""/usr/local/lib/python2.7/dist-packages/Keras-1.1.0-py2.7.egg/keras/caffe/convert.py"", line 395, in convert_weights
    nb_filter = int(blobs[0].shape.dim[0])
  File ""/usr/local/lib/python2.7/dist-packages/google/protobuf/internal/containers.py"", line 204, in __getitem__
    return self._values[key]
IndexError: list index out of range

Please tell me what is the problem",adelsalehali1982,b'stale',2016-11-03T14:37:12Z,2018-03-09T12:49:13Z
4266,Writing a custom RNN layer,"I'm trying to implement a Convolutional - LSTM. 
It's a recurrent layer which accepts an image as input and uses a convolution to calculate the various gates in the LSTM.
So I'm trying to subclass `Recurrent `and change the input dimension.

In order to do that I read the documentation on [writing a custom layer](https://keras.io/layers/writing-your-own-keras-layers/) and followed the suggestion to read source code to understand what's happening under the hood.

I read the code for recurrent.py and think that the structure is clear: You inherit from `Recurrent` but you don't overwrite call, instead you provide a custom `step `function and `Recurrent `will take care of applying the step to each entry in a sequence.

As a starting point I took the code for the GRU and tried to adapt it to my needs.
I want to combine a 2D convolution and a GRU (usually it's an LSTM, but that doesn't really matter - I decided to implement a C-GRU)

The idea is to have a usual 2D convolution in the model which outputs 3 features. Those 3 features will be used as the r,z and h activations in the GRU. In the custom layer I only have to keep track of the state. My layer doesn't even have trainable weights, they are contained in the convolution.

Notable changes to the original `GRU `code are:

```
    def step(self, x, states):
        # the previous state is a 2D vector
        h_tm1 = states[0]  # previous memory
       
        z=self.inner_activation(x[:,0,:,:])
        r=self.inner_activation(x[:,1,:,:])
        hh=self.activation(x[:,2,:,:])

        h = z * h_tm1 + (1 - z) * hh
        return h, [h]
```

As you can see, I'm simply reusing the features from the convolution. The multiplications should be performed element-wise. I'll debug this to make sure it has the intended behaviour.

Since the state becomes 2D, I'm changing the `initial_state`, too:

```
    def get_initial_states(self, x):
        initial_state=K.zeros_like(x)   # (samples, timesteps, input_dim)
                                        # input_dim = (3, x_dim, y_dim)
        initial_state=K.sum(initial_state, axis=(1,2)) # (samples, x_dim, y_dim)
        return initial_state
```

The `output_shape` seems to be hardcoded for Recurrent networks. I'm overriding it:

```
    def get_output_shape_for(self, input_shape):
        #TODO: this is hardcoding for th layout
        return (input_shape[0],1,input_shape[2],input_shape[3])
```

Another thing that's hardcoded is the `input_spec`.
In the constructor, after the call to super, I'm overriding it with my input dimension:
```

class CGRU(Recurrent):
    def __init__(self,
                 init='glorot_uniform', inner_init='orthogonal',
                 activation='tanh', inner_activation='hard_sigmoid', **kwargs):

        self.init = initializations.get(init)
        self.inner_init = initializations.get(inner_init)
        self.activation = activations.get(activation)
        self.inner_activation = activations.get(inner_activation)

        #removing the regularizers and the dropout

        super(CGRU, self).__init__(**kwargs)

        # this seems necessary in order to accept 5 input dimensions
        # (samples, timesteps, features, x, y)
        self.input_spec=[InputSpec(ndim=5)]
```

There are other small changes.
You can find the whole code here: http://pastebin.com/60ztPis3



When ran, this produces the following error message:

> theano.tensor.var.AsTensorError: ('Cannot convert [None] to TensorType', <class 'list'>)

The whole error message on pastebin: http://pastebin.com/Cdmr20Yn

I'm trying to debug the code. But that's rather hard, it goes deep into the Keras source code.
One thing: The execution never reaches my custom `step `function. So apparently something in the configuration is going wrong. In the `call `function of `Recurrent`, input_shape is a tuple with the entries `(None, 40,1,40,40)`

This is correct. My sequence has 40 elements. Each one is an image with 1 feature and 40x40 resolution. I'm using the ""th"" layout.

Here is the `call` function of `Recurrent`.
My code reaches the call to `K.rnn`, the setup looks fine to me. Input_spec seems correct.
But during `K.rnn` it crashes. Without reaching my step function.
```
    def call(self, x, mask=None):
        # input shape: (nb_samples, time (padded with zeros), input_dim)
        # note that the .build() method of subclasses MUST define
        # self.input_spec with a complete input shape.
        input_shape = self.input_spec[0].shape
        if self.stateful:
            initial_states = self.states
        else:
            initial_states = self.get_initial_states(x)
        constants = self.get_constants(x)
        preprocessed_input = self.preprocess_input(x)

        last_output, outputs, states = K.rnn(self.step, preprocessed_input,
                                             initial_states,
                                             go_backwards=self.go_backwards,
                                             mask=mask,
                                             constants=constants,
                                             unroll=self.unroll,
                                             input_length=input_shape[1])
```

At this point I'm lost.
Could you help me ?
Am I missing something, do I need to configure something else ?",lhk,None,2016-11-02T13:15:00Z,2016-11-03T07:44:23Z
4263,Can't use gpu when using cmd and ipython，but it workswhen usingSpyder?,"WIN10,VS2015,CUDA8.0
when using cmd and ipython

impot keras
using theano....

And then it begin to print debug information for 5k lines

The erro information is cuda is installed but gpu is unavailable.

but when opening Spyder ,some windows of nvcc flashed,and show 'kernel died ,restarting'forseveral times andthen everyting work well.i can run example in Spyder on gpu.",QuantumLiu,None,2016-11-02T09:08:24Z,2016-11-06T03:41:14Z
4259,keras/examples/variational_autoencoder_deconv.py  fails to run with Theano but working fine with Tensorflow,"keras/examples/variational_autoencoder_deconv.py  fails to run with Theano but working fine with Tensorflow.

I have the latest version .. also it was not working on older version.
In [2]: keras.__version__
Out[2]: '1.1.1'
In [4]: theano.__version__
Out[4]: '0.9.0dev1.dev-5e50147375ad507990655cc1a3e990aa4c190549'

On my PC which has Quadro GPU  I am getting error:

`
Train on 60000 samples, validate on 10000 samples
Epoch 1/5
Traceback (most recent call last):
  File ""variational_autoencoder_deconv.py"", line 133, in <module>
    validation_data=(x_test, x_test))
  File ""/home/isur2/0.Work/DEEP_LEARNING/keras/keras/engine/training.py"", line 1124, in fit
    callback_metrics=callback_metrics)
  File ""/home/isur2/0.Work/DEEP_LEARNING/keras/keras/engine/training.py"", line 842, in _fit_loop
    outs = f(ins_batch)
  File ""/home/isur2/0.Work/DEEP_LEARNING/keras/keras/backend/theano_backend.py"", line 792, in __call__
    return self.function(*inputs)
  File ""/home/isur2/Dropbox (ASU)/DEEP_LEARNING/Theano/theano/compile/function_module.py"", line 886, in __call__
    storage_map=getattr(self.fn, 'storage_map', None))
  File ""/home/isur2/Dropbox (ASU)/DEEP_LEARNING/Theano/theano/gof/link.py"", line 325, in raise_with_op
    reraise(exc_type, exc_value, exc_trace)
  File ""/home/isur2/Dropbox (ASU)/DEEP_LEARNING/Theano/theano/compile/function_module.py"", line 873, in __call__
    self.fn() if output_subset is None else\
**RuntimeError: GpuDnnConvGradI: error getting worksize: CUDNN_STATUS_BAD_PARAM**
Apply node that caused the error: GpuDnnConvGradI{algo='none', inplace=True}(GpuContiguous.0, GpuContiguous.0, GpuAllocEmpty.0, GpuDnnConvDesc{border_mode='half', subsample=(1, 1), conv_mode='conv', precision='float32'}.0, Constant{1.0}, Constant{0.0})
Toposort index: 332
Inputs types: [CudaNdarrayType(float32, 4D), CudaNdarrayType(float32, 4D), CudaNdarrayType(float32, 4D), <theano.gof.type.CDataType object at 0x7f9459ff1390>, Scalar(float32), Scalar(float32)]
Inputs shapes: [(64, 64, 3, 3), (100, 64, 14, 14), (100, 64, 14, 64), 'No shapes', (), ()]
Inputs strides: [(576, 9, 3, 1), (12544, 196, 14, 1), (57344, 896, 64, 1), 'No strides', (), ()]
Inputs values: ['not shown', 'not shown', 'not shown', <capsule object NULL at 0x7f945079a540>, 1.0, 0.0]
Inputs name: ('kernel', 'grad', 'output', 'descriptor', 'alpha', 'beta')

Outputs clients: [[GpuDimShuffle{0,2,3,1}(GpuDnnConvGradI{algo='none', inplace=True}.0)]]

HINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.
HINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.
`

On our cluster which has Tesla GPU  I am getting error:

`Train on 60000 samples, validate on 10000 samples
Epoch 1/5
Traceback (most recent call last):
  File ""variational_autoencoder_deconv.py"", line 133, in <module>
    validation_data=(x_test, x_test))
  File ""/home/isur2/.python_packages/keras/engine/training.py"", line 1124, in fit
    callback_metrics=callback_metrics)
  File ""/home/isur2/.python_packages/keras/engine/training.py"", line 842, in _fit_loop
    outs = f(ins_batch)
  File ""/home/isur2/.python_packages/keras/backend/theano_backend.py"", line 792, in __call__
    return self.function(*inputs)
  File ""/home/isur2/.python_packages/theano/compile/function_module.py"", line 871, in __call__
    storage_map=getattr(self.fn, 'storage_map', None))
  File ""/home/isur2/.python_packages/theano/gof/link.py"", line 314, in raise_with_op
    reraise(exc_type, exc_value, exc_trace)
  File ""/home/isur2/.python_packages/theano/compile/function_module.py"", line 859, in __call__
    outputs = self.fn()
**ValueError: GpuCorrMM shape inconsistency:
  bottom shape: 100 64 29 64
  weight shape: 64 64 2 2
  top shape: 100 64 14 14 (expected 100 64 14 32)**

Apply node that caused the error: GpuCorrMM_gradInputs{valid, (2, 2)}(GpuContiguous.0, GpuContiguous.0, TensorConstant{29}, TensorConstant{64})
Toposort index: 255
Inputs types: [CudaNdarrayType(float32, 4D), CudaNdarrayType(float32, 4D), TensorType(int64, scalar), TensorType(int64, scalar)]
Inputs shapes: [(64, 64, 2, 2), (100, 64, 14, 14), (), ()]
Inputs strides: [(256, 4, 2, 1), (12544, 196, 14, 1), (), ()]
Inputs values: ['not shown', 'not shown', array(29), array(64)]
Outputs clients: [[GpuDimShuffle{0,2,3,1}(GpuCorrMM_gradInputs{valid, (2, 2)}.0)]]

HINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.
HINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.
`


Tensorflow is not quiet working on our cluster and I need to fall back on Theano which has this problem. 
Note: keras/examples/variational_autoencoder.py  example is working fine with theano indicating the problem is with convolution or deconvolution layers

Regards,
Indranil",indraforyou,b'stale',2016-11-01T23:02:23Z,2017-06-22T21:13:47Z
4251,BUG: Deconvolution2D output shape not correctly referenced,"Error with the  get_config method from Deconvolution2D.

Throws the following error when saving a model with such layer.
Exception: The layer has never been called and thus has no defined output shape.
",mbaradad,None,2016-11-01T17:26:55Z,2016-11-01T18:24:54Z
4225,How to get classes from generator in case of Shuffle=True,"I've 10100 images split into 101 folders(classes) that I want to store as single dataset using keras datagen.flow_from_directory.

Here is the code

```
datagen = ImageDataGenerator(rescale=1./255)

generator = datagen.flow_from_directory(
        train_data_dir,
        target_size=(150, 150),
        batch_size=12,
        class_mode='sparse',
        shuffle=True)

```

However I want to shuffle the data while doing so,hence ideally generator.classes output should have been something like this
[0,
4,
5,
3,
2
.
.
....<some random number between 0-100>] ...and 101 such column each with 100 elements vertically one under other.However the actual class out put isn't showing any random fashion and rather showing the value like this
0,
0,
.
100 such 0's followed by 100 such 1's ...upto 100 such 100.hence no random fashion is seen.
Any idea whether this is a bug or there is a work around for this. 

Please make sure that the boxes below are checked before you submit your issue. Thank you!
- [ ] Check that you are up-to-date with the master branch of Keras. You can update with:
  pip install git+git://github.com/fchollet/keras.git --upgrade --no-deps
- [ ] If running on Theano, check that you are up-to-date with the master branch of Theano. You can update with:
  pip install git+git://github.com/Theano/Theano.git --upgrade --no-deps
- [ ] Provide a link to a GitHub Gist of a Python script that can reproduce your issue (or just copy the script here if it is short).
",tanayz,b'stale',2016-10-29T09:49:31Z,2019-12-15T21:15:15Z
4200,Bug fix when target is a SparseTensor.,"Bug fix when target is a SparseTensor.
Check for sparsity when creating target placeholder.
Remove shape argument when creating sparse placeholder.
",igormq,None,2016-10-26T10:18:07Z,2016-11-03T17:04:40Z
4192,Bidirectional wrapper with masking gives incorrect hidden states,"Please make sure that the boxes below are checked before you submit your issue. Thank you!
- [x] Check that you are up-to-date with the master branch of Keras. You can update with:
  pip install git+git://github.com/fchollet/keras.git --upgrade --no-deps
- [x] If running on Theano, check that you are up-to-date with the master branch of Theano. You can update with:
  pip install git+git://github.com/Theano/Theano.git --upgrade --no-deps
- [x] Provide a link to a GitHub Gist of a Python script that can reproduce your issue (or just copy the script here if it is short).

[Code to reproduce the bug](https://gist.github.com/ppasupat/933dfcd988dcca995451d4d68a909650)

The code creates a Bidirectional SimpleRNN layer upon an Embedding layer with masking. (Using LSTM also gives the same bug.)

The hidden states of the SimpleRNN backward pass are not the same when the paddings (input 0) are placed in different positions. The forward pass seems to be fine.
",ppasupat,b'stale',2016-10-25T22:25:41Z,2017-06-22T21:14:38Z
4181,Bug fix in zca_whitening,"When calculating covariance matrix 'sigma', denominator is # of instances (axis=0), not dimensionality (axis=1)

Proof:
http://ufldl.stanford.edu/wiki/index.php/Implementing_PCA/Whitening
http://ufldl.stanford.edu/wiki/index.php/Exercise:PCA_and_Whitening
Ng uses 2nd dim in denominator because his matrix is [features x instances]
",alexander-rakhlin,None,2016-10-25T14:40:13Z,2016-10-25T20:49:00Z
4176,"Out-of-memory error, even for a small dataset","Hi,

I have been trying to perform **end-to-end training** on a simple CNN-RNN network, however with no success.
A single image is provided as input to the CNN which produces a 4096D vector, which is in turn passed to every RNN time-steps (6 steps). In other words, the inputs to all RNN cells are identical vectors. I also need to get per-step outputs.
I have written the following code:

`input_layer = Input(shape=(6, 3, 224, 224))`
`RNN_in = TimeDistributed(CNN_model)(input_layer)  # CNN_model is a sequential model defined earlier`
`RNN_out = SimpleRNN(1000, return_sequences=True)(RNN_in)`
`Dropout_out = Dropout(0.5)(RNN_out)`
`Dense_out = TimeDistributed(Dense(num_classes))(Dropout_out)`
`Activation_out = Activation('softmax')(Dense_out)`
`model = Model(input=[input_layer], output=[Activation_out])`
`sgd = SGD(lr=0.001, momentum=0.9, decay=0.005, nesterov=True)`
`model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])`
`model.fit(X_train, train_labels, nb_epoch=50, batch_size=32, validation_data=(X_valid, valid_labels))`
`# X_train.shape is (10000, 6, 3, 224, 224)`

I have even tried for just 10 training samples, shape = (10, 6, 3, 224, 224), but I always get the following error:

> Using Theano backend.
> Using gpu device 0: GeForce GTX 1080 (CNMeM is disabled, cuDNN 5005)
> (10, 6, 3, 224, 224)
> (10, 6, 3, 224, 224)
> Train on 10 samples, validate on 10 samples
> Epoch 1/50
> Error allocating 192675840 bytes of device memory (out of memory). Driver report 43319296 bytes free and 8504279040 bytes total 
> Traceback (most recent call last):
>   File ""/home/monaj/Dropbox/codes/RNN/replicateRNN.py"", line 104, in <module>
>     validation_data=([force_test_data], test_labels))
>   File ""/usr/local/lib/python2.7/dist-packages/keras/engine/training.py"", line 1108, in fit
>     callback_metrics=callback_metrics)
>   File ""/usr/local/lib/python2.7/dist-packages/keras/engine/training.py"", line 826, in _fit_loop
>     outs = f(ins_batch)
>   File ""/usr/local/lib/python2.7/dist-packages/keras/backend/theano_backend.py"", line 562, in __call__
>     return self.function(*inputs)
>   File ""/usr/local/lib/python2.7/dist-packages/theano/compile/function_module.py"", line 879, in **call**
>     storage_map=getattr(self.fn, 'storage_map', None))
>   File ""/usr/local/lib/python2.7/dist-packages/theano/gof/link.py"", line 325, in raise_with_op
>     reraise(exc_type, exc_value, exc_trace)
>   File ""/usr/local/lib/python2.7/dist-packages/theano/compile/function_module.py"", line 866, in **call**
>     self.fn() if output_subset is None else\
> MemoryError: Error allocating 192675840 bytes of device memory (out of memory).
> Apply node that caused the error: GpuElemwise{add,no_inplace}(GpuDnnConv{algo='small', inplace=True}.0, GpuDimShuffle{x,0,x,x}.0)
> Toposort index: 385
> Inputs types: [CudaNdarrayType(float32, 4D), CudaNdarrayType(float32, (True, False, True, True))]
> Inputs shapes: [(60, 256, 56, 56), (1, 256, 1, 1)]
> Inputs strides: [(802816, 3136, 56, 1), (0, 1, 0, 0)]
> Inputs values: ['not shown', 'not shown']
> Outputs clients: [[GpuElemwise{Composite{(i0 \* (i1 + Abs(i1)))},no_inplace}(CudaNdarrayConstant{[[[[ 0.5]]]]}, GpuElemwise{add,no_inplace}.0), GpuElemwise{Composite{((i0 \* i1) + (i0 \* i1 \* sgn(i2)))}}[(0, 1)](CudaNdarrayConstant{[[[[ 0.5]]]]}, GpuDnnPoolGrad{mode='max'}.0, GpuElemwise{add,no_inplace}.0)]]
> HINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.
> HINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.

Note that the CNN model is pre-trained VGG16, whose last layer is removed.
Since the input to all time-steps of RNN is the same, is there any way to provide input_layer of the shape (10000, 3, 224, 224) to the CNN and then replicate the resulting 4096D vector to all RNN cells?
I mean do I really have to have an input_layer with 5 dimensions (including repeated images for different times)?
",monaj07,b'stale',2016-10-25T05:33:23Z,2017-06-22T21:14:34Z
4170,Reducing overfitting with embedding weights?? ,"- [X] Check that you are up-to-date with the master branch of Keras. You can update with:
  pip install git+git://github.com/fchollet/keras.git --upgrade --no-deps
- [X] If running on Theano, check that you are up-to-date with the master branch of Theano. You can update with:
  pip install git+git://github.com/Theano/Theano.git --upgrade --no-deps

Hi, 
I'm working on text prediction task using my pretrained word embeddings. The current model is severely overfitting with increasing val loss. Need your advice on how to mitigate this and the train network properly. I'm using embedding weights in input layer. The embeddings were trained using a larger corpus. The training corpus of model is a subset of it. For out of vocab words I'm using glorot_uniform(270,) to get random embeddings.

Q1- Is it because my network parameters are far greater than train size ?

Q2- Am I using embeddings correctly? Do I have problem with embedding weights?

Q3- What else can I try?

Things I've tried:
- Passing train data as val data for bug check. Val loss decreases.
- Adding regularization to all layers.
- Reducing lstm cells from 256-128
- Varying input sequence length 5-32
#### My model
- Trained a word2vec model to get word embeddings.
- X_train: sequence of words (indices map using wordvec and oov dictionary)
- Using X_train to get embedding weights from word2vec model. i.e embed[i]=word2vec[X_train[i]] 
- y_train- one hot target vector with 1 at pos of next word wrt to corpus indices i.e not using word2vec+oov dict.

``` python
Corpus size: 46265, Corpus vocab size: 22120
Out of vocab words:  15248
Vocab size of Word2vec model + oov words: 34444
Train corpus size:  46169
Test corpus size:  96
X_train.shape:  (46137, 32)
y_train.shape:  (46137, 22120)
embed_weight.shape:  (34444, 270)

w2v_dim= 270
seq_length= 32
corpus_vocab_size= # of unique words in corpus
memory_units=128

model.add(Embedding(embed_weight.shape[0], embed_weight.shape[1], mask_zero=False, weights=[embed_weight], input_length=seq_length, W_regularizer=l2(l2_emb)))
model.add(LSTM(memory_units, return_sequences=False, init= ""orthogonal"", W_regularizer=l2(l2_lstm)))
model.add(Dropout(0.5))
model.add((Dense(corpus_vocab_size, activation='softmax', init= ""orthogonal"", W_regularizer=l2(l2_dense)))

Compiling Model
l2_emb:  0.7  l2_lstm:  0.7  l2_dense:  0.7  Dropout:  0.5

Fitting model
Train on 36909 samples, validate on 9228 samples
('lr:', array(0.0010000000474974513, dtype=float32))
Epoch 1/40
36909/36909 [==============================] - 135s - loss: 300351.6275 - acc: 0.0223 - val_loss: 9.8617 - val_acc: 0.0237
('lr:', array(0.0010000000474974513, dtype=float32))
Epoch 2/40
36909/36909 [==============================] - 134s - loss: 35422.2196 - acc: 0.0231 - val_loss: 9.9594 - val_acc: 0.0237
('lr:', array(0.0010000000474974513, dtype=float32))
Epoch 3/40
36909/36909 [==============================] - 135s - loss: 3996.1297 - acc: 0.0231 - val_loss: 10.1249 - val_acc: 0.0237
('lr:', array(0.0010000000474974513, dtype=float32))
Epoch 4/40
36909/36909 [==============================] - 134s - loss: 254.4328 - acc: 0.0229 - val_loss: 10.3708 - val_acc: 0.0237
('lr:', array(0.0010000000474974513, dtype=float32))
.
.
.
Epoch 38/40
36909/36909 [==============================] - 134s - loss: 9.0427 - acc: 0.0231 - val_loss: 11.7586 - val_acc: 0.0237
('lr:', array(0.0005000000237487257, dtype=float32))
Epoch 39/40
36909/36909 [==============================] - 134s - loss: 9.0425 - acc: 0.0231 - val_loss: 11.7566 - val_acc: 0.0237
('lr:', array(0.0005000000237487257, dtype=float32))
Epoch 40/40
36909/36909 [==============================] - 134s - loss: 9.0423 - acc: 0.0231 - val_loss: 11.7524 - val_acc: 0.0237
```

@braingineer @farizrahman4u @carlthome your two cents??

Need advice. Thanks !

**Edit:** optimizer=adam, loss='categorical_crossentropy'
",ishank26,None,2016-10-24T13:18:44Z,2017-01-20T13:23:55Z
4159,Bug fix in TensorBoard callback and corresponding test,"Fixes issue: https://github.com/fchollet/keras/issues/4048
",mjdietzx,None,2016-10-23T13:32:50Z,2016-10-24T22:13:39Z
4150,[Feature]Input shape api inconsistency with Tensorflow Backend,"When using tensorflow as the backend, there is an inconsistent api format regarding tensor shape.

For example, If i want an input placeholder tensor of shape, `[None, 10]`

In tensorflow I instantiate it as:

`tf.placeholder(tf.float32,shape=[None, 10])`
`In []: <tf.Tensor 'Placeholder_4:0' shape=(?, 10) dtype=float32>`

However if I use the same vector as a shape vector in Keras `Input` tensor:

`Input(shape=[None, 10])`
`<tf.Tensor 'input_3:0' shape=(?, ?, 10) dtype=float32>`

Si it adds an extra dimension. 

Is this the desired behaviour? Not sure if this should be a feature request or a bug to be honest.
",manugarri,None,2016-10-22T23:56:03Z,2016-10-30T19:06:11Z
4148,masked merge concat fail after RNN,"code:

import numpy as np
from keras.layers import Input, merge, Masking, LSTM
from keras.models import Model

rand = lambda *shape: np.asarray(np.random.random(shape) > 0.5, dtype='int32')
# inputs

input_a = Input(shape=(3,4))
input_b = Input(shape=(3,4))
# masks

masked_a = Masking()(input_a)
masked_b = Masking()(input_b)
masked_a = LSTM(4, return_sequences=True)(masked_a)
# three different types of merging

merged_sum = merge([masked_a, masked_b], mode='sum')
merged_concat = merge([masked_a, masked_b], mode='concat', concat_axis=-1)
merged_concat_mixed = merge([masked_a, input_b], mode='concat', concat_axis=-1)
# test sum

model_sum = Model([input_a, input_b], [merged_sum])
model_sum.compile(loss='mse', optimizer='sgd')
model_sum.fit([rand(2, 3, 4), rand(2, 3, 4)], [rand(2, 3, 4)], nb_epoch=1)
# test concatenation

model_concat = Model([input_a, input_b], [merged_concat])
model_concat.compile(loss='mse', optimizer='sgd')
model_concat.fit([rand(2, 3, 4), rand(2, 3, 4)], [rand(2, 3, 8)], nb_epoch=1)
# test concatenation with masked and non-masked inputs

model_concat = Model([input_a, input_b], [merged_concat_mixed])
model_concat.compile(loss='mse', optimizer='sgd')
model_concat.fit([rand(2, 3, 4), rand(2, 3, 4)], [rand(2, 3, 8)], nb_epoch=1)

result:

Using Theano backend.
Using gpu device 0: GeForce GTX 860M (CNMeM is enabled with initial size: 80.0% of memory, cuDNN 5105)
Epoch 1/1
2/2 [==============================] - 0s - loss: 0.6706
<<!! BUG IN FGRAPH.REPLACE OR A LISTENER !!>> <class 'AssertionError'>  local_subtensor_merge
ERROR (theano.gof.opt): Optimization failure due to: local_subtensor_merge
ERROR (theano.gof.opt): node: Subtensor{int64:int64:int64}(Subtensor{int64::}.0, ScalarFromTensor.0, ScalarFromTensor.0, ScalarFromTensor.0)
ERROR (theano.gof.opt): TRACEBACK:
ERROR (theano.gof.opt): Traceback (most recent call last):
  File ""C:\Anaconda34\lib\site-packages\theano\gof\opt.py"", line 1962, in process_node
    remove=remove)
  File ""C:\Anaconda34\lib\site-packages\theano\gof\toolbox.py"", line 391, in replace_all_validate_remove
    chk = fgraph.replace_all_validate(replacements, reason)
  File ""C:\Anaconda34\lib\site-packages\theano\gof\toolbox.py"", line 340, in replace_all_validate
    fgraph.replace(r, new_r, reason=reason, verbose=False)
  File ""C:\Anaconda34\lib\site-packages\theano\gof\fg.py"", line 508, in replace
    self.change_input(node, i, new_r, reason=reason)
  File ""C:\Anaconda34\lib\site-packages\theano\gof\fg.py"", line 450, in change_input
    self.**import_r**(new_r, reason=reason)
  File ""C:\Anaconda34\lib\site-packages\theano\gof\fg.py"", line 351, in **import_r**
    self.**import**(variable.owner, reason=reason)
  File ""C:\Anaconda34\lib\site-packages\theano\gof\fg.py"", line 414, in **import**
    self.execute_callbacks('on_import', node, reason)
  File ""C:\Anaconda34\lib\site-packages\theano\gof\fg.py"", line 588, in execute_callbacks
    fn(self, _args, *_kwargs)
  File ""C:\Anaconda34\lib\site-packages\theano\tensor\opt.py"", line 1300, in on_import
    assert r in self.shape_of
AssertionError

Traceback (most recent call last):
  File ""C:/Users/eyalg/Dropbox/python/writer/temp.py"", line 30, in <module>
    model_concat.fit([rand(2, 3, 4), rand(2, 3, 4)], [rand(2, 3, 8)], nb_epoch=1)
  File ""C:\Anaconda34\lib\site-packages\keras\engine\training.py"", line 1092, in fit
    self._make_train_function()
  File ""C:\Anaconda34\lib\site-packages\keras\engine\training.py"", line 716, in _make_train_function
    *_self._function_kwargs)
  File ""C:\Anaconda34\lib\site-packages\keras\backend\theano_backend.py"", line 787, in function
    return Function(inputs, outputs, updates=updates, *_kwargs)
  File ""C:\Anaconda34\lib\site-packages\keras\backend\theano_backend.py"", line 773, in __init__
    *_kwargs)
  File ""C:\Anaconda34\lib\site-packages\theano\compile\function.py"", line 326, in function
    output_keys=output_keys)
  File ""C:\Anaconda34\lib\site-packages\theano\compile\pfunc.py"", line 486, in pfunc
    output_keys=output_keys)
  File ""C:\Anaconda34\lib\site-packages\theano\compile\function_module.py"", line 1776, in orig_function
    output_keys=output_keys).create(
  File ""C:\Anaconda34\lib\site-packages\theano\compile\function_module.py"", line 1458, in **init**
    optimizer_profile = optimizer(fgraph)
  File ""C:\Anaconda34\lib\site-packages\theano\gof\opt.py"", line 98, in **call**
    return self.optimize(fgraph)
  File ""C:\Anaconda34\lib\site-packages\theano\gof\opt.py"", line 87, in optimize
    ret = self.apply(fgraph, *args, *_kwargs)
  File ""C:\Anaconda34\lib\site-packages\theano\gof\opt.py"", line 235, in apply
    sub_prof = optimizer.optimize(fgraph)
  File ""C:\Anaconda34\lib\site-packages\theano\gof\opt.py"", line 87, in optimize
    ret = self.apply(fgraph, _args, *_kwargs)
  File ""C:\Anaconda34\lib\site-packages\theano\gof\opt.py"", line 2415, in apply
    lopt_change = self.process_node(fgraph, node, lopt)
  File ""C:\Anaconda34\lib\site-packages\theano\gof\opt.py"", line 1970, in process_node
    self.failure_callback(e, self, repl_pairs, lopt, node)
  File ""C:\Anaconda34\lib\site-packages\theano\gof\opt.py"", line 1821, in warn_inplace
    return NavigatorOptimizer.warn(exc, nav, repl_pairs, local_opt, node)
  File ""C:\Anaconda34\lib\site-packages\theano\gof\opt.py"", line 1807, in warn
    raise exc
  File ""C:\Anaconda34\lib\site-packages\theano\gof\opt.py"", line 1962, in process_node
    remove=remove)
  File ""C:\Anaconda34\lib\site-packages\theano\gof\toolbox.py"", line 391, in replace_all_validate_remove
    chk = fgraph.replace_all_validate(replacements, reason)
  File ""C:\Anaconda34\lib\site-packages\theano\gof\toolbox.py"", line 340, in replace_all_validate
    fgraph.replace(r, new_r, reason=reason, verbose=False)
  File ""C:\Anaconda34\lib\site-packages\theano\gof\fg.py"", line 508, in replace
    self.change_input(node, i, new_r, reason=reason)
  File ""C:\Anaconda34\lib\site-packages\theano\gof\fg.py"", line 450, in change_input
    self.**import_r**(new_r, reason=reason)
  File ""C:\Anaconda34\lib\site-packages\theano\gof\fg.py"", line 351, in **import_r**
    self.**import**(variable.owner, reason=reason)
  File ""C:\Anaconda34\lib\site-packages\theano\gof\fg.py"", line 414, in **import**
    self.execute_callbacks('on_import', node, reason)
  File ""C:\Anaconda34\lib\site-packages\theano\gof\fg.py"", line 588, in execute_callbacks
    fn(self, _args, *_kwargs)
  File ""C:\Anaconda34\lib\site-packages\theano\tensor\opt.py"", line 1300, in on_import
    assert r in self.shape_of
AssertionError

Process finished with exit code 1
",eyaler,None,2016-10-22T21:24:43Z,2016-10-23T12:52:53Z
4135,Fix json serialization in Lambda layer broken for windows + python3,"here: https://github.com/fchollet/keras/pull/3012 serialization was fixed for lambda layer by adding: .decode('raw_unicode_escape')

however if the code is in a folder or filename starting with the letter u or U, you get \u in the string due to windows notation. for example:
`<code object <lambda> at 0x0000000014BEBD20, file ""C:\Users\python\u_is_first_letter.py"", line 10>`

the decode then gives an error as:
`UnicodeDecodeError: 'rawunicodeescape' codec can't decode bytes in position ..-..: truncated \uXXXX`

apparently this is a python 3 issue. see here: https://bugs.python.org/issue19539

this is on latest master of theano and keras
",eyaler,b'stale',2016-10-21T00:45:33Z,2017-10-08T08:07:33Z
4123,it seems to be wrong progbar when verbose = 1 in the model.fit function,"Hi,
    I am a keras rookie. I have installed the keras and theano successfully at the latest version with the following command :
1. pip install git+git://github.com/Theano/Theano.git --upgrade --no-deps
2. pip install git+git://github.com/fchollet/keras.git --upgrade --no-deps 
   
   And I run some toy code, and got a strange output like that.

from keras.models import Sequential
from keras.layers import Dense
import numpy
seed = 7
numpy.random.seed(seed)
X = numpy.random.random((768,8))
Y = numpy.random.randint(2,size=(768,1))
model = Sequential()
model.add(Dense(12, input_dim=8, init='uniform', activation='relu'))
model.add(Dense(8, init='uniform', activation='relu'))
model.add(Dense(1, init='uniform', activation='sigmoid'))
model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
model.fit(X, Y, nb_epoch=150, batch_size=10, verbose=1)
scores = model.evaluate(X, Y, batch_size=40,verbose=1)
print(""%s: %.2f%%"" % (model.metrics_names[1], scores[1]*100))

the output is as follows:
768/768 [==============================] - 0s - loss: 0.6738 - acc: 0.5846
Epoch 147/150
768/768 [==============================] - 0s - loss: 0.6742 - acc: 0.5885
Epoch 148/150
768/768 [==============================] - 0s - loss: 0.6728 - acc: 0.5846
Epoch 149/150
768/768 [==============================] - 0s - loss: 0.6741 - acc: 0.5859
Epoch 150/150
768/768 [==============================] - 0s - loss: 0.6750 - acc: 0.5859
 40/768 [>.............................] - ETA: 0sacc: 59.37%

The progbar just run 1 batch and breaked.
After some limited debugging, I think it' wrong with the model.fit when verbose is set to 1.
So what I should do to solve it? It's seem to be OK just setting verbose to 0. 
",cyzhangAThit,b'stale',2016-10-20T01:16:08Z,2017-09-21T04:02:19Z
4096,image_dim_ordering causes very different convergence results (between using 'th' and 'tf' in keras config),"I am seeing **very** different convergence results when using 'th' and 'tf' in keras config file.
On both cases I'm using tensorflow backend.
I am fully aware of the different convention of dimension ordering between theano and tensorflow, and (hopefully) handle it correctly as you can see in the following gist.

**The bottom line is that I'm currently forced to use 'th' image_dim_ordering and ""suffer"" from extra copies which slow the training process**

Here's the gist of a standalone single-file reproducing of the problem:
https://gist.github.com/YoelShoshan/3ed8f827685d130cd01fbf787821ee87

I tried to make sure it runs without any issues, and has no external dependencies.

On one case I'm using this keras config file:

```
{
    ""floatx"": ""float32"",
    ""epsilon"": 1e-07,
    ""backend"": ""tensorflow"",
    ""image_dim_ordering"": ""th""  
}
```

In on the other case I switch the 'th' to 'tf'.

using 'th' converges **significantly** faster! (less iterations) and yes, I've tried many different random seeds.

on the 'th' this is a typical convergence scenario: **(4 epochs till convergence)**

```
Epoch 1/100
640/640 [==============================] - 3s - loss: 0.6891 - acc: 0.5594     
Epoch 2/100
640/640 [==============================] - 2s - loss: 0.6079 - acc: 0.7328     
Epoch 3/100
640/640 [==============================] - 2s - loss: 0.3166 - acc: 0.9422     
Epoch 4/100
640/640 [==============================] - 2s - loss: 0.1767 - acc: 0.9969  
```

and on 'tf' this is a typical convergence scenario: **(27 epochs till convergence!)**

```
Epoch 1/100
640/640 [==============================] - 1s - loss: 0.6932 - acc: 0.4781     
Epoch 2/100
640/640 [==============================] - 0s - loss: 0.6932 - acc: 0.4938     
Epoch 3/100
640/640 [==============================] - 0s - loss: 0.6921 - acc: 0.5203     
Epoch 4/100
640/640 [==============================] - 0s - loss: 0.6920 - acc: 0.5469     
Epoch 5/100
640/640 [==============================] - 0s - loss: 0.6935 - acc: 0.4875     
Epoch 6/100
640/640 [==============================] - 0s - loss: 0.6941 - acc: 0.4969     
Epoch 7/100
640/640 [==============================] - 0s - loss: 0.6937 - acc: 0.5047     
Epoch 8/100
640/640 [==============================] - 0s - loss: 0.6931 - acc: 0.5312     
Epoch 9/100
640/640 [==============================] - 0s - loss: 0.6923 - acc: 0.5250     
Epoch 10/100
640/640 [==============================] - 0s - loss: 0.6929 - acc: 0.5281     
Epoch 11/100
640/640 [==============================] - 0s - loss: 0.6934 - acc: 0.4953     
Epoch 12/100
640/640 [==============================] - 0s - loss: 0.6918 - acc: 0.5234     
Epoch 13/100
640/640 [==============================] - 0s - loss: 0.6930 - acc: 0.5125     
Epoch 14/100
640/640 [==============================] - 0s - loss: 0.6939 - acc: 0.4797     
Epoch 15/100
640/640 [==============================] - 0s - loss: 0.6936 - acc: 0.5047     
Epoch 16/100
640/640 [==============================] - 0s - loss: 0.6917 - acc: 0.4922     
Epoch 17/100
640/640 [==============================] - 0s - loss: 0.6945 - acc: 0.4891     
Epoch 18/100
640/640 [==============================] - 0s - loss: 0.6948 - acc: 0.5000     
Epoch 19/100
640/640 [==============================] - 0s - loss: 0.6968 - acc: 0.4594     
Epoch 20/100
640/640 [==============================] - 0s - loss: 0.6919 - acc: 0.5391     
Epoch 21/100
640/640 [==============================] - 0s - loss: 0.6904 - acc: 0.5172     
Epoch 22/100
640/640 [==============================] - 0s - loss: 0.6881 - acc: 0.5906     
Epoch 23/100
640/640 [==============================] - 0s - loss: 0.6804 - acc: 0.6359     
Epoch 24/100
640/640 [==============================] - 0s - loss: 0.6470 - acc: 0.8219     
Epoch 25/100
640/640 [==============================] - 0s - loss: 0.4134 - acc: 0.9625     
Epoch 26/100
640/640 [==============================] - 0s - loss: 0.2347 - acc: 0.9953     
Epoch 27/100
640/640 [==============================] - 0s - loss: 0.1231 - acc: 1.0000 

```

For simplification, all that the neural network needs to do in the gist that I provided, is to distinguish between patches  containing only the value -1.0 and between patches containing only the value 1.0

This is a toy example, and it might be worst on actual examples.

Is this expected behavior or a bug?

Cheers and thanks for this awesome lib! :)
Yoel.
",YoelShoshan,b'stale',2016-10-17T19:06:17Z,2017-06-22T22:14:57Z
4050,Automatic Image Inpainting with Keras and GpuElemwise Errors,"@fchollet @EderSantana 
Hi... Before anything I wanted to thank you for the hard work you've been putting into Keras... It's really become a splendid creation... Thanks!

I have a Model => Input : Gray Image : (1, 224, 224) || Output : RGB Image: (3, 224, 224)
and I want to predict pixel colors by giving it Grayscale images and getting RGB ones.
I tried to make a network in Keras which mostly resembles [this one (which has been made in Tensorflow)](http://tinyclouds.org/colorize).

Here's the Model code :

```
first_input = Input(batch_shape=(None, 1, 224, 224))

conv0_1_3 = Convolution2D(3, 3, 3, activation='relu', name='conv0_1_3', border_mode='same')(first_input)

conv1_1_64 = Convolution2D(64, 3, 3, activation='relu', name='conv1_1', border_mode='same')(conv0_1_3)
conv1_2_64 = Convolution2D(64, 3, 3, activation='relu', name='conv1_2', border_mode='same')(conv1_1_64)
conv1_2_64 = MaxPooling2D((2, 2))(conv1_2_64)

conv2_1_128 = Convolution2D(128, 3, 3, activation='relu', name='conv2_1', border_mode='same')(conv1_2_64)
conv2_2_128 = Convolution2D(128, 3, 3, activation='relu', name='conv2_2', border_mode='same')(conv2_1_128)
conv2_2_128 = MaxPooling2D((2, 2))(conv2_2_128)

conv3_1_256 = Convolution2D(256, 3, 3, activation='relu', name='conv3_1', border_mode='same')(conv2_2_128)
conv3_2_256 = Convolution2D(256, 3, 3, activation='relu', name='conv3_2', border_mode='same')(conv3_1_256)
conv3_3_256 = Convolution2D(256, 3, 3, activation='relu', name='conv3_3', border_mode='same')(conv3_2_256)
conv3_3_256 = MaxPooling2D((2, 2))(conv3_3_256)

conv4_1_512 = Convolution2D(512, 3, 3, activation='relu', name='conv4_1', border_mode='same')(conv3_3_256)
conv4_2_512 = Convolution2D(512, 3, 3, activation='relu', name='conv4_2', border_mode='same')(conv4_1_512)
conv4_3_512 = Convolution2D(512, 3, 3, activation='relu', name='conv4_3', border_mode='same')(conv4_2_512)
conv4_3_512 = MaxPooling2D((2, 2))(conv4_3_512)

residual1 = BatchNormalization(axis=1, name='batch1')(conv4_3_512)
residual1 = Convolution2D(256, 3, 3, activation='relu', name='residual1', border_mode='same')(residual1)
residual1 = UpSampling2D(name='upsample1')(residual1)

conv3_3_256_batch_norm = BatchNormalization(axis=1, name='batch2')(conv3_3_256)
merge1 = merge((conv3_3_256_batch_norm, residual1), mode='concat', name='merge1', concat_axis=0)
residual2 = Convolution2D(128, 3, 3, activation='relu', name='residual2', border_mode='same')(merge1)
residual2 = UpSampling2D(name='upsample2')(residual2)

conv2_2_128_batch_norm = BatchNormalization(axis=1, name='batch3')(conv2_2_128)
merge2 = merge((conv2_2_128_batch_norm, residual2), mode='concat', name='merge2', concat_axis=0)
residual3 = Convolution2D(64, 3, 3, activation='relu', name='residual3', border_mode='same')(merge2)
residual3 = UpSampling2D(name='upsample3')(residual3)

conv1_2_64_batch_norm = BatchNormalization(axis=1, name='batch4')(conv1_2_64)
merge3 = merge((conv1_2_64_batch_norm, residual3), mode='concat', name='merge3', concat_axis=0)
residual4 = Convolution2D(3, 3, 3, activation='relu', name='residual4', border_mode='same')(merge3)
residual4 = UpSampling2D(name='upsample4')(residual4)

conv0_1_3_batch_norm = BatchNormalization(axis=1, name='batch5')(conv0_1_3)
merge4 = merge((conv0_1_3_batch_norm, residual4), mode='concat', name='merge4', concat_axis=0)
residual5 = Convolution2D(3, 1, 1, activation='relu', name='residual5', border_mode='same')(merge4)

model = Model(input=first_input, output=residual5)
```

and here's the Model Summary:

```
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
input_1 (InputLayer)             (None, 1, 224, 224)   0                                            
____________________________________________________________________________________________________
conv0_1_3 (Convolution2D)        (None, 3, 224, 224)   30          input_1[0][0]                    
____________________________________________________________________________________________________
conv1_1 (Convolution2D)          (None, 64, 224, 224)  1792        conv0_1_3[0][0]                  
____________________________________________________________________________________________________
conv1_2 (Convolution2D)          (None, 64, 224, 224)  36928       conv1_1[0][0]                    
____________________________________________________________________________________________________
maxpooling2d_1 (MaxPooling2D)    (None, 64, 112, 112)  0           conv1_2[0][0]                    
____________________________________________________________________________________________________
conv2_1 (Convolution2D)          (None, 128, 112, 112) 73856       maxpooling2d_1[0][0]             
____________________________________________________________________________________________________
conv2_2 (Convolution2D)          (None, 128, 112, 112) 147584      conv2_1[0][0]                    
____________________________________________________________________________________________________
maxpooling2d_2 (MaxPooling2D)    (None, 128, 56, 56)   0           conv2_2[0][0]                    
____________________________________________________________________________________________________
conv3_1 (Convolution2D)          (None, 256, 56, 56)   295168      maxpooling2d_2[0][0]             
____________________________________________________________________________________________________
conv3_2 (Convolution2D)          (None, 256, 56, 56)   590080      conv3_1[0][0]                    
____________________________________________________________________________________________________
conv3_3 (Convolution2D)          (None, 256, 56, 56)   590080      conv3_2[0][0]                    
____________________________________________________________________________________________________
maxpooling2d_3 (MaxPooling2D)    (None, 256, 28, 28)   0           conv3_3[0][0]                    
____________________________________________________________________________________________________
conv4_1 (Convolution2D)          (None, 512, 28, 28)   1180160     maxpooling2d_3[0][0]             
____________________________________________________________________________________________________
conv4_2 (Convolution2D)          (None, 512, 28, 28)   2359808     conv4_1[0][0]                    
____________________________________________________________________________________________________
conv4_3 (Convolution2D)          (None, 512, 28, 28)   2359808     conv4_2[0][0]                    
____________________________________________________________________________________________________
maxpooling2d_4 (MaxPooling2D)    (None, 512, 14, 14)   0           conv4_3[0][0]                    
____________________________________________________________________________________________________
batch1 (BatchNormalization)      (None, 512, 14, 14)   1024        maxpooling2d_4[0][0]             
____________________________________________________________________________________________________
residual1 (Convolution2D)        (None, 256, 14, 14)   1179904     batch1[0][0]                     
____________________________________________________________________________________________________
batch2 (BatchNormalization)      (None, 256, 28, 28)   512         maxpooling2d_3[0][0]             
____________________________________________________________________________________________________
upsample1 (UpSampling2D)         (None, 256, 28, 28)   0           residual1[0][0]                  
____________________________________________________________________________________________________
merge1 (Merge)                   (None, 256, 28, 28)   0           batch2[0][0]                     
                                                                   upsample1[0][0]                  
____________________________________________________________________________________________________
residual2 (Convolution2D)        (None, 128, 28, 28)   295040      merge1[0][0]                     
____________________________________________________________________________________________________
batch3 (BatchNormalization)      (None, 128, 56, 56)   256         maxpooling2d_2[0][0]             
____________________________________________________________________________________________________
upsample2 (UpSampling2D)         (None, 128, 56, 56)   0           residual2[0][0]                  
____________________________________________________________________________________________________
merge2 (Merge)                   (None, 128, 56, 56)   0           batch3[0][0]                     
                                                                   upsample2[0][0]                  
____________________________________________________________________________________________________
residual3 (Convolution2D)        (None, 64, 56, 56)    73792       merge2[0][0]                     
____________________________________________________________________________________________________
batch4 (BatchNormalization)      (None, 64, 112, 112)  128         maxpooling2d_1[0][0]             
____________________________________________________________________________________________________
upsample3 (UpSampling2D)         (None, 64, 112, 112)  0           residual3[0][0]                  
____________________________________________________________________________________________________
merge3 (Merge)                   (None, 64, 112, 112)  0           batch4[0][0]                     
                                                                   upsample3[0][0]                  
____________________________________________________________________________________________________
residual4 (Convolution2D)        (None, 3, 112, 112)   1731        merge3[0][0]                     
____________________________________________________________________________________________________
batch5 (BatchNormalization)      (None, 3, 224, 224)   6           conv0_1_3[0][0]                  
____________________________________________________________________________________________________
upsample4 (UpSampling2D)         (None, 3, 224, 224)   0           residual4[0][0]                  
____________________________________________________________________________________________________
merge4 (Merge)                   (None, 3, 224, 224)   0           batch5[0][0]                     
                                                                   upsample4[0][0]                  
____________________________________________________________________________________________________
residual5 (Convolution2D)        (None, 3, 224, 224)   12          merge4[0][0]                     
====================================================================================================
Total params: 9187699
```

I don't know what I'm doing wrong since the summary fits exactly with what I have in mind but no matter what, I keep getting this error :

> ValueError: GpuElemwise. Input dimension mis-match. Input 2 (indices start at 0) has shape[0] == 1, but the output's size on that axis is 5.
> Apply node that caused the error: GpuElemwise{Composite{((i0 \* (i1 + Abs(i1))) - i2)},no_inplace}(CudaNdarrayConstant{[[[[ 0.5]]]]}, GpuElemwise{Add}[(0, 0)].0, GpuFromHost.0)
> Toposort index: 916
> Inputs types: [CudaNdarrayType(float32, (True, True, True, True)), CudaNdarrayType(float32, 4D), CudaNdarrayType(float32, 4D)]
> Inputs shapes: [(1, 1, 1, 1), (5, 3, 224, 224), (1, 3, 224, 224)]
> Inputs strides: [(0, 0, 0, 0), (150528, 50176, 224, 1), (0, 50176, 224, 1)]
> Inputs values: [CudaNdarray([[[[ 0.5]]]]), 'not shown', 'not shown']
> Inputs type_num: ['', '', '']

I've included a Graph of the Model with this question too:
![model](https://cloud.githubusercontent.com/assets/22426131/19362112/3368c77c-9192-11e6-99d9-643600b77c4b.png)

Debugging this is a nightmare... most of the other errors are pretty easy to understand and fix but these errors are really hard to understand... and unfortunately this isn't the first time I've had these errors with Keras.

Please! what is wrong with this model?! am I doing something completely wrong or perhaps this model shouldn't be designed this way?

Thanks so much...
",Neltherion,None,2016-10-13T18:49:26Z,2016-10-14T06:03:26Z
4020,AttributeError: 'Graph' object has no attribute 'layers',"Please make sure that the boxes below are checked before you submit your issue. Thank you!
- [x] Check that you are up-to-date with the master branch of Keras. You can update with:
  pip install git+git://github.com/fchollet/keras.git --upgrade --no-deps
- [x] If running on Theano, check that you are up-to-date with the master branch of Theano. You can update with:
  pip install git+git://github.com/Theano/Theano.git --upgrade --no-deps
- [x] Provide a link to a GitHub Gist of a Python script that can reproduce your issue (or just copy the script here if it is short).

```
In [1]: from keras.models import *
Using TensorFlow backend.

In [2]: model = Sequential()

In [3]: model.summary()
____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
Total params: 0
____________________________________________________________________________________________________

In [4]: model = Graph()

In [5]: model.summary()
---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
<ipython-input-5-9a7881f870d4> in <module>()
----> 1 model.summary()

/usr/local/lib/python2.7/dist-packages/Keras-1.1.0-py2.7.egg/keras/engine/topology.pyc in summary(self, line_length, positions)
   2687             flattened_layers = self.flattened_layers
   2688         else:
-> 2689             flattened_layers = self.layers
   2690 
   2691         print_summary(flattened_layers, getattr(self, 'container_nodes', None), line_length=line_length, positions=positions)

AttributeError: 'Graph' object has no attribute 'layers'

```

I'm on the latest version of Keras and this happens even if the graph is not empty. If this is a bug and it can be reproduced by others too, then I can try to work on this.
",AnishShah,None,2016-10-11T08:36:13Z,2016-10-11T17:59:46Z
4018,Upsampling fails with Atrous Convolution,"It seems Upsampling2D loses track of image size when it comes after a dilated convolution. The only difference between these two models is the atrous_rate. (I'm using tensorflow 0.11, but the error occurs for both dim_orderings={'th','tf'})

```
K.set_image_dim_ordering('th')     

working_model = Sequential()  
working_model.add(ZeroPadding2D((1,1),input_shape=(3,224,224)))  
working_model.add(AtrousConvolution2D(64,3,3, activation='relu',atrous_rate=(1,1)))  
working_model.add(UpSampling2D(size=(2,2)))  
working_model.summary()  

bug_model = Sequential()  
bug_model.add(ZeroPadding2D((1,1),input_shape=(3,224,224)))  
bug_model.add(AtrousConvolution2D(64,3,3, activation='relu',atrous_rate=(2,2)))  
bug_model.summary()  
bug_model.add(UpSampling2D(size=(2,2)))  
```

Error: notice how the summaries output the correct dimensions for the convolution even though tf shape output does not for the 2nd model.

```
[<tf.Tensor 'zeropadding2d_input_1:0' shape=(?, 3, 224, 224) dtype=float32>]
[<tf.Tensor 'Pad:0' shape=(?, 3, 226, 226) dtype=float32>]
[<tf.Tensor 'Relu:0' shape=(?, 64, 224, 224) dtype=float32>]

Layer (type)                     Output Shape          Param #     Connected to
==========================================================================================
zeropadding2d_1 (ZeroPadding2D)  (None, 3, 226, 226)   0           zeropadding2d_input_1[0
__________________________________________________________________________________________
atrousconvolution2d_1 (AtrousConv(None, 64, 224, 224)  1792        zeropadding2d_1[0][0]
__________________________________________________________________________________________
upsampling2d_1 (UpSampling2D)    (None, 64, 448, 448)  0           atrousconvolution2d_1[0
==========================================================================================
Total params: 1792


[<tf.Tensor 'zeropadding2d_input_2:0' shape=(?, 3, 224, 224) dtype=float32>]
[<tf.Tensor 'Pad_1:0' shape=(?, 3, 226, 226) dtype=float32>]
[<tf.Tensor 'Relu_1:0' shape=(?, 64, ?, ?) dtype=float32>]

Layer (type)                     Output Shape          Param #     Connected to
==========================================================================================
zeropadding2d_2 (ZeroPadding2D)  (None, 3, 226, 226)   0           zeropadding2d_input_2[0
__________________________________________________________________________________________
atrousconvolution2d_2 (AtrousConv(None, 64, 222, 222)  1792        zeropadding2d_2[0][0]
==========================================================================================
Total params: 1792


Traceback (most recent call last):
    bug_model.add(UpSampling2D(size=(2,2)))
File ""../keras/models.py"", line 308, in add
    output_tensor = layer(self.outputs[0])
File ""../keras/engine/topology.py"", line 514, in __call__
    self.add_inbound_node(inbound_layers, node_indices, tensor_indices)
File ""../keras/engine/topology.py"", line 572, in add_inbound_node
    Node.create_node(self, inbound_layers, node_indices, tensor_indices)
File ""../keras/layers/convolutional.py"", line 1336, in call
    self.dim_ordering)
File ""../keras/backend/tensorflow_backend.py"", line 757, in resize_images
    X.set_shape((None, original_shape[1] * height_factor, original_shape[2] * width_factor, None))
TypeError: unsupported operand type(s) for *: 'NoneType' and 'int'`
```

where I modified keras.engine.topology.create_node to print out the tensor shapes above:

```
for inbound_layer, node_index, tensor_index in zip(inbound_layers, node_indices, t
            inbound_node = inbound_layer.inbound_nodes[node_index]
            input_tensors.append(inbound_node.output_tensors[tensor_index])
            input_masks.append(inbound_node.output_masks[tensor_index])
            input_shapes.append(inbound_node.output_shapes[tensor_index])

        assert len(input_shapes) == len(input_tensors) == len(input_masks)
+       print (input_tensors)
```
",longlouisly,b'stale',2016-10-11T08:00:11Z,2017-07-22T19:57:19Z
4001,The type of the replacement must be compatible with the type of the original Variable ？ MergeOptimizer,"<<!! BUG IN FGRAPH.REPLACE OR A LISTENER !!>> <type 'exceptions.TypeError'> ('The type of the replacement must be compatible with the type of the original Variable.', GpuReshape{4}.0, GpuReshape{4}.0, CudaNdarrayType(float32, (False, False, True, False)), CudaNdarrayType(float32, 4D), 'MergeOptimizer') MergeOptimizer
ERROR (theano.gof.opt): SeqOptimizer apply <theano.gof.opt.EquilibriumOptimizer object at 0x00000000345A17B8>
ERROR (theano.gof.opt): Traceback:
ERROR (theano.gof.opt): Traceback (most recent call last):
  File ""C:\Anaconda2\lib\site-packages\theano\gof\opt.py"", line 230, in apply
    sub_prof = optimizer.optimize(fgraph)
  File ""C:\Anaconda2\lib\site-packages\theano\gof\opt.py"", line 89, in optimize
    ret = self.apply(fgraph, _args, *_kwargs)
  File ""C:\Anaconda2\lib\site-packages\theano\gof\opt.py"", line 2223, in apply
    sub_prof = gopt.apply(fgraph)
  File ""C:\Anaconda2\lib\site-packages\theano\gof\opt.py"", line 817, in apply
    fgraph.replace_all_validate(pairs, 'MergeOptimizer')
  File ""C:\Anaconda2\lib\site-packages\theano\gof\toolbox.py"", line 309, in replace_all_validate
    fgraph.replace(r, new_r, reason=reason, verbose=False)
  File ""C:\Anaconda2\lib\site-packages\theano\gof\fg.py"", line 561, in replace
    str(reason))
TypeError: ('The type of the replacement must be compatible with the type of the original Variable.', GpuReshape{4}.0, GpuReshape{4}.0, CudaNdarrayType(float32, (False, False, True, False)), CudaNdarrayType(float32, 4D), 'MergeOptimizer')
",wdl000001,b'stale',2016-10-08T16:30:49Z,2017-08-16T15:22:46Z
3972,Convert VGG 16 to 3D for activity recognition ,"Hello all I'm trying to convert VGG16 to 3D model for action recognition task but I'm getting error.
I tried to run it on GPU and on CPU. my GPU has 4 GB memory.

`
from keras.models import Sequential
from keras.layers.core import Flatten, Dense, Dropout

from keras.optimizers import SGD
import cv2, numpy as np
from keras.layers.convolutional import (Convolution3D, MaxPooling3D,
                                        ZeroPadding3D)

def VGG_16(weights_path=None):
    model = Sequential()
    model.add(ZeroPadding3D((0,1,1),input_shape=(3,16,224,224)))
    model.add(Convolution3D(64, 3, 3,3, activation='relu',dim_ordering='tf'))
    model.add(ZeroPadding3D((0,1,1)))
    model.add(Convolution3D(64, 3, 3,3, activation='relu',dim_ordering='tf'))
    model.add(MaxPooling3D(pool_size=(1,2,2), strides=(1,2,2)))

```
model.add(ZeroPadding3D((0,1,1)))
model.add(Convolution3D(128, 3, 3,3, activation='relu',dim_ordering='tf'))
model.add(ZeroPadding3D((0,1,1)))
model.add(Convolution3D(128, 3,3, 3, activation='relu',dim_ordering='tf'))
model.add(MaxPooling3D(pool_size=(1,2,2), strides=(1,2,2),dim_ordering='tf'))

model.add(ZeroPadding3D((0,1,1)))
model.add(Convolution3D(256, 3, 3,3, activation='relu',dim_ordering='tf'))
model.add(ZeroPadding3D((0,1,1)))
model.add(Convolution3D(256, 3,3, 3, activation='relu',dim_ordering='tf'))
model.add(ZeroPadding3D((0,1,1)))
model.add(Convolution3D(256, 3,3, 3, activation='relu',dim_ordering='tf'))
model.add(MaxPooling3D(pool_size=(1,2,2), strides=(1,2,2),dim_ordering='tf'))

model.add(ZeroPadding3D((0,1,1)))
model.add(Convolution3D(512, 3,3, 3, activation='relu',dim_ordering='tf'))
model.add(ZeroPadding3D((0,1,1)))
model.add(Convolution3D(512, 3,3, 3, activation='relu',dim_ordering='tf'))
model.add(ZeroPadding3D((0,1,1)))
model.add(Convolution3D(512,3, 3, 3, activation='relu',dim_ordering='tf'))
model.add(MaxPooling3D(pool_size=(2,2,2), strides=(2,2,2),dim_ordering='tf'))

model.add(ZeroPadding3D((0,1,1)))
model.add(Convolution3D(512, 3,3, 3, activation='relu',dim_ordering='tf'))
model.add(ZeroPadding3D((0,1,1)))
model.add(Convolution3D(512,3, 3, 3, activation='relu',dim_ordering='tf'))
model.add(ZeroPadding3D((0,1,1)))
model.add(Convolution3D(512, 3,3, 3, activation='relu',dim_ordering='tf'))
model.add(MaxPooling3D(pool_size=(2,2,2), strides=(2,2,2),dim_ordering='tf'))

model.add(Flatten())
xout=model.output_shape
xin=model.input_shape
model.add(Dense(4096, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(4096, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(1000, activation='softmax'))

#if weights_path:
  #  model.load_weights(weights_path)

return model
```

if **name** == ""**main**"":
    im = cv2.resize(cv2.imread('ss.jpg'), (224, 224)).astype(np.float32)
    im[:,:,0] -= 103.939
    im[:,:,1] -= 116.779
    im[:,:,2] -= 123.68
    im = im.transpose((2,0,1))
    im = np.expand_dims(im, axis=0)
    snap=[]
    for i in range(16):
        snap.append(im)
    print '***************************************'

```
snap=np.array(snap)
print snap.shape
#snap=np.reshape(snap,(snap.shape[0],snap.shape[2],snap.shape[3],snap.shape[4]))
snap=snap.transpose((1,2,0,3,4))
#snap=np.expand_dims(snap, axis=0)
print snap.shape
print '++++++++++++++++++++++++++++++++++++++'

# Test pretrained model
model = VGG_16()
sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)
model.compile(optimizer=sgd, loss='categorical_crossentropy')
out = model.predict(snap)
```

   # print np.argmax(out)
`
and Here is the   error message:

`Using Theano backend.

---

(16, 1, 3, 224, 224)
(1, 3, 16, 224, 224)
++++++++++++++++++++++++++++++++++++++
Traceback (most recent call last):
  File ""VGG16_3D.py"", line 85, in <module>
    out = model.predict(snap)
  File ""/usr/local/lib/python2.7/dist-packages/keras/models.py"", line 671, in predict
    return self.model.predict(x, batch_size=batch_size, verbose=verbose)
  File ""/usr/local/lib/python2.7/dist-packages/keras/engine/training.py"", line 1177, in predict
    batch_size=batch_size, verbose=verbose)
  File ""/usr/local/lib/python2.7/dist-packages/keras/engine/training.py"", line 876, in _predict_loop
    batch_outs = f(ins_batch)
  File ""/usr/local/lib/python2.7/dist-packages/keras/backend/theano_backend.py"", line 672, in __call__
    return self.function(_inputs)
  File ""/usr/local/lib/python2.7/dist-packages/theano/compile/function_module.py"", line 871, in **call**
    storage_map=getattr(self.fn, 'storage_map', None))
  File ""/usr/local/lib/python2.7/dist-packages/theano/gof/link.py"", line 314, in raise_with_op
    reraise(exc_type, exc_value, exc_trace)
  File ""/usr/local/lib/python2.7/dist-packages/theano/compile/function_module.py"", line 859, in **call**
    outputs = self.fn()
  File ""/usr/local/lib/python2.7/dist-packages/theano/gof/op.py"", line 912, in rval
    r = p(n, [x[0] for x in i], o)
  File ""/usr/local/lib/python2.7/dist-packages/theano/tensor/nnet/conv3d2d.py"", line 110, in perform
    xview = get_diagonal_subtensor_view(_inputs)
  File ""/usr/local/lib/python2.7/dist-packages/theano/tensor/nnet/conv3d2d.py"", line 23, in get_diagonal_subtensor_view
    raise NotImplementedError('is this allowed?')
NotImplementedError: is this allowed?
Apply node that caused the error: DiagonalSubtensor{inplace}(Reshape{6}.0, TensorConstant{1}, TensorConstant{3})
Toposort index: 190
Inputs types: [TensorType(float32, 6D), TensorType(int8, scalar), TensorType(int8, scalar)]
Inputs shapes: [(1, 1, 64, 3, 12, 224), (), ()]
Inputs strides: [(2064384, 2064384, 32256, 10752, 896, 4), (), ()]
Inputs values: ['not shown', array(1, dtype=int8), array(3, dtype=int8)]
Outputs clients: [[Sum{axis=[3], acc_dtype=float64}(DiagonalSubtensor{inplace}.0), Shape_i{4}(DiagonalSubtensor{inplace}.0), Shape_i{5}(DiagonalSubtensor{inplace}.0), Shape_i{2}(DiagonalSubtensor{inplace}.0), Shape_i{1}(DiagonalSubtensor{inplace}.0), Shape_i{0}(DiagonalSubtensor{inplace}.0)]]

Backtrace when the node is created(use Theano flag traceback.limit=N to make it longer):
  File ""VGG16_3D.py"", line 82, in <module>
    model = VGG_16()
  File ""VGG16_3D.py"", line 14, in VGG_16
    model.add(Convolution3D(64, 3, 3,3, activation='relu',dim_ordering='tf'))
  File ""/usr/local/lib/python2.7/dist-packages/keras/models.py"", line 308, in add
    output_tensor = layer(self.outputs[0])
  File ""/usr/local/lib/python2.7/dist-packages/keras/engine/topology.py"", line 515, in **call**
    self.add_inbound_node(inbound_layers, node_indices, tensor_indices)
  File ""/usr/local/lib/python2.7/dist-packages/keras/engine/topology.py"", line 573, in add_inbound_node
    Node.create_node(self, inbound_layers, node_indices, tensor_indices)
  File ""/usr/local/lib/python2.7/dist-packages/keras/engine/topology.py"", line 150, in create_node
    output_tensors = to_list(outbound_layer.call(input_tensors[0], mask=input_masks[0]))
  File ""/usr/local/lib/python2.7/dist-packages/keras/layers/convolutional.py"", line 1086, in call
    filter_shape=self.W_shape)
  File ""/usr/local/lib/python2.7/dist-packages/keras/backend/theano_backend.py"", line 1203, in conv3d
    border_mode=border_mode_3d)

HINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.

`
",adelsalehali1982,b'stale',2016-10-05T14:52:55Z,2017-06-22T21:12:04Z
3966,Sharing Ideas on Continuous Expansion of FAQ,"Following the discussion on slack, I am trying to compile a list of questions from the last 3 days for the purpose of finding trends and updating FAQ. The current idea is to compile a summary page for issues during a period, say weekly, and picking candidates to add to FAQ. 

You are welcome to share your thoughts, specially on
- 1. whether this is useful
- 2. how to go about it by using community efforts - commitment from specific people might not be a long term solution. 
  I have spent almost 2 hours compiling the questions from last 3 days - somehow longer than I expected. 
- 3. collection of questions fr om both issue pages and gitter, slack groups
- 4. formats of this sharing

For this experiment, I have put questions in the following categories.
- **_bug**_: bug reporting
- **_documentation**_: chance for revision of documentation 
- **_configuration**_: installation, configuration, integration with other tools
- **_performance**_: need suggestions for performance improvments
- **_customization**_: lego-building new layers/models by Keras
- **_enhancement**_: feature requests, modifications for Keras itself

See the compilation below.
# Bug
## [Gradients may become inf/nan through merge(mode = 'cos') #3941](https://github.com/fchollet/keras/issues/3941)
- Description: Suggestion of changing `merge(mode='cos')` implementation to avoid `inf/nan` gradients error
## [Compatibility models keras 1.0.4 and 1.1.0 #3957](https://github.com/fchollet/keras/issues/3957)
- Description: Models trained on Keras 1.0.4 cannot be loaded in 1.1.0
## [fail to load model with multiple outputs that have multiple metrics #3958](https://github.com/fchollet/keras/issues/3958)
- Description: `load_model` doesn't work for multiple output with multiple metrics
## [Cifar-10 example not converging when image_dim_ordering == 'tf' #3959](https://github.com/fchollet/keras/issues/3959)
- Description: 'cifar-10' example doesn't work with `tf` image_dim_ordering
## [load_model fails to load optimizer #3964](https://github.com/fchollet/keras/issues/3964)
- Description: `load_model` fails to load optimizer but `model_from_json` and `load_weights` work fine
## [None type on input size does not seem to work. #3965](https://github.com/fchollet/keras/issues/3965)
- Description: Specifying `None` in `input_shape` for `Convolution2D` with `tf` backend throws error
# Documentation
## [Dimension conventions #3925](https://github.com/fchollet/keras/issues/3925)
- Description: Explaination of 'th' and 'tf' image_dim_ordering for image and sequence data
## [Unable to Call model.predict_classes() #3938](https://github.com/fchollet/keras/issues/3938)
- Description: calling `predict_classes` on a non-sequential model throws an error
## [Keras MaxPooling2D gives ValueError: Negative dimension size caused by subtracting 2 from 1 for 'MaxPool_x' #3945](https://github.com/fchollet/keras/issues/3945)
- Description: ""Negative Dimension"" error by MaxPooling2D without explicitly specifying `dim_ordering`
## [flow_from_directory seems to find no images #3946](https://github.com/fchollet/keras/issues/3946)
- Description: `ImageDataGenerator.flow_from_directory` didn't work if there is no subdir created
## [Input, InputLayer, Embedding, Merge does not import #3951](https://github.com/fchollet/keras/issues/3951)
- Description: importing from `keras.layers.core` doesn't work any more
# Configuration
## [Theano backend will not work on AWS Ubuntu:14.04 #3936](https://github.com/fchollet/keras/issues/3936)
- Description: Configuring Keras on AWS with Flask, with different backend supports
# Performance
## [Memory not released from the gpu #3939](https://github.com/fchollet/keras/issues/3939)
- Description: GPU runs out of memory and `gc.collect()` doesn't work
## [Out of memory after 4 epochs #3954](https://github.com/fchollet/keras/issues/3954)
- Description: GPU runs out of memory and `gc.collect()` doesn't work
## [How to normalize input #3943](https://github.com/fchollet/keras/issues/3943)
- Description: Effects of normalizing inputs in sequence classification by RNN
## [BatchNorm with statistics from whole dataset #3949](https://github.com/fchollet/keras/issues/3949)
- Description: `BatchNormalization` has a high `momentum` value which influences performances
## [keras 1.1.0 conv problems? #3956](https://github.com/fchollet/keras/issues/3956)
- Description: Performance change of `Convolution2D`, `MaxPooling2D` from 1.0.6 to 1.1.0
# Customization
## [SRGAN - Bypass check_array_lengths(X, Y, W) in training.py for different input and output batch sizes #3940](https://github.com/fchollet/keras/issues/3940)
- Description: Effective way of implementing SRGAN
## [Implementing Custom Bilinear tensor product layer in keras #3944](https://github.com/fchollet/keras/issues/3944)
- Description: Implementing Bilinear tensor product layer
## [error making simple FFT layer #3950](https://github.com/fchollet/keras/issues/3950)
- Description: How to implement 1D FFT layer in Keras
## [How to create multiple outputs of sigmoid activation with shared layers #3960](https://github.com/fchollet/keras/issues/3960)
- Description: Replacing `softmax` with n `sigmoid` activations
## [How to parallelize fit_generator? (PicklingError) #3962](https://github.com/fchollet/keras/issues/3962)
- Description: Parallelizing data geneator
# Enhancement
## [GlobalPooling for 3D inputs #3942](https://github.com/fchollet/keras/issues/3942)
- Description: Suggestion of adding `GlobalMaxPooling3D` and `GlobalAveragePooling3D`
## [Feature Request: Output transformation in ImageDataGenerator #3953](https://github.com/fchollet/keras/issues/3953)
- Description: adding ""output transformation"" feature in `ImageDataGeneator`
",dolaameng,None,2016-10-05T04:25:51Z,2016-10-20T12:49:16Z
3962,How to parallelize fit_generator? (PicklingError),"I tried several ways but cannot get parallelization of sample / data generation to work successfully. Below is a gist. Am I doing something wrong, or is there a bug?

https://gist.github.com/stmax82/283ef735c8e2601ef841de8b37243ee1

I suppose that my fourth try would be the correct one - but when I set pickle_safe=True, I get the error:

```
PicklingError: Can't pickle <function generator_queue.<locals>.data_generator_task at 0x000000001B042EA0>: attribute lookup data_generator_task on keras.engine.training failed
```
",stmax82,b'stale',2016-10-04T15:42:10Z,2018-06-28T04:46:55Z
3959,Cifar-10 example not converging when image_dim_ordering == 'tf',"For some reason, the cifar-10 example is not converging when image_dim_ordering is set to tf. I have tried both with theano and with tensorflow – neither version works. When I switch image_dim_ordering to th all works as expected.

I have checked the data and it seems it gets loaded correctly – is it perhaps some quirk of the model or a bug in one of the layers' implementation?
",michalgregor,None,2016-10-04T11:15:17Z,2017-06-26T13:54:36Z
3950,error making simple FFT layer,"I want a simple layer that calculates a 1D fft of the input, and outputs the magnitude in the same number of dimensions.  In other words a computational layer with no variables, just a well-defined computation on the inputs.

This is what I've got so far,

```
class MyFFTLayer(keras.layers.Layer):
    def __init__(self, output_dim, **kwargs):
        super(MyFFTLayer, self).__init__(**kwargs)

    def build(self, input_shape):
        input_dim = input_shape[1]
        self.output_dim = input_shape[1]
        self.trainable_weights = []

    def call(self, x, mask=None):
        return K.tf.complex_abs(K.tf.fft(
            K.tf.complex(x, K.tf.zeros_like(x))))

    def get_output_shape_for(self, input_shape):
        return (input_shape[0], self.output_dim)
```

However I get errors, e.g.,

```
InvalidArgumentError: Cannot assign a device to node 'FFT_10': Node had no OpKernel registered to support this operation: Operation was FFT and inputs were complex64
Colocation Debug Info:
Colocation group had the following types and devices:
Mul: CPU
Complex: GPU
CPU
Cast: GPU CPU
Size: GPU CPU
IFFT: GPU
FFT:
Const: GPU CPU
```

In other words it seems to think the FFT op is not possible, despite FFT being implemented for the GPU.  For instance, the following program works fine for me:

```
import tensorflow as tf

x = tf.constant([1.0,2.0,3.0,2.0])
f = tf.complex_abs(tf.fft(tf.complex(x, tf.zeros_like(x))))

s = tf.Session()
y = s.run(f)
print(y)
```

I think it may be because in keras, the shape of `x` in `call()` is only partially defined.  How to get around this?  I'm not 100% sure that's the problem.
",radarsat1,b'stale',2016-10-03T15:11:39Z,2019-01-29T16:29:01Z
3893,Multitask network with missing labels class prediction,"I am trying to train a multitask network with multiple binary outcomes. Each datapoint has missing labels for many of the outputs.

The network I am building is based on [Ramsundar et al., 2015](https://arxiv.org/pdf/1502.02072.pdf)

I looked around some related issues:
- https://github.com/fchollet/keras/issues/3206
- https://github.com/fchollet/keras/issues/2650
- https://github.com/fchollet/keras/issues/462

Because of the missing labels, I do not think the graph model or multiple objective functions will work.

What I actually do need is target-based masking during training, which I achieved using custom functions for loss and metrics:

``` python
#toy problem
MASK_VALUE = -1
n = 25 # # datapoints
n_tasks = 19 # tasks / # binary classes
input_dim= 2048 # vector size

# generate random X vectors and random 
# Y labels (binary labels [0,1] or -1 for missing value
x = np.random.rand(n, input_dim)
x_test = np.random.rand(5, input_dim)
y = np.random.randint(3, size=(n, tasks))-1

def build_masked_loss(loss_function, mask_value=MASK_VALUE):
    """"""Builds a loss function that masks based on targets

    Args:
        loss_function: The loss function to mask
        mask_value: The value to mask in the targets

    Returns:
        function: a loss function that acts like loss_function with masked inputs
    """"""

    def masked_loss_function(y_true, y_pred):
        mask = K.cast(K.not_equal(y_true, mask_value), K.floatx())
        return loss_function(y_true * mask, y_pred * mask)

    return masked_loss_function

def masked_accuracy(y_true, y_pred):
    total = K.sum(K.not_equal(y_true, MASK_VALUE))
    correct = K.sum(K.equal(y_true, K.round(y_pred)))
    return correct / total

# create model
model = Sequential()
model.add(Dense(1000, activation='relu', input_dim=input_dim))
model.add(Dense(n_tasks, activation='sigmoid'))
model.compile(loss=build_masked_loss(K.binary_crossentropy), optimizer='adam', metrics=[masked_accuracy])
model.fit(x, y)
```

This trains the network successfully, decreasing the loss and increasing the masked accuracy at each epoch. 

However I am not sure wether the outputs are truly `n_task` independent predictions. I used sigmoid which should be elementwise.

Unfortunately, `model.predict_classes(x_test)` returns one class for each datapoint (interpreting `n_tasks` as the number of classes.

I can use `model.predict(x_test).round()` which seems to work. I actually wanted to use the `keras.wrappers.scikit_learn.KerasClassifier`,  which uses `predict_classes`.

I am also interested in ranking, and I use `model.predict_proba(x_test)` for that. The probabilities do not seem to add up to 1 row-wise, so I think that means that these probs are indeed independent.

Is my workaround correct, can I still use the scikit wrapper and can I trust the ranking of the probabilities?

**EDIT2**: I fixed a bug in the masking function

**EDIT**: I see now that  `np.allclose(model.predict(x), model.predict_proba(x))` is true. I could use predict_proba using the wrapper and use it to predict probabilities.
",tivaro,None,2016-09-27T22:19:49Z,2020-09-04T01:30:02Z
3892,Bug: output shape inference of batch_dot with Theano backend is not correct,"Tested on Mac, python 2.7, theano 0.8.2, tensorflow 0.10.0rc0, keras 1.1.0.
- Problem: with Theano backend, `batch_dot` output shape inference is not correct.
- Quick test code:

``` python
import keras
from keras import backend as K
import numpy as np
from keras.layers import Input, Lambda, merge, Reshape, Permute
from keras.models import Model

print('keras version: ', keras.__version__)
print('dim_ordering: ', K.image_dim_ordering())

x = Input((64, 32)) # (None, 64, 32) in batch
t = K.variable(np.ones((1, 32, 16))) # (1, 32, 16 in batch)
y = Lambda(lambda x: K.batch_dot(x, t, axes=(2, 1)))(x)
model = Model(input=x, output=y)
model.summary(line_length=80)
print('output_shape that the model thinks ', model.output_shape)
dummy_x = np.ones((64, 32))
dummy_y = model.predict(dummy_x[np.newaxis, :])
print('In fact, output shape is ', dummy_y.shape)
```
- test result: with theano

```
Using Theano backend.
('keras version: ', '1.1.0')
('dim_ordering: ', 'th')
________________________________________________________________________________
Layer (type)              Output Shape      Param #  Connected to
================================================================================
input_1 (InputLayer)      (None, 64, 32)    0
________________________________________________________________________________
lambda_1 (Lambda)         (None, 64, 32)    0        input_1[0][0]
================================================================================
Total params: 0
________________________________________________________________________________
('output_shape that the model thinks ', (None, 64, 32))
('In fact, output shape is ', (1, 64, 16))
```
- test result: with tensorflow:

```
Using TensorFlow backend.
('keras version: ', '1.1.0')
('dim_ordering: ', 'th')
________________________________________________________________________________
Layer (type)              Output Shape      Param #  Connected to
================================================================================
input_1 (InputLayer)      (None, 64, 32)    0
________________________________________________________________________________
lambda_1 (Lambda)         (1, 64, 16)       0        input_1[0][0]
================================================================================
Total params: 0
________________________________________________________________________________
('output_shape that the model thinks ', (1, 64, 16))
('In fact, output shape is ', (1, 64, 16))
```
",keunwoochoi,None,2016-09-27T21:14:21Z,2016-09-28T22:02:47Z
3859,clipnorm doesn't work with Embedding,"I'm getting a Traceback every time ""clipnorm"" is used in NN with Embedding layer.
Here is a simple script where the problem is obvious:

``` python
import numpy as np
from keras.layers import Input, Embedding
from keras.optimizers import Adam
from keras.models import Model

input_layer = Input(shape = (1,) )

embedding = Embedding(input_dim = 1,
                      output_dim = 1)(input_layer)

model = Model(input = input_layer, output = embedding)

model.compile(optimizer = Adam(clipnorm = 1.0), loss = 'mse')

X = np.array([[1]])
Y = np.array([[[0.5]]])
model.fit(X, Y, nb_epoch = 1)
```

Failure:

``` shell
I tensorflow/core/common_runtime/gpu/gpu_device.cc:867] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:01:00.0)
I tensorflow/core/common_runtime/gpu/gpu_device.cc:867] Creating TensorFlow device (/gpu:1) -> (device: 1, name: GeForce GTX TITAN X, pci bus id: 0000:02:00.0)
Traceback (most recent call last):
  File ""./clipnorm-bug.py"", line 20, in <module>
    model.fit(X, Y, nb_epoch = 1)
  File ""/usr/local/lib/python3.5/dist-packages/keras/engine/training.py"", line 1079, in fit
    self._make_train_function()
  File ""/usr/local/lib/python3.5/dist-packages/keras/engine/training.py"", line 696, in _make_train_function
    self.total_loss)
  File ""/usr/local/lib/python3.5/dist-packages/keras/optimizers.py"", line 379, in get_updates
    grads = self.get_gradients(loss, params)
  File ""/usr/local/lib/python3.5/dist-packages/keras/optimizers.py"", line 71, in get_gradients
    grads = [clip_norm(g, self.clipnorm, norm) for g in grads]
  File ""/usr/local/lib/python3.5/dist-packages/keras/optimizers.py"", line 71, in <listcomp>
    grads = [clip_norm(g, self.clipnorm, norm) for g in grads]
  File ""/usr/local/lib/python3.5/dist-packages/keras/optimizers.py"", line 9, in clip_norm
    g = K.switch(n >= c, g * c / n, g)
TypeError: unsupported operand type(s) for *: 'IndexedSlices' and 'float'
```

Keras version is 1.1.0, TensorFlow is 0.10rc

clipvalue on the other hand works fine.
",Vladimir-Yashin,None,2016-09-23T14:03:01Z,2017-06-10T19:08:09Z
3854,A Convolutional Neural Network Model Could not be loaded,"I have saved the model using _model.save('my_model.h5')_ it's working. However, when I try to load the model in a different project I get this error message: ValueError: Tensor(""cond/pred_id:0"", dtype=bool) must be from the same graph as Tensor(""dropout_1/mul_1:0"", shape=(?, 1, 256), dtype=float32).
Could this be a bug? Any idea?
",aykutcayir34,None,2016-09-23T07:12:55Z,2016-12-12T08:42:37Z
3843,unbreak timedistributed conv with new TF rnn,"is this only me or timedistributed(conv) was broken when using funcitonal api?
In any case setting unroll=True fixes it
the test I added is how to reproduce my bug
",EderSantana,None,2016-09-21T23:17:53Z,2016-09-21T23:27:41Z
3825,No training_data,"Hi,

I have recently updated from version 0.3.2 to version 1.1.0. I was using the property training_data of the sequential model for a custom callback which is now missing on version 1.1.0. Is this intentional? This is the sample code:

```
import numpy as np
import keras
from keras.models import Sequential
from keras.layers import Dense
model = Sequential()
model.add(Dense(output_dim=1, input_dim=1, activation='tanh'))
model.compile(loss='mean_squared_error',optimizer='adadelta')
x_t = np.array([[1]])
y_t = np.array([1])
model.fit(x_t, y_t)
model.training_data
```

The last line returns: 
`
[array([[1]]), array([[1]]), array([ 1.])]
`
on version 0.3.2 but an error on 1.1.0. The former contained, in models.py, function _fit of class Model the following:

```
        self.training_data = ins
        self.validation_data = val_ins
```

while 1.1.0 contains in training.py, in _fit_loop an assignment for self.validation_data but nothing for training_data.
Is this bug or on purpose? How can I access the training_data from a callback?

Thanks,

Luk
",luk-f-a,b'stale',2016-09-20T19:47:19Z,2017-06-23T00:11:53Z
3822,Matthews Correlation fix and test,"Fixes bug in matthews correlation coefficient metric and adds test to make sure it's actually working.
",kuza55,None,2016-09-20T15:48:30Z,2016-09-20T16:19:00Z
3807,Bug? Exception: Graph disconnected,"Please make sure that the boxes below are checked before you submit your issue. Thank you!
- [x] Check that you are up-to-date with the master branch of Keras. You can update with:
  pip install git+git://github.com/fchollet/keras.git --upgrade --no-deps
- [x] If running on Theano, check that you are up-to-date with the master branch of Theano. You can update with:
  pip install git+git://github.com/Theano/Theano.git --upgrade --no-deps
- [x] Provide a link to a GitHub Gist of a Python script that can reproduce your issue (or just copy the script here if it is short).

So I have this model, upon compilation I get
 `Using Theano backend.
/usr/local/lib/python2.7/dist-packages/Keras-1.0.7-py2.7.egg/keras/engine/topology.py:1655: UserWarning: Model inputs must come from a Keras Input layer, they cannot be the output of a previous non-Input layer. Here, a tensor specified as input to ""model_1"" was not an Input tensor, it was generated by layer timedistributed_1.
Note that input tensors are instantiated via`tensor = Input(shape)`.
The tensor that caused the issue was: None
  str(x.name))
Traceback (most recent call last):
  File ""/home/ubuntumax/keras_egg_code/train.py"", line 89, in <module>
    training_function()
  File ""/home/ubuntumax/keras_egg_code/train.py"", line 54, in training_function
    lstm_model = build_model()
  File ""/home/ubuntumax/keras_egg_code/train.py"", line 32, in build_model
    model = Model(input=main_input, output=main_loss)
  File ""/usr/local/lib/python2.7/dist-packages/Keras-1.0.7-py2.7.egg/keras/engine/topology.py"", line 1837, in __init__
    str(layers_with_complete_input))
Exception: Graph disconnected: cannot obtain value for tensor main_input at layer ""main_input"". The following previous layers were accessed without issue: []
`
Any suggestions on what is going wrong?
Thanks

```
    main_input = Input(shape=(240000, 16, 1), name='main_input')
    vision_model = Sequential()
    vision_model.add(Convolution1D(16, 1, activation='relu', border_mode='same', input_shape=(16, 1)))
    vision_model.add(MaxPooling1D(2, 2))
    vision_model.add(Convolution1D(16, 16, activation='relu', border_mode='same'))
    vision_model.add(MaxPooling1D(2, 2))
    vision_model.add(Convolution1D(8, 32, activation='relu', border_mode='same'))
    vision_model.add(MaxPooling1D(2, 2))
    vision_model.add(Convolution1D(4, 64, activation='relu', border_mode='same'))
    vision_model.add(MaxPooling1D(2, 2))
    vision_model.add(Flatten())

    main_input = TimeDistributed(vision_model)(main_input)
    x = LSTM(output_dim=512, return_sequences=True)(main_input)
    x = LSTM(output_dim=64)(x)
    main_loss = Dense(1, activation='sigmoid', name='main_output')(x)
    model = Model(input=main_input, output=main_loss)
    model.compile(optimizer='rmsprop', loss='mse')
    print(model.summary())
```
",AntreasAntoniou,b'stale',2016-09-18T23:40:58Z,2017-06-22T21:12:34Z
3799,Matthews Correlation Fix & Binary helpers,"I added some extra functions to the backend for logical operations.

Originally I had these just based on existing backend functions (as in the Theano implementation) and thought they could just be helpers in common or something, but it seems Tensorflow has built-in operations for this already.

While rewriting the matthews correlation metric with this I noticed it was buggy, so I fixed that and added tests for the metric and the new backend functions.

I haven't benchmarked the Theano backend to see if this is an ideal implementation, but it at the very least seems consistent with tensorflow, so at least they're accurate.

[EDIT]: Actually, the backend tests are failing on my machine since it seems like the CTC bits are incompatible with TF 0.10.0rc0 so I couldn't check if the backend test works, so hopefully CI can verify this. Metric test passes though.
",kuza55,None,2016-09-17T18:50:15Z,2016-09-20T15:48:43Z
3795,Error when building example network ,"Please make sure that the boxes below are checked before you submit your issue. Thank you!
- [x] Check that you are up-to-date with the master branch of Keras. You can update with:
  pip install git+git://github.com/fchollet/keras.git --upgrade --no-deps
- [x] If running on Theano, check that you are up-to-date with the master branch of Theano. You can update with:
  pip install git+git://github.com/Theano/Theano.git --upgrade --no-deps
- [x] Provide a link to a GitHub Gist of a Python script that can reproduce your issue (or just copy the script here if it is short).

I was reproducing example code from https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html - using code from https://gist.github.com/fchollet/0830affa1f7f19fd47b06d4cf89ed44d

it works in 1.0.8 but doesn't work in latest revision.

I Prepared a dockerfile for 1.0.8: https://gist.github.com/kretes/566d9d725891be683f5362c03dee484f which when downloaded as Dockerfile-working and run with:

`docker build -t keras-bug:1.0.8 -f Dockerfile-working . && docker run keras-bug:1.0.8` works ok

and alternative environment for latest git revision (fixed to the latest now (4fb3f1b3f384c3a05306b37ea9a736144ed6394a)): https://gist.github.com/kretes/7e4a0102fc64a3b6447f5ab44d7ab397 which when downloaded as Dockerfile-failing and run with: 
`docker build -t keras-bug:latest-git -f Dockerfile-failing . && docker run keras-bug:latest-git`
gives:

```
Traceback (most recent call last):
  File ""<stdin>"", line 6, in <module>
  File ""/opt/conda/lib/python3.5/site-packages/keras/models.py"", line 308, in add
    output_tensor = layer(self.outputs[0])
  File ""/opt/conda/lib/python3.5/site-packages/keras/engine/topology.py"", line 514, in __call__
    self.add_inbound_node(inbound_layers, node_indices, tensor_indices)
  File ""/opt/conda/lib/python3.5/site-packages/keras/engine/topology.py"", line 572, in add_inbound_node
    Node.create_node(self, inbound_layers, node_indices, tensor_indices)
  File ""/opt/conda/lib/python3.5/site-packages/keras/engine/topology.py"", line 149, in create_node
    output_tensors = to_list(outbound_layer.call(input_tensors[0], mask=input_masks[0]))
  File ""/opt/conda/lib/python3.5/site-packages/keras/layers/pooling.py"", line 162, in call
    dim_ordering=self.dim_ordering)
  File ""/opt/conda/lib/python3.5/site-packages/keras/layers/pooling.py"", line 212, in _pooling_function
    border_mode, dim_ordering, pool_mode='max')
  File ""/opt/conda/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py"", line 1696, in pool2d
    x = tf.nn.max_pool(x, pool_size, strides, padding=padding)
  File ""/opt/conda/lib/python3.5/site-packages/tensorflow/python/ops/nn_ops.py"", line 536, in max_pool
    name=name)
  File ""/opt/conda/lib/python3.5/site-packages/tensorflow/python/ops/gen_nn_ops.py"", line 1038, in _max_pool
    data_format=data_format, name=name)
  File ""/opt/conda/lib/python3.5/site-packages/tensorflow/python/ops/op_def_library.py"", line 704, in apply_op
    op_def=op_def)
  File ""/opt/conda/lib/python3.5/site-packages/tensorflow/python/framework/ops.py"", line 2262, in create_op
    set_shapes_for_outputs(ret)
  File ""/opt/conda/lib/python3.5/site-packages/tensorflow/python/framework/ops.py"", line 1702, in set_shapes_for_outputs
    shapes = shape_func(op)
  File ""/opt/conda/lib/python3.5/site-packages/tensorflow/python/ops/common_shapes.py"", line 505, in max_pool_shape
    padding)
  File ""/opt/conda/lib/python3.5/site-packages/tensorflow/python/ops/common_shapes.py"", line 184, in get2d_conv_output_size
    (row_stride, col_stride), padding_type)
  File ""/opt/conda/lib/python3.5/site-packages/tensorflow/python/ops/common_shapes.py"", line 149, in get_conv_output_size
    ""Filter: %r Input: %r"" % (filter_size, input_size))
ValueError: Filter must not be larger than the input: Filter: (2, 2) Input: (1, 148)
Exception ignored in: <bound method BaseSession.__del__ of <tensorflow.python.client.session.Session object at 0x7f40bc791780>>
Traceback (most recent call last):
  File ""/opt/conda/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 171, in __del__
  File ""/opt/conda/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 167, in close
TypeError: 'NoneType' object is not callable
```
",kretes,None,2016-09-17T07:11:05Z,2016-10-23T11:34:57Z
3778,LSTM simple example fails on GPU (Embedding `input_length=` argument bug),"Hi all,
I'm following an example from [http://machinelearningmastery.com/sequence-classification-lstm-recurrent-neural-networks-python-keras/], and it crashes:

``` python
# LSTM for sequence classification in the IMDB dataset
import numpy
from keras.datasets import imdb
from keras.models import Sequential
from keras.layers import Dense
from keras.layers import LSTM
from keras.layers.embeddings import Embedding
from keras.preprocessing import sequence
# fix random seed for reproducibility
numpy.random.seed(7)
# load the dataset but only keep the top n words, zero the rest
top_words = 5000
(X_train, y_train), (X_test, y_test) = imdb.load_data(nb_words=top_words)
# truncate and pad input sequences
max_review_length = 500
X_train = sequence.pad_sequences(X_train, maxlen=max_review_length)
X_test = sequence.pad_sequences(X_test, maxlen=max_review_length)
# create the model
embedding_vecor_length = 32
model = Sequential()
model.add(Embedding(top_words, embedding_vecor_length, input_length=max_review_length))
model.add(LSTM(100))
model.add(Dense(1, activation='sigmoid'))
model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
print(model.summary())
model.fit(X_train, y_train, nb_epoch=3, batch_size=64)
# Final evaluation of the model
scores = model.evaluate(X_test, y_test, verbose=0)
print(""Accuracy: %.2f%%"" % (scores[1]*100))
```

the error I get:

``` python
Traceback (most recent call last):
  File ""C:\Anaconda2\lib\site-packages\IPython\core\interactiveshell.py"", line 2885, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File ""<ipython-input-4-90314367626e>"", line 27, in <module>
    model.fit(X_train, y_train, nb_epoch=3, batch_size=64)
  File ""C:\Anaconda2\lib\site-packages\keras\models.py"", line 620, in fit
    sample_weight=sample_weight)
  File ""C:\Anaconda2\lib\site-packages\keras\engine\training.py"", line 1104, in fit
    callback_metrics=callback_metrics)
  File ""C:\Anaconda2\lib\site-packages\keras\engine\training.py"", line 822, in _fit_loop
    outs = f(ins_batch)
  File ""C:\Anaconda2\lib\site-packages\keras\backend\theano_backend.py"", line 672, in __call__
    return self.function(*inputs)
  File ""C:\Anaconda2\lib\site-packages\theano\compile\function_module.py"", line 875, in __call__
    storage_map=getattr(self.fn, 'storage_map', None))
  File ""C:\Anaconda2\lib\site-packages\theano\gof\link.py"", line 325, in raise_with_op
    reraise(exc_type, exc_value, exc_trace)
  File ""C:\Anaconda2\lib\site-packages\theano\compile\function_module.py"", line 862, in __call__
    self.fn() if output_subset is None else\
AssertionError: Can't store in size_t for the bytes requested 400 * 4
Apply node that caused the error: GpuAlloc{memset_0=True}(CudaNdarrayConstant{[[[ 0.]]]}, TensorConstant{500}, Elemwise{Composite{((i0 * i1) // i2)}}[(0, 0)].0, TensorConstant{400})
Toposort index: 114
Inputs types: [CudaNdarrayType(float32, (True, True, True)), TensorType(int64, scalar), TensorType(int64, scalar), TensorType(int64, scalar)]
Inputs shapes: [(1, 1, 1), (), (), ()]
Inputs strides: [(0, 0, 0), (), (), ()]
Inputs values: [CudaNdarray([[[ 0.]]]), array(500L, dtype=int64), array(-206L, dtype=int64), array(400L, dtype=int64)]
Outputs clients: [[GpuIncSubtensor{Inc;:int64:}(GpuAlloc{memset_0=True}.0, GpuSubtensor{::int64}.0, Constant{500}), GpuIncSubtensor{InplaceInc;int64::}(GpuAlloc{memset_0=True}.0, GpuIncSubtensor{Inc;:int64:}.0, Constant{0}), forall_inplace,gpu,grad_of_scan_fn}(TensorConstant{500}, GpuElemwise{tanh,no_inplace}.0, GpuSubtensor{int64:int64:int64}.0, GpuAlloc{memset_0=True}.0, GpuElemwise{Composite{(i0 - sqr(i1))},no_inplace}.0, GpuSubtensor{int64:int64:int64}.0, GpuSubtensor{int64:int64:int64}.0, GpuSubtensor{int64:int64:int64}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, TensorConstant{500}, TensorConstant{500}, TensorConstant{500}, TensorConstant{500}, TensorConstant{500}, lstm_3_U_o, lstm_3_U_f, lstm_3_U_i, lstm_3_U_c, GpuDimShuffle{1,0}.0, GpuDimShuffle{1,0}.0, GpuDimShuffle{1,0}.0, GpuDimShuffle{1,0}.0)]]
```

my setup: 
theano - 0.9.0dev2.dev-e4e08782d3a10d010d3a99bc87fd0fc3b0465405
keras - 1.0.8
gpu - Quadro K1000M (CNMeM is enabled with initial size: 80.0% of memory, cuDNN 5005)

Anyone knows what this might be? (it runs fine on cpu)
",izikgo,b'stale',2016-09-15T12:06:18Z,2017-06-22T21:12:50Z
3761,Bug: ImageDataGenerator for multiple output and single input fails,"The image data generator image.py fails when I tried to train a single input and multiple output model with data augmentation by saying 'the shape of X and y must be the same. 

But, for multiple output model, I supply a list of ndarrays and since the input is a single input, I supplied just X as is ndarray. I locally fixed it by checking to see if y is a list and bypass the exception and it works just fine.
",esube,b'stale',2016-09-13T17:20:43Z,2019-04-08T15:11:42Z
3752,is there a bug with 'relu'?,"Here is my network :

model = Sequential()
model.add(Convolution2D(128, 3, 3, border_mode='valid',input_shape=data.shape[-3:]))
model.add(Activation(act))
model.add(Convolution2D(128, 3, 3, border_mode='valid'))
model.add(Activation(act))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.25))
model.add(Convolution2D(256, 3, 3, border_mode='valid'))
model.add(Activation(act))
model.add(Convolution2D(256, 3, 3, border_mode='valid'))
model.add(Activation(act))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.25))
model.add(Convolution2D(512, 3, 3, border_mode='valid'))
model.add(Activation(act))
model.add(MaxPooling2D(pool_size=(2, 2)))
# 

model.add(Flatten())
model.add(Dense(4096, init='normal'))
model.add(Activation(act))
model.add(Dropout(0.5))
model.add(Dense(4096, init='normal'))
model.add(Activation(act))
model.add(Dropout(0.5))

model.add(Dense(classNumber, init='normal'))
model.add(Activation('softmax'))

First I set The act = 'relu' ,  the loss and accuracy does't change.
Then I changed the act = 'tanh' and traing it again,  the loss and acc were normal。
I that a known issue？  
",albertyou2,None,2016-09-12T12:44:07Z,2016-09-13T13:02:00Z
3721,Autoencoder with 0 nodes learns something,"Hi all,

I am currently running some test with simple Autoencoders. I just copied and pasted the code from this keras blog entry: https://blog.keras.io/building-autoencoders-in-keras.html

However, when I was testing different architectures, I just found out that even an Autoencoder with zero nodes in the (well, technically not even existing) first layer appears to be learning something. The loss I get is comparable with the loss I get with bigger architectures.

Could this be a bug in the Keras autoencoder code or might this be a problem of my dataset (which is quite noisy). My intuition was that I shouldn't learn anything when using a layer with zero nodes.

Any suggestions would be very helpful!
Thanks a lot! 
",NilsWinter,b'stale',2016-09-08T10:47:49Z,2017-06-22T20:09:52Z
3715,fix bug in neural_style_transfer example for image_dim_ordering=tf,"When image_dim_ordering = 'tf', the output_shape of layers in vgg model will be `(batch_size, nrows, ncols, nchannels)` rather than `(batch_size, nchannels, nrows, ncols)`.

Thus the `batch_flatten` line in `gram_matrix` will only work with 'th' ordering. As a result,  the color of the generated images will be screwed up for 'tf' ordering. This ordering difference only affects `style_loss` and `total_variation_loss`, but not `content_loss` .

The PR fixes this bug - tested for [sample images](https://github.com/DmitryUlyanov/fast-neural-doodle/tree/master/data) for both 'th' and 'tf' ordering.

Now it seems to be a pain point to repeat these image_dim_ordering() tests. Would there be a better way?
",dolaameng,None,2016-09-07T15:35:52Z,2016-09-07T23:52:20Z
3713,Training slows down when using larger dataset,"Hi,

I am training a deep recurrent model on batches of a dataset at a time, by manually slicing the data and calling model.fit() on it. I noticed that when I use a larger dataset (same batch size, but more validation data), training slows down quite a bit, and monitoring CPU usage I can see that the process seems to be IO bound in some way (one core is constantly at 100%, and the other cores sporadically spike slightly, seemingly on minibatch start and end).

For reference, here is the some of the relevant part of my training code:

``` python
# train_inputs is a list of large (in dim 0, i.e. number of samples) matrices, each matrix is the data for one model input

chunk_size = 10000
num_points = Y_train.shape[0]
num_chunks = num_points // chunk_size + 1
for chunk_no in range(num_chunks):
    slice_start, slice_end = chunk_no * chunk_size, min((chunk_no + 1) * chunk_size, num_points)

    # use advanced indexing so we create copies
    slice_indexes = range(slice_start, slice_end)

    # part refers to each of my model input matrices, all this does is create parallel slices of input_1, input_2, ...
    train_inputs_slice = [part[slice_indexes] for part in train_inputs]
    Y_train_slice = Y_train[slice_indexes]
    sample_weights_slice = sample_weights_train[slice_indexes]

    self.model.fit(
        train_inputs_slice, Y_train_slice,
        batch_size=32, nb_epoch=1,
        validation_data=(val_inputs, Y_val),
        callbacks=[checkpoint],
        sample_weight=sample_weights_slice
    )
```

Just to clarify: 
- the model gets the same amount of training data in each `fit` call, and that data is not a view but a copy of the relevant chunk of the big matrix)
- My systems RAM is far from being fully used
- I supply 2.5% of the whole dataset as validation data, so the amount of val data is higher if I use a larger dataset (note though that val testing does not seem to be what is slowing down training, as the CPU usage is poor during the epoch, not during testing)
- the larger the dataset, the more time one chunk takes to train. At 200k samples, it's around 240 seconds per `fit` call, and at 2 million samples, it goes to around 1000 seconds.
- the time each epoch takes seems to be increasing with each call to `fit`
- I've tried both RMSprop and SGD as optimizers, SGD seems to slow down less, but CPU usage is still bad on the large dataset

What could be slowing this down? If I drop the dataset size so that there are only around 2 chunks, CPU usage is basically perfect, and RAM does not seem to be the problem.

EDIT: the training time definitely appears to slow down with each epoch:

```
Train on 10000 samples, validate on 4978 samples
Epoch 1/1
 9984/10000 [============================>.] - ETA: 0s - loss: 3.1736 - acc: 0.6670Epoch 00000: val_acc improved from -inf to 0.75733, saving model to tmp_best_exp_weights_1473252153.81.hdf5
10000/10000 [==============================] - **242s** - loss: 3.1744 - acc: 0.6666 - val_loss: 0.5002 - val_acc: 0.7573
2016-09-07 14:47:01,922 DEBUG    main: Training on chunk 2 / 18 (iteration 1 / 500)
Train on 10000 samples, validate on 4978 samples
Epoch 1/1
 9984/10000 [============================>.] - ETA: 0s - loss: 3.0495 - acc: 0.7313Epoch 00000: val_acc improved from 0.75733 to 0.81559, saving model to tmp_best_exp_weights_1473252153.81.hdf5
10000/10000 [==============================] - **246s** - loss: 3.0511 - acc: 0.7312 - val_loss: 0.4576 - val_acc: 0.8156
2016-09-07 14:51:08,711 DEBUG    main: Training on chunk 3 / 18 (iteration 1 / 500)
Train on 10000 samples, validate on 4978 samples
Epoch 1/1
 9984/10000 [============================>.] - ETA: 0s - loss: 3.0236 - acc: 0.7467Epoch 00000: val_acc did not improve
10000/10000 [==============================] - **314s** - loss: 3.0238 - acc: 0.7467 - val_loss: 0.4797 - val_acc: 0.7909
2016-09-07 14:56:22,999 DEBUG    main: Training on chunk 4 / 18 (iteration 1 / 500)
Train on 10000 samples, validate on 4978 samples
Epoch 1/1
 9984/10000 [============================>.] - ETA: 0s - loss: 3.0511 - acc: 0.7590Epoch 00000: val_acc did not improve
10000/10000 [==============================] - **426s** - loss: 3.0547 - acc: 0.7588 - val_loss: 0.4879 - val_acc: 0.8114
2016-09-07 15:03:29,099 DEBUG    main: Training on chunk 5 / 18 (iteration 1 / 500)

```
",phdowling,b'stale',2016-09-07T12:56:52Z,2017-06-22T20:08:28Z
3708,Dot/cos merge : bug fix,"#3703
",farizrahman4u,None,2016-09-06T21:10:22Z,2016-09-06T22:04:26Z
3676,Bidirectional does not work with return_sequences=True and Masking,"I use embeddings, a bi-directional LSTM and a final, time-distributed Dense. However, if I want to use masking, I get a shape error.

The following code gives an error:

```
import numpy as np
from keras.engine.topology import Input, merge, Merge
from keras.layers.embeddings import Embedding
from keras.layers.wrappers import TimeDistributed, Bidirectional
from keras.layers.recurrent import LSTM
from keras.layers.core import Dense, Masking
from keras.engine.training import Model
from numpy import dtype, int32

num_classes = 10
num_symbols = 10
datapoints = 100
seq_len = 10
x = np.random.randint(num_symbols, size=(datapoints, seq_len))
y = np.random.randint(num_classes, size=(datapoints, seq_len))
y_one_hot = np.zeros((datapoints, seq_len, num_classes))

for i in range(datapoints):
    for j in range(seq_len):
        y_one_hot[i][j][y[i][j]] = 1

embedding_size = 10
embedding_weights = np.zeros((num_symbols, embedding_size))

for i in range(num_symbols):
    embedding_weights[i] = np.random.rand(embedding_size)

input = Input(shape=(seq_len,), dtype=""int32"")
embedding = Embedding(num_symbols, embedding_size, input_length=seq_len)

embedded_input = embedding(input)

mask = Masking(mask_value=0)(embedded_input)

bidirect = Bidirectional(LSTM(100, return_sequences=True))(mask)

final = TimeDistributed(Dense(num_classes, activation=""softmax""))(bidirect)

model = Model(input=[input], output=[final])

model.compile(loss='categorical_crossentropy', optimizer=""rmsprop"", metrics=['accuracy'])

model.fit(x, y_one_hot)
```

If one removes the mask, it compiles and runs without problems.

The error in the above case is:

```
ValueError: Shape (?, 10) must have rank 3
```

Whatever I do (e.g., reshaping the input, specifying input and output of each layer), it doesn't work. Is this a bug or am I doing something wrong?

Please make sure that the boxes below are checked before you submit your issue. Thank you!
- [x] Check that you are up-to-date with the master branch of Keras. You can update with:
  pip install git+git://github.com/fchollet/keras.git --upgrade --no-deps
- [x] If running on Theano, check that you are up-to-date with the master branch of Theano. You can update with:
  pip install git+git://github.com/Theano/Theano.git --upgrade --no-deps
- [x] Provide a link to a GitHub Gist of a Python script that can reproduce your issue (or just copy the script here if it is short).
",alex-j-j,None,2016-09-02T17:08:18Z,2016-09-02T19:39:26Z
3662,Fix TensorFlow RNN backwards support,"With TF dynamic RNN support in Keras 1.0.8 a bug was introduced when using `go_backwards=True` and masking. Mask has one less dimension than input.

Example code (should we add a unit test?):

``` python
import numpy as np
from keras.layers import Input, Embedding, Dense, GRU
from keras.models import Model

data_in = np.random.randint(2, size=(5, 10))
data_out = data_in[:, 0].astype(np.float32)

x_in = Input(shape=(10,), dtype='int32', name='x_in')
x = Embedding(2, 10, mask_zero=True)(x_in)

x = GRU(10, return_sequences=False, go_backwards=True)(x)

y_out = Dense(1, activation='softmax', name=""y_out"")(x)

model = Model(input=[x_in], output=[y_out])
model.compile(optimizer='adam', loss='mse')
model.fit([data_in], [data_out], nb_epoch=10)
```

```
Traceback (most recent call last):
  File ""test_rnn_backwards.py"", line 22, in <module>
    x = GRU(10, return_sequences=False, go_backwards=True)(x)
  File ""/usr/local/lib/python2.7/dist-packages/keras/engine/topology.py"", line 515, in __call__
    self.add_inbound_node(inbound_layers, node_indices, tensor_indices)
  File ""/usr/local/lib/python2.7/dist-packages/keras/engine/topology.py"", line 573, in add_inbound_node
    Node.create_node(self, inbound_layers, node_indices, tensor_indices)
  File ""/usr/local/lib/python2.7/dist-packages/keras/engine/topology.py"", line 150, in create_node
    output_tensors = to_list(outbound_layer.call(input_tensors[0], mask=input_masks[0]))
  File ""/usr/local/lib/python2.7/dist-packages/keras/layers/recurrent.py"", line 213, in call
    input_length=input_shape[1])
  File ""/usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py"", line 1139, in rnn
    mask = tf.reverse(mask, [True] + [False] * (ndim - 1))
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_array_ops.py"", line 1448, in reverse
    name=name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/op_def_library.py"", line 704, in apply_op
    op_def=op_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 2262, in create_op
    set_shapes_for_outputs(ret)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 1702, in set_shapes_for_outputs
    shapes = shape_func(op)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/array_ops.py"", line 662, in _ReverseShape
    input_shape = op.inputs[0].get_shape().with_rank(dims_shape[0])
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/tensor_shape.py"", line 641, in with_rank
    raise ValueError(""Shape %s must have rank %d"" % (self, rank))
ValueError: Shape (?, 10) must have rank 3
```
",gw0,None,2016-09-01T09:51:13Z,2016-09-01T12:56:42Z
3647,Theanio Flag Error when  Predict on CNN ,"## Error Message is below (Full Code  is attached)

Using Theano backend.
Using gpu device 0: GeForce GTX 1060 3GB (CNMeM is enabled with initial size: 81.0% of memory, cuDNN 5005)
(6L, 3L, 150L, 150L) <- this is data for predict

Traceback (most recent call last):
  File ""C:\Program Files (x86)\JetBrains\PyCharm Edu 2.0.4\helpers\pydev\pydevd.py"", line 2411, in <module>
    globals = debugger.run(setup['file'], None, None, is_module)
  File ""C:\Program Files (x86)\JetBrains\PyCharm Edu 2.0.4\helpers\pydev\pydevd.py"", line 1802, in run
    launch(file, globals, locals)  # execute the script
  File ""C:/Users/byoru/PycharmProjects/MailLession/FirstNN/Canvas.py"", line 50, in <module>
    output = model.predict(testarrnp, batch_size=2,verbose=1)
  File ""c:\program files (x86)\microsoft visual studio 12.0\vc\theano\keras\keras\models.py"", line 664, in predict
    return self.model.predict(x, batch_size=batch_size, verbose=verbose)
  File ""c:\program files (x86)\microsoft visual studio 12.0\vc\theano\keras\keras\engine\training.py"", line 1180, in predict
    batch_size=batch_size, verbose=verbose)
  File ""c:\program files (x86)\microsoft visual studio 12.0\vc\theano\keras\keras\engine\training.py"", line 879, in _predict_loop
    batch_outs = f(ins_batch)
  File ""c:\program files (x86)\microsoft visual studio 12.0\vc\theano\keras\keras\backend\theano_backend.py"", line 655, in __call__
    return self.function(*inputs)
  File ""c:\program files (x86)\microsoft visual studio 12.0\vc\theano\theano\compile\function_module.py"", line 879, in **call**
    storage_map=getattr(self.fn, 'storage_map', None))
  File ""c:\program files (x86)\microsoft visual studio 12.0\vc\theano\theano\gof\link.py"", line 325, in raise_with_op
    reraise(exc_type, exc_value, exc_trace)
  File ""c:\program files (x86)\microsoft visual studio 12.0\vc\theano\theano\compile\function_module.py"", line 866, in **call**
    self.fn() if output_subset is None else\
  File ""c:\program files (x86)\microsoft visual studio 12.0\vc\theano\theano\gof\op.py"", line 908, in rval
    r = p(n, [x[0] for x in i], o)
  File ""c:\program files (x86)\microsoft visual studio 12.0\vc\theano\theano\tensor\nnet\abstract_conv.py"", line 848, in perform
    conv_out = self.conv2d(img, kern, mode=""valid"", dilation=self.filter_dilation)
  File ""c:\program files (x86)\microsoft visual studio 12.0\vc\theano\theano\tensor\nnet\abstract_conv.py"", line 775, in conv2d
    dilated_kern[n, im0, ...],
IndexError: index 1 is out of bounds for axis 1 with size 1
Apply node that caused the error: AbstractConv2d{border_mode='valid', subsample=(1, 1), filter_flip=True, imshp=(None, None, None, None), kshp=(32, 3, 3, 3), filter_dilation=(1, 1)}(convolution2d_input_1, HostFromGpu.0)
Toposort index: 33
Inputs types: [TensorType(float32, 4D), TensorType(float32, 4D)]
Inputs shapes: [(2L, 3L, 150L, 150L), (32L, 1L, 3L, 3L)]
Inputs strides: [(270000L, 90000L, 600L, 4L), (36L, 36L, 12L, 4L)]
Inputs values: ['not shown', 'not shown']
Inputs type_num: [11, 11]
Outputs clients: [[Elemwise{add,no_inplace}(AbstractConv2d{border_mode='valid', subsample=(1, 1), filter_flip=True, imshp=(None, None, None, None), kshp=(32, 3, 3, 3), filter_dilation=(1, 1)}.0, Reshape{4}.0)]]

Backtrace when the node is created(use Theano flag traceback.limit=N to make it longer):
  File ""C:/Users/byoru/PycharmProjects/MailLession/FirstNN/Canvas.py"", line 11, in <module>
    model.add(Convolution2D(32, 3, 3, input_shape=(3, 150, 150)))
  File ""c:\program files (x86)\microsoft visual studio 12.0\vc\theano\keras\keras\models.py"", line 275, in add
    layer.create_input_layer(batch_input_shape, input_dtype)
  File ""c:\program files (x86)\microsoft visual studio 12.0\vc\theano\keras\keras\engine\topology.py"", line 367, in create_input_layer
    self(x)
  File ""c:\program files (x86)\microsoft visual studio 12.0\vc\theano\keras\keras\engine\topology.py"", line 511, in **call**
    self.add_inbound_node(inbound_layers, node_indices, tensor_indices)
  File ""c:\program files (x86)\microsoft visual studio 12.0\vc\theano\keras\keras\engine\topology.py"", line 569, in add_inbound_node
    Node.create_node(self, inbound_layers, node_indices, tensor_indices)
  File ""c:\program files (x86)\microsoft visual studio 12.0\vc\theano\keras\keras\engine\topology.py"", line 150, in create_node
    output_tensors = to_list(outbound_layer.call(input_tensors[0], mask=input_masks[0]))
  File ""c:\program files (x86)\microsoft visual studio 12.0\vc\theano\keras\keras\layers\convolutional.py"", line 353, in call
    filter_shape=self.W_shape)
  File ""c:\program files (x86)\microsoft visual studio 12.0\vc\theano\keras\keras\backend\theano_backend.py"", line 1073, in conv2d
    filter_shape=filter_shape)

Debugprint of the apply node: 
AbstractConv2d{border_mode='valid', subsample=(1, 1), filter_flip=True, imshp=(None, None, None, None), kshp=(32, 3, 3, 3), filter_dilation=(1, 1)} [id A] <TensorType(float32, 4D)> ''  
 |convolution2d_input_1 [id B] <TensorType(float32, 4D)>
 |HostFromGpu [id C] <TensorType(float32, 4D)> ''  
   |convolution2d_1_W [id D] <CudaNdarrayType(float32, 4D)>

Storage map footprint:
- dense_1_W, Shared Input, Shape: (18496, 64), ElemSize: 4 Byte(s), TotalSize: 4734976 Byte(s)
- convolution2d_input_1, Input, Shape: (2L, 3L, 150L, 150L), ElemSize: 4 Byte(s), TotalSize: 540000 Byte(s)
- <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (92160,), ElemSize: 4 Byte(s), TotalSize: 368640 Byte(s)
- <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (92160,), ElemSize: 4 Byte(s), TotalSize: 368640 Byte(s)
- <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (92160,), ElemSize: 4 Byte(s), TotalSize: 368640 Byte(s)
- convolution2d_3_W, Shared Input, Shape: (64, 32, 3, 3), ElemSize: 4 Byte(s), TotalSize: 73728 Byte(s)
- convolution2d_2_W, Shared Input, Shape: (32, 32, 3, 3), ElemSize: 4 Byte(s), TotalSize: 36864 Byte(s)
- HostFromGpu.0, Shape: (32L, 1L, 3L, 3L), ElemSize: 4 Byte(s), TotalSize: 1152 Byte(s)
- convolution2d_1_W, Shared Input, Shape: (32, 1, 3, 3), ElemSize: 4 Byte(s), TotalSize: 1152 Byte(s)
- convolution2d_3_b, Shared Input, Shape: (64,), ElemSize: 4 Byte(s), TotalSize: 256 Byte(s)
- dense_1_b, Shared Input, Shape: (64,), ElemSize: 4 Byte(s), TotalSize: 256 Byte(s)
- dense_2_W, Shared Input, Shape: (64, 1), ElemSize: 4 Byte(s), TotalSize: 256 Byte(s)
- convolution2d_1_b, Shared Input, Shape: (32,), ElemSize: 4 Byte(s), TotalSize: 128 Byte(s)
- convolution2d_2_b, Shared Input, Shape: (32,), ElemSize: 4 Byte(s), TotalSize: 128 Byte(s)
- TensorConstant{[ 1 32  1  1]}, Shape: (4L,), ElemSize: 4 Byte(s), TotalSize: 16 Byte(s)
- TensorConstant{[ 1 64  1  1]}, Shape: (4L,), ElemSize: 4 Byte(s), TotalSize: 16 Byte(s)
- TensorConstant{[ 1 32  1  1]}, Shape: (4L,), ElemSize: 4 Byte(s), TotalSize: 16 Byte(s)
- Constant{0}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)
- Constant{0}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)
- TensorConstant{0.5}, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)
- dense_2_b, Shared Input, Shape: (1,), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)
- TensorConstant{0.5}, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)
- DimShuffle{x,x,x,x}.0, Shape: (1L, 1L, 1L, 1L), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)
- TensorConstant{0.800000011921}, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)
- TensorConstant{0.800000011921}, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)
- TensorConstant{0.5}, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)
- DimShuffle{x,x}.0, Shape: (1L, 1L), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)
- TensorConstant{0.5}, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)
- TensorConstant{0.5}, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)
- TensorConstant{1.0}, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)
- TensorConstant{0.5}, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)
- DimShuffle{x,x,x,x}.0, Shape: (1L, 1L, 1L, 1L), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)
- DimShuffle{x,x,x,x}.0, Shape: (1L, 1L, 1L, 1L), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)
- TensorConstant{0.800000011921}, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)
- TensorConstant{0.800000011921}, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)
- TensorConstant{0.0}, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)
- DimShuffle{x,x,x,x}.0, Shape: (1L, 1L, 1L, 1L), ElemSize: 1 Byte(s), TotalSize: 1 Byte(s)
- DimShuffle{x,x,x,x}.0, Shape: (1L, 1L, 1L, 1L), ElemSize: 1 Byte(s), TotalSize: 1 Byte(s)
- DimShuffle{x,x}.0, Shape: (1L, 1L), ElemSize: 1 Byte(s), TotalSize: 1 Byte(s)
- keras_learning_phase, Input, Shape: (), ElemSize: 1 Byte(s), TotalSize: 1.0 Byte(s)
  TotalSize: 6494952.0 Byte(s) 0.006 GB
  TotalSize inputs: 6493781.0 Byte(s) 0.006 GB

---

---------- Full Code ----------------------------
import numpy as np
import os
from PIL import Image
from keras.models import Sequential
from keras.layers import Convolution2D, MaxPooling2D
from keras.layers import Activation, Dropout, Flatten, Dense

from keras.preprocessing.image import ImageDataGenerator

model = Sequential()
model.add(Convolution2D(32, 3, 3, input_shape=(3, 150, 150)))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Convolution2D(32, 3, 3))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.2))

model.add(Convolution2D(64, 3, 3))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.2))

model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors
model.add(Dense(64))
model.add(Activation('relu'))
model.add(Dropout(0.5))
model.add(Dense(1))
model.add(Activation('sigmoid'))

model.load_weights('weight1.h5')

model.compile(loss='binary_crossentropy',
              optimizer='rmsprop',
              metrics=['accuracy'])
path = 'test'
testarr = []

for item in os.listdir(path):
    imgpath = path + '\' + item
    img = Image.open(imgpath)
    resizedimg = img.resize((150,150),Image.ANTIALIAS)
    data = np.array( resizedimg )
    data2 = data.transpose(2,0,1)
    testarr.append(data2)
testarrnp = np.asarray(testarr)

print testarrnp.shape
output = model.predict(testarrnp, batch_size=2,verbose=1)
print output
",idioluck,b'stale',2016-08-31T14:43:36Z,2017-06-22T20:09:27Z
3637,RNN fails on 1.0.8 but runs fine on 1.0.7,"I get the following when trying to train a model (on a CPU) after upgrading to 1.0.8. Interestingly it works if I downgrade to 1.0.7. Perhaps even more surprising is that it works (with 1.0.8) on a ubuntu-GPU setup.

```
Traceback (most recent call last):
  File ""/Users/<me>/venvs3/general/lib/python3.5/site-packages/theano/compile/function_module.py"", line 859, in __call__
    outputs = self.fn()
MemoryError: alloc failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""./pipeline/train.py"", line 162, in <module>
    validation_data=[Xva, Yva],
  File ""/Users/<me>/venvs3/general/lib/python3.5/site-packages/keras/models.py"", line 620, in fit
    sample_weight=sample_weight)
  File ""/Users/<me>/venvs3/general/lib/python3.5/site-packages/keras/engine/training.py"", line 1104, in fit
    callback_metrics=callback_metrics)
  File ""/Users/<me>/venvs3/general/lib/python3.5/site-packages/keras/engine/training.py"", line 822, in _fit_loop
    outs = f(ins_batch)
  File ""/Users/<me>/venvs3/general/lib/python3.5/site-packages/keras/backend/theano_backend.py"", line 672, in __call__
    return self.function(*inputs)
  File ""/Users/<me>/venvs3/general/lib/python3.5/site-packages/theano/compile/function_module.py"", line 871, in __call__
    storage_map=getattr(self.fn, 'storage_map', None))
  File ""/Users/<me>/venvs3/general/lib/python3.5/site-packages/theano/gof/link.py"", line 314, in raise_with_op
    reraise(exc_type, exc_value, exc_trace)
  File ""/Users/<me>/venvs3/general/lib/python3.5/site-packages/six.py"", line 685, in reraise
    raise value.with_traceback(tb)
  File ""/Users/<me>/venvs3/general/lib/python3.5/site-packages/theano/compile/function_module.py"", line 859, in __call__
    outputs = self.fn()
MemoryError: alloc failed
Apply node that caused the error: AllocEmpty{dtype='float32'}(TensorConstant{11}, Elemwise{Composite{Switch(EQ(i0, i1), ((i2 * i0) // (i3 * i0)), i0)}}.0, TensorConstant{25})
Toposort index: 201
Inputs types: [TensorType(int64, scalar), TensorType(int64, scalar), TensorType(int64, scalar)]
Inputs shapes: [(), (), ()]
Inputs strides: [(), (), ()]
Inputs values: [array(11), array(-1334), array(25)]
Outputs clients: [[IncSubtensor{InplaceSet;:int64:}(AllocEmpty{dtype='float32'}.0, Rebroadcast{0}.0, Constant{1})]]

Backtrace when the node is created(use Theano flag traceback.limit=N to make it longer):
  File ""./pipeline/train.py"", line 90, in model_loader
    model, encoder = _get_model()
  File ""./pipeline/train.py"", line 65, in _get_model
    name='decoder_rnn_0')
  File ""/Users/<me>/venvs3/general/lib/python3.5/site-packages/keras/models.py"", line 308, in add
    output_tensor = layer(self.outputs[0])
  File ""/Users/<me>/venvs3/general/lib/python3.5/site-packages/keras/engine/topology.py"", line 515, in __call__
    self.add_inbound_node(inbound_layers, node_indices, tensor_indices)
  File ""/Users/<me>/venvs3/general/lib/python3.5/site-packages/keras/engine/topology.py"", line 573, in add_inbound_node
    Node.create_node(self, inbound_layers, node_indices, tensor_indices)
  File ""/Users/<me>/venvs3/general/lib/python3.5/site-packages/keras/engine/topology.py"", line 150, in create_node
    output_tensors = to_list(outbound_layer.call(input_tensors[0], mask=input_masks[0]))
  File ""/Users/<me>/venvs3/general/lib/python3.5/site-packages/keras/layers/recurrent.py"", line 213, in call
    input_length=input_shape[1])
  File ""/Users/<me>/venvs3/general/lib/python3.5/site-packages/keras/backend/theano_backend.py"", line 842, in rnn
    go_backwards=go_backwards)

HINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.
```

The model is:

```
encoder = Sequential(name=""encoder"")
encoder.add(
    Masking(
        input_shape=(config.Model.maxlen, config.Model.max_features),
        mask_value=0,
    )
)
encoder.add(
         LSTM(output_dim=config.Model.lstm_size,
         return_sequences=False,
         go_backwards=False,
         name='encode_rnn_0')
)

model = Sequential(name='char-auto-encoder')
model.add(encoder)

# Context
model.add(
    RepeatVector(n=config.Model.maxlen,
                 name='context_vector_repeat')
)

model.add(
        LSTM(output_dim=config.Model.lstm_size,
             return_sequences=True,
             go_backwards=False,
             name='decoder_rnn_0')
)

model.add(
    TimeDistributed(
        Dense(
            output_dim=config.Model.max_features,
            activation='softmax',
            name='distribution_over_tokens'
        ),
    )
)
```
",fmfn,None,2016-08-31T06:51:59Z,2016-09-01T05:19:19Z
3630,Bug fix : Sequential model guide,"The mode function of `Merge` layer takes a single argument : the list of tensors being merged.
",farizrahman4u,None,2016-08-30T16:07:44Z,2016-08-30T16:43:41Z
3626,Bug with Timedistributed and shared models,"The following code triggers a bug:

``` python
import numpy as np                                                                                      
from keras.layers import merge, Input, Dense, TimeDistributed, Lambda                                   
from keras.models import Model                                                                          
from keras import backend as K                                                                          
from keras.constraints import maxnorm                                                                   

# first, define the shared model                                                                          
input = Input(shape=(100,))                                                                             
out = Dense(10, W_constraint=maxnorm(10), name='shared_dense')(input)                                   
shared_model = Model(input, out, name='shared_model')                                                   

# then define the inputs                                                                                
a = Input(shape=(100,))                                                                                 
b = Input(shape=(5, 100,))                                                                              
out_a = shared_model(a)                                                                                 
out_b = TimeDistributed(shared_model)(b)                                                                
out_b = Lambda(                                                                                         
    function=lambda x: K.sum(x, axis=1),                                                                
    output_shape=lambda shape: (shape[0],) + shape[2:])(out_b)                                          
concatenated = merge([out_a, out_b], mode='concat')                                                     
out = Dense(1, activation='sigmoid')(concatenated)                                                      

classification_model = Model([a, b], out)                                                               
classification_model.compile(optimizer='sgd', loss='binary_crossentropy')                               

classification_model.train_on_batch(                                                                    
    [np.ones((20, 100)), np.ones((20, 5, 100))],                                                        
    [np.ones(20)]                                                                                       
)                

```

The bug is triggered by the constraint on the shared_dense layer (removing it results in working code), and stems from container:constraints method. 
The max_norm constraint is added both via the `shared_model` and the `shared_dense`.
This also results in regularizations appearing more than once, but silently, as there is no check as in constraints. This bug is only triggered when sharing a model via the TimeDistributed wrapper. 

Any ideas on how to solve this?
",tzachar,None,2016-08-30T12:14:06Z,2016-08-30T20:55:28Z
3624,Compile function for 1D convolutional neural networks,"Hello guys, I am working on a time series data, fitting it into a 1D convolutional neural network but I seem to not find the right compile model. My net is configured in the following way:
model = Sequential()

model.add(Convolution1D(21, 1, 7,activation='relu',init='uniform'))
model.add(MaxPooling1D(pool_length=2))
model.add(Dropout(0.2))

model.add(Flatten())
model.add(Dense(7,1, activation='sigmoid'))

nb_timesteps = 7 # 2 (previous) + 1 (current)
nb_sequences = input_var.shape[0] - nb_timesteps #8-3=5

input_3D = np.array([input_var[i:i+nb_timesteps] for i in range(nb_sequences)])
model.compile(loss='mean_squared_error', optimizer='adadelta')
model.fit(input_3D, targetValue, batch_size=450, nb_epoch=10, validation_split=0.05,show_accuracy=True,verbose = 0)

And I do get this kind of error:

model.fit(input_3D, targetValue, batch_size=450, nb_epoch=10, validation_split=0.05,show_accuracy=True,verbose = 0)
File ""build/bdist.linux-x86_64/egg/keras/models.py"", line 490, in fit
File ""build/bdist.linux-x86_64/egg/keras/models.py"", line 211, in fit
File ""/usr/local/lib/python2.7/dist-packages/Theano-0.8.0rc1-py2.7.egg/theano/compile/function_module.py"", line 871, in __call_
storage_map=getattr(self.fn, 'storage_map', None))
File ""/usr/local/lib/python2.7/dist-packages/Theano-0.8.0rc1-py2.7.egg/theano/gof/link.py"", line 314, in raise_with_op
reraise(exc_type, exc_value, exc_trace)
File ""/usr/local/lib/python2.7/dist-packages/Theano-0.8.0rc1-py2.7.egg/theano/compile/function_module.py"", line 859, in call
outputs = self.fn()
ValueError: the filter stack size (21) and image stack size (7) differ
Apply node that caused the error: ConvOp{('imshp', (None, None, None)),('kshp', (None, None)),('nkern', None),('bsize', None),('dx', 1),('dy', 1),('out_mode', 'valid'),('unroll_batch', None),('unroll_kern', None),('unroll_patch', True),('imshp_logical', (None, None, None)),('kshp_logical', (None, None)),('kshp_logical_top_aligned', True)}(InplaceDimShuffle{0,2,1,3}.0, )
Toposort index: 41
Inputs types: [TensorType(float64, (False, False, False, True)), TensorType(float64, 4D)]
Inputs shapes: [(450, 7, 7, 1), (1, 21, 7, 1)]
Inputs strides: [(392, 8, 56, 8), (1176, 56, 8, 8)]
Inputs values: ['not shown', 'not shown']
Outputs clients: [[Elemwise{add,no_inplace}(ConvOp{('imshp', (None, None, None)),('kshp', (None, None)),('nkern', None),('bsize', None),('dx', 1),('dy', 1),('out_mode', 'valid'),('unroll_batch', None),('unroll_kern', None),('unroll_patch', True),('imshp_logical', (None, None, None)),('kshp_logical', (None, None)),('kshp_logical_top_aligned', True)}.0, InplaceDimShuffle{x,0,x,x}.0), Elemwise{Composite{(i0 \* (Abs(i1) + i2 + i3))}}(0, 2),('unroll_batch', None),('unroll_kern', None),('unroll_patch', True),('imshp_logical', (None, None, None)),('kshp_logical', (None, None)),('kshp_logical_top_aligned', True)}.0, InplaceDimShuffle{x,0,x,x}.0)]]

Backtrace when the node is created(use Theano flag traceback.limit=N to make it longer):
File ""build/bdist.linux-x86_64/egg/keras/layers/core.py"", line 43, in get_input
return self.previous.get_output(train=train)
File ""build/bdist.linux-x86_64/egg/keras/layers/core.py"", line 331, in get_output
X = self.get_input(train)
File ""build/bdist.linux-x86_64/egg/keras/layers/core.py"", line 43, in get_input
return self.previous.get_output(train=train)
File ""build/bdist.linux-x86_64/egg/keras/layers/core.py"", line 250, in get_output
X = self.get_input(train)
File ""build/bdist.linux-x86_64/egg/keras/layers/core.py"", line 43, in get_input
return self.previous.get_output(train=train)
File ""build/bdist.linux-x86_64/egg/keras/layers/convolutional.py"", line 211, in get_output
X = self.get_input(train)
File ""build/bdist.linux-x86_64/egg/keras/layers/core.py"", line 43, in get_input
return self.previous.get_output(train=train)
File ""build/bdist.linux-x86_64/egg/keras/layers/convolutional.py"", line 72, in get_output
conv_out = T.nnet.conv.conv2d(X, self.W, border_mode=border_mode, subsample=self.subsample)

HINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.
",nalamotse1,b'stale',2016-08-30T09:22:37Z,2017-06-22T20:09:09Z
3621,TimeDistributed Wrapper Fails w/ Exception,"When I use the TimeDistributed wrapper after an LSTM layer, I get the following exception:

```
Exception: Error when checking model target: expected timedistributed_1 to have 3 dimensions, but got array with shape (100, 1)
```
- [x] Check that you are up-to-date with the master branch of Keras. You can update with:
  pip install git+git://github.com/fchollet/keras.git --upgrade --no-deps
- [X] If running on Theano, check that you are up-to-date with the master branch of Theano. You can update with:
  pip install git+git://github.com/Theano/Theano.git --upgrade --no-deps
- [X] Provide a link to a GitHub Gist of a Python script that can reproduce your issue (or just copy the script here if it is short). (Script below...)

```
from keras.models import Sequential
from keras.layers import Dense, LSTM
from keras.layers.wrappers import TimeDistributed
import numpy

samples = 100
timesteps = 32
inputs = 3
outputs = 1

Xt = numpy.random.random((samples, timesteps, inputs))
Yt = numpy.random.random((samples, outputs))

print(""Building model..."")
model = Sequential()
model.add(LSTM(output_dim=128, input_shape=(timesteps, inputs), activation='tanh', return_sequences=True))
#model.add(BatchNormalization())
model.add(LSTM(output_dim=128, activation='tanh', return_sequences=True))
#model.add(BatchNormalization())
model.add(TimeDistributed(Dense(outputs, init='uniform', activation='linear')))

model.compile(loss='mean_squared_error', optimizer='rmsprop', metrics=['accuracy'])

model.summary()

print(""Fitting model..."")

model.fit(Xt, Yt)
```

Full script output:

```
(env)[alex@annie annie]$ THEANO_FLAGS=mode=FAST_RUN,device=gpu,force_device=true,floatX=float32 python keras/kerasBug.py
Using Theano backend.
Using gpu device 0: GeForce GTX 1070 (CNMeM is disabled, cuDNN 5005)
Building model...
____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to
====================================================================================================
lstm_1 (LSTM)                    (None, 32, 128)       67584       lstm_input_1[0][0]
____________________________________________________________________________________________________
lstm_2 (LSTM)                    (None, 32, 128)       131584      lstm_1[0][0]
____________________________________________________________________________________________________
timedistributed_1 (TimeDistribute(None, 32, 1)         129         lstm_2[0][0]
====================================================================================================
Total params: 199297
____________________________________________________________________________________________________
Fitting model...
Traceback (most recent call last):
  File ""keras/kerasBug.py"", line 29, in <module>
    model.fit(Xt, Yt)
  File ""/home/alex/Tests/annie/env/lib/python2.7/site-packages/keras/models.py"", line 620, in fit
    sample_weight=sample_weight)
  File ""/home/alex/Tests/annie/env/lib/python2.7/site-packages/keras/engine/training.py"", line 1032, in fit
    batch_size=batch_size)
  File ""/home/alex/Tests/annie/env/lib/python2.7/site-packages/keras/engine/training.py"", line 963, in _standardize_user_data
    exception_prefix='model target')
  File ""/home/alex/Tests/annie/env/lib/python2.7/site-packages/keras/engine/training.py"", line 97, in standardize_input_data
    str(array.shape))
Exception: Error when checking model target: expected timedistributed_1 to have 3 dimensions, but got array with shape (100, 1)
(env)[alex@annie annie]$
```

Help? :)
",alexmarkley,None,2016-08-29T19:45:36Z,2016-08-29T19:54:00Z
3605,illegal instruction bug,"I'm getting the illegal instruction bug when running examples?  Any ideas for how to debug?
This is on a Mac running 10.11.5

host:examples stevens$ python mnist_cnn.py
Using Theano backend.
X_train shape: (60000, 1, 28, 28)
60000 train samples
10000 test samples
Illegal instruction: 4
host:examples stevens$ 

Please make sure that the boxes below are checked before you submit your issue. Thank you!
- [ ] Check that you are up-to-date with the master branch of Keras. You can update with:
  pip install git+git://github.com/fchollet/keras.git --upgrade --no-deps
- [ ] If running on Theano, check that you are up-to-date with the master branch of Theano. You can update with:
  pip install git+git://github.com/Theano/Theano.git --upgrade --no-deps
- [ ] Provide a link to a GitHub Gist of a Python script that can reproduce your issue (or just copy the script here if it is short).
",Tipizen,b'stale',2016-08-27T21:51:14Z,2017-06-22T20:09:01Z
3590,"Bug fix, batch_size set instead of default one","The evaluate function was called with the default batch_size (32).
So it doesn't work when your GPU does not handle a batch_size of 32.
",pambros,None,2016-08-26T10:13:45Z,2016-08-26T21:30:57Z
3579,Training gets slower with each repetition,"Hi,
I'm not attaching any code as it is not specific to any form of my model. Im running keras with tensorflow, everything is up to date.
When I run keras inside pytho notebook (python 3) and try to train a model multiple time to search optimal parameters it gets slower with each iteration. For example from 3 min per iteration to 6 min in 40 iterations. I run a function that builds new model = sequential() in each iteration. 
I looked for any command to ""restart"" tensorflow or keras but couldn't find anything. Is it a bug or am I doing something wrong?

Kind regards.
",macwilam,None,2016-08-25T18:08:40Z,2020-08-24T23:30:28Z
3576,Training with Adam gets slower each epoch,"I am training a simple neural network in Keras with Theano backend consisting of 4 dense layers connected to a Merge layer and then to a softmax classifier layer. Using Adam for training, the first few epochs train in about 60s each (in the CPU) but, after that, the training time per epoch starts increasing, taking more than 400s by epoch 70, making it unusable.

Is there anything wrong with my code? Is this supposed to happen or is it a bug?

This only happens when using Adam, not with sgd, adadelta, rmsprop or adagrad.  I'd use any of the other methods but Adam produces far better results.

The code:

```
modela = Sequential()
modela.add(Dense(700, input_dim=40, init='uniform', activation='relu'))
modelb = Sequential()
modelb.add(Dense(700, input_dim=40, init='uniform', activation='relu'))
modelc = Sequential()
modelc.add(Dense(700, input_dim=40, init='uniform', activation='relu'))
modeld = Sequential()
modeld.add(Dense(700, input_dim=40, init='uniform', activation='relu'))

model = Sequential()
model.add(Merge([modela, modelb, modelc, modeld], mode='concat', concat_axis=1))
model.add(Dense(258, init='uniform', activation='softmax'))

model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

hist = model.fit([Xa, Xb, Xc, Xd], Ycat, validation_split=.25, nb_epoch=80, batch_size=100, verbose=2)
```
",chusb40,None,2016-08-25T14:52:47Z,2020-10-06T20:37:05Z
3555,Shared frozen model for joint training,"Hi!

In <=0.3.3, I used to be able to define something like

```
D = Sequential()
D.add(...)
...

G = Sequential()
G.add(...)
...
G.compile(...) # necessary but irrelevant

DG = Sequential()
DG.add(G)  
D.trainable = False
DG.add(D) # layers of D are frozen for GD

D.compile(some_loss)
DG.compile(some_other_loss)
```

And then be able to train jointly `D` and `DG` (writing some small custom loop for alternating updates), such that updates on `DG` only change the weights of the inner model `G`. 

In master, the same code has different behaviour -- namely, `D.trainable = False` seems to no longer be taken into account, resulting in `DG.trainable_weights` to include both `G` and `D` weights. Is this new behaviour expected or this a bug? 
",glouppe,None,2016-08-23T19:47:26Z,2016-08-23T20:30:19Z
3551,Bug: Default 'nb_words' value should be set in 'Tokenizer' constructor,"### Summary

Initializing `keras.preprocessing.text.Tokenizer` without any arguments results in a `MemoryError`. This appears to be because the variable `nb_words` is not set. Setting this to 1000 in the constructor fixes this issue. Suggested fix: if `nb_words` is not set using an argument it should have a sensible default.

See the script below for an example.
### `bug.py` - script to reproduce error

Run this script after [downloading and unzipping the attached data file](https://github.com/fchollet/keras/files/432150/reddit_titles.zip) (17MB). Change the value of the `SOURCE_FILE` variable to point to the unzipped file.

``` python
import io
import json
import keras
from keras.preprocessing import text

SOURCE_FILE = ""/tmp/reddit_titles""
with open(SOURCE_FILE, ""r"") as f:
    data = json.load(f)

data = [d.encode('ascii') for d in data]

tk = text.Tokenizer() # Change this to fix: tk = text.Tokenizer(nb_words=1000)
tk.fit_on_texts(data)
tfidf = tk.texts_to_matrix(data, mode=""tfidf"")
```
### Traceback (`MemoryError`)

```
Traceback (most recent call last):
  File ""bug.py"", line 13, in <module>
    tfidf = tk.texts_to_matrix(data, mode=""tfidf"")
  File ""/home/sumanas/Documents/python/keras/local/lib/python2.7/site-packages/Keras-1.0.7-py2.7.egg/keras/preprocessing/text.py"", line 167, in texts_to_matrix
    return self.sequences_to_matrix(sequences, mode=mode)
  File ""/home/sumanas/Documents/python/keras/local/lib/python2.7/site-packages/Keras-1.0.7-py2.7.egg/keras/preprocessing/text.py"", line 191, in sequences_to_matrix
    X = np.zeros((len(sequences), nb_words))
MemoryError
```

Using Keras version: 

``` bash
$ git describe --abbrev=4 HEAD
1.0.7-40-g090b
```

| Desc | Version |
| --- | --- |
| OS | Ubuntu 14.04.5 64-bit |
| Python | 2.7.6 |
| Numpy | 1.11.1 |

**DATA FILE:** [reddit_titles.zip](https://github.com/fchollet/keras/files/432150/reddit_titles.zip) (17MB)
",insectatorious,b'stale',2016-08-23T10:43:17Z,2017-06-23T00:11:28Z
3550,Bug fix : RNNs,"Avoid concatenating too many tensors (~100) when the actual logic is to tile, as this might cause `Blocks nested too deeply` error in large models (theano backend, Windows). This is actually an issue with Microsoft's Visual C compiler.
",farizrahman4u,None,2016-08-23T10:30:37Z,2016-08-24T00:03:17Z
3534,Support sparse labels and squeeze prediction outputs in sklearn wrapper (bugfix),"This PR proposes two small changes to `keras/wrappers/scikit_learn.py`
## Add support for sparse labels in KerasClassifier.score(X,y)

According to the documentation, the sklearn classification wrapper `KerasClassifier` should accept labels for the `fit` and `score` methods in the following two formats:
1. (n_samples,)
2. (n_samples, n_outputs)

In `fit`, the 1. format is transformed to the 2. with the following code:

``` python
loss_name = self.model.loss
if hasattr(loss_name, '__name__'):
    loss_name = loss_name.__name__
if loss_name == 'categorical_crossentropy' and len(y.shape) != 2:
    y = to_categorical(y)
```

The same code should be in `score` but is currently missing. I have added the code.
## Squeeze output of KerasClassifier.predict(X)

According to the documentation (and sklearn standards), the `predict` method of a regressor returns an array of shape `(n_samples,)`.  `KerasClassifier.predict(X)` though seems to return an array of shape `(n_samples,1)`. I've added a `np.squeeze` to make it match the output format.
## Tests

I noticed that the wrapper tests are not executed (methods not prefixed with ""test_""?), so  I've changed the tests a bit and now `py.test tests/` seems to pick them up. First time I've used py.test, so if what I did violates any standards, please let me know!
",DominicBreuker,None,2016-08-21T13:47:10Z,2016-08-22T22:19:26Z
3515,Error when RNN's output_dim = 1 while using theano backend.,"Script for reproducing the bug:

``` python
from keras.layers import LSTM
from keras.models import Sequential
import numpy as np

model = Sequential()
model.add(LSTM(1, input_shape=(3, 2)))
model.compile(loss='mse', optimizer='sgd')

x = np.random.random((4, 3, 2))
y = np.random.random((4, 1))

model.fit(x, y)
```

Error message : 

```
PS C:\Users\Fariz\Desktop> python keras_bug.py
Using Theano backend.
Using gpu device 0: GeForce GTX 980M (CNMeM is enabled with initial size: 50.0% of memory, cuDNN 5103)
Traceback (most recent call last):
  File ""keras_bug.py"", line 12, in <module>
    model.fit(x, y)
  File ""C:\Python27\lib\site-packages\keras-1.0.7-py2.7.egg\keras\models.py"", line 613, in fit
    sample_weight=sample_weight)
  File ""C:\Python27\lib\site-packages\keras-1.0.7-py2.7.egg\keras\engine\training.py"", line 1080, in fit
    self._make_train_function()
  File ""C:\Python27\lib\site-packages\keras-1.0.7-py2.7.egg\keras\engine\training.py"", line 697, in _make_train_functio

    training_updates = self.optimizer.get_updates(trainable_weights, self.constraints, self.total_loss)
  File ""C:\Python27\lib\site-packages\keras-1.0.7-py2.7.egg\keras\optimizers.py"", line 140, in get_updates
    grads = self.get_gradients(loss, params)
  File ""C:\Python27\lib\site-packages\keras-1.0.7-py2.7.egg\keras\optimizers.py"", line 68, in get_gradients
    grads = K.gradients(loss, params)
  File ""C:\Python27\lib\site-packages\keras-1.0.7-py2.7.egg\keras\backend\theano_backend.py"", line 677, in gradients
    return T.grad(loss, variables)
  File ""C:\Python27\lib\site-packages\theano\gradient.py"", line 549, in grad
    grad_dict, wrt, cost_name)
  File ""C:\Python27\lib\site-packages\theano\gradient.py"", line 1312, in _populate_grad_dict
    rval = [access_grad_cache(elem) for elem in wrt]
  File ""C:\Python27\lib\site-packages\theano\gradient.py"", line 1267, in access_grad_cache
    term = access_term_cache(node)[idx]
  File ""C:\Python27\lib\site-packages\theano\gradient.py"", line 961, in access_term_cache
    output_grads = [access_grad_cache(var) for var in node.outputs]
  File ""C:\Python27\lib\site-packages\theano\gradient.py"", line 1267, in access_grad_cache
    term = access_term_cache(node)[idx]
  File ""C:\Python27\lib\site-packages\theano\gradient.py"", line 1101, in access_term_cache
    input_grads = node.op.grad(inputs, new_output_grads)
  File ""C:\Python27\lib\site-packages\theano\scan_module\scan_op.py"", line 2523, in grad
    outputs = local_op(*outer_inputs)
  File ""C:\Python27\lib\site-packages\theano\gof\op.py"", line 602, in __call__
    node = self.make_node(*inputs, **kwargs)
  File ""C:\Python27\lib\site-packages\theano\scan_module\scan_op.py"", line 430, in make_node
    new_inputs.append(format(outer_seq, as_var=inner_seq))
  File ""C:\Python27\lib\site-packages\theano\scan_module\scan_op.py"", line 422, in format
    rval = tmp.filter_variable(rval)
  File ""C:\Python27\lib\site-packages\theano\tensor\type.py"", line 234, in filter_variable
    self=self))
TypeError: Cannot convert Type TensorType(float32, 3D) (of Variable Subtensor{:int64:}.0) into Type TensorType(float32,
(False, False, True)). You can try to manually convert Subtensor{:int64:}.0 into a TensorType(float32, (False, False, T
ue)).
PS C:\Users\Fariz\Desktop>
```
",farizrahman4u,None,2016-08-18T15:23:38Z,2018-03-21T17:23:01Z
3511,Keras speed slow on VGG-16,"I was comparing Keras with Caffe and found that Keras is 3.5x slower using Theano or 5x slower using TensorFlow.  This is using CUDA 8, cuDNN 5.0 on GTX 1080.  

I packaged up the comparison here: https://github.com/aizvorski/caffe-vs-keras

As far as I can tell all three implementations are working correctly (they converge if run outside of a benchmark), and have no problems using 100% of the GPU as shown by nvidia-smi dmon.  

Also as far as I can tell there is nothing unusual about my implementation of VGG-16 (the Caffe version is from the model zoo, the Keras version is from https://gist.github.com/baraldilorenzo/07d7802847aaad0a35d3).

This is surprising because I would expect all implementations running on top of cuDNN to have approximately the same speed, barring something quite unusual.

Is this expected? Could it be a performance bug?
- [x] Check that you are up-to-date with the master branch of Keras. You can update with:
  pip install git+git://github.com/fchollet/keras.git --upgrade --no-deps
- [x] If running on Theano, check that you are up-to-date with the master branch of Theano. You can update with:
  pip install git+git://github.com/Theano/Theano.git --upgrade --no-deps
- [x] Provide a link to a GitHub Gist of a Python script that can reproduce your issue (or just copy the script here if it is short).
",aizvorski,None,2016-08-18T08:52:00Z,2016-08-20T01:49:29Z
3493,fit_generator is ignoring ValueErrors from generators,"As seen [here](/fchollet/keras/blob/master/keras/engine/training.py#L425), Keras just ignores ValueErrors raised by a generator.

``` python
                        try:
                            generator_output = next(generator)
                        except ValueError:
                            continue
```

Is it for thread safety? If it is, then I think a thread safe wrapper would be a better approach (see [this post](http://anandology.com/blog/using-iterators-and-generators/) about the subject). I just spent 1 hour trying to track down a bug because Keras was intercepting my exceptions.
",fredtcaroli,None,2016-08-16T16:54:20Z,2016-08-17T18:36:17Z
3491,Net2Net MNIST Example for Comments,"I am posting an PR candidate for comments. It is an implementation of [""Net2Net: Accelerating Learning via Knowledge Transfer""](http://arxiv.org/abs/1511.05641). Updates can be found [on my fork](https://github.com/dolaameng/keras/blob/mnist_net2net_example/examples/mnist_net2net.py). 

I noticed there have been several implementations on github, e.g., [paengs/Net2Net](https://github.com/paengs/Net2Net), [DanielSlater/Net2Net](https://github.com/DanielSlater/Net2Net), and [DT42/net2net_demo](https://github.com/DT42/net2net_demo). I have tried to squeeze the code into one example file.  The current implementation is tested on MNIST - it is fast to run but may not be the ideal case for demonstrating the power of net2net models - slight improvements have been observed against benchmarks. 

I am looking for comments on the code so that I may make a PR if possible, as well as
1. potential bugs
2. stronger evidence of advantages on other datasets
3. more natural ways of integrating net2net mechanism into Keras, e.g., specific weight_initializers, layer_wrappers and etc.

See codes below. Thanks!

``` python
'''This is an implementation of Net2Net experiment with MNIST in 
""Net2Net: Accelerating Learning via Knowledge Transfer""
by Tianqi Chen, Ian Goodfellow, and Jonathon Shlens

arXiv:1511.05641v4 [cs.LG] 23 Apr 2016
http://arxiv.org/abs/1511.05641

Tested with ""Theano"" backend and ""th"" image_dim_ordering. 
Performance Comparisons - loss value of first 3 epoches:
(1) teacher_model:             0.44    0.14    0.09
(2) wider_random_pad:          0.09    0.05    0.04
(3) wider_net2wider:           0.07    0.05    0.05
(4) deeper_random_init:        0.18    0.07    0.05
(5) deeper_net2deeper:         0.07    0.05    0.04
'''

from __future__ import print_function

from keras.models import Sequential
from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten
from keras.utils import np_utils
from keras.datasets import mnist

import numpy as np 

np.random.seed(1337)
input_shape = (1, 28, 28) # image shape

## load and pre-process data

(train_x, train_y), (validation_x, validation_y) = mnist.load_data()
preprocess_input = lambda x: x.reshape((-1, ) + input_shape) / 255.
preprocess_output = lambda y: np_utils.to_categorical(y)
train_x, validation_x = map(preprocess_input, [train_x, validation_x])
train_y, validation_y = map(preprocess_output, [train_y, validation_y])
print(""Loading MNIST data..."")
print(""train_x shape:"", train_x.shape, ""train_y shape:"", train_y.shape)
print(""validation_x shape:"", validation_x.shape, ""validation_y shape"", validation_y.shape, ""\n"")


## algorithm for wider/deeper layers

def wider2net_conv2d(teacher_w1, teacher_b1, teacher_w2, new_width, init):
    """"""Get initial weights for a wider conv2d layer with a bigger nb_filter, 
    by 'random-padding' or 'net2wider'.

    # Auguments
        teacher_w1: `weight` of conv2d layer to become wider, of shape (nb_filter1, nb_channel1, h1, w1)
        teacher_b1: `bias` of conv2d layer to become wider, of shape (nb_filter1, )
        teacher_w2: `weight` of next connected conv2d layer, of shape (nb_filter2, nb_channel2, h2, w2)
        new_width: new `nb_filter` for the wider conv2d layer
        init: initialization algorithm for new weights, either 'random-pad' or 'net2wider'
    """"""

    assert teacher_w1.shape[0] == teacher_w2.shape[1]  # nb_filter1 == nb_channel2 for connected layers
    assert teacher_w1.shape[0] == teacher_b1.shape[0]
    assert new_width > teacher_w1.shape[0]

    n = new_width - teacher_w1.shape[0]
    if init == 'random-pad': 
        new_w1 = np.random.normal(0, 0.1, size = (n, ) + teacher_w1.shape[1:])
        new_b1 = np.ones(n) * 0.1
        new_w2 = np.random.normal(0, 0.1, size = (teacher_w2.shape[0], n) + teacher_w2.shape[2:] )
    elif init == 'net2wider':
        index = np.random.randint(teacher_w1.shape[0], size = n)
        factors = np.bincount(index)[index] + 1.
        new_w1 = teacher_w1[index, :, :, :]
        new_b1 = teacher_b1[index]
        new_w2 = teacher_w2[:, index, :, :] / factors.reshape((1, -1, 1, 1))      
    else:
        raise ValueError(""Unsupported weight initializer: %s"" % init)

    student_w1 = np.concatenate((teacher_w1, new_w1), axis = 0)
    student_w2 = np.concatenate((teacher_w2, new_w2), axis = 1)
    if init == 'net2wider':
        student_w2[:, index, :, :] = new_w2
    student_b1 = np.concatenate((teacher_b1, new_b1), axis = 0)

    return student_w1, student_b1, student_w2

def wider2net_fc(teacher_w1, teacher_b1, teacher_w2, new_width, init):
    """"""Get initial weights for a wider fully connected (dense) layer with a bigger nout, 
    by 'random-padding' or 'net2wider'.

    # Auguments
        teacher_w1: `weight` of fc layer to become wider, of shape (nin1, nout1)
        teacher_b1: `bias` of fc layer to become wider, of shape (nout1, )
        teacher_w2: `weight` of next connected fc layer, of shape (nin2, nout2)
        new_width: new `nout` for the wider fc layer
        init: initialization algorithm for new weights, either 'random-pad' or 'net2wider'
    """"""

    assert teacher_w1.shape[1] == teacher_w2.shape[0] ## nout1 == nin2 for connected layers
    assert teacher_w1.shape[1] == teacher_b1.shape[0]
    assert new_width > teacher_w1.shape[1]

    n = new_width - teacher_w1.shape[1]
    if init == 'random-pad':
        new_w1 = np.random.normal(0, 0.1, size = (teacher_w1.shape[0], n))
        new_b1 = np.ones(n) * 0.1
        new_w2 = np.random.normal(0, 0.1, size = (n, teacher_w2.shape[1]))
    elif init == 'net2wider':
        index = np.random.randint(teacher_w1.shape[1], size = n)
        factors = np.bincount(index)[index] + 1.
        new_w1 = teacher_w1[:, index]
        new_b1 = teacher_b1[index]
        new_w2 = teacher_w2[index, :] / factors[:, np.newaxis]
    else:
        raise ValueError(""Unsupported weight initializer: %s"" % init)

    student_w1 = np.concatenate((teacher_w1, new_w1), axis = 1)
    student_w2 = np.concatenate((teacher_w2, new_w2), axis = 0)
    if init == 'net2wider':
        student_w2[index, :] = new_w2
    student_b1 = np.concatenate((teacher_b1, new_b1), axis = 0)

    return student_w1, student_b1, student_w2

def deeper2net_conv2d(teacher_w):
    """"""Get initial weights for a deeper conv2d layer by net2deeper'.

    # Auguments
        teacher_w: `weight` of previous conv2d layer, of shape (nb_filter, nb_channel, h, w)
    """"""
    nb_filter, nb_channel, w, h = teacher_w.shape
    student_w = np.zeros((nb_filter, nb_filter, w, h))
    for i in xrange(nb_filter):
        student_w[i, i, (h - 1) / 2, (w - 1) / 2] = 1.
    student_b = np.zeros(nb_filter)
    return student_w, student_b

def copy_weights(teacher_model, student_model, layer_names):
    """"""Copy weights from teacher_model to student_model, 
     for layers listed in layer_names 
    """"""
    for name in layer_names:
        weights = teacher_model.get_layer(name = name).get_weights()
        student_model.get_layer(name = name).set_weights(weights)

## experiments setup

def make_teacher_model(train_data, validation_data):
    """"""Train a simple CNN as teacher model.
    """""" 
    model = Sequential()
    model.add(Conv2D(64, 3, 3, input_shape = input_shape, border_mode = ""same"", name = ""conv1""))
    model.add(MaxPooling2D(name = ""pool1""))
    model.add(Conv2D(128, 3, 3, border_mode = ""same"", name = ""conv2""))
    model.add(MaxPooling2D(name = ""pool2""))
    model.add(Flatten(name = ""flatten""))
    model.add(Dense(128, activation = ""relu"", name = ""fc1""))
    model.add(Dense(10, activation = ""softmax"", name = ""fc2""))
    model.compile(loss = ""categorical_crossentropy"", optimizer = ""sgd"", metrics = [""accuracy""])

    train_x, train_y = train_data
    history = model.fit(train_x, train_y, nb_epoch=3, validation_data = validation_data)
    return model, history

def make_wider_student_model(teacher_model, train_data, validation_data, init):
    """"""Train a wider student model based on teacher_model, with either 'random-pad' (baseline)
    or 'net2wider'
    """"""
    new_conv1_width = 128
    new_fc1_width = 256

    model = Sequential()
    ## a wider conv1 compared to teacher_model
    model.add(Conv2D(new_conv1_width, 3, 3, input_shape = input_shape, border_mode = ""same"", name = ""conv1""))
    model.add(MaxPooling2D(name = ""pool1""))
    model.add(Conv2D(128, 3, 3, border_mode = ""same"", name = ""conv2""))
    model.add(MaxPooling2D(name = ""pool2""))
    model.add(Flatten(name = ""flatten""))
    ## a wider fc1 compared to teacher model
    model.add(Dense(new_fc1_width, activation = ""relu"", name = ""fc1""))
    model.add(Dense(10, activation = ""softmax"", name = ""fc2""))

    ## The weights for other layers need to be copied from teacher_model 
    ## to student_model, except for widened layers and their immediate downstreams, 
    ## which will be initialized separately.
    ## For this example there are no other layers that need to be copied.

    w_conv1, b_conv1 = teacher_model.get_layer(""conv1"").get_weights()
    w_conv2, b_conv2 = teacher_model.get_layer(""conv2"").get_weights()
    new_w_conv1, new_b_conv1, new_w_conv2  = wider2net_conv2d(w_conv1, b_conv1, w_conv2, new_conv1_width, init)
    model.get_layer(""conv1"").set_weights([new_w_conv1, new_b_conv1])
    model.get_layer(""conv2"").set_weights([new_w_conv2, b_conv2])

    w_fc1, b_fc1 = teacher_model.get_layer(""fc1"").get_weights()
    w_fc2, b_fc2 = teacher_model.get_layer(""fc2"").get_weights()
    new_w_fc1, new_b_fc1, new_w_fc2  = wider2net_fc(w_fc1, b_fc1, w_fc2, new_fc1_width, init)
    model.get_layer(""fc1"").set_weights([new_w_fc1, new_b_fc1])
    model.get_layer(""fc2"").set_weights([new_w_fc2, b_fc2])

    model.compile(loss = ""categorical_crossentropy"", optimizer = ""sgd"", metrics = [""accuracy""])

    train_x, train_y = train_data
    history = model.fit(train_x, train_y, nb_epoch=3, validation_data = validation_data)
    return model, history

def make_deeper_student_model(teacher_model, train_data, validation_data, init):
    """"""Train a deeper student model based on teacher_model, with either 'random-init' (baseline)
    or 'net2deeper'
    """"""
    model = Sequential()
    model.add(Conv2D(64, 3, 3, input_shape = input_shape, border_mode = ""same"", name = ""conv1""))
    model.add(MaxPooling2D(name = ""pool1""))
    model.add(Conv2D(128, 3, 3, border_mode = ""same"", name = ""conv2""))
    ## add another conv2d layer to make original conv2 deeper
    if init == ""net2deeper"":
        prev_w, _ = model.get_layer(""conv2"").get_weights()
        new_weights = deeper2net_conv2d(prev_w)
        model.add(Conv2D(128, 3, 3, border_mode = ""same"", name = ""conv2-deeper"", weights = new_weights))
    elif init == ""random-init"":
        model.add(Conv2D(128, 3, 3, border_mode = ""same"", name = ""conv2-deeper""))
    else:
        raise ValueError(""Unsupported weight initializer: %s"" % init)
    model.add(MaxPooling2D(name=""pool2""))
    model.add(Flatten(name=""flatten""))
    model.add(Dense(128, activation=""relu"", name=""fc1""))
    ## add another fc layer to make original fc1 deeper
    if init == ""net2deeper"":
        ## net2deeper for fc layer with relu, is just an identity initializer
        model.add(Dense(128, init = ""identity"", activation = ""relu"", name = ""fc1-deeper""))
    elif init == ""random-init"":
        model.add(Dense(128, activation = ""relu"", name = ""fc1-deeper""))
    else:
        raise ValueError(""Unsupported weight initializer: %s"" % init)
    model.add(Dense(10, activation=""softmax"", name=""fc2""))

    ## copy weights for other layers
    copy_weights(teacher_model, model, layer_names=[""conv1"", ""conv2"", ""fc1"", ""fc2""])

    model.compile(loss = ""categorical_crossentropy"", optimizer = ""sgd"", metrics = [""accuracy""])

    train_x, train_y = train_data
    history = model.fit(train_x, train_y, nb_epoch=3, validation_data = validation_data)
    return model, history

def net2wider_experiment():
    """"""Benchmark performances of 
    (1) a teach model, 
    (2) a wider student model with `random_pad` initializer
    (3) a wider student model with `Net2WiderNet` initializer
    """"""
    train_data = (train_x, train_y)
    validation_data = (validation_x, validation_y)
    print(""Experiment of Net2WiderNet ..."")
    print(""building teacher model ..."")
    teacher_model, teacher_history = make_teacher_model(train_data, validation_data)

    print(""building wider student model by random padding ..."")
    random_student_model, random_student_history = make_wider_student_model(
                                                        teacher_model,
                                                        train_data, 
                                                        validation_data, 
                                                        ""random-pad"")
    print(""building wider student model by net2wider ..."")
    net2wider_student_model, net2wider_student_history = make_wider_student_model(
                                                        teacher_model,
                                                        train_data, 
                                                        validation_data, 
                                                        ""net2wider"")

def net2deeper_experiment():
    """"""Benchmark performances of 
    (1) a teach model, 
    (2) a deeper student model with `random_init` initializer
    (3) a deeper student model with `Net2DeeperNet` initializer
    """"""
    train_data = (train_x, train_y)
    validation_data = (validation_x, validation_y)
    print(""Experiment of Net2DeeperNet ..."")
    print(""building teacher model ..."")
    teacher_model, teacher_history = make_teacher_model(train_data, validation_data)

    print(""building deeper student model by random init ..."")
    random_student_model, random_student_history = make_deeper_student_model(
                                                        teacher_model,
                                                        train_data, 
                                                        validation_data, 
                                                        ""random-init"")
    print(""building deeper student model by net2deeper ..."")
    net2deeper_student_model, net2deeper_student_history = make_deeper_student_model(
                                                        teacher_model,
                                                        train_data, 
                                                        validation_data, 
                                                        ""net2deeper"")

## run the experiments

net2wider_experiment()
net2deeper_experiment()
```
",dolaameng,None,2016-08-16T12:39:05Z,2016-08-17T14:50:33Z
3470,Fix a issue when only specify one dot_axes for in the Merge layer in the dot mode,"@farizrahman4u Just wonder if there is a bug in line 1225. When there is only one dot_axes specified in the Merge layer in the dot mode, should not we change the dot_axes = [dot_axes, dot_axes] just as done in line 1147-1148? After the this fix, the following code can be ran correctly(only specify one dot_axes) otherwise will fail:

```
model_word = Sequential()
model_word.add(Embedding(1e4, 300, input_length=1))
model_word.add(Reshape((1,300)))
models.append(model_word)

model_context = Sequential()
model_context.add(Embedding(1e4, 300, input_length=5))
model_context.add(Reshape((5,300)))
models.append(model_context)

model = Sequential()
# Both dot_axes = 2 and dot_axes = [2, 2] will work now, otherwise only [2,2] will work
model.add(Merge(models, mode='dot', dot_axes = 2))
print model.layers[-1].output_shape
model.add(Reshape((5,)))
print model.layers[-1].output_shape
model.add(Dense(5))
model.add(Activation('sigmoid'))
model.compile(loss='mean_squared_error', optimizer='sgd')
```
",kemaswill,None,2016-08-14T05:39:59Z,2016-08-17T20:30:46Z
3459,Bug Keras1.0.7 - Convolution2D or Objectives?,"When I upgrade from Keras1.0.6 to 1.0.7, the following code produces wildly different results for the loss. In 1.0.6, the loss starts ~1.5 and steadily decreases. In 1.0.7, however, the MSE loss starts around 14,000 .. which is clearly not correct. I'm thinking it's either a problem with the MSE objective, the convolution layer, or maybe the regularizer is not getting picked up. Note this code is trivial to reproduce the error.

It happens w/ theano0.8.2 and 0.9.0dev. I'm using NVIDIA GPU with CUDA7.5 and visual studio VC12.0, cuDNN 5005.

```
from __future__ import division
import numpy as np

from keras.models import Sequential
from keras.layers import Dense, Flatten, Convolution2D
from keras.regularizers import l1l2
from keras.optimizers import SGD


images = np.random.randn(10000,1,32,32)

x_train = images[0:8000,:,:,:]
y_train = x_train.copy()
x_test = images[8000:,:,:,:]
y_test = x_test.copy()

ytr = np.empty((y_train.shape[0],y_train.shape[-1]**2))
yte = np.empty((y_test.shape[0],y_test.shape[-1]**2))
for i in range(y_train.shape[0]):
    ytr[i,:] = y_train[i,:,:,:].flatten()
    if i < y_test.shape[0]:
        yte[i,:] = y_test[i,:,:,:].flatten()
y_train = ytr
y_test = yte

stride = (2,2)
kernel_size = (15,15)
nb_kernels = 2

autoencoder = Sequential()
autoencoder.add(Convolution2D(nb_kernels, kernel_size[0], kernel_size[1], 
    border_mode='same', subsample=stride, W_regularizer=l1l2(l1=1.0,l2=0.1),
    activation='relu', input_shape=(1,x_train.shape[-1],x_train.shape[-1])))
autoencoder.add(Flatten())
autoencoder.add(Dense(y_train.shape[-1], 
    activation='tanh', W_regularizer=l1l2(l1=1.0,l2=0.1)))


autoencoder.compile(optimizer=SGD(lr=0.5), loss='mse')

autoencoder.fit(x_train, y_train,
                nb_epoch=100,
                batch_size=512,
                verbose = 1,
                validation_data=(x_test,y_test))
```

1.0.7:

Train on 8000 samples, validate on 2000 samples
Epoch 1/100
8000/8000 [==============================] - 0s - loss: 138498.2220 - val_loss: 1.9168
Epoch 2/100
8000/8000 [==============================] - 0s - loss: 140987.8638 - val_loss: 1.9382
Epoch 3/100
8000/8000 [==============================] - 0s - loss: 141583.5654 - val_loss: 1.9408

1.0.6:

Train on 8000 samples, validate on 2000 samples
Epoch 1/100
8000/8000 [==============================] - 0s - loss: 1.0857 - val_loss: 1.0002
Epoch 2/100
8000/8000 [==============================] - 0s - loss: 1.0361 - val_loss: 0.9999
Epoch 3/100
8000/8000 [==============================] - 0s - loss: 1.0316 - val_loss: 0.9999
",ncullen93,b'stale',2016-08-12T17:03:23Z,2017-06-23T01:11:09Z
3452,A model cannot be restored from configuration,"The following code:

```
model = Model(input=a, output=b)
config = model.get_config()
restored_model = model_from_config(config)
```

Fails with an exception:

Traceback (most recent call last):
  File ""C:\Program Files (x86)\JetBrains\PyCharm 2016.2\helpers\pydev\pydevd.py"", line 1556, in <module>
    globals = debugger.run(setup['file'], None, None, is_module)
  File ""C:\Program Files (x86)\JetBrains\PyCharm 2016.2\helpers\pydev\pydevd.py"", line 940, in run
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File ""C:\Program Files (x86)\JetBrains\PyCharm 2016.2\helpers\pydev_pydev_imps_pydev_execfile.py"", line 18, in execfile
    exec(compile(contents+""\n"", file, 'exec'), glob, loc)
  File ""C:/Users/develop/code/ladder/test.py"", line 41, in <module>
    model_recovered = model_from_config(config)
  File ""C:\Program Files\Dragonfly\Anaconda3\lib\site-packages\keras-1.0.7-py3.5.egg\keras\models.py"", line 177, in model_from_config
    return layer_from_config(config, custom_objects=custom_objects)
  File ""C:\Program Files\Dragonfly\Anaconda3\lib\site-packages\keras-1.0.7-py3.5.egg\keras\utils\layer_utils.py"", line 25, in layer_from_config
    **class_name = config['class_name']
KeyError: 'class_name'**

I have a fix for this, and will submit it as a pull request. 

Please make sure that the boxes below are checked before you submit your issue. Thank you!
- [v] Check that you are up-to-date with the master branch of Keras. You can update with:
  pip install git+git://github.com/fchollet/keras.git --upgrade --no-deps
- [v] If running on Theano, check that you are up-to-date with the master branch of Theano. You can update with:
  pip install git+git://github.com/Theano/Theano.git --upgrade --no-deps
- [v] Provide a link to a GitHub Gist of a Python script that can reproduce your issue (or just copy the script here if it is short).
",ruslanagit,None,2016-08-11T17:37:26Z,2016-08-11T20:43:15Z
3439,[Bug?] MemoryError (CNEM_STATUS_OUT_OF_MEMORY) even after going back to a batch size that worked before,"Let's assume I am in a python shell and I start training a model:

`model.fit(X,Y, batch_size = 8)`

Works like a charm, but now I want to try a larger batch size:

```
model.fit(X,Y, batch_size = 16)
MemoryError: Error allocating 52428800 bytes of device memory (CNMEM_STATUS_OUT_OF_MEMORY).
```

Alright, that was too much, let's go back to the batch size that worked before

```
model.fit(X,Y, batch_size = 8)
MemoryError: Error allocating 26214400 bytes of device memory (CNMEM_STATUS_OUT_OF_MEMORY).
```

woops, suddenly I can't train my model anymore. I've encountered this problem in different keras/theano versions. Running the most recent versions of both now and I can still observe this behaviour.
",madeofwin,b'stale',2016-08-10T10:43:16Z,2017-06-23T01:11:08Z
3433,Bug fix : squeeze,"Avoid all the broadcasting stuff.
",farizrahman4u,None,2016-08-09T20:17:38Z,2016-08-09T20:59:47Z
3431,Potential Bug in K.squeeze for Theano?,"[Here](https://gist.github.com/jmhessel/ede93c03ed04824c72ad773e13b37265) is an example of a case where Theano and Tensorflow differ in their behavior with respect to the K.squeeze function. Essentially, [K.squeeze(x, 2)](https://github.com/fchollet/keras/blob/master/keras/backend/theano_backend.py#L504-L511) doesn't perform as it should in the example I provided, but only when using the Theano backend.

Has anyone else encountered this? Is this indeed a bug? If so, do folks have thoughts about what could be potentially not working?
#3420 also mentions an issue with this function in the Theano backend, though I'm not sure if this is exactly the same issue
",jmhessel,b'type:bug/performance',2016-08-09T18:55:41Z,2017-01-26T16:46:43Z
3422,Bug in ImageDataGenerator/standartize,"the samplewise operations should be over the spatial axes not over the channel axis. i.e.

x -= np.mean(x, axis=img_channel_index, keepdims=True)

should be:

x -= np.mean(x, axis=(row_index, col_index), keepdims=True)
",eyaler,None,2016-08-08T16:22:13Z,2016-11-23T04:22:06Z
3420,"maybe a bug in "" keras/backend/theano_backend.py: line 507 in function squeeze""??","if axis == -1,  then line 507 will be 
      broadcastable = x.broadcastable[:-1] + x.broadcastable[0:]
and will not remove   @@correctly?

504 def squeeze(x, axis):
505    '''Remove a 1-dimension from the tensor at index ""axis"".
506    '''
507    broadcastable = x.broadcastable[:axis] + x.broadcastable[axis+1:]
508    x = T.patternbroadcast(x, [i == axis for i in range(x.type.ndim)])
509    x = T.squeeze(x)
510    x = T.patternbroadcast(x, broadcastable)
511    return x
",sunlylorn,b'stale',2016-08-08T10:41:25Z,2017-06-23T01:10:47Z
3384,maybe a bug in run multiprocess environment,"version: 1.0.6
file: keras/backend/**init**.py, line: 46

keras will save config in ~/.keras/keras.json everytime when it run, it's ok if only has one process to run, but if in multiprocess env, it maybe overwrite the config file when other process just reading it.
so it will raise an exception in line 26
so why keras need save config every running?
",ricky1203,b'stale',2016-08-03T09:48:35Z,2017-06-23T01:10:34Z
3371,Deconvolution2D stack with different nb_filter ,"I'm attempting to implement [Image Restoration Using Convolutional Auto-encoders with Symmetric Skip
Connections](http://arxiv.org/pdf/1606.08921v1.pdf) in Keras using the new Deconvolution2D layer.

I have a working version of this architecture using the UpSampling2D and Conv2D method to implement Deconvolutions, but due to max pooling and subsequent upsampling, I couldn't create a very deep model.

With the new Deconvolution2D, I can implement this, but it crashes giving an Input dimension mismatch when using Deconv stacks with different number of output filters. An example script is given below. (I know that the authors use skip connections every 2 corresponding layers and that I use skip connection after every layer, but I have tested it with every two layers and the same error occurs.)

Gist : [Conv Auto Encoder with Symmetric Skip Connections](https://gist.github.com/titu1994/6de7e693126c3b5fcc5edc98faa46ea1)

System config:
Windows 10
Theano 0.9.devr2
Keras (master branch)
CuDNN 5.1 RC

**Crash report:**
Using Theano backend.
Using gpu device 0: GeForce GTX 980M (CNMeM is enabled with initial size: 80.0% of memory, cuDNN 5103)
Epoch 1/10
Traceback (most recent call last):
  File ""D:\Users\Yue\Anaconda3\lib\site-packages\theano\compile\function_module.py"", line 866, in **call**
    self.fn() if output_subset is None else\
ValueError: GpuElemwise. Input dimension mis-match. Input 3 (indices start at 0) has shape[0] == 64, but the output's size on that axis is 128.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""D:/Users/Yue/PycharmProjects/ImageSuperResolution/conv_auto_encoder.py"", line 52, in <module>
    model.fit(dataX, dataY, batch_size=batch_size, nb_epoch=10)
  File ""D:\Users\Yue\Anaconda3\lib\site-packages\keras\engine\training.py"", line 1107, in fit
    callback_metrics=callback_metrics)
  File ""D:\Users\Yue\Anaconda3\lib\site-packages\keras\engine\training.py"", line 825, in _fit_loop
    outs = f(ins_batch)
  File ""D:\Users\Yue\Anaconda3\lib\site-packages\keras\backend\theano_backend.py"", line 643, in __call__
    return self.function(*inputs)
  File ""D:\Users\Yue\Anaconda3\lib\site-packages\theano\compile\function_module.py"", line 879, in **call**
    storage_map=getattr(self.fn, 'storage_map', None))
  File ""D:\Users\Yue\Anaconda3\lib\site-packages\theano\gof\link.py"", line 325, in raise_with_op
    reraise(exc_type, exc_value, exc_trace)
  File ""D:\Users\Yue\Anaconda3\lib\site-packages\six.py"", line 685, in reraise
    raise value.with_traceback(tb)

  File ""D:\Users\Yue\Anaconda3\lib\site-packages\theano\compile\function_module.py"", line 866, in **call**
    self.fn() if output_subset is None else\
ValueError: GpuElemwise. Input dimension mis-match. Input 3 (indices start at 0) has shape[0] == 64, but the output's size on that axis is 128.
Apply node that caused the error: GpuElemwise{Composite{((i0 \* i1) + (i2 \* i3))}}[(0, 1)](GpuDimShuffle{x,x,x,x}.0, <CudaNdarrayType%28float32, 4D%29>, GpuDimShuffle{x,x,x,x}.0, GpuDnnConvGradW{algo='none', inplace=True}.0)
Toposort index: 364
Inputs types: [CudaNdarrayType(float32, (True, True, True, True)), CudaNdarrayType(float32, 4D), CudaNdarrayType(float32, (True, True, True, True)), CudaNdarrayType(float32, 4D)]
Inputs shapes: [(1, 1, 1, 1), (128, 64, 3, 3), (1, 1, 1, 1), (64, 64, 3, 3)]
Inputs strides: [(0, 0, 0, 0), (576, 9, 3, 1), (0, 0, 0, 0), (576, 9, 3, 1)]
Inputs values: [b'CudaNdarray([[[[ 0.89999998]]]])', 'not shown', b'CudaNdarray([[[[ 0.10000002]]]])', 'not shown']
Outputs clients: [['output', GpuElemwise{Composite{(i0 - ((i1 \* i2) / (i3 + sqrt(clip(i4, i5, i6)))))}}[(0, 0)](convolution2d_3_W, GpuDimShuffle{x,x,x,x}.0, GpuElemwise{Composite{%28%28i0 * i1%29 + %28i2 * i3%29%29}}[%280, 1%29].0, CudaNdarrayConstant{[[[[  9.99999994e-09]]]]}, GpuElemwise{Composite{%28%28i0 * i1%29 + %28i2 * sqr%28i3%29%29%29}}[%280, 1%29].0, CudaNdarrayConstant{[[[[ 0.]]]]}, CudaNdarrayConstant{[[[[ inf]]]]})]]

HINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.
HINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.

**To remove this error**
-  If n1 = n2 = any number, then crash does not occur. This isn't very useful since accuracy depends on number of filters as well. The previous version used 64, 128 and 256 filters, achieving an accuracy of 37.39 PSNR (Peak Signal to Noise Ratio). This one doesn't go above 36.41 PSNR with n1 = n2 = 64.
",titu1994,b'stale',2016-08-01T15:40:42Z,2017-06-22T21:14:28Z
3359,load_weights fails because 'layer_names' is missing,"`load_weights` is broken.
""Can't open attribute (Can't locate attribute: 'layer_names')""

```
Traceback (most recent call last):
  File ""/u/visin/.local/lib/python2.7/site-packages/ipdb/__main__.py"", line 168, in main
    pdb._runscript(mainpyfile)
  File ""/Tmp/lisa/os_v5/anaconda/lib/python2.7/pdb.py"", line 1233, in _runscript
    self.run(statement)
  File ""/Tmp/lisa/os_v5/anaconda/lib/python2.7/bdb.py"", line 400, in run
    exec cmd in globals, locals
  File ""<string>"", line 1, in <module>
  File ""eval_camvid2.MD10_relu.py"", line 1, in <module>
    from keras.optimizers import RMSprop as Optimizer
  File ""rec_conv_deconv.py"", line 318, in run
    model.load_weights('./tmp/tmp_' + save_name + ""_latest.w"")
  File ""/u/visin/exp/keras/keras/engine/topology.py"", line 2414, in load_weights
    self.load_weights_from_hdf5_group(f)
  File ""/u/visin/exp/keras/keras/engine/topology.py"", line 2451, in load_weights_from_hdf5_group
    layer_names = [n.decode('utf8') for n in f.attrs['layer_names']]
  File ""h5py/_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper (/home/ilan/minonda/conda-bld/work/h5py/_objects.c:2579)
  File ""h5py/_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper (/home/ilan/minonda/conda-bld/work/h5py/_objects.c:2538)
  File ""/Tmp/lisa/os_v5/anaconda/lib/python2.7/site-packages/h5py/_hl/attrs.py"", line 52, in __getitem__
    attr = h5a.open(self._id, self._e(name))
  File ""h5py/_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper (/home/ilan/minonda/conda-bld/work/h5py/_objects.c:2579)
  File ""h5py/_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper (/home/ilan/minonda/conda-bld/work/h5py/_objects.c:2538)
  File ""h5py/h5a.pyx"", line 77, in h5py.h5a.open (/home/ilan/minonda/conda-bld/work/h5py/h5a.c:2088)
KeyError: ""Can't open attribute (Can't locate attribute: 'layer_names')""
Uncaught exception. Entering post mortem debugging
```
",fvisin,None,2016-07-31T21:42:26Z,2017-07-24T19:18:31Z
3349,ActivityRegularizer causing tensor shape mismatch,"Hi there,

I am experiencing a bug where the addition of an regularizer causes keras to throw a ValueError.

My code is as follows:
`input_lc = Input(shape=(X.shape[1],))

encoded = Dense(100, activation='relu', input_shape=(X.shape[1],))(input_lc)
encoded = Dense(50,  activation='relu')(encoded)
encoded = Dense(output_dim=encoding_dim, activation='linear')(encoded)

decoded = Dense(50,  activation='relu', input_shape=(encoding_dim,))(encoded)
decoded = Dense(100,  activation='relu')(decoded)
decoded = Dense(output_dim=X.shape[1], activation='linear')(decoded)

autoencoder = Model(input=input_lc, output=decoded)
encoder = Model(input=input_lc, output=encoded)
autoencoder.compile(optimizer='adam', loss='mse')`

This code runs fine. However, if I alter the last encoder layer such that it is 

`encoded = Dense(output_dim=encoding_dim, activation='linear', activity_regularizer=regularizers.activity_l1(0.1))(encoded)`

then I get this error:

`
Traceback (most recent call last):
  File ""/usr/local/lib/python3.5/dist-packages/keras/optimizers.py"", line 321, in get_updates
    grads = self.get_gradients(loss, params)
  File ""/usr/local/lib/python3.5/dist-packages/keras/optimizers.py"", line 53, in get_gradients
    grads = K.gradients(loss, params)
  File ""/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py"", line 770, in gradients
    return tf.gradients(loss, variables)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients.py"", line 505, in gradients
    in_grad.set_shape(t_in.get_shape())
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py"", line 404, in set_shape
    self._shape = self._shape.merge_with(shape)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/tensor_shape.py"", line 570, in merge_with
    (self, other))
**ValueError: Shapes (24,) and () are not compatible**`

Any ideas on why this might be happening?

(Sorry for the edit spam, I accidentally submitted before having anything written...)
",NMRobert,None,2016-07-29T16:30:57Z,2016-07-29T17:07:32Z
3348,False positive topology UserWarning,"When executing this code:

``` python
from keras.models import Model
from keras.layers import Input, Lambda

from numpy import array

def identity(img):
    return img

def identity_shape(input_shape):
    return input_shape

img = Input(shape=(1, None, None))
identity = Lambda(identity, output_shape=identity_shape)(img)

model = Model(img, identity)
model.summary()
print(model.predict(array([[[[1, 2], [3, 4]]]])))
```

I get following output with warning:

```
Using Theano backend.
Using gpu device 0: GeForce GTX 980 (CNMeM is disabled, cuDNN 5005)
/usr/lib64/python3.4/site-packages/keras/engine/topology.py:1625: UserWarning: Model inputs must come from a Keras Input layer, they cannot be the output of a previous non-Input layer. Here, a tensor specified as input to ""model_1"" was not an Input tensor, it was generated by layer lambda_1.
Note that input tensors are instantiated via `tensor = Input(shape)`.
The tensor that caused the issue was: input_1
  str(x.name))
____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
input_1 (InputLayer)             (None, 1, None, None) 0                                            
____________________________________________________________________________________________________
lambda_1 (Lambda)                (None, 1, None, None) 0           input_1[0][0]                    
====================================================================================================
Total params: 0
____________________________________________________________________________________________________
[[[[ 1.  2.]
   [ 3.  4.]]]]
```

Although model works correct, the warning is pretty annoying. Must be a bug with lambda connectivity identification.

Keras and Theano are fresh from GitHub.
",shahurik,b'stale',2016-07-29T12:51:42Z,2017-06-23T01:10:50Z
3340,Incosistent Color Channel Order in examples/neural_style_transfer.py,"I notice there is a difference in how images are pre-processed in the [neural_style_transfer example](https://github.com/fchollet/keras/blob/master/examples/neural_style_transfer.py) and the [recommended way](https://gist.github.com/baraldilorenzo/07d7802847aaad0a35d3) of using VGG16 model. Specially,
- The color channels in neural_style_transfer example is RGB (as read by scipy.misc.imread), whereas the order in original VGG is expected to be BGR. 
-  The mean-centering step is not performed in the example, i.e.,

```
im[:,:,0] -= 103.939
im[:,:,1] -= 116.779
im[:,:,2] -= 123.68
```

Some of my experiments showed that these differences could result in sub-optimal results in image classification, e.g., [red fox](https://www.google.com.sg/?ion=1&espv=2#q=red%20fox) misclassified to [grey fox](https://www.google.com.sg/?ion=1&espv=2#q=grey%20fox) due to the wrong order of color channel. 

However, when it comes to generating ""artistic"" images as in the neural_style_transfer example, it seems that the results caused by the difference are not so different.  I can understand there are probably some reasons behind this,
- 1. The ""content loss"" and ""total variation loss"" defined in the example don't depend on the order of color channels.
- 2. The ""style loss"" might depend on the color orders, because it depends on the difference of ""styles""  in the original and the generated image. And this style is measured by the inner-product distribution of different vgg filters (Gram matrix). However, it should be expected that most of vgg filters will be based on a mix of colors (e.g., edges, corners) rather than a single color alone (e.g, blue color for sea).

Those could be the reasons why I don't see many differences when experimenting with the different color channel encoding in the neural_style_transfer example. _But I really want to know whether we can come up with some contrived cases where the different color channel order will result in a difference for the neural_style_transfer example._

I post this question here because it might lead to a potential bug report to the above example code.
",dolaameng,None,2016-07-28T14:55:08Z,2016-07-29T12:51:56Z
3332,variational auto-encoder input dimension mis-match,"Hi, 

I am using the variational auto encoder described in [http://blog.keras.io/building-autoencoders-in-keras.html](url). 

My input shape is (22664, 678) and I have changed loss to ""categorical_crossentropy"". I am not using the customized loss function(I thought that me be causing the problem). And following are parameters values 

batch_size = 64
original_dim = 678
latent_dim = 2
intermediate_dim = 45
nb_epoch = 5

My input contains value ranging from 0.5 to 21(most of them are 0s). 

The program is giving the following error 

`Input dimension mis-match. (input[0].shape[0] = 8, input[1].shape[0] = 64)
Apply node that caused the error: Elemwise{mul,no_inplace}(Elemwise{Composite{exp((i0 * (i1 + i2)))}}[(0, 1)].0, Reshape{2}.0)
Toposort index: 47
Inputs types: [TensorType(float32, matrix), TensorType(float32, matrix)]
Inputs shapes: [(8, 2), (64, 2)]
Inputs strides: [(8, 4), (8, 4)]
Inputs values: ['not shown', 'not shown']
Outputs clients: [[Gemm{inplace}(Elemwise{mul,no_inplace}.0, TensorConstant{1.0},Elemwise{Composite{(i0 * (Abs(i1) + i2 + i3))}}[(0, 2)].0, dense_47_W, TensorConstant{1.0})]]
HINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.
HINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.`

Can someone please explain the reasons behind this? 
",aironashish,None,2016-07-27T14:55:05Z,2016-07-29T09:34:25Z
3325,Misclassification on small training set with pre-trained word vectors,"I am one of the many users having issues with passing the pre-trained embedding matrix to the Keras Embedding layer. My code currently looks like the following:

``` python
from keras.models import Sequential
from keras.layers import Embedding, LSTM, Dropout, Dense
from keras.preprocessing.sequence import pad_sequences
from keras.utils.np_utils import to_categorical

trainX = [sentence_to_vecidxs(entry[0]) for entry in train_data]
trainY = [entry[1] - 1 for entry in train_data]

testX = [sentence_to_vecidxs(entry[0]) for entry in test_data]
testY = [entry[1] - 1 for entry in test_data]

hidden_units = 100
maxwords = 50 # pad sentences to contain this number of words

# padding sentences
trainX = pad_sequences(trainX, maxlen=maxwords)
testX = pad_sequences(testX, maxlen=maxwords)

# class hot vectors
trainY = to_categorical(trainY, nb_classes=nlabels)
testY = to_categorical(testY, nb_classes=nlabels)

# pre-trained word embeddings of size (vocabulary_size x embedding_size)
W = final_embeedings

model = Sequential()
model.add(Embedding(vocabulary_size, embedding_size, input_length=maxwords, mask_zero=True, weights=[W]))
model.add(LSTM(hidden_units, return_sequences=False))
model.add(Dropout(0.3))
model.add(Dense(nlabels, activation='softmax'))

model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])
model.fit(trainX, trainY, validation_data=(testX, testY), nb_epoch=30, batch_size=16, verbose=2)
```

The first row of the pre-trained matrix `final_embeddings` contains a random vector for the special token 'PAD'. This token is assigned the index 0 in the corpus and I assume that this index has special meaning in the lookup. The second row in this matrix contains a trained vector for the 'UNK' token which is returned whenever a word is not found in the vocabulary ('PAD' != 'UNK').

In the Embedding layer the input_dim is `vocabulary_size`, which is the same number of rows in the `final_embeddings` matrix. The output_dim is `embedding_size`, which is the dimension of the word vectors. The input_length is `maxwords` which is the (fixed) number of words in the padded sentences (padding with 0). The mask_zero argument is set to False because the matrix `final_embeddings` already has a vector assigned in the first row for the 'PAD' token (index 0).

After running this on a very small training set of ~200 labeled sentences (3 labels) the accuracy is around 55% in both training and validation, but the prediction completely fails even on the training set. Almost all sentences therein are labeled the same.

So now it comes the questions:
1. Is it reasonable to use such a small training set to predict labels on sentences given a pre-trained word embeddnig matrix?
2. We have tried **not** passing the pre-trained embedding matrix and it produces the ""same"" results in terms of accuracy and predicted labels. How can we make sure this matrix is being used by the LSTM classifier?
3. Is it necessary to have a zero vector for the 'PAD' token or it can be random like we did?
4. We observe that the accuracy is highly correlated to the proportion of the labels in the training set. Do you think this information can help further debug the issue?
5. Could you add a complete example to the documentation with multiclass classification of sentences given word vectors? It seems that many people are struggling to get it working.

Please let me know if you need anything else in order to help with this issue.
",juliohm,None,2016-07-26T22:53:44Z,2017-12-09T22:43:48Z
3286,gradient computing error when using warp-ctc theano wrapper  as objective function,"Hi everyone, I use [this theano wrapper](https://github.com/mcf06/theano_ctc) for [warp-ctc](https://github.com/baidu-research/warp-ctc) as Keras objective function with a 1 layer lstm RNN, but got following error. My code is attached in the end. Did I make mistakes using this lib? I'm sure it was installed correctly since 2 tests were all passed. I dont know where the problem is and hope someone can help me out. Thanks a lot:D

```
Epoch 1/5
Traceback (most recent call last):
  File ""./lstm_ctc.py"", line 66, in <module>
    model.fit(data, label, nb_epoch = 5, batch_size = batch_size)
  File ""/home/speech/TRAINDATA1/wudan/iris75dev/lib/python2.7/site-packages/Keras-1.0.5-py2.7.egg/keras/models.py"", line 415, in fit
    sample_weight=sample_weight)
  File ""/home/speech/TRAINDATA1/wudan/iris75dev/lib/python2.7/site-packages/Keras-1.0.5-py2.7.egg/keras/engine/training.py"", line 1151, in fit
    callback_metrics=callback_metrics)
  File ""/home/speech/TRAINDATA1/wudan/iris75dev/lib/python2.7/site-packages/Keras-1.0.5-py2.7.egg/keras/engine/training.py"", line 870, in _fit_loop
    outs = f(ins_batch)
  File ""/home/speech/TRAINDATA1/wudan/iris75dev/lib/python2.7/site-packages/Keras-1.0.5-py2.7.egg/keras/backend/theano_backend.py"", line 533, in __call__
    return self.function(*inputs)
  File ""/home/speech/TRAINDATA1/wudan/iris75dev/lib/python2.7/site-packages/Theano-0.9.0.dev1-py2.7.egg/theano/compile/function_module.py"", line 908, in __call__
    storage_map=getattr(self.fn, 'storage_map', None))
  File ""/home/speech/TRAINDATA1/wudan/iris75dev/lib/python2.7/site-packages/Theano-0.9.0.dev1-py2.7.egg/theano/gof/link.py"", line 314, in raise_with_op
    reraise(exc_type, exc_value, exc_trace)
  File ""/home/speech/TRAINDATA1/wudan/iris75dev/lib/python2.7/site-packages/Theano-0.9.0.dev1-py2.7.egg/theano/compile/function_module.py"", line 895, in __call__
    self.fn() if output_subset is None else\
TypeError: expected a CudaNdarray, not None
Apply node that caused the error: GpuDimShuffle{1,0,2}(gpu_ctc_grad)
Toposort index: 171
Inputs types: [CudaNdarrayType(float32, 3D)]
Inputs shapes: ['No shapes']
Inputs strides: ['No strides']
Inputs values: [None]
Outputs clients: [[GpuElemwise{Composite{((-(i0 * i1)) / i2)},no_inplace}(GpuDimShuffle{1,0,2}.0, GpuElemwise{Composite{exp((i0 - i1))}}[(0, 0)].0, GpuElemwise{sqr,no_inplace}.0), GpuElemwise{Composite{(((i0 / i1) + i2) * i3)}}[(0, 0)](GpuDimShuffle{1,0,2}.0, GpuDimShuffle{0,1,x}.0, GpuDimShuffle{0,1,x}.0, GpuElemwise{Composite{exp((i0 - i1))}}[(0, 0)].0)]]

HINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.
HINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.
```

My code 

``` python
#!/usr/bin/env python

from __future__ import print_function
import numpy as np
import keras.backend as K
np.random.seed(1337)

from keras.preprocessing import sequence
from keras.utils import np_utils
from keras.models import Sequential
from keras.layers.core import Dense, Dropout, Activation, Masking
from keras.layers.wrappers import TimeDistributed
from keras.layers.recurrent import LSTM, GRU, SimpleRNN
from keras.layers.normalization import BatchNormalization
from keras.optimizers import SGD, Adam, RMSprop, Adadelta
from keras.callbacks import LearningRateScheduler

gpuid = 1

from theano.sandbox import cuda
cuda.use('gpu{}'.format(gpuid))

# wrapper of ctc_cost
def ctc_cost(y_true, y_pred):
    '''
    CTC cost:
    a theano wrapper for warp-ctc
    Arguments:
        y_true : label
        y_pred : acts
    '''
    from theano_ctc import ctc_cost as warp_ctc_cost

    # convert (batch size, timestep, target) to (timestep, batch size, target)
    acts = K.permute_dimensions(y_pred, (1, 0, 2))
    labels = K.cast(K.squeeze(y_true, axis=2), 'int32')
    return warp_ctc_cost(acts, labels)

batch_size = 16
frame_len = 80
nb_feat = 120
nb_class = 12250
inner_dim = 512
nb_cell = 1024
print(""Building model..."")
model = Sequential()
model.add(LSTM(inner_dim, input_shape = (frame_len, nb_feat), return_sequences = True))
model.add(BatchNormalization())
model.add(TimeDistributed(Dense(nb_class)))
model.add(Activation('softmax'))

model.summary()

# Compiling
opt = SGD(lr = 1e-3, momentum = 0.9, nesterov = True)
model.compile(optimizer = opt, loss = ctc_cost, metrics = ['accuracy'],
              sample_weight_mode = None)

# Generate dummy data
data = np.random.uniform(low = -5, high = 5, size = (batch_size, frame_len, nb_feat))
label = np.random.randint(nb_class, size = (batch_size, frame_len, 1))

# Training
model.fit(data, label, nb_epoch = 5, batch_size = batch_size)
```
",w1d2s,None,2016-07-22T07:45:02Z,2016-07-25T02:57:35Z
3268,"froze layer, but weights still changed","I used trainable to freeze some layers of my model, added some layers and continued training. During training, I found the weights still changed. I'm not sure what happened.

Here are some weights in different epochs. I cut them in debug mode.

---

array([[[[ 0.16177908, -0.09839147, -0.0857864 ]],

```
    [[ 0.10176676,  0.16003887, -0.13533698]],

    [[-0.06665382,  0.05389806,  0.01333128]],
```

---

array([[[[ 0.16171053, -0.09800326, -0.08534878]],

```
    [[ 0.10163011,  0.15987687, -0.13544077]],

    [[-0.06666315,  0.05425047,  0.01373971]],
```

---

array([[[[ 0.16169044, -0.09756043, -0.08492716]],

```
    [[ 0.10153792,  0.15963693, -0.13562557]],

    [[-0.06665007,  0.05445961,  0.01388009]],
```

---

array([[[[ 0.16182417, -0.0971467 , -0.08453723]],

```
    [[ 0.10148849,  0.15936331, -0.13582289]],

    [[-0.06648023,  0.05473858,  0.01407069]],
```
",benwu232,None,2016-07-20T10:07:57Z,2018-01-23T19:38:52Z
3252,Bug fix + test - Sequential.pop(),"Update inbound nodes after popping last layer. Otherwise `output_shape` of the model will not be updated.

``` python
model = Sequential()
model.add(Dense(10, input_dim=10))
model.add(Dense(20))
print model.output_shape  # >> (None, 20)
model.pop()
print model.output_shape  # >> (None, 20) 
```

Also since `pop()` is sort of a hack, I thought it would be good to have a test.
",farizrahman4u,None,2016-07-18T21:14:11Z,2017-03-07T11:53:45Z
3229,"write my layer about Deep NMF, some problems with it","I just want to rewrite the code as a keras layer, the code come from this paper[A Deep Semi-NMF Model for Learning Hidden Representations](http://www.ibug.doc.ic.ac.uk/media/uploads/documents/icml_2014.pdf)

```
from __future__ import print_function
from collections import OrderedDict

import numpy as np
import theano
import theano.tensor as T

from scipy.sparse.linalg import svds

relu = lambda x: 0.5 * (x + abs(x))

def floatX(x):
    return np.asarray(x, dtype=theano.config.floatX)

def appr_seminmf(M, r):
    """"""
        Approximate Semi-NMF factorisation. 

        Parameters
        ----------
        M: array-like, shape=(n_features, n_samples)
        r: number of components to keep during factorisation
    """"""

    if r < 2:
        raise ValueError(""The number of components (r) has to be >=2."")

    A, S, B = svds(M, r-1)
    S = np.diag(S)
    A = np.dot(A, S)

    m, n = M.shape

    for i in range(r-1):
        if B[i, :].min() < (-B[i, :]).min():
            B[i, :] = -B[i, :]
            A[:, i] = -A[:, i]


    if r == 2:
        U = np.concatenate([A, -A], axis=1)
    else:
        An = -np.sum(A, 1).reshape(A.shape[0], 1)
        U = np.concatenate([A, An], 1)

    V = np.concatenate([B, np.zeros((1, n))], 0)

    if r>=3:
        V -= np.minimum(0, B.min(0))
    else:
        V -= np.minimum(0, B)

    return U, V

def adam(loss, params, learning_rate=0.001, beta1=0.9,
         beta2=0.999, epsilon=1e-8):
    """"""Adam updates

    Adam updates implemented as in [1]_.

    Parameters
    ----------
    loss_or_grads : symbolic expression or list of expressions
        A scalar loss expression, or a list of gradient expressions
    params : list of shared variables
        The variables to generate update expressions for
    learning_rate : float
        Learning rate
    beta_1 : float
        Exponential decay rate for the first moment estimates.
    beta_2 : float
        Exponential decay rate for the second moment estimates.
    epsilon : float
        Constant for numerical stability.

    Returns
    -------
    OrderedDict
        A dictionary mapping each parameter to its update expression

    Notes
    -----
    The paper [1]_ includes an additional hyperparameter lambda. This is only
    needed to prove convergence of the algorithm and has no practical use
    (personal communication with the authors), it is therefore omitted here.

    References
    ----------
    .. [1] Kingma, Diederik, and Jimmy Ba (2014):
           Adam: A Method for Stochastic Optimization.
           arXiv preprint arXiv:1412.6980.
    """"""

    all_grads = theano.grad(loss, params)
    t_prev = theano.shared(floatX(0.))
    updates = OrderedDict()

    for param, g_t in zip(params, all_grads):
        m_prev = theano.shared(param.get_value() * 0.)
        v_prev = theano.shared(param.get_value() * 0.)
        t = t_prev + 1
        m_t = beta1*m_prev + (1-beta1)*g_t
        v_t = beta2*v_prev + (1-beta2)*g_t**2
        a_t = learning_rate*T.sqrt(1-beta2**t)/(1-beta1**t)
        step = a_t*m_t/(T.sqrt(v_t) + epsilon)

        updates[m_prev] = m_t
        updates[v_prev] = v_t
        updates[param] = param - step

    updates[t_prev] = t
    return updates


def init_weights(X, num_components, svd_init=True):
    if svd_init:
        return appr_seminmf(X, num_components)

    Z = 0.08 * np.random.rand(X.shape[0], num_components)
    H = 0.08 * np.random.rand(num_components, X.shape[1])

    return Z, H


from theano.sandbox.rng_mrg import MRG_RandomStreams as RandomStreams
rng = RandomStreams()

def dropout(x, p=0):
    if p == 0:
        return x
    else:
        p = 1 - p
        x /= p

        return x * rng.binomial(x.shape, p=p, dtype=theano.config.floatX)


class DSNMF(object):

    def __init__(self, data, layers, verbose=False, l1_norms=[], pretrain=True, learning_rate=1e-3):
        """"""
        Parameters
        ----------
        :param data: array-like, shape=(n_samples, n_features)
        :param layers: list, shape=(n_layers) containing the size of each of the layers
        :param verbose: boolean
        :param l1_norms: list, shape=(n_layers) the l1-weighting of each of the layers
        :param pretrain: pretrain layers using svd
        """"""
        H = data.T

        assert len(layers) > 0, ""You have to provide a positive number of layers.""

        params = []

        for i, l in enumerate(layers, start=1):
            print('Pretraining {}th layer [{}]'.format(i, l), end='\r')

            Z, H = init_weights(H, l, svd_init=pretrain)

            params.append(theano.shared(floatX(Z), name='Z_%d' % (i)))

        params.append(theano.shared(floatX(H), name='H_%d' % len(layers)))

        self.params = params
        self.layers = layers

        cost = ((data.T - self.get_h(-1))**2).sum()

        for norm, param in zip(l1_norms, params):
            cost += ((abs(param)) * norm).sum()

        H = relu(self.params[-1])

        updates = adam(cost, params, learning_rate=learning_rate)

        self.cost = cost
        self.train_fun = theano.function([], cost, updates=updates)
        self.get_features = theano.function([], H)

        self.get_reconstruction = theano.function([], self.get_h(-1))

    def finetune_features(self):

        updates = adam(self.cost, self.params[-1:])
        self.train_fun = theano.function([], self.cost, updates=updates)

    def get_param_values(self):
        return [p.get_value() for p in self.params]

    def set_param_values(self, values):
        params = self.params

        if len(params) != len(values):
            raise ValueError(""mismatch: got %d values to set %d parameters"" %
                            (len(values), len(params)))

        for p, v in zip(params, values):
            if p.get_value().shape[0] != v.shape[0]:
                raise ValueError(""mismatch: parameter has shape %r but value to ""
                             ""set has shape %r"" %
                             (p.get_value().shape, v.shape))
            else:
                p.set_value(v)

    def get_h(self, layer_num, have_dropout=False):
        h = relu(self.params[-1])

        if have_dropout:
            h = dropout(h, p=.1)

        for z in reversed(self.params[1:-1][:]):
            h = relu(z.dot(h))

        if layer_num == -1:
            h = self.params[0].dot(h)

        return h

```

and following code are my code:

```
# -*- coding: utf-8 -*-
# author = sai
from keras import backend as K
from keras.engine.topology import Layer
import numpy as np

def init_weights(X, num_components, i, svd_init=True):
    # if svd_init:
    #     return appr_seminmf(X, num_components)

    Z = K.variable(0.08 * np.random.rand(X.shape[0], num_components), name='z_%d'%(i))
    H = K.variable(0.08 * np.random.rand(num_components, X.shape[1]), name='h_%d'%(i))
    return Z, H

class NMFLayer(Layer):
    def __init__(self, layers, input_dim=None, input_length=None, **kwargs):
        self.output_dim = layers[-1]
        self.layers = layers
        self.input_dim = input_dim
        self.input_length = input_length
        if self.input_dim:
            kwargs['input_shape'] = (self.input_length, self.input_dim)
        super(NMFLayer, self).__init__(**kwargs)

    def build(self, input_shape):
        self.trainable = []
        H = K.variable(value=np.random.rand(input_shape[::-1]))
        for i, l in enumerate(self.layers):
            Z, H = init_weights(H, l, i)
            self.trainable.append(Z)
        self.trainable.append(H)

    def call(self, x, mask=None):
        h = K.relu(self.trainable[-1])
        for z in reversed(self.trainable[1:-1][:]):
            h = K.relu(K.dot(z, h))
        h = K.dot(self.trainable[0], h)
        return h

    def get_output_shape_for(self, input_shape):
        return (input_shape[1], input_shape[0])

def cost(y_true, y_pred):
    return K.sum((y_true.T - y_pred)**2)

def DSNMF(shape):
    inputs = InputLayer(input_shape=shape)
    nmf_layer = NMFLayer(layers=[400, 100])(inputs)
    model = Model(input=inputs, output=nmf_layer)
    model.compile(optimizer=Adam(lr=1e-5), loss=cost, metrics=[cost])
    return model

if __name__=='__main__':
    shape = data.T.shape
    dsnmf = DSNMF(shape)
```

When `DSNMF` is created, there will be a error:

```
Traceback (most recent call last):
  File ""/home/sai/code/papers_code/Deep-Semi-NMF/deep_smi_nmf.py"", line 37, in <module>
    dsnmf = DSNMF(shape)
  File ""/home/sai/code/papers_code/Deep-Semi-NMF/deep_smi_nmf.py"", line 31, in DSNMF
    nmf_layer = NMF_layer.NMFLayer(layers=[400, 100])(inputs)
  File ""/home/sai/anaconda2/lib/python2.7/site-packages/Keras-1.0.5-py2.7.egg/keras/engine/topology.py"", line 452, in __call__
    '"". This layer has no information'
Exception: You tried to call layer ""nmflayer_1"". This layer has no information about its expected input shape, and thus cannot be built. You can build it manually via: `layer.build(batch_input_shape)`

```

I do not know how to process `intput_shape`
",saicoco,None,2016-07-15T01:34:33Z,2016-07-16T06:24:19Z
3218,Masked and non-masked merge bug fix,,pdasigi,None,2016-07-13T20:59:25Z,2016-07-28T00:50:50Z
3195,Calling ProgbarLogger before other callbacks,"As stated in #2354, printing something inside a Callback will break the progress bar logging (verbose=1).

This bug is fixed if I change the callbacks list to call the ProgbarLogger first. The test suite doesn't point out any other bugs with this change, but I'm skeptical.
Someone with more knowledge about Keras could have a better view on this change.
",fredtcaroli,None,2016-07-11T11:33:03Z,2016-07-11T21:28:33Z
3172,Changing input size in cifar10 example,"Hello,

I am attempting to train the exact network in the cifar10 example but with input image sizes of 299x299x3, instead of 32x32x3. I kept the original network the same as the example except for a few changes:
- img_rows, img_cols = 299, 299
- X_train shape: (10000L, 3L, 299L, 299L) #only used 10,000 because only 10,000 could fit on memory

I get an error when running model.fit that goes like this:

""RuntimeError: BaseGpuCorrMM: Failed to allocate output of 32 x 32 x 299 x 299
Apply node that caused the error: GpuCorrMM{half, (1, 1)}(GpuContiguous.0, GpuContiguous.0)
Toposort index: 61
Inputs types: [CudaNdarrayType(float32, 4D), CudaNdarrayType(float32, 4D)]
Inputs shapes: [(32, 3, 299, 299), (32, 3, 3, 3)]
Inputs strides: [(268203, 89401, 299, 1), (27, 9, 3, 1)]
Inputs values: ['not shown', 'not shown']
Outputs clients: [[GpuElemwise{Add}[(0, 0)](GpuCorrMM{half, %281, 1%29}.0, GpuReshape{4}.0)]]

HINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.
HINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.""

As far as I can see, it seems like an issue with the dimensions I gave model.fit. However, I cannot see what else needs to be changed. 

Thank you in advance for any help!
Cheers
",anthonyfuller7,b'stale',2016-07-07T22:00:16Z,2017-06-22T21:11:23Z
3171,ImageDataGenerator save_to_dir changes generated data,"Hello,
I'm trying out Keras and I liked the ImageDatagenerator idea.
However there are still some bugs as far as I can see.

One that I notices was when you save the images to a directory, the generated data gets changed.
`if self.save_to_dir:
            for i in range(current_batch_size):
                img = array_to_img(batch_x[i]`

array_to_img _can_ change batch_x[i](it scales the values)

So a fix might be :
`array_to_img(batch_x[i].copy())`

I hope I did not overlook anything
",juliandewit,b'stale',2016-07-07T20:14:53Z,2017-06-22T21:11:22Z
3168,Training doesn't start when using device=gpu,"My network works properly when I don't use the _device=gpu_ flag. Even with _device=gpu_ , it worked for a couple of times, but then it stopped working. This is how it looks, when it doesn't work:

![gpuproblem](https://cloud.githubusercontent.com/assets/1523786/16659499/f191fe88-4487-11e6-8099-3dcb85fd983b.png)
 As seen above, it just prints Epoch 1/5 and stops. 

Is there any way I can know what's going wrong, debug logs for cuda etc?

I'm using 3D convolutions and I first tried with a small set of examples, and it worked, with gpu. Then I ran a larger set, with _fit_generator_ , and then it gave the above problem. Since then, it has not worked at all, even for the smaller set of examples.

Also, I'm using CUDNN, but Keras prints cuDNN None. What does that mean? Earlier it had printed cuDNN Not availble, and after installing cuDNN it prints ""None"".
",sanjeevmk,None,2016-07-07T15:48:50Z,2018-02-27T14:06:05Z
3146,Dim-Ordering for 1DConv/Pool,"`layer.convolutional.Pooling1D` and `layer.convolutional.Convolution1D` are hard-coded to use theano dimensions (the other 2D/3D operations aren't):

```
self.init = initializations.get(init, dim_ordering='th')
...
output = K.conv2d(x, self.W, strides=self.subsample,
                          border_mode=self.border_mode,
                          dim_ordering='th')
```

Is this a workaround for something or a bug? From a design perspective, I don't think that passing `dim_ordering` to the backend makes any sense. The backend knows whether theano or TF is being used, i.e. the dimensionality should be hardcoded in tensorflow_backed to support tensorflow and in theano_backend to support theano (by directly calling e.g. `K.image_dim_ordering`). I don't see a reasonable scenario where one would ever use Tensorflow but want Theano dimension ordering as the default.
",talpay,b'stale',2016-07-05T09:05:28Z,2017-06-22T22:14:15Z
3142,fix docs bugs,"Fix #3141
",EderSantana,None,2016-07-04T17:51:54Z,2016-07-04T18:02:47Z
3141,A tiny bug in http://keras.io/backend/#batch_dot,"In `example` section of http://keras.io/backend/#batch_dot, it reads:

Assume x = [[1, 2] and y = [[5, 6] [3, 4]] [7, 8]] batch_dot(x, y, axes=1) = [[17, 53]] ...

It confused me for a while and later I refer to the comment of source (https://github.com/fchollet/keras/blob/master/keras/backend/theano_backend.py, L130), 
and it should look like:

```
Assume x = [[1, 2]   and y = [[5, 6]
            [3, 4]]          [7, 8]]
```

I think mkdocs just views it as two lines and then combine them into a single line, so matrix should be written in a single line. 
May you fix it and notice other potential bugs like this. Thanks.
",suquark,None,2016-07-04T17:39:24Z,2016-07-30T03:27:25Z
3137,LocallyConnected layer only working on cpu,"Hi,

I'm trying to use the recently added local layers (keras/keras/layers/local.py). Training the exact same network with the same script works on cpu but not on gpu (CUDA, with or without CuDNN). I'm using Theano backend. I had no problems with gpu before. I suppose the problem lies in the local layers implementation.

Issue script:

```
import numpy.random as random

from keras.models import Sequential
import keras.layers as layers
from keras.optimizers import SGD


model = Sequential()

model.add(layers.ZeroPadding2D(padding=(1, 1),input_shape = (1,10,14))) 
model.add(layers.LocallyConnected2D(2,3,3,activation = 'relu',border_mode = 'valid'))

model.add(layers.Flatten())
model.add(layers.Dense(1, activation = 'sigmoid'))

model.compile(optimizer = SGD(lr = 0.001, momentum = 0.1, decay = 0.0), loss = 'binary_crossentropy', metrics = ['accuracy'])
model.summary()

model.fit(random.rand(10,1,10,14),random.rand(10,1), batch_size = 1,nb_epoch = 5)
```

**with cpu:**

```
Using Theano backend.
____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
zeropadding2d_1 (ZeroPadding2D)  (None, 1, 12, 16)     0           zeropadding2d_input_1[0][0]      
____________________________________________________________________________________________________
locallyconnected2d_1 (LocallyConn(None, 2, 10, 14)     2800        zeropadding2d_1[0][0]            
____________________________________________________________________________________________________
flatten_1 (Flatten)              (None, 280)           0           locallyconnected2d_1[0][0]       
____________________________________________________________________________________________________
dense_1 (Dense)                  (None, 1)             281         flatten_1[0][0]                  
====================================================================================================
Total params: 3081
____________________________________________________________________________________________________
Epoch 1/5
10/10 [==============================] - 0s - loss: 0.6649 - acc: 0.0000e+00     
Epoch 2/5
10/10 [==============================] - 0s - loss: 0.6631 - acc: 0.0000e+00     
Epoch 3/5
10/10 [==============================] - 0s - loss: 0.6613 - acc: 0.0000e+00     
Epoch 4/5
10/10 [==============================] - 0s - loss: 0.6598 - acc: 0.0000e+00     
Epoch 5/5
10/10 [==============================] - 0s - loss: 0.6582 - acc: 0.0000e+00  
```

**with gpu:**

```
Traceback (most recent call last):

  File ""<ipython-input-3-da4ca203c2ba>"", line 1, in <module>
    runfile('*/test_issue.py', wdir='*')

  File ""C:\Users\sicarbonnell\AppData\Local\Continuum\Anaconda3\envs\python34\lib\site-packages\spyderlib\widgets\externalshell\sitecustomize.py"", line 714, in runfile
    execfile(filename, namespace)

  File ""C:\Users\sicarbonnell\AppData\Local\Continuum\Anaconda3\envs\python34\lib\site-packages\spyderlib\widgets\externalshell\sitecustomize.py"", line 89, in execfile
    exec(compile(f.read(), filename, 'exec'), namespace)

  File ""E:/Simon/Documents/Projets Data Science/Ultrasound Nerve Segmentation- Kaggle/test_issue.py"", line 25, in <module>
    model.fit(random.rand(10,1,10,14),random.rand(10,1), batch_size = 1,nb_epoch = 5)

  File ""C:\Users\sicarbonnell\AppData\Local\Continuum\Anaconda3\envs\python34\lib\site-packages\keras\models.py"", line 413, in fit
    sample_weight=sample_weight)

  File ""C:\Users\sicarbonnell\AppData\Local\Continuum\Anaconda3\envs\python34\lib\site-packages\keras\engine\training.py"", line 1081, in fit
    self._make_train_function()

  File ""C:\Users\sicarbonnell\AppData\Local\Continuum\Anaconda3\envs\python34\lib\site-packages\keras\engine\training.py"", line 705, in _make_train_function
    **self._function_kwargs)

  File ""C:\Users\sicarbonnell\AppData\Local\Continuum\Anaconda3\envs\python34\lib\site-packages\keras\backend\theano_backend.py"", line 541, in function
    return Function(inputs, outputs, updates=updates, **kwargs)

  File ""C:\Users\sicarbonnell\AppData\Local\Continuum\Anaconda3\envs\python34\lib\site-packages\keras\backend\theano_backend.py"", line 527, in __init__
    **kwargs)

  File ""C:\Users\sicarbonnell\AppData\Local\Continuum\Anaconda3\envs\python34\lib\site-packages\theano\compile\function.py"", line 322, in function
    output_keys=output_keys)

  File ""C:\Users\sicarbonnell\AppData\Local\Continuum\Anaconda3\envs\python34\lib\site-packages\theano\compile\pfunc.py"", line 480, in pfunc
    output_keys=output_keys)

  File ""C:\Users\sicarbonnell\AppData\Local\Continuum\Anaconda3\envs\python34\lib\site-packages\theano\compile\function_module.py"", line 1784, in orig_function
    defaults)

  File ""C:\Users\sicarbonnell\AppData\Local\Continuum\Anaconda3\envs\python34\lib\site-packages\theano\compile\function_module.py"", line 1648, in create
    input_storage=input_storage_lists, storage_map=storage_map)

  File ""C:\Users\sicarbonnell\AppData\Local\Continuum\Anaconda3\envs\python34\lib\site-packages\theano\gof\link.py"", line 699, in make_thunk
    storage_map=storage_map)[:3]

  File ""C:\Users\sicarbonnell\AppData\Local\Continuum\Anaconda3\envs\python34\lib\site-packages\theano\gof\vm.py"", line 1042, in make_all
    no_recycling))

  File ""C:\Users\sicarbonnell\AppData\Local\Continuum\Anaconda3\envs\python34\lib\site-packages\theano\sandbox\cuda\__init__.py"", line 256, in make_thunk
    compute_map, no_recycling)

  File ""C:\Users\sicarbonnell\AppData\Local\Continuum\Anaconda3\envs\python34\lib\site-packages\theano\gof\op.py"", line 975, in make_thunk
    no_recycling)

  File ""C:\Users\sicarbonnell\AppData\Local\Continuum\Anaconda3\envs\python34\lib\site-packages\theano\gof\op.py"", line 875, in make_c_thunk
    output_storage=node_output_storage)

  File ""C:\Users\sicarbonnell\AppData\Local\Continuum\Anaconda3\envs\python34\lib\site-packages\theano\gof\cc.py"", line 1189, in make_thunk
    keep_lock=keep_lock)

  File ""C:\Users\sicarbonnell\AppData\Local\Continuum\Anaconda3\envs\python34\lib\site-packages\theano\gof\cc.py"", line 1130, in __compile__
    keep_lock=keep_lock)

  File ""C:\Users\sicarbonnell\AppData\Local\Continuum\Anaconda3\envs\python34\lib\site-packages\theano\gof\cc.py"", line 1585, in cthunk_factory
    key=key, lnk=self, keep_lock=keep_lock)

  File ""C:\Users\sicarbonnell\AppData\Local\Continuum\Anaconda3\envs\python34\lib\site-packages\theano\gof\cmodule.py"", line 1145, in module_from_key
    module = lnk.compile_cmodule(location)

  File ""C:\Users\sicarbonnell\AppData\Local\Continuum\Anaconda3\envs\python34\lib\site-packages\theano\gof\cc.py"", line 1491, in compile_cmodule
    preargs=preargs)

  File ""C:\Users\sicarbonnell\AppData\Local\Continuum\Anaconda3\envs\python34\lib\site-packages\theano\sandbox\cuda\nvcc_compiler.py"", line 403, in compile_str
    'for cmd', ' '.join(cmd))

Exception: ('The following error happened while compiling the node', GpuJoin(TensorConstant{0}, Rebroadcast{1}.0, Rebroadcast{1}.0, Rebroadcast{1}.0, Rebroadcast{1}.0, Rebroadcast{1}.0, Rebroadcast{1}.0, Rebroadcast{1}.0, Rebroadcast{1}.0, Rebroadcast{1}.0, Rebroadcast{1}.0, Rebroadcast{1}.0, Rebroadcast{1}.0, Rebroadcast{1}.0, Rebroadcast{1}.0, Rebroadcast{1}.0, Rebroadcast{1}.0, Rebroadcast{1}.0, Rebroadcast{1}.0, Rebroadcast{1}.0, Rebroadcast{1}.0, Rebroadcast{1}.0, Rebroadcast{1}.0, Rebroadcast{1}.0, Rebroadcast{1}.0, Rebroadcast{1}.0, Rebroadcast{1}.0, Rebroadcast{1}.0, Rebroadcast{1}.0, Rebroadcast{1}.0, Rebroadcast{1}.0, Rebroadcast{1}.0, Rebroadcast{1}.0, Rebroadcast{1}.0, Rebroadcast{1}.0, Rebroadcast{1}.0, Rebroadcast{1}.0, Rebroadcast{1}.0, Rebroadcast{1}.0, Rebroadcast{1}.0, Rebroadcast{1}.0, Rebroadcast{1}.0, Rebroadcast{1}.0, Rebroadcast{1}.0, Rebroadcast{1}.0, Rebroadcast{1}.0, Rebroadcast{1}.0, Rebroadcast{1}.0, Rebroadcast{1}.0, Rebroadcast{1}.0, Rebroadcast{1}.0, Rebroadcast{1}.0, Rebroadcast{1}.0, Rebroadcast{1}.0, Rebroadcast{1}.0, Rebroadcast{1}.0, Rebroadcast{1}.0, Rebroadcast{1}.0, Rebroadcast{1}.0, Rebroadcast{1}.0, Rebroadcast{1}.0, Rebroadcast{1}.0, Rebroadcast{1}.0, Rebroadcast{1}.0, Rebroadcast{1}.0, Rebroadcast{1}.0, Rebroadcast{1}.0, Rebroadcast{1}.0, Rebroadcast{1}.0, Rebroadcast{1}.0, Rebroadcast{1}.0, Rebroadcast{1}.0, Rebroadcast{1}.0, Rebroadcast{1}.0, Rebroadcast{1}.0, Rebroadcast{1}.0, Rebroadcast{1}.0, Rebroadcast{1}.0, Rebroadcast{1}.0, Rebroadcast{1}.0, Rebroadcast{1}.0, Rebroadcast{1}.0, Rebroadcast{1}.0, Rebroadcast{1}.0, Rebroadcast{1}.0, Rebroadcast{1}.0, Rebroadcast{1}.0, Rebroadcast{1}.0, Rebroadcast{1}.0, Rebroadcast{1}.0, Rebroadcast{1}.0, Rebroadcast{1}.0, Rebroadcast{1}.0, Rebroadcast{1}.0, Rebroadcast{1}.0, Rebroadcast{1}.0, Rebroadcast{1}.0, Rebroadcast{1}.0, Rebroadcast{1}.0, Rebroadcast{1}.0, Rebroadcast{1}.0, Rebroadcast{1}.0, Rebroadcast{1}.0, Rebroadcast{1}.0, Rebroadcast{1}.0, Rebroadcast{1}.0, Rebroadcast{1}.0, Rebroadcast{1}.0, Rebroadcast{1}.0, Rebroadcast{1}.0, Rebroadcast{1}.0, Rebroadcast{1}.0, Rebroadcast{1}.0, Rebroadcast{1}.0, Rebroadcast{1}.0, Rebroadcast{1}.0, Rebroadcast{1}.0, Rebroadcast{1}.0, Rebroadcast{1}.0, Rebroadcast{1}.0, Rebroadcast{1}.0, Rebroadcast{1}.0, Rebroadcast{1}.0, Rebroadcast{1}.0, Rebroadcast{1}.0, Rebroadcast{1}.0, Rebroadcast{1}.0, Rebroadcast{1}.0, Rebroadcast{1}.0, Rebroadcast{1}.0, Rebroadcast{1}.0, Rebroadcast{1}.0, Rebroadcast{1}.0, Rebroadcast{1}.0, Rebroadcast{1}.0, Rebroadcast{1}.0, Rebroadcast{1}.0, Rebroadcast{1}.0, Rebroadcast{1}.0, Rebroadcast{1}.0, Rebroadcast{1}.0), '\n', 'nvcc return status', 2, 'for cmd', 'nvcc -shared -O3 -arch=sm_50 -Xlinker /DEBUG -D HAVE_ROUND -m64 -Xcompiler -DCUDA_NDARRAY_CUH=m18715462c72ed6afcd7ca5d52813ce90,-DNPY_NO_DEPRECATED_API=NPY_1_7_API_VERSION,/Zi,/MD -IC:\\Users\\sicarbonnell\\AppData\\Local\\Theano\\compiledir_Windows-7-6.1.7601-SP1-Intel64_Family_6_Model_61_Stepping_4_GenuineIntel-3.4.4-64\\cuda_ndarray -IC:\\Users\\sicarbonnell\\AppData\\Local\\Continuum\\Anaconda3\\envs\\python34\\lib\\site-packages\\numpy\\core\\include -IC:\\Users\\sicarbonnell\\AppData\\Local\\Continuum\\Anaconda3\\envs\\python34\\include -IC:\\Users\\sicarbonnell\\AppData\\Local\\Continuum\\Anaconda3\\envs\\python34\\lib\\site-packages\\theano\\gof -IC:\\Users\\sicarbonnell\\AppData\\Local\\Continuum\\Anaconda3\\envs\\python34\\lib\\site-packages\\theano\\sandbox\\cuda -o C:\\Users\\sicarbonnell\\AppData\\Local\\Theano\\compiledir_Windows-7-6.1.7601-SP1-Intel64_Family_6_Model_61_Stepping_4_GenuineIntel-3.4.4-64\\tmpkc7vegoz\\mac87adaa1b92aafdf1d5bd49bc08bc35.pyd mod.cu -LC:\\Users\\sicarbonnell\\AppData\\Local\\Theano\\compiledir_Windows-7-6.1.7601-SP1-Intel64_Family_6_Model_61_Stepping_4_GenuineIntel-3.4.4-64\\cuda_ndarray -LC:\\Users\\sicarbonnell\\AppData\\Local\\Continuum\\Anaconda3\\envs\\python34\\libs -LC:\\Users\\sicarbonnell\\AppData\\Local\\Continuum\\Anaconda3\\envs\\python34 -lcudart -lcublas -lcuda_ndarray -lpython34', '[GpuJoin(TensorConstant{0}, <CudaNdarrayType(float32, (True, False, False))>, <CudaNdarrayType(float32, (True, False, False))>, <CudaNdarrayType(float32, (True, False, False))>, <CudaNdarrayType(float32, (True, False, False))>, <CudaNdarrayType(float32, (True, False, False))>, <CudaNdarrayType(float32, (True, False, False))>, <CudaNdarrayType(float32, (True, False, False))>, <CudaNdarrayType(float32, (True, False, False))>, <CudaNdarrayType(float32, (True, False, False))>, <CudaNdarrayType(float32, (True, False, False))>, <CudaNdarrayType(float32, (True, False, False))>, <CudaNdarrayType(float32, (True, False, False))>, <CudaNdarrayType(float32, (True, False, False))>, <CudaNdarrayType(float32, (True, False, False))>, <CudaNdarrayType(float32, (True, False, False))>, <CudaNdarrayType(float32, (True, False, False))>, <CudaNdarrayType(float32, (True, False, False))>, <CudaNdarrayType(float32, (True, False, False))>, <CudaNdarrayType(float32, (True, False, False))>, <CudaNdarrayType(float32, (True, False, False))>, <CudaNdarrayType(float32, (True, False, False))>, <CudaNdarrayType(float32, (True, False, False))>, <CudaNdarrayType(float32, (True, False, False))>, <CudaNdarrayType(float32, (True, False, False))>, <CudaNdarrayType(float32, (True, False, False))>, <CudaNdarrayType(float32, (True, False, False))>, <CudaNdarrayType(float32, (True, False, False))>, <CudaNdarrayType(float32, (True, False, False))>, <CudaNdarrayType(float32, (True, False, False))>, <CudaNdarrayType(float32, (True, False, False))>, <CudaNdarrayType(float32, (True, False, False))>, <CudaNdarrayType(float32, (True, False, False))>, <CudaNdarrayType(float32, (True, False, False))>, <CudaNdarrayType(float32, (True, False, False))>, <CudaNdarrayType(float32, (True, False, False))>, <CudaNdarrayType(float32, (True, False, False))>, <CudaNdarrayType(float32, (True, False, False))>, <CudaNdarrayType(float32, (True, False, False))>, <CudaNdarrayType(float32, (True, False, False))>, <CudaNdarrayType(float32, (True, False, False))>, <CudaNdarrayType(float32, (True, False, False))>, <CudaNdarrayType(float32, (True, False, False))>, <CudaNdarrayType(float32, (True, False, False))>, <CudaNdarrayType(float32, (True, False, False))>, <CudaNdarrayType(float32, (True, False, False))>, <CudaNdarrayType(float32, (True, False, False))>, <CudaNdarrayType(float32, (True, False, False))>, <CudaNdarrayType(float32, (True, False, False))>, <CudaNdarrayType(float32, (True, False, False))>, <CudaNdarrayType(float32, (True, False, False))>, <CudaNdarrayType(float32, (True, False, False))>, <CudaNdarrayType(float32, (True, False, False))>, <CudaNdarrayType(float32, (True, False, False))>, <CudaNdarrayType(float32, (True, False, False))>, <CudaNdarrayType(float32, (True, False, False))>, <CudaNdarrayType(float32, (True, False, False))>, <CudaNdarrayType(float32, (True, False, False))>, <CudaNdarrayType(float32, (True, False, False))>, <CudaNdarrayType(float32, (True, False, False))>, <CudaNdarrayType(float32, (True, False, False))>, <CudaNdarrayType(float32, (True, False, False))>, <CudaNdarrayType(float32, (True, False, False))>, <CudaNdarrayType(float32, (True, False, False))>, <CudaNdarrayType(float32, (True, False, False))>, <CudaNdarrayType(float32, (True, False, False))>, <CudaNdarrayType(float32, (True, False, False))>, <CudaNdarrayType(float32, (True, False, False))>, <CudaNdarrayType(float32, (True, False, False))>, <CudaNdarrayType(float32, (True, False, False))>, <CudaNdarrayType(float32, (True, False, False))>, <CudaNdarrayType(float32, (True, False, False))>, <CudaNdarrayType(float32, (True, False, False))>, <CudaNdarrayType(float32, (True, False, False))>, <CudaNdarrayType(float32, (True, False, False))>, <CudaNdarrayType(float32, (True, False, False))>, <CudaNdarrayType(float32, (True, False, False))>, <CudaNdarrayType(float32, (True, False, False))>, <CudaNdarrayType(float32, (True, False, False))>, <CudaNdarrayType(float32, (True, False, False))>, <CudaNdarrayType(float32, (True, False, False))>, <CudaNdarrayType(float32, (True, False, False))>, <CudaNdarrayType(float32, (True, False, False))>, <CudaNdarrayType(float32, (True, False, False))>, <CudaNdarrayType(float32, (True, False, False))>, <CudaNdarrayType(float32, (True, False, False))>, <CudaNdarrayType(float32, (True, False, False))>, <CudaNdarrayType(float32, (True, False, False))>, <CudaNdarrayType(float32, (True, False, False))>, <CudaNdarrayType(float32, (True, False, False))>, <CudaNdarrayType(float32, (True, False, False))>, <CudaNdarrayType(float32, (True, False, False))>, <CudaNdarrayType(float32, (True, False, False))>, <CudaNdarrayType(float32, (True, False, False))>, <CudaNdarrayType(float32, (True, False, False))>, <CudaNdarrayType(float32, (True, False, False))>, <CudaNdarrayType(float32, (True, False, False))>, <CudaNdarrayType(float32, (True, False, False))>, <CudaNdarrayType(float32, (True, False, False))>, <CudaNdarrayType(float32, (True, False, False))>, <CudaNdarrayType(float32, (True, False, False))>, <CudaNdarrayType(float32, (True, False, False))>, <CudaNdarrayType(float32, (True, False, False))>, <CudaNdarrayType(float32, (True, False, False))>, <CudaNdarrayType(float32, (True, False, False))>, <CudaNdarrayType(float32, (True, False, False))>, <CudaNdarrayType(float32, (True, False, False))>, <CudaNdarrayType(float32, (True, False, False))>, <CudaNdarrayType(float32, (True, False, False))>, <CudaNdarrayType(float32, (True, False, False))>, <CudaNdarrayType(float32, (True, False, False))>, <CudaNdarrayType(float32, (True, False, False))>, <CudaNdarrayType(float32, (True, False, False))>, <CudaNdarrayType(float32, (True, False, False))>, <CudaNdarrayType(float32, (True, False, False))>, <CudaNdarrayType(float32, (True, False, False))>, <CudaNdarrayType(float32, (True, False, False))>, <CudaNdarrayType(float32, (True, False, False))>, <CudaNdarrayType(float32, (True, False, False))>, <CudaNdarrayType(float32, (True, False, False))>, <CudaNdarrayType(float32, (True, False, False))>, <CudaNdarrayType(float32, (True, False, False))>, <CudaNdarrayType(float32, (True, False, False))>, <CudaNdarrayType(float32, (True, False, False))>, <CudaNdarrayType(float32, (True, False, False))>, <CudaNdarrayType(float32, (True, False, False))>, <CudaNdarrayType(float32, (True, False, False))>, <CudaNdarrayType(float32, (True, False, False))>, <CudaNdarrayType(float32, (True, False, False))>, <CudaNdarrayType(float32, (True, False, False))>, <CudaNdarrayType(float32, (True, False, False))>, <CudaNdarrayType(float32, (True, False, False))>, <CudaNdarrayType(float32, (True, False, False))>, <CudaNdarrayType(float32, (True, False, False))>, <CudaNdarrayType(float32, (True, False, False))>, <CudaNdarrayType(float32, (True, False, False))>, <CudaNdarrayType(float32, (True, False, False))>, <CudaNdarrayType(float32, (True, False, False))>, <CudaNdarrayType(float32, (True, False, False))>, <CudaNdarrayType(float32, (True, False, False))>, <CudaNdarrayType(float32, (True, False, False))>)]')
```

Looking forward for your help.

Simon
",Simoncarbo,None,2016-07-04T12:25:01Z,2017-05-19T07:55:58Z
3099,"Fixes #2110 ""ValueError: I/O operation on closed file""","This is a workaround for #2110 where calling `model.fit` with `verbose=1` using IPython can intermittently raise ""ValueError: I/O operation on closed file"".

This exception appears to be caused by an unknown IO bug with IPython that is raised when updating the `ProgbarLogger` progress bar. To workaround this bug and prevent users from unexpectedly losing their model:
- The minimum progress bar refresh interval is now 0.1 seconds (up from 0.01 seconds).
- Progress bar updates are now wrapped in `try/catch` blocks that ignore `ValueError` exceptions raised when calling `progbar.update`

An ideal solution would resolve the IPython at the source, however, this is an important workaround for users who want to use IPython with `verbose=1`.
",scottlawsonbc,None,2016-06-28T23:24:18Z,2016-08-29T19:44:22Z
3097,Layer shape error with autoencoder,"I'm experimenting with the convolutional autoencoder demo from the blog post but I'm getting some odd shape errors. My input data are (nSamples, 1, 512, 1). 

The model structure is:

```
input_img = Input(shape=(1, 512, 1))

x = Convolution2D(32, 3, 1, activation='relu', border_mode='same')(input_img)
x = MaxPooling2D((2,1), border_mode='same')(x)
x = Convolution2D(32, 3, 1, activation='relu', border_mode='same')(x)
encoded = MaxPooling2D((2,1), border_mode='same')(x)


x = Convolution2D(32, 3, 1, activation='relu', border_mode='same')(encoded)
x = UpSampling2D((2,1))(x)
x = Convolution2D(32,3,1, activation='relu', border_mode='same')(x)
x = UpSampling2D((2,1))(x)
decoded = Convolution2D(1, 3,1, activation='sigmoid', border_mode='same')(x)

autoencoder = Model(input_img, decoded)
```

```
autoencoder.summary()
____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
input_14 (InputLayer)            (None, 1, 512, 1)     0                                            
____________________________________________________________________________________________________
convolution2d_50 (Convolution2D) (None, 32, 512, 1)    128         input_14[0][0]                   
____________________________________________________________________________________________________
maxpooling2d_19 (MaxPooling2D)   (None, 32, 256, 1)    0           convolution2d_50[0][0]           
____________________________________________________________________________________________________
convolution2d_51 (Convolution2D) (None, 32, 256, 1)    3104        maxpooling2d_19[0][0]            
____________________________________________________________________________________________________
maxpooling2d_20 (MaxPooling2D)   (None, 32, 128, 1)    0           convolution2d_51[0][0]           
____________________________________________________________________________________________________
convolution2d_52 (Convolution2D) (None, 32, 128, 1)    3104        maxpooling2d_20[0][0]            
____________________________________________________________________________________________________
upsampling2d_19 (UpSampling2D)   (None, 32, 256, 1)    0           convolution2d_52[0][0]           
____________________________________________________________________________________________________
convolution2d_53 (Convolution2D) (None, 32, 256, 1)    3104        upsampling2d_19[0][0]            
____________________________________________________________________________________________________
upsampling2d_20 (UpSampling2D)   (None, 32, 512, 1)    0           convolution2d_53[0][0]           
____________________________________________________________________________________________________
convolution2d_54 (Convolution2D) (None, 1, 512, 1)     97          upsampling2d_20[0][0]            
====================================================================================================
Total params: 9537
____________________________________________________________________________________________________


```

However, I'm getting the following error, which suggests that the nb_col dimension is somehow becoming -1 in the network. I'm not sure how that's happening, as the structure above looks correct to me. Anyone have any ideas?

```
AssertionError: Can't store in size_t for the bytes requested 18446744073709551615 * 4
Apply node that caused the error: GpuAlloc{memset_0=True}(CudaNdarrayConstant{[[[[ 0.]]]]}, Shape_i{0}.0, TensorConstant{32}, Elemwise{Composite{((i0 + i1) // i0)}}[(0, 1)].0, Elemwise{add,no_inplace}.0)
Toposort index: 94
Inputs types: [CudaNdarrayType(float32, (True, True, True, True)), TensorType(int64, scalar), TensorType(int64, scalar), TensorType(int64, scalar), TensorType(int64, scalar)]
Inputs shapes: [(1, 1, 1, 1), (), (), (), ()]
Inputs strides: [(0, 0, 0, 0), (), (), (), ()]
Inputs values: [CudaNdarray([[[[ 0.]]]]), array(64L, dtype=int64), array(32L, dtype=int64), array(257L, dtype=int64), array(-1L, dtype=int64)]
Outputs clients: [[GpuIncSubtensor{InplaceInc;::, ::, :int64:, :int64:}(GpuAlloc{memset_0=True}.0, GpuDnnConvGradI{algo='time_once', inplace=True}.0, ScalarFromTensor.0, ScalarFromTensor.0)]]

HINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.
HINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node. 
```

Please make sure that the boxes below are checked before you submit your issue. Thank you!
- [x] Check that you are up-to-date with the master branch of Keras. You can update with:
  pip install git+git://github.com/fchollet/keras.git --upgrade --no-deps
- [x] If running on Theano, check that you are up-to-date with the master branch of Theano. You can update with:
  pip install git+git://github.com/Theano/Theano.git --upgrade --no-deps
- [x] Provide a link to a GitHub Gist of a Python script that can reproduce your issue (or just copy the script here if it is short).
",jacobzweig,b'stale',2016-06-28T15:43:40Z,2017-06-22T22:11:49Z
3089,passing a fixed matrix into the custom loss,"For a given data $X \in N*M$ (N is the data size, M is the input dim), the reconstruction of autoencoder and the corresponding representation (the output of encoder) are $Y$ and $H$. I hope to enforce some constraints on $H$, and my loss function is: 

$(X-Y)^{2} + lambda*(H-CH)^{2}$, where C is a pre-defined matrix. My code is as follows:

X = Input(shape=(784,), name='X')
H = Dense(10, activation='tank')(X)
Y = Dense(784, activation='tanh')(H)
model = Model(input=X, output=Y)
model.compile(optimizer='sgd', loss=my_loss(C, H, 0.2)) #  C is the given matrix, whose shape is N*N, where N is the size of X.
model.fit(X, X, nb_epoch=100, batch_size=32)
# the custom loss function

def my_loss(C, H, lmd): #  C is given, whose shape is N*N, where N is the size of X.
    global_loss = K.mean(K.square(encoded - K.dot(C, encoded)), axis=-1)
    def loss(y_true, y_pred):
        local_loss = K.mean(K.square(y_true - y_pred), axis=-1)
        return local_loss + lmd \* global_loss
    return loss
## I got the following errors:

AssertionError: Theano Assert failed!
Apply node that caused the error: Assert{msg='Theano Assert failed!'}(Elemwise{Composite{(i0 \* (Abs(i1) + i2 + i3))}}[(0, 2)].0, Elemwise{eq,no_inplace}.0)
Toposort index: 46
Inputs types: [TensorType(float32, matrix), TensorType(int8, scalar)]
Inputs shapes: [(32, 10), ()]
Inputs strides: [(40, 4), ()]
Inputs values: ['not shown', array(0, dtype=int8)]
Outputs clients: [[Elemwise{sub,no_inplace}(Assert{msg='Theano Assert failed!'}.0, InplaceDimShuffle{x,x}.0)]]

HINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.
## HINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.

I guess that the obtained error may result from passing the fix-sized matrix C into my loss. Anybody can kindly help me to solve this issue? Thank you very much. 
",pengx-scu,b'stale',2016-06-28T07:44:36Z,2017-06-22T22:11:48Z
3088,Order of weights in LSTM,"I'm trying to export an LSTM layer from Keras to a portable C implementation.  I accept the possibility there is a bug in my code, but assuming there isn't, I can't figure out the order of the weights / gates in the LSTM layer.

`model = Sequential()`
`model.add(LSTM(4,input_dim=5,input_length=N,return_sequences=True))`
`shapes = [x.shape for x in model.get_weights()]`
`print shapes`

[(5, 4),
 (4, 4),
 (4,),
 (5, 4),
 (4, 4),
 (4,),
 (5, 4),
 (4, 4),
 (4,),
 (5, 4),
 (4, 4),
 (4,)]

What I see is 
- Weights that handle inputs
- Weights that handle recurrent / hidden outputs
- bias
- repeat

But which weight set goes to which gate?  The third set of weights have biases initialized to 1.0, so I'm assuming that's the forget gates.

Looking in recurrent.py, I see something like this:
            i = self.inner_activation(z0)
            f = self.inner_activation(z1)
            c = f \* c_tm1 + i \* self.activation(z2)
            o = self.inner_activation(z3)

But i,f,c,o is not the order, because of the biases set to 1.0.  So I'm kind of confused, and would appreciate the help.
",bennythedataguy,b'stale',2016-06-28T06:27:13Z,2018-07-23T17:45:04Z
3084,fit_generator used with two generators calling the same keras model,"I am using the function fit_generator with different generators for training and testing. These generators, albeit different, are calling the same Keras model. 

Here is a minimal example (the code is useless as both train and test generators are the same) 

``` python
import numpy as np

from keras.layers.core import Masking, Dense, TimeDistributedDense

from keras.layers.recurrent import GRU
from keras.models import Sequential

model = Sequential()
model.add(Masking(mask_value = 0.0, input_shape = (10,2)))
model.add(GRU(2, consume_less = 'gpu', return_sequences = False))
model.add(Dense(2, activation = 'softmax'))
model.summary()

modelBis = Sequential()
modelBis.add(Masking(mask_value = 0.0, input_shape = (10,2)))
modelBis.add(GRU(2, consume_less = 'gpu', return_sequences = True))
modelBis.add(TimeDistributedDense(2))

y = np.asarray([[0,1] for i in range(10)])
def generatorTrain():
    while 1:
        x = np.random.rand(10,10,2)
        prediction = modelBis.predict(x)
        yield prediction, y

def generatorTest():
    while 1:
        x = np.random.rand(10,10,2)
        prediction = modelBis.predict(x)
        yield prediction, y

genTrain = generatorTrain()
genTest = generatorTest()

model.compile('sgd','mse')
model.fit_generator(genTrain, 100, 10, validation_data = genTest, nb_val_samples=100)
```

After a few epochs, this gives rise to the following error.

```
Exception in thread Thread-8:
Traceback (most recent call last):
  File ""/usr/lib/python2.7/threading.py"", line 801, in __bootstrap_inner
    self.run()
  File ""/usr/lib/python2.7/threading.py"", line 754, in run
    self.__target(*self.__args, **self.__kwargs)
  File ""/usr/local/lib/python2.7/dist-packages/keras/engine/training.py"", line 404, in data_generator_task
    generator_output = next(generator)
  File ""<stdin>"", line 4, in generatorTest
  File ""/usr/local/lib/python2.7/dist-packages/keras/models.py"", line 459, in predict
    return self.model.predict(x, batch_size=batch_size, verbose=verbose)
  File ""/usr/local/lib/python2.7/dist-packages/keras/engine/training.py"", line 1126, in predict
    batch_size=batch_size, verbose=verbose)
  File ""/usr/local/lib/python2.7/dist-packages/keras/engine/training.py"", line 846, in _predict_loop
    batch_outs = f(ins_batch)
  File ""/usr/local/lib/python2.7/dist-packages/keras/backend/theano_backend.py"", line 518, in __call__
    return self.function(*inputs)
  File ""/usr/local/lib/python2.7/dist-packages/theano/compile/function_module.py"", line 871, in __call__
    storage_map=getattr(self.fn, 'storage_map', None))
  File ""/usr/local/lib/python2.7/dist-packages/theano/gof/link.py"", line 314, in raise_with_op
    reraise(exc_type, exc_value, exc_trace)
  File ""/usr/local/lib/python2.7/dist-packages/theano/compile/function_module.py"", line 859, in __call__
    outputs = self.fn()
  File ""/usr/local/lib/python2.7/dist-packages/theano/scan_module/scan_op.py"", line 951, in rval
    r = p(n, [x[0] for x in i], o)
  File ""/usr/local/lib/python2.7/dist-packages/theano/scan_module/scan_op.py"", line 940, in <lambda>
    self, node)
  File ""theano/scan_module/scan_perform.pyx"", line 76, in theano.scan_module.scan_perform.perform (/home/riminder/.theano/compiledir_Linux-3.19--generic-x86_64-with-Ubuntu-14.04-trusty-x86_64-2.7.11-64/scan_perform/mod.cpp:1863)
TypeError: an integer is required
Apply node that caused the error: forall_inplace,gpu,scan_fn}(Shape_i{1}.0, GpuSubtensor{int64:int64:int8}.0, Subtensor{int64:int64:int8}.0, GpuIncSubtensor{InplaceSet;:int64:}.0, GpuIncSubtensor{InplaceSet;:int64:}.0, gru_2_W, GpuSubtensor{::, int64::}.0, GpuSubtensor{::, :int64:}.0, GpuDimShuffle{x,0}.0)
Toposort index: 42
Inputs types: [TensorType(int64, scalar), CudaNdarrayType(float32, 3D), TensorType(int8, (False, False, True)), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, (True, False, False)), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, row)]
Inputs shapes: ['No shapes', 'No shapes', 'No shapes', (10, 10, 2), 'No shapes', (2, 6), 'No shapes', 'No shapes', 'No shapes']
Inputs strides: ['No strides', 'No strides', 'No strides', (20, 2, 1), 'No strides', (6, 1), 'No strides', 'No strides', 'No strides']
Inputs values: [None, None, None, 'not shown', None, 'not shown', None, None, None]
Outputs clients: [[GpuSubtensor{int64:int64:int8}(forall_inplace,gpu,scan_fn}.0, ScalarFromTensor.0, ScalarFromTensor.0, Constant{1})], []]

HINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.
HINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.

Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/usr/local/lib/python2.7/dist-packages/keras/models.py"", line 656, in fit_generator
    max_q_size=max_q_size)
  File ""/usr/local/lib/python2.7/dist-packages/keras/engine/training.py"", line 1412, in fit_generator
    max_q_size=max_q_size)
  File ""/usr/local/lib/python2.7/dist-packages/keras/engine/training.py"", line 1474, in evaluate_generator
    'or (x, y). Found: ' + str(generator_output))
Exception: output of generator should be a tuple (x, y, sample_weight) or (x, y). Found: None
```

Any idea what is going wrong ?
",anMabbe,b'stale',2016-06-27T16:13:36Z,2017-09-21T14:03:16Z
3072,`predict` should be able to activate learning phase,"In models such as denoising auto-encoders it is often helpful to inspect the reconstruction results. However, noise is only available in the learning phase, not in prediction phase. Thus one cannot use `model.predict` but has to create a function from the model using `K.function`. This however may introduce bugs where the batch size is not correct and generates general discomfort.

Why not add a `in_learning_phase` parameter to `Model.predict`? E.g.

```
    def predict(self, x, batch_size=32, verbose=0, in_learning_phase=False):
        # ...
        if self.uses_learning_phase:
            ins = x + [1. if in_learning_phase else 0.]
        # ...
```
",githubnemo,None,2016-06-25T18:14:19Z,2018-11-12T14:16:51Z
3065,Non-masked + masked merge bug fix,"This was pointed out in [the PR thread](https://github.com/fchollet/keras/pull/2413) after it was merged, I'm not sure what the best way to go about making another change would be so I'll put it here.

Reference [this commit](https://github.com/codekansas/keras/commit/96c84158a569cc2a0e3fe256178a9d5415ee7164).

**`keras/engine/topology.py`**

``` python
             masks = [K.expand_dims(m, 0) for m in mask if m is not None]
              return K.all(K.concatenate(masks, axis=0), axis=0, keepdims=False)
          elif self.mode == 'concat':
 -            masks = [K.ones_like(inputs[i][:-1]) if m is None else m for i, m in zip(inputs, mask)]
 -            expanded_dims = [K.expand_dims(m) for m in masks]
 -            concatenated = K.concatenate(expanded_dims, axis=self.concat_axis)
 +            masks = [K.ones_like(inputs[i]) if m is None else K.expand_dims(m) for i, m in enumerate(mask)]
 +            concatenated = K.concatenate(masks, axis=self.concat_axis)
              return K.all(concatenated, axis=-1, keepdims=False)
          elif self.mode in ['cos', 'dot']:
              return None
```

**`tests/keras/layers/test_core.py`**

``` python
     # two different types of merging
      merged_sum = merge([masked_a, masked_b], mode='sum')
      merged_concat = merge([masked_a, masked_b], mode='concat', concat_axis=1)
 +    merged_concat_normal = merge([masked_a, input_b], mode='concat', concat_axis=1)

      # test sum
      model_sum = Model([input_a, input_b], [merged_sum])

                          ...

      model_concat.compile(loss='mse', optimizer='sgd')
      model_concat.fit([rand(2,3), rand(2,3)], [rand(2,6)], nb_epoch=1)

 +    # test concatenation with no mask
 +    model_concat_normal = Model([input_a, input_b], [merged_concat_normal])
 +    model_concat.compile(loss='mse', optimizer='sgd')
 +    model_concat.fit([rand(2,3), rand(2,3)], [rand(2,6)], nb_epoch=1)
 +

  def test_merge_mask_3d():
      from keras.layers import Input, merge, Embedding, SimpleRNN
```
",codekansas,b'stale',2016-06-24T20:12:51Z,2017-06-22T21:11:40Z
3026,"no histogram in tensorboard, keras 1.0.4, tensorflow 0.8","Hi,

I'm now using keras 1.0.4 + tensorflow 0.8. In my tensorboard, I can see accuracy, loss in 'events' tab, but the 'histograms' tab is always empty. 

I'm using fit_generator, here is the code:

tensorboard = keras.callbacks.TensorBoard(log_dir=mydir.tb_log, histogram_freq=1, write_graph=True)
history = self.model.fit_generator(train_generator, samples_per_epoch=samples_per_epoch,
                                          nb_epoch=pars['nb_epoch'],
                                          verbose=2,
                                          callbacks=[tensorboard],
                                          validation_data=validate_generator, nb_val_samples=nb_val_samples,
                                          class_weight=pars['class_weight'])

I debugged into _set_model in callbacks.py, at about line 455, I get variables like below:
layer: <keras.layers.core.Dense object at 0x7f668c8a74d0>
'{}_W'.format(layer): '<keras.layers.core.Dense object at 0x7f668c8a74d0>_W'
'{}_b'.format(layer): '<keras.layers.core.Dense object at 0x7f668c8a74d0>_b'
'{}_out'.format(layer): '<keras.layers.core.Dense object at 0x7f668c8a74d0>_out'

Are these right? I think 'layer' should be a string, but here it is an object. I saw fig_generator has some issues with tensorboard, are them solved?

Thanks a lot!
",benwu232,None,2016-06-20T09:00:43Z,2016-06-30T06:11:26Z
3002,Bug in combination of TimeDistributed with LSTM with param consume_less='cpu',"Hello,
I encountered a problem, which I guess is a Bug. I do combine TimeDistributed with LSTM and run into a broadcast problem when I use the LSTM with parameter `consume_less='cpu'` :
`ValueError: operands could not be broadcast together with shapes (50,64) (100,64) (50,64)`

Using the LSTM with parameter `consume_less='gpu'` works.

Code in Github[(link):](https://github.com/siavash9000/mixed_word_embedding/blob/master/simplified.py)

```
from keras.models import Model
from keras.utils import np_utils
from keras.layers import Dense, Embedding, Input, TimeDistributed, LSTM,  \
    Activation
import numpy as np


def main():
    DATA_SIZE = 1000
    BATCH_SIZE = 100
    WORD_COUNT = 20
    WORD_LENGTH = 10
    CHAR_VOCAB_SIZE = 50
    NB_CLASSES = 5
    CONSUME_LESS = 'cpu'

    X = np.random.randint(CHAR_VOCAB_SIZE, size=(DATA_SIZE, WORD_COUNT, WORD_LENGTH))
    Y = np.random.randint(NB_CLASSES, size=DATA_SIZE)
    Y = np_utils.to_categorical(Y, NB_CLASSES)

    input = Input(batch_shape=(BATCH_SIZE,WORD_COUNT, WORD_LENGTH, ),
                  dtype='int32')
    embedded = TimeDistributed(Embedding(CHAR_VOCAB_SIZE, 128,
                                         input_length=WORD_COUNT))(input)
    char_lstm = TimeDistributed(LSTM(64, consume_less=CONSUME_LESS))(embedded)
    lstm = LSTM(64,consume_less=CONSUME_LESS)(char_lstm)
    dense = Dense(NB_CLASSES, activation='sigmoid')(lstm)
    output = Activation('softmax')(dense)
    model = Model(input=input, output=output)
    model.compile(loss='categorical_crossentropy', optimizer='adam',
                  metrics=['accuracy'])
    model.fit(X, Y, batch_size=BATCH_SIZE, nb_epoch=5)


if __name__ == ""__main__"":
    main()
```

Please make sure that the boxes below are checked before you submit your issue. Thank you!
- [x] Check that you are up-to-date with the master branch of Keras. You can update with:
  pip install git+git://github.com/fchollet/keras.git --upgrade --no-deps
- [x] If running on Theano, check that you are up-to-date with the master branch of Theano. You can update with:
  pip install git+git://github.com/Theano/Theano.git --upgrade --no-deps
- [x] Provide a link to a GitHub Gist of a Python script that can reproduce your issue (or just copy the script here if it is short). 
",siavash9000,b'stale',2016-06-17T08:18:49Z,2017-06-22T22:11:25Z
2998,Fixed a bug which prevented rectangular images from loading.,"Modified ImageDataGenerator.flow_from_directory to fix a bug:
image.py uses PIL to load images, and PIL expects image dimensions to be specified in
the format (width,height), however load_img(...,target_size) takes target_size in the
matrix-format: target_size=(num_rows,num_columns). We need to specify width=num_rows and
height=num_columns rather than passing target_size directly to PIL. Prior to this bug-fix,
there were broadcasting errors when trying to load non-square images.
",davidlibland,None,2016-06-16T18:31:57Z,2016-08-03T04:47:04Z
2976,unrolling recurrent networks causes theano optimization error,"Just reinstalled theano+keras to make sure. I've tried a few things and it seems the problem only happens when the RNN being unrolled is before a `RepeatVector` layer (unrolling a network after the `RepeatVector` doesn't cause any problem).

My code:

``````
embedding_models =[]
for _ in xrange(n_simultaneous):
    embedding_models += [Sequential()]
    embedding_models[-1].add(Embedding(28,2,batch_input_shape=(b_sz,50 )))

model.add(Merge(embedding_models,mode='concat'))
model.add(GRU(10,stateful=True,unroll=True,return_sequences=True))
model.add(Flatten())
model.add(RepeatVector(10))
model.add(GRU(10,stateful=True,unroll=False,return_sequences=True))
model.add(TimeDistributedDense(180,activation='softmax'))'''
model.compile(loss=categorial_ce, optimizer='rmsprop',metrics=['accuracy'])
X_train,Y_train = get_batch()
model.fit(X_train, Y_train, batch_size=b_sz, nb_epoch=4, verbose=1,validation_split=v_splt)```


The error: (50 times `TensorConstant{10}` if anyone's wondering. probably number of timesteps. And no, `config.mode` is not `FAST_COMPILE`, is `Mode`, which is equivalent to `FAST_RUN`):


```ERROR (theano.gof.opt): Optimization failure due to: constant_folding
ERROR (theano.gof.opt): node: Elemwise{add,no_inplace}(TensorConstant{10}, TensorConstant{10}, TensorConstant{10}, TensorConstant{10}, TensorConstant{10}, TensorConstant{10}, TensorConstant{10}, TensorConstant{10}, TensorConstant{10}, TensorConstant{10}, TensorConstant{10}, TensorConstant{10}, TensorConstant{10}, TensorConstant{10}, TensorConstant{10}, TensorConstant{10}, TensorConstant{10}, TensorConstant{10}, TensorConstant{10}, TensorConstant{10}, TensorConstant{10}, TensorConstant{10}, TensorConstant{10}, TensorConstant{10}, TensorConstant{10}, TensorConstant{10}, TensorConstant{10}, TensorConstant{10}, TensorConstant{10}, TensorConstant{10}, TensorConstant{10}, TensorConstant{10}, TensorConstant{10}, TensorConstant{10}, TensorConstant{10}, TensorConstant{10}, TensorConstant{10}, TensorConstant{10}, TensorConstant{10}, TensorConstant{10}, TensorConstant{10}, TensorConstant{10}, TensorConstant{10}, TensorConstant{10}, TensorConstant{10}, TensorConstant{10}, TensorConstant{10}, TensorConstant{10}, TensorConstant{10}, TensorConstant{10})
ERROR (theano.gof.opt): TRACEBACK:
ERROR (theano.gof.opt): Traceback (most recent call last):
  File ""/home/azureuser/anaconda2/lib/python2.7/site-packages/theano/gof/opt.py"", line 1772, in process_node
    replacements = lopt.transform(node)
  File ""/home/azureuser/anaconda2/lib/python2.7/site-packages/theano/tensor/opt.py"", line 5827, in constant_folding
    required = thunk()
  File ""/home/azureuser/anaconda2/lib/python2.7/site-packages/theano/gof/op.py"", line 912, in rval
    r = p(n, [x[0] for x in i], o)
  File ""/home/azureuser/anaconda2/lib/python2.7/site-packages/theano/tensor/elemwise.py"", line 839, in perform
    super(Elemwise, self).perform(node, inputs, output_storage)
  File ""/home/azureuser/anaconda2/lib/python2.7/site-packages/theano/gof/op.py"", line 769, in perform
    ""Did you used Theano flags mode=FAST_COMPILE?""
MethodNotDefined: ('perform', <class 'theano.tensor.elemwise.Elemwise'>, 'Elemwise', 'Did you used Theano flags mode=FAST_COMPILE? You can use optimizer=fast_compile instead.')

ERROR (theano.gof.opt): Optimization failure due to: local_mul_zero
ERROR (theano.gof.opt): node: Elemwise{mul,no_inplace}(TensorConstant{50}, Elemwise{switch,no_inplace}.0, Elemwise{switch,no_inplace}.0)
ERROR (theano.gof.opt): TRACEBACK:
ERROR (theano.gof.opt): Traceback (most recent call last):
  File ""/home/azureuser/anaconda2/lib/python2.7/site-packages/theano/gof/opt.py"", line 1772, in process_node
    replacements = lopt.transform(node)
  File ""/home/azureuser/anaconda2/lib/python2.7/site-packages/theano/tensor/opt.py"", line 5193, in local_mul_zero
    value = get_scalar_constant_value(i)
  File ""/home/azureuser/anaconda2/lib/python2.7/site-packages/theano/tensor/basic.py"", line 660, in get_scalar_constant_value
    for i in v.owner.inputs]
  File ""/home/azureuser/anaconda2/lib/python2.7/site-packages/theano/tensor/basic.py"", line 662, in get_scalar_constant_value
    v.owner.op.perform(v.owner, const, ret)
  File ""/home/azureuser/anaconda2/lib/python2.7/site-packages/theano/tensor/elemwise.py"", line 839, in perform
    super(Elemwise, self).perform(node, inputs, output_storage)
  File ""/home/azureuser/anaconda2/lib/python2.7/site-packages/theano/gof/op.py"", line 769, in perform
    ""Did you used Theano flags mode=FAST_COMPILE?""
MethodNotDefined: ('perform', <class 'theano.tensor.elemwise.Elemwise'>, 'Elemwise', 'Did you used Theano flags mode=FAST_COMPILE? You can use optimizer=fast_compile instead.')```

I'd try to help, but I spent all my sanity during the weekend trying to debug my implementation of a neural tensor network.
``````
",ReallyCoolName,None,2016-06-14T10:48:49Z,2016-06-15T13:43:52Z
2966,"Bug: When loading two sequential models, the second gets the input of the first one. ","Hi, following my previous message I can now confirm the bug at loading the models. 

So, a minimum working example is: 

```
from keras.models import model_from_json

with open(model_1_file_name) as f:
    model_1 = model_from_json(f.read())
with open(model_2_file_name) as f:
    model_2 = model_from_json(f.read())
```

Now, if someone checks the `model_1.input` and the `model_2.input` he will see that both are the same. 
",dr-costas,None,2016-06-13T11:17:26Z,2016-06-16T16:08:58Z
2937,Are the quoted numbers accurate in the cifar-10 script?,"The numbers seem 'optomistic' for the cifar-10,  after 70 epochs I'm nowhere close to the numbers stated in the script claims to get at 40 epoch and reading bug reports - other people tend to get a NN with similar accuracy (80-81%).

Here is the output for all 71 epochs

50000/50000 [==============================] - 678s - loss: 1.7646 - acc: 0.3460 - val_loss: 1.3379 - val_acc: 0.5161
Epoch 2/200
50000/50000 [==============================] - 701s - loss: 1.3731 - acc: 0.5027 - val_loss: 1.0936 - val_acc: 0.6131
Epoch 3/200
50000/50000 [==============================] - 706s - loss: 1.2137 - acc: 0.5645 - val_loss: 1.0011 - val_acc: 0.6478
Epoch 4/200
50000/50000 [==============================] - 709s - loss: 1.1154 - acc: 0.6033 - val_loss: 0.8915 - val_acc: 0.6866
Epoch 5/200
50000/50000 [==============================] - 708s - loss: 1.0465 - acc: 0.6294 - val_loss: 0.8605 - val_acc: 0.7020
Epoch 6/200
50000/50000 [==============================] - 707s - loss: 1.0045 - acc: 0.6450 - val_loss: 0.8188 - val_acc: 0.7131
Epoch 7/200
50000/50000 [==============================] - 706s - loss: 0.9582 - acc: 0.6624 - val_loss: 0.7967 - val_acc: 0.7213
Epoch 8/200
50000/50000 [==============================] - 707s - loss: 0.9401 - acc: 0.6698 - val_loss: 0.7908 - val_acc: 0.7217
Epoch 9/200
50000/50000 [==============================] - 706s - loss: 0.9125 - acc: 0.6786 - val_loss: 0.7928 - val_acc: 0.7213
Epoch 10/200
50000/50000 [==============================] - 712s - loss: 0.9029 - acc: 0.6867 - val_loss: 0.7373 - val_acc: 0.7464
Epoch 11/200
50000/50000 [==============================] - 703s - loss: 0.8805 - acc: 0.6929 - val_loss: 0.7339 - val_acc: 0.7488
Epoch 12/200
50000/50000 [==============================] - 705s - loss: 0.8716 - acc: 0.6975 - val_loss: 0.7351 - val_acc: 0.7474
Epoch 13/200
50000/50000 [==============================] - 704s - loss: 0.8701 - acc: 0.6980 - val_loss: 0.7118 - val_acc: 0.7592
Epoch 14/200
50000/50000 [==============================] - 705s - loss: 0.8568 - acc: 0.7026 - val_loss: 0.7170 - val_acc: 0.7509
Epoch 15/200
50000/50000 [==============================] - 706s - loss: 0.8455 - acc: 0.7070 - val_loss: 0.7144 - val_acc: 0.7547
Epoch 16/200
50000/50000 [==============================] - 706s - loss: 0.8402 - acc: 0.7092 - val_loss: 0.7077 - val_acc: 0.7587
Epoch 17/200
50000/50000 [==============================] - 704s - loss: 0.8281 - acc: 0.7142 - val_loss: 0.7092 - val_acc: 0.7572
Epoch 18/200
50000/50000 [==============================] - 709s - loss: 0.8237 - acc: 0.7141 - val_loss: 0.7385 - val_acc: 0.7435
Epoch 19/200
50000/50000 [==============================] - 708s - loss: 0.8221 - acc: 0.7187 - val_loss: 0.6947 - val_acc: 0.7653
Epoch 20/200
50000/50000 [==============================] - 708s - loss: 0.8065 - acc: 0.7200 - val_loss: 0.6668 - val_acc: 0.7746
Epoch 21/200
50000/50000 [==============================] - 705s - loss: 0.8116 - acc: 0.7191 - val_loss: 0.6542 - val_acc: 0.7782
Epoch 22/200
50000/50000 [==============================] - 705s - loss: 0.8026 - acc: 0.7230 - val_loss: 0.6961 - val_acc: 0.7628
Epoch 23/200
50000/50000 [==============================] - 705s - loss: 0.8079 - acc: 0.7233 - val_loss: 0.6516 - val_acc: 0.7763
Epoch 24/200
50000/50000 [==============================] - 705s - loss: 0.7935 - acc: 0.7284 - val_loss: 0.6369 - val_acc: 0.7874
Epoch 25/200
50000/50000 [==============================] - 704s - loss: 0.7916 - acc: 0.7296 - val_loss: 0.6373 - val_acc: 0.7835
Epoch 26/200
50000/50000 [==============================] - 702s - loss: 0.7996 - acc: 0.7254 - val_loss: 0.6692 - val_acc: 0.7773
Epoch 27/200
50000/50000 [==============================] - 704s - loss: 0.7945 - acc: 0.7272 - val_loss: 0.6274 - val_acc: 0.7884
Epoch 28/200
50000/50000 [==============================] - 705s - loss: 0.7864 - acc: 0.7287 - val_loss: 0.6561 - val_acc: 0.7817
Epoch 29/200
50000/50000 [==============================] - 703s - loss: 0.7896 - acc: 0.7303 - val_loss: 0.6403 - val_acc: 0.7841
Epoch 30/200
50000/50000 [==============================] - 700s - loss: 0.7778 - acc: 0.7341 - val_loss: 0.6983 - val_acc: 0.7614
Epoch 31/200
50000/50000 [==============================] - 701s - loss: 0.7801 - acc: 0.7352 - val_loss: 0.6287 - val_acc: 0.7870
Epoch 32/200
50000/50000 [==============================] - 701s - loss: 0.7806 - acc: 0.7341 - val_loss: 0.6288 - val_acc: 0.7924
Epoch 33/200
50000/50000 [==============================] - 694s - loss: 0.7721 - acc: 0.7347 - val_loss: 0.6406 - val_acc: 0.7851
Epoch 34/200
50000/50000 [==============================] - 690s - loss: 0.7772 - acc: 0.7353 - val_loss: 0.6186 - val_acc: 0.7913
Epoch 35/200
50000/50000 [==============================] - 689s - loss: 0.7712 - acc: 0.7363 - val_loss: 0.6650 - val_acc: 0.7773
Epoch 36/200
50000/50000 [==============================] - 799s - loss: 0.7784 - acc: 0.7361 - val_loss: 0.6450 - val_acc: 0.7800
Epoch 37/200
50000/50000 [==============================] - 760s - loss: 0.7757 - acc: 0.7350 - val_loss: 0.6757 - val_acc: 0.7732
Epoch 38/200
50000/50000 [==============================] - 689s - loss: 0.7772 - acc: 0.7340 - val_loss: 0.6248 - val_acc: 0.7885
Epoch 39/200
50000/50000 [==============================] - 691s - loss: 0.7653 - acc: 0.7400 - val_loss: 0.6317 - val_acc: 0.7881
Epoch 40/200
50000/50000 [==============================] - 688s - loss: 0.7655 - acc: 0.7398 - val_loss: 0.6243 - val_acc: 0.7906
Epoch 41/200
50000/50000 [==============================] - 686s - loss: 0.7655 - acc: 0.7403 - val_loss: 0.6436 - val_acc: 0.7807
Epoch 42/200
50000/50000 [==============================] - 685s - loss: 0.7645 - acc: 0.7391 - val_loss: 0.6266 - val_acc: 0.7916
Epoch 43/200
50000/50000 [==============================] - 681s - loss: 0.7711 - acc: 0.7381 - val_loss: 0.6114 - val_acc: 0.7953
Epoch 44/200
50000/50000 [==============================] - 679s - loss: 0.7626 - acc: 0.7413 - val_loss: 0.6245 - val_acc: 0.7912
Epoch 45/200
50000/50000 [==============================] - 682s - loss: 0.7704 - acc: 0.7394 - val_loss: 0.6468 - val_acc: 0.7891
Epoch 46/200
50000/50000 [==============================] - 681s - loss: 0.7698 - acc: 0.7391 - val_loss: 0.6166 - val_acc: 0.7910
Epoch 47/200
50000/50000 [==============================] - 672s - loss: 0.7672 - acc: 0.7399 - val_loss: 0.6231 - val_acc: 0.7876
Epoch 48/200
50000/50000 [==============================] - 674s - loss: 0.7517 - acc: 0.7440 - val_loss: 0.6103 - val_acc: 0.7957
Epoch 49/200
50000/50000 [==============================] - 677s - loss: 0.7681 - acc: 0.7384 - val_loss: 0.6192 - val_acc: 0.7906
Epoch 50/200
50000/50000 [==============================] - 675s - loss: 0.7691 - acc: 0.7413 - val_loss: 0.6612 - val_acc: 0.7835
Epoch 51/200
50000/50000 [==============================] - 669s - loss: 0.7586 - acc: 0.7429 - val_loss: 0.6632 - val_acc: 0.7771
Epoch 52/200
50000/50000 [==============================] - 672s - loss: 0.7548 - acc: 0.7449 - val_loss: 0.6844 - val_acc: 0.7724
Epoch 53/200
50000/50000 [==============================] - 671s - loss: 0.7605 - acc: 0.7431 - val_loss: 0.6271 - val_acc: 0.7911
Epoch 54/200
50000/50000 [==============================] - 670s - loss: 0.7607 - acc: 0.7427 - val_loss: 0.6207 - val_acc: 0.7934
Epoch 55/200
50000/50000 [==============================] - 667s - loss: 0.7570 - acc: 0.7445 - val_loss: 0.5973 - val_acc: 0.8035
Epoch 56/200
50000/50000 [==============================] - 666s - loss: 0.7657 - acc: 0.7407 - val_loss: 0.6121 - val_acc: 0.7956
Epoch 57/200
50000/50000 [==============================] - 665s - loss: 0.7652 - acc: 0.7424 - val_loss: 0.5917 - val_acc: 0.8051
Epoch 58/200
50000/50000 [==============================] - 666s - loss: 0.7587 - acc: 0.7435 - val_loss: 0.6507 - val_acc: 0.7855
Epoch 59/200
50000/50000 [==============================] - 662s - loss: 0.7495 - acc: 0.7471 - val_loss: 0.6322 - val_acc: 0.7917
Epoch 60/200
50000/50000 [==============================] - 662s - loss: 0.7574 - acc: 0.7463 - val_loss: 0.6830 - val_acc: 0.7764
Epoch 61/200
50000/50000 [==============================] - 663s - loss: 0.7506 - acc: 0.7442 - val_loss: 0.6091 - val_acc: 0.7978
Epoch 62/200
50000/50000 [==============================] - 658s - loss: 0.7609 - acc: 0.7454 - val_loss: 0.6281 - val_acc: 0.7934
Epoch 63/200
50000/50000 [==============================] - 657s - loss: 0.7482 - acc: 0.7492 - val_loss: 0.6026 - val_acc: 0.8025
Epoch 64/200
50000/50000 [==============================] - 653s - loss: 0.7471 - acc: 0.7489 - val_loss: 0.6273 - val_acc: 0.7913
Epoch 65/200
50000/50000 [==============================] - 660s - loss: 0.7507 - acc: 0.7452 - val_loss: 0.6090 - val_acc: 0.7979
Epoch 66/200
50000/50000 [==============================] - 656s - loss: 0.7471 - acc: 0.7474 - val_loss: 0.6177 - val_acc: 0.7970
Epoch 67/200
50000/50000 [==============================] - 655s - loss: 0.7515 - acc: 0.7453 - val_loss: 0.5881 - val_acc: 0.8052
Epoch 68/200
50000/50000 [==============================] - 661s - loss: 0.7476 - acc: 0.7479 - val_loss: 0.6323 - val_acc: 0.7899
Epoch 69/200
50000/50000 [==============================] - 667s - loss: 0.7466 - acc: 0.7486 - val_loss: 0.5878 - val_acc: 0.8070
Epoch 70/200
50000/50000 [==============================] - 708s - loss: 0.7435 - acc: 0.7515 - val_loss: 0.6329 - val_acc: 0.7951
Epoch 71/200
50000/50000 [==============================] - 731s - loss: 0.7546 - acc: 0.7462 - val_loss: 0.6165 - val_acc: 0.7941
",LetterRip,b'stale',2016-06-08T21:29:51Z,2017-06-22T22:11:23Z
2913,"keras imdb_lstm.py gives the following error ('The following error happened while compiling the node', GpuJoin(TensorConstant{1}, GpuAlloc.0, GpuAlloc.0, GpuAlloc.0, GpuAlloc.0' ","This is full traceback after printing the train and test shapes. Before the below traceback, a 10492 line python code was also printed to the console

Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""C:\Users\mukris\AppData\Local\Continuum\Anaconda2\lib\site-packages\spyderlib\widgets\externalshell\sitecustomize.py"", line 699, in runfile
    execfile(filename, namespace)
  File ""C:\Users\mukris\AppData\Local\Continuum\Anaconda2\lib\site-packages\spyderlib\widgets\externalshell\sitecustomize.py"", line 74, in execfile
    exec(compile(scripttext, filename, 'exec'), glob, loc)
  File ""C:/Users/mukris/keras_examples/examples_imdb_lstm.py"", line 45, in <module>
    validation_data=(X_test, y_test))
  File ""c:\users\mukris\keras\keras\models.py"", line 408, in fit
    sample_weight=sample_weight)
  File ""c:\users\mukris\keras\keras\engine\training.py"", line 1009, in fit
    self._make_test_function()
  File ""c:\users\mukris\keras\keras\engine\training.py"", line 686, in _make_test_function
    *_self._function_kwargs)
  File ""c:\users\mukris\keras\keras\backend\theano_backend.py"", line 528, in function
    return Function(inputs, outputs, updates=updates, *_kwargs)
  File ""c:\users\mukris\keras\keras\backend\theano_backend.py"", line 514, in __init__
    **kwargs)
  File ""c:\users\mukris\theano\theano\compile\function.py"", line 322, in function
    output_keys=output_keys)
  File ""c:\users\mukris\theano\theano\compile\pfunc.py"", line 480, in pfunc
    output_keys=output_keys)
  File ""c:\users\mukris\theano\theano\compile\function_module.py"", line 1828, in orig_function
    defaults)
  File ""c:\users\mukris\theano\theano\compile\function_module.py"", line 1692, in create
    input_storage=input_storage_lists, storage_map=storage_map)
  File ""c:\users\mukris\theano\theano\gof\link.py"", line 693, in make_thunk
    storage_map=storage_map)[:3]
  File ""c:\users\mukris\theano\theano\gof\vm.py"", line 1021, in make_all
    no_recycling))
  File ""c:\users\mukris\theano\theano\sandbox\cuda__init__.py"", line 256, in make_thunk
    compute_map, no_recycling)
  File ""c:\users\mukris\theano\theano\gof\op.py"", line 969, in make_thunk
    no_recycling)
  File ""c:\users\mukris\theano\theano\gof\op.py"", line 872, in make_c_thunk
    output_storage=node_output_storage)
  File ""c:\users\mukris\theano\theano\gof\cc.py"", line 1200, in make_thunk
    keep_lock=keep_lock)
  File ""c:\users\mukris\theano\theano\gof\cc.py"", line 1143, in **compile**
    keep_lock=keep_lock)
  File ""c:\users\mukris\theano\theano\gof\cc.py"", line 1591, in cthunk_factory
    key=key, lnk=self, keep_lock=keep_lock)
  File ""c:\users\mukris\theano\theano\gof\cmodule.py"", line 1142, in module_from_key
    module = lnk.compile_cmodule(location)
  File ""c:\users\mukris\theano\theano\gof\cc.py"", line 1502, in compile_cmodule
    preargs=preargs)
  File ""c:\users\mukris\theano\theano\sandbox\cuda\nvcc_compiler.py"", line 403, in compile_str
    'for cmd', ' '.join(cmd))
Exception: ('The following error happened while compiling the node', GpuJoin(TensorConstant{1}, GpuAlloc.0, GpuAlloc.0, GpuAlloc.0, GpuAlloc.0, GpuAlloc.0, GpuAlloc.0, GpuAlloc.0, GpuAlloc.0, GpuAlloc.0, GpuAlloc.0, GpuAlloc.0, GpuAlloc.0, GpuAlloc.0, GpuAlloc.0, GpuAlloc.0, GpuAlloc.0, GpuAlloc.0, GpuAlloc.0, GpuAlloc.0, GpuAlloc.0, GpuAlloc.0, GpuAlloc.0, GpuAlloc.0, GpuAlloc.0, GpuAlloc.0, GpuAlloc.0, GpuAlloc.0, GpuAlloc.0, GpuAlloc.0, GpuAlloc.0, GpuAlloc.0, GpuAlloc.0, GpuAlloc.0, GpuAlloc.0, GpuAlloc.0, GpuAlloc.0, GpuAlloc.0, GpuAlloc.0, GpuAlloc.0, GpuAlloc.0, GpuAlloc.0, GpuAlloc.0, GpuAlloc.0, GpuAlloc.0, GpuAlloc.0, GpuAlloc.0, GpuAlloc.0, GpuAlloc.0, GpuAlloc.0, GpuAlloc.0, GpuAlloc.0, GpuAlloc.0, GpuAlloc.0, GpuAlloc.0, GpuAlloc.0, GpuAlloc.0, GpuAlloc.0, GpuAlloc.0, GpuAlloc.0, GpuAlloc.0, GpuAlloc.0, GpuAlloc.0, GpuAlloc.0, GpuAlloc.0, GpuAlloc.0, GpuAlloc.0, GpuAlloc.0, GpuAlloc.0, GpuAlloc.0, GpuAlloc.0, GpuAlloc.0, GpuAlloc.0, GpuAlloc.0, GpuAlloc.0, GpuAlloc.0, GpuAlloc.0, GpuAlloc.0, GpuAlloc.0, GpuAlloc.0, GpuAlloc.0, GpuAlloc.0, GpuAlloc.0, GpuAlloc.0, GpuAlloc.0, GpuAlloc.0, GpuAlloc.0, GpuAlloc.0, GpuAlloc.0, GpuAlloc.0, GpuAlloc.0, GpuAlloc.0, GpuAlloc.0, GpuAlloc.0, GpuAlloc.0, GpuAlloc.0, GpuAlloc.0, GpuAlloc.0, GpuAlloc.0, GpuAlloc.0, GpuAlloc.0, GpuAlloc.0, GpuAlloc.0, GpuAlloc.0, GpuAlloc.0, GpuAlloc.0, GpuAlloc.0, GpuAlloc.0, GpuAlloc.0, GpuAlloc.0, GpuAlloc.0, GpuAlloc.0, GpuAlloc.0, GpuAlloc.0, GpuAlloc.0, GpuAlloc.0, GpuAlloc.0, GpuAlloc.0, GpuAlloc.0, GpuAlloc.0, GpuAlloc.0, GpuAlloc.0, GpuAlloc.0, GpuAlloc.0, GpuAlloc.0, GpuAlloc.0, GpuAlloc.0, GpuAlloc.0, GpuAlloc.0), '\n', 'nvcc return status', 2, 'for cmd', 'nvcc -shared -O3 -LC:\Users\mukris\AppData\Local\Continuum\Anaconda2\libs -use_fast_math -arch=sm_21 --compiler-bindir C:\Program Files (x86)\Microsoft Visual Studio 12.0\VC\bin -Xlinker /DEBUG -D HAVE_ROUND -m64 -Xcompiler -DCUDA_NDARRAY_CUH=18715462c72ed6afcd7ca5d52813ce90,-DNPY_NO_DEPRECATED_API=NPY_1_7_API_VERSION,/Zi,/MD -IC:\Users\mukris\AppData\Local\Theano\compiledir_Windows-8.1-6.3.9600-Intel64_Family_6_Model_58_Stepping_9_GenuineIntel-2.7.11-64\cuda_ndarray -IC:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v6.5\bin\include -IC:\Users\mukris\AppData\Local\Continuum\Anaconda2\lib\site-packages\numpy\core\include -IC:\Users\mukris\AppData\Local\Continuum\Anaconda2\include -Ic:\users\mukris\theano\theano\gof -Ic:\users\mukris\theano\theano\sandbox\cuda -o C:\Users\mukris\AppData\Local\Theano\compiledir_Windows-8.1-6.3.9600-Intel64_Family_6_Model_58_Stepping_9_GenuineIntel-2.7.11-64\tmp9z4sxl\e01240057833926033b89ffb155e750b.pyd mod.cu -LC:\Users\mukris\AppData\Local\Theano\compiledir_Windows-8.1-6.3.9600-Intel64_Family_6_Model_58_Stepping_9_GenuineIntel-2.7.11-64\cuda_ndarray -LC:\Users\mukris\AppData\Local\Continuum\Anaconda2\libs -LC:\Users\mukris\AppData\Local\Continuum\Anaconda2 -lcudart -lcublas -lcuda_ndarray -lpython27', '[GpuJoin(TensorConstant{1}, <CudaNdarrayType(float32, col)>, <CudaNdarrayType(float32, col)>, <CudaNdarrayType(float32, col)>, <CudaNdarrayType(float32, col)>, <CudaNdarrayType(float32, col)>, <CudaNdarrayType(float32, col)>, <CudaNdarrayType(float32, col)>, <CudaNdarrayType(float32, col)>, <CudaNdarrayType(float32, col)>, <CudaNdarrayType(float32, col)>, <CudaNdarrayType(float32, col)>, <CudaNdarrayType(float32, col)>, <CudaNdarrayType(float32, col)>, <CudaNdarrayType(float32, col)>, <CudaNdarrayType(float32, col)>, <CudaNdarrayType(float32, col)>, <CudaNdarrayType(float32, col)>, <CudaNdarrayType(float32, col)>, <CudaNdarrayType(float32, col)>, <CudaNdarrayType(float32, col)>, <CudaNdarrayType(float32, col)>, <CudaNdarrayType(float32, col)>, <CudaNdarrayType(float32, col)>, <CudaNdarrayType(float32, col)>, <CudaNdarrayType(float32, col)>, <CudaNdarrayType(float32, col)>, <CudaNdarrayType(float32, col)>, <CudaNdarrayType(float32, col)>, <CudaNdarrayType(float32, col)>, <CudaNdarrayType(float32, col)>, <CudaNdarrayType(float32, col)>, <CudaNdarrayType(float32, col)>, <CudaNdarrayType(float32, col)>, <CudaNdarrayType(float32, col)>, <CudaNdarrayType(float32, col)>, <CudaNdarrayType(float32, col)>, <CudaNdarrayType(float32, col)>, <CudaNdarrayType(float32, col)>, <CudaNdarrayType(float32, col)>, <CudaNdarrayType(float32, col)>, <CudaNdarrayType(float32, col)>, <CudaNdarrayType(float32, col)>, <CudaNdarrayType(float32, col)>, <CudaNdarrayType(float32, col)>, <CudaNdarrayType(float32, col)>, <CudaNdarrayType(float32, col)>, <CudaNdarrayType(float32, col)>, <CudaNdarrayType(float32, col)>, <CudaNdarrayType(float32, col)>, <CudaNdarrayType(float32, col)>, <CudaNdarrayType(float32, col)>, <CudaNdarrayType(float32, col)>, <CudaNdarrayType(float32, col)>, <CudaNdarrayType(float32, col)>, <CudaNdarrayType(float32, col)>, <CudaNdarrayType(float32, col)>, <CudaNdarrayType(float32, col)>, <CudaNdarrayType(float32, col)>, <CudaNdarrayType(float32, col)>, <CudaNdarrayType(float32, col)>, <CudaNdarrayType(float32, col)>, <CudaNdarrayType(float32, col)>, <CudaNdarrayType(float32, col)>, <CudaNdarrayType(float32, col)>, <CudaNdarrayType(float32, col)>, <CudaNdarrayType(float32, col)>, <CudaNdarrayType(float32, col)>, <CudaNdarrayType(float32, col)>, <CudaNdarrayType(float32, col)>, <CudaNdarrayType(float32, col)>, <CudaNdarrayType(float32, col)>, <CudaNdarrayType(float32, col)>, <CudaNdarrayType(float32, col)>, <CudaNdarrayType(float32, col)>, <CudaNdarrayType(float32, col)>, <CudaNdarrayType(float32, col)>, <CudaNdarrayType(float32, col)>, <CudaNdarrayType(float32, col)>, <CudaNdarrayType(float32, col)>, <CudaNdarrayType(float32, col)>, <CudaNdarrayType(float32, col)>, <CudaNdarrayType(float32, col)>, <CudaNdarrayType(float32, col)>, <CudaNdarrayType(float32, col)>, <CudaNdarrayType(float32, col)>, <CudaNdarrayType(float32, col)>, <CudaNdarrayType(float32, col)>, <CudaNdarrayType(float32, col)>, <CudaNdarrayType(float32, col)>, <CudaNdarrayType(float32, col)>, <CudaNdarrayType(float32, col)>, <CudaNdarrayType(float32, col)>, <CudaNdarrayType(float32, col)>, <CudaNdarrayType(float32, col)>, <CudaNdarrayType(float32, col)>, <CudaNdarrayType(float32, col)>, <CudaNdarrayType(float32, col)>, <CudaNdarrayType(float32, col)>, <CudaNdarrayType(float32, col)>, <CudaNdarrayType(float32, col)>, <CudaNdarrayType(float32, col)>, <CudaNdarrayType(float32, col)>, <CudaNdarrayType(float32, col)>, <CudaNdarrayType(float32, col)>, <CudaNdarrayType(float32, col)>, <CudaNdarrayType(float32, col)>, <CudaNdarrayType(float32, col)>, <CudaNdarrayType(float32, col)>, <CudaNdarrayType(float32, col)>, <CudaNdarrayType(float32, col)>, <CudaNdarrayType(float32, col)>, <CudaNdarrayType(float32, col)>, <CudaNdarrayType(float32, col)>, <CudaNdarrayType(float32, col)>, <CudaNdarrayType(float32, col)>, <CudaNdarrayType(float32, col)>, <CudaNdarrayType(float32, col)>, <CudaNdarrayType(float32, col)>, <CudaNdarrayType(float32, col)>, <CudaNdarrayType(float32, col)>, <CudaNdarrayType(float32, col)>, <CudaNdarrayType(float32, col)>, <CudaNdarrayType(float32, col)>, <CudaNdarrayType(float32, col)>, <CudaNdarrayType(float32, col)>, <CudaNdarrayType(float32, col)>, <CudaNdarrayType(float32, col)>, <CudaNdarrayType(float32, col)>)]')

Is this something to do with the GPU(NVS 5400M). I'm running the latest theano version (from github) and keras(pip) with VS 2012.

UPDATE: I downgraded to keras 1.0.1 and changed the dimensions of lstm from 128 to 64 which is running fine without any errors?
",krishnateja614,b'stale',2016-06-06T17:24:53Z,2017-06-22T22:12:41Z
2889,bug in get_output_shape_for() function of Flatten layer,"Currently the get_output_shape_for() funciton of Flatten layer requires all dimensions are explicitly defined, otherwise it will raise an exception. However, when building FCN model with variable-sized input, this will be a problem since not all input dimensions are fixed. I suggest modifying the get_output_shape_for() function from 

```
def get_output_shape_for(self, input_shape):
    if not all(input_shape[1:]):
         raise Exception('The shape of the input to ""Flatten"" '
                         'is not fully defined '
                         '(got ' + str(input_shape[1:]) + '. '
                         'Make sure to pass a complete ""input_shape"" '
                         'or ""batch_input_shape"" argument to the first '
                         'layer in your model.')
    return (input_shape[0], np.prod(input_shape[1:]))
```

to 

```
def get_output_shape_for(self, input_shape):
    if not all(input_shape[1:]):
        return (input_shape[0], None)
    return (input_shape[0], np.prod(input_shape[1:]))
```

This will resolve the problem.

_Index: FCN, fully convolutional network_

Please make sure that the boxes below are checked before you submit your issue. Thank you!
- [x] Check that you are up-to-date with the master branch of Keras. You can update with:
  pip install git+git://github.com/fchollet/keras.git --upgrade --no-deps
- [ ] If running on Theano, check that you are up-to-date with the master branch of Theano. You can update with:
  pip install git+git://github.com/Theano/Theano.git --upgrade --no-deps
- [ ] Provide a link to a GitHub Gist of a Python script that can reproduce your issue (or just copy the script here if it is short).
",ghost,b'stale',2016-06-03T06:19:00Z,2017-06-22T22:12:30Z
2865,fix bug: change seed range for RandomStreams in Theano,"Uses can run into this problem while using functions at Theano backend that include RandomStreams. 

Currently, in theano_backend.py, we use this code to generate a random seed for RandomStreams

```
    if seed is None:
        seed = np.random.randint(10e6)
    rng = RandomStreams(seed=seed)
```

However, RandomStreams does not take 0 as an input for seed and using numpy.random.randint(10e6) can potentially generate 0 as an output (even though it is very unlikely) and it will result in the following error:

```
ValueError: ('seed should not be 0', 0)
```

So I modified the code to be

```
    if seed is None:
        seed = np.random.randint(1,10e6+1)
    rng = RandomStreams(seed=seed)
```

and seed will have a new range [1,10e6] compared to the previous range [0,10e6-1] and we can avoid running into ValueError.
",matthewmok,None,2016-05-31T22:10:13Z,2016-06-02T20:05:51Z
2842,fix bug: rename duplicated loss name,"While users use a shared layer to get two different outputs but have one same name, the batch_logs/epoch_logs will only left one loss, because it's a `dict`.

```
import numpy as np
from keras.models import *
from keras.layers import *

train_d = np.random.rand(128, 64)
test_d  = np.random.rand(2, 128, 32)

x = Input(shape=(64, ))
a = Dense(32)(x)
b = Dense(32)(x)

shared_dense = Dense(32, name='shared_dense')
out1 = shared_dense(a)
out2 = shared_dense(b)

model = Model(input=x, output=[out1, out2])
model.compile(optimizer='rmsprop', loss='mse')

his = model.fit(train_d, [test_d[0], test_d[1]])
```

The code above will get output like below, but it should have two shared_dense_loss.

![image](https://cloud.githubusercontent.com/assets/17693755/15631854/8d1d9868-25b0-11e6-8cc2-ed211e3ef996.png)

To solve this problem, I rename the duplicates name by appending it a number. Then it works well:

![image](https://cloud.githubusercontent.com/assets/17693755/15631865/df869e6a-25b0-11e6-92e4-f9287e7b0f7f.png)
",ZihengJiang,None,2016-05-29T07:23:37Z,2016-06-08T18:51:34Z
2818,TypeError: Not JSON Serializable,"There is a sample code that will reproduce the error:
https://gist.github.com/henry0312/c5e37cf219498a692520ddc01d2e41ba

Run: `python keras_save_json_bug.py`

```
Traceback (most recent call last):
  File ""keras_save_json_bug.py"", line 59, in <module>
    json_string = net.to_json()
  File ""/usr/local/var/pyenv/versions/3.5.1/lib/python3.5/site-packages/keras/engine/topology.py"", line 2373, in to_json
    return json.dumps(model_config, default=get_json_type, **kwargs)
  File ""/usr/local/var/pyenv/versions/3.5.1/lib/python3.5/json/__init__.py"", line 237, in dumps
    **kw).encode(obj)
  File ""/usr/local/var/pyenv/versions/3.5.1/lib/python3.5/json/encoder.py"", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File ""/usr/local/var/pyenv/versions/3.5.1/lib/python3.5/json/encoder.py"", line 257, in iterencode
    return _iterencode(o, 0)
  File ""/usr/local/var/pyenv/versions/3.5.1/lib/python3.5/site-packages/keras/engine/topology.py"", line 2366, in get_json_type
    raise TypeError('Not JSON Serializable')
TypeError: Not JSON Serializable
```
",henry0312,None,2016-05-26T02:00:36Z,2016-05-31T03:30:07Z
2807,model.to_json not saving input layer used in shared Embedding,"I have a model, constructed like this:

``` python
text_input = Input((self.text_maxlen,), dtype=""int32"")
title_input = Input((self.title_maxlen,), dtype=""int32"")
embed = Embedding(  # TODO re-enable masking once merge supports it!
    input_dim=self.vocab_size, output_dim=self.text_embedding_size, mask_zero=False, 
    name=""word_embeddings"",
    weights=[get_word_vector_matrix()]
)
title_embedding = embed(title_input)
title_encoded = LSTM(self.title_lstm_size, return_sequences=False)(title_embedding)
title_encoded = Dropout(0.3)(title_encoded)
title_encoded_repeat = RepeatVector(self.text_maxlen)(title_encoded)
text_embedding = embed(text_input)
merged_aux_and_text = merge([title_encoded_repeat, text_embedding], mode=""concat"")
merged_text_lstm = LSTM(self.text_lstm_size, return_sequences=False)(merged_aux_and_text)
merged_text_lstm = Dropout(0.3)(merged_text_lstm)
prediction = Dense(1, activation=""sigmoid"")(merged_text_lstm)
model = Model(input=[text_input, title_input], output=prediction)
```

I save using something like 

``` python
fname = folder + ""expertise_classifier_%s.model"" % (time.time())
with open(fname, ""w"") as of:
    of.write(self.model.to_json())

self.model.save_weights(fname + "".weights"")
```

Loading:

``` python
with open(fname, ""r"") as inf:
    self.model = model_from_json(inf.read())

ln.debug(""Loading weights.."")
self.model.load_weights(fname + "".weights"")
```

I get the following error:

``` python
  File ""/usr/local/lib/python2.7/dist-packages/keras/engine/topology.py"", line 2206, in from_config
    assert inbound_layer_name in created_layers, 'Missing layer: %s' % inbound_layer_name
AssertionError: Missing layer: input_1
```

Here's the model JSON, it seems the ~~input layer really is missing:~~ No it's not, but somehow it's not being loaded!

```
{""class_name"": ""Model"", ""config"": {""layers"": [{""class_name"": ""InputLayer"", ""config"": {""batch_input_shape"": [null, 18], ""name"": ""input_2"", ""input_dtype"": ""int32""}, ""inbound_nodes"": [], ""name"": ""input_2""}, {""class_name"": ""Embedding"", ""config"": {""trainable"": true, ""name"": ""word_embeddings"", ""activity_regularizer"": null, ""W_constraint"": null, ""init"": ""uniform"", ""input_dtype"": ""int32"", ""mask_zero"": false, ""input_dim"": 160693, ""batch_input_shape"": [null, null], ""W_regularizer"": null, ""dropout"": 0.0, ""output_dim"": 300, ""input_length"": null}, ""inbound_nodes"": [[[""input_2"", 0, 0]], [[""input_1"", 0, 0]]], ""name"": ""word_embeddings""}, {""class_name"": ""LSTM"", ""config"": {""U_regularizer"": null, ""name"": ""lstm_1"", ""inner_activation"": ""hard_sigmoid"", ""go_backwards"": false, ""activation"": ""tanh"", ""trainable"": true, ""unroll"": false, ""consume_less"": ""cpu"", ""stateful"": false, ""init"": ""glorot_uniform"", ""inner_init"": ""orthogonal"", ""dropout_U"": 0.0, ""dropout_W"": 0.0, ""input_dim"": 300, ""return_sequences"": false, ""b_regularizer"": null, ""W_regularizer"": null, ""output_dim"": 200, ""forget_bias_init"": ""one"", ""input_length"": null}, ""inbound_nodes"": [[[""word_embeddings"", 0, 0]]], ""name"": ""lstm_1""}, {""class_name"": ""Dropout"", ""config"": {""p"": 0.3, ""trainable"": true, ""name"": ""dropout_1""}, ""inbound_nodes"": [[[""lstm_1"", 0, 0]]], ""name"": ""dropout_1""}, {""class_name"": ""InputLayer"", ""config"": {""batch_input_shape"": [null, 450], ""name"": ""input_1"", ""input_dtype"": ""int32""}, ""inbound_nodes"": [], ""name"": ""input_1""}, {""class_name"": ""RepeatVector"", ""config"": {""trainable"": true, ""name"": ""repeatvector_1"", ""n"": 450}, ""inbound_nodes"": [[[""dropout_1"", 0, 0]]], ""name"": ""repeatvector_1""}, {""class_name"": ""Merge"", ""config"": {""name"": ""merge_1"", ""concat_axis"": -1, ""mode_type"": ""raw"", ""dot_axes"": [-1, -1], ""mode"": ""concat"", ""output_shape"": null, ""output_shape_type"": ""raw""}, ""inbound_nodes"": [[[""repeatvector_1"", 0, 0], [""word_embeddings"", 1, 0]]], ""name"": ""merge_1""}, {""class_name"": ""LSTM"", ""config"": {""U_regularizer"": null, ""name"": ""lstm_2"", ""inner_activation"": ""hard_sigmoid"", ""go_backwards"": false, ""activation"": ""tanh"", ""trainable"": true, ""unroll"": false, ""consume_less"": ""cpu"", ""stateful"": false, ""init"": ""glorot_uniform"", ""inner_init"": ""orthogonal"", ""dropout_U"": 0.0, ""dropout_W"": 0.0, ""input_dim"": 500, ""return_sequences"": false, ""b_regularizer"": null, ""W_regularizer"": null, ""output_dim"": 200, ""forget_bias_init"": ""one"", ""input_length"": null}, ""inbound_nodes"": [[[""merge_1"", 0, 0]]], ""name"": ""lstm_2""}, {""class_name"": ""Dropout"", ""config"": {""p"": 0.3, ""trainable"": true, ""name"": ""dropout_2""}, ""inbound_nodes"": [[[""lstm_2"", 0, 0]]], ""name"": ""dropout_2""}, {""class_name"": ""Dense"", ""config"": {""W_constraint"": null, ""b_constraint"": null, ""name"": ""dense_1"", ""activity_regularizer"": null, ""trainable"": true, ""init"": ""glorot_uniform"", ""bias"": true, ""input_dim"": null, ""b_regularizer"": null, ""W_regularizer"": null, ""activation"": ""sigmoid"", ""output_dim"": 1}, ""inbound_nodes"": [[[""dropout_2"", 0, 0]]], ""name"": ""dense_1""}], ""input_layers"": [[""input_1"", 0, 0], [""input_2"", 0, 0]], ""output_layers"": [[""dense_1"", 0, 0]], ""name"": ""model_1""}}
```

Something seems to be going wrong when saving (or loading?) the model. Any ideas how to fix this?
",phdowling,None,2016-05-25T08:57:41Z,2016-05-25T23:35:20Z
2806,correctly serialize loss function (one liner),"This fixes a bug I introduced during review of #2690, which caused the loss function to be incorrectly serialized. 😞
",cmyr,None,2016-05-24T20:31:46Z,2016-05-25T04:27:57Z
2736,fix a bug in evaluating accuracy,"Correct me if I am wrong: I think the code in the current example:

```
def compute_accuracy(predictions, labels):
    '''Compute classification accuracy with a fixed threshold on distances.
    '''
    return labels[predictions.ravel() < 0.5].mean()
```

is not accuracy over all the samples, but over samples with negative prediction.
",llcao,None,2016-05-17T03:27:17Z,2016-12-19T22:54:22Z
2722,I think there's an bug in serialization of advaced activations,"after training the layers with ELU(advaced activation), I tried to save the model using model.to_json()

but I got an error message containing ""AttributeError: 'ELU' object has no attribute '**name**'""

I think model.to_json() method doesn't support for advanced activations
",ghost,None,2016-05-14T07:45:07Z,2016-05-21T20:31:10Z
2668,Shape and dimension issues with vectors representing text,"Hi, Can anyone help me with getting the shapes and dimension right when feeding vectors representing text to a CNN? 

The input vectors are 127 matrices, each of dimension 100 (token number) x 100 (vector representing the token as generated by word2vec). They are stored in a 3d numpy array. 

When doing the convolution layer, I first try:

```
Convolution2D(10, 3, 3, border_mode='same', input_shape=(100, 100))
```

which gives me:

Input 0 is incompatible with layer convolution2d_1: expected ndim=4, found ndim=3

The document tells me that 10 is the filter number and that from reading the tutorial on CNN:

http://cs231n.github.io/convolutional-networks/

2d convolution is possible for 2d input. 

I consider it a historical problem due to cnn being first used with images, which has a channel dimension. I add 1 dimension to input shape and assign it the value 1 to get rid of the error message, without being certain that it is the right thing to do. 

```
Convolution2D(10, 3, 3, border_mode='same', input_shape=(1, 100, 100))
```

But I cannot get very far. 

I cannot add a softmax activation layer, getting this error message. 

Exception: Cannot apply softmax to a tensor that is not 2D or 3D. Here, ndim=4

I need this activation layer to implement a cnn model mentioned in this paper:

http://arxiv.org/pdf/1508.01585v2.pdf

But for the time being, I skip it in order to proceed with debugging other parts of the program. 
Then another error comes up from the following: 

```
model.fit([leftData, rightData], labels, nb_epoch=10, batch_size=32)
```

The error message reads: Wrong number of dimensions: expected 3, got 2 with shape (32, 1)

It feels like whether I add or remove a dimension, I cannot make it fit the expectation of Keras on video/image data. 

Any advice would be appreciated. Thanks in advance. 

Please make sure that the boxes below are checked before you submit your issue. Thank you!
- [O ] Check that you are up-to-date with the master branch of Keras. You can update with:
  pip install git+git://github.com/fchollet/keras.git --upgrade --no-deps
- [O ] If running on Theano, check that you are up-to-date with the master branch of Theano. You can update with:
  pip install git+git://github.com/Theano/Theano.git --upgrade --no-deps
- [O ] Provide a link to a GitHub Gist of a Python script that can reproduce your issue (or just copy the script here if it is short).

https://github.com/mynlp/qa/commit/05ac682c91ee656e90f4ccd5ea85396ef13c45a3
",wailoktam,b'stale',2016-05-09T09:31:33Z,2017-06-22T21:10:49Z
2666,Error when trying to make prediction from loaded model.,"Problem appears when I save model to file, load it later, try to do prediction. Sample script: https://github.com/ternaus/kaggle_statefarm/blob/master/src/keras_bug.py

What script does:
[1] creates a model
[2] makes prediction (And it works)
[3] saves architecture and weights to files
[4] loads model from weights
[5] Tries to make prediction, but it does not work.

Here is output:

```
python keras_bug.py 
Using Theano backend.
Using gpu device 0: GeForce GTX 980 Ti (CNMeM is disabled, cuDNN 5004)
[[ 0.10087813  0.09831175  0.09730584  0.09975019  0.10368711  0.10139024
   0.09724771  0.10462044  0.09375019  0.1030584 ]]

Traceback (most recent call last):
  File ""keras_bug.py"", line 111, in <module>
    print model_new.predict(X_train)
  File ""/home/vladimir/anaconda2/lib/python2.7/site-packages/keras/models.py"", line 460, in predict
    return self.model.predict(x, batch_size=batch_size, verbose=verbose)
  File ""/home/vladimir/anaconda2/lib/python2.7/site-packages/keras/engine/training.py"", line 1125, in predict
    batch_size=batch_size, verbose=verbose)
  File ""/home/vladimir/anaconda2/lib/python2.7/site-packages/keras/engine/training.py"", line 845, in _predict_loop
    batch_outs = f(ins_batch)
  File ""/home/vladimir/anaconda2/lib/python2.7/site-packages/keras/backend/theano_backend.py"", line 518, in __call__
    return self.function(*inputs)
  File ""/home/vladimir/anaconda2/lib/python2.7/site-packages/theano/compile/function_module.py"", line 871, in __call__
    storage_map=getattr(self.fn, 'storage_map', None))
  File ""/home/vladimir/anaconda2/lib/python2.7/site-packages/theano/gof/link.py"", line 314, in raise_with_op
    reraise(exc_type, exc_value, exc_trace)
  File ""/home/vladimir/anaconda2/lib/python2.7/site-packages/theano/compile/function_module.py"", line 859, in __call__
    outputs = self.fn()
ValueError: dimension mismatch in args to gemm (1,4096)x(1000,10)->(1,10)
Apply node that caused the error: GpuDot22(GpuElemwise{Composite{Switch(i0, (Composite{(i0 + Abs(i0))}((i1 + i2)) * i3), (i4 * Composite{(i0 + Abs(i0))}((i1 + i2))))}}[(0, 1)].0, dense_4_W)
Toposort index: 301
Inputs types: [CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix)]
Inputs shapes: [(1, 4096), (1000, 10)]
Inputs strides: [(0, 1), (10, 1)]
Inputs values: ['not shown', 'not shown']
Outputs clients: [[GpuSoftmaxWithBias(GpuDot22.0, dense_4_b)]]

HINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.
HINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.

```
",ternaus,b'stale',2016-05-09T06:44:06Z,2017-06-22T22:13:53Z
2665,Bug or misunderstanding in keras  code example mnist_siamese_graph.py,"Hi  
   I am learning the keras code example mnist_siamese_graph.py. The Lambda layer in this example accepts two inputs from below layers, so I think  eucl_dist_output_shape function would also process a list of two corresponding input shapes.  Assume  input ""processed_a"" and processed_b have  shapes with (nsamples,dim)., then the input shape will be like [(nsamples,dim),(nsamples,dim)]
According to function method ""eucl_dist_output_shape(shapes)"", it will give a result (nsampels,dim). But actually, the result of eucl_dist is (nsamples,1). 
I am not sure whether I have a misunderstanding about Lambda layer's input.

---

1.distance = Lambda(euclidean_distance, output_shape=eucl_dist_output_shape)([processed_a, processed_b])
2.def eucl_dist_output_shape(shapes):
    shape1, shape2 = shapes
    return shape1
3.def euclidean_distance(vects):
    x, y = vects
    return K.sqrt(K.sum(K.square(x - y), axis=1, keepdims=True))
",cxfneo,b'stale',2016-05-09T06:27:42Z,2017-06-22T21:10:35Z
2656,"`repeat_elements(x, rep, axis)` incompatibility: in Theano rep=""int, scalar or tensor variable"", but TF rep must be ""int""","I'm trying to run some [Keras code that implement ""Stochastic Depth""](https://github.com/dblN/stochastic_depth_keras/blob/master/train.py) on TensorFlow. The original code runs on Theano, and when switching to TensorFlow I'm getting an error (note I have pulled the latest Keras commits):

```
Traceback (most recent call last):
...
  File ""~/git/keras/keras/backend/tensorflow_backend.py"", line 525, in repeat_elements
    x_rep = [s for s in splits for i in range(rep)]
TypeError: range() integer end argument expected, got Tensor.
```

The code that is breaking it is (where `x` is a collection of Keras layers built-up using the Functional API):

```
pad_shape = (1,16,80,60)
padding = K.zeros(pad_shape)
# logging.debug(K.shape(x))
# logging.debug(K.shape(x)[0])
padding = K.repeat_elements(padding, rep=K.shape(x)[0], axis=0)
```

Thus is looks like, the [Theano `repeat_elements`](https://github.com/fchollet/keras/blob/master/keras/backend/theano_backend.py#L300) (which I believe implements [this function from Theano](https://github.com/Theano/Theano/blob/master/theano/tensor/extra_ops.py#L861)) handles ""rep=int, scalar or tensor variable""; however the [TensorFlow `repeat_elements`](https://github.com/fchollet/keras/blob/master/keras/backend/tensorflow_backend.py#L515) doesn't.

I'm not particularly familiar with the TensorFlow API so I'm not sure if there already exists a similar `repeat` function to Theano. Otherwise, please can we implement the TensorFlow backend `repeat_elements` function to handle ""int, scalar or tensor variable"" like Theano? If it helps, when I uncomment my `logging.debug` code above I get Theano:

```
DEBUG:root:Shape.0
DEBUG:root:Subtensor{int64}.0
```

and TensorFlow:

```
DEBUG:root:Tensor(""Shape:0"", shape=(4,), dtype=int32)
DEBUG:root:Tensor(""Squeeze:0"", shape=(), dtype=int32)
```

Thanks!
",asmith26,b'stale',2016-05-07T17:41:43Z,2017-09-11T14:11:44Z
2627,How to debug nan in Keras,"Hi, I am working sequences similarity task following **Sentence Similarity Learning by Lexical Decomposition and Composition**[http://arxiv.org/abs/1602.07019]

I wrote a network like this.
![](https://raw.githubusercontent.com/3rduncle/DeepNLP/master/lexical_distance.png)

``` py
____________________________________________________________________________________________________
Layer (type)                       Output Shape        Param #     Connected to
====================================================================================================
a_input (InputLayer)               (None, 1072)        0
____________________________________________________________________________________________________
q_input (InputLayer)               (None, 33)          0
____________________________________________________________________________________________________
embedding_1 (Embedding)            (None, 33, 300)     768600      q_input[0][0]
                                                                   a_input[0][0]
____________________________________________________________________________________________________
semantic (Merge)                   (33, 1072)          0           embedding_1[0][0]
                                                                   embedding_1[1][0]
____________________________________________________________________________________________________
a_match (Merge)                    (1072, 300)         0           embedding_1[0][0]
                                                                   semantic[0][0]
____________________________________________________________________________________________________
q_match (Merge)                    (33, 300)           0           embedding_1[1][0]
                                                                   semantic[0][0]
____________________________________________________________________________________________________
a+ (Merge)                         (50, 1072, 300)     0           embedding_1[1][0]
                                                                   a_match[0][0]
____________________________________________________________________________________________________
q+ (Merge)                         (50, 33, 300)       0           embedding_1[0][0]
                                                                   q_match[0][0]
____________________________________________________________________________________________________
a- (Lambda)                        (50, 1072, 300)     0           a+[0][0]
____________________________________________________________________________________________________
q- (Lambda)                        (50, 33, 300)       0           q+[0][0]
____________________________________________________________________________________________________
a_conv (Convolution1D)             (50, 1070, 500)     450500      a-[0][0]
                                                                   a+[0][0]
____________________________________________________________________________________________________
q_conv (Convolution1D)             (50, 31, 500)       450500      q-[0][0]
                                                                   q+[0][0]
____________________________________________________________________________________________________
merge_1 (Merge)                    (50, 31, 500)       0           q_conv[0][0]
                                                                   q_conv[1][0]
____________________________________________________________________________________________________
merge_2 (Merge)                    (50, 1070, 500)     0           a_conv[0][0]
                                                                   a_conv[1][0]
____________________________________________________________________________________________________
activation_1 (Activation)          (50, 31, 500)       0           merge_1[0][0]
____________________________________________________________________________________________________
activation_2 (Activation)          (50, 1070, 500)     0           merge_2[0][0]
____________________________________________________________________________________________________
a_maxpool (Lambda)                 (50, 500)           0           activation_2[0][0]
____________________________________________________________________________________________________
q_maxpool (Lambda)                 (50, 500)           0           activation_1[0][0]
____________________________________________________________________________________________________
similar (Merge)                    (50, 1)             0           q_maxpool[0][0]
                                                                   a_maxpool[0][0]
====================================================================================================
Total params: 1669600
____________________________________________________________________________________________________
```

When training, I got nan loss and weights after some batches.
I debug with `mode=NanGuardMode(nan_is_error=True, inf_is_error=True)`. 

``` py
Traceback (most recent call last):
  File ""LexicalDistance.py"", line 252, in <module>
    nb_epoch=1,
  File ""/usr/local/lib/python2.7/site-packages/keras/engine/training.py"", line 1046, in fit
    callback_metrics=callback_metrics)
  File ""/usr/local/lib/python2.7/site-packages/keras/engine/training.py"", line 784, in _fit_loop
    outs = f(ins_batch)
  File ""/usr/local/lib/python2.7/site-packages/keras/backend/theano_backend.py"", line 507, in __call__
    return self.function(*inputs)
  File ""/usr/local/lib/python2.7/site-packages/theano/compile/function_module.py"", line 859, in __call__
    outputs = self.fn()
  File ""/usr/local/lib/python2.7/site-packages/theano/gof/link.py"", line 1014, in f
    raise_with_op(node, *thunks)
  File ""/usr/local/lib/python2.7/site-packages/theano/gof/link.py"", line 314, in raise_with_op
    reraise(exc_type, exc_value, exc_trace)
  File ""/usr/local/lib/python2.7/site-packages/theano/gof/link.py"", line 1012, in f
    wrapper(i, node, *thunks)
  File ""/usr/local/lib/python2.7/site-packages/theano/compile/nanguardmode.py"", line 302, in nan_check
    do_check_on(x[0], node, fn, True)
  File ""/usr/local/lib/python2.7/site-packages/theano/compile/nanguardmode.py"", line 272, in do_check_on
    raise AssertionError(msg)
AssertionError: Inf detected
Big value detected
NanGuardMode found an error in an input of this node.
Node:
Elemwise{Composite{((i0 * sqrt(clip((i1 - (i2 ** i3)), i4, i5))) / (i1 - (i6 ** i3)))}}(<TensorType(float32, scalar)>, TensorConstant{1.0}, <TensorType(float32, scalar)>, Elemwise{Add}[(0, 1)].0, TensorConstant{0.0}, TensorConstant{inf}, <TensorType(float32, scalar)>)
The input variable that cause problem:
Elemwise{Composite{((i0 * sqrt(clip((i1 - (i2 ** i3)), i4, i5))) / (i1 - (i6 ** i3)))}} [id A] ''
 |<TensorType(float32, scalar)> [id B]
 |TensorConstant{1.0} [id C]
 |<TensorType(float32, scalar)> [id D]
 |Elemwise{Add}[(0, 1)] [id E] ''
 | |TensorConstant{1.0} [id C]
 | |<TensorType(float32, scalar)> [id F]
 |TensorConstant{0.0} [id G]
 |TensorConstant{inf} [id H]
 |<TensorType(float32, scalar)> [id I]
```

I don't know the the exact meaning of this info. It seems error is division by zero.
All functions in Lambda Layers or Merge Layers are listed below. I can't fine where are the problems.

```
def semantic_matrix(argv):
    assert len(argv) == 2
    q = argv[0]
    a = argv[1]
    q_l2 = K.l2_normalize(q, axis=2)
    a_l2 = K.l2_normalize(a, axis=2)
    return K.batch_dot(q_l2, K.permute_dimensions(a_l2, [0,2,1]))

def match_matrix(argv, axis=0, w=3):
    assert len(argv) == 2
    o = argv[0]
    s = argv[1]
    idx = T.argmax(s, axis=2-axis)
    i0 = T.repeat(T.arange(idx.shape[0]), idx.shape[1]).flatten()
    i1 = idx.flatten()
    indexed = o[i0, i1, :]
    return indexed.reshape((idx.shape[0], idx.shape[1], o.shape[2]))

def parallel(source, target):
    einner_product = (source * target).sum(axis=2).reshape((source.shape[0],source.shape[1], 1))
    enorm = (target ** 2).sum(axis=2).reshape((source.shape[0],source.shape[1],1))
    response = target * (einner_product / enorm)
    return response

def compute_similar(source, target):
    normlized_source = K.l2_normalize(source, axis=1)
    normlized_target = K.l2_normalize(target, axis=1)
    return (normlized_source * normlized_target).sum(axis=1).reshape((source.shape[0], 1))
```

The problem may be in `semantic_matrix` and `compute_similar`, which compute the cosine similarity with inputs. I guest `K.l2_normalize` is not safe when passing a zero vector.
How to compute cosine distance over matrix in safe way?
thanks for any help.
",3rduncle,None,2016-05-05T14:40:47Z,2016-05-07T05:58:36Z
2616,Passing incorrect parameter names to RMSprop (and other optimizers) silently does nothing,"I just spent a while trying to hunt down a bug that turned out to be caused by passing `learning_rate` instead of `lr` to `RMSprop`. I'm not familiar enough with the internals of Keras to tell whether there's good reason for allowing any user specified arguments to pass through. It would, however, be nice to get an error message on invalid parameter names. 
",iskandr,None,2016-05-04T23:08:06Z,2016-05-05T01:31:21Z
2610,Convolution1D inconsistent with Convolution2D,"Convolution1D behaves differently from Convolution2D, e.g. the output shape are inconsistent. Shouldn't these two layers be equivalent for the following example?

```
from keras.models import Sequential
from keras.layers import Convolution1D, Convolution2D

model = Sequential()
model.add(Convolution2D(32, 1, 3, input_shape=(1, 1, 128)))
print(model.output_shape)  # -> (None, 32, 1, 126)

model = Sequential()
model.add(Convolution1D(32, 3, input_shape=(1, 128)))
print(model.output_shape)  # -> (None, -1, 32) instead of (None, 32, 126), which I would expect
```

Is this a bug or is there a reason for this that I don't understand?
",ricoj,b'stale',2016-05-04T14:30:11Z,2017-06-22T22:13:08Z
2594,"For temporal weights, Why y should be 3D?","Hi, if my understanding on the temporal output is correct. It generates a vector rather than a scalar for each example. Considering the number of example, the output should be (nsample, nstep), which should be 2D. In https://github.com/fchollet/keras/blob/master/keras/engine/training.py#L344, the checker seems to enforce y to be 3D, which seems strange to me. Also, the checker, `if sample_weight is not None and len(sample_weight.shape) != 2:` looks very reasonable, as the sample of sample_weight is (nsample, nstep). Shouldn't y have the same shape as sample_weight ?
In my own example:

```
model.compile(loss=_batched_binary_crossentropy, optimizer='adam', sample_weight_mode='temporal')
model.fit(x_train, y_train, sample_weight=w_train, batch_size=_args.batch_size, nb_epoch=_args.nepoch, validation_data=(x_dev, y_dev, w_dev))
```

The shape of x is not important, the shape of y is (nsample, nstep), which means the model predicts a vector with length nstep for each x. w is the weight matrix that have the same shape with y. When I did this. I got an error:

> Timestep-wise sample weighting (use of sample_weight_mode=""temporal"") is restricted to outputs that are at least 3D, i.e. that have a time dimension.

Is my understanding wrong on the temporal usage? Thanks!
Please make sure that the boxes below are checked before you submit your issue. Thank you!
- [Y] Check that you are up-to-date with the master branch of Keras. You can update with:
  pip install git+git://github.com/fchollet/keras.git --upgrade --no-deps
- [Y] If running on Theano, check that you are up-to-date with the master branch of Theano. You can update with:
  pip install git+git://github.com/Theano/Theano.git --upgrade --no-deps
- [  ] Provide a link to a GitHub Gist of a Python script that can reproduce your issue (or just copy the script here if it is short).
  Basically, it is a conceptual question, not a bug.
",wddabc,b'stale',2016-05-03T20:34:05Z,2018-02-28T05:09:41Z
2585,updated for list check bug in predict/predict_on_batch,"i think this will do it
",braingineer,None,2016-05-02T21:26:38Z,2016-05-02T22:33:26Z
2553,Bug? Differences between Graph() of version 0.3.3 and latest Keras API when I built Bidirectional GRU with two layers.,"Two problems happened when I used the latest Keras API.
1. After the model was trained, I saved the model architecture and weights. However, the reloaded model can't do prediction. Then I find I have to recompile a exactly same model and just loaded the weights. Actually, the model architecture can't be reloaded successfully. In addition, I didn't find such problem in 0.3.3.
   GRU_model = model_from_json(open('GRU_model_architecture.json').read()) # -->something wrong in source code?
   GRU_model.load_weights('GRU_model_weights.h5')
2. I built a Bidirectional GRU with two layers with the latest Keras API by the following codes. I find the results haven't been improved by comparing with the normal GRU model with one layer. However, it showed there are huge differences between the simple GRU and complex GRU models when I used the old version 0.3.3 by Graph(). In the latest version, have the model really compiled? No error was reported during running.  Bug or my bad coding..? 
   ### latest version
   
   def Bi_2l_GRU(self, X, Y, vec_dim, sent_length, first_output_dim, drop_percent, nepoch):
   
   ```
   inputs = Input(shape=(None, vec_dim), batch_shape=(1, None, vec_dim), name='inputs')
   layer1_out1 = GRU(sent_length, activation='tanh', return_sequences=True, dropout_U=drop_percent, dropout_W=drop_percent)(inputs)
   layer1_out2 = GRU(sent_length, activation='tanh', return_sequences=True, dropout_U=drop_percent, dropout_W=drop_percent, go_backwards=True)(inputs)
   layer1_loss = TimeDistributed(Dense(first_output_dim, activation='softmax'))(layer1_out1, layer1_out2)
   layer2_out1 = GRU(sent_length, activation='tanh', return_sequences=True, dropout_U=drop_percent, dropout_W=drop_percent)(layer1_loss)
   layer2_out2 = GRU(sent_length, activation='tanh', return_sequences=True, dropout_U=drop_percent, dropout_W=drop_percent, go_backwards=True)(layer1_loss)
   predictions = TimeDistributed(Dense(3, activation='softmax'))(layer2_out1, layer2_out2)
   model = Model(input=inputs, output=predictions)
   model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])
   
   for epoch in xrange(nepoch):
       print 'epoch:', epoch
       for idx, (seq, label) in enumerate(zip(X, Y)):
           #model.train_on_batch(np.array([seq]), np.array([label.T]))
           loss, accuracy = model.train_on_batch(np.array([seq]), np.array([label.T]))
           if idx % 50 == 0:
               print ""\tidx={0}, loss={1}, accuracy={2}"".format(idx, loss, accuracy)
   return model
   ```
### version 0.3.3

```
def Bi_2l_GRU(self, X, Y, vec_dim, HIDDEN_SIZE, nepoch):

    model = Graph()
    model.add_input(name='input', input_shape=(None, vec_dim))
    model.add_node(GRU(HIDDEN_SIZE, activation='tanh', return_sequences=True), name='forward', input='input')
    model.add_node(GRU(HIDDEN_SIZE, activation='tanh', return_sequences=True, go_backwards=True), name='backward', input='input')
    model.add_node(Dropout(0.5), name='dropout', merge_mode='concat', inputs=['forward', 'backward'])
    model.add_node(GRU(HIDDEN_SIZE, activation='tanh', return_sequences=True), name='level2_forward', input='dropout')
    model.add_node(GRU(HIDDEN_SIZE, activation='tanh', return_sequences=True, go_backwards=True), name='level2_backward', input='dropout')
    model.add_node(Dropout(0.5), name='level2_dropout', merge_mode='concat', inputs=['level2_forward', 'level2_backward'])
    model.add_node(TimeDistributed(Dense(3, activation='softmax')), name='softmax', input='level2_dropout')
    model.add_output(name='output', input='softmax')
    model.compile('adam', {'output': 'categorical_crossentropy'}, metrics=[""accuracy""])

    for epoch in xrange(nepoch):
        print 'epoch:', epoch
        for idx, (seq, label) in enumerate(zip(X, Y)):
            loss, accuracy = model.train_on_batch({'input':np.array([seq]), 'output':np.array([label.T])})
            if idx % 50 == 0:
                print ""\tidx={0}, loss={1}, accuracy={2}"".format(idx, loss, accuracy)
    return model
```
- [Yes ] Check that you are up-to-date with the master branch of Keras. You can update with:
  pip install git+git://github.com/fchollet/keras.git --upgrade --no-deps
- [ Yes] If running on Theano, check that you are up-to-date with the master branch of Theano. You can update with:
  pip install git+git://github.com/Theano/Theano.git --upgrade --no-deps
- [ Yes] Provide a link to a GitHub Gist of a Python script that can reproduce your issue (or just copy the script here if it is short).
",TwoScientists,b'stale',2016-04-29T08:25:05Z,2017-06-23T00:12:42Z
2546,loss computation with mask has a bug,"https://github.com/fchollet/keras/pull/2541

If you have for example time series output with a mask then current code multiply the loss by
1/mean(mask)
https://github.com/fchollet/keras/blob/master/keras/engine/training.py#L319
but this does not make much sense because different batches will have different scaling
and as a result a higher weight in training will be given to batches that happens by accident to have many short samples (i.e. a lot of zeros in their mask)
this also scales the reported loss by the same factor while you would expect the loss to be just the sum over all steps.

instead what you should do is first find out if any of the samples in the batch was unmasked.
In the case of time series this will happen in the rare case in which all the steps of a single sample had all mask elements set to 0.

you should then compute the mean of the entire batch but only on the samples which were masked.
For example by factoring by `1/mean(per_sample_mask)`
In most cases this will always be all samples so this bug had very little effect with this respect.

However the usage of mean in the past over `mask` entered a single batch scaling factor which is usually was > 1 so after the PR your loss values should drop by a big factor
",udibr,None,2016-04-28T13:07:09Z,2016-04-29T21:08:09Z
2541,fix bug in the way weighted objective is computed for time series mask,"this looks like a critical bug for anyone working with time series. So I'm surprised it didn't surfaced before. Maybe I'm missing something?

This PR does not fix an additional bug in this function which happens if using time series weights and mask together.

Also the line
        if weights is not None:
which appears just _after_ weights is used looks redundant (at best)
",udibr,None,2016-04-28T01:20:23Z,2016-04-30T23:52:27Z
2538,Exception's stacktrace is not properly propagated,"[`raise e`](https://github.com/fchollet/keras/blob/3779b8a008d199fe1f2ea0b05254a7d775500e5a/keras/engine/training.py#L1374) does not properly propagate the stacktrace of the exception. This makes debugging errors in the framework very painful.
",fvisin,b'stale',2016-04-27T22:37:53Z,2017-06-22T21:11:19Z
2508,Custom loss function leads to -inf loss,"hi,

I have my model compile with multiple loss functions including custom loss functions declared as follows:

> model.compile(optimizer='rmsprop', loss=['categorical_crossentropy','custom_loss'])

There are two problems I am facing:

1.) If I define this function locally inside my code file, I get 'invalid loss function' error. But if I change objective.py in the lib and add the custom function to it, the model is able to use it. Is this normal or is it supposed to be recognized even when I define it locally? Please let me know if I am missing something.

2.) When the model uses the function, it provides -inf values. Is there a way to debug why the loss is returned as -inf? I am sure that this custom loss function is causing the whole loss to be -inf. If either I remove the custom loss or change the definition of custom loss to something simple, it does not give -inf. 

Thanks
",code-ball,b'stale',2016-04-26T01:35:56Z,2017-06-22T21:11:12Z
2504,Added simple support for returning a multitarget loss,"Adds support for returning each target's loss as a metric. Couldn't find an easy way to do this with metrics without repeating all loss functions, and this is important to us for tuning our loss functions.

Feel free to reject or refactor, I know it's a feature and not a bugfix. Or maybe I'm just dumb and there's an easy way to do this (tried ""loss"" as the metric in the multi_output dictionary, didn't work, would have had to respecify each function by name)
",geohot,None,2016-04-25T19:30:34Z,2016-04-30T22:12:20Z
2482,Why this model can compile but can't run? (about dot product),"x1 = Input(shape=(3,))

x2 = Input(shape=(3,))

v1 = Reshape((3,1,))(x1)
v2 = Reshape((3,1,))(x2)

v = merge([v1, v2], mode='dot')

model = Model(input=[x1,x2], output=[v])

dummyData = np.random.random((1,3,))
xData = np.random.random((1,3,))

model.compile(loss='mse',
              optimizer='rmsprop')
# ans = model.predict([dummyData, xData])
# print(ans)

If I comment the last two lines, the code can compile. But If I run model.predict..., it'll get error.

---

ValueError                                Traceback (most recent call last)
<ipython-input-5-f74f98ef74d0> in <module>()
     21               optimizer='rmsprop')
     22 
---> 23 ans = model.predict([dummyData, xData])
     24 #print(ans)

C:\Users\xxx\AppData\Local\Continuum\Anaconda2\lib\site-packages\keras\engine\training.pyc in predict(self, x, batch_size, verbose)
   1111         f = self.predict_function
   1112         return self._predict_loop(f, ins,
-> 1113                                   batch_size=batch_size, verbose=verbose)
   1114 
   1115     def train_on_batch(self, x, y,

C:\Users\xxx\AppData\Local\Continuum\Anaconda2\lib\site-packages\keras\engine\training.pyc in _predict_loop(self, f, ins, batch_size, verbose)
    831                 ins_batch = slice_X(ins, batch_ids)
    832 
--> 833             batch_outs = f(ins_batch)
    834             if type(batch_outs) != list:
    835                 batch_outs = [batch_outs]

C:\Users\xxx\AppData\Local\Continuum\Anaconda2\lib\site-packages\keras\backend\theano_backend.pyc in **call**(self, inputs)
    497     def **call**(self, inputs):
    498         assert type(inputs) in {list, tuple}
--> 499         return self.function(*inputs)
    500 
    501 

C:\Users\xxx\AppData\Local\Continuum\Anaconda2\lib\site-packages\theano\compile\function_module.pyc in **call**(self, _args, *_kwargs)
    900                     node=self.fn.nodes[self.fn.position_of_error],
    901                     thunk=thunk,
--> 902                     storage_map=getattr(self.fn, 'storage_map', None))
    903             else:
    904                 # old-style linkers raise their own exceptions

C:\Users\xxx\AppData\Local\Continuum\Anaconda2\lib\site-packages\theano\gof\link.pyc in raise_with_op(node, thunk, exc_info, storage_map)
    312         # extra long error message in that case.
    313         pass
--> 314     reraise(exc_type, exc_value, exc_trace)
    315 
    316 

C:\Users\xxx\AppData\Local\Continuum\Anaconda2\lib\site-packages\theano\compile\function_module.pyc in **call**(self, _args, *_kwargs)
    887         try:
    888             outputs =\
--> 889                 self.fn() if output_subset is None else\
    890                 self.fn(output_subset=output_subset)
    891         except Exception:

ValueError: negative dimensions are not allowed
Apply node that caused the error: InplaceDimShuffle{0,1,2,-1}(Reshape{3}.0)
Toposort index: 9
Inputs types: [TensorType(float32, (False, False, True))]
Inputs shapes: [(1L, 3L, 1L)]
Inputs strides: [(12L, 4L, 4L)]
Inputs values: [array([[[ 0.27034158],
        [ 0.08950941],
        [ 0.12575579]]], dtype=float32)]
Outputs clients: [[Reshape{3}(InplaceDimShuffle{0,1,2,-1}.0, MakeVector{dtype='int64'}.0)]]

Backtrace when the node is created(use Theano flag traceback.limit=N to make it longer):
  File ""C:\Users\xxx\AppData\Local\Continuum\Anaconda2\lib\site-packages\IPython\core\interactiveshell.py"", line 3066, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File ""<ipython-input-5-f74f98ef74d0>"", line 12, in <module>
    v = merge([v1, v2], mode='dot')
  File ""C:\Users\xxx\AppData\Local\Continuum\Anaconda2\lib\site-packages\keras\engine\topology.py"", line 1442, in merge
    name=name)
  File ""C:\Users\xxx\AppData\Local\Continuum\Anaconda2\lib\site-packages\keras\engine\topology.py"", line 1118, in **init**
    self.add_inbound_node(layers, node_indices, tensor_indices)
  File ""C:\Users\xxx\AppData\Local\Continuum\Anaconda2\lib\site-packages\keras\engine\topology.py"", line 543, in add_inbound_node
    Node.create_node(self, inbound_layers, node_indices, tensor_indices)
  File ""C:\Users\xxx\AppData\Local\Continuum\Anaconda2\lib\site-packages\keras\engine\topology.py"", line 153, in create_node
    output_tensors = to_list(outbound_layer.call(input_tensors, mask=input_masks))
  File ""C:\Users\xxx\AppData\Local\Continuum\Anaconda2\lib\site-packages\keras\engine\topology.py"", line 1217, in call
    output = K.batch_dot(l1, l2, self.dot_axes)
  File ""C:\Users\xxx\AppData\Local\Continuum\Anaconda2\lib\site-packages\keras\backend\theano_backend.py"", line 146, in batch_dot
    out = T.batched_tensordot(x, y, axes=axes)

HINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.
",phu4ku,None,2016-04-24T06:57:00Z,2016-08-03T12:50:57Z
2444,sparse_categorical_crossentropy doesn't seem to be working,"[Here](https://gist.github.com/hr0nix/c7d56944e14b7a26349aa4113a879be3) is an example language model, that doesn't work with sparse_categorical_crossentropy. If one uncomments lines 25-26, running the script will result in the following error:

`Traceback (most recent call last):
  File ""./sparse_softmax_example.py"", line 34, in <module>
    main()
  File ""./sparse_softmax_example.py"", line 26, in main
    model.fit(input, output, batch_size=1, nb_epoch=1)
  File ""/place/home/hr0nix/src/text_features/env2/lib/python2.7/site-packages/keras/models.py"", line 402, in fit
    sample_weight=sample_weight)
  File ""/place/home/hr0nix/src/text_features/env2/lib/python2.7/site-packages/keras/engine/training.py"", line 1036, in fit
    callback_metrics=callback_metrics)
  File ""/place/home/hr0nix/src/text_features/env2/lib/python2.7/site-packages/keras/engine/training.py"", line 774, in _fit_loop
    outs = f(ins_batch)
  File ""/place/home/hr0nix/src/text_features/env2/lib/python2.7/site-packages/keras/backend/theano_backend.py"", line 499, in __call__
    return self.function(*inputs)
  File ""/place/home/hr0nix/src/text_features/env2/lib/python2.7/site-packages/theano/compile/function_module.py"", line 815, in __call__
    allow_downcast=s.allow_downcast)
  File ""/place/home/hr0nix/src/text_features/env2/lib/python2.7/site-packages/theano/tensor/type.py"", line 178, in filter
    data.shape))
TypeError: ('Bad input argument to theano function with name ""/place/home/hr0nix/src/text_features/env2/lib/python2.7/site-packages/keras/backend/theano_backend.py:495""  at index 1(0-based)', 'Wrong number of dimensions: expected 3, got 2 with shape (1, 2).')`

Lines 28-30 work just fine. Am I doing something wrong or is it a bug in keras codebase?
",hr0nix,b'stale',2016-04-21T09:40:52Z,2017-06-23T00:10:18Z
2415,"Input 0 is incompatible with layer dense_1: expected ndim=2, found ndim=3","Hi,

I am trying to merge three embedded layers by concatenation and then apply Dense Layer on the merged layer - very similar to multiple-input, multiple output example provided in Functional API section (except that I have three layers to be merged instead of two and I am merging the embedded input layers rather than an LSTM). 

The merge is happening fine but when I try to add the dense layer with an activation, I get the following error:

Exception: Input 0 is incompatible with layer dense_1: expected ndim=2, found ndim=3

Following is the relevant code excerpt:

```

> l1 = Input(shape = (1000,), dtype='int32', name = 'l1')
> e1 = Embedding(output_dim=60,input_dim=1000,input_length=1000) (l1)
> 
> l2 = Input(shape = (1000,), dtype='int32', name = 'l2')
> e2 = Embedding(output_dim=60,input_dim=1000,input_length=1000) (l2)
> 
> l3 = Input(shape = (20,), dtype='int32', name = 'l3')
> e3 = Embedding(output_dim=60,input_dim=20,input_length=20) (l3)
> 
> I = merge([e1,e2,e3], mode='concat',concat_axis=1)
> layer = Dense(60, activation = 'tanh') (I)

```

And following is the full error trace:

`File ""/home/.eclipse/org.eclipse.platform_4.5.1_1473617060_linux_gtk_x86_64/plugins/org.python.pydev_4.5.4.201601292234/pysrc/pydevd.py"", line 1524, in <module>
    globals = debugger.run(setup['file'], None, None, is_module)
  File ""/home/.eclipse/org.eclipse.platform_4.5.1_1473617060_linux_gtk_x86_64/plugins/org.python.pydev_4.5.4.201601292234/pysrc/pydevd.py"", line 931, in run
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File ""/home/.eclipse/org.eclipse.platform_4.5.1_1473617060_linux_gtk_x86_64/plugins/org.python.pydev_4.5.4.201601292234/pysrc/_pydev_imps/_pydev_execfile.py"", line 18, in execfile
    exec(compile(contents+""\n"", file, 'exec'), glob, loc)
  File ""/home/workspace/src/main.py"", line 75, in <module>
    relTP_model = relTP()
  File ""/home/workspace/src/main.py"", line 45, in relTP
    h_a = Dense(96, input_shape=(3,), activation = 'relu') (I)
  File ""/usr/local/lib/python3.4/dist-packages/keras/engine/topology.py"", line 441, in __call__
    self.assert_input_compatibility(x)
  File ""/usr/local/lib/python3.4/dist-packages/keras/engine/topology.py"", line 382, in assert_input_compatibility
    str(K.ndim(x)))`

I am not able to understand what is causing the error? Can someone please help me to resolve this?

Thanks
",code-ball,None,2016-04-20T06:46:51Z,2019-04-11T19:44:08Z
2397,Tensorflow backend - bug in model._make_predict_function(...),"There appears to be a bug in the make_predict_function for the tensorflow backend. The following error message appears for me when trying to call model.predict(...)

```
self._make_predict_function()
  File ""/usr/local/lib/python3.4/dist-packages/keras/engine/training.py"", line 679, in _make_predict_function
    **self._function_kwargs)
  File ""/usr/local/lib/python3.4/dist-packages/keras/backend/tensorflow_backend.py"", line 615, in function
    return Function(inputs, outputs, updates=updates)
  File ""/usr/local/lib/python3.4/dist-packages/keras/backend/tensorflow_backend.py"", line 589, in __init__
    with tf.control_dependencies(self.outputs):
  File ""/usr/local/lib/python3.4/dist-packages/tensorflow/python/framework/ops.py"", line 3192, in control_dependencies
    return get_default_graph().control_dependencies(control_inputs)
  File ""/usr/local/lib/python3.4/dist-packages/tensorflow/python/framework/ops.py"", line 2993, in control_dependencies
    c = self.as_graph_element(c)
  File ""/usr/local/lib/python3.4/dist-packages/tensorflow/python/framework/ops.py"", line 2291, in as_graph_element
    raise ValueError(""Tensor %s is not an element of this graph."" % obj)
ValueError: Tensor Tensor(""Sigmoid_2:0"", shape=(?, 17), dtype=float32) is not an element of this graph.
```

This does not happen when using the theano backend.

Notes: The model is loaded from json, and is defined as follows:

```
    seq1=Input(dtype='int32',shape=(400,),name='input_text')
    seq2=Input(dtype='int32',shape=(20,),name='input_titles')

    embeddeding=Embedding(max_features,embedding_dims,dropout=0.3)

    encoding_1=embeddeding(seq1)
    encoding_2=embeddeding(seq2)

    filter_lengths = [1,3,6]


    def max_1d(X):
        return K.max(X, axis=1)
    convs1=[]
    convs2=[]
    for fl in filter_lengths:

        conv1=Convolution1D(nb_filter=nb_filter,
                        filter_length=fl,
                        border_mode='valid',
                        activation='relu',
                        subsample_length=1)(encoding_1)
        conv1=Lambda(max_1d, output_shape=(nb_filter,))(conv1)
        convs1.append(conv1)

        conv2=Convolution1D(nb_filter=nb_filter,
                        filter_length=fl,
                        border_mode='valid',
                        activation='relu',
                        subsample_length=1)(encoding_2)
        conv2=Lambda(max_1d, output_shape=(nb_filter,))(conv2)
        convs2.append(conv2)

    m=merge([*convs1,*convs2],mode='concat')
    m=Highway(activation='relu')(m)
    m=Highway(activation='relu')(m)
    m=Dropout(0.5)(m)
    hovedkategori_loss=Dense(labsHovedKat.shape[1],activation='sigmoid',name='hovedkategori')(m)

    m1=merge([hovedkategori_loss,m],mode='concat')
    underkategori_loss=Dense(labsUnderKat.shape[1],activation='sigmoid',name='underkategori')(m1)

    model=Model(input=[seq1,seq2],output=[hovedkategori_loss,underkategori_loss])
    model.compile(optimizer='adam',loss='binary_crossentropy',metrics={'hovedkategori':'accuracy','underkategori':'accuracy'})
```
- [x] Check that you are up-to-date with the master branch of Keras. You can update with:
  pip install git+git://github.com/fchollet/keras.git --upgrade --no-deps
- [x] If running on Theano, check that you are up-to-date with the master branch of Theano. You can update with:
  pip install git+git://github.com/Theano/Theano.git --upgrade --no-deps
",Froskekongen,None,2016-04-19T09:08:30Z,2020-08-07T15:44:20Z
2385,How to correctly obtain TensorFlow tensors' shapes during runtime in order to infer output shapes?,"Hi,

We are trying to implement Convolution Transpose (Deconvolution) layer in Keras using TensorFlow conv2d_transpose (https://www.tensorflow.org/versions/r0.8/api_docs/python/nn.html#conv2d_transpose) basing on #2106 , but for arbitrary input sizes (without requirement to pass deconv_shape and filter shape as parameters).

conv2d_transpose requires explicit setting of output_shape, so we have to calculate it during runtime.
We've implemented it (see https://gist.github.com/lukovkin/610e18590f3d6138aa0bc6a6af414450), it compiles OK, but fails on training.
I've added some print statements for debugging (see below).
Probably we don't get tensors' shapes inference right.

> input_lenght: Tensor(""Squeeze_13:0"", shape=(), dtype=int32), filter_size: 2, border_mode: valid, stride: 2
> Output width:  Tensor(""add_20:0"", shape=(), dtype=int32)
> Input shape:  Tensor(""Shape_34:0"", shape=(3,), dtype=int32)
> Input shape after expand:  Tensor(""Shape_35:0"", shape=(4,), dtype=int32)
> Input shape after permute:  Tensor(""Shape_36:0"", shape=(4,), dtype=int32)
> Deconv shape:  Tensor(""pack_4:0"", shape=(4,), dtype=int32)
> Output shape:  Tensor(""Shape_37:0"", shape=(4,), dtype=int32)
> Output shape after permute:  Tensor(""Shape_38:0"", shape=(4,), dtype=int32)
> Output shape after squeeze:  Tensor(""Shape_39:0"", shape=(3,), dtype=int32)
> input_lenght: 5, filter_size: 2, border_mode: valid, stride: 2
> Output length:  9
> input_lenght: Tensor(""Squeeze_16:0"", shape=(), dtype=int32), filter_size: 2, border_mode: valid, stride: 2
> Output width:  Tensor(""add_22:0"", shape=(), dtype=int32)
> Input shape:  Tensor(""Shape_42:0"", shape=(3,), dtype=int32)
> Input shape after expand:  Tensor(""Shape_43:0"", shape=(4,), dtype=int32)
> Input shape after permute:  Tensor(""Shape_44:0"", shape=(4,), dtype=int32)
> Deconv shape:  Tensor(""pack_5:0"", shape=(4,), dtype=int32)
> Output shape:  Tensor(""Shape_45:0"", shape=(4,), dtype=int32)
> Output shape after permute:  Tensor(""Shape_46:0"", shape=(4,), dtype=int32)
> Output shape after squeeze:  Tensor(""Shape_47:0"", shape=(3,), dtype=int32)
> input_lenght: 9, filter_size: 2, border_mode: valid, stride: 2
> Output length:  17
> input_lenght: Tensor(""Squeeze_19:0"", shape=(), dtype=int32), filter_size: 2, border_mode: valid, stride: 2
> Output width:  Tensor(""add_24:0"", shape=(), dtype=int32)
> Input shape:  Tensor(""Shape_50:0"", shape=(3,), dtype=int32)
> Input shape after expand:  Tensor(""Shape_51:0"", shape=(4,), dtype=int32)
> Input shape after permute:  Tensor(""Shape_52:0"", shape=(4,), dtype=int32)
> Deconv shape:  Tensor(""pack_6:0"", shape=(4,), dtype=int32)
> Output shape:  Tensor(""Shape_53:0"", shape=(4,), dtype=int32)
> Output shape after permute:  Tensor(""Shape_54:0"", shape=(4,), dtype=int32)
> Output shape after squeeze:  Tensor(""Shape_55:0"", shape=(3,), dtype=int32)
> input_lenght: 17, filter_size: 2, border_mode: valid, stride: 2
> Output length:  33
> input_lenght: Tensor(""Squeeze_22:0"", shape=(), dtype=int32), filter_size: 2, border_mode: valid, stride: 2
> Output width:  Tensor(""add_26:0"", shape=(), dtype=int32)
> Input shape:  Tensor(""Shape_58:0"", shape=(3,), dtype=int32)
> Input shape after expand:  Tensor(""Shape_59:0"", shape=(4,), dtype=int32)
> Input shape after permute:  Tensor(""Shape_60:0"", shape=(4,), dtype=int32)
> Deconv shape:  Tensor(""pack_7:0"", shape=(4,), dtype=int32)
> Output shape:  Tensor(""Shape_61:0"", shape=(4,), dtype=int32)
> Output shape after permute:  Tensor(""Shape_62:0"", shape=(4,), dtype=int32)
> Output shape after squeeze:  Tensor(""Shape_63:0"", shape=(3,), dtype=int32)
> input_lenght: 33, filter_size: 2, border_mode: valid, stride: 2
> Output length:  65
> Before FIT
> ## Epoch 1/500
> 
> StatusNotOK                               Traceback (most recent call last)
> /root/miniconda2/envs/tf/lib/python3.4/site-packages/tensorflow/python/client/session.py in _do_call(self, fn, _args)
>     643     try:
> --> 644       return fn(_args)
>     645     except tf_session.StatusNotOK as e:
> 
> /root/miniconda2/envs/tf/lib/python3.4/site-packages/tensorflow/python/client/session.py in _run_fn(session, feed_dict, fetch_list, target_list, options, run_metadata)
>     627         return tf_session.TF_Run(
> --> 628             session, None, feed_dict, fetch_list, target_list, None)
>     629 
> 
> StatusNotOK: Invalid argument: Conv2DBackpropInput: Number of cols of out_backprop doesn't match computed: actual = 5, computed = 4
>    [[Node: conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format=""NHWC"", padding=""VALID"", strides=[1, 1, 2, 1], use_cudnn_on_gpu=true, _device=""/job:localhost/replica:0/task:0/cpu:0""](pack, convolution1d_transpose_arbitrary_1_W/read, transpose_18)]]
> 
> During handling of the above exception, another exception occurred:
> 
> InvalidArgumentError                      Traceback (most recent call last)
> <ipython-input-6-566ae3145e39> in <module>()
>       2 print(""Before FIT"")
>       3 
> ----> 4 model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epoch, verbose=1)
>       5 
>       6 score = model.evaluate(X_test, Y_test, verbose=0, batch_size=batch_size)
> 
> /root/miniconda2/envs/tf/lib/python3.4/site-packages/Keras-1.0.1-py3.4.egg/keras/models.py in fit(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, **kwargs)
>     400                               shuffle=shuffle,
>     401                               class_weight=class_weight,
> --> 402                               sample_weight=sample_weight)
>     403 
>     404     def evaluate(self, x, y, batch_size=32, verbose=1,
> 
> /root/miniconda2/envs/tf/lib/python3.4/site-packages/Keras-1.0.1-py3.4.egg/keras/engine/training.py in fit(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight)
>    1028                               verbose=verbose, callbacks=callbacks,
>    1029                               val_f=val_f, val_ins=val_ins, shuffle=shuffle,
> -> 1030                               callback_metrics=callback_metrics)
>    1031 
>    1032     def evaluate(self, x, y, batch_size=32, verbose=1, sample_weight=None):
> 
> /root/miniconda2/envs/tf/lib/python3.4/site-packages/Keras-1.0.1-py3.4.egg/keras/engine/training.py in _fit_loop(self, f, ins, out_labels, batch_size, nb_epoch, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics)
>     766                 batch_logs['size'] = len(batch_ids)
>     767                 callbacks.on_batch_begin(batch_index, batch_logs)
> --> 768                 outs = f(ins_batch)
>     769                 if type(outs) != list:
>     770                     outs = [outs]
> 
> /root/miniconda2/envs/tf/lib/python3.4/site-packages/Keras-1.0.1-py3.4.egg/keras/backend/tensorflow_backend.py in **call**(self, inputs)
>     595         feed_dict = dict(zip(names, inputs))
>     596         session = get_session()
> --> 597         updated = session.run(self.outputs + self.updates, feed_dict=feed_dict)
>     598         return updated[:len(self.outputs)]
>     599 
> 
> /root/miniconda2/envs/tf/lib/python3.4/site-packages/tensorflow/python/client/session.py in run(self, fetches, feed_dict, options, run_metadata)
>     338     try:
>     339       result = self._run(None, fetches, feed_dict, options_ptr,
> --> 340                          run_metadata_ptr)
>     341       if run_metadata:
>     342         proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)
> 
> /root/miniconda2/envs/tf/lib/python3.4/site-packages/tensorflow/python/client/session.py in _run(self, handle, fetches, feed_dict, options, run_metadata)
>     562     try:
>     563       results = self._do_run(handle, target_list, unique_fetches,
> --> 564                              feed_dict_string, options, run_metadata)
>     565     finally:
>     566       # The movers are no longer used. Delete them.
> 
> /root/miniconda2/envs/tf/lib/python3.4/site-packages/tensorflow/python/client/session.py in _do_run(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)
>     635     if handle is None:
>     636       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,
> --> 637                            target_list, options, run_metadata)
>     638     else:
>     639       return self._do_call(_prun_fn, self._session, handle, feed_dict,
> 
> /root/miniconda2/envs/tf/lib/python3.4/site-packages/tensorflow/python/client/session.py in _do_call(self, fn, *args)
>     657       # pylint: disable=protected-access
>     658       raise errors._make_specific_exception(node_def, op, error_message,
> --> 659                                             e.code)
>     660       # pylint: enable=protected-access
>     661 
> 
> InvalidArgumentError: Conv2DBackpropInput: Number of cols of out_backprop doesn't match computed: actual = 5, computed = 4
>    [[Node: conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format=""NHWC"", padding=""VALID"", strides=[1, 1, 2, 1], use_cudnn_on_gpu=true, _device=""/job:localhost/replica:0/task:0/cpu:0""](pack, convolution1d_transpose_arbitrary_1_W/read, transpose_18)]]
> Caused by op 'conv2d_transpose', defined at:
>   File ""/root/miniconda2/envs/tf/lib/python3.4/runpy.py"", line 170, in _run_module_as_main
>     ""__main__"", mod_spec)
>   File ""/root/miniconda2/envs/tf/lib/python3.4/runpy.py"", line 85, in _run_code
>     exec(code, run_globals)
>   File ""/root/miniconda2/envs/tf/lib/python3.4/site-packages/ipykernel/__main__.py"", line 3, in <module>
>     app.launch_new_instance()
>   File ""/root/miniconda2/envs/tf/lib/python3.4/site-packages/traitlets/config/application.py"", line 596, in launch_instance
>     app.start()
>   File ""/root/miniconda2/envs/tf/lib/python3.4/site-packages/ipykernel/kernelapp.py"", line 442, in start
>     ioloop.IOLoop.instance().start()
>   File ""/root/miniconda2/envs/tf/lib/python3.4/site-packages/zmq/eventloop/ioloop.py"", line 162, in start
>     super(ZMQIOLoop, self).start()
>   File ""/root/miniconda2/envs/tf/lib/python3.4/site-packages/tornado/ioloop.py"", line 883, in start
>     handler_func(fd_obj, events)
>   File ""/root/miniconda2/envs/tf/lib/python3.4/site-packages/tornado/stack_context.py"", line 275, in null_wrapper
>     return fn(_args, *_kwargs)
>   File ""/root/miniconda2/envs/tf/lib/python3.4/site-packages/zmq/eventloop/zmqstream.py"", line 440, in _handle_events
>     self._handle_recv()
>   File ""/root/miniconda2/envs/tf/lib/python3.4/site-packages/zmq/eventloop/zmqstream.py"", line 472, in _handle_recv
>     self._run_callback(callback, msg)
>   File ""/root/miniconda2/envs/tf/lib/python3.4/site-packages/zmq/eventloop/zmqstream.py"", line 414, in _run_callback
>     callback(_args, *_kwargs)
>   File ""/root/miniconda2/envs/tf/lib/python3.4/site-packages/tornado/stack_context.py"", line 275, in null_wrapper
>     return fn(_args, *_kwargs)
>   File ""/root/miniconda2/envs/tf/lib/python3.4/site-packages/ipykernel/kernelbase.py"", line 276, in dispatcher
>     return self.dispatch_shell(stream, msg)
>   File ""/root/miniconda2/envs/tf/lib/python3.4/site-packages/ipykernel/kernelbase.py"", line 228, in dispatch_shell
>     handler(stream, idents, msg)
>   File ""/root/miniconda2/envs/tf/lib/python3.4/site-packages/ipykernel/kernelbase.py"", line 391, in execute_request
>     user_expressions, allow_stdin)
>   File ""/root/miniconda2/envs/tf/lib/python3.4/site-packages/ipykernel/ipkernel.py"", line 199, in do_execute
>     shell.run_cell(code, store_history=store_history, silent=silent)
>   File ""/root/miniconda2/envs/tf/lib/python3.4/site-packages/IPython/core/interactiveshell.py"", line 2723, in run_cell
>     interactivity=interactivity, compiler=compiler, result=result)
>   File ""/root/miniconda2/envs/tf/lib/python3.4/site-packages/IPython/core/interactiveshell.py"", line 2825, in run_ast_nodes
>     if self.run_code(code, result):
>   File ""/root/miniconda2/envs/tf/lib/python3.4/site-packages/IPython/core/interactiveshell.py"", line 2885, in run_code
>     exec(code_obj, self.user_global_ns, self.user_ns)
>   File ""<ipython-input-5-0293a96e7d95>"", line 97, in <module>
>     model.add(Convolution1D_Transpose_Arbitrary(5, 2, strides=strides, padding=padding))
>   File ""/root/miniconda2/envs/tf/lib/python3.4/site-packages/Keras-1.0.1-py3.4.egg/keras/models.py"", line 139, in add
>     output_tensor = layer(self.outputs[0])
>   File ""/root/miniconda2/envs/tf/lib/python3.4/site-packages/Keras-1.0.1-py3.4.egg/keras/engine/topology.py"", line 485, in __call__
>     self.add_inbound_node(inbound_layers, node_indices, tensor_indices)
>   File ""/root/miniconda2/envs/tf/lib/python3.4/site-packages/Keras-1.0.1-py3.4.egg/keras/engine/topology.py"", line 543, in add_inbound_node
>     Node.create_node(self, inbound_layers, node_indices, tensor_indices)
>   File ""/root/miniconda2/envs/tf/lib/python3.4/site-packages/Keras-1.0.1-py3.4.egg/keras/engine/topology.py"", line 148, in create_node
>     output_tensors = to_list(outbound_layer.call(input_tensors[0], mask=input_masks[0]))
>   File ""../models/convolutional_transpose.py"", line 478, in call
>     output_shape=deconv_shape)
>   File ""/root/miniconda2/envs/tf/lib/python3.4/site-packages/tensorflow/python/ops/nn_ops.py"", line 104, in conv2d_transpose
>     name=name)
>   File ""/root/miniconda2/envs/tf/lib/python3.4/site-packages/tensorflow/python/ops/gen_nn_ops.py"", line 379, in conv2d_backprop_input
>     data_format=data_format, name=name)
>   File ""/root/miniconda2/envs/tf/lib/python3.4/site-packages/tensorflow/python/ops/op_def_library.py"", line 655, in apply_op
>     op_def=op_def)
>   File ""/root/miniconda2/envs/tf/lib/python3.4/site-packages/tensorflow/python/framework/ops.py"", line 2154, in create_op
>     original_op=self._default_original_op, op_def=op_def)
>   File ""/root/miniconda2/envs/tf/lib/python3.4/site-packages/tensorflow/python/framework/ops.py"", line 1154, in __init__
>     self._traceback = _extract_stack()

​

Please make sure that the boxes below are checked before you submit your issue. Thank you!
- [x] Check that you are up-to-date with the master branch of Keras. You can update with:
  pip install git+git://github.com/fchollet/keras.git --upgrade --no-deps
- [x] If running on Theano, check that you are up-to-date with the master branch of Theano. You can update with:
  pip install git+git://github.com/Theano/Theano.git --upgrade --no-deps
- [x] Provide a link to a GitHub Gist of a Python script that can reproduce your issue (or just copy the script here if it is short).
",lukovkin,None,2016-04-18T16:37:50Z,2016-04-19T09:25:41Z
2362,Implement HLSTM,"I know you would prefer a generic Highway layer, and I would quite like to help write one. I chose to start by implementing a Highway LSTM layer in order to get a feel for the problem and because I wanted to see if they really are as good as they are supposed to be.

**The HLSTM class is a copy of the LSTM class with a few additions.**
- `__init__()` takes a transform_bias parameter, with default value -2
- `build()` sets up the `W_carry` and `b_carry` weights arrays and adds them to the list of trainable weights
- `call()` calls the inherited `call` function to get the lstm's return value and combines it with the input according to the highway transformation

**One bug remains...**

It doesn't work if the layer's `input_dim` and `output_dim` are not the same. My linear algebra gets a little confused when there are more than two dimensions.

I notice the existing `Highway` layer doesn't even have an output_dim parameter. Is that a necessary feature of any Highway layer?
",jpeg729,None,2016-04-16T16:36:43Z,2016-04-18T09:34:29Z
2361,ImportError while fitting a Keras model,"Hi, I got an error while fitting a model on Keras 1.0 on Theano on Windows 10 x64. Previously, I can fit Keras models on Keras 0.6 with Theano 0.8-dev just fine. Here a simple Perceptron code to demonstrate the error while fitting:

```
model = Sequential()
model.add(Dense(64, input_dim=220, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(3, activation='softmax'))
model.compile(loss='categorical_crossentropy', optimizer='sgd')
# Fine

model.fit(X,y,nb_epoch=1)
# Error
```

```
---------------------------------------------------------------------------
ImportError                               Traceback (most recent call last)
<ipython-input-9-38fd95106b65> in <module>()
----> 1 model.fit(X, y, nb_epoch=1)

C:\Anaconda2\lib\site-packages\keras\models.pyc in fit(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, **kwargs)
    400                               shuffle=shuffle,
    401                               class_weight=class_weight,
--> 402                               sample_weight=sample_weight)

...........
(truncated for brevity)
...........

C:\Anaconda2\lib\site-packages\theano\gof\cmodule.pyc in compile_str(module_name, src_code, location, include_dirs, lib_dirs, libs, preargs, py_module, hide_symbols)
   2211             open(os.path.join(location, ""__init__.py""), 'w').close()
   2212             assert os.path.isfile(lib_filename)
-> 2213             return dlimport(lib_filename)

C:\Anaconda2\lib\site-packages\theano\gof\cmodule.pyc in dlimport(fullpath, suffix)
    297             warnings.filterwarnings(""ignore"",
    298                                     message=""numpy.ndarray size changed"")
--> 299             rval = __import__(module_name, {}, {}, [module_name])
    300         t1 = time.time()
    301         import_time += t1 - t0

ImportError: ('The following error happened while compiling the node', Dot22(dense_input_1, dense_2_W), '\n', 'DLL load failed: The specified module could not be found.', '[Dot22(dense_input_1, dense_2_W)]')
```

Is this a code regression in Keras or just another installation error? If so, any tips to debug it?

Thanks.

**Additional Info:**
- [x] Up-to-date with the master branch of Keras
- [x] Up-to-date with the master branch of Theano
- OS: Windows 10 x64
- Running on CPU
- Backend: Theano
- can import theano
",rilut,None,2016-04-16T16:30:47Z,2016-04-17T06:00:38Z
2308,fix non-trainable embedding bug,"fix bug, when embedding layer is untrainable, the weights should be added into self.non_trainable_weights
",xingdi-eric-yuan,None,2016-04-13T22:30:09Z,2016-04-14T00:59:37Z
2293,master branch seems not compatible ,"master branch seems not compatible with previous version's model dump file, when using json read the old model file, there's a bug
",fayeshine,None,2016-04-13T01:09:55Z,2016-04-13T03:22:24Z
2276,W_constraint in Embedding layer ignored during training,"I'm running the latest Keras 1.0 release from GitHub - here's a little snippet for reproducing the problem:

``` python
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import numpy as np

from keras.preprocessing import sequence
from keras.models import Sequential
from keras.layers.core import Dense, Activation, Flatten
from keras.layers.embeddings import Embedding
from keras.constraints import MaxNorm
from keras.datasets import imdb

(X_train, y_train), (X_test, y_test) = imdb.load_data(nb_words=500, test_split=0.05)

X_train = sequence.pad_sequences(X_train, maxlen=100)
X_test = sequence.pad_sequences(X_test, maxlen=100)


for norm_constraint in [None, MaxNorm(m=.001, axis=1)]:
    np.random.seed(1337)

    model = Sequential()

    model.add(Embedding(500, 10, input_length=100, W_constraint=norm_constraint))
    model.add(Flatten())
    model.add(Dense(1))
    model.add(Activation('sigmoid'))

    model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])
    model.fit(X_test, y_test, batch_size=32, nb_epoch=5, validation_data=(X_test, y_test), verbose=2)
```

As you can see, there are two training procedures: one without any constraint on the embeddings, and another one with a MaxNorm constraint.

However, there is no noticeable difference between the two training procedures:

``` bash
bugs$ ./constraints.py 
Using Theano backend.
Train on 1250 samples, validate on 1250 samples
Epoch 1/5
0s - loss: 0.6928 - acc: 0.5008 - val_loss: 0.6850 - val_acc: 0.6608
Epoch 2/5
0s - loss: 0.6846 - acc: 0.6480 - val_loss: 0.6773 - val_acc: 0.7448
Epoch 3/5
0s - loss: 0.6764 - acc: 0.7112 - val_loss: 0.6678 - val_acc: 0.7912
Epoch 4/5
0s - loss: 0.6664 - acc: 0.7736 - val_loss: 0.6561 - val_acc: 0.8208
Epoch 5/5
0s - loss: 0.6538 - acc: 0.7960 - val_loss: 0.6418 - val_acc: 0.8336
Train on 1250 samples, validate on 1250 samples
Epoch 1/5
0s - loss: 0.6928 - acc: 0.5008 - val_loss: 0.6850 - val_acc: 0.6608
Epoch 2/5
0s - loss: 0.6846 - acc: 0.6480 - val_loss: 0.6773 - val_acc: 0.7448
Epoch 3/5
0s - loss: 0.6764 - acc: 0.7112 - val_loss: 0.6678 - val_acc: 0.7912
Epoch 4/5
0s - loss: 0.6664 - acc: 0.7736 - val_loss: 0.6561 - val_acc: 0.8208
Epoch 5/5
0s - loss: 0.6538 - acc: 0.7960 - val_loss: 0.6418 - val_acc: 0.8336
```
",pminervini,None,2016-04-12T13:14:04Z,2016-04-12T16:29:12Z
2265,model.predict_classes fails on loaded models,"Version:

```
  Keras commit: df42e997b7d0f7c5e417c6a5a452c6ddd51e4c24 (Mon Apr 11 09:20:52 2016 -0700)
  Theano: 1efb15394850a1cf08c7e26eea6fec256634aa7a (Mon Apr 11 17:49:20 2016 -0400)
```

After saving a model arch and weights to disk, and then loading them, the loaded model errors out in using the predict_classes() function.

To reproduce,

```
# Modified version of the LSTM example from http://keras.io/getting-started/sequential-model-guide/
from keras.models import Sequential
from keras.layers import LSTM, Dense
import numpy as np
from keras.models import model_from_json
import keras


data_dim = 16
timesteps = 8
nb_classes = 10

# expected input data shape: (batch_size, timesteps, data_dim)
model = Sequential()
model.add(LSTM(32, return_sequences=True,
               input_shape=(timesteps, data_dim)))  # returns a sequence of vectors of dimension 32
model.add(LSTM(32, return_sequences=True))  # returns a sequence of vectors of dimension 32
model.add(LSTM(32))  # return a single vector of dimension 32
model.add(Dense(10, activation='softmax'))

model.compile(loss='categorical_crossentropy',
              optimizer='rmsprop',
              metrics=['accuracy'])

# generate dummy training data
x_train = np.random.random((1000, timesteps, data_dim))
y_train = np.random.random((1000, nb_classes))

# generate dummy validation data
x_val = np.random.random((100, timesteps, data_dim))
y_val = np.random.random((100, nb_classes))

model.fit(x_train, y_train,
          batch_size=64, nb_epoch=5,
          validation_data=(x_val, y_val))

# -- end example code here and start bug report code --
# test that the predict functions are working fine

c = model.predict_classes(x_val, batch_size=32, verbose=True)
d = model.predict_proba(x_val, batch_size=32, verbose=True)

# save model weights and arch to disk
model.save_weights(""./keras1.h5"", overwrite=True)
json_string = model.to_json()
with open(""keras1.json"", ""w"") as f:
    f.write(json_string)

print(""-- Read from file ---"")
jstring_from_file = open(""keras1.json"").read()
print(jstring_from_file)
model_from_file = model_from_json(jstring_from_file)
model_from_file.load_weights(""./keras1.h5"")
print(model_from_file.summary())
print(""-- predict classes --"")

model_from_file.predict_classes(x_val, batch_size=32, verbose=True)

```

Traceback

```
Traceback (most recent call last):
  File ""keras1.py"", line 53, in <module>
    model_from_file.predict_classes(x_val, batch_size=32, verbose=True)
  File ""/Users/viksit/miniconda2/envs/my-environment/lib/python2.7/site-packages/Keras-1.0.0-py2.7.egg/keras/models.py"", line 549, in predict_classes
    proba = self.predict(x, batch_size=batch_size, verbose=verbose)
  File ""/Users/viksit/miniconda2/envs/my-environment/lib/python2.7/site-packages/Keras-1.0.0-py2.7.egg/keras/models.py"", line 446, in predict
    return self.model.predict(x, batch_size=batch_size, verbose=verbose)
AttributeError: 'NoneType' object has no attribute 'predict'
```
",viksit,None,2016-04-11T23:24:00Z,2016-11-08T00:22:06Z
2259,Bug: Recurrent dropout fails silenty when set on loaded model,"Pretrained models are often finetuned on small datasets. For these use cases it can be relevant to add dropout to prevent overfitting. However, adding recurrent dropout to a loaded model (and recompiling the model) has no effect at all.

I've modified the `imdb_lstm` to demonstrate this. With recurrent dropout of 0.999, the model should not be able to learn anything, but it actually starts overfitting dramatically (it gets an accuracy of ~99% after 3 epochs). See the code below.

```
'''Train a LSTM on the IMDB sentiment classification task.

The dataset is actually too small for LSTM to be of any advantage
compared to simpler, much faster methods such as TF-IDF+LogReg.

Notes:

- RNNs are tricky. Choice of batch size is important,
choice of loss and optimizer is critical, etc.
Some configurations won't converge.

- LSTM loss decrease patterns during training can be quite different
from what you see with CNNs/MLPs/etc.

GPU command:
    THEANO_FLAGS=mode=FAST_RUN,device=gpu,floatX=float32 python imdb_lstm.py
'''

from __future__ import print_function
import numpy as np
np.random.seed(1337)  # for reproducibility

from keras.preprocessing import sequence
from keras.utils import np_utils
from keras.models import Sequential, model_from_yaml
from keras.layers.core import Dense, Dropout, Activation
from keras.layers.embeddings import Embedding
from keras.layers.recurrent import LSTM
from keras.datasets import imdb

max_features = 20000
maxlen = 100  # cut texts after this number of words (among top max_features most common words)
batch_size = 32

print('Loading data...')
(X_train, y_train), (X_test, y_test) = imdb.load_data(nb_words=max_features,
                                                      test_split=0.2)
print(len(X_train), 'train sequences')
print(len(X_test), 'test sequences')

print(""Pad sequences (samples x time)"")
X_train = sequence.pad_sequences(X_train, maxlen=maxlen)
X_test = sequence.pad_sequences(X_test, maxlen=maxlen)
print('X_train shape:', X_train.shape)
print('X_test shape:', X_test.shape)

print('Build model...')
model = Sequential()
model.add(Embedding(max_features, 128, input_length=maxlen))
model.add(LSTM(128))  # try using a GRU instead, for fun
model.add(Dropout(0.5))
model.add(Dense(1))
model.add(Activation('sigmoid'))

# try using different optimizers and different optimizer configs
model.compile(loss='binary_crossentropy',
              optimizer='adam',
              class_mode=""binary"")

print(""Train..."")
model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=3,
          validation_data=(X_test, y_test), show_accuracy=True)
score, acc = model.evaluate(X_test, y_test,
                            batch_size=batch_size,
                            show_accuracy=True)
print('Test score:', score)
print('Test accuracy:', acc)


print("""")
print('Saving weights.')

yaml_string = model.to_yaml()
open('imdb_lstm_config.yaml', 'w+').write(yaml_string)
model.save_weights('imdb_lstm_weights.h5', overwrite=True)

print('Reloading weights in new model with recurrent dropout.')
print("""")

loaded_model = model_from_yaml(open('imdb_lstm_config.yaml').read())
loaded_model.load_weights('imdb_lstm_weights.h5')
loaded_model.layers[0].dropout = 0.99
loaded_model.layers[1].dropout_U = 0.99
loaded_model.layers[1].dropout_W = 0.99

loaded_model.compile(loss='binary_crossentropy',
              optimizer='adam',
              class_mode=""binary"")

print(""Train..."")
loaded_model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=3,
                 validation_data=(X_test, y_test), show_accuracy=True)
score, acc = loaded_model.evaluate(X_test, y_test,
                                   batch_size=batch_size,
                                   show_accuracy=True)
print('Test score:', score)
print('Test accuracy:', acc)
```
",PiranjaF,None,2016-04-11T15:19:14Z,2016-04-16T19:18:36Z
2251,copy-paste bug in recurrent.py line 280 and 283,"I found the following bug. It's the reason one cannot use U_regularizer or b_regularizer with recurrent layers

```
        self.regularizers = []
        if self.W_regularizer:
            self.W_regularizer.set_param(self.W)
            self.regularizers.append(self.W_regularizer)
        if self.U_regularizer:
            self.W_regularizer.set_param(self.U)
            self.regularizers.append(self.U_regularizer)
        if self.b_regularizer:
            self.W_regularizer.set_param(self.b)
            self.regularizers.append(self.b_regularizer)
```
",BaldwinTheThird,None,2016-04-10T14:02:02Z,2016-04-10T14:46:26Z
2246,"text classification predict one sentence ,ValueError:Shape mismatch","I am a newer to keras, and  I use LTSM to text classification,here is my model:
`def train_lstm(n_symbols,embedding_weights,x_train,y_train,x_test,y_test):

```
print 'Defining a Simple Keras Model...' 
model = Sequential()  # or Graph or whatever
model.add(Embedding(output_dim=vocab_dim,
                    input_dim=n_symbols,
                    mask_zero=True,
                    weights=[embedding_weights],
                    input_length=input_length))  # Adding Input Length
model.add(LSTM(output_dim=50, activation='sigmoid', inner_activation='hard_sigmoid'))
model.add(Dropout(0.5))
model.add(Dense(1))
model.add(Activation('sigmoid'))

print 'Compiling the Model...' 
model.compile(loss='binary_crossentropy',
              optimizer='adam')

print ""Train..."" 
model.fit(x_train, y_train, batch_size=batch_size, nb_epoch=n_epoch,
          validation_data=(x_test, y_test),verbose=1, show_accuracy=True)
cPickle.dump(model,open(""./lstm_model.pkl"",""wb""))
print ""Evaluate..."" 
score, acc = model.evaluate(x_test, y_test,
                            batch_size=batch_size,
                            show_accuracy=True)
print 'Test score:', score 
print 'Test accuracy:', acc `
```

and the x_train shape is (16884, 100),y_train shape is (16884,);

I save the model and then load it to predict:
`model.predict(data)`
and the data shape is (1,100)

but I get the follow error:

`ValueError: Shape mismatch: x has 100 cols (and 1 rows) but y has 300 rows (and 64 cols)
Apply node that caused the error: Dot22(<TensorType(float32, matrix)>, dense_W)
Toposort index: 1
Inputs types: [TensorType(float32, matrix), TensorType(float32, matrix)]
Inputs shapes: [(1, 100), (300, 64)]
Inputs strides: [(400, 4), (256, 4)]
Inputs values: ['not shown', 'not shown']
Outputs clients: [[Elemwise{Composite{tanh((i0 + i1))}}[(0, 0)](Dot22.0, InplaceDimShuffle{x,0}.0)]]

HINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.
HINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.`
Sorry about my poor English,Thank you every much if anyone can help me !
",BUPTLdy,b'stale',2016-04-10T05:34:33Z,2017-06-23T00:11:06Z
2236,error when get the layer out of cnn model,"`featuer=K.function([model.layers[0].input],model.layers[21].get_output(train=False))
trainfeature=feature(X_train)`

then, it raised error assert type(inputs) in {list, tuple}  ,AssertionError
My X_train is float32,(380L,1L,160L,160L)

another question:
if i use `featuer=theano.function([model.layers[0].input],model.layers[21].get_output(train=False)),`
it raised error 
`
MemoryError: Error allocating 1189933056 bytes of device memory (out of memory).
Apply node that caused the error: GpuAllocEmpty(Shape_i{0}.0, Shape_i{0}.0, Elemwise{Composite{((i0 + i1) - i2)}}.0, Elemwise{Composite{((i0 + i1) - i2)}}.0)
Toposort index: 55
Inputs types: [TensorType(int64, scalar), TensorType(int64, scalar), TensorType(int64, scalar), TensorType(int64, scalar)]
Inputs shapes: [(), (), (), ()]
Inputs strides: [(), (), (), ()]
Inputs values: [array(382L, dtype=int64), array(32L, dtype=int64), array(156L, dtype=int64), array(156L, dtype=int64)]
Outputs clients: [[GpuDnnConv{algo='small', inplace=True}(GpuContiguous.0, GpuContiguous.0, GpuAllocEmpty.0, GpuDnnConvDesc{border_mode='valid', subsample=(1, 1), conv_mode='conv', precision='float32'}.0, Constant{1.0}, Constant{0.0})]]`
`Backtrace when the node is created(use Theano flag traceback.limit=N to make it longer):
  File ""C:\Users\Tori\Anaconda2\lib\site-packages\keras\layers\core.py"", line 679, in get_output
    X = self.get_input(train)
  File ""C:\Users\Tori\Anaconda2\lib\site-packages\keras\layers\core.py"", line 175, in get_input
    previous_output = self.previous.get_output(train=train)
  File ""C:\Users\Tori\Anaconda2\lib\site-packages\keras\layers\convolutional.py"", line 312, in get_output
    X = self.get_input(train)
  File ""C:\Users\Tori\Anaconda2\lib\site-packages\keras\layers\core.py"", line 175, in get_input
    previous_output = self.previous.get_output(train=train)
  File ""C:\Users\Tori\Anaconda2\lib\site-packages\keras\layers\core.py"", line 679, in get_output
    X = self.get_input(train)
  File ""C:\Users\Tori\Anaconda2\lib\site-packages\keras\layers\core.py"", line 175, in get_input
    previous_output = self.previous.get_output(train=train)
  File ""C:\Users\Tori\Anaconda2\lib\site-packages\keras\layers\convolutional.py"", line 317, in get_output
    filter_shape=self.W_shape)
  File ""C:\Users\Tori\Anaconda2\lib\site-packages\keras\backend\theano_backend.py"", line 610, in conv2d
    subsample=strides)`
`HINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.`

if you know the problem, plz tell me and thank you very much
",RukinoSaki,b'stale',2016-04-08T14:02:29Z,2017-06-23T00:11:02Z
2223,"dimension mismatch in args to gemm (64,121)x(121,100)->(64,121)","I have a dataset of size 84000x121 (image patches) and I want to train a autoencoder with single hidden layer. My architecture is 121 -> 100 -> 121 and use the hidden layer as features to train a regression model (say SVR).

```
import h5py
import scipy.io as sio
import numpy as np

from keras.models import Sequential
from keras.layers import containers
from keras.layers.core import Dense, AutoEncoder
from keras.activations import sigmoid
from keras.utils import np_utils
from keras.optimizers import SGD, RMSprop

# layer dimension
h1_dim = 100
input_dim = 121

# training data
data = sio.loadmat('../data/GBLUR_Patches.mat')
X_train = data['all_patches']
X_train = np.transpose(X_train)
# X_train = X_train.reshape(84000,h1_dim)

print np.shape(X_train)

# define model
model = Sequential()
encoder = containers.Sequential([Dense(output_dim=h1_dim, input_dim=input_dim)])
decoder = containers.Sequential([Dense(output_dim=input_dim, input_dim=h1_dim)])
model.add(AutoEncoder(encoder=encoder, decoder=decoder, output_reconstruction=False))

# optimizer 
rms = RMSprop(lr=0.001, rho=0.9, epsilon=1e-06)
model.compile(loss='mean_squared_error', optimizer=rms)

# fit model
model.fit(X_train, X_train, nb_epoch=10, batch_size=64, validation_data=None, verbose = 2, shuffle=True, show_accuracy = `False)
```

But when i train this model i'm getting the following error

Epoch 1/10
Traceback (most recent call last):
  File ""autoencoder_gblur.py"", line 38, in <module>
    model.fit(X_train, X_train, nb_epoch=10, batch_size=64, validation_data=None, verbose = 2, shuffle=True, show_accuracy = False)
  File ""/usr/local/lib/python2.7/dist-packages/Keras-0.3.3-py2.7.egg/keras/models.py"", line 701, in fit
    shuffle=shuffle, metrics=metrics)
  File ""/usr/local/lib/python2.7/dist-packages/Keras-0.3.3-py2.7.egg/keras/models.py"", line 317, in _fit
    outs = f(ins_batch)
  File ""/usr/local/lib/python2.7/dist-packages/Keras-0.3.3-py2.7.egg/keras/backend/theano_backend.py"", line 446, in __call__
    return self.function(*inputs)
  File ""/usr/local/lib/python2.7/dist-packages/theano/compile/function_module.py"", line 871, in **call**
    storage_map=getattr(self.fn, 'storage_map', None))
  File ""/usr/local/lib/python2.7/dist-packages/theano/gof/link.py"", line 314, in raise_with_op
    reraise(exc_type, exc_value, exc_trace)
  File ""/usr/local/lib/python2.7/dist-packages/theano/compile/function_module.py"", line 859, in **call**
    outputs = self.fn()
ValueError: dimension mismatch in args to gemm (64,121)x(121,100)->(64,121)
Apply node that caused the error: GpuGemm{inplace}(GpuFromHost.0, TensorConstant{1.0}, GpuFromHost.0, dense_W, TensorConstant{-1.0})
Toposort index: 15
Inputs types: [CudaNdarrayType(float32, matrix), TensorType(float32, scalar), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), TensorType(float32, scalar)]
Inputs shapes: [(64, 121), (), (64, 121), (121, 100), ()]
Inputs strides: [(121, 1), (), (121, 1), (100, 1), ()]
Inputs values: ['not shown', array(1.0, dtype=float32), 'not shown', 'not shown', array(-1.0, dtype=float32)]
Outputs clients: [[GpuElemwise{Add}[(0, 1)](GpuDimShuffle{x,0}.0, GpuGemm{inplace}.0)]]

HINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.
HINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.

Please anyone can help me with this.. 
",indra215,b'stale',2016-04-07T11:52:58Z,2017-06-23T00:10:57Z
2217,Bug fix to set correct uses_learning_phase flag,"`test_on_batch` and `predict_on_batch` had the wrong `uses_learning_phase` flag
",the-moliver,None,2016-04-06T23:22:23Z,2016-04-06T23:56:32Z
2209,Upcast to `float64` when using any RNN,"While debugging huge memory consumption issues, I stumbled that using any RNN with `return_sequences=False` (eg. SimpleRNN, GRU) results in an upcast to `float64`. Consequently everything that follows is also `float64` and memory consumption is increased. As stated in [Theano documentation](http://deeplearning.net/software/theano/faq.html#float32-int-32-64-gives-float64) any operation between `float32` or `int32`/`int64` results in `float64`.

Solution would probably be to cast all integers to `float32` to prevent unnecessary memory usage?

``` python
# Problem example that casts to float64
#   THEANO_FLAGS='floatX=float32,warn_float64=raise' python foo.py

import numpy as np
from keras.models import Sequential
from keras.layers import SimpleRNN, Dense

data_dim = 16
timesteps = 8
nb_classes = 10
batch_size = 32

model = Sequential()
model.add(SimpleRNN(nb_classes, return_sequences=False, batch_input_shape=(batch_size, timesteps, data_dim)))
#model.add(Dense(nb_classes, batch_input_shape=(batch_size, data_dim)))
model.compile(loss='categorical_crossentropy', optimizer='rmsprop')

# generate dummy training data
x_train = np.random.random((batch_size * 10, timesteps, data_dim)).astype(np.float32)
#x_train = np.random.random((batch_size * 10, data_dim)).astype(np.float32)
y_train = np.random.random((batch_size * 10, nb_classes)).astype(np.float32)

model.fit(x_train, y_train, batch_size=batch_size, nb_epoch=5)
```

Triggering the issue by raising Theano warnings for `float64` (latest Keras https://github.com/fchollet/keras/commit/b587aeee1c1be3633a56b945af3e7c2c303369ca, Theano 0.8.1):

``` bash
$ THEANO_FLAGS='floatX=float32,warn_float64=raise' python foo.py 
Using Theano backend.
ERROR (theano.gof.opt): Optimization failure due to: local_opt_alloc
ERROR (theano.gof.opt): node: Sum{axis=[1], acc_dtype=float64}(Alloc.0)
ERROR (theano.gof.opt): TRACEBACK:
ERROR (theano.gof.opt): Traceback (most recent call last):
  File ""/home/venv/local/lib/python2.7/site-packages/theano/gof/opt.py"", line 1772, in process_node
    replacements = lopt.transform(node)
  File ""/home/venv/local/lib/python2.7/site-packages/theano/tensor/opt.py"", line 5137, in local_opt_alloc
    val *= T.mul(*to_prod)
  File ""/home/venv/local/lib/python2.7/site-packages/theano/tensor/var.py"", line 240, in __rmul__
    return theano.tensor.basic.mul(other, self)
  File ""/home/venv/local/lib/python2.7/site-packages/theano/gof/op.py"", line 611, in __call__
    node = self.make_node(*inputs, **kwargs)
  File ""/home/venv/local/lib/python2.7/site-packages/theano/tensor/elemwise.py"", line 597, in make_node
    out_broadcastables)]
  File ""/home/venv/local/lib/python2.7/site-packages/theano/gof/type.py"", line 400, in __call__
    return utils.add_tag_trace(self.make_variable(name))
  File ""/home/venv/local/lib/python2.7/site-packages/theano/tensor/type.py"", line 431, in make_variable
    return self.Variable(self, name=name)
  File ""/home/venv/local/lib/python2.7/site-packages/theano/tensor/var.py"", line 762, in __init__
    raise Exception(msg)
Exception: You are creating a TensorVariable with float64 dtype. You requested an action via the Theano flag warn_float64={ignore,warn,raise,pdb}.

ERROR (theano.gof.opt): Optimization failure due to: local_opt_alloc
ERROR (theano.gof.opt): node: Sum{axis=[1], acc_dtype=float64}(Alloc.0)
...
Exception: You are creating a TensorVariable with float64 dtype. You requested an action via the Theano flag warn_float64={ignore,warn,raise,pdb}.

Epoch 1/5
320/320 [==============================] - 0s - loss: 25.0333     
Epoch 2/5
320/320 [==============================] - 0s - loss: 23.8539     
Epoch 3/5
320/320 [==============================] - 0s - loss: 23.5233     
Epoch 4/5
320/320 [==============================] - 0s - loss: 23.4157     
Epoch 5/5
320/320 [==============================] - 0s - loss: 23.3869
$
```

It seems there is some multiplication between a constant `float32` and `int64` happening:

```
(Pdb) self
<theano.tensor.elemwise.Elemwise object at 0x7faefc245a90>
(Pdb) inputs
[TensorConstant{0.0}, Elemwise{mul,no_inplace}.0]
(Pdb) inputs[0].type
TensorType(float32, scalar)
(Pdb) inputs[1].type
TensorType(int64, scalar)
```
",gw0,None,2016-04-06T12:43:54Z,2016-11-24T16:06:12Z
2187,Can't compile Bidirectional LSTM with Theano 8.1,"```
from keras.models import Graph
from keras.layers.core import Dense
from keras.layers.recurrent import LSTM   

model = Graph()
model.add_input(name='input', input_shape=(1, 30)) 

model.add_node(LSTM(100, return_sequences=False), name='forward', input='input')
model.add_node(LSTM(100, return_sequences=False, go_backwards=True), name='backward', input='input')

model.add_node(Dense(12, activation='sigmoid'), name='sigmoid', inputs=['forward','backward'])
model.add_output(name='output', input='sigmoid')

model.compile(optimizer='Adam', loss={'output': 'categorical_crossentropy'})
```

The code throws a series of errors like this: 

```
<<!! BUG IN FGRAPH.REPLACE OR A LISTENER !!>> <type 'exceptions.TypeError'> ('The type of the replacement must be compatible with the type of the original Variable.', Subtensor{:int64:}.0, Subtensor{int64:int64:int64}.0, TensorType(float32, (True, False, False)), TensorType(float32, 3D), 'local_subtensor_merge') local_subtensor_merge
ERROR (theano.gof.opt): Optimization failure due to: local_subtensor_merge
ERROR (theano.gof.opt): node: Subtensor{:int64:}(Subtensor{::int64}.0, ScalarFromTensor.0)
ERROR (theano.gof.opt): TRACEBACK:
ERROR (theano.gof.opt): Traceback (most recent call last):
  File ""/usr/local/lib/python2.7/dist-packages/theano/gof/opt.py"", line 1807, in process_node
    fgraph.replace_all_validate(repl_pairs, reason=lopt)
  File ""/usr/local/lib/python2.7/dist-packages/theano/gof/toolbox.py"", line 309, in replace_all_validate
    fgraph.replace(r, new_r, reason=reason, verbose=False)
  File ""/usr/local/lib/python2.7/dist-packages/theano/gof/fg.py"", line 561, in replace
    str(reason))
TypeError: ('The type of the replacement must be compatible with the type of the original Variable.', Subtensor{:int64:}.0, Subtensor{int64:int64:int64}.0, TensorType(float32, (True, False, False)), TensorType(float32, 3D), 'local_subtensor_merge')
```

removing `go_backwards=True` the model compiles. 
",fio710,None,2016-04-04T19:29:10Z,2016-09-13T07:51:54Z
2160,Bugs in save and load weights,"I want to train a model with parts of parameters fixed. When I tried to load saved weights from the HDF5 file, it fails. It seems the saveweight function does not save none-trainable weights, while loadweight function requires them. See example code below:

<pre><code>
from keras.models import Sequential
from keras.layers.core import Merge
from keras.layers.convolutional import Convolution2D


model_range_5 = Sequential()
model_range_5.add(Convolution2D(128,5,5,dim_ordering='tf',activation='relu',border_mode='same',input_shape=(256,200,3),trainable=False))

model_range_4 = Sequential()
model_range_4.add(Convolution2D(128,5,5,dim_ordering='tf',activation='relu',border_mode='same',input_shape=(256,200,3)))


test_model = Sequential([Merge([model_range_5,model_range_4])])

test_model.compile(optimizer='SGD',loss='mse')
test_model.save_weights('weight.model',overwrite=True)
test_model.load_weights('weight.model')
</code></pre>
",tanxchong,b'stale',2016-04-01T15:13:06Z,2019-12-12T18:21:45Z
2159,EarlyStopping not working properly ,"```
from keras.callbacks import EarlyStopping  
early_stopping =EarlyStopping(monitor='value_loss', patience=100)  

history = model.fit(X_train, Y_train, nb_epoch=2000, batch_size=4, show_accuracy=True, verbose=2,
                     callbacks=[early_stopping])
```

it always stop when patience number reached. then i went to debug and found
in callbacks.py
logs is always empty when on_epoch_end in was called.
so value current is always null, training will always stop when patience number reached.
but logs isn't empty when on_batch_begin/end was called.  will logs reset before on_epoch_end was called?

Do I miss something?     

```
def on_epoch_end(self, epoch, logs={}):
        current = logs.get(self.monitor)  
        if current is None:
            warnings.warn('Early stopping requires %s available!' %
                          (self.monitor), RuntimeWarning)

        if self.monitor_op(current, self.best):   # current is [] , self.wait never been reset to 0
            self.best = current
            self.wait = 0   
        else:
            if self.wait >= self.patience:
                if self.verbose > 0:
                    print('Epoch %05d: early stopping' % (epoch))
                self.model.stop_training = True
            self.wait += 1


```
",yanje03,b'stale',2016-04-01T06:10:23Z,2018-02-19T15:59:26Z
2152,Keras 1.0 preview,"This is a near-total rewriting of the Keras codebase, still undergoing but already 95% complete. It will not be merged into master, rather it will replace master, which means that the merged PRs from the past two weeks will need to be backported.

Some notes:
- this introduces the functional API and deprecates the `Graph` model. See `docs/templates/complete_guide_to_the_keras_functional_api.md` for an (as of yet incomplete) introduction. You can also check out the unit tests `tests/keras/engine/test_topology.py`.
- this introduces modular metrics, including the ability to monitor arbitrary lists of metrics on arbitrary outputs of a multi-output model.
- this introduces support for multi-input and multi-output layers.
- this improves RNNs by providing 4 different implementations to choose from in Theano and 2 different implementations in TensorFlow, each with a different memory/cpu profile. This will allow users to have fast RNNs across very different setups and tasks.
- this improves `Lambda`.
- and much more.

What works at the current time:
- everything, modulo a few things that were overlooked and a few potentially remaining bugs (only one is currently known, fix pending). All examples are running, and the following tests are passing: `test_topology` (functional API test), `test_sequential`, `test_graph`, all integration tests...

TODO:
- backport recent modifications from master into `keras-1`
- rewrite unit tests. In the process of getting them to pass, some bugs will have to be fixed (the set of tests that are passing is already very extensive, so the bugs should be few and minor).
- rewrite documentation.

Get involved:
You can take a look at unit tests.
All further PRs to Keras should be made to the present branch, not to master.
",fchollet,None,2016-03-31T19:03:56Z,2016-04-11T17:31:46Z
2141,Bug in loading the reuters dataset,"There is possibly a bug in the loading of the reuters dataset.

In the data loading section, specifically, 

(X_train, y_train), (X_test, y_test) = reuters.load_data(nb_words=max_words, test_split=0.2)

I get the following ValueError. 

---

ValueError                                Traceback (most recent call last)
<ipython-input-11-20dbe1cbaee1> in <module>()
      1 print('Loading data...')
----> 2 (X_train, y_train), (X_test, y_test) = reuters.load_data(nb_words=max_words, test_split=0.2)
      3 print(len(X_train), 'train sequences')
      4 print(len(X_test), 'test sequences')

/home/debo/.conda/envs/flowers/lib/python2.7/site-packages/keras/datasets/reuters.pyc in load_data(path, nb_words, skip_top, maxlen, test_split, seed, start_char, oov_char, index_from)
     13     path = get_file(path, origin=""https://s3.amazonaws.com/text-datasets/reuters.pkl"")
     14     f = open(path, 'rb')
---> 15     X, labels = cPickle.load(f)
     16     f.close()
     17 

ValueError: could not convert string to int

I checked with the imdb dataset, and the following works:

(X_train, y_train), (X_test, y_test) = imdb.load_data(nb_words=max_features,
                                                      test_split=0.5)
",debajyotidatta,None,2016-03-31T01:08:30Z,2016-11-28T00:50:43Z
2138,BatchNormalization not using the runningMean and Var when Train is True,"In the title ^^
I'm not sure whether this is a bug or an intended behaviour, but it looks strange because it would mean that when the example are streamed one at a time they wouldn't get normalized at all, during training.

I would recommend outputting something like (1/momentum) / ((1/momentum)+minibatchsize) \* runningMean + (minibatchsize)/((1/momentum)+minibatchsize) \* meanofminibatch

Below is the problematic code in get_output of BatchNormalization
if train:
                m = K.mean(X, axis=reduction_axes)
                brodcast_m = K.reshape(m, broadcast_shape)
                std = K.mean(K.square(X - brodcast_m) + self.epsilon, axis=reduction_axes)
                std = K.sqrt(std)
                brodcast_std = K.reshape(std, broadcast_shape)
                mean_update = self.momentum \* self.running_mean + (1-self.momentum) \* m
                std_update = self.momentum \* self.running_std + (1-self.momentum) \* std
                self.updates = [(self.running_mean, mean_update),
                                (self.running_std, std_update)]
                X_normed = (X - brodcast_m) / (brodcast_std + self.epsilon)
",unrealwill,None,2016-03-30T18:07:09Z,2016-03-31T11:36:09Z
2124,CUDNN_STATUS_MAPPING_ERROR,"Hello,

I have a larger Graph-Model that runs fine with a sequence_length of 500 . If I change the sequence_length to 5000, I get a CUDNN_STATUS_MAPPING_ERROR. I tried it twice, and the error happens at exactly the same iteration, stacktrace is below.

The GPU is a Titan X with 12. GB Memory

What can I do to trace the error further?

Thanks, Ernst

Epoch 4096/10000
1/2 [==============>...............] - ETA: 2s - loss: 0.3742Traceback (most recent call last):
  File ""/home/ernst/anaconda2/envs/anaconda3/lib/python3.5/site-packages/Theano-0.8.0.dev0-py3.5.egg/theano/compile/function_module.py"", line 859, in **call**
    outputs = self.fn()
RuntimeError: GpuDnnConvGradI: error doing operation: CUDNN_STATUS_MAPPING_ERROR

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""UFCNN1_5000.py"", line 977, in <module>
    nb_epoch=epoch)
  File ""/home/ernst/anaconda2/envs/anaconda3/lib/python3.5/site-packages/Keras-0.3.2-py3.5.egg/keras/models.py"", line 1795, in fit_generator
    accuracy=show_accuracy)
  File ""/home/ernst/anaconda2/envs/anaconda3/lib/python3.5/site-packages/Keras-0.3.2-py3.5.egg/keras/models.py"", line 1475, in train_on_batch
    return self._train(ins)
  File ""/home/ernst/anaconda2/envs/anaconda3/lib/python3.5/site-packages/Keras-0.3.2-py3.5.egg/keras/backend/theano_backend.py"", line 450, in __call__
    return self.function(*inputs)
  File ""/home/ernst/anaconda2/envs/anaconda3/lib/python3.5/site-packages/Theano-0.8.0.dev0-py3.5.egg/theano/compile/function_module.py"", line 871, in **call**
    storage_map=getattr(self.fn, 'storage_map', None))
  File ""/home/ernst/anaconda2/envs/anaconda3/lib/python3.5/site-packages/Theano-0.8.0.dev0-py3.5.egg/theano/gof/link.py"", line 314, in raise_with_op
    reraise(exc_type, exc_value, exc_trace)
  File ""/home/ernst/anaconda2/envs/anaconda3/lib/python3.5/site-packages/six.py"", line 685, in reraise
    raise value.with_traceback(tb)
  File ""/home/ernst/anaconda2/envs/anaconda3/lib/python3.5/site-packages/Theano-0.8.0.dev0-py3.5.egg/theano/compile/function_module.py"", line 859, in **call**
    outputs = self.fn()
RuntimeError: GpuDnnConvGradI: error doing operation: CUDNN_STATUS_MAPPING_ERROR
Apply node that caused the error: GpuDnnConvGradI{algo='time_once', inplace=True}(GpuContiguous.0, GpuContiguous.0, GpuAllocEmpty.0, GpuDnnConvDesc{border_mode='full', subsample=(1, 1), conv_mode='conv', precision='float32'}.0, Constant{1.0}, Constant{0.0})
Toposort index: 283
 Inputs types: [CudaNdarrayType(float32, 4D), CudaNdarrayType(float32, 4D), CudaNdarrayType(float32, (False, False, False, True)), <theano.gof.type.CDataType object at 0x7fba712634a8>, Scalar(float32), Scalar(float32)]
Inputs shapes: [(3, 150, 5000, 1), (1, 3, 58460, 1), (1, 150, 53461, 1), 'No shapes', (), ()]
Inputs strides: [(750000, 5000, 1, 0), (0, 58460, 1, 0), (0, 53461, 1, 0), 'No strides', (), ()]
Inputs values: ['not shown', 'not shown', 'not shown', <capsule object NULL at 0x7fba5a029390>, 1.0, 0.0]
Inputs name: ('kernel', 'grad', 'output', 'descriptor', 'alpha', 'beta')

Outputs clients: [[GpuDimShuffle{0,1,2,x}(GpuDnnConvGradI{algo='time_once', inplace=True}.0)]]

HINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.
HINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.
",ErnstTmp,None,2016-03-29T19:17:38Z,2018-11-07T23:39:58Z
2111,Bug: input_shape error for advanced activations,"I just updated Keras and my code stopped functioning due to the error:

`Exception: Layer is not connected. Did you forget to set ""input_shape""?`

Note that my code was running minutes ago before updating Keras. After trying a lot, I found out that by replacing all `LeakyReLU()` by `'relu'`, the error gets resolved. So, I reproduced this issue on the `mnist_cnn.py` script in Keras Examples folder. Even more bizarre phenomena is that if you put some random `input_shape` values, you will be able to get the code compiled. If this was not the case, it would have been at least acceptable, since for each activation layer, user is forced to calculate the **correct** input shape. However, now this behavior is susceptible to user errors.

Script to reproduce the issue: 

```
from __future__ import print_function
import numpy as np
np.random.seed(1337)  # for reproducibility

from keras.datasets import mnist
from keras.models import Sequential
from keras.layers.core import Dense, Dropout, Activation, Flatten
from keras.layers.convolutional import Convolution2D, MaxPooling2D
from keras.utils import np_utils

batch_size = 128
nb_classes = 10
nb_epoch = 12

# input image dimensions
img_rows, img_cols = 28, 28
# number of convolutional filters to use
nb_filters = 32
# size of pooling area for max pooling
nb_pool = 2
# convolution kernel size
nb_conv = 3

# the data, shuffled and split between train and test sets
(X_train, y_train), (X_test, y_test) = mnist.load_data()

X_train = X_train.reshape(X_train.shape[0], 1, img_rows, img_cols)
X_test = X_test.reshape(X_test.shape[0], 1, img_rows, img_cols)
X_train = X_train.astype('float32')
X_test = X_test.astype('float32')
X_train /= 255
X_test /= 255
print('X_train shape:', X_train.shape)
print(X_train.shape[0], 'train samples')
print(X_test.shape[0], 'test samples')

# convert class vectors to binary class matrices
Y_train = np_utils.to_categorical(y_train, nb_classes)
Y_test = np_utils.to_categorical(y_test, nb_classes)

model = Sequential()

model.add(Convolution2D(nb_filters, nb_conv, nb_conv,
                        border_mode='valid',
                        input_shape=(1, img_rows, img_cols)))
model.add(Activation(LeakyReLU()))
model.add(Convolution2D(nb_filters, nb_conv, nb_conv))
model.add(Activation(LeakyReLU()))
model.add(MaxPooling2D(pool_size=(nb_pool, nb_pool)))
model.add(Dropout(0.25))

model.add(Flatten())
model.add(Dense(128))
model.add(Activation(LeakyReLU()))
model.add(Dropout(0.5))
model.add(Dense(nb_classes))
model.add(Activation('softmax'))

model.compile(loss='categorical_crossentropy', optimizer='adadelta')

model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epoch,
          show_accuracy=True, verbose=1, validation_data=(X_test, Y_test))
score = model.evaluate(X_test, Y_test, show_accuracy=True, verbose=0)
print('Test score:', score[0])
print('Test accuracy:', score[1])
```

To make the above script work(?), replace `LeakyReLU()` by `LeakyReLU(input_shape=(20,20,20))`. Its quite obvious that these numbers (20, 20, 20) are random and code works as long as you put some value.

I think this is a serious bug and should be addressed as soon as possible. @fchollet 
",parag2489,b'stale',2016-03-29T05:58:56Z,2017-06-22T21:10:21Z
2071,class_weight,"Hello,
I am trying to add a class weight to a graph model that is fitted by a generator. I have 3 classes, and the occurrence of the classes are in a ratio of 1:1:10. Whatever class_weight I chose, result is identical: only class 2 is chosen (the one occurring the most). Also, losses and final loss of the optimization are identical, and seem not take into account the class_weight. Am I doing something wrong or is this a bug?

The number of classes is 3, and the class_weight looks like this:

`class_weight = {'output': {0:1000., 1:1000., 2:1.}}`

The compile looks like this:

```
loss=""categorical_crossentropy""
model.compile(optimizer=optimizer, loss={'output': loss})
```

The fit_generator looks like this: 

```
    history = model.fit_generator(generator(X, y),
                      nb_worker=1,
                      samples_per_epoch=2,
                      verbose=1,
                      class_weight=class_weight,
                      nb_epoch=epoch)
```

Thanks a lot for your help,
Ernst
",ErnstTmp,None,2016-03-24T18:41:34Z,2017-06-04T03:06:45Z
2059,Loading a previously saved model weights returns a gibberish model,"Python3, used latest keras.git and Theano.git with update prior to posting. Consistent repro.

Previously I saved a model after running the lstm_text_generation.py for 500 epochs. The model spits our reasonable output. I saved the weights and reloaded the model using the weights file and it completely becomes gibberish. I saw previous bugs like https://github.com/fchollet/keras/issues/655 that indicates the save/load may not be perfect that it misses some information during save/load, could this be a case of that?
# 

I modified the lstm_text_generation and I get a repro as well. When the model is trained, it gives ""reasonable output"" like this, but not after load weights. I even hardcoded the generating seed to minimize variance. For the example to repro, I used fewer epochs (5) only and a small piece of text. However, I used a larger text corpus with more epochs and it's still the same (trained for 18 hours).

Train + Save: https://gist.github.com/log0/d54ba54fb73837c2e3bf
Load: https://gist.github.com/log0/50c43671dd1426cf1cea

```
// This is the model that is trained.
Iteration 5                                                                                                                                                                  [37/220]
Epoch 1/1
11644/11644 [==============================] - 11s - loss: 3.0284     

----- diversity: 0.2
----- Generating with seed: ""ilosophers, in so fa""
ilosophers, in so fa   oaae ta    oaoea toat    est oa e o  e otoo eao to o     ae ao ooetta  t  t ooto ioo t      oteasaet o t  ttt tot te   o tttot  otot t t ott a t   oto to te t
t  teto  so ooaot  tt t attt r  tttt   t t tr e oseoa totttt    teae aoaott to    h eeaeeootttt     et ttoets oto  tttttt   t    eaottoot et      eeoteot o     eeteaoeostt     oao a
t   oooaaa t e   taeooo eeo tt e et hortr h   oeteo   teot

----- diversity: 0.5
----- Generating with seed: ""ilosophers, in so fa""
ilosophers, in so faso et   u ats sarosst aooo a rnaseut aio oa a heestertatnenouptttlhtt t    tiaoteootetst  oetu uo  tdae  eittoethettt to  ehor mrso tea  ead  autlttwotnea  nh  t
aiett leoas
 isno ttettds l ot t o atrar
t t o s tattarh t oah o taltae ow  sto tr oyeotooarotesottsh rn  e ehtr oo ottteiee e ste   esoertpaan  it s atstit ta thoa p ee aee e aaeheo ttaoate  ee t lruhe ht eao e utst earrt
 to t  rfr oantha
```

```
// This model never trains, just use the previously supplied weights.
----- diversity: 0.2
----- Generating with seed: ""ilosophers, in so fa""
ilosophers, in so fa((((((e):l9(::(9e9(9)(d(:::((9e(e99(e((e)))(9(((e:((e9)(:eee9e9(((:99:((99:9(:ee((9999:9)(9:d9(((9(e9:9e9(:(ee(()((9:9::(9((e(le:9(9)(e9999(e)((e((e9:e:(9)(e19($e9(((e(:)e(:ee9le(9(9(9(((::(:e)e9):9((()99((((:9e(e:e99(e(9:::(((999ee99)((99(((((eeeee:((e()ee9(:((e(((9:ee9e9:((d99(((u:(9(::)9e9e((99(((:9)(ee::999((((:e9e:():999(e(99:(:(9(:(9$e:9(9((99(9(:(emeeeeel(999(l(9()9(:(ee(e(e9e()9((()(9::9)(

----- diversity: 0.5
----- Generating with seed: ""ilosophers, in so fa""
ilosophers, in so fae(9(9(m(u99:(9(nd19(9(l(dm(e(eues9(::e:ulm(lu:feo(e((:(m((u:e(ds(:(ee9e::(:1(e(ue 1(e:)(dnd o(eel(:))()(:9ee1((9d9e(s(9u:((e e:9eeeo(de9(()99:::9(991:ee9e :1(99$((:s)):,()1ee9((n(((e9:)de((d):lee9m),))9(9(9:() 19 ((9lmee9eeeb9(11(:99(l:(e9(u1((e):d(e()(9((9:()l)9d:l(edl:9999nu)nd(e9l(e)((d():1,)(9(9((e (f):le)s(be((((19le99(,:(9()(,:e):d9e$9()((b((:9f11)lee9(e(((e(le)9d)9()()(1(9(b)():)des:9e::e9)
```

As you can see above, the output looks much more gibberish. Also, I have tested with a text corpus with no english characters but chinese characters, the output is similar and only outputs english characters even though there is not a single english character.

Appreciate any help on this. Thank you.
",log0,b'stale',2016-03-24T08:41:01Z,2017-06-23T00:10:43Z
2042,Passing Input Layer by name in Graph Model causes error in Embedding Layer,"If I replace `graph.add_node(Embedding(.., input=input))` by `graph.add_node(Embedding(.., input='%s_input'%name)` - it would not work, because embedding_layer.previous would store `str('token_input')` (not the reference to input layer) that would cause an error in embeddings's `get_output()`: `K.gather(..., string)`).

It might be an expected behavior rather then a bug (one must pass input layer as an object, not as a string), but I didn't find any place in docs where it was mentioned and it should probably fail if someone's trying to pass a string?

```
def build_model2(vocab_size_dict, max_seq_len, embedding_dim_dict, hidden_dim, depth=1, drop_prob=0):
    graph = Graph()
    branch_names = ['token', 'type', 'command']
    for name in branch_names:
        # does NOT include batch_size
        input = graph.add_input(input_shape=(max_seq_len, ), name='%s_input'%name)
        graph.add_node(Embedding(input_dim=vocab_size_dict[name]+1, 
                                 output_dim=embedding_dim_dict[name], 
                                 input_length=max_seq_len, mask_zero=True),
                       name='%s_embedding'%name, input=input)

        ## add independant GRU for each before merge?

    graph.add_node(Activation('linear'), name='linear_merge', merge_mode='concat',
                   inputs=['%s_embedding'%name for name in branch_names])

    for i in range(depth):
        graph.add_node(GRU(output_dim=hidden_dim, return_sequences=True,
                           dropout_W=drop_prob, dropout_U=drop_prob), 
                       name='proc_gru%d'%i, input='linear_merge')

    encoding_input_name = 'proc_gru%d'%i if depth > 0 else 'linear_merge'
    graph.add_node(GRU(output_dim=hidden_dim), name='encoding', input=encoding_input_name)

    for name in branch_names:
        graph.add_node(Dense(output_dim=vocab_size_dict[name], activation='softmax'), 
                       name='%s_dense'%name, input='encoding')
        graph.add_output(name='%s_output'%name, input='%s_dense'%name)

    graph.compile(loss=dict([('%s_output'%name, 'categorical_crossentropy') for name in branch_names]), 
                  optimizer='rmsprop')

    return model
```

udp: and if I pass it by value, an error `UnusedInputError` occurs :(
",MInner,b'stale',2016-03-22T23:20:36Z,2017-06-22T21:10:02Z
2035,Add a check for output layer(s) in graph model,"This prevents new users from running into debugging hell if they make the innocent mistake of forgetting to add an output layer to a graph model.
",musically-ut,None,2016-03-22T16:31:44Z,2016-04-11T20:36:48Z
2029,Error or BUG? : when graph shared node merge multi-inputs in keras? ,"Hi  all
## When I try to merge multi-inputs to a shard basenetwork, it will give an error:""theano.compile.function_module.UnusedInputError: theano.function was asked to create a function computing outputs given certain inputs, but the provided input variable at index 1 is not part of the computational graph needed to compute the outputs: input_b ""    

g.add_shared_node(base_network, name='shared', inputs['input_a','input_b','input_c'],merge_mode='join')

The base_network is as follows:
def create_base_network(last_hidden_dims,hidden_units,vocabsize,timesteps,data_dim):
    model.add_input(name='input0', input_shape=(timesteps,), dtype=int)
    model.add_node(Embedding(vocabsize, data_dim, input_length=timesteps),
               name='embedding', input='input0')
    model.add_node(LSTM(hidden_units), name='forward', input='embedding')
    model.add_node(Dense(last_hidden_dims, activation='sigmoid'), name='sigmoid', input='forward')
    model.add_output(name='output', input='sigmoid')
    return model
",cxfneo,b'stale',2016-03-22T02:47:12Z,2017-06-22T21:09:55Z
2020,Bug in Graph model with matrix input ?,"Hi, 
I was trying to train a very simple model using embeddings and LSTM for sentiment prediction.
Basically my input data is a matrix, in which, each row is one sentence, 
and each column, is the index of the word in my embedding matrix. 
Number of columns is fixed and set to the maximum length of a sentence I notice in the
training set, and I do padding from the left. Assuming that I have 500 sentences,
and maximum seen length of a sentence is 52, then I will have a 500x**52** input matrix. 

I didn't pay attention to the maximum length of a sentence in the test data. 
I just created the input matrix for test data and it became a 200x**65** matrix. 
Surely, 65 does not agree with 52, but keras didn't complain at all, and I could train, optimize, and evaluate the whole pipeline! 

the following code, simply demonstrate my problem:  

`import numpy as np ; 
from keras.models import Graph ; 
from keras.layers import Embedding 
import theano.tensor as T ; #for fixing theano error in Graph model ... see: https://github.com/fchollet/keras/issues/340

data1 = np.array ([[1,0],[0,1]])
data2 = np.array ([[0,1,0,1],[1,0,1,0]])

E = np.array ([[10,10,10],[20,20,20]])
max_features      = E.shape[0]
embedding_size = E.shape[1]

model = Graph();
model.add_input (name=""I"" , input_shape = (2,)) ; 
model.inputs[""I""].input = T.imatrix(); ##for fixing theano error in Graph model ... see: https://github.com/fchollet/keras/issues/340

model.add_node (Embedding (input_dim = max_features , output_dim = embedding_size , weights=[E]), input=""I"" , name=""E"")
model.add_output (name=""O"", input=""E"")
model.compile (loss={""O"":'mse'}, optimizer=""sgd"") ; 
print model.predict ({""I"":data1}) , ""\n""
print model.predict ({""I"":data2})
`
and the output is: 
{'O': array([[[ 20.,  20.,  20.],
        [ 10.,  10.,  10.]],

```
   [[ 10.,  10.,  10.],
    [ 20.,  20.,  20.]]])} 
```

{'O': array([[[ 10.,  10.,  10.],
        [ 20.,  20.,  20.],
        [ 10.,  10.,  10.],
        [ 20.,  20.,  20.]],

```
   [[ 20.,  20.,  20.],
    [ 10.,  10.,  10.],
    [ 20.,  20.,  20.],
    [ 10.,  10.,  10.]]])}
```

I was expecting to get an error when doing prediction for data2, since the input shape of the data2 does not agree with what is defined (input_shape). 
1) Isn't it a bug? 
2) Should I care to set the number of columns for train and test matrices EQUALLY when
crating the matrix, especially if the maximum length of a sentence in test set is bigger than train set? 

Thanks in advance.
",farmeh,b'stale',2016-03-21T09:54:55Z,2017-06-22T21:09:53Z
1993,get_weights() returns nan array - only highway layer,"So, i'm trying to debug something, and created a network with 2 layers, each with one neuron. I want to print the weights before and after training and see the difference. However, Highway layers return a nan array. Softmax and Dense layers return OK results.

Here is the code:

```
sgd = SGD(lr=0.1)

model = Sequential()
for current_hidden in hidden_units:
    model.add(Highway(input_dim=data_dim, activation='relu'))
    print model.layers[-1].get_weights()

print 'compiling...'
model.compile(loss='categorical_crossentropy', optimizer='adadelta')
for epoch in range(nb_epoch):
    model.fit(X_train, y_train, batch_size=128, nb_epoch=1,
        show_accuracy=True, validation_data=(X_test, y_test), shuffle=True, verbose=0)

    predictions = model.predict_proba(X_test)
    print metrics.roc_auc_score(y_test, predictions)
    prediction_scores[epoch] += metrics.roc_auc_score(y_test, predictions)

print model.layers[-2].get_weights()
print model.layers[-1].get_weights()
```

And here is a sample output. Note that before training the weights seem ok, and after training the net is functioning pretty well. 

```
[array([[ 0.58852339]], dtype=float32), array([ 0.], dtype=float32), array([[ 1.68141031]], dtype=float32), array([-2.], dtype=float32)]
[array([[-1.62892556]], dtype=float32), array([ 0.], dtype=float32), array([[ 1.28964162]], dtype=float32), array([-2.], dtype=float32)]
compiling...
2/2 [==============================] - 0s
1.0
[array([[ nan]], dtype=float32), array([ nan], dtype=float32), array([[ nan]], dtype=float32), array([ nan], dtype=float32)]
[array([[ nan]], dtype=float32), array([ nan], dtype=float32), array([[ nan]], dtype=float32), array([ nan], dtype=float32)]
```
",HristoBuyukliev,b'stale',2016-03-17T02:10:56Z,2017-09-27T10:21:05Z
1955,Bug in preprocessing/text.py,"In  sequences_to_matrix, **pass** is used twice, where **continue** should be used (lines 183 and 187). 

Problems should occour when you pass an empty sequence or a sequence containing a word with index >= nb_words.
",seppyr,None,2016-03-11T18:32:54Z,2016-03-11T18:51:39Z
1954,Warn user when number of y labels doesn't match output shape,"The following code fails for pretty obvious reasons:

```
>>> import numpy as np
>>> from keras.models import Sequential
>>> from keras.layers.core import Dense
>>>
>>> # Very simple architecture
>>> model = Sequential()
>>> model.add(Dense(400, input_dim=400))
>>> model.compile(loss='categorical_crossentropy', optimizer='adam')
>>> 
>>> X = np.random.rand(5, 400)
>>> y = [1, -1, -1, 1, 1]
>>> model.fit(X, y)
```

It leaves the not-so-helpful error message (below). I'm not sure what variety of architectures Keras is expected to support, but it would be nice if a warning was thrown if the problem is a multiclass classification problem, and there is no softmax output layer (or some similar output layer).

---

Output message:

```
ValueError: Input dimension mis-match. (input[0].shape[1] = 400, input[3].shape[1] = 1)
Apply node that caused the error: Elemwise{Composite{((i0 * i1 * i2 * i3 * i4) / (i5 * i6 * i7 * i8 * i8))}}[(0, 4)](Elemwise{Composite{AND(GE(i0, i1), LE(i0, i2))}}.0, InplaceDimShuffle{x,x}.0, InplaceDimShuffle{0,x}.0, <TensorType(float32, matrix)>, Elemwise{Add}[(0, 0)].0, InplaceDimShuffle{x,x}.0, InplaceDimShuffle{x,x}.0, Elemwise{Clip}[(0, 0)].0, InplaceDimShuffle{0,x}.0)
Toposort index: 32
Inputs types: [TensorType(int8, matrix), TensorType(float32, (True, True)), TensorType(float32, col), TensorType(float32, matrix), TensorType(float32, matrix), TensorType(float32, (True, True)), TensorType(float32, (True, True)), TensorType(float32, matrix), TensorType(float32, col)]
Inputs shapes: [(5, 400), (1, 1), (5, 1), (5, 1), (5, 400), (1, 1), (1, 1), (5, 400), (5, 1)]
Inputs strides: [(400, 1), (4, 4), (4, 4), (4, 4), (1600, 4), (4, 4), (4, 4), (1600, 4), (4, 4)]
Inputs values: ['not shown', array([[ 5.]], dtype=float32), array([[ 1.],
       [ 1.],
       [ 1.],
       [ 1.],
       [ 1.]], dtype=float32), array([[-1.],
       [ 1.],
       [ 1.],
       [-1.],
       [ 1.]], dtype=float32), 'not shown', array([[ 5.]], dtype=float32), array([[ 5.]], dtype=float32), 'not shown', array([[ 15.79184151],
       [ 11.54109573],
       [  4.8348279 ],
       [ 12.4104147 ],
       [  9.79920959]], dtype=float32)]
Outputs clients: [[Sum{axis=[1], acc_dtype=float64}(Elemwise{Composite{((i0 * i1 * i2 * i3 * i4) / (i5 * i6 * i7 * i8 * i8))}}[(0, 4)].0)]]

HINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.
HINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.
```
",hlin117,b'stale',2016-03-11T18:06:21Z,2017-06-22T23:11:47Z
1944,Tensorboard callback gives error on Test data shape when using stateful LSTM  ,"Hello, 
The TensorBoard calback does't seem to work with stateful LSTM.
Here's my model:
`model = Sequential()`
`model.add(LSTM(7, return_sequences = True,  stateful=True,  batch_input_shape=(10, 10, 24), input_shape=(10, 24)))`
....
`tb = TensorBoard(log_dir='./logs', histogram_freq=1)`
`model.fit(X_train, y_train, batch_size=10, nb_epoch=nb_epoch, validation_data=(X_test, y_test), show_accuracy=True, callbacks=[tb])`

When I train it, I get following error: 

> ValueError: Cannot feed value of shape (300, 10, 24) for Tensor u'Placeholder_1:0', which has shape '(10, 10, 24)
> BTW: (300, 10, 24) is the shape of the Test data.

When I remove the callback from model.fit() it doesn't give the error.

Is this a bug or am I overlooking something?
",marcdumon,None,2016-03-10T22:54:23Z,2016-03-12T13:36:33Z
1935,Reproducibility with Embedding layer.,"Hello everyone, i want to report (and probably resubmit) an old issue that is in Keras for a while.
I have tried to debug a known issue about reproducibility of the code on GPU.

Many of you have probably noticed that when run on GPU keras code produce slightly different results from time to time. So i tried to debug the problem starting from the the examples of the repository.

The only code that i found not reproducible is the code that involves the Embedding layers.
In particular all the imdb examples are not reproducible. At first i thought it was some problem related to the shuffling of the dataset (in the imdb dataset_loader). But the same lines of code are present in the reuter corpus. And the code is perfectly reproducible. 

Can anybody help me to spot the bug?

PS i was thinking even on some convolution related stuff but on mnist everything is fine.
In personal experiments (work related) with this layer i get the same issue (and it occurs even with a preinitialised word embedding matrix) it may be related to gradient updates? 

Please make sure that the boxes below are checked before you submit your issue. Thank you!
- [x ] Check that you are up-to-date with the master branch of Keras. You can update with:
  pip install git+git://github.com/fchollet/keras.git --upgrade --no-deps
- [x ] If running on Theano, check that you are up-to-date with the master branch of Theano. You can update with:
  pip install git+git://github.com/Theano/Theano.git --upgrade --no-deps
- [ ] Provide a link to a GitHub Gist of a Python script that can reproduce your issue (or just copy the script here if it is short).
",dbonadiman,b'stale',2016-03-09T14:32:51Z,2020-05-19T13:52:24Z
1931,Bug in ImageDataGenerator Whitening procedure?,"I was looking at the source code of the whitening procedure. I found that the data is never mean centered before doing the whitening. Specifically, if we keep all the other options as False and just keep the image whitening to be true, then covariance matrix is computed without mean centering the data! Thus `XX^T` will no longer be the covariance matrix of the data if `mean(X) ~= 0`.

If everyone agrees with me on this, I can submit a pull request to correct this issue.
",parag2489,b'stale',2016-03-09T01:40:32Z,2017-06-22T23:11:34Z
1915,Bug: model_from_json crashes on Graphs with create_output=True layer,"This code:

```
m = krm.Graph()
m.add_input('x', input_shape=(10,))
m.add_node(klc.Dense(5), 'y', input='x', create_output=True)
m.compile(loss={'y': 'mse'}, optimizer='adam')

with open('test.json', 'w') as f:
    f.write(m.to_json())

with open('test.json', 'r') as f:
    m = krm.model_from_json(f.read())
```

crashes with the following error:

```
... models.py"", line 166, in model_from_json
... models.py"", line 177, in model_from_config
... layer_utils.py"", line 64, in container_from_config
... containers.py"", line 568, in add_output
    raise Exception('Duplicate output identifier: ' + name)
Exception: Duplicate output identifier: y
```

I'll see if I can fix it.
",qdbp,None,2016-03-08T00:35:41Z,2016-03-08T01:49:11Z
1877,to_graph and plot should show the shape of the expected input and output,"First, I love the `keras.utils.visualize_util` module. It makes a quick summary of the neural network possible.

![model](https://cloud.githubusercontent.com/assets/1865885/13476093/cad1236a-e08b-11e5-9b65-814b74e1aba1.png)

But it would be nice to also annotate the visualization with the expected input and output shape. This would make debugging the neural network easier.

How does a change to `keras.utils.visualize_util.plot` and `keras.utils.visualize_util.to_graph` with this feature sound?
",hlin117,None,2016-03-02T21:32:54Z,2017-12-22T02:47:49Z
1870,stateful lstm,"Hi developers,

I run over the stateful_lstm.py example and see some problems:
1. The data doesn't arrange as it suppose to be in stateful mode - the batch_size are 25 and ""cos"" doesn't arrange in like it say Keras FAQ - "" If X1 and X2 are successive batches of samples, then X2[i] is the follow-up sequence to X1[i], for every i"".
2. When i turn off stateful mode (stateful=False) i get the good results:
stateful=True  >>> loss = ±0.28
stateful=False >>> loss = ±0.3

Beside that, I just built a model using stateful lstm layers, and have some issue, i saw that when i turn on the stateful mode, the train loss getting better but the test loss are getting very bad.
After debugging the data preprocessing step (and see that it has no bugs), i really think that it has some bug in the lstm stateful implementation. (I order the data as it write in Keras FAQ for stateful mode).
When i turn off the stateful mode the model archive better results in the test set.

Has anyone been able to train stateful network that achieve good result compare to unstateful network?

(I use the latest version of Keras)

Thanks!
",ghost,None,2016-03-02T07:45:28Z,2016-07-31T09:15:20Z
1864,Training loss not going down at all!,"I am training the following model (code is [here](https://gist.github.com/shyamupa/06209500e202a8d57084)),

I have a input sequence (`X`) and its corresponding sequence (`Y`). You can think of `X` being a question and `Y` being its correct answer. I am trying to learn a similarity function `F` such that `F(X,Y)=1` and `F(X,Y')=0`.

My training input is `X` concatenated with `Y` and my target output is 1/0 (0 is for negative examples). I generate `k` negative examples by picking a random `Y'` to concat with `X` (with a delimiter separating them). So my input looks something like (I pre-pad `X` with 0s and post-pad `Y` with 0s to ensure `length = xmaxlen + ymaxlen + 1` for all examples),

```
[...0 0 0 0 634.  1759.   890.  1289.   255.  ... 1.  2164.  1746. 0 0 0 ..]--> [1.0]
[...0 0 0 0 634.  1759.   890.  1289.   255.  ... 1.  2141.  1733. 0 0 0 ..]--> [0.0]
[...0 0 0 0 634.  1759.   890.  1289.   255.  ... 1.  2111.  1033. 0 0 0 ..]--> [0.0]
...
[...0 0 0 64.  179.   89.  128.   25.  ... 1.  216.  174....0 0 0 ]--> [1.0]
[...0 0 0 64.  179.   89.  128.   25.  ... 1.  210.  118....0 0 0 ]--> [0.0]
...
```

I plug in both sequences into a bidirectional LSTM and get its last state's output to a softmax which predicts the label. 

```
    def get_H_n(X):
        ans=X[:, -1, :]  # get last element from time dim
        return ans

    model.add_input(name='input', input_shape=(N,), dtype=int)
    model.add_node(Embedding(options.max_features, options.wx_emb, input_length=N), name='emb',
                   input='input')
    model.add_node(LSTM(options.lstm_units, return_sequences=True), name='forward', input='emb')
    model.add_node(LSTM(options.lstm_units, return_sequences=True, go_backwards=True), name='backward', input='emb')

    model.add_node(Dropout(0.5), name='dropout', inputs=['forward','backward'])
    model.add_node(Lambda(get_H_n, output_shape=(k,)), name='h_n', input='dropout')
    model.add_node(Dense(1, activation='softmax'), name='out', input='h_n')
    model.add_output(name='output', input='out')
```

The model compiles and trains, but nothing changes at all!

```
Epoch 1/10
1094/1094 [==============================] - 3s - loss: 14.4560 - val_loss: 14.4409
Epoch 2/10
1094/1094 [==============================] - 3s - loss: 14.4560 - val_loss: 14.4409
Epoch 3/10
1094/1094 [==============================] - 4s - loss: 14.4560 - val_loss: 14.4409
Epoch 4/10
1094/1094 [==============================] - 3s - loss: 14.4560 - val_loss: 14.4409
Epoch 5/10
```

Things I have tried to debug,
1. Lower learning rate.
2. Check if data manipulation is sane.
3. Chop input to avg xlen and avg ylen
4. Print the output of embedding layers (look alright).
5. Tried custom embedding layer which drives 0 to 0-vector (from #1800).
6. Print softmax weights (bias is always 0, but the W is non-zero).

**Why is this happening?** Any suggestion is welcome!

Please make sure that the boxes below are checked before you submit your issue. Thank you!
- [x] Check that you are up-to-date with the master branch of Keras. You can update with:
  pip install git+git://github.com/fchollet/keras.git --upgrade --no-deps
- [x] If running on Theano, check that you are up-to-date with the master branch of Theano. You can update with:
  pip install git+git://github.com/Theano/Theano.git --upgrade --no-deps
- [x] Provide a link to a GitHub Gist of a Python script that can reproduce your issue (or just copy the script here if it is short).
",shyamupa,None,2016-03-01T16:37:57Z,2016-08-10T08:27:06Z
1858,Print layer output while training?,"Is there a way to print the output of a layer during training? I am trying to debug a attention model in which the loss is not at all changing during training. I have tried changing learning rates, checking data sanity, but to no success. I want to see whether the layer outputs actually make any sense during training (eg. is my Lambda layer slicing correctly etc.). 

I know I can print the weights by using,

```
Wr=m.nodes['Wr'].get_weights()
emb=m.nodes['emb'].get_weights()
```

but I want the output. When I do `m.nodes['emb'].get_output()` I get a theano variable instead.

Please make sure that the boxes below are checked before you submit your issue. Thank you!
- [x] Check that you are up-to-date with the master branch of Keras. You can update with:
  pip install git+git://github.com/fchollet/keras.git --upgrade --no-deps
- [x] If running on Theano, check that you are up-to-date with the master branch of Theano. You can update with:
  pip install git+git://github.com/Theano/Theano.git --upgrade --no-deps
- [ ] Provide a link to a GitHub Gist of a Python script that can reproduce your issue (or just copy the script here if it is short).
",shyamupa,None,2016-02-29T23:30:35Z,2017-06-21T10:40:42Z
1840,lstm error: blocks nested too deeply,"i am running master imdb_lstm.py example
works for:
https://github.com/fchollet/keras/commit/3f905e4a357c05b216c29e34d26c12a4cd866f8e

broken by:
https://github.com/fchollet/keras/commit/73e563ecaf915d073d8b8fabc4a568ecddb0ea11

i can run by reducing LSTM(128) to LSTM(64)

error message for LSTM(128):

C:\Anaconda34\python.exe C:/Users/eyaler/Dropbox/python/keras-lstm/lstm.py
Using Theano backend.
DEBUG: nvcc STDOUT mod.cu
   Creating library C:/Users/eyaler/AppData/Local/Theano/compiledir_Windows-10-10.0.10586-Intel64_Family_6_Model_94_Stepping_3_GenuineIntel-3.4.4-64/tmp40r8j54g/m91973e5c136ea49268a916ff971b7377.lib and object C:/Users/eyaler/AppData/Local/Theano/compiledir_Windows-10-10.0.10586-Intel64_Family_6_Model_94_Stepping_3_GenuineIntel-3.4.4-64/tmp40r8j54g/m91973e5c136ea49268a916ff971b7377.exp

Using gpu device 0: GeForce GTX 970 (CNMeM is enabled with initial size: 70.0% of memory, CuDNN 4004)
C:\Anaconda34\lib\site-packages\theano\tensor\signal\downsample.py:5: UserWarning: downsample module has been moved to the pool module.
  warnings.warn(""downsample module has been moved to the pool module."")
Loading data...
20000 train sequences
5000 test sequences
Pad sequences (samples x time)
X_train shape: (20000, 100)
X_test shape: (5000, 100)
Build model...
C:\Anaconda34\lib\site-packages\theano\sandbox\cuda\cuda_ndarray.cuh(17) : warning C4005: 'PyString_Check' : macro redefinition
        C:\Anaconda34\lib\site-packages\numpy\core\include\numpy/npy_3kcompat.h(63) : see previous definition of 'PyString_Check'
C:\Anaconda34\lib\site-packages\theano\sandbox\cuda\cuda_ndarray.cuh(18) : warning C4005: 'PyString_FromString' : macro redefinition
        C:\Anaconda34\lib\site-packages\numpy\core\include\numpy/npy_3kcompat.h(65) : see previous definition of 'PyString_FromString'
C:\Anaconda34\lib\site-packages\theano\sandbox\cuda\cuda_ndarray.cuh(19) : warning C4005: 'PyString_AsString' : macro redefinition
        C:\Anaconda34\lib\site-packages\numpy\core\include\numpy/npy_3kcompat.h(72) : see previous definition of 'PyString_AsString'
C:\Anaconda34\lib\site-packages\theano\sandbox\cuda\cuda_ndarray.cuh(20) : warning C4005: 'PyString_FromStringAndSize' : macro redefinition
        C:\Anaconda34\lib\site-packages\numpy\core\include\numpy/npy_3kcompat.h(66) : see previous definition of 'PyString_FromStringAndSize'
C:\Anaconda34\lib\site-packages\theano\sandbox\cuda\cuda_ndarray.cuh(21) : warning C4005: 'PyString_Size' : macro redefinition
        C:\Anaconda34\lib\site-packages\numpy\core\include\numpy/npy_3kcompat.h(74) : see previous definition of 'PyString_Size'

C:\Anaconda34\lib\site-packages\theano\sandbox\cuda\cuda_ndarray.cuh(17) : warning C4005: 'PyString_Check' : macro redefinition
        C:\Anaconda34\lib\site-packages\numpy\core\include\numpy/npy_3kcompat.h(63) : see previous definition of 'PyString_Check'
C:\Anaconda34\lib\site-packages\theano\sandbox\cuda\cuda_ndarray.cuh(18) : warning C4005: 'PyString_FromString' : macro redefinition
        C:\Anaconda34\lib\site-packages\numpy\core\include\numpy/npy_3kcompat.h(65) : see previous definition of 'PyString_FromString'
C:\Anaconda34\lib\site-packages\theano\sandbox\cuda\cuda_ndarray.cuh(19) : warning C4005: 'PyString_AsString' : macro redefinition
        C:\Anaconda34\lib\site-packages\numpy\core\include\numpy/npy_3kcompat.h(72) : see previous definition of 'PyString_AsString'
C:\Anaconda34\lib\site-packages\theano\sandbox\cuda\cuda_ndarray.cuh(20) : warning C4005: 'PyString_FromStringAndSize' : macro redefinition
        C:\Anaconda34\lib\site-packages\numpy\core\include\numpy/npy_3kcompat.h(66) : see previous definition of 'PyString_FromStringAndSize'
C:\Anaconda34\lib\site-packages\theano\sandbox\cuda\cuda_ndarray.cuh(21) : warning C4005: 'PyString_Size' : macro redefinition
        C:\Anaconda34\lib\site-packages\numpy\core\include\numpy/npy_3kcompat.h(74) : see previous definition of 'PyString_Size'

Traceback (most recent call last):
  File ""C:/Users/eyaler/Dropbox/python/keras-lstm/lstm.py"", line 52, in <module>
    class_mode=""binary"")
  File ""C:\Anaconda34\lib\site-packages\keras\models.py"", line 547, in compile
mod.cu
mod.cu(9609) : fatal error C1061: compiler limit : blocks nested too deeply

['nvcc', '-shared', '-O3', '-use_fast_math', '-arch=sm_52', '-Xlinker', '/DEBUG', '-D HAVE_ROUND', '-m64', '-Xcompiler', '-DCUDA_NDARRAY_CUH=m18715462c72ed6afcd7ca5d52813ce90,-DNPY_NO_DEPRECATED_API=NPY_1_7_API_VERSION,/Zi,/MD', '-IC:\Users\eyaler\AppData\Local\Theano\compiledir_Windows-10-10.0.10586-Intel64_Family_6_Model_94_Stepping_3_GenuineIntel-3.4.4-64\cuda_ndarray', '-IC:\Anaconda34\lib\site-packages\numpy\core\include', '-IC:\Anaconda34\include', '-IC:\Anaconda34\lib\site-packages\theano\gof', '-IC:\Anaconda34\lib\site-packages\theano\sandbox\cuda', '-o', 'C:\Users\eyaler\AppData\Local\Theano\compiledir_Windows-10-10.0.10586-Intel64_Family_6_Model_94_Stepping_3_GenuineIntel-3.4.4-64\tmpjn1b5rys\m4ede61e241807f1f7e84ac7a20c0e454.pyd', 'mod.cu', '-LC:\Users\eyaler\AppData\Local\Theano\compiledir_Windows-10-10.0.10586-Intel64_Family_6_Model_94_Stepping_3_GenuineIntel-3.4.4-64\cuda_ndarray', '-LC:\Anaconda34\libs', '-LC:\Anaconda34', '-lcudart', '-lcublas', '-lcuda_ndarray', '-lpython34']
    self._train = K.function(train_ins, [train_loss], updates=updates)
  File ""C:\Anaconda34\lib\site-packages\keras\backend\theano_backend.py"", line 449, in function
    return Function(inputs, outputs, updates=updates)
  File ""C:\Anaconda34\lib\site-packages\keras\backend\theano_backend.py"", line 441, in __init__
    allow_input_downcast=True, **kwargs)
  File ""C:\Anaconda34\lib\site-packages\theano\compile\function.py"", line 320, in function
    output_keys=output_keys)
  File ""C:\Anaconda34\lib\site-packages\theano\compile\pfunc.py"", line 479, in pfunc
    output_keys=output_keys)
  File ""C:\Anaconda34\lib\site-packages\theano\compile\function_module.py"", line 1777, in orig_function
    defaults)
  File ""C:\Anaconda34\lib\site-packages\theano\compile\function_module.py"", line 1641, in create
    input_storage=input_storage_lists, storage_map=storage_map)
  File ""C:\Anaconda34\lib\site-packages\theano\gof\link.py"", line 690, in make_thunk
    storage_map=storage_map)[:3]
  File ""C:\Anaconda34\lib\site-packages\theano\gof\vm.py"", line 1003, in make_all
    no_recycling))
  File ""C:\Anaconda34\lib\site-packages\theano\sandbox\cuda__init__.py"", line 257, in make_thunk
    compute_map, no_recycling)
  File ""C:\Anaconda34\lib\site-packages\theano\gof\op.py"", line 970, in make_thunk
    no_recycling)
  File ""C:\Anaconda34\lib\site-packages\theano\gof\op.py"", line 879, in make_c_thunk
    output_storage=node_output_storage)
  File ""C:\Anaconda34\lib\site-packages\theano\gof\cc.py"", line 1200, in make_thunk
    keep_lock=keep_lock)
  File ""C:\Anaconda34\lib\site-packages\theano\gof\cc.py"", line 1143, in **compile**
    keep_lock=keep_lock)
  File ""C:\Anaconda34\lib\site-packages\theano\gof\cc.py"", line 1595, in cthunk_factory
    key=key, lnk=self, keep_lock=keep_lock)
  File ""C:\Anaconda34\lib\site-packages\theano\gof\cmodule.py"", line 1142, in module_from_key
    module = lnk.compile_cmodule(location)
  File ""C:\Anaconda34\lib\site-packages\theano\gof\cc.py"", line 1506, in compile_cmodule
    preargs=preargs)
  File ""C:\Anaconda34\lib\site-packages\theano\sandbox\cuda\nvcc_compiler.py"", line 396, in compile_str
    'for cmd', ' '.join(cmd))
Exception: ('The following error happened while compiling the node', GpuJoin(TensorConstant{0}, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0), '\n', 'nvcc return status', 2, 'for cmd', 'nvcc -shared -O3 -use_fast_math -arch=sm_52 -Xlinker /DEBUG -D HAVE_ROUND -m64 -Xcompiler -DCUDA_NDARRAY_CUH=m18715462c72ed6afcd7ca5d52813ce90,-DNPY_NO_DEPRECATED_API=NPY_1_7_API_VERSION,/Zi,/MD -IC:\Users\eyaler\AppData\Local\Theano\compiledir_Windows-10-10.0.10586-Intel64_Family_6_Model_94_Stepping_3_GenuineIntel-3.4.4-64\cuda_ndarray -IC:\Anaconda34\lib\site-packages\numpy\core\include -IC:\Anaconda34\include -IC:\Anaconda34\lib\site-packages\theano\gof -IC:\Anaconda34\lib\site-packages\theano\sandbox\cuda -o C:\Users\eyaler\AppData\Local\Theano\compiledir_Windows-10-10.0.10586-Intel64_Family_6_Model_94_Stepping_3_GenuineIntel-3.4.4-64\tmpjn1b5rys\m4ede61e241807f1f7e84ac7a20c0e454.pyd mod.cu -LC:\Users\eyaler\AppData\Local\Theano\compiledir_Windows-10-10.0.10586-Intel64_Family_6_Model_94_Stepping_3_GenuineIntel-3.4.4-64\cuda_ndarray -LC:\Anaconda34\libs -LC:\Anaconda34 -lcudart -lcublas -lcuda_ndarray -lpython34', '[GpuJoin(TensorConstant{0}, <CudaNdarrayType(float32, row)>, <CudaNdarrayType(float32, row)>, <CudaNdarrayType(float32, row)>, <CudaNdarrayType(float32, row)>, <CudaNdarrayType(float32, row)>, <CudaNdarrayType(float32, row)>, <CudaNdarrayType(float32, row)>, <CudaNdarrayType(float32, row)>, <CudaNdarrayType(float32, row)>, <CudaNdarrayType(float32, row)>, <CudaNdarrayType(float32, row)>, <CudaNdarrayType(float32, row)>, <CudaNdarrayType(float32, row)>, <CudaNdarrayType(float32, row)>, <CudaNdarrayType(float32, row)>, <CudaNdarrayType(float32, row)>, <CudaNdarrayType(float32, row)>, <CudaNdarrayType(float32, row)>, <CudaNdarrayType(float32, row)>, <CudaNdarrayType(float32, row)>, <CudaNdarrayType(float32, row)>, <CudaNdarrayType(float32, row)>, <CudaNdarrayType(float32, row)>, <CudaNdarrayType(float32, row)>, <CudaNdarrayType(float32, row)>, <CudaNdarrayType(float32, row)>, <CudaNdarrayType(float32, row)>, <CudaNdarrayType(float32, row)>, <CudaNdarrayType(float32, row)>, <CudaNdarrayType(float32, row)>, <CudaNdarrayType(float32, row)>, <CudaNdarrayType(float32, row)>, <CudaNdarrayType(float32, row)>, <CudaNdarrayType(float32, row)>, <CudaNdarrayType(float32, row)>, <CudaNdarrayType(float32, row)>, <CudaNdarrayType(float32, row)>, <CudaNdarrayType(float32, row)>, <CudaNdarrayType(float32, row)>, <CudaNdarrayType(float32, row)>, <CudaNdarrayType(float32, row)>, <CudaNdarrayType(float32, row)>, <CudaNdarrayType(float32, row)>, <CudaNdarrayType(float32, row)>, <CudaNdarrayType(float32, row)>, <CudaNdarrayType(float32, row)>, <CudaNdarrayType(float32, row)>, <CudaNdarrayType(float32, row)>, <CudaNdarrayType(float32, row)>, <CudaNdarrayType(float32, row)>, <CudaNdarrayType(float32, row)>, <CudaNdarrayType(float32, row)>, <CudaNdarrayType(float32, row)>, <CudaNdarrayType(float32, row)>, <CudaNdarrayType(float32, row)>, <CudaNdarrayType(float32, row)>, <CudaNdarrayType(float32, row)>, <CudaNdarrayType(float32, row)>, <CudaNdarrayType(float32, row)>, <CudaNdarrayType(float32, row)>, <CudaNdarrayType(float32, row)>, <CudaNdarrayType(float32, row)>, <CudaNdarrayType(float32, row)>, <CudaNdarrayType(float32, row)>, <CudaNdarrayType(float32, row)>, <CudaNdarrayType(float32, row)>, <CudaNdarrayType(float32, row)>, <CudaNdarrayType(float32, row)>, <CudaNdarrayType(float32, row)>, <CudaNdarrayType(float32, row)>, <CudaNdarrayType(float32, row)>, <CudaNdarrayType(float32, row)>, <CudaNdarrayType(float32, row)>, <CudaNdarrayType(float32, row)>, <CudaNdarrayType(float32, row)>, <CudaNdarrayType(float32, row)>, <CudaNdarrayType(float32, row)>, <CudaNdarrayType(float32, row)>, <CudaNdarrayType(float32, row)>, <CudaNdarrayType(float32, row)>, <CudaNdarrayType(float32, row)>, <CudaNdarrayType(float32, row)>, <CudaNdarrayType(float32, row)>, <CudaNdarrayType(float32, row)>, <CudaNdarrayType(float32, row)>, <CudaNdarrayType(float32, row)>, <CudaNdarrayType(float32, row)>, <CudaNdarrayType(float32, row)>, <CudaNdarrayType(float32, row)>, <CudaNdarrayType(float32, row)>, <CudaNdarrayType(float32, row)>, <CudaNdarrayType(float32, row)>, <CudaNdarrayType(float32, row)>, <CudaNdarrayType(float32, row)>, <CudaNdarrayType(float32, row)>, <CudaNdarrayType(float32, row)>, <CudaNdarrayType(float32, row)>, <CudaNdarrayType(float32, row)>, <CudaNdarrayType(float32, row)>, <CudaNdarrayType(float32, row)>, <CudaNdarrayType(float32, row)>, <CudaNdarrayType(float32, row)>, <CudaNdarrayType(float32, row)>, <CudaNdarrayType(float32, row)>, <CudaNdarrayType(float32, row)>, <CudaNdarrayType(float32, row)>, <CudaNdarrayType(float32, row)>, <CudaNdarrayType(float32, row)>, <CudaNdarrayType(float32, row)>, <CudaNdarrayType(float32, row)>, <CudaNdarrayType(float32, row)>, <CudaNdarrayType(float32, row)>, <CudaNdarrayType(float32, row)>, <CudaNdarrayType(float32, row)>, <CudaNdarrayType(float32, row)>, <CudaNdarrayType(float32, row)>, <CudaNdarrayType(float32, row)>, <CudaNdarrayType(float32, row)>, <CudaNdarrayType(float32, row)>, <CudaNdarrayType(float32, row)>, <CudaNdarrayType(float32, row)>, <CudaNdarrayType(float32, row)>, <CudaNdarrayType(float32, row)>, <CudaNdarrayType(float32, row)>, <CudaNdarrayType(float32, row)>, <CudaNdarrayType(float32, row)>, <CudaNdarrayType(float32, row)>, <CudaNdarrayType(float32, row)>)]')

Process finished with exit code 1
",eyaler,b'stale',2016-02-27T18:13:29Z,2017-06-23T00:09:58Z
1835,"Bug in LSTM.build, in setting up regularizers","In `keras.layers.recurrent.LSTM.build()`:

``` python
        for W in [self.W_i, self.W_f, self.W_i, self.W_o]:
            append_regulariser(self.W_regularizer, W, self.regularizers)
        for U in [self.U_i, self.U_f, self.U_i, self.U_o]:
            append_regulariser(self.U_regularizer, U, self.regularizers)
        for b in [self.b_i, self.b_f, self.b_i, self.b_o]:
            append_regulariser(self.b_regularizer, b, self.regularizers)
```

should be

``` python
        for W in [self.W_i, self.W_f, self.W_c, self.W_o]:
            append_regulariser(self.W_regularizer, W, self.regularizers)
        for U in [self.U_i, self.U_f, self.U_c, self.U_o]:
            append_regulariser(self.U_regularizer, U, self.regularizers)
        for b in [self.b_i, self.b_f, self.b_c, self.b_o]:
            append_regulariser(self.b_regularizer, b, self.regularizers)
```

The 3rd element in each of the lists should be `*_c` instead of `*_i`.

Please make sure that the boxes below are checked before you submit your issue. Thank you!
- [x] Check that you are up-to-date with the master branch of Keras. You can update with:
  pip install git+git://github.com/fchollet/keras.git --upgrade --no-deps
- [x] If running on Theano, check that you are up-to-date with the master branch of Theano. You can update with:
  pip install git+git://github.com/Theano/Theano.git --upgrade --no-deps
- [ ] Provide a link to a GitHub Gist of a Python script that can reproduce your issue (or just copy the script here if it is short).
",sunil-at-gh,None,2016-02-26T20:56:26Z,2016-02-26T21:04:49Z
1830,Input dimension mis-match,"when I run exampel/imdb_bidirectional_lstm.py i have this trouble:
ValueError: Input dimension mis-match. (input[1].shape[1] = 128, input[2].shape[1] = 64)
I find this is because the backward layer have influence on forward layer，but I don't kown how to fix it.
Can you help me ? Thanks.

Log is as follows:
Traceback (most recent call last):
  File ""imdb_bidirectional_lstm.py"", line 57, in <module>
    batch_size=batch_size,nb_epoch=4)
  File ""/home/rank_intern/share/python/anaconda2/lib/python2.7/site-packages/keras/models.py"", line 1127, in fit
    shuffle=shuffle, metrics=metrics)
  File ""/home/rank_intern/share/python/anaconda2/lib/python2.7/site-packages/keras/models.py"", line 239, in _fit
    outs = f(ins_batch)
  File ""/home/rank_intern/share/python/anaconda2/lib/python2.7/site-packages/keras/backend/theano_backend.py"", line 365, in __call__
    return self.function(*inputs)
  File ""/home/rank_intern/share/python/anaconda2/lib/python2.7/site-packages/theano/compile/function_module.py"", line 606, in **call**
    storage_map=self.fn.storage_map)
  File ""/home/rank_intern/share/python/anaconda2/lib/python2.7/site-packages/theano/compile/function_module.py"", line 595, in **call**
    outputs = self.fn()
ValueError: Input dimension mis-match. (input[1].shape[1] = 72, input[2].shape[1] = 64)
Apply node that caused the error: Elemwise{mul,no_inplace}(TensorConstant{(1, 1) of 2.0}, Join.0, Elemwise{Composite{Cast{float32}(LT(i0, i1))}}.0)
Inputs types: [TensorType(float32, (True, True)), TensorType(float32, matrix), TensorType(float32, matrix)]
Inputs shapes: [(1, 1), (32, 72), (32, 64)]
Inputs strides: [(4, 4), (288, 4), (256, 4)]
Inputs values: [array([[ 2.]], dtype=float32), 'not shown', 'not shown']

HINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.
HINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.
",lifeng1989,b'stale',2016-02-26T09:27:23Z,2017-06-22T23:12:42Z
1823,Update SiameseHead,"We forgot to pass the train parameter to the layer.**call** inside get_output_at. This is a bug.
",EderSantana,None,2016-02-25T18:50:31Z,2016-02-25T19:33:42Z
1817,Fix a little bug in pad_sequences,,AIshb,None,2016-02-25T12:39:45Z,2016-02-25T17:51:48Z
1808,Compile error due to Lambda Layer?,"This is a followup of another issue #1779. I upgraded to the latest version after the bugfix in #1801. 

Now I am getting another strange error for the argument of the Lambda layer when I do `model.compile(loss={'output':'categorical_crossentropy'}, optimizer='rmsprop')`,

```
def get_R(X):
    return K.dot(X[0], X[1])


line 1482, in get_output
    return func(X)
line 83, in get_R
    return K.dot(X[0], X[1])
KeyError: 0
```

Here is the [gist](https://gist.github.com/shyamupa/90a9050a6f35323c10df) to reproduce.
Is the bug still persisting in the Lambda Layer?

Please make sure that the boxes below are checked before you submit your issue. Thank you!
- [x] Check that you are up-to-date with the master branch of Keras. You can update with:
  pip install git+git://github.com/fchollet/keras.git --upgrade --no-deps
- [x] If running on Theano, check that you are up-to-date with the master branch of Theano. You can update with:
  pip install git+git://github.com/Theano/Theano.git --upgrade --no-deps
- [x] Provide a link to a GitHub Gist of a Python script that can reproduce your issue (or just copy the script here if it is short).
",shyamupa,b'stale',2016-02-24T16:36:26Z,2017-06-22T21:10:50Z
1801,Lambda layer: Bug Fix,"Handle case `input_shape == None`.(Previous layer is a join `Merge`).
",farizrahman4u,None,2016-02-23T21:42:38Z,2016-02-24T04:53:56Z
1772,Inspecting multitask loss in Graph instances,"When training or validating a `Graph` model with two objectives, it's frustrating to be unable to see both losses at once. Right now, for instance, I'm trying to train a network to regress and classify at the same time, but it's impossible to balance the regression and classification losses because I can't see how large they are. For one illustration of how the balance parameter in a multitask loss can impact accuracy, look at Table 9 in [Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks](http://arxiv.org/pdf/1506.01497v3.pdf) (loss terms and relative importance of λ explained below Eqn. 1 on p5).
#580 presents a workaround, but that workaround is slow (especially if you want to see each loss on every minibatch!) and error-prone. Ideally `train_on_batch`, `validate_on_batch`, etc. should give a dictionary of losses like

```
{
  'regressor_loss': 23.5185,
  'classifier_loss': 3.9618
}
```

The return value and debugging output of `.fit()` and other convenience methods would have to be similarly modified. This probably breaks a lot of old code, so it may be necessary to introduce a flag analogous to `accuracy={True,False}` which indicates whether all losses should be returned or just one.

Kind-of related: #1510.
",qxcv,None,2016-02-20T07:07:42Z,2016-12-10T06:25:47Z
1768,Bug in callbacks.py ModelCheckpoint class,"There is a bug in the constructor of the ModelCheckpoint class (lines 247-259)

See code below (from master branch). If the mode parameter is not recognized, the warning message refers to a self.mode variable that is never initialized, and an exception is thrown:

`AttributeError: 'ModelCheckpoint' object has no attribute 'mode'`

--- Code from callbacks.py ---

```
 def __init__(self, filepath, monitor='val_loss', verbose=0,
                 save_best_only=False, mode='auto'):


        super(Callback, self).__init__()
        self.monitor = monitor
        self.verbose = verbose
        self.filepath = filepath
        self.save_best_only = save_best_only

        if mode not in ['auto', 'min', 'max']:
            warnings.warn('ModelCheckpoint mode %s is unknown, '
                          'fallback to auto mode.' % (self.mode),
                          RuntimeWarning)
```
",mbarison,None,2016-02-19T22:29:11Z,2016-02-20T03:14:39Z
1716,Dropout with multiple layer network,"Hello,

I have tried the dropout feature with multiple layers, and get a problem I couldn't figure out.

With Dropout = [0.8, 0.5, 0.5] for input layer and the 2 hidden layers,
and the structure Layers = [784, 300, 100, 10] with MNIST database, I get this error:

> File X in fit_network
>     output_file=output_filepath
>   File ""X\keras\models.py"", line 438, in fit
>     shuffle=shuffle, metrics=metrics, output_file=output_file)
>   File ""X\keras\models.py"", line 192, in _fit
>     outs = f(*ins_batch)
>   File ""X\Anaconda\lib\site-packages\theano\compile\function_module.py"", line 606, in _ _call__
>     storage_map=self.fn.storage_map)
>   File ""X\Anaconda\lib\site-packages\theano\compile\function_module.py"", line 595, in _ _call__
>     outputs = self.fn()
> 
> ValueError:
>  Input dimension mis-match. (input[0].shape[0] = 100, input[4].shape[0] = 300)
> Apply node that caused the error: Elemwise{Composite{(((i0 + (i1 \* i2)) - i3) \* i4)}}[(0, 0)](TensorType%28float64, matrix%29>, TensorConstant{%281L, 1L%29 of 0.9}, Elemwise{Composite{%28%28i0 * i1%29 - i2%29}}[%280, 1%29].0, Dot22Scalar.0, TensorConstant{[[ 1.  1. ..  0.  1.]]})
> Inputs types: [TensorType(float64, matrix), TensorType(float64, (True, True)), TensorType(float64, matrix), TensorType(float64, matrix), TensorType(float64, matrix)]
> Inputs shapes: [(100L, 10L), (1L, 1L), (100L, 10L), (100L, 10L), (300L, 100L)]
> Inputs strides: [(80L, 8L), (8L, 8L), (80L, 8L), (80L, 8L), (800L, 8L)]
> Inputs values: ['not shown', array([[ 0.9]]), 'not shown', 'not shown', 'not shown']
> 
> HINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.
> HINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.
",Albyorix,None,2016-02-14T11:40:12Z,2016-02-14T17:19:34Z
1707,Added visualization based on Bokeh,"- [x] **If your PR introduces a change in functionality, make sure you start by opening an issue to discuss whether the change should be made, and how to handle it. This will save you from having your PR closed down the road! Of course, if your PR is a simple bug fix, you don't need to do that.**

Relevant discussions: [Visualization RFC](https://github.com/fchollet/keras/issues/1680) and [Keras Roadmap](https://github.com/fchollet/keras/issues/100)
- [x] **Write the code. This is the hard part!**
- [x] **Make sure any new function or class you introduce has proper docstrings. Make sure any code you touch still has up-to-date docstrings and documentation.**
- [x] **Write tests. Your code should have full unit test coverage. If you want to see your PR merged promptly, this is crucial.**
- [x] **Run tests with the Theano backend, on Python 2.7 and Python 3.5**
- [x] **Run tests with TensorFlow backend, on Python 2.7**
- [x] **When committing, use appropriate, descriptive commit messages. Make sure that your branch history is not a string of ""bug fix"", ""fix"", ""oops"", etc. When submitting your PR, squash your commits into a single commit with an appropriate commit message, to make sure the project history stays clean and readable. See 'rebase and squash' for technical help on how to squash your commits.**
- [x] **Update the documentation. If introducing new functionality, make sure you include code snippets demonstrating the usage of your new feature.**
",claymcleod,None,2016-02-12T20:21:08Z,2016-02-13T17:56:25Z
1703,"if go_backward == 1,  the output seqences should be reversed","I think there is a bug in the current theano_backend.rnn
",ypxie,b'stale',2016-02-12T14:11:46Z,2017-06-25T01:00:14Z
1690,Bug: ImageDataGenerator actually shifts image vertically when used width_shift_range >0 and height_shift_range=0 (and vice-versa),"The title is explains the problem in ImageDataGenerator. I defined the data generator as follows:

```
datagen = ImageDataGenerator(
        featurewise_center=False,  # set input mean to 0 over the dataset
        samplewise_center=False,  # set each sample mean to 0
        featurewise_std_normalization=False,  # divide inputs by std of the dataset
        samplewise_std_normalization=False,  # divide each input by its std
        zca_whitening=False,  # apply ZCA whitening
        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)
        width_shift_range=0.5,  # randomly shift images horizontally (fraction of total width)
        height_shift_range=0.0,  # randomly shift images vertically (fraction of total height)
        horizontal_flip=False,  # randomly flip images
        vertical_flip=False)  # randomly flip images
```

Now one may assume by reading the `ImageDataGenerator` documentation that the images will be shifted by `0.5*image_width` from left to right (or from right to left). What I found by looking at the shifted images was totally opposite. When width_shift_range>0 and height_shift_range=0, it shifts the image from **top to bottom**. 

The culprit is in this line in `image.py`:

```
ndimage.interpolation.shift(x, (0, crop_left_pixels, crop_top_pixels), order=0, 
mode=fill_mode, cval=cval)
```

If we change the order of `crop_left_pixels` and `crop_right_pixels`, the images will shift as expected. One more thing remains, if `crop_left_pixels = 0.2`, then the image shifts in one direction only (I think `ndimage` does it from left to right). This prevents images getting shifted from other direction. Solution? Multiply `crop_left_pixels` by -1 in a random fashion. The modified function looks as follows:

```
def random_shift(x, wrg, hrg, fill_mode=""nearest"", cval=0.):
    crop_left_pixels = 0
    crop_top_pixels = 0

    if wrg:
        crop = random.uniform(0., wrg)
        split = random.uniform(0, 1)
        randSign = 2*np.random.randint(2)-1 #allows cropping from left and right both
        crop_left_pixels = randSign*int(split*crop*x.shape[2]) #x.shape[2] are actually columns
    if hrg:
        crop = random.uniform(0., hrg)
        split = random.uniform(0, 1)
    randSign = 2*np.random.randint(2)-1 #allows cropping from top and bottom both
        crop_top_pixels = randSign*int(split*crop*x.shape[1]) #x.shape[1] are actually rows
    x = ndimage.interpolation.shift(x, (0, crop_top_pixels, crop_left_pixels),
                                    order=0,
                                    mode=fill_mode,
                                    cval=cval)
    return x

```

If @fchollet can comment on this, then I can submit a pull request or anything else needed as per the norms.
",parag2489,None,2016-02-11T03:53:38Z,2016-02-15T07:39:25Z
1689,ImageDataGenerator fetches ~ ten times more samples than necessary.,"###### System configuration: Running on CPU, Ubuntu 12.04, Theano latest version, Keras updated around Mid-January

I want to use real-time data augmentation and so I started using `fit_generator()` with `ImageDataGenerator` object as its generator. According to [generator documentation](keras.io/models/): _An epoch finishes when samples_per_epoch samples have been seen by the model_. So I wrote my generator as follows (mainly to test it):

```
# written in such a way that only the mean of the dataset will be subtracted 
# from each image and the data itself will not be augmented.

datagen = ImageDataGenerator(
        featurewise_center=True,  # set input mean to 0 over the dataset
        samplewise_center=False,  # set each sample mean to 0
        featurewise_std_normalization=False,  # divide inputs by std of the dataset
        samplewise_std_normalization=False,  # divide each input by its std
        zca_whitening=False,  # apply ZCA whitening
        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)
        width_shift_range=0,  # randomly shift images horizontally (fraction of total width)
        height_shift_range=0,  # randomly shift images vertically (fraction of total height)
        horizontal_flip=False,  # randomly flip images
        vertical_flip=False)  # randomly flip images

    # compute quantities required for featurewise normalization
    # (std, mean, and principal components if ZCA whitening is applied)
    datagen.fit(X_train)

    batch_size=32
    nb_epoch =10

    # fit the model on the batches generated by datagen.flow()
    model.fit_generator(datagen.flow(X_train, Y_train, batch_size=batch_size),
                        samples_per_epoch=batch_size ,
                        nb_epoch=nb_epoch, verbose=2, show_accuracy=True, callbacks = [history],
                        validation_data=(X_test[0:100], Y_test[0:100]),
                        nb_worker=1)
```

Note that I have purposely set `samples_per_epoch = batch_size`. So after the generator has yielded **one batch**, it should start the next epoch. However, it loops over 11 batches to start the next epoch. I know this from the callback I have written as follows:

```
class LossHistory(callbacks.Callback):
    def on_train_begin(self, logs={}):
        self.losses = []

    def on_epoch_end(self, epoch, logs={}):
        self.losses.append(logs.get('val_loss'))
        logging.info('-----------------------------------------------------------------------')
        logging.info('Epoch ' + str(epoch) + ' - Validation loss: ' + str(logs.get('val_loss')) + ' accuracy : ' + str(logs.get('val_acc')))
        logging.info('-----------------------------------------------------------------------')

    def on_batch_end(self,batch,logs={}):
        logging.info('Batch ' + str(batch) + ' - Validation loss: ' + str(logs.get('loss')) + ', validation accuracy: ' + str(logs.get('acc')))
```

If `samples_per_epoch = 2*batch_size`, then the `fit_generator()` loops over 22 batches. This is quite surprising to me. It would be great if someone can explain this phenomena. I am not sure whether this bears some relation with #1639. I am tagging @fchollet @wongjingping as they have been helping me in the issues with data generator.

**If someone wants to runnable script reproducing this issue (very similar to Keras demos), here it is:**

```
from __future__ import print_function
import sys
import threading
from multiprocessing import Queue

from keras.datasets import cifar10
from keras.preprocessing.image import ImageDataGenerator
from keras.models import Sequential
from keras.layers.core import Dense, Dropout, Activation, Flatten
from keras.layers.convolutional import Convolution2D, MaxPooling2D
from keras.optimizers import SGD
from keras.utils import np_utils
from keras import callbacks
from keras.callbacks import ModelCheckpoint
import logging

logging.basicConfig(level=logging.DEBUG,
                    format='%(asctime)s %(name)-12s %(levelname)-8s %(message)s',
                    datefmt='%m-%d %H:%M',
                    filename='Run_10Feb_cifar10_withDataAug_2.txt',
                    filemode='w')


logging.info('Done with all the imports')

class LossHistory(callbacks.Callback):
    def on_train_begin(self, logs={}):
        self.losses = []

    def on_epoch_end(self, epoch, logs={}):
        self.losses.append(logs.get('val_loss'))
        logging.info('-----------------------------------------------------------------------')
        logging.info('Epoch ' + str(epoch) + ' - Validation loss: ' + str(logs.get('val_loss')) + ' accuracy : ' + str(logs.get('val_acc')))
        logging.info('-----------------------------------------------------------------------')

    def on_batch_end(self,batch,logs={}):
        logging.info('Batch ' + str(batch) + ' - Validation loss: ' + str(logs.get('loss')) + ', validation accuracy: ' + str(logs.get('acc')))

logging.info('History class defined')

batch_size = 32
nb_classes = 10
nb_epoch = 100
data_augmentation = True
weightSavePath = '/media/vijetha/DATA/vijetha2/Documents/imageClassification_Parag/weights/'

# input image dimensions
img_rows, img_cols = 32, 32
# the CIFAR10 images are RGB
img_channels = 3

# the data, shuffled and split between train and test sets
(X_train, y_train), (X_test, y_test) = cifar10.load_data()
logging.info('X_train shape:' + str(X_train.shape))
logging.info(str(X_train.shape[0]) + ' train samples')
logging.info(str(X_test.shape[0]) + ' test samples')

# convert class vectors to binary class matrices
Y_train = np_utils.to_categorical(y_train, nb_classes)
Y_test = np_utils.to_categorical(y_test, nb_classes)

history = LossHistory()

logging.info('Model buidling started')

model = Sequential()

model.add(Convolution2D(32, 3, 3, border_mode='same',
                        input_shape=(img_channels, img_rows, img_cols)))
model.add(Activation('relu'))
model.add(Convolution2D(32, 3, 3))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.25))

model.add(Convolution2D(64, 3, 3, border_mode='same'))
model.add(Activation('relu'))
model.add(Convolution2D(64, 3, 3))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.25))

model.add(Flatten())
model.add(Dense(512))
model.add(Activation('relu'))
model.add(Dropout(0.5))
model.add(Dense(nb_classes))
model.add(Activation('softmax'))

# let's train the model using SGD + momentum (how original).
sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)
model.compile(loss='categorical_crossentropy', optimizer=sgd, class_mode='categorical')

logging.info('Model buidling and compilation finished')

X_train = X_train.astype('float32')
X_test = X_test.astype('float32')
X_train /= 255
X_test /= 255

checkpointer_all = ModelCheckpoint(filepath= weightSavePath + ""withDataAug_weights.{epoch:02d}.hdf5"", verbose=1, save_best_only=False)
checkpointer_best = ModelCheckpoint(filepath= weightSavePath + ""withDataAug_bestWeights.hdf5"", verbose=1, save_best_only=True)


if not data_augmentation:
    logging.info('Not using data augmentation.')
    model.fit(X_train, Y_train, batch_size=batch_size,
              nb_epoch=nb_epoch, verbose=2, show_accuracy=True, callbacks = [history, checkpointer_all, checkpointer_best],
              validation_data=(X_test, Y_test), shuffle=True)
else:
    logging.info('Using real-time data augmentation.')

    # this will do preprocessing and realtime data augmentation
    datagen = ImageDataGenerator(
        featurewise_center=True,  # set input mean to 0 over the dataset
        samplewise_center=False,  # set each sample mean to 0
        featurewise_std_normalization=False,  # divide inputs by std of the dataset
        samplewise_std_normalization=False,  # divide each input by its std
        zca_whitening=False,  # apply ZCA whitening
        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)
        width_shift_range=0,  # randomly shift images horizontally (fraction of total width)
        height_shift_range=0,  # randomly shift images vertically (fraction of total height)
        horizontal_flip=False,  # randomly flip images
        vertical_flip=False)  # randomly flip images
    # compute quantities required for featurewise normalization
    # (std, mean, and principal components if ZCA whitening is applied)
    datagen.fit(X_train)

    # fit the model on the batches generated by datagen.flow()
    model.fit_generator(datagen.flow(X_train, Y_train, batch_size=batch_size),
                        samples_per_epoch=2*batch_size,
                        nb_epoch=nb_epoch, verbose=2, show_accuracy=True, callbacks = [history],
                        validation_data=(X_test[0:100], Y_test[0:100]),
                        nb_worker=1)

    logging.info('History of the losses is: ')
    logging.info(str(history.losses))
```
",parag2489,None,2016-02-10T23:25:57Z,2016-08-05T10:04:09Z
1685,fit_generator,"So I've been trying to work with the fit_generator method for the graph model.
All works well if I set nb_worker=1, but any value higher than that and it just crashes.

It seems thread.start automatically triggers _stop.is_set() after the first thread. This is in python3. Haven't tested python2.7

I lack the skills for any more informative debugging >.>
",lemuriandezapada,b'stale',2016-02-10T14:29:27Z,2017-06-22T23:12:12Z
1670,BUG: Typo in Examples Page?,"In the examples on http://keras.io/examples/, I think the lines that read

```
from keras.layers import Dense, Dropout, Activation
```

should be

```
from keras.layers.core import Dense, Dropout, Activation
```

If not, there is a problem with my installation.;P
",jsphon,None,2016-02-09T06:21:24Z,2016-02-09T21:53:33Z
1639,Bug: Incorrect batch_size in fit_generator (Sequential),"I'm having an issue with the batch sizes showing up correctly; whenever I print out the batch logs using a callback the batch_size is always the 2nd entry in the X.shape tuple. For example, if my X generated was of shape (batch_size, nrow, ncol, nb_channel), the batch_size would always be `nrow`. 
Another user faced a similar issue #1627 (his last comment), where his X.shape tuple was (batch_size, nb_channel, nrow, ncol). As his images had only 1 channel, this resulted in the batch_size being 1, and the loop iterating from 1-6000 instead of 1-1875.

My suspect of the offending line is in models.py line 1017

`batch_logs = {}`
`--->       batch_size = len(X[0])`
`batch_logs['batch'] = batch_index`

I'm looking at other parts of the code to check why it was implemented this way, but from what I see so far it seems like it should be 
`batch_size = len(X)` instead

Let me know if this is an issue faced by others and I'll submit a PR :)
",wongjingping,None,2016-02-04T10:10:22Z,2016-02-04T18:50:26Z
1633,Error in AutoEncoder docs,"I'm new to OSS and english is not my native language, but I think I found a little bug in the docs and since this framework is very useful to me I would like to help a bit to improve it.

The problem I found is that in the official docs section devoted to the AutoEncoder layer, at http://keras.io/layers/core/#autoencoder . There is a small example code which uses output_reconstruction to use the decoder or the encoder as a output. 

`from keras.layers import containers

**input shape: (nb_samples, 32)**

encoder = containers.Sequential([Dense(16, input_dim=32), Dense(8)])
decoder = containers.Sequential([Dense(16, input_dim=8), Dense(32)])

autoencoder = Sequential()
autoencoder.add(AutoEncoder(encoder=encoder, decoder=decoder,
        output_reconstruction=True))

**training the autoencoder:**

autoencoder.compile(optimizer='sgd', loss='mse')
autoencoder.fit(X_train, X_train, nb_epoch=10)

**predicting compressed representations of inputs:**

autoencoder.output_reconstruction = False  # the autoencoder has to be recompiled after modifying this property
autoencoder.compile(optimizer='sgd', loss='mse')
representations = autoencoder.predict(X_test)

**the model is still trainable, although it now expects compressed representations as targets:**

autoencoder.fit(X_test, representations, nb_epoch=1)  # in this case the loss will be 0, so it's useless

**to keep training against the original inputs, just switch back output_reconstruction to True:**

autoencoder.output_reconstruction = False
autoencoder.compile(optimizer='sgd', loss='mse')
autoencoder.fit(X_train, X_train, nb_epoch=10)`

The problem with this is that output_reconstruction is set  on the Sequential, not in the AutoEncoder layer, so the layer never notices that has to change the output. Additionally, the last time is set should be set to True according to ""just switch back output_reconstruction to True"". The correct code would be according to my opinion:

``from keras.layers import containers

**input shape: (nb_samples, 32)**

encoder = containers.Sequential([Dense(16, input_dim=32), Dense(8)])
decoder = containers.Sequential([Dense(16, input_dim=8), Dense(32)])

autoencoder = Sequential()
autoencoder.add(AutoEncoder(encoder=encoder, decoder=decoder,
        output_reconstruction=True))

**training the autoencoder:**

autoencoder.compile(optimizer='sgd', loss='mse')
autoencoder.fit(X_train, X_train, nb_epoch=10)

**predicting compressed representations of inputs:**

autoencoder.layers[0].output_reconstruction = False  # the autoencoder has to be recompiled after modifying this property
autoencoder.compile(optimizer='sgd', loss='mse')
representations = autoencoder.predict(X_test)

**the model is still trainable, although it now expects compressed representations as targets:**

autoencoder.fit(X_test, representations, nb_epoch=1)  # in this case the loss will be 0, so it's useless

**to keep training against the original inputs, just switch back output_reconstruction to True:**

autoencoder.layers[0].output_reconstruction = True
autoencoder.compile(optimizer='sgd', loss='mse')
autoencoder.fit(X_train, X_train, nb_epoch=10)``

Furthermore, I have been trouble also while compiling the network because I found that for some reason the build method of the AutoEncoder layer is never called, but since I'm not sure it is not a bug in my code I'm not posting it here.

Thank you for your time and for your great software!
",blauigris,None,2016-02-03T10:15:41Z,2016-02-04T12:42:22Z
1623,Convolutional layers for 3D,"This PR includes the following convolution layers:
- Convolution3D
- MaxPooling3D
- AveragePooling3D
- UpSampling3D
- ZeroPadding3D

And also the corresponding test functions for these layers.

You can use it like this:
Convolution3D(nb_filters, nb_time, nb_row, nb_col)
See the convolution 3D example in examples/shapes_3d_cnn.py by @MinhazPalasara.

The shape of the underlaying 5D tensor:
        `(samples, channels, time, rows, cols)` if dim_ordering='th'
        `(samples, time, rows, cols, channels)` if dim_ordering='tf'.

Here I used ""time"" for the case of movies, of course it can be depth of a 3D volume. I didn't use the notion ""depth"" because some people use ""depth"" to stand for filter or channel, the word ""depth"" sometimes appears in the docstring of Keras when it means channel.

The following functions are added into theano_backend.py:
- conv3d
- pool3d
- resize_volumes
- spatial_3d_padding

But notice that, currently, these layers won't work in tensorflow backend, due the fact that there is no convolution3d ops implemented in tensorflow. It would be great if anyone can implement it.

Details about convolutional 3D in theano:

   There are two implementations available in theano, I used `conv3d2d.conv3d` for both GPU and CPU, because it's faster:
- on CPU:

```
        *  conv3d2d.conv3d:    160 ms per loop
output:
[  2.30778933   2.12729692  -3.06885958  -4.90572691  10.89875412
   3.7447443   -4.60463953   8.3501606    3.69148254  -0.93439424]

        *  nnet.conv3D: 1.19 s per loop
output:
[  2.30778956   2.12729645  -3.0688591   -4.90572643  10.89875507
   3.74474525  -4.60463953   8.35016346   3.69148254  -0.93439448]
```
- on GPU (k40):

```
        *  conv3d2d.conv3d:    36.2 ms per loop
output:
[  2.30778933   2.12729692  -3.06885958  -4.90572691  10.89875412
   3.7447443   -4.60463953   8.3501606    3.69148254  -0.93439424]

       *  nnet.conv3D: 941 ms per loop
output:
[  2.30778956   2.12729645  -3.0688591   -4.90572643  10.89875507
   3.74474525  -4.60463953   8.35016346   3.69148254  -0.93439448]

```

Notice that there are precision differences with `conv3d2d.conv3d` on GPU and CPU. The testing code can be found in this discussion: https://groups.google.com/d/msg/theano-users/1S9_bZgHxVw/0cQR9a4riFUJ.

Another PR(#718) was created by @MinhazPalasara  but it's out dated. Many functions, the test example and test dataset in this PR are taken from #718, thanks @MinhazPalasara, @rbharath, @fchollet and others for improving that codes and giving suggestions.

Be careful that, these codes are not tested restrictedly, please report bugs if you encountered any.
",oeway,None,2016-02-02T13:49:49Z,2016-05-06T07:50:19Z
1594,Bug/Issue when loading weights on graph model,"I have included the model.py. Basically I can train the model just fine, however when I attempt to reload weights, it raises an exception that it can't find some part of the weights.

```
Using gpu device 0: GeForce GTX 980 (CNMeM is disabled)
/usr/local/lib/python2.7/dist-packages/theano/tensor/signal/downsample.py:5: UserWarning:

downsample module has been moved to the pool module.

Compiling models...
---------------------------------------------------------------------------
AssertionError                            Traceback (most recent call last)
/usr/lib/python2.7/dist-packages/IPython/utils/py3compat.pyc in execfile(fname, *where)
    202             else:
    203                 filename = fname
--> 204             __builtin__.execfile(filename, *where)

/home/ubuntumax/keras_branch/keras-dsb/experiment.py in <module>()
    309             run(sys.argv[2])
    310         elif sys.argv[1] == 'continue':
--> 311             run(sys.argv[2], cont=True)
    312         elif sys.argv[1] == 'submission':
    313             submission(sys.argv[2])

/home/ubuntumax/keras_branch/keras-dsb/experiment.py in run(experiment_name, cont)
     80     # load weights (if continue experiment)
     81     if cont:
---> 82         model_systole.load_weights(experiment_path + '/' + META_DIR + '/' + MODEL_SYS_W)
     83         model_diastole.load_weights(experiment_path + '/' + META_DIR + '/' + MODEL_DIAS_W)
     84     # import pre-process module

/usr/local/lib/python2.7/dist-packages/keras/models.pyc in load_weights(self, filepath)
   1230         g = f['graph']
   1231         weights = [g['param_{}'.format(p)] for p in range(g.attrs['nb_params'])]
-> 1232         self.set_weights(weights)
   1233         f.close()
   1234 

/usr/local/lib/python2.7/dist-packages/keras/layers/containers.pyc in set_weights(self, weights)
    526         for layer in self.nodes.values():
    527             nb_param = len(layer.get_weights())
--> 528             layer.set_weights(weights[:nb_param])
    529             weights = weights[nb_param:]

/usr/local/lib/python2.7/dist-packages/keras/layers/containers.pyc in set_weights(self, weights)
    157         for i in range(len(self.layers)):
    158             nb_param = len(self.layers[i].params)
--> 159             self.layers[i].set_weights(weights[:nb_param])
    160             weights = weights[nb_param:]
    161 

/usr/local/lib/python2.7/dist-packages/keras/layers/normalization.pyc in set_weights(self, weights)
     70         K.set_value(self.running_mean, weights[-2])
     71         K.set_value(self.running_std, weights[-1])
---> 72         super(BatchNormalization, self).set_weights(weights[:-2])
     73 
     74     def get_output(self, train):

/usr/local/lib/python2.7/dist-packages/keras/layers/core.pyc in set_weights(self, weights)
    211         assert len(self.params) == len(weights), ('Provided weight array does not match layer weights (' +
    212                                                   str(len(self.params)) + ' layer params vs. ' +
--> 213                                                   str(len(weights)) + ' provided weights)')
    214         for p, w in zip(self.params, weights):
    215             if K.get_value(p).shape != w.shape:

AssertionError: Provided weight array does not match layer weights (2 layer params vs. 0 provided weights)

```

Graph used:

```
conv = Sequential()
conv.add(Activation(activation=scale, input_shape=(30, 128, 128)))

conv.add(Convolution2D(64, 3, 3, border_mode='same'))
conv.add(Activation('relu'))
conv.add(Convolution2D(64, 3, 3, border_mode='same'))
conv.add(Activation('relu'))
conv.add(MaxPooling2D(pool_size=(2, 2)))
conv.add(BatchNormalization())
conv.add(Dropout(0.2))

conv.add(Convolution2D(128, 3, 3, border_mode='same'))
conv.add(Activation('relu'))
conv.add(Convolution2D(128, 3, 3, border_mode='same'))
conv.add(Activation('relu'))
conv.add(MaxPooling2D(pool_size=(2, 2)))
conv.add(BatchNormalization())
conv.add(Dropout(0.2))

conv.add(Convolution2D(256, 3, 3, border_mode='same'))
conv.add(Activation('relu'))
conv.add(Convolution2D(256, 3, 3, border_mode='same'))
conv.add(Activation('relu'))
conv.add(MaxPooling2D(pool_size=(2, 2)))
conv.add(BatchNormalization())
conv.add(Dropout(0.2))

conv.add(Convolution2D(512, 3, 3, border_mode='same'))
conv.add(Activation('relu'))
conv.add(Convolution2D(512, 3, 3, border_mode='same'))
conv.add(Activation('relu'))
conv.add(MaxPooling2D(pool_size=(2, 2)))
conv.add(BatchNormalization())
conv.add(Dropout(0.2))

conv.add(Convolution2D(512, 3, 3, border_mode='same'))
conv.add(Activation('relu'))
conv.add(Convolution2D(512, 3, 3, border_mode='same'))
conv.add(Activation('relu'))
conv.add(MaxPooling2D(pool_size=(2, 2)))
conv.add(BatchNormalization())
conv.add(Dropout(0.2))

conv.add(Convolution2D(512, 3, 3, border_mode='same'))
conv.add(Activation('relu'))
conv.add(Convolution2D(512, 3, 3, border_mode='same'))
conv.add(Activation('relu'))
conv.add(MaxPooling2D(pool_size=(2, 2)))
conv.add(BatchNormalization())
conv.add(Dropout(0.2))
conv.add(Flatten())
#conv.add(Reshape((1, 2048)))

meta = Sequential()
# meta.add(Dense(512, input_dim=4))
# meta.add(Activation('relu'))
# meta.add(Reshape((1, 512)))
meta.add(LSTM(512, input_shape=(1, 4), return_sequences=False))
meta.add(Dropout(0.5))
#meta.add(Reshape((1, 512)))

model = Graph()
model.add_input(name='conv_input', input_shape=(30, 128, 128))
model.add_input(name='meta_input', input_shape=(4,))
model.add_node(Reshape((1, 4)),name='meta_reshape', input='meta_input')
model.add_node(conv, name='conv', input='conv_input')
model.add_node(meta, name='meta', input='meta_reshape')
model.add_node(Dense(2048+512, W_regularizer=l2(1e-3)), name='merge', inputs=['conv', 'meta'], merge_mode='concat')
model.add_node(Reshape((1, 2048+512)), name='merge_reshape', input='merge')
model.add_node(LSTM(512, return_sequences=False), name='lstm_0', input='merge_reshape')
model.add_node(Dropout(0.5), name='lstm_do_0', input='lstm_0')
# model.add_node(LSTM(512), name='lstm_1', input='lstm_do_0')
# model.add_node(Dropout(0.5), name='lstm_do_1', input='lstm_1')
model.add_node(Dense(1), name='merge_out', input='lstm_do_0')
model.add_output(name='output', input='merge_out')
```
",AntreasAntoniou,b'stale',2016-01-29T20:45:41Z,2017-06-23T01:11:16Z
1592,Convolutional Neural Net bug,"I am trying to run the specific code on a pc with a Titan X gpu:

```

from keras.models import Sequential
from keras.layers.core import Dense, Dropout, Activation, Flatten
from keras.layers.convolutional import Convolution2D, MaxPooling2D, MaxPooling1D, Convolution1D
from keras.optimizers import SGD
import numpy as np


X = [
[
[
[1,2,3],
[1,2,3],
[1,2,3],
[1,2,3]
]
]
]

Y = [
[1,2,3,4,5]
]

X = np.array(X)

Y = np.array(Y) 

Conv_size = 10
Dense_size = 10

filters = 5
rows= 2
cols= X.shape[-1]


model = Sequential()
model.add(Convolution2D(filters, rows, cols, activation='sigmoid' , input_shape = X.shape[1:]))
model.add(MaxPooling2D(pool_size=(rows, cols)))
model.add(Flatten())
model.add(Dense(Dense_size, activation='sigmoid'))
model.add(Dropout(0.5))
model.add(Dense(5, activation='linear'))
model.compile(loss='rmse', optimizer='sgd')
model.fit(X, Y, nb_epoch=50)


```

and it yields the following error

```

>>> model.add(Dense(Dense_size, activation='sigmoid'))
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/usr/local/lib/python2.7/dist-packages/keras/layers/containers.py"", line 68, in add
    self.layers[-1].set_previous(self.layers[-2])
  File ""/usr/local/lib/python2.7/dist-packages/keras/layers/core.py"", line 82, in set_previous
    assert self.input_ndim == len(layer.output_shape), ('Incompatible shapes: layer expected input with ndim=' +
  File ""/usr/local/lib/python2.7/dist-packages/keras/layers/core.py"", line 814, in output_shape
    '(got ' + str(input_shape[1:]) + '. '
Exception: The shape of the input to ""Flatten"" is not fully defined (got (5, 1, 0). Make sure to pass a complete ""input_shape"" or ""batch_input_shape"" argument to the first layer in your model.

```

also the versions are 

```
pip show theano | grep Version
Metadata-Version: 1.1
Version: 0.8.0.dev0

pip show keras | grep Version
Metadata-Version: 1.1
Version: 0.3.1
```

When i run the same code on another pc it passes!

```
>>> model = Sequential()
>>> model.add(Convolution2D(filters, rows, cols, activation='sigmoid' , input_shape = X.shape[1:]))
>>> model.add(MaxPooling2D(pool_size=(rows, cols)))
>>> model.add(Flatten())
>>> model.add(Dense(Dense_size, activation='sigmoid'))
>>> model.add(Dropout(0.5))
>>> model.add(Dense(5, activation='linear'))
>>> model.compile(loss='rmse', optimizer='sgd')

>>> model.fit(X, Y, nb_epoch=5)
Epoch 1/5
1/1 [==============================] - 0s - loss: 3.4482
Epoch 2/5
1/1 [==============================] - 0s - loss: 3.7623
Epoch 3/5
1/1 [==============================] - 0s - loss: 3.7835
Epoch 4/5
1/1 [==============================] - 0s - loss: 3.8206
Epoch 5/5
1/1 [==============================] - 0s - loss: 4.4849
<keras.callbacks.History object at 0x5751610>

```

It is a machine without gpu and versions 

```
pip show theano| grep Version
Metadata-Version: 1.1
Version: 0.7.0

pip show keras| grep Version
Metadata-Version: 2.0
Version: 0.3.0

```

What could i do in order to use such a good gpu ? 
Should i fall back to keras 3.0 or is it a theano problem ? 

Thank you in advance
",dpappas,None,2016-01-29T14:48:48Z,2016-12-23T16:42:17Z
1583,Fixed backend tests for `random_uniform` and `random_normal`,"It looks like this was a copy+paste bug where neither `random_uniform` nor the theano backend were being tested. Thanks for keras!
",awentzonline,None,2016-01-28T22:03:42Z,2016-01-28T23:16:43Z
1580,Embedding layer and Constraints,"Dear everyone,
what follows is not really a bug, but IMO it can be considered a sort of counter-intuitive behavior.

When enforcing unitary norm constraints on an embedding layer, the constraints are enforced on the columns of the embedding matrix (the embedding vector dimension) instead of the rows (the no. of embedding vectors).

 For instance consider the following setting, in which we have two embedding vectors of size 10:

``` python
import numpy as np
from keras.models import Sequential
from keras.layers.embeddings import Embedding
from keras.layers.core import Flatten, TimeDistributedDense, Activation

from keras.constraints import unitnorm

model = Sequential()
embedding_layer = Embedding(input_dim=2, output_dim=10, input_length=1, W_constraint=unitnorm())
model.add(embedding_layer)
model.add(Flatten())
model.add(Dense(output_dim=1))
model.add(Activation('sigmoid'))

model.compile(loss='binary_crossentropy', optimizer='adagrad')
model.fit(np.array([[0]]), np.array([0]), batch_size=1, nb_epoch=5, verbose=0)

embedding_matrix = embedding_layer.params[0].get_value()

print(embedding_matrix.shape)
print(np.linalg.norm(embedding_matrix[1, :]))
print(np.linalg.norm(embedding_matrix[:, 1]))
```

The unitary norm is enforced on each column of the matrix; in my opinion, it could make sense to enforce it on its rows (the actual embedding vectors).

``` bash
(2, 10)
2.25984
1.0
```

At the moment I'm working around this by using a custom Constraint:

``` python
class FixedNorm(Constraint):
    def __init__(self, m=1.):
        self.m = m

    def __call__(self, p):
        p = K.transpose(p)
        unit_norm = p / (K.sqrt(K.sum(K.square(p), axis=0)) + 1e-7)
        unit_norm = K.transpose(unit_norm)
        return unit_norm * self.m

    def get_config(self):
        return {'name': self.__class__.__name__, 'm': self.m}
```
",pminervini,b'stale',2016-01-28T15:18:37Z,2018-07-12T17:08:47Z
1574,theano support for 5d tensor in placeholder and rnn,"Added the possibility to create 5D tensor in theano,
correction of a bug in rnn which prevented output shape to
be different from input shape. (for 5D tensors)
",jeammimi,None,2016-01-28T09:03:11Z,2016-02-08T10:14:10Z
1567,Does Masking have a bug?,"It seems that `K.rnn` thinks that mask has 3 dimensions. How to get the error:

``` python
from keras.models import  Sequential
from keras.layers.recurrent import LSTM
from keras.layers.core import Masking

model = Sequential()
model.add(Masking(input_shape=(None, 8)))
model.add(LSTM(output_dim=256, return_sequences=True))

model.compile(loss='binary_crossentropy', optimizer='adam')
```

And the error is:

```
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
<ipython-input-7-23d1674d2143> in <module>()
----> 1 model.compile(loss='binary_crossentropy', optimizer='adam')

/home/eders/python/keras/keras/models.pyc in compile(self, optimizer, loss, class_mode)
    433         self.X_test = self.get_input(train=False)
    434 
--> 435         self.y_train = self.get_output(train=True)
    436         self.y_test = self.get_output(train=False)
    437 

/home/eders/python/keras/keras/layers/containers.pyc in get_output(self, train)
    126 
    127     def get_output(self, train=False):
--> 128         return self.layers[-1].get_output(train)
    129 
    130     def set_input(self):

/home/eders/python/keras/keras/layers/recurrent.pyc in get_output(self, train)
    148                                              initial_states,
    149                                              go_backwards=self.go_backwards,
--> 150                                              mask=mask)
    151         if self.stateful:
    152             self.updates = []

/home/eders/python/keras/keras/backend/theano_backend.pyc in rnn(step_function, inputs, initial_states, go_backwards, mask)
    448         mask = expand_dims(ones_like(T.sum(inputs, axis=-1)))
    449     else:
--> 450         mask = mask.dimshuffle(axes)
    451 
    452     def _step(input, mask, output_tm1, *states):

/home/eders/python/Theano/theano/tensor/var.pyc in dimshuffle(self, *pattern)
    358             pattern = pattern[0]
    359         op = theano.tensor.basic.DimShuffle(list(self.type.broadcastable),
--> 360                                             pattern)
    361         return op(self)
    362 

/home/eders/python/Theano/theano/tensor/elemwise.pyc in __init__(self, input_broadcastable, new_order, inplace)
    144                     raise ValueError((""new_order[%d] is %d, but the input ""
    145                                       ""only has %d axes."") %
--> 146                                      (i, j, len(input_broadcastable)))
    147                 if j in new_order[(i + 1):]:
    148                     raise ValueError(""The same input dimension may not appear ""

ValueError: new_order[2] is 2, but the input only has 2 axes.
```
",EderSantana,None,2016-01-27T16:54:22Z,2016-02-01T22:24:21Z
1558,Incorporating recurrent convolutionnal layers to keras,"Hi, 
I developped a recurrent convolutionnal layer according to  LSTM Network: A Machine Learning Approach for Precipitation Nowcasting (http://arxiv.org/pdf/1506.04214v1.pdf) for keras.

![gt_animation](https://cloud.githubusercontent.com/assets/6568042/12576861/f64afffc-c416-11e5-8b8d-78de0d6f3735.gif)

![gt3_animation](https://cloud.githubusercontent.com/assets/6568042/12576868/03aa5ee0-c417-11e5-9d41-b46ee04c2445.gif)

Before doing a pull request I would have liked some advices:
for the convolution part ,usually you can use or dim_ordering=""tf"" or ""th"" .
I can't make ""th"" work. I tried to debug, but I don't know why it does not work.

To use this layer, it is also nice to have a time distributed version of the 2D convolution layer.
I implemented one, but maybe it is too much to add two layers in the same pull?

I can't install tensorflow backend so I don't know if it works with it.

What are your suggestions?
",jeammimi,b'stale',2016-01-26T14:24:29Z,2017-06-22T21:13:15Z
1524,One class classification,"Hey there,

I have a binary cross-entropy problem that I would like to solve using one-class classification.

So to do this, I have the following model...

```
    model = Sequential()
    model.add(Dense(256, input_shape=(1022, )))
    model.add(Activation(""relu""))
    model.add(Dropout(0.5))
    model.add(Dense(128))
    model.add(Activation(""relu""))
    model.add(Dropout(0.5))
    model.add(Dense(1))
    model.add(Activation(""sigmoid""))

    adam = Adam()
    model.compile(loss='binary_crossentropy', optimizer=adam, class_mode=""binary"")
```

However, this is returning the following error.

```
ValueError: Input dimension mis-match. (input[0].shape[1] = 2, input[1].shape[1] = 1)
Apply node that caused the error: Elemwise{Composite{EQ(i0, RoundHalfAwayFromZero(i1))}}(<TensorType(float32, matrix)>, Elemwise{Composite{scalar_sigmoid((i0 + i1))}}[(0, 0)].0)
Toposort index: 54
Inputs types: [TensorType(float32, matrix), TensorType(float32, matrix)]
Inputs shapes: [(8, 2), (8, 1)]
Inputs strides: [(8, 4), (4, 4)]
Inputs values: ['not shown', 'not shown']
Outputs clients: [[Sum{acc_dtype=int64}(Elemwise{Composite{EQ(i0, RoundHalfAwayFromZero(i1))}}.0)]]

HINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.
HINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.
```

Can anyone help?
",KeironO,None,2016-01-21T16:48:22Z,2016-01-21T17:08:15Z
1508,Unable to load_weights when using multiple merge layer,"Hi, Heros
i have a small program that using the ""dot merge"".
it goes smoothly in training phase,but when i want to do some test with the model, the parameters cannot be loaded into, and it reported an error:
""AssertionError: Provided weight array does not match layer weights (12 layer params vs. 3 provided weights)""
Related codes are as follows (irrelevant parts are removed. ):

a1=Sequential()
a1.add(Embedding(100,input_length=maxlen))
a1.add(LSTM(100,return_sequence=True))

a2=Sequential()
a2.add(Embedding(100,input_length=maxlen))
a2.add(LSTM(100,return_sequence=True, go_backwards=True))
# output: (n_sample, maxlen, dim)

a = Sequential()
a.add(Merge([a1,a2], mode='concat'))

b1=Sequential()
b1.add(Embedding(100,input_length=maxlen))
b1.add(LSTM(100,return_sequence=True))

b2=Sequential()
b2.add(Embedding(100,input_length=maxlen))
b2.add(LSTM(100,return_sequence=True, go_backwards=True))
# output: (n_sample, dim)

b = Sequential()
b.add(Merge([b1,b2], mode='concat'))
b.add(TimeDistributedMerge(mode='sum'))
# output: (n_sample, maxlen ,dim)

b_rep = Sequential()
b_rep.add(Merge([b1,b2], mode='concat'))
b_rep.add(TimeDistributedMerge(mode='sum'))
b_rep.add(RepeatVector(maxlen))
# output: (n_sample, maxlen)

c = Sequential()
c.add(Merge([a,b_rep], mode='concat'))
c.add(TimeDistributedMerge(mode='sum'))
c.add(Dense(maxlen))
# hope to output : (n_sample, dim)

res=Sequential()
res.add(Merge([b_rep,c], mode='dot', dot_axes=([1],[1]))) #also tried other merge mode, such as: res.add(Merge([b,c], mode='concat')) but it also report the error. so it seems that not the problem only with the DOT mode, but the Merge layer.
# the following the is debug code

w = res.get_weights()  
model.set_weights(w)      #this will cause the error, also tried using save/load_weights, but do not solve the problem

i have tried 0.2.0, 0.3.0, 0.3.1 versions, but none of them can solve this problem.
Wish anyone can help!
",ymcui,None,2016-01-20T09:48:32Z,2016-01-25T09:48:42Z
1474,"In Merged two Embeddings, trainable=False => trainable=True cause Error","This works

``` python
import numpy as np
from keras.models import Graph
from keras.layers.core import LambdaMerge
from keras.layers.embeddings import Embedding
from keras.objectives import mse

index_size=3
vocab_size=3
vector_size=2
code_dim=2
maxlen=1

kerasmodel = Graph()

kerasmodel.add_input(name='iword' , input_shape=(1,), dtype=int)
kerasmodel.add_node(Embedding(vocab_size, vector_size,
                              trainable=False,
                              weights=[np.array([[1,2],[3,4],[5,6]],'float32')]
                              ),name='embedword', input='iword')

kerasmodel.add_input(name='index' , input_shape=(1,), dtype=int)
kerasmodel.add_node(Embedding(index_size, vector_size,
                              trainable=False,
                              weights=[np.array([[10,20],[30,40],[50,60]],'float32')]
                              ),name='embedindex', input='index')

kerasmodel.add_node(LambdaMerge([kerasmodel.nodes['embedword'],kerasmodel.nodes['embedindex']] ,
                                lambda x: x[0].mean(-2)+x[1].mean(-2)
                                ,output_shape=(vector_size,)
                                 ),
                    name='merege'
                    )

kerasmodel.add_output(name='out',input='merege')
kerasmodel.compile('rmsprop', {'out':'mse'})

print kerasmodel.predict({'index':np.array([[0,0],[1,0]]),'iword':np.array([[1,0],[1,1]]) })
```

However, comment out

``` python
#trainable=False 
```

in these two Embeddings cause error 

``` bash
Traceback (most recent call last):
  File ""for-debug-post.py"", line 39, in <module>
    kerasmodel.compile('rmsprop', {'out':'mse'})
  File ""/usr/lib64/python2.7/site-packages/keras/models.py"", line 1076, in compile
    self._train = K.function(train_ins, [train_loss], updates=updates)
  File ""/usr/lib64/python2.7/site-packages/keras/backend/theano_backend.py"", line 394, in function
    return Function(inputs, outputs, updates=updates)
  File ""/usr/lib64/python2.7/site-packages/keras/backend/theano_backend.py"", line 386, in __init__
    allow_input_downcast=True, **kwargs)
  File ""/usr/lib64/python2.7/site-packages/theano/compile/function.py"", line 266, in function
    profile=profile)
  File ""/usr/lib64/python2.7/site-packages/theano/compile/pfunc.py"", line 489, in pfunc
    no_default_updates=no_default_updates)
  File ""/usr/lib64/python2.7/site-packages/theano/compile/pfunc.py"", line 198, in rebuild_collect_shared
    (store_into, update_d[store_into]))
ValueError: ('this shared variable already has an update expression', (<CudaNdarrayType(float32, matrix)>, GpuFromHost.0))
```
",niitsuma,b'stale',2016-01-15T12:20:38Z,2017-06-22T23:10:00Z
1447,Autoencoder validation split bug,"The following model fails:

```
ae = Sequential()
encoder = containers.Sequential([Dense(input_dim=n_in, output_dim=n_out, activation='sigmoid')])
decoder = containers.Sequential([Dense(input_dim=n_out, output_dim=n_in, activation='sigmoid')])
ae.add(AutoEncoder(encoder=encoder, decoder=decoder,
                   output_reconstruction=False))
ae.compile(loss='mean_squared_error', optimizer='rmsprop')
ae.fit(X_train_tmp, X_train_tmp, batch_size=batch_size, nb_epoch=nb_epoch, validation_split=0.1)
```

The first epoch goes fine, and then it gives error message
`File ""/usr/local/lib/python2.7/dist-packages/keras/models.py"", line 581, in fit
    shuffle=shuffle, metrics=metrics)
  File ""/usr/local/lib/python2.7/dist-packages/keras/models.py"", line 254, in _fit
    verbose=0)
  File ""/usr/local/lib/python2.7/dist-packages/keras/models.py"", line 308, in _test_loop
    batch_outs = f(ins_batch)`

```
ValueError: Input dimension mis-match. (input[0].shape[1] = 400, input[2].shape[1] = 626)
Apply node that caused the error: Elemwise{Composite{sqr((scalar_sigmoid((i0 + i1)) - i2))}}[(0, 0)](Dot22.0, InplaceDimShuffle{x,0}.0, <TensorType(float32, matrix)>)
Toposort index: 5
Inputs types: [TensorType(float32, matrix), TensorType(float32, row), TensorType(float32, matrix)]
Inputs shapes: [(100, 400), (1, 400), (100, 626)]
Inputs strides: [(1600, 4), (1600, 4), (2504, 4)]
Inputs values: ['not shown', 'not shown', 'not shown']
Outputs clients: [[Sum{axis=[1], acc_dtype=float64}(Elemwise{Composite{sqr((scalar_sigmoid((i0 + i1)) - i2))}}[(0, 0)].0)]]
```

I don't see why that wouldn't work, as it is 1:1 with the FAQs. Any ideas?
",HristoBuyukliev,b'stale',2016-01-11T22:20:30Z,2017-06-22T23:09:48Z
1433,Updating WeightRegularizer parameters results in non-deterministic behaviour,"Hi all

I think I've found a really strange bug in weight regularization. Basically, I'm pretraining some autoencoder layers with l2 regularization of 0.001, and then adding the pretrained layers to my network. At this point, I'd like to change the l2 regularization weight to 0.01.

I thought I'd start by changing the l2 reg value to the same value it currently is, to see if that would affect anything. Adding the following lines of code

``` python
for r in model.regularizers:
    tmp = regularizer.l2
    regularizer.l2 = tmp
```

before model compilation dramatically affects the resulting training loss. In fact, the following code

``` python
for r in model.regularizers:
    tmp = regularizer.l2
    print(tmp)
    regularizer.l2 = tmp
```

gets a different training loss yet again.

What could be the cause of this non-determinism? Is there some Theano trickery going on behind the scenes?

Thanks
Kris
",around1991,None,2016-01-08T23:02:40Z,2016-01-09T00:45:22Z
1428,fit_generator uses the wrong axis to get the batch_size,"When the generator returns a numpy array and not a list, the `fit_generator` function uses the wrong axis to determine the `batch_size`. This results in a wrong counting of the samples seen.
For example, if the generator returns numpy arrays with shape `(128, 40, ..)`, then the number seen will be increased in 40 steps instead of 128. This can cause an Exception if the `sampes_per_epoche` is not dividable by 40.  This bug is fixed in pull request #1407.
",berleon,None,2016-01-08T18:21:55Z,2016-02-05T13:42:26Z
1413,Possible theano bug when using time distributed layers (Windows),"I think using the step function that uses the Theano rnn function may cause a crash sometimes.
I experienced many crashes when used a relu activation and when increasing the number of hidden units in the TimeDistributedDense layer (e.g. 128 -> 512)

I solved it simply by replacing the 'rnn' function with my implementation.

Did anyone encounter such a problem?
",loyeamen,b'stale',2016-01-06T17:07:43Z,2017-06-22T23:11:12Z
1404,model.train_on_batch(accuracy = True) bug with Theano backend,"Hi Folks,

I switched some code over from the Tensorflow backend to the Theano backend, and I got a strange formatting error. The code is as follows:

```
trainL, acc = model.train_on_batch(cXtrain, cYtrain, accuracy = True)
print ""loss={:.3f}, acc={:.3f}"".format(aveLoss, acc)
```

when using the TensorFlow backend, acc is a np.float32. When using the theano backend, acc is a numpy ndarray. I don't have time to dig through to figure out what's happening but I figured I'd report this.

Jack
",jmhessel,b'stale',2016-01-05T02:38:16Z,2017-06-22T23:11:10Z
1386,BUG: BatchNormalization in nested models throws DisconnectedInputError,"As mentioned by @Sebubu in #1275 the following code results in a DisconnectedInputError:
He notes removing the BatchNormalization layer fixes the code.

``` python
from keras.models import Graph,  Sequential
from keras.layers.core import Dense
from keras.layers.normalization import BatchNormalization
from keras.layers.advanced_activations import PReLU


g = Graph()
g.add_input(""input"", input_shape=[20])
g.add_node(Dense(10), ""dense"", ""input"")
g.add_node(BatchNormalization(),""bn"", ""dense"")
g.add_node(PReLU(),""activ"", ""bn"")
g.add_output(""output"", ""activ"")
print ""g output "" + str(g.output_shape)

g2 = Graph()
g2.add_input(""input"", input_shape=[10])
g2.add_node(Dense(15), ""dense"", ""input"")
g2.add_node(BatchNormalization(),""bn"", ""dense"")
g2.add_node(PReLU(),""activ"", ""bn"")
g2.add_output(""output"", ""activ"")

model = Sequential()

model.add(g)
model.add(g2)

model.compile(loss=""mse"",optimizer=""adadelta"")
```

The problem here is that in the `BatchNormalization` layer the `update` rules of the `running_mean` and `running_std` members are set in the `build` method. When the input of the batch norm layer changes, the `update` rules are not updated accordingly. 
",berleon,None,2015-12-31T15:51:43Z,2016-01-01T20:02:15Z
1383,Fixed dnn_conv output size,"This patch closes #1276.
As I understand the bug, the padding is applied on both sides horizontally and vertically when using custom padding in cuDNN.
To be consistent with the behavior of [T.nnet.conv.conv2d](https://github.com/fchollet/keras/blob/master/keras/backend/theano_backend.py#L577-L581) the same trick is applied here.
The convolution is padded according to the `full` mode and then sliced to have the same size as the input.
",tboquet,None,2015-12-31T03:35:36Z,2016-03-24T14:44:55Z
1362,Per-epoch validation is broken for AutoEncoder with output_reconstruction=False,"The per-epoch validation (e.g.: using validation_split=0.25) is broken for AutoEncoder with output_reconstruction=False. This is because in the AutoEncoder class:

``` python
    def get_output(self, train=False):
        if not train and not self.output_reconstruction:
            return self.encoder.get_output(train)

        return self.decoder.get_output(train)
```

This source code is currently located at: https://github.com/fchollet/keras/blob/master/keras/layers/core.py#L1174

For validation purposes, Keras uses `y_test = output.get_output(False)`. Since both `train` and `self.output_reconstruction` are False at this point, the validation output will be encoded values rather than reconstructed values, leading to a dimension mismatch. Since `output_reconstruction=False`, this leads to validation being broken for the majority of AutoEncoder users. I hoped to submit a fix for this, but I wasn't quite sure of a way to fix within the context of Keras. I might have time to fix this if given a direction, if not, I will just leave this bug report here.

-Cory
",corywalker,b'stale',2015-12-27T21:04:40Z,2017-06-22T23:11:00Z
1360,why lstm loss is NaN for pre-trained word2vec,"I'm a theano and keras fresher, and want to learn them , which I think very interesting and helpful.
The following question confuses me about for one week. But I can't work it out after try some ways mentioned before.
I want to do sentiment analysis for texts to three classes. And I train word2vec(dim = 600) with gensim.
My train data is 10475 sequences in different length. label shape is [10475,3] After setting maxlen of sequence 200, every sequence are converted to 200*600 2D array.If some sequence's length is less than 200, then the remaining values is filled with 0(padding), resulting some rows are all zeroes. And then I feed them into LSTM, 
## LSTM code as following:

```
    sgd = SGD(lr=0.001, decay = 1e-6, momentum=0.9, nesterov=True, clipnorm=0.3)
    rmsprop = RMSprop(clipnorm=0.1,epsilon=5e-04)
    adam = Adam(epsilon=1e-03,clipnorm=0.1)
    model = Sequential()

    model.add(LSTM(output_dim=300,input_length=200,input_dim=600)) 
#     model.add(Dropout(0.5))
    model.add(BatchNormalization(epsilon=1e-04))
    model.add(Dense(nb_classes))
    model.add(Activation('softmax'))
    model.compile(loss='mean_squared_error',
                  optimizer='adam', class_mode=""categorical"")
```

model.fit(train,label,batch_size=100,nb_epoch=4,verbose=1,shuffle=True,validation_split=0.1,show_accuracy=True)
## But Getting:
## loss: nan

Train on 9430 samples, validate on 1048 samples
Epoch 1/4
9430/9430 [==============================] - 99s - loss: nan - acc: 0.2992 - val_loss: nan - val_acc: 0.1355
Epoch 2/4
9430/9430 [==============================] - 96s - loss: nan - acc: 0.2992 - val_loss: nan - val_acc: 0.1355
Epoch 3/4
9430/9430 [==============================] - 96s - loss: nan - acc: 0.2992 - val_loss: nan - val_acc: 0.1355
Epoch 4/4
1600/9430 [====>.........................] - ETA: 75s - loss: nan - acc: 0.3038

I test different optimizer,also improve epsilon value, set clipnorm(in optimizer above) and different loss functions('mean_squared_error', 'categorical_crossentropy') and so on, but failed.
#### Also in cpu or gpu mode, loss value is also nan.
# ##Even I switch to Convolution2D:

```
    nb_feature_maps = 120
    n_gram = 10
    model.add(Convolution2D(nb_filter = nb_feature_maps, nb_row=n_gram, nb_col=600,input_shape=(1,200,600)))
    model.add(Activation('relu'))

    model.add(MaxPooling2D(pool_size=(maxlen - n_gram + 1, 1)))
    model.add(Dropout(0.25))

    model.add(Flatten())
    model.add(Dense(128))
    model.add(Activation('tanh'))
    model.add(Dropout(0.5))
    model.add(Dense(3))
    model.add(Activation('softmax'))

    model.compile(loss='mean_squared_error',
              optimizer='sgd', class_mode=""categorical"")
```
### The loss values remain nan
### Ways to solve?

So I'm wondering what's the real reason for the NaN loss value? How to solve or debug it?
Is the word2vec data wrong , padding method wrong or other?
If keras can't solve, I have to choose another deep learning package, or the reason is theano?
what can I do then? please help.
",liyi193328,b'stale',2015-12-27T09:04:04Z,2019-05-21T08:03:04Z
1351,why 'Graph' object has no attribute 'fit_generator'?,"I have built a graph and have a large number of data. The fit_generator method has been used. However, the error "" 'Graph' object has no attribute 'fit_generator' "" occurred. I have updated keras and still have the problem. Is it a bug? 
",lvzhiqiang,None,2015-12-25T03:40:21Z,2015-12-25T18:05:12Z
1350,Keras Model working in Version 0.2.0 is giving error in 0.3.0 with updated Theano,"Hi @fchollet ,

I wrote a simple LSTM based model for doing Boundary Detection in text data using the following code.  This model was working fine with version 0.2.0 of Keras but after I updated Keras and Theano to the latest version using the git repo of each module, I have started getting the following errors (I have added the THEANO VERBOSE output as well):

```
$ THEANO_FLAGS=""optimizer=fast_compile,exception_verbosity=high"" python model.py 
EntityExtractor_Model INFO 2015-12-24 18:46:53,845:Started Logger
Couldn't import dot_parser, loading of dot files will not be possible.
EntityExtractor_Model INFO 2015-12-24 18:46:54,253:Using Keras version 0.3.0
EntityExtractor_Model INFO 2015-12-24 18:46:54,253:Using Theano version 0.7.0.dev-54186290a97186b9c6b76317e007844529a352f4
Using Theano backend.
Reloaded Ext.
EntityExtractor INFO 2015-12-24 18:46:54,356:Started Logger
EntityExtractor INFO 2015-12-24 18:46:54,370:Initializing WordToken word_dict with 10000 items
EntityExtractor_Model INFO 2015-12-24 18:46:54,370:Parameters: vocab_size = 10004, embedding_size = 128, maxlen = 100, boundary_size = 6, category_size = 96, embedding_size = 128, hidden_layer_size = 100
EntityExtractor_Model INFO 2015-12-24 18:46:54,370:Parameters: vocab_size = 10004, embedding_size = 128, maxlen = 100, boundary_size = 6, category_size = 96, embedding_size = 128, hidden_layer_size = 100
EntityExtractor_Model INFO 2015-12-24 18:46:54,370:Building Model
EntityExtractor_Model INFO 2015-12-24 18:46:54,370:Init Model with vocab_size = 10004, embedding_size = 128, maxlen = 100
EntityExtractor_Model INFO 2015-12-24 18:46:54,398:Added Embedding Layer
EntityExtractor_Model INFO 2015-12-24 18:46:54,401:Added Dropout Layer
EntityExtractor_Model INFO 2015-12-24 18:46:54,431:Added LSTM Layer
EntityExtractor_Model INFO 2015-12-24 18:46:54,432:Added Dropout Layer
EntityExtractor_Model INFO 2015-12-24 18:46:54,435:Added LSTM Layer
EntityExtractor_Model INFO 2015-12-24 18:46:54,436:Created model with following config:
{
    ""layers"": [
        {
            ""name"": ""Embedding"", 
            ""output_dim"": 128, 
            ""W_constraint"": null, 
            ""input_shape"": [
                10004
            ], 
            ""cache_enabled"": true, 
            ""init"": ""uniform"", 
            ""input_dim"": 10004, 
            ""mask_zero"": true, 
            ""W_regularizer"": null, 
            ""activity_regularizer"": null, 
            ""input_length"": 100
        }, 
        {
            ""cache_enabled"": true, 
            ""name"": ""Dropout"", 
            ""p"": 0.5
        }, 
        {
            ""name"": ""LSTM"", 
            ""inner_activation"": ""hard_sigmoid"", 
            ""go_backwards"": false, 
            ""output_dim"": 100, 
            ""stateful"": false, 
            ""cache_enabled"": true, 
            ""init"": ""glorot_uniform"", 
            ""inner_init"": ""orthogonal"", 
            ""input_dim"": 128, 
            ""return_sequences"": true, 
            ""activation"": ""sigmoid"", 
            ""forget_bias_init"": ""one"", 
            ""input_length"": null
        }, 
        {
            ""cache_enabled"": true, 
            ""name"": ""Dropout"", 
            ""p"": 0.5
        }, 
        {
            ""name"": ""LSTM"", 
            ""inner_activation"": ""hard_sigmoid"", 
            ""go_backwards"": false, 
            ""output_dim"": 6, 
            ""stateful"": false, 
            ""cache_enabled"": true, 
            ""init"": ""glorot_uniform"", 
            ""inner_init"": ""orthogonal"", 
            ""input_dim"": 100, 
            ""return_sequences"": true, 
            ""activation"": ""softmax"", 
            ""forget_bias_init"": ""one"", 
            ""input_length"": null
        }
    ], 
    ""name"": ""Sequential""
}
EntityExtractor_Model INFO 2015-12-24 18:46:54,436:Compiling model with optimizer adam
EntityExtractor_Model INFO 2015-12-24 18:47:53,062:Model compiled in 58.6263 seconds.
EntityExtractor_Model INFO 2015-12-24 18:48:44,030:Loaded data shapes:
X_train: (39459, 100), Y_train: (39459, 100, 6)
X_test: (9452, 100), Y_test: (9452, 100, 6)
EntityExtractor_Model INFO 2015-12-24 18:48:44,030:Starting Epochs 0 to 1
Train on 39459 samples, validate on 9452 samples
Epoch 1/1
Traceback (most recent call last):
  File ""model.py"", line 136, in <module>
    model.fit(X_train,Y_train, validation_data=(X_test, Y_test), nb_epoch=save_every, verbose=2)
  File ""/usr/local/lib/python2.7/dist-packages/keras/models.py"", line 581, in fit
    shuffle=shuffle, metrics=metrics)
  File ""/usr/local/lib/python2.7/dist-packages/keras/models.py"", line 239, in _fit
    outs = f(ins_batch)
  File ""/usr/local/lib/python2.7/dist-packages/keras/backend/theano_backend.py"", line 365, in __call__
    return self.function(*inputs)
  File ""/usr/local/lib/python2.7/dist-packages/theano/compile/function_module.py"", line 871, in __call__
    storage_map=getattr(self.fn, 'storage_map', None))
  File ""/usr/local/lib/python2.7/dist-packages/theano/gof/link.py"", line 314, in raise_with_op
    reraise(exc_type, exc_value, exc_trace)
  File ""/usr/local/lib/python2.7/dist-packages/theano/compile/function_module.py"", line 859, in __call__
    outputs = self.fn()
ValueError: Input dimension mis-match. (input[0].shape[1] = 128, input[1].shape[1] = 100)
Apply node that caused the error: Elemwise{mul,no_inplace}(DimShuffle{x,0}.0, Elemwise{mul,no_inplace}.0)
Toposort index: 330
Inputs types: [TensorType(float32, row), TensorType(int32, matrix)]
Inputs shapes: [(1, 128), (128, 100)]
Inputs strides: [(512, 4), (400, 4)]
Inputs values: ['not shown', 'not shown']
Outputs clients: [[Elemwise{true_div,no_inplace}(Elemwise{mul,no_inplace}.0, DimShuffle{x,x}.0)]]

Backtrace when the node is created:
  File ""/usr/local/lib/python2.7/dist-packages/keras/models.py"", line 85, in weighted
    score_array *= mask

Debugprint of the apply node: 
Elemwise{mul,no_inplace} [id A] <TensorType(float64, matrix)> ''   
 |DimShuffle{x,0} [id B] <TensorType(float32, row)> ''   
 | |Elemwise{true_div,no_inplace} [id C] <TensorType(float32, vector)> 'mean'   
 |Elemwise{mul,no_inplace} [id D] <TensorType(int32, matrix)> ''   
   |Elemwise{second,no_inplace} [id E] <TensorType(int32, matrix)> ''   
   | |<TensorType(int32, matrix)> [id F] <TensorType(int32, matrix)>
   | |TensorConstant{(1, 1) of 1} [id G] <TensorType(int32, (True, True))>
   |Elemwise{sub,no_inplace} [id H] <TensorType(int8, matrix)> ''   
     |TensorConstant{(1, 1) of 1} [id I] <TensorType(int8, (True, True))>
     |Elemwise{eq,no_inplace} [id J] <TensorType(int8, matrix)> ''   
       |<TensorType(int32, matrix)> [id F] <TensorType(int32, matrix)>
       |TensorConstant{(1, 1) of 0} [id K] <TensorType(int8, (True, True))>

Storage map footprint:
 - AdvancedSubtensor1.0, Shape: (12800, 128), ElemSize: 4 Byte(s), TotalSize: 6553600 Byte(s)
 - Elemwise{Cast{float32}}.0, Shape: (128, 100, 128), ElemSize: 4 Byte(s), TotalSize: 6553600 Byte(s)
 - DimShuffle{1,0,2}.0, Shape: (100, 128, 128), ElemSize: 4 Byte(s), TotalSize: 6553600 Byte(s)
 - Subtensor{int64::}.0, Shape: (100, 128, 128), ElemSize: 4 Byte(s), TotalSize: 6553600 Byte(s)
 - Subtensor{:int64:}.0, Shape: (100, 128, 128), ElemSize: 4 Byte(s), TotalSize: 6553600 Byte(s)
 - for{cpu,scan_fn}.0, Shape: (101, 128, 100), ElemSize: 4 Byte(s), TotalSize: 5171200 Byte(s)
 - for{cpu,scan_fn}.1, Shape: (101, 128, 100), ElemSize: 4 Byte(s), TotalSize: 5171200 Byte(s)
 - <TensorType(float32, matrix)>, Shared Input, Shape: (10004, 128), ElemSize: 4 Byte(s), TotalSize: 5122048 Byte(s)
 - <TensorType(float32, matrix)>, Shared Input, Shape: (10004, 128), ElemSize: 4 Byte(s), TotalSize: 5122048 Byte(s)
 - <TensorType(float32, matrix)>, Shared Input, Shape: (10004, 128), ElemSize: 4 Byte(s), TotalSize: 5122048 Byte(s)
 - Elemwise{Cast{float32}}.0, Shape: (128, 100, 100), ElemSize: 4 Byte(s), TotalSize: 5120000 Byte(s)
 - DimShuffle{1,0,2}.0, Shape: (100, 128, 100), ElemSize: 4 Byte(s), TotalSize: 5120000 Byte(s)
 - Subtensor{:int64:}.0, Shape: (100, 128, 100), ElemSize: 4 Byte(s), TotalSize: 5120000 Byte(s)
 - Subtensor{int64::}.0, Shape: (100, 128, 100), ElemSize: 4 Byte(s), TotalSize: 5120000 Byte(s)
 - for{cpu,scan_fn}.2, Shape: (100, 128, 100), ElemSize: 4 Byte(s), TotalSize: 5120000 Byte(s)
 - mrg_uniform{TensorType(float32, 3D),no_inplace}.0, Shape: (15360, 6), ElemSize: 4 Byte(s), TotalSize: 368640 Byte(s)
 - <TensorType(int32, matrix)>, Shared Input, Shape: (15360, 6), ElemSize: 4 Byte(s), TotalSize: 368640 Byte(s)
 - mrg_uniform{TensorType(float32, 3D),no_inplace}.0, Shape: (15360, 6), ElemSize: 4 Byte(s), TotalSize: 368640 Byte(s)
 - <TensorType(int32, matrix)>, Shared Input, Shape: (15360, 6), ElemSize: 4 Byte(s), TotalSize: 368640 Byte(s)
 - for{cpu,scan_fn}.0, Shape: (101, 128, 6), ElemSize: 4 Byte(s), TotalSize: 310272 Byte(s)
 - for{cpu,scan_fn}.1, Shape: (101, 128, 6), ElemSize: 4 Byte(s), TotalSize: 310272 Byte(s)
 - Elemwise{mul,no_inplace}.0, Shape: (128, 100, 6), ElemSize: 4 Byte(s), TotalSize: 307200 Byte(s)
 - for{cpu,scan_fn}.2, Shape: (100, 128, 6), ElemSize: 4 Byte(s), TotalSize: 307200 Byte(s)
 - <TensorType(float32, 3D)>, Input, Shape: (128, 100, 6), ElemSize: 4 Byte(s), TotalSize: 307200 Byte(s)
 - Elemwise{true_div,no_inplace}.0, Shape: (128, 100, 6), ElemSize: 4 Byte(s), TotalSize: 307200 Byte(s)
 - DimShuffle{1,0,2}.0, Shape: (128, 100, 6), ElemSize: 4 Byte(s), TotalSize: 307200 Byte(s)
 - Elemwise{clip,no_inplace}.0, Shape: (128, 100, 6), ElemSize: 4 Byte(s), TotalSize: 307200 Byte(s)
 - DimShuffle{0,1,x}.0, Shape: (128, 100, 1), ElemSize: 4 Byte(s), TotalSize: 51200 Byte(s)
 - <TensorType(float32, matrix)>, Shared Input, Shape: (128, 100), ElemSize: 4 Byte(s), TotalSize: 51200 Byte(s)
 - <TensorType(float32, matrix)>, Shared Input, Shape: (128, 100), ElemSize: 4 Byte(s), TotalSize: 51200 Byte(s)
 - <TensorType(float32, matrix)>, Shared Input, Shape: (128, 100), ElemSize: 4 Byte(s), TotalSize: 51200 Byte(s)
 - <TensorType(float32, matrix)>, Shared Input, Shape: (128, 100), ElemSize: 4 Byte(s), TotalSize: 51200 Byte(s)
 - <TensorType(int32, matrix)>, Input, Shape: (128, 100), ElemSize: 4 Byte(s), TotalSize: 51200 Byte(s)
 - <TensorType(float32, matrix)>, Shared Input, Shape: (128, 100), ElemSize: 4 Byte(s), TotalSize: 51200 Byte(s)
 - <TensorType(float32, matrix)>, Shared Input, Shape: (128, 100), ElemSize: 4 Byte(s), TotalSize: 51200 Byte(s)
 - <TensorType(float32, matrix)>, Shared Input, Shape: (128, 100), ElemSize: 4 Byte(s), TotalSize: 51200 Byte(s)
 - <TensorType(float32, matrix)>, Shared Input, Shape: (128, 100), ElemSize: 4 Byte(s), TotalSize: 51200 Byte(s)
 - <TensorType(float32, matrix)>, Shared Input, Shape: (128, 100), ElemSize: 4 Byte(s), TotalSize: 51200 Byte(s)
 - Elemwise{neg,no_inplace}.0, Shape: (128, 100), ElemSize: 4 Byte(s), TotalSize: 51200 Byte(s)
 - <TensorType(float32, matrix)>, Shared Input, Shape: (128, 100), ElemSize: 4 Byte(s), TotalSize: 51200 Byte(s)
 - <TensorType(float32, matrix)>, Shared Input, Shape: (128, 100), ElemSize: 4 Byte(s), TotalSize: 51200 Byte(s)
 - <TensorType(float32, matrix)>, Shared Input, Shape: (128, 100), ElemSize: 4 Byte(s), TotalSize: 51200 Byte(s)
 - <TensorType(float32, matrix)>, Shared Input, Shape: (128, 100), ElemSize: 4 Byte(s), TotalSize: 51200 Byte(s)
 - Elemwise{mul,no_inplace}.0, Shape: (128, 100), ElemSize: 4 Byte(s), TotalSize: 51200 Byte(s)
 - Elemwise{Cast{float32}}.0, Shape: (128, 100, 1), ElemSize: 4 Byte(s), TotalSize: 51200 Byte(s)
 - Reshape{1}.0, Shape: (12800,), ElemSize: 4 Byte(s), TotalSize: 51200 Byte(s)
 - <TensorType(float32, matrix)>, Shared Input, Shape: (100, 100), ElemSize: 4 Byte(s), TotalSize: 40000 Byte(s)
 - <TensorType(float32, matrix)>, Shared Input, Shape: (100, 100), ElemSize: 4 Byte(s), TotalSize: 40000 Byte(s)
 - <TensorType(float32, matrix)>, Shared Input, Shape: (100, 100), ElemSize: 4 Byte(s), TotalSize: 40000 Byte(s)
 - <TensorType(float32, matrix)>, Shared Input, Shape: (100, 100), ElemSize: 4 Byte(s), TotalSize: 40000 Byte(s)
 - <TensorType(float32, matrix)>, Shared Input, Shape: (100, 100), ElemSize: 4 Byte(s), TotalSize: 40000 Byte(s)
 - <TensorType(float32, matrix)>, Shared Input, Shape: (100, 100), ElemSize: 4 Byte(s), TotalSize: 40000 Byte(s)
 - <TensorType(float32, matrix)>, Shared Input, Shape: (100, 100), ElemSize: 4 Byte(s), TotalSize: 40000 Byte(s)
 - <TensorType(float32, matrix)>, Shared Input, Shape: (100, 100), ElemSize: 4 Byte(s), TotalSize: 40000 Byte(s)
 - <TensorType(float32, matrix)>, Shared Input, Shape: (100, 100), ElemSize: 4 Byte(s), TotalSize: 40000 Byte(s)
 - <TensorType(float32, matrix)>, Shared Input, Shape: (100, 100), ElemSize: 4 Byte(s), TotalSize: 40000 Byte(s)
 - <TensorType(float32, matrix)>, Shared Input, Shape: (100, 100), ElemSize: 4 Byte(s), TotalSize: 40000 Byte(s)
 - <TensorType(float32, matrix)>, Shared Input, Shape: (100, 100), ElemSize: 4 Byte(s), TotalSize: 40000 Byte(s)
 - <TensorType(float32, matrix)>, Shared Input, Shape: (100, 6), ElemSize: 4 Byte(s), TotalSize: 2400 Byte(s)
 - <TensorType(float32, matrix)>, Shared Input, Shape: (100, 6), ElemSize: 4 Byte(s), TotalSize: 2400 Byte(s)
 - <TensorType(float32, matrix)>, Shared Input, Shape: (100, 6), ElemSize: 4 Byte(s), TotalSize: 2400 Byte(s)
 - <TensorType(float32, matrix)>, Shared Input, Shape: (100, 6), ElemSize: 4 Byte(s), TotalSize: 2400 Byte(s)
 - <TensorType(float32, matrix)>, Shared Input, Shape: (100, 6), ElemSize: 4 Byte(s), TotalSize: 2400 Byte(s)
 - <TensorType(float32, matrix)>, Shared Input, Shape: (100, 6), ElemSize: 4 Byte(s), TotalSize: 2400 Byte(s)
 - <TensorType(float32, matrix)>, Shared Input, Shape: (100, 6), ElemSize: 4 Byte(s), TotalSize: 2400 Byte(s)
 - <TensorType(float32, matrix)>, Shared Input, Shape: (100, 6), ElemSize: 4 Byte(s), TotalSize: 2400 Byte(s)
 - <TensorType(float32, matrix)>, Shared Input, Shape: (100, 6), ElemSize: 4 Byte(s), TotalSize: 2400 Byte(s)
 - <TensorType(float32, matrix)>, Shared Input, Shape: (100, 6), ElemSize: 4 Byte(s), TotalSize: 2400 Byte(s)
 - <TensorType(float32, matrix)>, Shared Input, Shape: (100, 6), ElemSize: 4 Byte(s), TotalSize: 2400 Byte(s)
 - <TensorType(float32, matrix)>, Shared Input, Shape: (100, 6), ElemSize: 4 Byte(s), TotalSize: 2400 Byte(s)
 - <TensorType(float32, matrix)>, Shared Input, Shape: (100, 6), ElemSize: 4 Byte(s), TotalSize: 2400 Byte(s)
 - DimShuffle{x,0}.0, Shape: (1, 128), ElemSize: 4 Byte(s), TotalSize: 512 Byte(s)
 - <TensorType(float32, vector)>, Input, Shape: (128,), ElemSize: 4 Byte(s), TotalSize: 512 Byte(s)
 - <TensorType(float32, vector)>, Shared Input, Shape: (100,), ElemSize: 4 Byte(s), TotalSize: 400 Byte(s)
 - <TensorType(float32, vector)>, Shared Input, Shape: (100,), ElemSize: 4 Byte(s), TotalSize: 400 Byte(s)
 - <TensorType(float32, vector)>, Shared Input, Shape: (100,), ElemSize: 4 Byte(s), TotalSize: 400 Byte(s)
 - <TensorType(float32, vector)>, Shared Input, Shape: (100,), ElemSize: 4 Byte(s), TotalSize: 400 Byte(s)
 - <TensorType(float32, vector)>, Shared Input, Shape: (100,), ElemSize: 4 Byte(s), TotalSize: 400 Byte(s)
 - <TensorType(float32, vector)>, Shared Input, Shape: (100,), ElemSize: 4 Byte(s), TotalSize: 400 Byte(s)
 - <TensorType(float32, vector)>, Shared Input, Shape: (100,), ElemSize: 4 Byte(s), TotalSize: 400 Byte(s)
 - <TensorType(float32, vector)>, Shared Input, Shape: (100,), ElemSize: 4 Byte(s), TotalSize: 400 Byte(s)
 - <TensorType(float32, vector)>, Shared Input, Shape: (100,), ElemSize: 4 Byte(s), TotalSize: 400 Byte(s)
 - <TensorType(float32, vector)>, Shared Input, Shape: (100,), ElemSize: 4 Byte(s), TotalSize: 400 Byte(s)
 - <TensorType(float32, vector)>, Shared Input, Shape: (100,), ElemSize: 4 Byte(s), TotalSize: 400 Byte(s)
 - <TensorType(float32, vector)>, Shared Input, Shape: (100,), ElemSize: 4 Byte(s), TotalSize: 400 Byte(s)
 - <TensorType(float32, matrix)>, Shared Input, Shape: (6, 6), ElemSize: 4 Byte(s), TotalSize: 144 Byte(s)
 - <TensorType(float32, matrix)>, Shared Input, Shape: (6, 6), ElemSize: 4 Byte(s), TotalSize: 144 Byte(s)
 - <TensorType(float32, matrix)>, Shared Input, Shape: (6, 6), ElemSize: 4 Byte(s), TotalSize: 144 Byte(s)
 - <TensorType(float32, matrix)>, Shared Input, Shape: (6, 6), ElemSize: 4 Byte(s), TotalSize: 144 Byte(s)
 - <TensorType(float32, matrix)>, Shared Input, Shape: (6, 6), ElemSize: 4 Byte(s), TotalSize: 144 Byte(s)
 - <TensorType(float32, matrix)>, Shared Input, Shape: (6, 6), ElemSize: 4 Byte(s), TotalSize: 144 Byte(s)
 - <TensorType(float32, matrix)>, Shared Input, Shape: (6, 6), ElemSize: 4 Byte(s), TotalSize: 144 Byte(s)
 - <TensorType(float32, matrix)>, Shared Input, Shape: (6, 6), ElemSize: 4 Byte(s), TotalSize: 144 Byte(s)
 - <TensorType(float32, matrix)>, Shared Input, Shape: (6, 6), ElemSize: 4 Byte(s), TotalSize: 144 Byte(s)
 - <TensorType(float32, matrix)>, Shared Input, Shape: (6, 6), ElemSize: 4 Byte(s), TotalSize: 144 Byte(s)
 - <TensorType(float32, matrix)>, Shared Input, Shape: (6, 6), ElemSize: 4 Byte(s), TotalSize: 144 Byte(s)
 - <TensorType(float32, matrix)>, Shared Input, Shape: (6, 6), ElemSize: 4 Byte(s), TotalSize: 144 Byte(s)
 - <TensorType(float32, vector)>, Shared Input, Shape: (6,), ElemSize: 4 Byte(s), TotalSize: 24 Byte(s)
 - <TensorType(float32, vector)>, Shared Input, Shape: (6,), ElemSize: 4 Byte(s), TotalSize: 24 Byte(s)
 - <TensorType(float32, vector)>, Shared Input, Shape: (6,), ElemSize: 4 Byte(s), TotalSize: 24 Byte(s)
 - <TensorType(float32, vector)>, Shared Input, Shape: (6,), ElemSize: 4 Byte(s), TotalSize: 24 Byte(s)
 - <TensorType(float32, vector)>, Shared Input, Shape: (6,), ElemSize: 4 Byte(s), TotalSize: 24 Byte(s)
 - <TensorType(float32, vector)>, Shared Input, Shape: (6,), ElemSize: 4 Byte(s), TotalSize: 24 Byte(s)
 - <TensorType(float32, vector)>, Shared Input, Shape: (6,), ElemSize: 4 Byte(s), TotalSize: 24 Byte(s)
 - <TensorType(float32, vector)>, Shared Input, Shape: (6,), ElemSize: 4 Byte(s), TotalSize: 24 Byte(s)
 - <TensorType(float32, vector)>, Shared Input, Shape: (6,), ElemSize: 4 Byte(s), TotalSize: 24 Byte(s)
 - <TensorType(float32, vector)>, Shared Input, Shape: (6,), ElemSize: 4 Byte(s), TotalSize: 24 Byte(s)
 - <TensorType(float32, vector)>, Shared Input, Shape: (6,), ElemSize: 4 Byte(s), TotalSize: 24 Byte(s)
 - <TensorType(float32, vector)>, Shared Input, Shape: (6,), ElemSize: 4 Byte(s), TotalSize: 24 Byte(s)
 - Subtensor{int64}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)
 - ScalarFromTensor.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)
 - Constant{2}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)
 - Subtensor{int64}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)
 - Constant{0}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)
 - ScalarFromTensor.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)
 - Constant{-1}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)
 - TensorConstant{1.0}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)
 - Constant{1}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)
 - TensorConstant{(1,) of -1}, Shape: (1,), ElemSize: 8 Byte(s), TotalSize: 8 Byte(s)
 - TensorConstant{(1,) of 0.0}, Shape: (1,), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)
 - TensorConstant{(1,) of inf}, Shape: (1,), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)
 - TensorConstant{(1, 1) of 1}, Shape: (1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)
 - TensorConstant{(1, 1) of inf}, Shape: (1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)
 - <TensorType(float32, scalar)>, Shared Input, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)
 - <TensorType(float32, scalar)>, Shared Input, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)
 - <TensorType(float32, scalar)>, Shared Input, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)
 - <TensorType(float32, scalar)>, Shared Input, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)
 - TensorConstant{(1, 1, 1) of 1e-07}, Shape: (1, 1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)
 - TensorConstant{inf}, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)
 - TensorConstant{(1, 1) of 1e-08}, Shape: (1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)
 - TensorConstant{(1,) of 1e-08}, Shape: (1,), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)
 - DimShuffle{x}.0, Shape: (1,), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)
 - TensorConstant{(1, 1, 1) of 0.0}, Shape: (1, 1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)
 - TensorConstant{0.0}, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)
 - TensorConstant{(1, 1, 1) of 0.5}, Shape: (1, 1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)
 - TensorConstant{(1, 1) of 0.0}, Shape: (1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)
 - TensorConstant{(1, 1, 1) of 1.0}, Shape: (1, 1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)
 - TensorConstant{(1, 1, 1) of 1.0}, Shape: (1, 1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)
 - TensorConstant{1.0}, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)
 - TensorConstant{0}, Shape: (), ElemSize: 1 Byte(s), TotalSize: 1.0 Byte(s)
 - TensorConstant{(1, 1) of 1}, Shape: (1, 1), ElemSize: 1 Byte(s), TotalSize: 1 Byte(s)
 - TensorConstant{1}, Shape: (), ElemSize: 1 Byte(s), TotalSize: 1.0 Byte(s)
 - TensorConstant{(1, 1) of 0}, Shape: (1, 1), ElemSize: 1 Byte(s), TotalSize: 1 Byte(s)
 TotalSize: 66108452.0 Byte(s) 0.062 GB
 TotalSize inputs: 17646080.0 Byte(s) 0.016 GB
```

The code of `model.py` is as follows:

```
$ cat model.py 
# coding: utf-8
import logging
logger = logging.getLogger(""EntityExtractor_Model"")
logger.setLevel(logging.INFO)
ch = logging.StreamHandler()
ch.setLevel(logging.INFO)
formatter = logging.Formatter('%(name)s %(levelname)s %(asctime)s:%(message)s')
ch.setFormatter(formatter)
logger.addHandler(ch)
logger.info(""Started Logger"")

import theano, keras
logger.info(""Using Keras version %s"" % keras.__version__)
logger.info(""Using Theano version %s"" % theano.__version__)
from keras.models import Sequential
from keras.layers.core import Dense, Dropout, Activation, TimeDistributedDense, Flatten, Merge
from keras.layers.embeddings import Embedding
from keras.layers.recurrent import LSTM, GRU
from keras.preprocessing.sequence import pad_sequences

import numpy as np
import glob
import json
import time

import preprocess as pp

CONFIG = json.load(open(""config.json""))

BASE_DATA_DIR = CONFIG[""BASE_DATA_DIR""]
DATA_DIR = ""%s/%s"" % (BASE_DATA_DIR, CONFIG[""DATA_DIR""])
vocab_file = ""%s/%s"" % (BASE_DATA_DIR, CONFIG[""vocab_file""])
boundary_file = ""%s/%s"" % (BASE_DATA_DIR, CONFIG[""boundary_file""])
category_file = ""%s/%s"" % (BASE_DATA_DIR, CONFIG[""category_file""])
BASE_OUT_DIR = CONFIG[""BASE_OUT_DIR""]
SAVE_MODEL_DIR = ""%s/%s"" % (BASE_OUT_DIR, CONFIG[""SAVE_MODEL_DIR""])
MODEL_PREFIX = CONFIG.get(""MODEL_PREFIX"", ""model"")
maxlen = CONFIG[""maxlen""]
num_hidden_layers = CONFIG[""num_hidden_layers""]
embedding_size = CONFIG[""embedding_size""]
hidden_layer_size = CONFIG[""hidden_layer_size""]
RNN_LAYER_TYPE = CONFIG.get(""RNN_LAYER_TYPE"", ""LSTM"")
optimizer = CONFIG[""optimizer""]
n_epochs = CONFIG[""n_epochs""]
save_every = CONFIG[""save_every""]

RNN_CLASS = LSTM
if RNN_LAYER_TYPE == ""GRU"":
    RNN_CLASS = GRU


index_word, word_dict = pp.load_vocab(vocab_file)
pp.WordToken.set_vocab(word_dict = word_dict)
index_boundary, boundary_dict = pp.load_vocab(boundary_file)
index_category, category_dict = pp.load_vocab(category_file)
vocab_size = len(index_word) + pp.WordToken.VOCAB + 1 # Add offset of VOCAB and then extra token for padding
boundary_size = len(index_boundary) + 1 # Add extra token for padding 
category_size = len(index_category) + 1 # Add extra token for padding

logger.info(""Parameters: vocab_size = %s, embedding_size = %s, maxlen = %s, boundary_size = %s, category_size = %s, embedding_size = %s, hidden_layer_size = %s"" %\
                (vocab_size, embedding_size, maxlen, boundary_size, category_size, embedding_size, hidden_layer_size))

def vectorize_data(filenames, maxlen=maxlen, output_label_size=boundary_size, output_label_dict=boundary_dict):
    X = []
    Y = []
    for i, filename in enumerate(filenames):
        for docid, doc in pp.get_documents(filename):
            for seq in pp.get_sequences(doc):
                x = []
                y = []
                for token in seq:
                    x.append(1 + token.word_index) # Add 1 to include token for padding
                    #y_vec = np.zeros(boundary_size)
                    y_idx = 1 + output_label_dict.get(token.b_label, -1) # Add 1 to include token for padding
                    #y_vec[y_idx] = 1
                    y.append(y_idx) # Add 1 to include token for padding
                X.append(x)
                Y.append(y)
    X = pad_sequences(X, maxlen=maxlen)
    Y = pad_sequences(Y, maxlen=maxlen)
    Y_vec = []
    # Now y should be converted to one hot vector for each index value
    for i in xrange(len(Y)):
        Y_vec.append([])
        for j in xrange(maxlen):
            #Y_vec[-1].append([])
            y_vec = np.zeros(output_label_size)
            y_vec[Y[i][j]] = 1
            Y_vec[-1].append(y_vec)
    X = np.array(X)
    Y = np.array(Y_vec)
    return X, Y

def gen_model():
    logger.info(""Parameters: vocab_size = %s, embedding_size = %s, maxlen = %s, boundary_size = %s, category_size = %s, embedding_size = %s, hidden_layer_size = %s"" %\
            (vocab_size, embedding_size, maxlen, boundary_size, category_size, embedding_size, hidden_layer_size))
    logger.info(""Building Model"")
    model = Sequential()
    logger.info(""Init Model with vocab_size = %s, embedding_size = %s, maxlen = %s"" % (vocab_size, embedding_size, maxlen))
    model.add(Embedding(vocab_size, embedding_size, input_length=maxlen, mask_zero=True))
    logger.info(""Added Embedding Layer"")
    model.add(Dropout(0.5))
    logger.info(""Added Dropout Layer"")
    for i in xrange(num_hidden_layers):
        model.add(RNN_CLASS(output_dim=hidden_layer_size, activation='sigmoid', inner_activation='hard_sigmoid', return_sequences=True))
        logger.info(""Added %s Layer"" % RNN_LAYER_TYPE)
        model.add(Dropout(0.5))
        logger.info(""Added Dropout Layer"")
    model.add(RNN_CLASS(output_dim=boundary_size, activation='softmax', inner_activation='hard_sigmoid', return_sequences=True))
    logger.info(""Added %s Layer"" % RNN_LAYER_TYPE)
    logger.info(""Created model with following config:\n%s"" % json.dumps(model.get_config(), indent=4))
    logger.info(""Compiling model with optimizer %s"" % optimizer)
    start_time = time.time()
    model.compile(loss='categorical_crossentropy', optimizer=optimizer)
    total_time = time.time() - start_time
    logger.info(""Model compiled in %.4f seconds."" % total_time)
    return model


model = gen_model()

# Read the data
CV_filenames = [glob.glob(""%s/%s/*.xml"" % (DATA_DIR, i)) for i in range(1,6)]

train_files = reduce(lambda x, y: x + y, CV_filenames[0:4])
test_files = reduce(lambda x, y: x + y, CV_filenames[4:])

X_train, Y_train = vectorize_data(train_files)
X_test, Y_test = vectorize_data(test_files)

logger.info(""Loaded data shapes:\nX_train: %s, Y_train: %s\nX_test: %s, Y_test: %s"" % (X_train.shape, Y_train.shape, X_test.shape, Y_test.shape))

for epoch in range(0, n_epochs, save_every):
    logger.info(""Starting Epochs %s to %s"" % (epoch, epoch + save_every))
    start_time = time.time()
    model.fit(X_train,Y_train, validation_data=(X_test, Y_test), nb_epoch=save_every, verbose=2)
    total_time = time.time() - start_time
    logger.info(""Finished training %.3f epochs in %s seconds with %.5f seconds/epoch"" % (save_every, total_time, total_time * 1.0/ save_every))
    model.save_weights(""%s/%s_%s.h5"" % (SAVE_MODEL_DIR, MODEL_PREFIX, epoch))
```
",napsternxg,None,2015-12-25T01:10:50Z,2016-01-05T21:17:25Z
1343,Keras's fit() doesn't check if X and y have the same row number ,"Once I wrongly put A X and y with different row number into fit, as keras's fit has not check the row number of input, it took me a long time to debug according to the traceback.
It will be great to fix it.
",kelvict,None,2015-12-23T20:28:30Z,2015-12-23T22:49:47Z
1336,fix iteration shadowed in loop,"The variable `iteration` is shadowed between the second loop and the third loop. So if I want to print `iteration` there, I always get `399`.

This is not a bug for now but since this is an example and many people may write more code from here. It's better to fix it.
",wb14123,None,2015-12-23T09:18:38Z,2015-12-23T18:29:45Z
1315,Bug in /theano/sandbox/cuda/dnn.py,"/usr/bin/python2.7 /home/dell/DLTest/cifar_test/Residul/cifar_residul_net.py
Using Theano backend.
Using gpu device 1: GeForce GTX TITAN X (CNMeM is disabled)
('X_train shape:', (50000, 3, 32, 32))
(50000, 'train samples')
(10000, 'test samples')
Traceback (most recent call last):
  File ""/home/dell/DLTest/cifar_test/Residul/cifar_residul_net.py"", line 87, in <module>
    model.compile(loss='categorical_crossentropy', optimizer=sgd)
  File ""/home/dell/.local/lib/python2.7/site-packages/keras/models.py"", line 372, in compile
    self.y_train = self.get_output(train=True)
  File ""/home/dell/.local/lib/python2.7/site-packages/keras/layers/containers.py"", line 73, in get_output
    return self.layers[-1].get_output(train)
  File ""/home/dell/.local/lib/python2.7/site-packages/keras/layers/core.py"", line 681, in get_output
    X = self.get_input(train)
  File ""/home/dell/.local/lib/python2.7/site-packages/keras/layers/core.py"", line 102, in get_input
    return self.previous.get_output(train=train)
  File ""/home/dell/.local/lib/python2.7/site-packages/keras/layers/core.py"", line 591, in get_output
    X = self.get_input(train)
  File ""/home/dell/.local/lib/python2.7/site-packages/keras/layers/core.py"", line 102, in get_input
    return self.previous.get_output(train=train)
  File ""/home/dell/.local/lib/python2.7/site-packages/keras/layers/containers.py"", line 216, in get_output
    return self.outputs[self.output_order[0]].get_output(train)
  File ""/home/dell/.local/lib/python2.7/site-packages/keras/layers/core.py"", line 389, in get_output
    s = self.layers[0].get_output(train)
  File ""/home/dell/.local/lib/python2.7/site-packages/keras/layers/convolutional.py"", line 212, in get_output
    X = self.get_input(train)
  File ""/home/dell/.local/lib/python2.7/site-packages/keras/layers/core.py"", line 102, in get_input
    return self.previous.get_output(train=train)
  File ""/home/dell/.local/lib/python2.7/site-packages/keras/layers/core.py"", line 98, in get_output
    return self.get_input(train)
  File ""/home/dell/.local/lib/python2.7/site-packages/keras/layers/core.py"", line 102, in get_input
    return self.previous.get_output(train=train)
  File ""/home/dell/.local/lib/python2.7/site-packages/keras/layers/containers.py"", line 216, in get_output
    return self.outputs[self.output_order[0]].get_output(train)
  File ""/home/dell/.local/lib/python2.7/site-packages/keras/layers/core.py"", line 389, in get_output
    s = self.layers[0].get_output(train)
  File ""/home/dell/.local/lib/python2.7/site-packages/keras/layers/convolutional.py"", line 215, in get_output
    dim_ordering=self.dim_ordering)
  File ""/home/dell/.local/lib/python2.7/site-packages/keras/backend/theano_backend.py"", line 543, in conv2d
    border_mode=(pad_x, pad_y))
  File ""/usr/local/lib/python2.7/dist-packages/theano/sandbox/cuda/dnn.py"", line 1191, in dnn_conv
    conv_mode=conv_mode)(img.shape, kerns.shape)
  File ""/usr/local/lib/python2.7/dist-packages/theano/sandbox/cuda/dnn.py"", line 251, in **init**
    border_mode = tuple(map(int, border_mode))
TypeError: int() argument must be a string or a number, not 'TensorVariable'

I got a bug after i delete /usr/local/cuda/lib64/libcudnn\*  and /usr/local/cuda/include/cudnn.h

Then add the same files of cudnn7-5v3 into the same path 
",meank,b'stale',2015-12-20T13:13:50Z,2017-06-22T23:11:15Z
1310,Masking passed to the backend RNN calls.,"This has been discussed in a number of places, #1282 #1300 #1206 #1224.

@fchollet proposed this:

> What are your thoughts on the following:
> - handling masking via an explicit mask array being passed around
> - rnn returning the last valid output for any masked step (in much the same way that it currently returns as states the last valid states). For instance, for a timeseries [1., 2., 3., masked, masked], an accumulator RNN would return [1., 3., 6., 6., 6.].

This turned out to be much simpler than I originally expected, due to
the nicely componentized design of the new RNN backend. Nice job!

This currently works with the Theano backend, and I've included new tests that check with both left- and right-padding.

There's still an issue with TensorFlow, so don't merge yet. I wanted to get some feedback on the API and the Theano approach.

Also if anyone wants to help debug TensorFlow I'm certainly not opposed to help ;)
",wxs,None,2015-12-18T22:18:22Z,2017-11-11T22:37:05Z
1291,`AutoEncoder` does not work as a layer when built using `container.Sequential` encoder/decoder,"The following script fails.

``` python
import keras

from keras.models import *
from keras.layers import *
from keras.layers.core import *

encoder = containers.Sequential([Dense(10, input_dim=100), Dense(2)])
decoder = containers.Sequential([Dense(2, input_dim=10), Dense(100)])

model = Sequential()
model.add(AutoEncoder(encoder=encoder, decoder=decoder, output_reconstruction=False))
model.add(Dense(1))

model.compile(loss='binary_crossentropy', optimizer='sgd')
```

``` bash
[ice-phoenix@niobium ml]$ python auto_encoder_bug.py 
Using Theano backend.
Using gpu device 0: GeForce GTX 960 (CNMeM is disabled)
Traceback (most recent call last):
  File ""auto_encoder_bug.py"", line 14, in <module>
    model.add(Dense(1))
  File ""/usr/lib/python3.5/site-packages/Keras-0.3.0-py3.5.egg/keras/layers/containers.py"", line 68, in add
  File ""/usr/lib/python3.5/site-packages/Keras-0.3.0-py3.5.egg/keras/layers/core.py"", line 82, in set_previous
  File ""/usr/lib/python3.5/site-packages/Keras-0.3.0-py3.5.egg/keras/layers/core.py"", line 1162, in output_shape
AttributeError: 'Sequential' object has no attribute 'previous'
```

The problem is that `AutoEncoder.output_shape` is defined as follows:

``` python
class AutoEncoder(Layer):
    ...
    @property
    def output_shape(self):
        if self.output_reconstruction:
            return self.encoder.previous.output_shape
        else:
            return self.decoder.previous.output_shape
```

and `containers.Sequential` does not define `previous`.

It could be fixed in several ways:
- Define `AutoEncoder.output_shape` via `encoder.output_shape / decoder.output_shape`
- Introduce `previous` property to `containers.Sequential` (does not fix things when `AutoEncoder` is the first layer in the net as there'll be no previous layer)

I could try to work on this after getting some feedback on what would be the best way to fix this.
",ice-phoenix,b'stale',2015-12-17T12:01:27Z,2017-06-22T23:10:01Z
1276,Tests crash for the shape inference,"Hello all,

When I tried to run some scripts after updating to the latest version of Theano and Keras I had some errors.

I maybe didn't notice a change on my side but I tried to run the tests and it seems the shape inference is not behaving nicely:

``` python
Using gpu device 0: GeForce GTX 980 (CNMeM is disabled)
......FF.........
======================================================================
FAIL: test_shape_inference.test_Convolution1D
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""/home/thomas/anaconda3/envs/anapy27/lib/python2.7/site-packages/nose/case.py"", line 197, in runTest
    self.test(*self.arg)
  File ""/home/thomas/libraries/forks/keras/tests/test_shape_inference.py"", line 75, in test_Convolution1D
    check_layer_output_shape(layer, input_data)
  File ""/home/thomas/libraries/forks/keras/tests/test_shape_inference.py"", line 18, in check_layer_output_shape
    assert output.shape[1:] == expected_output_shape, ""output shape: {} expected output shape: {}"".format(output.shape[1:], ex
pected_output_shape)                                                                                                         
AssertionError: output shape: (2, 1) expected output shape: (3, 1)

======================================================================
FAIL: test_shape_inference.test_Convolution2D
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""/home/thomas/anaconda3/envs/anapy27/lib/python2.7/site-packages/nose/case.py"", line 197, in runTest
    self.test(*self.arg)
  File ""/home/thomas/libraries/forks/keras/tests/test_shape_inference.py"", line 91, in test_Convolution2D
    check_layer_output_shape(layer, input_data)
  File ""/home/thomas/libraries/forks/keras/tests/test_shape_inference.py"", line 18, in check_layer_output_shape
    assert output.shape[1:] == expected_output_shape, ""output shape: {} expected output shape: {}"".format(output.shape[1:], ex
pected_output_shape)                                                                                                         
AssertionError: output shape: (1, 2, 2) expected output shape: (1, 3, 3)

----------------------------------------------------------------------
Ran 17 tests in 7.296s

FAILED (failures=2)
```

I tried to digg in and I made my example work but the tests are still failing.

This is my reproductible example:

``` python
from sklearn.feature_extraction.image import extract_patches_2d
import theano
import keras


import numpy as np
np.random.seed(1337)

from keras.models import Graph
from keras.layers.core import Dense, Flatten
from keras.layers.convolutional import Convolution1D, MaxPooling1D

len_ts_y = 60
sample = 1000
Fs = 8000
f = 5
x_bug = np.arange(sample)

y_test = np.sin(2 * np.pi * f * x_bug / Fs)
y_test = y_test+np.random.normal(0, 0.2, sample)

data_patched = extract_patches_2d(y_test[:,None], (len_ts_y+1,1))
y_train = data_patched[:,:,-1]
endog_train = data_patched[:,-len_ts_y-1:-1,-1]

model = Graph()
model.add_input(name='endog', input_shape=(len_ts_y,1))

model.add_node(Convolution1D(nb_filter=4,
                            filter_length=2,
                            border_mode=""same"",
                            activation=""relu"",
                            subsample_length=1,
                            ),
                            name='conv_1', input='endog')
model.add_node(Flatten(), name=""flat"", input='conv_1')
model.add_node(Dense(32, activation=""sigmoid""), name=""Dense"", input='flat')
model.add_node(Dense(1, activation=""softplus""), name='last_dense', input='Dense')
model.add_output(name='output', input='last_dense')
model.compile(optimizer='sgd', loss={'output':'mse'})

model.fit({'endog': endog_train[:-100,:, None], 'output': y_train[:-100,-1]},
          validation_data={'endog':endog_train[-100:,:, None], 'output': y_train[-100:,-1]},
          batch_size=128,
          nb_epoch=4)
```

I changed the size of the `output_shape` in the `conv_output_length` function of `convolutionnal.py` to make the above example work :

``` python
def conv_output_length(input_length, filter_size, border_mode, stride):
    if input_length is None:
        return None
    assert border_mode in {'same', 'valid'}
    if border_mode == 'same':
        output_length = input_length
    elif border_mode == 'valid':
        output_length = input_length - filter_size + 1
    return ((output_length + stride - 1) // stride) - 1
```

Does anyone is having the same errors?

Thank you!
",tboquet,None,2015-12-15T16:48:21Z,2016-03-07T13:22:15Z
1275,BUG: models with AutoEncoder layers not as first layer cause DisconnectedInputErrors on compilation,"Hi, I've got another bug report, sorry :(

The following sample code causes an error when compiling:

``` python
from keras.models import Sequential
encoder = Dense(input_dim=10, output_dim=2)
decoder = Dense(input_dim=2, output_dim=10)
model = Sequential()
model.add(Dense(input_dim=20, output_dim=10))
model.add(AutoEncoder(encoder=encoder, decoder=decoder, output_reconstruction=False))
model.compile(loss='mse', optimizer='sgd')
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/auto/homes/kc391/event_rnn/env/bin/keras/keras/models.py"", line 432, in compile
    train_loss)
  File ""/auto/homes/kc391/event_rnn/env/bin/keras/keras/optimizers.py"", line 79, in get_updates
    grads = self.get_gradients(loss, params)
  File ""/auto/homes/kc391/event_rnn/env/bin/keras/keras/optimizers.py"", line 47, in get_gradients
    grads = K.gradients(loss, params)
  File ""/auto/homes/kc391/event_rnn/env/bin/keras/keras/backend/theano_backend.py"", line 365, in gradients
    return T.grad(loss, variables)
  File ""/auto/homes/kc391/event_rnn/env/bin/Theano/theano/gradient.py"", line 545, in grad
    handle_disconnected(elem)
  File ""/auto/homes/kc391/event_rnn/env/bin/Theano/theano/gradient.py"", line 532, in handle_disconnected
    raise DisconnectedInputError(message)
theano.gradient.DisconnectedInputError: grad method was asked to compute the gradient with respect to a variable that is not part of the computational graph of the cost, or is used only by a non-differentiable operator: <TensorType(float32, matrix)>
Backtrace when the node is created:
  File ""/auto/homes/kc391/event_rnn/env/bin/keras/keras/backend/theano_backend.py"", line 34, in variable
    return theano.shared(value=value, name=name, strict=False)

```

The error is caused by:
- when AutoEncoder is inited, `self.params` is set by scraping the weights and biases from the encoder and decoder layers.
- when `model.add` is called with an AutoEncoder layer as the argument, this calls `AutoEncoder.set_previous()`, which calls `AutoEncoder.encoder.set_previous()`. 
- this reinitialises the weights and biases on the encoder layer, so that the pointers contained in `AutoEncoder.params` no longer points to the correct weights and biases on the encoder layer.

Possible solutions:
- update `AutoEncoder.params` when `AutoEncoder.set_previous()` is called
- add an ability to call `set_previous()` without overwriting existing weights (similar to #1266)

Thoughts?
Kris
",around1991,b'stale',2015-12-15T14:22:17Z,2017-06-22T23:11:07Z
1271,Siamese Layer - Complete fix + tests,"In this PR:
- Fix `Siamese` layer
- Fix bugs in `__call__` (required by `Siamese`). This includes:
  1)  mask support
  2) support for nested models
  3) temporarily disable layer cache during `__call__`
- Test for `__call__` with nested model
- **Tests for `Siamese` layer (all 5 APIs - 2 Sequential + 3  Graph)**
",farizrahman4u,None,2015-12-15T07:54:24Z,2015-12-15T19:37:12Z
1262,Model won't compile in Keras 0.3.0,"Hello,

I've been using Keras 0.2.0 and I've just upgraded to 0.3.0. When I compile my model in 0.2.0, it has no problem but when compile the same model in 0.3.0, I've got the error:

```
Using Theano backend.
Epoch 1/20
Traceback (most recent call last):
  File ""/Users/ceguo/Documents/PycharmProjects/convnet/Test.py"", line 81, in <module>
    verbose=1, show_accuracy=True)
  File ""build/bdist.macosx-10.10-intel/egg/keras/models.py"", line 507, in fit
  File ""build/bdist.macosx-10.10-intel/egg/keras/models.py"", line 226, in _fit
  File ""build/bdist.macosx-10.10-intel/egg/keras/backend/theano_backend.py"", line 357, in __call__
  File ""/Users/ceguo/Documents/GitHub/Theano/theano/compile/function_module.py"", line 871, in __call__
    storage_map=getattr(self.fn, 'storage_map', None))
  File ""/Users/Documents/GitHub/Theano/theano/gof/link.py"", line 314, in raise_with_op
    reraise(exc_type, exc_value, exc_trace)
  File ""/Users/ceguo/Documents/GitHub/Theano/theano/compile/function_module.py"", line 859, in __call__
    outputs = self.fn()
ValueError: The hardcoded shape for the number of rows in the image (66) isn't the run time shape (130).
Apply node that caused the error: ConvOp{('imshp', (32, 66, 66)),('kshp', (1, 1)),('nkern', 21),('bsize', None),('dx', 1),('dy', 1),('out_mode', 'valid'),('unroll_batch', None),('unroll_kern', None),('unroll_patch', True),('imshp_logical', (32, 66, 66)),('kshp_logical', (1, 1)),('kshp_logical_top_aligned', True)}(IncSubtensor{InplaceSet;::, ::, int64:int64:, int64:int64:}.0, <TensorType(float32, 4D)>)
Toposort index: 117
Inputs types: [TensorType(float32, 4D), TensorType(float32, 4D)]
Inputs shapes: [(50, 32, 130, 130), (21, 32, 1, 1)]
Inputs strides: [(2163200, 67600, 520, 4), (128, 4, 4, 4)]
Inputs values: ['not shown', 'not shown']
Outputs clients: [[Elemwise{Add}[(0, 0)](ConvOp{('imshp', (32, 66, 66)),('kshp', (1, 1)),('nkern', 21),('bsize', None),('dx', 1),('dy', 1),('out_mode', 'valid'),('unroll_batch', None),('unroll_kern', None),('unroll_patch', True),('imshp_logical', (32, 66, 66)),('kshp_logical', (1, 1)),('kshp_logical_top_aligned', True)}.0, Reshape{4}.0)]]

Backtrace when the node is created:
  File ""build/bdist.macosx-10.10-intel/egg/keras/backend/theano_backend.py"", line 570, in conv2d
    filter_shape=filter_shape)

HINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.
```

Any ideas? Thanks in advance!
",KlaymenGC,None,2015-12-14T12:52:38Z,2015-12-14T13:04:50Z
1260,fix model checkpointer string formatter bug,"Fix an issue with string formatter inside model checkpointer when breaking string to 2 lines
",chenb67,None,2015-12-14T11:39:55Z,2015-12-14T18:05:05Z
1258,correct masking: switch for each example in a batch,"```
        [  # input 0 in a batch
           [0], [1], [2], [3]
           ],
        [  # input 1 in a batch
           [0], [0], [1], [2]
           ]
```

when we compute 'switch' for the second example ([1], [0]), the switch will be '1'.  Obvious, for input 1, switch should be 0. 
Actually, switch should not be a scalar, instead it should be a vector (1, 0). 

@fchollet Another huge bug in RNN I mentioned at https://github.com/fchollet/keras/issues/856#issuecomment-157771075. How do you think? Any plan to fix this?
",jeffzhengye,None,2015-12-13T21:04:23Z,2015-12-16T01:42:57Z
1254,BUG: Layer.get_input returns the wrong input for shared nodes,"Hi all

I'm trying to build a network that takes in two sentences, turns them into fixed-length representations using a shared feed-forward NN, and then calculates their dot product. Unfortunately, I get an error when I try this.

My code for this is

``` python
from keras.models import Graph, Sequential
from keras.layers.embeddings import Embedding
from keras.layers.core import Dense, Flatten

inner_model = Sequential()

# This is the global word lookup table
embedding = Embedding(input_dim=400, output_dim=300, input_length=4)

inner_model.add(embedding)
inner_model.add(Flatten())
inner_model.add(Dense(output_dim=600))
inner_model.add(Dense(output_dim=300))

model = Graph()
model.add_input(name='left', input_shape=(4,), dtype='int')
model.add_input(name='right', input_shape=(4,), dtype='int')
model.add_shared_node(layer=inner_model,
                      name='arg_comp',
                      inputs=['left', 'right'],
                      merge_mode='dot', dot_axes=((0,), (0,)),
                      create_output=True)

model.compile(loss={'arg_comp': 'binary_crossentropy'}, optimizer='sgd')
```

However, I get the following exception:

```
Traceback (most recent call last):
  File ""src/models/test_arg_comp.py"", line 25, in <module>
    model.compile(loss={'arg_comp': 'binary_crossentropy'}, optimizer='sgd')
  File ""build/bdist.linux-x86_64/egg/keras/models.py"", line 635, in compile
  File ""build/bdist.linux-x86_64/egg/keras/backend/theano_backend.py"", line 361, in function
  File ""build/bdist.linux-x86_64/egg/keras/backend/theano_backend.py"", line 354, in __init__
  File ""/usr/local/lib/python2.7/dist-packages/theano/compile/function.py"", line 266, in function
    profile=profile)
  File ""/usr/local/lib/python2.7/dist-packages/theano/compile/pfunc.py"", line 511, in pfunc
    on_unused_input=on_unused_input)
  File ""/usr/local/lib/python2.7/dist-packages/theano/compile/function_module.py"", line 1465, in orig_function
    on_unused_input=on_unused_input).create(
  File ""/usr/local/lib/python2.7/dist-packages/theano/compile/function_module.py"", line 1124, in __init__
    self._check_unused_inputs(inputs, outputs, on_unused_input)
  File ""/usr/local/lib/python2.7/dist-packages/theano/compile/function_module.py"", line 1244, in _check_unused_inputs
    raise UnusedInputError(msg % (inputs.index(i), i.variable, err_msg))
theano.compile.function_module.UnusedInputError: theano.function was asked to create a function computing outputs given certain inputs, but the provided input variable at index 1 is not part of the computational graph needed to compute the outputs: right.
To make this error into a warning, you can pass the parameter on_unused_input='warn' to theano.function. To disable it completely, use on_unused_input='ignore'.
```

Is this a bug in the Siamese layer? Or am I doing something wrong?

Thanks
Kris
",around1991,b'stale',2015-12-12T18:17:06Z,2017-06-22T23:10:40Z
1253,Add debug_mode for enabling suggested Theano detect_nan implementation.,"Added `debug_mode` configuration with values:
- `'none'` is the previous and default behavior.
- `detect_nan` enables suggested Theano `detect_nan` implementation for debugging NaN values (some combinations of optimizer, objective, and activations result are numerically unstable and can cause such problems, eg. adam, mse, PReLu).
",gw0,None,2015-12-12T11:18:56Z,2016-04-11T20:36:25Z
1233,Bug report in RNN,"Around line 68 in recurrent.py
If we are using float32, line 68 will be a float32 times int32, which will produce a float64. (is it because of theano version?)
changing line 68 to X *= K.expand_dims(mask).astype(X.dtype) will fix this problem. 

```
    if mask:
        # apply mask
        X *= K.expand_dims(mask)   # line 68
        masking = True
```
",jeffzhengye,None,2015-12-10T02:07:09Z,2015-12-11T18:42:07Z
1219,Why this model doesn't work?,"```
graph = Graph()


graph.add_input(name='input1',input_shape=(1,28,28))
graph.add_input(name='input2',input_shape=(1,28,28))
#graph.add

graph.add_shared_node(Convolution2D(96,4,4),name=""shared_conv1"",inputs=['input1','input2'],merge_mode=None)
graph.add_shared_node(MaxPooling2D((3,3)),name='shared_P1',inputs=['shared_conv1'],merge_mode=None)
graph.add_shared_node(Convolution2D(256,4,4),name='shared_conv2',inputs=['shared_P1'],merge_mode=None)
graph.add_shared_node(MaxPooling2D((3,3)),name='shared_P2',inputs=['shared_conv2'],merge_mode='concat')



graph.add_node(Convolution2D(96,4,4),name='Tconv1',input='shared_P2')
graph.add_node(MaxPooling2D((3,3)),name='TP1',input='Tconv1')
graph.add_node(Convolution2D(256,4,4),name='Tconv2',input='TP1')
graph.add_node(MaxPooling2D((3,3)),name='TP2',input='Tconv2')
graph.add_node(Flatten(),name='Fla',input='TP2')
graph.add_node(Dense(10),name='dense1',input='Fla')
graph.add_node(Activation('softmax'),name='act',input='dense1')
graph.add_output(name='output',input='act')
graph.compile('Adam', {'output':'categorical_crossentropy'})

X_train1 = d['feature'][:1000,0].reshape((1000,1,28,28))
X_train2 = d['feature'][:1000,1].reshape((1000,1,28,28))
Y_train = d['label'][:1000]
hist = model.fit(data={'input1':X_train1, 'input2':X_train2, 'output':Y_train},batch_size=64, nb_epoch=6, verbose=1)
```

WARNING: probably bad CudaNdarray_set_dim arguments: self->ndim=4, idx=3 stride=-1
WARNING: probably bad CudaNdarray_set_dim arguments: self->ndim=4, idx=2 stride=-2
Traceback (most recent call last):
  File ""/home/mowayao/PycharmProjects/dl/siamese1.py"", line 113, in <module>
    train()
  File ""/home/mowayao/PycharmProjects/dl/siamese1.py"", line 101, in train
    hist = model.fit(data={'input1':X_train1, 'input2':X_train2, 'output':Y_train},batch_size=64, nb_epoch=6, verbose=1)
  File ""build/bdist.linux-x86_64/egg/keras/models.py"", line 692, in fit
  File ""build/bdist.linux-x86_64/egg/keras/models.py"", line 226, in _fit
  File ""build/bdist.linux-x86_64/egg/keras/backend/theano_backend.py"", line 357, in __call__
  File ""/home/mowayao/anaconda/lib/python2.7/site-packages/Theano-0.7.0-py2.7.egg/theano/compile/function_module.py"", line 871, in **call**
    storage_map=getattr(self.fn, 'storage_map', None))
  File ""/home/mowayao/anaconda/lib/python2.7/site-packages/Theano-0.7.0-py2.7.egg/theano/gof/link.py"", line 314, in raise_with_op
    reraise(exc_type, exc_value, exc_trace)
  File ""/home/mowayao/anaconda/lib/python2.7/site-packages/Theano-0.7.0-py2.7.egg/theano/compile/function_module.py"", line 859, in **call**
    outputs = self.fn()
AssertionError: Can't store in size_t for the bytes requested 18446744073709551615 \* 4
Apply node that caused the error: GpuAllocEmpty(Shape_i{0}.0, Shape_i{0}.0, Elemwise{Composite{(i0 + (i1 - i2))}}[(0, 1)].0, Elemwise{Composite{(i0 + (i1 - i2))}}[(0, 1)].0)
Toposort index: 135
Inputs types: [TensorType(int64, scalar), TensorType(int64, scalar), TensorType(int64, scalar), TensorType(int64, scalar)]
Inputs shapes: [(), (), (), ()]
Inputs strides: [(), (), (), ()]
Inputs values: [array(64), array(96), array(-2), array(-1)]
Outputs clients: [[GpuDnnConv{algo='small', inplace=True}(GpuContiguous.0, GpuContiguous.0, GpuAllocEmpty.0, GpuDnnConvDesc{border_mode='valid', subsample=(1, 1), conv_mode='conv'}.0, Constant{1.0}, Constant{0.0})]]

Backtrace when the node is created:
  File ""build/bdist.linux-x86_64/egg/keras/backend/theano_backend.py"", line 556, in conv2d
    subsample=strides)

HINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.
",mowayao,b'stale',2015-12-09T06:18:04Z,2017-06-23T01:11:17Z
1216,Bug fix - Siamese,,farizrahman4u,None,2015-12-08T17:44:07Z,2015-12-08T18:21:18Z
1212,Bug fix + Allow Layers to be called  with mask argument,"- Current implementation of **call** does not work for models in which the first layer is also a Sequential.
- Added option to provide mask.
",farizrahman4u,None,2015-12-08T10:16:21Z,2015-12-15T07:57:17Z
1211,Bug fix - Cos,,farizrahman4u,None,2015-12-08T09:53:17Z,2015-12-11T20:30:58Z
1209,Is there a bug in Siamese?,"graph = Graph()
graph.add_input(name='input1',input_shape=(1,28,28))
graph.add_input(name='input2',input_shape=(1,28,28))
graph.add_shared_node(Convolution2D(96,4,4),name=""shared_conv1"",inputs=['input1','input2'],merge_mode='concat')

but,it reported that:

File ""build/bdist.linux-x86_64/egg/keras/layers/containers.py"", line 329, in add_shared_node
AttributeError: 'Siamese' object has no attribute 'set_name'
",mowayao,b'stale',2015-12-08T09:09:21Z,2017-06-22T23:10:31Z
1201,Problem about Keras-0.3.0-2015/12/1-updating MaxPooling2D,"At the beginning I use Keras-0.2.0 Theano-0.7.0 on pypi source, I have wrote a small program to test mnist dataset recognize, at each epoch it takes 40s after 8 epochs it's accuracy will be 0.99, but I can not use Activation('relu') when I use 'relu' it will throw a exception, then I public a issue on github, the owner told me to update Theano from github, so I uninstall Theano on my computer and install new Theano from Github, when I use new Theano 'relu' can be used, but it's accuracy is very low may be 0.2 or less,so I thought it may be Keras' problem so I update my Keras to 0.3.0, But ETA is too high about 900s and accuracy is too low about 0.1 it must haven't pooling, so I delete MaxPooling2D code, and use subsample=() parameter ETA is lower but accuracy is too low about 0.1. Then I have to install Keras-0.2.0 and do not use 'relu'.

I think this is a small bug on Keras-0.3.0, Maxpooling2D and Activation('relu') can not be used very well.
If somebody meet the same problem please tell me how to solve it. The example of mnist_cnn.py's result is very well so I think may be it's my own problem.

Thanks For Reading My Problem...
",lqchn,b'stale',2015-12-07T07:34:53Z,2017-06-22T23:10:30Z
1136,babi_memnn.py Error,"When running babi_memnn.py, I  get  the following error:

```
Compiling...
C:\Python27\lib\site-packages\theano\scan_module\scan_perform_ext.py:133: Runtim
eWarning: numpy.ndarray size changed, may indicate binary incompatibility
  from scan_perform.scan_perform import *
Train on 10000 samples, validate on 1000 samples
Epoch 1/70
Traceback (most recent call last):
  File ""babi_memnn.py"", line 202, in <module>
    validation_data=([inputs_test, queries_test, inputs_test], answers_test))
  File ""build\bdist.win32\egg\keras\models.py"", line 507, in fit
  File ""build\bdist.win32\egg\keras\models.py"", line 226, in _fit
  File ""build\bdist.win32\egg\keras\backend\theano_backend.py"", line 357, in __c
all__
  File ""C:\Python27\lib\site-packages\theano\compile\function_module.py"", line 6
06, in __call__
    storage_map=self.fn.storage_map)
  File ""C:\Python27\lib\site-packages\theano\compile\function_module.py"", line 5
95, in __call__
    outputs = self.fn()
  File ""C:\Python27\lib\site-packages\theano\gof\op.py"", line 768, in rval
    r = p(n, [x[0] for x in i], o)
  File ""C:\Python27\lib\site-packages\theano\tensor\blas.py"", line 1612, in perf
orm
    z[0] = numpy.asarray(numpy.dot(x, y))
ValueError: ('shapes (32,68) and (132,64) not aligned: 68 (dim 1) != 132 (dim 0)
', (32, 68), (132, 64))
Apply node that caused the error: Dot22(Alloc.0, <TensorType(float32, matrix)>)
Inputs types: [TensorType(float32, matrix), TensorType(float32, matrix)]
Inputs shapes: [(32, 68), (132, 64)]
Inputs strides: [(272, 4), (256, 4)]
Inputs values: ['not shown', 'not shown']

HINT: Re-running with most Theano optimization disabled could give you a back-tr
ace of when this node was created. This can be done with by setting the Theano f
lag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be
 disabled with 'optimizer=None'.
HINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storag
e map footprint of this apply node.
```
",farizrahman4u,None,2015-12-02T16:09:11Z,2015-12-06T19:34:00Z
1135,ZeroPadding2D bug with TensorFlow?,"Hello,

I'm getting that kind of error when I use ZeroPadding2D layers with TensorFlow (it works well when Theano is the backend). 

```
Traceback (most recent call last):
  File ""vgg_net.py"", line 1345, in <module>
    custom_convnet()
  File ""vgg_net.py"", line 1235, in custom_convnet
    model = build_custom3()
  File ""vgg_net.py"", line 1226, in build_custom3
    model.compile(loss='categorical_crossentropy',optimizer=optimizer)
  File ""//anaconda/lib/python2.7/site-packages/keras/models.py"", line 372, in compile
    self.y_train = self.get_output(train=True)
  File ""//anaconda/lib/python2.7/site-packages/keras/layers/containers.py"", line 73, in get_output
    return self.layers[-1].get_output(train)
  File ""//anaconda/lib/python2.7/site-packages/keras/layers/core.py"", line 686, in get_output
    X = self.get_input(train)
  File ""//anaconda/lib/python2.7/site-packages/keras/layers/core.py"", line 107, in get_input
    return self.previous.get_output(train=train)
  File ""//anaconda/lib/python2.7/site-packages/keras/layers/core.py"", line 686, in get_output
    X = self.get_input(train)
  File ""//anaconda/lib/python2.7/site-packages/keras/layers/core.py"", line 107, in get_input
    return self.previous.get_output(train=train)
  File ""//anaconda/lib/python2.7/site-packages/keras/layers/core.py"", line 686, in get_output
    X = self.get_input(train)
  File ""//anaconda/lib/python2.7/site-packages/keras/layers/core.py"", line 107, in get_input
    return self.previous.get_output(train=train)
  File ""//anaconda/lib/python2.7/site-packages/keras/layers/core.py"", line 597, in get_output
    return K.flatten(X)
  File ""//anaconda/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py"", line 258, in flatten
    x = tf.reshape(x, [-1, np.prod(x.get_shape()[1:].as_list())])
  File ""//anaconda/lib/python2.7/site-packages/numpy/core/fromnumeric.py"", line 2349, in prod
    out=out, keepdims=keepdims)
  File ""//anaconda/lib/python2.7/site-packages/numpy/core/_methods.py"", line 35, in _prod
    return umr_prod(a, axis, dtype, out, keepdims)
TypeError: unsupported operand type(s) for *: 'int' and 'NoneType'
```
",Zebreu,b'stale',2015-12-02T15:56:14Z,2019-10-05T01:05:52Z
1120,make keras.io/examples = github.com/fchollet/keras/README.md,"I've been slowly trudging through the examples page trying to adapt it to the new API and correct the bugs etc only to find that there is a lovely, up to date version of the same examples in the github repo's README. 

Would be nice if the examples page reflected the README. 
",mikedewar,b'stale',2015-12-01T15:51:33Z,2017-06-22T23:09:42Z
1109,There seems a bug in the cosine merge layer,"It seems that when combining two tensor V1 and V2, the cosine merge output is not dot(V1, V2) / sqrt(dot(V1,V1) \* dot(V2, V2)). Suppose V1 and V2 is (batch_size, dim). The result should be (batch_size, 1) while dot(V1, V2) / sqrt(dot(V1,V1) \* dot(V2, V2)) is (batch_size, batch_size). Thus, I change it to the tensordot with parameter `self.dotaxes`.

I was wondering is that reasonable?
",largelymfs,None,2015-11-29T20:02:25Z,2015-12-30T18:28:48Z
1107,imdb bidirectional example bug,"The imdb bidirectional example ""imdb_bidirectional_lstm.py"" is returning an error:

```
ValueError: Input dimension mis-match. (input[1].shape[1] = 128, input[2].shape[1] = 64)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""imdb_bidirectional_lstm.py"", line 80, in <module>
    nb_epoch=4)
  File ""/home/nawarhalabi/deepnet/keras/keras/models.py"", line 684, in fit
    shuffle=shuffle, metrics=metrics)
  File ""/home/nawarhalabi/deepnet/keras/keras/models.py"", line 216, in _fit
    outs = f(*ins_batch)
  File ""/usr/local/lib/python3.2/dist-packages/theano/compile/function_module.py"", line 606, in __call__
    storage_map=self.fn.storage_map)
  File ""/usr/local/lib/python3.2/dist-packages/theano/gof/link.py"", line 206, in raise_with_op
    raise exc_type(exc_value).with_traceback(exc_trace)
  File ""/usr/local/lib/python3.2/dist-packages/theano/compile/function_module.py"", line 595, in __call__
    outputs = self.fn()
ValueError: Input dimension mis-match. (input[1].shape[1] = 128, input[2].shape[1] = 64)
Apply node that caused the error: Elemwise{mul,no_inplace}(TensorConstant{(1, 1) of 2.0}, Join.0, Elemwise{Composite{Cast{float64}(LT(i0, i1))}}[(0, 0)].0)
Inputs types: [TensorType(float64, (True, True)), TensorType(float64, matrix), TensorType(float64, matrix)]
Inputs shapes: [(1, 1), (32, 128), (32, 64)]
Inputs strides: [(8, 8), (1024, 8), (512, 8)]
Inputs values: [array([[ 2.]]), 'not shown', 'not shown']
```

When I set the dropout layer probability to 0 it works (not sure if this is right though)
",nawarhalabi,b'stale',2015-11-29T09:34:22Z,2017-06-22T23:09:50Z
1106,Bug report in Convolution2D,"We can see in the Convolution2D:

```
self.params = [self.W, self.b]
if weights is not None:
    self.set_weights(weights)
```

and in the set_weights function, we have:

```
def set_weights(self, weights):
    for p, w in zip(self.params, weights):
        if p.eval().shape != w.shape:
            raise Exception(""Layer shape %s not compatible with weight shape %s."" % (p.eval().shape, w.shape))
        p.set_value(floatX(w))
```

Ok, now we have a weight matrix whose shape is (64,3,3,3), means that there are 64 filters in the layer, for each filter there are 3 channels and the size of each filter is 3*3
And we have bias stored in another file, its a (64,1) np array, according to set_weights showed above, kera will check if the weights matrix given matches the initial one, since the params contains two part: weight and bias, we should merge our weight matrix and bias together, for example:

```
merge_weight = (weight, bias)
```

I am very sure that the shape of weight here is (64,3,3,3), but when I was trying to pass the merge_matrix to Convolution2D, it turns out in the conlution2D, merge_weight[0].shape is (64,)
and thus the set_weights raise the exception: 

```
Layer shape (64, 3, 3, 3) not compatible with weight shape (64,)
```

If you trying to access weights[0][0], it's ok although the shape here is showed to be (64,)

Hope to fix this problem as soon as possible....
Thank you very much
",MoyanZitto,None,2015-11-29T07:28:11Z,2016-07-20T13:58:32Z
1081,Bug fix - Siamese layer,,farizrahman4u,None,2015-11-25T20:40:29Z,2015-11-25T21:28:59Z
1078,Fix bug in Merge.get_input(),"`get_input()` return the inputs of input layers, instead of their outputs.
",farizrahman4u,None,2015-11-25T15:31:21Z,2015-11-25T16:31:33Z
1076,mnist_irnn.py strange behavior,"Not sure if it is due to my personal setting or it is a general issue.

I can run the example mnist_irnn.py using CPU.
When I run it using gnu, I got this error message:

```
ubuntu@ip-172-31-2-0:~/keras/examples$ python mnist_irnn.py
Using gpu device 0: GRID K520 (CNMeM is disabled)
X_train shape: (60000, 784, 1)
60000 train samples
10000 test samples
Evaluate IRNN...
Train on 60000 samples, validate on 10000 samples
Epoch 1/200
Traceback (most recent call last):
  File ""mnist_irnn.py"", line 69, in <module>
    show_accuracy=True, verbose=1, validation_data=(X_test, Y_test))
  File ""build/bdist.linux-x86_64/egg/keras/models.py"", line 495, in fit
  File ""build/bdist.linux-x86_64/egg/keras/models.py"", line 216, in _fit
  File ""/usr/local/lib/python2.7/dist-packages/theano/compile/function_module.py"", line 871, in __call__
    storage_map=getattr(self.fn, 'storage_map', None))
  File ""/usr/local/lib/python2.7/dist-packages/theano/gof/link.py"", line 314, in raise_with_op
    reraise(exc_type, exc_value, exc_trace)
  File ""/usr/local/lib/python2.7/dist-packages/theano/compile/function_module.py"", line 859, in __call__
    outputs = self.fn()
  File ""/usr/local/lib/python2.7/dist-packages/theano/scan_module/scan_op.py"", line 963, in rval
    r = p(n, [x[0] for x in i], o)
  File ""/usr/local/lib/python2.7/dist-packages/theano/scan_module/scan_op.py"", line 952, in <lambda>
    self, node)
  File ""theano/scan_module/scan_perform.pyx"", line 389, in theano.scan_module.scan_perform.perform (/home/ubuntu/.theano/compiledir_Linux-3.13--generic-x86_64-with-Ubuntu-14.04-trusty-x86_64-2.7.6-64/scan_perform/mod.cpp:3936)
AttributeError: 'CudaNdarray' object has no attribute 'data'
Apply node that caused the error: forall_inplace,gpu,grad_of_scan_fn}(Elemwise{minimum,no_inplace}.0, GpuSubtensor{int64:int64:int64}.0, Subtensor{int64:int64:int64}.0, GpuSubtensor{int64:int64:int64}.0, GpuSubtensor{::int64}.0, Elemwise{minimum,no_inplace}.0, Elemwise{minimum,no_inplace}.0, <CudaNdarrayType(float32, matrix)>, GpuDimShuffle{1,0}.0)
Toposort index: 247
Inputs types: [TensorType(int64, scalar), CudaNdarrayType(float32, 3D), TensorType(int8, (False, False, True)), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), TensorType(int64, scalar), TensorType(int64, scalar), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix)]
Inputs shapes: [(), (784, 32, 100), (784, 32, 1), (784, 32, 100), (785, 32, 100), (), (), (100, 100), (100, 100)]
Inputs strides: [(), (-3200, 100, 1), (-32, 1, 1), (-3200, 100, 1), (-3200, 100, 1), (), (), (100, 1), (1, 100)]
Inputs values: [array(784), 'not shown', 'not shown', 'not shown', 'not shown', array(784), array(784), 'not shown', 'not shown']
Outputs clients: [[], [GpuSubtensor{::int64}(forall_inplace,gpu,grad_of_scan_fn}.1, Constant{-1})], [GpuReshape{2}(forall_inplace,gpu,grad_of_scan_fn}.2, MakeVector{dtype='int64'}.0)]]

HINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.
HINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.
```

According to the output, I re-run the code using:

```
THEANO_FLAGS='optimizer=None' python mnist_irnn.py
```

Then there is no error message but very slow.

Anyone has similar issues?
",lxc-xx,b'stale',2015-11-25T08:04:49Z,2017-06-22T22:10:14Z
1070,Clarification on  mask behaviour,"Guys i have a question on the mask behaviour, i don't understand how masks works in Keras.
Now let's assume i have a masked Input (embedding layer with mask zeros) If i want to concatenate over the embedding dimension that layer with another embedding layer (to represent another feature of the word (pos tag?, capitalisation?, ner tag?) with the same mask all the mask information are lost? So if i apply a recurrent layer on top of that it will be unmasked?

Another things is about the Time distributed merge, if i have a mask on my embedding layer i cannot compute the average of the embeddings to lazy represent my input sentence? For two reason actually `TimeDistributedMerge` do not support masked inputs, and if it can accept mask the mean is computed over all the tensors without taking in consideration the possibility of having variable length inputs. I think that this behaviour is problematic even if we are applying this layer over a `recurrent` layer.

From my honest opinion the mask should be calculated over the input sequence and broadcasted through the upper layers that have a time dimension that may be specified in the `Layer` constructor, in that way it is possible to keep track of the masks when needed. Most of the time, masks are lost during model composition without any notification. Another advantage of making clear what the time dimension is about debugging and error checking.

What do you think?

Thanks,
Daniele
",dbonadiman,b'stale',2015-11-24T12:23:22Z,2017-06-22T23:12:29Z
1065,Save weights fwrite buffer issue in Windows,"I encountered an issue saving weights upon epoch completion in Windows. I found this [bug workaround](http://webcache.googleusercontent.com/search?q=cache:rrgvnf2-0LIJ:https:%2F%2Fsupport.microsoft.com%2Fen-us%2Fkb%2F899149%20&cd=1&hl=en&ct=clnk&gl=us) which suggested using 'wb' mode when opening the file to write. I edited the mode for both Sequential and Graph mode if using Windows. It seems to have solved the issue for me.
",jacobzweig,None,2015-11-23T21:50:49Z,2015-11-23T22:13:10Z
1044,Fix the spell error bug of Lambda Layer,,jasonwbw,None,2015-11-20T06:37:42Z,2015-11-20T06:43:07Z
1031,Bug in the evaluation of the validation data in the Graph model,"Hello all,

I'm experimenting with the `Graph` model and I think I'm not using the `validation_data` parameter properly.

This is the structure of my model where I'm trying to fit a time series using lags:

``` python
f_length = [2,3,4,5]
convs = []
model = Graph()
model.add_input(name='endog', input_shape=(len_ts_y,1))
for i in f_length:
    model.add_node(Convolution1D(nb_filter=nb_filter/2,
                                filter_length=i,
                                border_mode=""full"",
                                activation=""relu"",
                                subsample_length=1,
                                W_regularizer=l1(0.0001)
                                ),
                                name='conv_'+str(i), input='endog')
    model.add_node(MaxPooling1D(pool_length=pool_length),
               name=""Max_pool""+str(i), input='conv_'+str(i))

for i in f_length:
    model.add_node(Convolution1D(nb_filter=nb_filter/2,
                                filter_length=i,
                                border_mode=""full"",
                                activation=""relu"",
                                subsample_length=1,
                                W_regularizer=l1(0.0001)
                                ),
                                name='conv_2'+str(i), input=""Max_pool""+str(i))

    model.add_node(Flatten(), name=""flat_""+str(i), input='conv_2'+str(i))
    convs.append(""flat_""+str(i))

model.add_node(Dense(32, activation=""sigmoid""), name=""Dense_rec2"", inputs=convs)
model.add_node(Dense(32, activation=""sigmoid""), name=""Dense_rec3"", input='Dense_rec2')
model.add_node(Dense(1, activation=""softplus""), name='last_dense', input='Dense_rec3')
model.add_output(name='output', input='last_dense')
model.compile(optimizer='adam', loss={'output':'mse'})
```

The shape of my data is:

``` python
endog_train.shape, y_train.shape
((182725, 60), (182725, 120))
```

And I tried with both `validation_split` and `validation_data`.

``` python
model.fit({'endog': endog_train[:-10000,:,None], 'output': y_train[:-10000,-1]},
          # validation_split=0.3,
          validation_data={'endog':endog_train[-10000:,:,None], 'output': y_train[-10000:,-1]},
          batch_size=batch_size,
          nb_epoch=nb_epoch+4)
```

When the model is evaluated on the test set I get this error:

``` python
Train on 172725 samples, validate on 10000 samples
Epoch 1/8
172544/172725 [============================>.] - ETA: 0s - loss: 0.0155
---------------------------------------------------------------------------
IndexError                                Traceback (most recent call last)
<ipython-input-50-c0aba739c291> in <module>()
      3           validation_data={'endog':endog_train[-10000:,:,None], 'output': y_train[-10000:,-1]},
      4           batch_size=batch_size,
----> 5           nb_epoch=nb_epoch+4)

/media/thomas/data/libraries/keras/keras/models.pyc in fit(self, data, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight)
    680                             verbose=verbose, callbacks=callbacks,
    681                             val_f=val_f, val_ins=val_ins,
--> 682                             shuffle=shuffle, metrics=metrics)
    683         return history
    684 

/media/thomas/data/libraries/keras/keras/models.pyc in _fit(self, f, ins, out_labels, batch_size, nb_epoch, verbose, callbacks, val_f, val_ins, shuffle, metrics)
    226                     if do_validation:
    227                         # replace with self._evaluate
--> 228                         val_outs = self._test_loop(val_f, val_ins, batch_size=batch_size, verbose=0)
    229                         if type(val_outs) != list:
    230                             val_outs = [val_outs]

/media/thomas/data/libraries/keras/keras/models.pyc in _test_loop(self, f, ins, batch_size, verbose)
    280         for batch_index, (batch_start, batch_end) in enumerate(batches):
    281             batch_ids = index_array[batch_start:batch_end]
--> 282             ins_batch = slice_X(ins, batch_ids)
    283 
    284             batch_outs = f(*ins_batch)

/media/thomas/data/libraries/keras/keras/models.pyc in slice_X(X, start, stop)
     56             if hasattr(start, 'shape'):
     57                 start = start.tolist()
---> 58             return [x[start] for x in X]
     59         else:
     60             return [x[start:stop] for x in X]

IndexError: index 1 is out of bounds for axis 1 with size 1
```

Everything is working fine if I use `validation_split`.

Am I doing something wrong?

Thank you!
",tboquet,None,2015-11-18T18:41:09Z,2015-11-18T21:32:45Z
996,Failure to converge when linked with Intel MKL,"I've run into a problem that I'm not sure where to even begin debugging.  I'm getting wildly different results when I run the same program on different hardware.  It has something to do with the Intel MKL BLAS -- when I use a version of numpy linked with MKL, the results are terrible. To take one example, when I run a particular network using MKL BLAS and device=cpu, the loss starts at around 10 and drifts a but up and down but never consistently decreases .  With MKL BLAS and device=gpu, the loss drops quick to 5 and then hovers around that.  Using numpy linked with OpenBLAS, the loss steadily decreases from 10 to (after 1500 epochs) about 0.003.  

Has anyone reported something like this before?  It's not a critical bug for me, since the solution is obvious: just use OpenBLAS.  But the community ought to be concerned about this.  As I say, I don't know where to begin to isolate this... whether it's a problem with MKL, numpy, theano, keras, the compilers, or some combination of all of the above.  
",rmalouf,None,2015-11-11T20:12:13Z,2015-11-11T23:56:08Z
988,Bug with TimeDistributedDense?,"Hello.

It seems there is a bug (??) in TimeDistributedDense, or I may be doing something wrong.
Loading a model from file gives different predictions that the same model b4 saving to file.
I've been banging my head over this for the last couple of days.
Sorry for cross posting in keras-users.

Here is the code:

```
from __future__ import print_function
import numpy as np
from keras.models import Sequential
from keras.layers.core import Dense, TimeDistributedDense, TimeDistributedMerge
from keras.models import model_from_json


def create_model(n_features):
    model = Sequential()

    model.add(
        TimeDistributedDense(
            input_dim=n_features, output_dim=10, init=""one"",
        ))
    model.add(TimeDistributedMerge(mode='ave'))
    model.add(Dense(output_dim=1, init=""one""))
    return model


def save_model(model, fname):
    json_string = model.to_json()
    open(fname, 'w').write(json_string)
    model.save_weights(fname + '.h5', overwrite=True)


def load_model(fname):
    model = model_from_json(open(fname).read())
    model.load_weights(fname + '.h5')
    return model


if __name__ == '__main__':
    np.random.seed(1337)
    n_features = 4000

    model = create_model(n_features)
    model.compile(loss='mse',
                class_mode=""categorical"",
                optimizer='rmsprop')

    input_matrix = np.random.random((1000, 5, n_features))
    ys = np.random.random(1000)

    for i in xrange(5):
        loss = model.train_on_batch(input_matrix, ys)
        print(i, loss)

    probs = model.predict(input_matrix)
    print(probs[:10])
    save_model(model, 'tmp_model')
    model_loaded = load_model('tmp_model')
    print('='*20)
    probs_after = model_loaded.predict(input_matrix)
    print(probs_after[:10])

    print('total diffs:', sum(probs != probs_after))
```
",tzachar,None,2015-11-10T09:39:53Z,2015-11-11T09:46:40Z
980,error happed in example code mnist_mlp.py,"I runned example code mnist_mlp.py, getting following warning and error. I wondering what leads to these error. Thanks in advance.

UserWarning: MRG_RandomStreams Can't determine #streams from size (Shape.0), guessing 60*256
  nstreams = self.n_streams(size)

ValueError: size must remain unchanged, changed from 1280 to -10
Apply node that caused the error: GpuReshape{2}(GpuElemwise{Add{output_types_preference=transfer_type{0}}}[(0, 0)].0, MakeVector.0)
Inputs shapes: [(128, 10), (2,)]
Inputs strides: [(10, 1), (8,)]
Inputs types: [CudaNdarrayType(float32, matrix), TensorType(int64, vector)]
Use the Theano flag 'exception_verbosity=high' for a debugprint of this apply node.
",danieljf24,None,2015-11-09T14:08:53Z,2015-11-10T07:36:24Z
977,Better keras checks and exceptions.,"Hello everybody,
At the moment we execute all the variable checks inside the init function of every layer.
Shouldn't we build a more consistent type check?

Here is an example from convolution 1d:

``` python
        if border_mode not in {'valid', 'full', 'same'}:
            raise Exception('Invalid border mode for Convolution1D:', border_mode)

```

I think that this check shouldn't be inside the init directly but we should have something like:

``` python

self.border_mode =  border_mode

```

inside the init function and 

``` python
@property
def border_mode(self):
        return self._border_mode

@border_mode.setter
def border_mode(self, value):
        if value not in {'valid', 'full', 'same'}:
            raise Exception('Invalid border mode for Convolution1D:', value)
        self._border_mode = value       

```

In this way properties are checked even if we change a variable in a second stance.

``` python
layer.border_mode  =  'full'
```

and  we can build a more solid types check for every keras layer and property.

another interesting things is to make some private types. That rise exception if you try to change them.
What we need at the moment is a more solid environment to experiment on.

This is in line with https://github.com/fchollet/keras/issues/754 and in particular this point:

> Thorough checking of assumptions made about user-provided constructor arguments throughout the codebase, and raising helpful and clear error messages when some assumptions aren't respected. Ideally no error will ever be raised by Theano, because we will be catching everything on the Keras side. This will make debugging of Keras models much faster and easier.

Moreover this will help when we want to build much more ""complex class"" such as the Merge.
We can make the merge mode variable immutable (we block the setter function with an exception).
by doing so we can move all the type checks for the layers away from the init leaving it as clean as possible.

EDIT:
An example can be found in this branch for the merge mode:
https://github.com/dbonadiman/keras/commit/14c2fc66b6620cc8496b272c4472ae643ad1192c
",dbonadiman,b'stale',2015-11-09T10:26:12Z,2017-06-22T22:11:19Z
976,Theano unusedInputError,"Hi it's me again...
      I was trying to build a deep autoencoder, which is a little different to the deep autoencoder showed in keras examples: I need to pre-train the autoencoder and apply fine tune on the pre-trained model. The progress is as follows:

```
#Model
autoEncoder = Sequential()

#PreTrain
for i in range(4):
    subModel = Sequential()
    encoder = Dense(inpNum, hidNum, activation = activation, init = init)
    decoder = Dense(hidNum, inpNum, activation = activation, init = init)
    subAutoEncoder=AutoEncoder(encoder=encoder,decoder=decoder,
output_reconstruction=False)
    if i==0:
         subModel.add(noise.GaussianNoise(0.2))
         subModel.add(subAutoEncoder)
    else:
         subModel.add(subAutoEncoder)
         subModel.compile(optimizer=optimizer, loss='mse')
         subModel.fit(temp_data, temp_data, batch_size=batch_size, nb_epoch=nb_epoch, shuffle=True, verbose=1)   
         temp_data = np.asarray(subModel.predict(temp_data,batch_size=batch_size),dtype='float32')
         inpNum,hidNum = hidNum, inpNum
         autoEncoder.add(encoder)


#Fine Tune
autoEncoder.compile(optimizer=optimizer,loss='mse')
autoEncoder.fit(inpData, inpData, batch_size=batch_size, nb_epoch=nb_epoch, shuffle=True, verbose=1)
```

And this is the error message, the error happens at Fine Tune process, autoEncoder.compile(optimizer=optimizer,loss='mse') .

raise UnusedInputError(msg % (inputs.index(i), i.variable, err_msg))
theano.compile.function_module.UnusedInputError: theano.function was asked to create a function computing outputs given certain inputs, but the provided input variable at index 0 is not part of the computational graph needed to compute the outputs: Elemwise{add,no_inplace}.0.

It seems that the input variable provided for computing loss at index 0, which is X_train in keras code, is not used. I really don't understand it...

I know github may not a proper place for such problems, because it's neither a bug report nor a code contribution, but the Googlegroup you provided at Keras Home page is blocked in China. So...I'm really sorry but still need your help, thank you very much! 
#  π__π

update:
    Although I still don't know why this problem occurred, but it's GaussianNoise that cause this problem, once I remove the GaussianNoise, the code works.
#     = = But I need the GaussianNoise layer ...

update:
    To fix the problem, just adjust the postion of GaussianNoise..
    for example, this code:

```
for i in range(4):
    subModel = Sequential()
    encoder = Dense(inpNum, hidNum, activation = activation, init = init)
    decoder = Dense(hidNum, inpNum, activation = activation, init = init)
    subAutoEncoder=AutoEncoder(encoder=encoder,decoder=decoder,
output_reconstruction=False)
    subModel.add(noise.GaussianNoise(0.2))
    subModel.add(subAutoEncoder)
    subModel.compile(optimizer=optimizer, loss='mse')
    subModel.fit(temp_data, temp_data, batch_size=batch_size, nb_epoch=nb_epoch, shuffle=True, verbose=1)   
         temp_data = np.asarray(subModel.predict(temp_data,batch_size=batch_size),dtype='float32')
         inpNum,hidNum = hidNum, inpNum
         autoEncoder.add(encoder)
```

  is wrong, but if we move subModel.add(GaussianNoise(0.2)) to the second line in for loop, like this:

```
for i in range(4):
    subModel = Sequential()
    # the gaussianNoise layer is here now
    subModel.add(noise.GaussianNoise(0.2))
    encoder = Dense(inpNum, hidNum, activation = activation, init = init)
    decoder = Dense(hidNum, inpNum, activation = activation, init = init)
    subAutoEncoder=AutoEncoder(encoder=encoder,decoder=decoder,
output_reconstruction=False)
    #the gaussianNoise layer is no longer here anymore
    subModel.add(subAutoEncoder)
    subModel.compile(optimizer=optimizer, loss='mse')
    subModel.fit(temp_data, temp_data, batch_size=batch_size, nb_epoch=nb_epoch, shuffle=True, verbose=1)   
         temp_data = np.asarray(subModel.predict(temp_data,batch_size=batch_size),dtype='float32')
         inpNum,hidNum = hidNum, inpNum
         autoEncoder.add(encoder)
```

Yes it works...This is definitely the oddest bug I ever met.
",MoyanZitto,None,2015-11-09T05:35:51Z,2016-07-20T13:59:10Z
967,[Probably bug?] imdb.py return X_test value without an input file,"Basically, I don't know how the imdb.py obtain the data from even through I have change the path to 'None' but it still get an X_test with 5000 rows.

EDIT: My bad!! sorry, I just notice that it currently used the dist-package which I have installed via pypi instead of the clone code.
",tunoat,None,2015-11-07T15:20:34Z,2015-11-07T15:40:18Z
946,"Graph bug: ""AttributeError: 'Dense' object has no attribute 'initial_weights'""","The following works just fine:

```
d_in = 10
d_out = 55
weights = np.random.random((d_in,d_out))
model = Sequential()
D = Dense(input_dim=d_in, output_dim=d_out, weights=[weights, np.zeros(d_out)])
model.add(D)
```

But trying the same thing with `Graph` results in an error:

```
model = Graph()
model.add_input(name='input',input_shape=(d_in,))
D = Dense(input_dim=d_in, output_dim=d_out, weights=[weights, np.zeros(d_out)])
model.add_node(D,name='dense', input='input')
```

Here's the full trace:

```
Traceback (most recent call last):

  File ""<ipython-input-40-c6155a32b3d8>"", line 12, in <module>
    model.add_node(D,name='dense', input='input')

  File ""build\bdist.win-amd64\egg\keras\layers\containers.py"", line 254, in add_node
    layer.set_previous(self.inputs[input])

  File ""build\bdist.win-amd64\egg\keras\layers\core.py"", line 39, in set_previous
    self.build()

  File ""build\bdist.win-amd64\egg\keras\layers\core.py"", line 645, in build
    if self.initial_weights is not None:

AttributeError: 'Dense' object has no attribute 'initial_weights'
```
",sergeyf,b'stale',2015-11-03T21:18:11Z,2017-06-22T22:11:12Z
936,Dot Merge do not return the correct output shape,"This is not a bug but only a consideration. The dot merge mode as first intended was thinked to do a dot product between 1d tensors.
For that it works perfectly, however if we give the possibility to use 2D tensors in input and a dot-asxes we need to make some adjustment.
Giving the following tensors as input (None, 50, 100) and (None, 50, 2) and ([1], [1]) as dot-asxes the computed output shape is (None, 100) if we invert the order of the input is (None, 2) But the correct output shape are (None, 100, 2) and (None, 2, 100).

From that the function dimshuffle(0, 'x') will fail.

I'm here to reason about a possible solution (that can be a simple check that the two shape are equal) and directly limit the api potential. 

The first Naive solution is to correctly compute the output_shape by concatenating all the dimension excluding the ""dotted_ones"" and using the reshape function instead of the dim shuffle 'don't know about the last change so i ask for suggestion'.
",dbonadiman,None,2015-11-02T14:50:34Z,2015-11-18T14:32:06Z
932,network diverges,"Hi,

It seems that using 'rmsprop' and 'categorical_crossentropy' the network diverges. 
370784/370784 [==============================] - 6700s - loss: 1.8887 - acc: 0.4243 - val_loss: 1.8804 - val_acc: 0.4097
370784/370784 [==============================] - 6702s - loss: 1.9328 - acc: 0.4118 - val_loss: 1.9089 - val_acc: 0.3977
370784/370784 [==============================] - 6702s - loss: 1.9986 - acc: 0.3866 - val_loss: 1.9611 - val_acc: 0.3873
370784/370784 [==============================] - 6708s - loss: 2.0482 - acc: 0.3752 - val_loss: 1.9454 - val_acc: 0.3878
370784/370784 [==============================] - 6714s - loss: 2.1057 - acc: 0.3539 - val_loss: 2.0767 - val_acc: 0.3591
137856/370784 [==========>...................] - ETA: 4147s - loss: 2.1578 - acc: 0.3390

I use a convolutional network with dropout on the last FC layers. Can dropout cause to such a behaviour, or it just a bug?

Thanks,

Oren
",loyeamen,b'stale',2015-11-02T08:37:53Z,2017-06-22T22:11:09Z
901,Getting IndexError,"I am very new to keras. Trying to build a binary classifier for an NLP task. (My code is motivated from imdb example - https://github.com/fchollet/keras/blob/master/examples/imdb_cnn.py) 

below is my code snippet:

```
max_features = 30
maxlen = 30
batch_size = 32
embedding_dims = 30
nb_filter = 250
filter_length = 3
hidden_dims = 250
nb_epoch = 3

(Train_X, Train_Y, Test_X, Test_Y) = load_and_split_data()
model = Sequential()
model.add(Embedding(max_features, embedding_dims, input_length=maxlen))
model.add(Convolution1D(nb_filter=nb_filter,filter_length=filter_length,border_mode=""valid"",activation=""relu"",subsample_length=1))
model.add(MaxPooling1D(pool_length=2))
model.add(Flatten())
model.add(Dense(hidden_dims))
model.add(Activation('relu'))
model.add(Dense(1))
model.add(Activation('sigmoid'))
model.compile(loss='binary_crossentropy', optimizer='rmsprop', class_mode=""binary"")
fitlog = model.fit(Train_X, Train_Y, batch_size=batch_size, nb_epoch=nb_epoch, show_accuracy=True, verbose=2)
```

When I run model.fit(), I get the following:

```
/.virtualenvs/nnet/lib/python2.7/site-packages/theano/compile/function_module.pyc in __call__(self, *args, **kwargs)
    857         t0_fn = time.time()
    858         try:
--> 859             outputs = self.fn()
    860         except Exception:
    861             if hasattr(self.fn, 'position_of_error'):

IndexError: One of the index value is out of bound. Error code: 65535.\n
Apply node that caused the error: GpuAdvancedSubtensor1(<CudaNdarrayType(float32, matrix)>, Elemwise{Cast{int64}}.0)
Toposort index: 47
Inputs types: [CudaNdarrayType(float32, matrix), TensorType(int64, vector)]
Inputs shapes: [(30, 30), (3840,)]
Inputs strides: [(30, 1), (8,)]
Inputs values: ['not shown', 'not shown']
Outputs clients: [[GpuReshape{3}(GpuAdvancedSubtensor1.0, MakeVector{dtype='int64'}.0)]]

HINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.
HINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.
```

Can you please help me resolve this ?
",anujgupta82,None,2015-10-27T14:44:25Z,2018-02-16T14:27:18Z
900,splitting data causes network to diverge,"I'm training a net for a classification task.
I used the mnist_cnn.py as reference.
Currently I am limited to work with images of size 160x160 since using larger resolution causes the GPU to run out of memory (I have about 30K samples).
I tried to change the configuration to load images from an iterator in chunks of 5K (as suggested [here](https://github.com/fchollet/keras/issues/68)).
I am sure there is no bug in the iterator code.
I even ran some simple tests to see the affects of splitting the data and I saw longer convergence times when the data is split.
Is this normal behaviour? how can I overcome this problem?
",edocoh87,b'stale',2015-10-27T11:47:53Z,2017-06-22T22:16:02Z
865,Update optimizers.py,"Bug:
float() argument must be a string or a number, not 'TensorSharedVariable'
fixed!
",suixudongi8,None,2015-10-21T13:30:53Z,2015-10-23T12:59:58Z
849,Freezing layer updates on a graph,"There seems to be some inconsistency when freezing weight updates in graphs. For example, the following code works as expected if I use a `Sequential()` model: 

```
# Simple input
x = reshape( [1,2,3,4,5,6,7,8], (1,8,1))

# Filter with a delta, does nothing to the input
w = array( zeros( (1,1,4,1) )); w[0,0,1,0] = 1
cl = Convolution1D( 1, 4, weights=[w, array([0])], border_mode='same', input_dim=1)

# Don't update the weights during training
cl.params = []
cl.updates = []

# Compile and train
model = Sequential()
model.add( cl)
model.compile( loss='mse', optimizer='rmsprop')
model.fit( x, 2*x, nb_epoch=1000, verbose=0)

# Output should be the same as input
y = model.predict( x).T
print vstack( (squeeze(x),squeeze(y)))
```

I essentially made a convolutional layer which doesn't update, so the output is the same as input even after training (the layer weights stay as initialized).

If I try to do the same thing using a `Graph()` it doesn't seem to produce the same result:

```
x = reshape( [1,2,3,4,5,6,7,8], (1,8,1))

# Simple convolution layer as before
w = array( zeros( (1,1,4,1) )); w[0,0,1,0] = 1
cl = Convolution1D( 1, 4, weights=[w, array([0])], border_mode='same')
cl.params = []
cl.updates = []

# Make the graph
model = Graph()
model.add_input( name='in', input_shape=(x.shape[1],x.shape[2]))
model.add_node( cl, name='conv', input='in')
model.add_output( name='output', input='conv')

# Why is this defined now??
print model.nodes['conv'].get_params()

# Compile and train
model.compile( RMSprop(), {'output':'mse'})
model.fit({'in':x, 'output':2*x}, nb_epoch=2000, verbose=0)

# Predict. Outputs are now close to the targets and not the same the as the input
y = model.predict( {'in':x})['output']
print vstack( (squeeze(x),squeeze(y)))

# Not what I initialized with
print model.nodes['conv'].get_weights()[0]
```

I would have assumed that the convolutive layer parameters wouldn't be updated, but they clearly are.

Outside of changing the code to use a graph, I also had to drop the `input_dim` parameter when refining the convolutional layer. If I define it and also define the `weights` then I get the error: `AttributeError: 'Convolution1D' object has no attribute 'initial_weights'` (presumably a bug?)

I speculate that by not defining `input_dim` the parameters are somehow reinitialized internally so my preceding setting of `params` and `updates` to `[]` doesn't hold anymore.

Am I missing something, or is this a bug of some sort? It would be very valuable to be able to freeze updates for layers this way.

Thanks!
",psmaragdis,b'stale',2015-10-17T21:14:56Z,2017-06-22T22:11:00Z
835,Merge concat fails concatenating embeddings,"I just experienced a problem concatenating the output of two embedding layer

``` python
model = Graph()
model.add_input(name='input1', input_shape=(1,), dtype=int)
model.add_input(name='input2', input_shape=(1,), dtype=int)
model.add_node(Embedding(1000, 50, input_length=5), name='we', input='input1')
model.add_node(Embedding(500, 25, input_length=5), name='f1e', input='input2')
model.add_node(Flatten(), name='flat', inputs=['we', 'f1e'])
model.add_node(Dense(256, activation='tanh'), name='hid', input='flat')
model.add_node(Dense(len(labels), activation='softmax'), name='class', input='hid')
model.add_output('output', input='class')
```

printing the output shape of each node i obtain:

```
(None, 5,  50)
(None, 5, 25)
(None, 375)
(None, 256)
```

with input_shape for the flatten layer as 

```
(None, 5, 75)
```

so i was pretty sure all was ok.

But i obtained a dimension mismatch error due to the merging layer.
All was fixed by explicitly force the concat_axis=2 (the output_shapes as well as the input shapes results the same but it works at run time).

I was pretty sure that in the embedding case:

```
concat_axis=-1=2
```

Am i missing something or it should be considered as bug?
",dbonadiman,None,2015-10-14T15:29:03Z,2015-10-15T00:07:15Z
828,NaNs when training ReLU's on an input with all zeros,"Hello!

I'm running into an issue where training a simple model on examples that contain all zeroes returns NaN for the weights and the loss. Here is an example:

```
import numpy as np 

from keras.models import Sequential
from keras.layers.core import Activation
from keras.layers.convolutional import Convolution1D

np.random.seed(0)

X2 = np.zeros([1, 1, 1])
Y2 = np.ones([1, 1, 1])

model = Sequential()
model.add(            
    Convolution1D(                    
        1,
        1,
        input_dim=1,
        border_mode='valid'))   
model.add(Activation('relu'))

model.compile(optimizer='adagrad', loss='MSE')

hist = model.fit(
    X2,
    Y2,
    nb_epoch=2)
```

Running the above code gives:

```
Epoch 1/2
1/1 [==============================] - 0s - loss: 1.0000
Epoch 2/2
1/1 [==============================] - 0s - loss: nan
```

This happens even when the number of examples is larger (in the above code, it's 1) – just one example that's all zero is sufficient for the NaN to occur. Changing the zero to any other number, even 0.00001, removes the problem. The problem also goes away when you remove the ReLU layer.

I don't get this problem when running on the PyPI Theano build. The problem only occurs when I pull the latest Theano build from their Github repo. However, using the older Theano build isn't an option, because of the concat bug there.

Does anyone know what's going on? Thanks in advance!
",kohpangwei,b'stale',2015-10-14T02:13:14Z,2017-06-22T22:13:47Z
827,Fix evaluated and weighted_objective,"Hi all,

first: Keras is awesome :-) !
I am new here, and suggest the following PR to make Keras even better:

1) Fixes weight standardization in `evaluate()` of Graph model
Before, the unnormalized version of output vectors (y) was used to standardize weights, which resulted in a shape mismatch between y and the weight vector when standardize_y changed the shape of y. Now, y is first standardized and used afterwards to standardize weights as also done in other methods like `fit()`.

2) Fixes division by zero in `weighted_objective()`
Before, `weighted_objective()` returned nan due to division by zero if the weight vector contained only zero weights. Now, it returns zero if there are no observations. I found this bug when I trained a multi-task model with sparse output vectors. In some batches, there were no observations for some tasks, which resulted in nan in the objective.

Cheers,
Christof 
",cangermueller,None,2015-10-13T20:02:20Z,2015-12-02T04:56:20Z
821,'float' object has no attribute 'get_value' problem.,"When I was trying to print the configuration of a model by ""model.get_config()"" or trying to save my model as a 'json' file:

json_str = autoEncoder.to_json()
open('temp_model.json','w').write(json_str)
autoEncoder.save_weights('temp_model_weights.h5')

It raise the exception ""float object has no attribute 'get_value' "" in file 'optimizer.py', in class SGD(because I was using SGD as the optimizer), the definition of get_config() is:

 def get_config(self):
        return {""name"": self.**class**.**name**,
                ""lr"": float(self.lr.get_value()),
                ""momentum"": float(self.momentum.get_value()),
                ""decay"": float(self.decay.get_value()),
                ""nesterov"": self.nesterov}

while the **init** of class SGD does not contain decay and nesterov

```
def __init__(self, lr=0.01, momentum=0., decay=0., nesterov=False, *args, **kwargs):
    super(SGD, self).__init__(**kwargs)
    self.__dict__.update(locals())
    self.iterations = shared_scalar(0)
    self.lr = shared_scalar(lr)
    self.momentum = shared_scalar(momentum)
```

Is it a bug? Can I fix the problem by adding 'self.decay = shared_scalar(decay)' or something like this?

Thank you very much!
",MoyanZitto,None,2015-10-13T08:22:24Z,2015-10-13T18:41:16Z
819,Bug fixes:,"“TypeError: Cannot cast ufunc subtract output from dtype('float64') to
dtype('uint8') with casting rule 'same_kind'” in
keras/preprocessing/image.py, line 239, when using data augmentation.
",xingdi-eric-yuan,None,2015-10-12T07:12:42Z,2015-10-13T03:15:13Z
791,Add automatic shape inference.,"## Introducing a new API
### Simple NN:

``` python
model = Sequential()
model.add(Dense(64, input_dim=20))
model.add(Dropout(0.5))
model.add(Dense(64))

# alternatively
model = Sequential()
model.add(Dense(64, input_shape=(20,)))
model.add(Dropout(0.5))
model.add(Dense(64))

```
### Recurrent network:

``` python
model = Sequential()
model.add(Embedding(max_features, 256))
model.add(LSTM(128))

# with LSTM as first layer
model = Sequential()
model.add(LSTM(128, input_dim=32))

# with LSTM as first layer, alternative
model = Sequential()
model.add(LSTM(128, input_shape=(None, 32)))

# adding sequence length information
model = Sequential()
model.add(LSTM(128, input_dim=32, input_length=10, return_sequences=True))
model.add(Flatten())
model.add(Dense(16)) # now this works automatically

# or alternatively
model = Sequential()
model.add(LSTM(128, input_shape=(10, 32), return_sequences=True))

# also possible with Embedding, TimeDistributedDense, Convolution1D
model = Sequential()
model.add(Embedding(max_features, 256, input_length=10))
model.add(LSTM(128, return_sequences=True))
```
### Convnet:

``` python
model = Sequential()
# input: 100x100 images with 3 channels -> (3, 100, 100) tensors.
# this applies 32 convolution filters of size 3x3 each.
model.add(Convolution2D(32, 3, 3, border_mode='full', input_shape=(3, 100, 100))) 
model.add(Activation('relu'))
model.add(Convolution2D(32, 3, 3))
model.add(Activation('relu'))
model.add(MaxPooling2D(poolsize=(2, 2)))
model.add(Dropout(0.25))

model.add(Convolution2D(64, 3, 3, border_mode='valid')) 
model.add(Activation('relu'))
model.add(Convolution2D(64, 3, 3)) 
model.add(Activation('relu'))
model.add(MaxPooling2D(poolsize=(2, 2)))
model.add(Dropout(0.25))

model.add(Flatten())
model.add(Dense(256))  # boom
model.add(Activation('relu'))
model.add(Dropout(0.5))

model.add(Dense(10))
model.add(Activation('softmax'))
```
### Graph:

``` python
graph = Graph()
graph.add_input(name='input1', input_shape=(32,))
graph.add_input(name='input2', input_shape=(32,))
graph.add_node(Dense(16), name='dense1', input='input1')
graph.add_node(Dense(4), name='dense2', input='input2')
graph.add_node(Dense(4), name='dense3', input='dense1')
graph.add_output(name='output', inputs=['dense2', 'dense3'], merge_mode='sum')
graph.compile('rmsprop', {'output':'mse'})
```
- All examples are updated.
- All documentation is updated.
- All tests are updated.
## Moreover:
- faster convolutional layers (by providing `image_shape` and `filter_shape` to Theano).
- multiple bugs in the library and its tests fixed, additional correctness checks added
- small API consistency fixes.
",matsuyamax,None,2015-10-06T00:19:01Z,2015-10-30T01:59:09Z
779,Recurrent NN not saving and loading correctly,"First, I love keras and its great software! 

I think I found a bug in the saving and loading models from disk. I'm using a recurrent neural network and both the architecture and weights to disk and then would like to reload the same model. However when I reload the model, it does not make the same predictions. Here is a reproducible test case. 

``` python

from keras.models import Sequential, model_from_json
from keras.layers.core import Activation, Dense, RepeatVector
from keras.layers import recurrent

import unittest
import tempfile
import json
import numpy as np

class IntegrationTest(unittest.TestCase):
    def setUp(self):
        self.archfile = tempfile.NamedTemporaryFile(mode = 'w')
        self.weightfile = tempfile.NamedTemporaryFile(mode = 'r')

    def test_save_load(self):
        model = Sequential()
        model.add(recurrent.JZS1(3, 64))
        model.add(RepeatVector(1))
        for _ in range(2):
            model.add(recurrent.JZS1(64, 64, return_sequences = True))
        model.add(Dense(64, 3))
        model.add(Activation('softmax'))
        model.compile(loss='categorical_crossentropy', optimizer = 'adam')
        np_inp = np.array([[[False, False, True],
                            [False, False, True],
                            [True, False, False]]])
        test_output_before_save = model.predict(np_inp, verbose = 0).copy()
        self.archfile.write(model.to_json())
        self.archfile.flush()
        model.save_weights(self.weightfile.name, overwrite = True)

        archfile_reopen = open(self.archfile.name, 'r')
        new_model = model_from_json(archfile_reopen.read())
        archfile_reopen.close()
        new_model.load_weights(self.weightfile.name)
        test_output_after_save = new_model.predict(np_inp, verbose = 0).copy()
        np.testing.assert_array_equal(
            test_output_before_save, test_output_after_save)
```
",wrmelicher,None,2015-10-04T14:56:22Z,2015-10-04T18:08:01Z
771,Bugfix/reshape,"There's an issue with loading a model from a YAML/JSON file when the network contains a layer which only has *args such as `Reshape`. 

``` py
TypeError: __init__() got an unexpected keyword argument 'dims'
```

This error is due to how the models are loaded in https://github.com/fchollet/keras/blob/master/keras/utils/generic_utils.py#L8.

Layers like `Reshape` that have no keyword arguments simply won't work. This could be fixed by having a `**kwargs` that could catch the provided argument in addition to list arguments (default to list args if `dims` is not empty). However, I'm not sure if there are some unforeseen backwards compatibility issues that I'm not seeing here.

Let me know if you see any issues that I'm missing.
",stephenbalaban,None,2015-10-03T00:04:28Z,2015-10-03T17:10:03Z
762,Implementation of cifar10 example using Graph model,"I tried to implement cifar example usign Graph model.
https://github.com/fchollet/keras/blob/1a572b10e8ffb6407c54ec64a70e0ddf8493eea3/examples/cifar10_cnn.py

```
'''#####################################################################
 Defining varibales
#####################################################################'''

batch_size = 32
nb_classes = 10
nb_epoch = 2
data_augmentation = True

# shape of the image (SHAPE x SHAPE)
shapex, shapey = 32, 32
# number of convolutional filters to use at each layer
nb_filters = [32, 64]
# level of pooling to perform at each layer (POOL x POOL)
nb_pool = [2, 2]
# level of convolution to perform at each layer (CONV x CONV)
nb_conv = [3, 3]
# the CIFAR10 images are RGB
image_dimensions = 3


'''#####################################################################
 Loading the data and labels
#####################################################################'''
dirname = ""cifar-10-batches-py""
origin = ""http://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz""
path = get_file(dirname, origin=origin, untar=True)

nb_test_samples = 10000
nb_train_samples = 50000

X_train = np.zeros((nb_train_samples, 3, 32, 32), dtype=""uint8"")
y_train = np.zeros((nb_train_samples,), dtype=""uint8"")

for i in range(1, 6):
    fpath = os.path.join(path, 'data_batch_' + str(i))
    data, labels = load_batch(fpath)
    X_train[(i-1)*10000:i*10000, :, :, :] = data
    y_train[(i-1)*10000:i*10000] = labels

fpath = os.path.join(path, 'test_batch')
X_test, y_test = load_batch(fpath)

y_train = np.reshape(y_train, (len(y_train), 1))
y_test = np.reshape(y_test, (len(y_test), 1))

# convert class vectors to binary class matrices
Y_train = np_utils.to_categorical(y_train, nb_classes)
Y_test = np_utils.to_categorical(y_test, nb_classes)

'''#####################################################################
 Graph model
#####################################################################'''
model =  Graph()
# Load the input
model.add_input(name='input1', ndim=4)
# Convolution Neural Network architecture (5 convolution layers, 3 pooling layers)

model.add_node(Convolution2D(nb_filters[0], image_dimensions, nb_conv[0], nb_conv[0], activation='relu', border_mode='full'), name='conv2', input='input1')
model.add_node(Convolution2D(nb_filters[0], nb_filters[0], nb_conv[0], nb_conv[0], activation='relu', border_mode='full'), name='conv3', input='conv2')
model.add_node(MaxPooling2D(poolsize=(nb_pool[0], nb_pool[0])), name='pool1', input='conv3')

model.add_node(Convolution2D(nb_filters[1], nb_filters[0], nb_conv[0], nb_conv[0], activation='relu', border_mode='full'), name='conv4', input='pool1')
model.add_node(Convolution2D(nb_filters[1], nb_filters[1], nb_conv[1], nb_conv[1], activation='relu', border_mode='full'), name='conv5', input='conv4')
model.add_node(MaxPooling2D(poolsize=(nb_pool[1], nb_pool[1])), name='pool2', input='conv5')

model.add_node(Flatten(), name='flatten', input='pool2')

model.add_node(Dense(nb_filters[-1] * (shapex / nb_pool[0] / nb_pool[1]) * (shapey / nb_pool[0] / nb_pool[1]), 512, activation='relu', init='uniform'),  name='dense1', input='flatten')
model.add_node(Dense(512, nb_classes, activation='softmax', init='uniform'), name='dense2', input='dense1')

model.add_output(name='output1', input='dense2', merge_mode='sum')
model.compile('sgd', {'output1':'categorical_crossentropy'})
model.get_config(verbose=1)

model.fit({'input1':X_train, 'output1':Y_train},batch_size=batch_size, nb_epoch=nb_epoch)

#model.predict({'input1':X_test})

```

I got the below error :

```
Epoch 1/200
Traceback (most recent call last):
  File ""cifar10-graph.py"", line 135, in <module>
    model.fit({'input1':X_train, 'output1':Y_train},batch_size=batch_size, nb_epoch=nb_epoch)
  File ""build/bdist.linux-x86_64/egg/keras/models.py"", line 677, in fit
    shuffle=shuffle, metrics=metrics)
  File ""build/bdist.linux-x86_64/egg/keras/models.py"", line 210, in _fit
    outs = f(*ins_batch)
  File ""/usr/local/lib/python2.7/dist-packages/theano/compile/function_module.py"", line 606, in __call__
    storage_map=self.fn.storage_map)
  File ""/usr/local/lib/python2.7/dist-packages/theano/compile/function_module.py"", line 595, in __call__
    outputs = self.fn()
ValueError: Shape mismatch: x has 7744 cols (and 32 rows) but y has 4096 rows (and 512 cols)
Apply node that caused the error: Dot22(Reshape{2}.0, dense1_W)
Inputs types: [TensorType(float64, matrix), TensorType(float64, matrix)]
Inputs shapes: [(32, 7744), (4096, 512)]
Inputs strides: [(61952, 8), (4096, 8)]
Inputs values: ['not shown', 'not shown']

HINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.
HINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.
```

Any suggestion to debug the error???? 
",nitish11,None,2015-10-01T17:58:24Z,2016-05-06T06:43:40Z
754,Keras: near-future directions,"Here are a few things I think would be valuable to add to Keras in the near future.

These are mere suggestions. You are welcome to discuss them, contest them, add your own ideas... I would like the development of Keras to be increasingly driven by the community. I don't want to be a bottleneck of development.

I won't be writing code myself, but I will happily give feedback and advice to any contributor who wants to tackle some of these features. I will also keep reviewing and merging PRs. 

Here's a list of features. Their focus is on simplicity and user experience.
- Automatic tensor shape inference. We should be able to add layers to a Sequential mode or a Graph model without having to worry about input shapes.
- Introduction of `Input` layers as part of the above, to define expected input data dimensions.
- Ability to re-initialize layer weights without re-compiling a model.
- New API for the Graph container. [Some thoughts here](https://github.com/fchollet/keras/issues/620#issuecomment-144483091). As part of this change I believe we should get rid of the `add_input` and `add_output` methods, which are cumbersome. A single `add` method should suffice.
- Thorough checking of assumptions made about user-provided constructor arguments throughout the codebase, and raising helpful and clear error messages when some assumptions aren't respected. Ideally no error will ever be raised by Theano, because we will be catching everything on the Keras side. This will make debugging of Keras models much faster and easier.
- Abstracting all references to Theano functionality to a Keras backend. This will allow us to implement non-Theano backends in the near future (for instance, based on Nervana's [Neon](https://github.com/NervanaSystems/neon) library), that could be readily plugged into Keras in a seamless way. This will allow Keras to keep up with new advances in symbolic tensor libraries (Neon, CGT, etc...)
",fchollet,b'stale',2015-09-30T17:50:31Z,2017-06-22T22:11:06Z
739,Fix bug in deserialization of convolutional layers,"Fix issue #722
",matsuyamax,None,2015-09-28T04:50:34Z,2015-09-28T15:22:14Z
738,Fix bug with Graph sample_weights,"Should fix issue #624 
",matsuyamax,None,2015-09-28T03:54:56Z,2015-09-28T04:39:16Z
711,"ValueError: GpuElemwise. Input dimension mis-match. Input 1 (indices start at 0) has shape[1] == 1, but the output's size on that axis is 10.","I just install keras and try an example:
from keras.models import Sequential
from keras.layers.core import Dense, Dropout, Activation, Flatten
from keras.layers.convolutional import Convolution2D, MaxPooling2D
from keras.optimizers import SGD
from keras.datasets import cifar100
# from read_data import get_CIFAR10_data_original

(X_train, y_train), (X_test, y_test) = cifar100.load_data(label_mode='fine')
# datasets = get_CIFAR10_data_original() # 3_32_32
# train_set_x, train_set_y = datasets[0]
# valid_set_x, valid_set_y = datasets[1]
# test_set_x, test_set_y = datasets[2]

model = Sequential()
model.add(Convolution2D(32, 3, 3, 3, border_mode='full')) 
model.add(Activation('relu'))
model.add(Convolution2D(32, 32, 3, 3))
model.add(Activation('relu'))
model.add(MaxPooling2D(poolsize=(2, 2)))
model.add(Dropout(0.25))

model.add(Convolution2D(64, 32, 3, 3, border_mode='full')) 
model.add(Activation('relu'))
model.add(Convolution2D(64, 64, 3, 3)) 
model.add(Activation('relu'))
model.add(MaxPooling2D(poolsize=(2, 2)))
model.add(Dropout(0.25))

model.add(Flatten())
model.add(Dense(64_8_8, 256))
model.add(Activation('relu'))
model.add(Dropout(0.5))

model.add(Dense(256, 10))
model.add(Activation('softmax'))

sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)
model.compile(loss='categorical_crossentropy', optimizer=sgd)

model.fit(X_train, y_train, batch_size=64, nb_epoch=5, verbose=2, show_accuracy=True)

I got the error like this:
Epoch 0
Traceback (most recent call last):
  File ""/home/mvg/workspace/CIFAR_10/test_keras/test_keras.py"", line 43, in <module>
    model.fit(X_train, y_train, batch_size=64, nb_epoch=5, verbose=2, show_accuracy=True)
  File ""/usr/local/lib/python2.7/dist-packages/keras/models.py"", line 490, in fit
    shuffle=shuffle, metrics=metrics)
  File ""/usr/local/lib/python2.7/dist-packages/keras/models.py"", line 211, in _fit
    outs = f(*ins_batch)
  File ""/usr/local/lib/python2.7/dist-packages/theano/compile/function_module.py"", line 618, in __call__
    storage_map=self.fn.storage_map)
  File ""/usr/local/lib/python2.7/dist-packages/theano/gof/link.py"", line 297, in raise_with_op
    reraise(exc_type, exc_value, exc_trace)
  File ""/usr/local/lib/python2.7/dist-packages/theano/compile/function_module.py"", line 607, in **call**
    outputs = self.fn()
ValueError: GpuElemwise. Input dimension mis-match. Input 1 (indices start at 0) has shape[1] == 1, but the output's size on that axis is 10.
Apply node that caused the error: GpuElemwise{Composite{(i0 \* ((i1 / i2) + i3))}}[(0, 0)](GpuElemwise{Composite{Cast{float32}%28AND%28GE%28i0, i1%29, LE%28i0, i2%29%29%29},no_inplace}.0, GpuElemwise{Mul}[%280, 1%29].0, GpuElemwise{Clip}[%280, 0%29].0, GpuElemwise{Composite{%28%28-i0%29 / i1%29}}[%280, 0%29].0)
Toposort index: 162
Inputs types: [CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, col)]
Inputs shapes: [(64, 10), (64, 1), (64, 10), (64, 1)]
Inputs strides: [(10, 1), (1, 0), (10, 1), (1, 0)]
Inputs values: ['not shown', 'not shown', 'not shown', 'not shown']
Outputs clients: [[GpuAdvancedIncSubtensor1_dev20{inplace,inc}(GpuAlloc{memset_0=True}.0, GpuElemwise{Composite{(i0 \* ((i1 / i2) + i3))}}[(0, 0)].0, Elemwise{Cast{int64}}.0)]]

HINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.
HINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.
",lfwin,None,2015-09-23T08:03:17Z,2017-12-08T19:17:42Z
710,Possible bug with tensor outputs,"I wrote the following cost function:

``` python
def cost_function(y_true, y_pred):
    leng = (y_true.shape[1]-1) / 2
    ytrue = y_true[:, -leng:, :]
    ypred = y_pred[:, -leng:, :]
    return binary_crossentropy(ytrue, ypred)
```

But Keras said

```
ValueError: The index list is longer (size 3) than the number of dimensions
of the tensor(namely 2). You are asking for a dimension of the tensor that
does not exist! You might need to use dimshuffle to add extra dimension to your tensor.
```

But I am pretty sure my model outputs a `T.tensor3`. The compiled output does have 3 dimensions. Where did the third dimension go? I tried to read the `compile` method but I had no clue. Have you experienced that before @fchollet ??? Am I missing something here?
",EderSantana,b'stale',2015-09-23T00:55:10Z,2017-06-22T22:10:44Z
708,Batch normalization bug,"I think there is a bug in how batch normalization is implemented.

Let me focus on the `mode=0` case.

The `gamma` and `beta` parameters are feature-specific (the same across batches or other dimensions like time).  They are initiated with shared parameters with the same shape as inputs.

```
self.gamma = self.init((self.input_shape))
```

Note that with mini batches, this is too many parameters (you need as many `gamma` parameters as features, not features x mini batches x other dimensions).  And then they are directly applied to the normed inputs

```
out = self.gamma * X_normed + self.beta
```

In theory, if you are randomizing the order of mini batches at each iteration, you might learn the same set of parameters across the redundant dimensions but this is probably something you don't want to leave to chance.  Lasagne does a nice trick at the final application of the `gamma` and `beta` to the `normed_inputs` by using Theano's `add_broadcast()`.  See https://gist.github.com/f0k/f1a6bd3c8585c400c190#file-batch_norm-py-L92 
",allentran,None,2015-09-21T21:45:00Z,2015-11-23T21:58:54Z
693,Output masking exception when outputting sequences,"I get the error:

```
ERROR: test_graph_seq (test_loss_weighting.TestLossWeighting)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""/home/blake/src/keras/tests/auto/test_loss_weighting.py"", line 162, in test_graph_seq
    model.fit(data, nb_epoch=1, batch_size=2, verbose=1, sample_weight=masks)
  File ""/home/blake/src/keras/env/lib/python3.4/site-packages/keras/models.py"", line 678, in fit
    shuffle=shuffle, metrics=metrics)
  File ""/home/blake/src/keras/env/lib/python3.4/site-packages/keras/models.py"", line 211, in _fit
    outs = f(*ins_batch)
  File ""/home/blake/src/keras/env/lib/python3.4/site-packages/theano/compile/function_module.py"", line 513, in __call__
    allow_downcast=s.allow_downcast)
  File ""/home/blake/src/keras/env/lib/python3.4/site-packages/theano/tensor/type.py"", line 169, in filter
    data.shape))
TypeError: ('Bad input argument to theano function with name ""/home/blake/src/keras/env/lib/python3.4/site-packages/keras/models.py:616""  at index 2(0-based)', 'Wrong number of dimensions: expected 3, got 2 with shape (2, 4).')
```

when attempting to use output masking when outputting sequences. Either I'm doing something wrong, or there's a bug. I have created unit tests that exposes this issue in https://github.com/brainwater/keras/tree/outmasktest 
n.b. This happens in both python 2 and python 3

It can be run with:
`$ python -m unittest test_loss_weighting.TestLossWeighting.test_graph_seq`
or
`$ python -m unittest test_loss_weighting.TestLossWeighting.test_sequential_seq`
",brainwater,b'stale',2015-09-16T16:54:58Z,2017-06-23T01:09:54Z
668,Texts classification using convolution2D gets an error!,"Opinions/Views would be highly appreciated!

``` python
model = Sequential()
model.add(Embedding(max_features, embedding_dims)) # embed into dense 3D float tensor (samples, maxlen, 256)
model.add(Reshape(1, maxlen, embedding_dims)) # reshape into 4D tensor (samples, 1, maxlen, 256)
model.add(Convolution2D(nb_filters, 1, filter_length, filter_length, border_mode='full')) 
model.add(Activation('relu'))
model.add(MaxPooling2D(poolsize=(2,2)))
model.add(Dropout(0.25))
model.add(Flatten())
output_size = nb_filters * (((maxlen - filter_length) / 1) + 1) / 2*(((embedding_dims - filter_length) / 1) + 1) / 2
 # We add a vanilla hidden layer:
model.add(Dense(output_size, hidden_dims))
model.add(Dropout(0.25))
model.add(Activation('relu'))

 # We project onto a single unit output layer, and squash it with a sigmoid:
model.add(Dense(hidden_dims, nb_classes))
model.add(Activation('softmax'))


Traceback (most recent call last):
  File ""D:\workspace\search\src\test\cnn2D.py"", line 284, in <module>
    loss,accuracy = model.train_on_batch(X_train[i*batch_size:(i+1)*batch_size], Y_train[i*batch_size:(i+1)*batch_size],accuracy=True)
  File ""D:\Python27\lib\site-packages\keras\models.py"", line 429, in train_on_batch
    return self._train_with_acc(*ins)
  File ""D:\Python27\lib\site-packages\theano\compile\function_module.py"", line 606, in __call__
    storage_map=self.fn.storage_map)
  File ""D:\Python27\lib\site-packages\theano\compile\function_module.py"", line 595, in __call__
    outputs = self.fn()
ValueError: dimension mismatch in args to gemm (32,83232)x(76832,250)->(32,250)
Apply node that caused the error: GpuDot22(GpuReshape{2}.0, <CudaNdarrayType(float32, matrix)>)
Inputs types: [CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix)]
Inputs shapes: [(32, 83232), (76832, 250)]
Inputs strides: [(83232, 1), (250, 1)]
Inputs values: ['not shown', 'not shown']

HINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.
HINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.

```
",Imorton-zd,None,2015-09-10T07:28:00Z,2016-01-21T02:47:29Z
664,Likely bug in Theano breaks Keras,"It seems like there was a bug recently introduced in Theano that breaks parts of Keras in subtle ways, i.e. things run but don't work very well. The last good commit was:
https://github.com/Theano/Theano/commit/2595fea0688a6e08db00c9d0a349b51d820f9ab1
The code below works if you pull from this commit, but loss doesn't really decrease with bleeding edge Theano. If someone can confirm I'll report it to the Theano devs. I've only tried on GPU, so it may only apply there

``` Python
from __future__ import print_function
import numpy as np
np.random.seed(1337)

from keras.utils.test_utils import get_test_data
from keras.models import Sequential
from keras.layers.core import TimeDistributedDense
import unittest

(X_train, y_train), (X_test, y_test) = get_test_data(nb_train=1000, nb_test=200, input_shape=(5, 10), output_shape=(5, 10),
                                                 classification=False)

model = Sequential()
model.add(TimeDistributedDense(X_train.shape[-1], y_train.shape[-1]))
model.compile(loss='hinge', optimizer='rmsprop')
history = model.fit(X_train, y_train, nb_epoch=12, batch_size=16, validation_data=(X_test, y_test), verbose=2)
```
",the-moliver,None,2015-09-09T02:55:20Z,2015-09-10T22:52:01Z
657,Possible bugs in sample_weight in model.fit() for RNN,"Hi there,

From Keras's documentation it says that:

> For time-distributed data, there is one weight per sample per timestep, i.e. if your output data is shaped (nb_samples, timesteps, output_dim), your mask should be of shape (nb_samples, timesteps). This allows you to mask out or reweight individual output timesteps, which is useful in sequence to sequence learning.

However, I happened to find that the sample_weight should have shape **(nb_samples, timesteps, 1)**, otherwise there will be some shape mismatch errors. 

If we do prefer **(nb_samples, timesteps)**, then there is a bug in:

https://github.com/fchollet/keras/blob/master/keras/models.py#L83-L85

Because we need to expand the shape of sample_weight
",blackyang,None,2015-09-07T20:21:15Z,2015-09-29T15:37:25Z
655,Bias between Save_weights and Load_weights,"Hi All,

I want to save the model which shows the best result on validation set during model.fit() process. I create a callback that uses model.save_weights to save the best model to a hdf5 file. However, after the whole training is finished, by re-constructing the best model via model.load_weights, I cannot repeat that best result on the validation set anymore. The reconstructed model does not produce the same performance that it shows in the fitting process. The bias exists in model.set_weights and model.get_weights as well.

My current solution is to use the copy.deepcopy function to copy the whole ""model"" when a model with better performance is found. But it largely deteriorates the speed. I was wondering is this a bug or I miss some basic things of the ""model"" during re-construction?

Thanks you very much.
Yang
",yyaodong,None,2015-09-07T15:29:12Z,2015-09-07T19:50:52Z
652,Possible bug in Conv + BN,"After adding BN after Conv layer:
model.add(Convolution2D(nb_filters, nb_filters, nb_conv, nb_conv))
model.add(BatchNormalization((nb_filters,)))

I have got the following Theano error:

TypeError: ('An update must have the same type as the original shared variable (shared_var=<CudaNdarrayType(float32, vector)>, shared_var.type=CudaNdarrayType(float32, vector), update_val=Elemwise{add,no_inplace}.0, update_val.type=TensorType(float32, 3D)).', 'If the difference is related to the broadcast pattern, you can call the tensor.unbroadcast(var, axis_to_unbroadcast[, ...]) function to remove broadcastable dimensions.')
",loyeamen,None,2015-09-06T16:26:12Z,2015-09-06T17:31:45Z
628,H5Py dataset for input tensor?,"This isn't a bug, but seems a little technical for the user group.

I have an h5py dataset with shape (300,000, 60, 50). My 8GB ram laptop will not consider this an acceptable transaction.

However, loading the h5py dataset straight into the model (i.e. without creating a numpy array from it) throws an error.

Am I doing something wrong, or is the h5py format not supported as an input tensor in either Theano or Keras?
",cjmcmurtrie,b'stale',2015-09-02T19:12:31Z,2019-05-28T02:11:46Z
625,Automatic Tensor Size Calculation,"I saw the mention on issue number 60 about automatic tensor size calculation, where it's suggested that it would necessitate a change in the API. I've been thinking about this recently.

I've been having a go at a solution which doesn't change the API. Basically the user supplies the sequential container itself in place of the parameter in the layer's constructor.
So you can write this:
model = Sequential()
model.add(Dense(20, 64, init='uniform'))
model.add(Activation('tanh'))
model.add(Dropout(0.5))
model.add(Dense(model, 64, init='uniform'))
model.add(Activation('tanh'))
model.add(Dropout(0.5))
model.add(Dense(model, 2, init='uniform'))
model.add(Activation('softmax'))

My implementation is in https://github.com/bottler/keras/ .

In addition, the user can add a layer to specify the size, so the above example could begin
model = Sequential()
model.add(SpecifyShape([20]))
model.add(Dense(model, 64, init='uniform'))

The overhead when creating a layer is that a layer should either define get_output_dims(self) or calc_output_dims(self,lastdims). I have added these to some built-in layers. 

It currently assumes that ""prev="" has not been used - it assumes all layers are sequential.

I would like some feedback on whether this is a good idea, and how it might be improved. I have not yet added any tests, it's probably buggy.
",bottler,b'stale',2015-09-01T20:03:09Z,2017-06-22T22:10:42Z
620,[WIP] Recursive container,"### What?

Over the weekend I worked on a solution to design arbitrary RNNs using Keras API. The result allow us write a vanilla RNN as:

``` python
self.input_dim = 2
self.state_dim = 2

self.model = Recursive(return_sequences=True)

self.model.add_input('input', ndim=3)  # Input is 3D tensor
self.model.add_state('h', dim=self.state_dim)
self.model.add_node(Dense(self.input_dim, self.state_dim, init='one'), 
                    name='i2h', inputs=['input', ])
self.model.add_node(Dense(self.state_dim, self.state_dim, init='orthogonal'),
                    name='h2h', inputs=['h', ])
self.model.add_node(Activation('tanh'). name='rec', inputs=['i2h', 'h2h'], 
                    merge_mode='sum', return_state='h', create_output=True)
```

Note that the class definition of SimpleRNN is much bigger than this and we don't have the choice of outputting intermediate values, like ex. the input-to-hidden projection. This should be interesting to design different state based models without having to dig into Theano code. I started the development on the repo I usually put [my Keras extensions](https://github.com/EderSantana/seya/blob/master/seya/layers/containers.py). There is a test [here](https://github.com/EderSantana/seya/blob/master/tests/test_containers.py) showing how to use this new container (there will be lots of printing I used for debugging. That should be cleaned up soon). If there is a general interest on this, I could just PR a new branch here.
### How? (dev details)

The Recursive container is basically a Graph container with a few mods. The most important difference is the way we connect layers. Contrary to regular feedforward networks, we cannot use `set_previous` inside the `add_node` method. Everything has to be done inside a `_step` function and we have to take care of the order which we pass arguments to scan (I didn't explore the idea of using dictionaries as inputs to scan yet). In other words, the entire connection logic is moved from `add_node` (like it is done for Sequential and Graph) to `_step`.
### Next Steps?

There is a lot of code clean up and refactoring that could possibly make the internals cleaner. For example, in a conversation with @fchollet, he also suggested me that we should define the states as `self.model.add_state('h', dim=self.state_dim, input='rec')` instead of using a `return_state` option inside the `add_node`.
##### Stateful?

Another interesting problem is how to handle stateful models, where the hidden states are not wiped out after each batch. In a previous experiment I did, I set up the initial states of an RNN to be a shared variable and defined its update to be the last state returned by scan. I did that inside the `get_output` method. Now that Keras gets all the individual layers `self.updates`, everything else was handled by the Model class. We could also do this here. The problem is that shared variables can't change sizes and we have to make sure we always have batches of the same size, otherwise, we would have to recompile the model. I would love to hear about alternatives for this.
### Final words

Sorry for the long post, but hopefully it will get people interested in developing this API (and/or inspiring new ones) that I believe will make our lives much easier when it comes to design new RNNs.
",EderSantana,b'stale',2015-09-01T02:09:02Z,2017-06-22T20:12:14Z
614,view intermediate values,"If there any way to check the intermediate values after each layer?

I write my a predictor program with my own convolution, maxpooling and so on, and import the weights trained from keras into my program. But the results predicted result is different from keras. 

It must help a lot to debug my program if I can see intermediate values in keras.

Thanks
",Howard--C,None,2015-08-28T23:22:49Z,2015-08-28T23:28:42Z
590,nan loss with poisson objective function,"Hello all,

I'm trying to fit a model using the poisson loss function and I get `nan` from the first epoch.
I'm merging 2 models with time dependant sequences/covariates and put a dense layer on the top.

``` python
left = Sequential()
left.add(Embedding(len(X_1), 256))
left.add(LSTM(256, 256))
left.add(Dropout(0.3))
left.add(Dense(256, 128))

right = Sequential()
right.add(LSTM(X_1.shape[2], 512, return_sequences=True))
right.add(Dropout(0.3))
right.add(LSTM(512, 256, return_sequences=False))
right.add(Dropout(0.1))
right.add(Dense(256,128))

model = Sequential()
model.add(Merge([left, right], mode='sum'))

model.add(Dense(128, 1))

model.compile(loss='poisson', optimizer='adam')
components = model.fit([X_1, X_2], y, batch_size=256,
                       nb_epoch=20, validation_split=0.1)
```

I've tried to convert my target variable to a 0-1 variable in order to use the binary crossentropy loss and it's working as expected.
I'm not sure of the behavior of the loss function if `y_pred` is 0. The log would be minus infinity and this could be the bug?

I'm not sure how to debug it so if you have some recommandations let me now :).

Thank you!
",tboquet,None,2015-08-24T17:47:47Z,2020-03-26T19:39:14Z
582,"NotImplementedError: ERROR: We disable ConvOp.grad now when dx or dy are different from 1 and 2, as there is a bug i n it.   ","Has anybody every had this error before?

```
Traceback (most recent call last):
  File ""OneColumn.py"", line 67, in <module>
    ze_model = ze_model.fit(train_x,train_y)
  File ""/home/vincent/workspace/machine_learning/keras/keras/wrappers/scikit_learn.py"", line 126, in fit
    self.compiled_model_.compile(optimizer=self.optimizer, loss=self.loss)
  File ""/home/vincent/workspace/machine_learning/keras/keras/models.py"", line 391, in compile
    updates = self.optimizer.get_updates(self.params, self.constraints, train_loss)
  File ""/home/vincent/workspace/machine_learning/keras/keras/optimizers.py"", line 119, in get_updates
    grads = self.get_gradients(loss, params)
  File ""/home/vincent/workspace/machine_learning/keras/keras/optimizers.py"", line 38, in get_gradients
    grads = T.grad(loss, params)
  File ""/home/vincent/workspace/machine_learning/Theano/theano/gradient.py"", line 547, in grad
    grad_dict, wrt, cost_name)
  File ""/home/vincent/workspace/machine_learning/Theano/theano/gradient.py"", line 1288, in _populate_grad_dict
    rval = [access_grad_cache(elem) for elem in wrt]
  File ""/home/vincent/workspace/machine_learning/Theano/theano/gradient.py"", line 1246, in access_grad_cache
    term = access_term_cache(node)[idx]
  File ""/home/vincent/workspace/machine_learning/Theano/theano/gradient.py"", line 953, in access_term_cache
    output_grads = [access_grad_cache(var) for var in node.outputs]
  File ""/home/vincent/workspace/machine_learning/Theano/theano/gradient.py"", line 1246, in access_grad_cache
    term = access_term_cache(node)[idx]
  File ""/home/vincent/workspace/machine_learning/Theano/theano/gradient.py"", line 1093, in access_term_cache
    input_grads = node.op.grad(inputs, new_output_grads)
  File ""/home/vincent/workspace/machine_learning/Theano/theano/tensor/nnet/conv.py"", line 850, in grad
    ""ERROR: We disable ConvOp.grad now when dx or ""
NotImplementedError: ERROR: We disable ConvOp.grad now when dx or dy are different from 1 and 2, as there is a bug i
n it. 
```
",valexandersaulys,b'stale',2015-08-22T14:38:41Z,2017-06-22T22:10:29Z
545,Sparse sample_weight causes crashes,"When sample_weight is a sparse vector, the following simple example code crashes (I'm running on Anaconda python, with a GeForce GTX 980, on Ubuntu 12.04):

```
import numpy as np
from keras.models import Sequential
from keras.layers.core import Dense, Dropout, Activation
from keras.optimizers import SGD

# Generate data
X = np.zeros((100, 100))
y = np.zeros((100, 2))
## The training always fails with
#W = np.zeros((100,))
## The training fails roughly half the time with
W = np.random.binomial(1, .05, size=(100,))
## The training always succeeds with
# W = np.ones((100,))

model = Sequential()
model.add(Dense(100, 50, init='uniform', activation=""relu""))
model.add(Dense(50, 2, init='uniform', activation=""softmax""))
sgd = SGD(lr=.01, decay=1e-6, momentum=0.9, nesterov=True)
model.compile(optimizer=sgd, loss=""binary_crossentropy"")
model.fit(X, y, nb_epoch=20, batch_size=50,
          sample_weight=W)
```

The code crashes halfway through training with output:

```
rbharath@not0rious:~/torch-models$ python simple_multitask_seq.py
Using gpu device 0: GeForce GTX 980
Epoch 0
100/100 [==============================] - 0s - loss: 0.6931
Epoch 1
Traceback (most recent call last):
  File ""simple_multitask_seq.py"", line 22, in <module>
    sample_weight=W)
  File ""build/bdist.linux-x86_64/egg/keras/models.py"", line 477, in fit
  File ""build/bdist.linux-x86_64/egg/keras/models.py"", line 215, in _fit
  File ""/home/rbharath/anaconda/lib/python2.7/site-packages/theano/compile/function_module.py"", line 606, in __call__
    storage_map=self.fn.storage_map)
  File ""/home/rbharath/anaconda/lib/python2.7/site-packages/theano/compile/function_module.py"", line 595, in __call__
    outputs = self.fn()
  File ""/home/rbharath/anaconda/lib/python2.7/site-packages/theano/gof/op.py"", line 768, in rval
    r = p(n, [x[0] for x in i], o)
  File ""/home/rbharath/anaconda/lib/python2.7/site-packages/theano/sandbox/cuda/basic_ops.py"", line 2384, in perform
    out[0] = x.reshape(tuple(shp))
ValueError: Reshape has invalid dimension 0 (must be >0)
Apply node that caused the error: GpuReshape{1}(GpuElemwise{TrueDiv}[(0, 0)].0, MakeVector.0)
Inputs types: [CudaNdarrayType(float32, vector), TensorType(int64, vector)]
Inputs shapes: [(0,), (1,)]
Inputs strides: [(1,), (8,)]
Inputs values: [<CudaNdarray object at 0x7f3909e31d70>, array([0])]

Debugprint of the apply node:
GpuReshape{1} [@A] <CudaNdarrayType(float32, vector)> ''
 |GpuElemwise{TrueDiv}[(0, 0)] [@B] <CudaNdarrayType(float32, vector)> ''
 | |GpuFlatten{1} [@C] <CudaNdarrayType(float32, vector)> ''
 | | |GpuFromHost [@D] <CudaNdarrayType(float32, vector)> ''
 | |   |AdvancedSubtensor [@E] <TensorType(float32, vector)> ''
 | |     |<TensorType(float32, matrix)> [@F] <TensorType(float32, matrix)>
 | |     |Subtensor{int64} [@G] <TensorType(int64, vector)> ''
 | |     | |Nonzero [@H] <TensorType(int64, matrix)> ''
 | |     | | |<TensorType(float32, matrix)> [@F] <TensorType(float32, matrix)>
 | |     | |Constant{0} [@I] <int64>
 | |     |Subtensor{int64} [@J] <TensorType(int64, vector)> ''
 | |       |Nonzero [@H] <TensorType(int64, matrix)> ''
 | |       |Constant{1} [@K] <int64>
 | |GpuDimShuffle{x} [@L] <CudaNdarrayType(float32, (True,))> ''
 |   |GpuFromHost [@M] <CudaNdarrayType(float32, scalar)> ''
 |     |Elemwise{Cast{float32}} [@N] <TensorType(float32, scalar)> ''
 |       |Shape_i{1} [@O] <TensorType(int64, scalar)> ''
 |         |Nonzero [@H] <TensorType(int64, matrix)> ''
 |MakeVector [@P] <TensorType(int64, vector)> ''
   |Shape_i{1} [@O] <TensorType(int64, scalar)> ''
```

The crashing behavior is nondeterministic and appears to depend on the sparsity of the `sample_weight`. If `sample_weight` is uniformly 0, then it always crashes, with a sparse `sample_weight`, it crashes about half the time, and if it is uniformly one, then the code never crashes. On CPU, the code doesn't crash, but the loss function goes to NaN instead. This behavior isn't limited to Sequential models. Here's a Graph model with the same behavior:

```
import numpy as np
from keras.models import Graph
from keras.layers.core import Dense, Dropout, Activation
from keras.optimizers import SGD

# Generate data
X = np.zeros((100, 100))
y = np.zeros((100, 2))
## The training always fails with
#W = np.zeros((100,))
## The training fails roughly half the time with
W = np.random.binomial(1, .05, size=(100,))
## The training always succeeds with
# W = np.ones((100,))

model = Graph()
model.add_input(name=""input"", ndim=100)
model.add_node(
    Dense(100, 50, init='uniform', activation=""relu""),
    name=""dense"", input=""input"")
model.add_node(
    Dense(50, 2, init='uniform', activation=""softmax""),
    name=""head"", input=""dense"")
model.add_output(name=""task"", input=""head"")
sgd = SGD(lr=.01, decay=1e-6, momentum=0.9, nesterov=True)
model.compile(optimizer=sgd, loss={""task"": ""binary_crossentropy""})
model.fit({""input"": X, ""task"": y}, nb_epoch=20, batch_size=50,
          sample_weight={""task"": W})
```

Any suggestions for debugging/fixing this issue would be greatly appreciated. I've been banging my head against it for a day or so.
",rbharath,None,2015-08-17T19:14:40Z,2017-03-01T00:40:27Z
537,bAbI example broken on GPU?,"While the bAbI example works fine when using the CPU, I get the following error when changing to a GPU run 

ValueError: dimension mismatch in args to gemm (32,100)x(200,22)->(32,22)
Apply node that caused the error: GpuDot22(GpuJoin.0, <CudaNdarrayType(float32, matrix)>)
Inputs types: [CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix)]
Inputs shapes: [(32, 100), (200, 22)]
Inputs strides: [(100, 1), (22, 1)]
Inputs values: ['not shown', 'not shown']

HINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.
HINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.

cmd line: THEANO_FLAGS=mode=FAST_RUN,device=gpu,floatX=float32 python babi_rnn.py 
",ssamot,None,2015-08-16T06:57:14Z,2015-08-16T19:35:02Z
508,Keras model not converging on IRIS dataset,"I have the following code for training a model on the IRIS dataset

``` python
import numpy as np

from keras.models import Sequential
from keras.layers.core import Dense, Dropout, Activation
from keras.optimizers import SGD

from sklearn.datasets import load_iris
from sklearn.cross_validation import train_test_split
from sklearn.preprocessing import OneHotEncoder

iris = load_iris()

X, y = iris.data, iris.target
enc = OneHotEncoder()
y= enc.fit_transform(y[:, np.newaxis]).toarray()

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)

print X.shape, y.shape # Outputs ((150L, 4L), (150L, 3L))


# Implement Model in Keras
model = Sequential()
model.add(Dense(X.shape[1], 10, init='uniform', activation='tanh'))
model.add(Dropout(0.5))
model.add(Dense(10, 10, init='uniform', activation='tanh'))
model.add(Dropout(0.5))
model.add(Dense(10, y.shape[1], init='uniform', activation='softmax'))

sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)
# Compile the model using theano
model.compile(loss='categorical_crossentropy', optimizer=sgd)

from sklearn import cross_validation
print model.to_yaml()
""""""
Outputs the following:
class_mode: categorical
layers:
- {W_constraint: null, W_regularizer: null, activation: tanh, activity_regularizer: null,
  b_constraint: null, b_regularizer: null, init: uniform, input_dim: !!python/long '4',
  name: Dense, output_dim: 10}
- {name: Dropout, p: 0.5}
- {W_constraint: null, W_regularizer: null, activation: tanh, activity_regularizer: null,
  b_constraint: null, b_regularizer: null, init: uniform, input_dim: 10, name: Dense,
  output_dim: 10}
- {name: Dropout, p: 0.5}
- {W_constraint: null, W_regularizer: null, activation: softmax, activity_regularizer: null,
  b_constraint: null, b_regularizer: null, init: uniform, input_dim: 10, name: Dense,
  output_dim: !!python/long '3'}
loss: categorical_crossentropy
name: Sequential
optimizer: {decay: 1.0e-06, lr: 0.1, momentum: 0.9, name: SGD, nesterov: true}
theano_mode: null
""""""

# Perform cross validated training
kf = cross_validation.KFold(X.shape[0], n_folds=10)
scores = []
for train_index, test_index in kf:
    model.fit(X[train_index], y[train_index], nb_epoch=20, batch_size=20, verbose=0)
    scores.append(model.evaluate(X[test_index], y[test_index], show_accuracy=1))
print scores
print np.mean(scores)

""""""
After many runs I get the following output:
15/15 [==============================] - 0s
15/15 [==============================] - 0s
15/15 [==============================] - 0s
15/15 [==============================] - 0s
15/15 [==============================] - 0s
15/15 [==============================] - 0s
15/15 [==============================] - 0s
15/15 [==============================] - 0s
15/15 [==============================] - 0s
15/15 [==============================] - 0s
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
0.0

This means that the model accuracy is 0.0
""""""
```

Since I am getting the model accuracy as 0 hence I decided to reset the weights of the model and train it again. Here is how I did it:

``` python
#print model.get_weights()
model.set_weights(np.array([np.random.rand(*k.shape) for k in model.get_weights()]))
kf = cross_validation.KFold(X.shape[0], n_folds=10)
scores = []
for train_index, test_index in kf:
    model.fit(X[train_index], y[train_index], nb_epoch=20, batch_size=20, verbose=0)
    scores.append(model.evaluate(X[test_index], y[test_index], show_accuracy=1))
print scores
print np.mean(scores)
""""""
This time I get the following outputs:
15/15 [==============================] - 0s
15/15 [==============================] - 0s
15/15 [==============================] - 0s
15/15 [==============================] - 0s
15/15 [==============================] - 0s
15/15 [==============================] - 0s
15/15 [==============================] - 0s
15/15 [==============================] - 0s
15/15 [==============================] - 0s
15/15 [==============================] - 0s
[[0.28251698613166809, 1.0], [0.1529315859079361, 1.0], [0.12931123375892639, 1.0], [0.6154976487159729, 0.33333333333333331], [0.86187130212783813, 0.0], [1.0279873609542847, 0.0], [0.70736020803451538, 0.33333333333333331], [0.74620842933654785, 0.0], [0.73251497745513916, 0.0], [0.86093902587890625, 0.0]]
[ 0.61171388  0.36666667]
""""""
```

Notice the accuracy is around 0.366 and this is after multiple runs. And it keeps going down continuously. 

However, I get very good results (not the best) using around 30k epochs when I try to train a logistic regression using the following code:

``` python
logit = Sequential()
logit.add(Dense(X.shape[1], y.shape[1], init='uniform', activation='softmax'))
logit_sgd = SGD()
logit.compile(loss='categorical_crossentropy', optimizer=logit_sgd)

kf = cross_validation.KFold(X.shape[0], n_folds=10)
for train_index, test_index in kf:
    logit.fit(X[train_index], y[train_index], nb_epoch=10000, batch_size=200, verbose=0)
    scores.append(logit.evaluate(X[test_index], y[test_index], show_accuracy=1)[1])
print scores
print np.mean(scores)
""""""
Output after running the above loop 2-3 times:
15/15 [==============================] - 0s
15/15 [==============================] - 0s
15/15 [==============================] - 0s
15/15 [==============================] - 0s
15/15 [==============================] - 0s
15/15 [==============================] - 0s
15/15 [==============================] - 0s
15/15 [==============================] - 0s
15/15 [==============================] - 0s
15/15 [==============================] - 0s
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.66666666666666663, 0.66666666666666663, 0.66666666666666663, 1.0, 1.0, 0.80000000000000004, 1.0, 1.0, 1.0, 1.0, 1.0, 0.80000000000000004, 0.80000000000000004, 1.0, 1.0, 0.73333333333333328, 1.0, 1.0, 1.0, 1.0, 1.0, 0.80000000000000004, 0.8666666666666667, 1.0, 1.0, 0.73333333333333328, 1.0, 1.0, 1.0, 1.0, 1.0, 0.80000000000000004, 0.8666666666666667, 1.0, 1.0, 0.73333333333333328, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8666666666666667, 0.8666666666666667, 1.0, 1.0, 0.80000000000000004, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8666666666666667, 0.8666666666666667, 1.0, 1.0, 0.80000000000000004, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8666666666666667, 0.8666666666666667, 1.0, 1.0, 0.80000000000000004, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8666666666666667, 0.8666666666666667, 1.0, 1.0, 0.8666666666666667, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8666666666666667, 0.93333333333333335, 1.0, 1.0, 0.80000000000000004, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8666666666666667, 0.93333333333333335, 1.0, 1.0, 0.80000000000000004, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8666666666666667, 0.93333333333333335, 1.0, 1.0, 0.80000000000000004, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8666666666666667, 0.93333333333333335, 1.0, 1.0, 0.80000000000000004, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8666666666666667, 0.93333333333333335, 1.0, 1.0, 0.80000000000000004, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8666666666666667, 0.93333333333333335, 1.0, 1.0, 0.80000000000000004, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8666666666666667, 0.93333333333333335, 1.0, 1.0, 0.8666666666666667, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8666666666666667, 0.93333333333333335, 1.0, 1.0, 0.8666666666666667, 1.0]
0.894509803922
""""""
```

The decision surfaces for the logistic regression and the neural net are:
![image](https://cloud.githubusercontent.com/assets/112678/9152422/64b66e82-3ded-11e5-8853-48d3a940d055.png)

I have also tried to reset the learning rates, momentum and decay of the SGD but the model always gets stuck in the accuracy around 58-64%

What can be the reason for this ?

I will try some more things. My working copy can be seen at the Ipython notebook: https://github.com/napsternxg/ipython-notebooks/blob/master/Keras%20Demo.ipynb

**UPDATE**: After doing some more debugging, I found that the neural network model is just learning to predict only 2 of the 3 classes. The pair of classes are usually (0, 1) and (0,2). 
",napsternxg,None,2015-08-08T21:52:37Z,2015-08-09T01:23:43Z
501,Fixes and full results for bAbi RNN example,"This PR contains two bugfixes (missing vocabulary item in QA19 + issues with running on Python 3) and additional documentation (results and comparison to the Facebook LSTM baseline when run over all 20 tasks).
",Smerity,None,2015-08-07T04:50:54Z,2015-08-17T11:34:55Z
488,Bug in BatchNormalization,"I found the implementation of the `BatchNormalization` is wrong. If the `mode` is 0, ""featurewise normalization"" is used and two attributes which named  `running_mean` and `running_std` are used to store the mean and STD of the training data. But both of these attributes are implemented as a Theano expression in the `get_output` function. In the test stage, they refer to mean and STD of the input data, not the mean and STD of the training data as we expected. 

To fix it, the `running_mean` and `running_std` should be implemented as a Theano shared value as model's parameters, and should be updated when training. And I noted that the updating mechanism of them is different from the conventional parameters which are updated by their gradient. Therefore, we need to define individual update methods in some especial `Layer`, and the `update` list should be integrated into the conventional one in the training function of the `Model`.
",alzhusan,None,2015-08-06T08:25:44Z,2015-08-09T06:28:43Z
465,Bidirectional RNNs Debug,"#453 , @iskandr submitted  a 'Bidirectional‘ RNN class. This submission resolves the bug in @iskandr 's code.
",ghost,None,2015-07-31T06:01:58Z,2015-08-21T00:53:24Z
464,Incorrect MSE reported on status bar when l2_lambda is not zero.,"Consider the following toy example dataset and network:

```
from __future__ import print_function
import numpy as np
from keras.models import Graph
from keras.layers.core import Dense
from keras.regularizers import l2

# generate random data
d = 6000
X1 = np.random.random((10000,d))**2
X2 = np.log(np.random.random((10000,d)))
Y = (np.dot(X1,np.random.random((d,1))) - np.dot(X2,np.random.random((d,1))))**2
Y /= Y.max() # scale to be between 0 and 1

data = {'X1':X1, 'X2':X2, 'output':Y}

# network parameters
d1 = 512
d2 = 256
l2_lambda = 1e-3

# graph model
model = Graph()

# inputs
model.add_input(name='X1', ndim=2)
model.add_input(name='X2', ndim=2)

# X1 dense layer
model.add_node(Dense(d, d1, activation='relu',W_regularizer=l2(l2_lambda)), 
               name='dense_X1', input='X1')

# X2 dense layer
model.add_node(Dense(d, d1, activation='relu',W_regularizer=l2(l2_lambda)), 
               name='dense_X2', input='X2')

# merging dense layer
model.add_node(Dense(2*d1 , d2, activation='relu',W_regularizer=l2(l2_lambda)), 
               name='dense_merge', merge_mode=""concat"", 
               inputs=['dense_X1','dense_X2'])

# output dense layer
model.add_node(Dense(d2 , 1, activation='sigmoid',W_regularizer=l2(l2_lambda)), 
               name='dense_final',input='dense_merge')      

model.add_output(name='output', input=""dense_final"")

model.compile('rmsprop', {""output"": 'mse'})
```

First, I check the MSE of the network BEFORE it is trained. 

```
predictions = model.predict(data)
print('MSE before any training:')
print(np.mean((predictions['output']-Y)**2))

MSE before any training:
0.444015524597
```

The MSE before training is 0.44. So, once we actually start training, we would expect the progress bar to report something in that vicinity.

However, during the actual training the `output` is nonsensically huge:

```
history = model.fit(data=data, nb_epoch=3, validation_split=0.25)
Train on 7500 samples, validate on 2500 samples
Epoch 0
7500/7500 [==============================] - 2s - output: 2.1041 - val_output: 0.0096
Epoch 1
7500/7500 [==============================] - 2s - output: 1.6632 - val_output: 0.0096
```

Note the `output: 2.1041` which is MUCH bigger than the val_output. How can the MSE be this large?

I have noticed that this bug is not active if we change `l2_lambda` to be 0:

```
MSE before any training:
0.0487085829439

Train on 7500 samples, validate on 2500 samples
Epoch 0
7500/7500 [==============================] - 2s - output: 0.0093 - val_output: 0.0083
Epoch 1
7500/7500 [==============================] - 2s - output: 0.0084 - val_output: 0.0083
```

Any idea what's going on here?
",sergeyf,None,2015-07-30T17:24:57Z,2016-07-07T21:51:21Z
463,A bug in the latest version of keras: bias is not updated,"Hi guys, I have some problems with the latest version of keras. This is a simple autoencoder code:

import numpy as np

from keras.models import Sequential
from keras.layers.core import Dense, Activation, AutoEncoder
from keras.optimizers import SGD
from keras.layers import containers

train_feature = np.zeros((1,4))
for i in range(1):
        train_feature[i,] = [0.5, 0.3, 0.2, 0.1]

model = Sequential()
encoder = containers.Sequential([Dense(4,2,activation='tanh')])
decoder = containers.Sequential([Dense(2,4,activation='tanh')])
autoencoder = AutoEncoder(encoder=encoder,decoder=decoder)
model.add(autoencoder)

sgd = SGD(lr = 1)
model.compile(loss='mse', optimizer=sgd)
weights_org = model.get_weights()
model.fit(train_feature, train_feature, nb_epoch=1, batch_size=1, shuffle=False)
weights_now = model.get_weights()
print ""Weights and bias before trainning is""
print weights_org
print ""Weights and bias after trainning is""
print weights_now

If I use the past version, the result is fine, which looks like:
Epoch 0
1/1 [==============================] - 0s - loss: 0.1271
Weights and bias before trainning is
[array([[-0.92038186,  0.05200247],
       [ 0.46043892, -0.82942702],
       [-0.57505271, -0.25431725],
       [ 0.03477517, -0.10212894]]), array([ 0.,  0.]), array([[-0.16022001, -0.06501606, -0.68613223,  0.96541306],
       [ 0.15240795, -0.41876942,  0.50621491,  0.11618159]]), array([ 0.,  0.,  0.,  0.])]
Weights and bias after trainning is
[array([[-0.86223659,  0.07199206],
       [ 0.49532608, -0.81743327],
       [-0.5517946 , -0.24632141],
       [ 0.04640422, -0.09813102]]), array([ 0.11629053,  0.03997918]), array([[-0.25749549, -0.09675063, -0.69828947,  0.87946589],
       [ 0.08653298, -0.44026008,  0.49798202,  0.05797814]]), array([ 0.23823399,  0.07772003,  0.02977387,  0.21049024])]
However, if I use the latest version of keras, then the result will be:
Epoch 0
1/1 [==============================] - 0s - loss: 0.0328
Weights and bias before trainning is
[array([[ 0.99807841, -0.0321337 ],
       [-0.34120891,  0.31954411],
       [ 0.61708271,  0.51410343],
       [-0.68198998,  0.58714997]]), array([ 0.,  0.]), array([[ 0.69201076,  0.3782278 ,  0.95140293,  0.22793627],
       [ 0.16048078,  0.68251729,  0.26576419, -0.86654349]]), array([ 0.,  0.,  0.,  0.])]
Weights and bias after trainning is
[array([[ 0.99807841, -0.0321337 ],
       [-0.34120891,  0.31954411],
       [ 0.61708271,  0.51410343],
       [-0.68198998,  0.58714997]]), array([ 0.,  0.]), array([[ 0.69201076,  0.3782278 ,  0.95140293,  0.22793627],
       [ 0.16048078,  0.68251729,  0.26576419, -0.86654349]]), array([ 0.,  0.,  0.,  0.])]

Basically, the bias of the neural network is not updating. Could someone help to fix it?
",bangrui,None,2015-07-30T17:16:08Z,2015-07-31T01:52:52Z
452,Re-generating a net with to/from_yaml() and save/load_weights() does not preserve training,"I have worked on models for text generation (cough..Karpathy..cough) as my getting-back-into NNs project for a while now. Slowly getting to where they make sense, I would like to preserve the trained network's states. I'm assuming that model.to_yaml() -> model_from_yaml() and model.get_weights() -> model.set_weights() should do that, but either I'm missing something or there's a bug in one of those two functions.

Here's my example code (with a keras version cloned from git yesterday afternoon):

```
newmodel = model_from_yaml(model.to_yaml()) 
# copy the model (model_from_yaml() should compile() according to source code)
wts=model.get_weights()
newmodel.set_weights(wts)
```

This should copy over the weights and thus the trained state
So let's compare the errors of both on a subset of my training data:

```
print(model.evaluate(trainX[:1000],trainy[:1000]))
print(newmodel.evaluate(trainX[:1000],trainy[:1000]))
```

.. results in this output:

```
1000/1000 [==============================] - 2s     
0.46311536622

1000/1000 [==============================] - 2s     
4.9628265152
```

So the errors are clearly not the same. The generated text also coincides with what seems to be an untrained new_network, just like the evaluate error level indicates.

So - am I missing a piece of the puzzle to save/load a trained model or did I find a bug?
",w0nk0,None,2015-07-27T19:10:12Z,2015-09-03T03:21:59Z
400,Modifying Merge to work with conv layers. Has a weird bug,"Hi

Let me explain in a few lines what I'm trying to do. I'm a neuroscientist studying visual processing and I'm interested in creating CNN that mimic the visual system (that's what CNNs where originally created for). One thing that the retina does for example is mixing of independent pathways with different scales. Therefore that's what I'm trying to achieve in these branch. The relevant piece of code is in **examples/mnist_cnn2.py** and **keras/layers/core.py** (Merge) the code Iooks like this:

**mnist_cnn2.py**
`path1 = Sequential()`
`path1.add(Convolution2D(3, 1, 3, 3, border_mode='same'))`
`path1.add(Activation('relu'))`

`path2 = Sequential()`
`path2.add(Convolution2D(3, 1, 7, 7, border_mode='same'))`
`path2.add(Activation('relu'))`

`model = Sequential()`
`model.add(Merge([path1, path2], mode='concat', axis=1))`

I think this looks very natural. Note that I modified the Merge layer, it now has an axis parameter.
However, this example doesn't work as shown above (that's why i created a new dev branch), but if you change the Merge line to be either
`model.add(Merge([path1, path1], mode='concat', axis=1))`
or
`model.add(Merge([path2, path2], mode='concat', axis=1))`

it works perfectly well. However, when mixing path1 and path2 it crashes and I don't understand the error.

Any ideas?
Thanks
",pjadzinsky,None,2015-07-16T16:05:51Z,2015-07-21T01:54:25Z
399,Bug in 'same' border,"Hi,
-            clip_row = (self.nb_row - 1) // 2
-            clip_col = (self.nb_col - 1) // 2
-            output = output[:, :, clip_row:-clip_row, clip_col:-clip_col]

In case of clip_row or  clip_col are 1 (1D input), there will be a crash.
Can you please fix it?

Thanks
",loyeamen,None,2015-07-16T13:33:52Z,2015-07-16T14:30:58Z
386,Possible bug in Autoencoder class,"Hi Francois, et al., I'm a PhD student in CS/machine learning at USC. We started our DL odyssey using Theano directly and just discovered keras, which has thus far been great, especially for rapidly trying a lot of different models. Thanks for the great work!

I did find what I believe to be a bug in the Autoencoder class, in its handling of tied weights. I noticed after training an autoencoder with tied weights set to true, the actual encoder and decoder weights were NOT identical (which means they WEREN'T actually tied during training). This is because the only place the tie_weights option is used is inside of get_output -- i.e., it just returns the encoder weights as the decoder weights.

Unless I am mistaken, what you want is for the decoder's Theano symbolic variable parameter (e.g., W for a Dense layer) to be the transpose of the encoder's parameter. For example, see the dA class in the Theano tutorial.

I can fix this, but I have two questions:
- Do you have a preferred procedure for accepting fixes? I.e., just fork keras, make the changes, send a pull request?
- I'm torn about the best way to make the actual fix. I created a new Layer called TiedDense that accepts a Dense ""layer"" in its constructor and does the ""right thing"" (sets the W parameter to be equal to layer.W.T, makes an untied bias, only includes the bias in the params list, etc.). For now, I've just been sticking that in a Sequential model and eschewing the Autoencoder class altogether.

Another option would be a to make a class method that takes a (generic) layer and creates a decoder version of that layer with tied weights. With that, one could perhaps build the decoder automatically within the Autoencoder constructor.

Thoughts?

P.S. I've also implemented some Noise layers for use with denoising autoencoders, if those are of interest.
",turambar,b'stale',2015-07-13T20:23:56Z,2017-06-22T20:08:36Z
383,implement CTC with keras?,"Hi there,

Has anyone implemented a (Connectionist-Temporal-Classification)CTC loss with keras? 

I attempt to add such a cost function in objectives.py file, based on [rakeshvar's code](https://github.com/rakeshvar/rnn_ctc). The model could be compiled, however, there are several errors when I do model.fit(). I am new to theano so it's really tough for me to debug...

It shouldn't be hard in theory, so I guess I made some ""naive"" mistakes...
",blackyang,None,2015-07-12T21:16:30Z,2018-02-07T17:32:08Z
361,layers.recurrent: fix masking from input,"If there is no input layer to a recurrent layer, mask is automatically
taken from the input data. Fix a bug where timesteps whose features were
all zeroes were included in the mask, instead of excluded.

Signed-off-by: Amit Beka amit.beka@gmail.com
",amitbeka,None,2015-07-08T06:26:52Z,2015-07-20T14:44:50Z
360,change Layer to MaskedLayer & sqrt bugfix for GaussianDropout,"Oops, didn't notice this change in API
",the-moliver,None,2015-07-08T01:22:59Z,2015-07-08T20:33:34Z
337,ModelCheckpoint - a bug in line 177,"You forgot to initialize self.monitor with monitor.
The line appears like this:
self.monitor

and the error
AttributeError: 'ModelCheckpoint' object has no attribute 'monitor'

Would appreciate if you could fix that, thanks
",loyeamen,None,2015-07-05T18:14:16Z,2015-07-05T18:20:34Z
332,fix a bug in DenoisingAutoEncoder,"There should be `self.encoder.input_dim` since `DenoisingAutoEncoder` class doesn't have attribute `input_dim`.
",DelightRun,None,2015-07-03T14:00:54Z,2015-07-03T18:10:01Z
317,Recurrent model with merged embedding lookups,"Hi,

I'm attempting to build a sequence model where at each time step, the input is the concatenation of representations from two lookup tables. The single lookup table case can be done with something like this:

``` python
net = Sequential()
net.add(Embedding(10, 2))
net.GRU(2, 1)
net.compile(loss='binary_crossentropy', optimizer='sgd')

X = np.arange(5).reshape((-1, 1))
Y = np.array([1, 0, 1, 0, 0]).reshape((-1, 1))
net.train(X, Y)
```

However, I'm having trouble getting the two lookup table case to work. This is my attempt:

``` python
e1 = Sequential()
e1.add(Embedding(5, 2))
e2 = Sequential()
e2.add(Embedding(10, 3))
net = Sequential()
net.add(Merge([e1, e2], mode='concat'))
net.add(GRU(5, 1))
net.compile(loss='binary_crossentropy', optimizer='sgd')

X = [
    np.array([1, 3, 3]).reshape((-1, 1)), # the first sequence of indices for lookup table 1
    np.array([2, 2, 0]).reshape((-1, 1)), # the second sequence of indices for lookup table 2
]
Y = np.array([1., 0., 1.]).reshape((-1, 1))
net.train(X, Y)
```

The error I'm getting is

```
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
<ipython-input-14-772f824ecbef> in <module>()
      4 ]
      5 Y = np.array([1., 0., 1.]).reshape((-1, 1))
----> 6 net.train(X, Y)

/Users/victor/Developer/keras/keras/models.pyc in train(self, X, y, accuracy)
    170             return self._train_with_acc(*ins)
    171         else:
--> 172             return self._train(*ins)
    173 
    174 

/usr/local/lib/python2.7/site-packages/theano/compile/function_module.pyc in __call__(self, *args, **kwargs)
    604                         self.fn.nodes[self.fn.position_of_error],
    605                         self.fn.thunks[self.fn.position_of_error],
--> 606                         storage_map=self.fn.storage_map)
    607                 else:
    608                     # For the c linker We don't have access from

/usr/local/lib/python2.7/site-packages/theano/compile/function_module.pyc in __call__(self, *args, **kwargs)
    593         t0_fn = time.time()
    594         try:
--> 595             outputs = self.fn()
    596         except Exception:
    597             if hasattr(self.fn, 'position_of_error'):

ValueError: total size of new array must be unchanged
Apply node that caused the error: Reshape{2}(InplaceDimShuffle{1,0,2}.0, MakeVector.0)
Inputs types: [TensorType(float32, 3D), TensorType(int64, vector)]
Inputs shapes: [(1, 3, 5), (2,)]
Inputs strides: [(60, 20, 4), (8,)]
Inputs values: ['not shown', array([3, 2])]

HINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.
HINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.
```

Has anyone seen this before? Any ideas on how to proceed? Is the concatentation of `Embeddings` supported?
",vzhong,None,2015-07-02T00:09:17Z,2015-10-21T01:04:16Z
304,Bug with Merge when mode='concat'?,"I have the following network configuration:

``` python
nb_feature_maps = 32
embedding_size = 64

ngram_filters = [3, 5, 7, 9]
conv_filters = []

for n_gram in ngram_filters:
    sequential = Sequential()
    conv_filters.append(sequential)

    sequential.add(Embedding(max_features, embedding_size))
    sequential.add(Reshape(1, maxlen, embedding_size))
    sequential.add(Convolution2D(nb_feature_maps, 1, n_gram, embedding_size))
    sequential.add(Activation(""relu""))
    sequential.add(MaxPooling2D(poolsize=(maxlen - n_gram + 1, 1))) #collapses to nb_feature_maps * 1
    sequential.add(Flatten())
    sequential.add(Dense(nb_feature_maps, 32))

model = Sequential()
model.add(Merge(conv_filters, mode='concat'))
model.add(Dense(128, 1)) # len(ngram_filters) * 32
model.add(Activation(""sigmoid""))

model.compile(loss='binary_crossentropy', optimizer='adam', class_mode=""binary"")
```

According to your documentation and tests, the output dimensionality of the merge + concat layer should be 128, 4 \* 32, but this causes the following error when compiling:

  File ""/Users/simon.hughes/Library/Enthought/Canopy_64bit/User/lib/python2.7/site-packages/theano/compile/function_module.py"", line 595, in **call**
    outputs = self.fn()
ValueError: dimension mismatch in args to gemm (16,32)x(128,1)->(16,1)
Apply node that caused the error: GpuDot22(GpuJoin.0, <CudaNdarrayType(float32, matrix)>)
Inputs types: [CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix)]
Inputs shapes: [(16, 32), (128, 1)]
Inputs strides: [(32, 1), (1, 0)]
Inputs values: ['not shown', 'not shown']

Please help! I can get this working with mode='sum', but that doesn't seem to do very well on my problem. I think concat would do much better. 
",simonhughes22,None,2015-06-30T04:58:00Z,2015-06-30T05:05:37Z
303,Omit input dimensions (for hidden layers) and auto-calculate if not specified,"Most of the time when I have a bug it's because I haven't correctly figured out the input dimensionality for some hidden layer that's layered on top of a convolutional or max pooling layer. Can we have the code auto-compute the input dimensionality of non-input layers for ease of use? This would have saved me hours initially, as is how Passage works (you just specify the output dimensionality).
",simonhughes22,b'stale',2015-06-30T04:52:30Z,2017-06-22T22:09:44Z
289,"not existing directory bug on example ""skipgram_word_embeddings.py""","```
FileNotFoundError: [Errno 2] No such file or directory: 'D:\\WinPython\\basedir34\\build\\winpython-3.4.3.amd64 - Copie\\settings/HNCommentsAll.1perline.json'
```
",stonebig,None,2015-06-28T08:52:31Z,2015-06-28T18:08:18Z
270,Inconsistent behavior of batch normalization layer,"As you can see by the code below, the behavior of batch normalization seems to be dependent on the batch of samples. Any given sample should always be classified exactly the same (in mode 0 at least). Note that for the single item batch, the output of model.predict(arr1[:1]) is identical to the output of model.predict(arr1[1:]).

```
>>> import numpy
>>> 
>>> from keras.models import Sequential
>>> from keras.layers.core import Dense, Activation
>>> from keras.layers.normalization import BatchNormalization
>>> from keras.optimizers import SGD
>>> 
>>> model = Sequential()
>>> model.add(Dense(200,5))
>>> model.add(BatchNormalization(5))
>>> model.add(Activation('softmax'))
>>> sgd = SGD(lr=0.01, decay=3e-6, momentum=0.9, nesterov=False)
>>> model.compile(loss='categorical_crossentropy', optimizer=sgd)
>>> arr1 = numpy.random.rand(2,200)
>>> y1 = numpy.random.rand(2,5)
>>> model.train(arr1,y1)
array(3.693775110217432)
>>> model.predict(arr1)
2/2 [==============================] - 0s
array([[ 0.21000414,  0.20690492,  0.19180691,  0.19093657,  0.20034746],
       [ 0.1894262 ,  0.19338509,  0.20825628,  0.20882832,  0.2001041 ]])
>>> model.predict(arr1[:1])
1/1 [==============================] - 0s
array([[ 0.19959944,  0.20018073,  0.20001223,  0.1998318 ,  0.2003758 ]])
>>> model.predict(arr1[1:])
1/1 [==============================] - 0s
array([[ 0.19959944,  0.20018073,  0.20001223,  0.1998318 ,  0.2003758 ]])
```

I've read the source code a thousand times and cannot find a reason for this to happen. I've got a working theory that there is an issue with running mean and running std being mutable within get_output(). Those values are also not inspectable as they are not stored as a tensor value:

```
>>> import theano
>>> theano.printing.debugprint(model.layers[1].running_mean)
Elemwise{true_div,no_inplace} [@A] ''   
 |Sum{axis=[0], acc_dtype=float64} [@B] ''   
 | |Elemwise{add,no_inplace} [@C] ''   
 |   |dot [@D] ''   
 |   | |<TensorType(float64, matrix)> [@E]
 |   | |<TensorType(float64, matrix)> [@F]
 |   |DimShuffle{x,0} [@G] ''   
 |     |<TensorType(float64, vector)> [@H]
 |DimShuffle{x} [@I] ''   
   |Subtensor{int64} [@J] ''   
     |Elemwise{Cast{float64}} [@K] ''   
     | |Shape [@L] ''   
     |   |Elemwise{add,no_inplace} [@C] ''   
     |Constant{0} [@M]
```

This issue makes batch normalization fairly useless to me as I cannot guarantee that a sample will always generate the same prediction.
",kofd,None,2015-06-23T17:09:42Z,2015-08-13T15:21:09Z
267,Add a name parameter to Dense.__init__,"When debugging theano errors, if the error message contains a variable name, it will print something like `<CudaNdarrayType(float32, matrix)>`, which is not very useful. With this change, a `name` parameter can be supplied to `Dense.__init__` function and the variables of the layer will be named with 'layername_varname' which make debugging easier.

For example, a theano error message before this change :

```
DisconnectedInputError: grad method was asked to compute the gradient with respect to a variable 
that is not part of the computational graph of the cost, or is used only by a non-differentiable 
operator: <CudaNdarrayType(float32, matrix)>
```

And after (with my layer named 'in0') :

```
DisconnectedInputError: grad method was asked to compute the gradient with respect to a variable 
that is not part of the computational graph of the cost, or is used only by a non-differentiable 
operator: in0_W
```

For now, this only changes `Dense.__init__`, but if you think this is an interesting change, I'll add the same parameter to other layers.
",julienr,None,2015-06-23T12:50:59Z,2015-07-20T08:29:51Z
207,Use the inner_init for internal weights in SimpleRNN,"It appears this was a bug in the implementation of SimpleRNN. The `init` initializer was being used for both sets of weights.
",wxs,None,2015-06-09T07:53:24Z,2015-06-09T16:25:00Z
205,Fixed python 2.x bug with input() in save_weights(),"Hey François,

the `save_weights` method makes more trouble. :)

For Python 2.x using `input()` does not work. Instead to reliably get the input in python 2/3 one needs to use different functions.
",tdhd,None,2015-06-08T15:26:04Z,2015-06-08T16:58:57Z
171,Callbacks,"## Callbacks

The logs and history given by `keras.models.Sequential().fit()` are great ways to easily debug your models. To provide new debugging tools in the future, I am introducing callbacks for easy access to inner loops inside the training procedure.
- **Keep debug separated from the main code**: Using callbacks one can separate the training code in `fit()` from debug functions (history and logging) as they can be expressed as callbacks themselves. This improves readability and is safe for future changes.
- **Access internal states and statistics of the model**: Callbacks allow you to access internal states of the model and statistics about training _while the training procedure is still running_. You have the choice to trigger functions at any stage of training, be it at the epoch level or the batch level.

Here is an example of what you can do with callbacks, inspired by @Newmu's [tutorial](https://www.youtube.com/watch?v=S75EdAcXHKk):

![cnn_activations](https://cloud.githubusercontent.com/assets/2018752/7866089/6378de1e-056d-11e5-96f9-68dabdd60bb4.gif)
_Activation layers on a test example in a simple CNN during training on MNIST_
#### Why callbacks?

Callbacks are a flexible way to apply functions at any point of training. Here are some example of applications using callbacks:
- Save statistics of the training procedure, similarly to `history` in `fit()`. This callback is already available as `keras.callbacks.History`.
- Logging informations about the training procedure, depending on `verbose`. This callback is already available as `keras.callbacks.Logger` and is applied by default.
- Create animations of the weight matrices or activation layers. See below a more in-depth example.
- Get real-time informations, like the loss curve.
- Programmatically stop training ; this can be a path towards a GUI manager.
#### How to use callbacks?

To create a callback to be called during the training procedure, you only have to extend the class `keras.callbacks.Callback` with your custom functions. It supports the following methods:
- **on_train_begin**(): Method called at the beginning of training.
- **on_train_end**(): Method called at the end of training.
- **on_epoch_begin**(epoch): Method called at the beginning of epoch `epoch`.
- **on_epoch_end**(epoch, val_loss, val_acc): Method called at the end of epoch `epoch`, with validation loss `val_loss` and accuracy `val_acc` (if applicable).
- **on_batch_begin**(batch): Method called at the beginning of batch `batch`.
- **on_batch_end**(batch, indices, loss, accuracy): Method called at the end of batch `batch`, given by the indices `indices`, with loss `loss` and accuracy `accuracy` (if applicable).

In the spirit of #100 , one typical application of callbacks is to create visualizations to see how the model behaves during training. Here is an example of how you can use a callback to create an animation of a weight matrix as a function of time during training.

``` python
import matplotlib.pyplot as plt
import matplotlib.animation as animation

class DrawWeights(keras.callbacks.Callback):

    def __init__(self, figsize, layer_id=0, param_id=0, weight_slice=(slice(None), 0)):
        self.layer_id = layer_id
        self.param_id = param_id
        self.weight_slice = weight_slice
        # Initialize the figure and axis
        self.fig = plt.figure(figsize=figsize)
        self.ax = self.fig.add_subplot(1, 1, 1)

    def on_train_begin(self):
        self.imgs = []

    def on_batch_end(self, batch, indices, loss, accuracy):
        # Get a snapshot of the weight matrix every 5 batches
        if batch % 5 == 0:
            # Access the full weight matrix
            weights = self.model.layers[self.layer_id].params[self.param_id].get_value()
            # Create the frame and add it to the animation
            img = self.ax.imshow(weights[self.weight_slice], interpolation='nearest')
            self.imgs.append(img)

    def on_train_end(self):
        # Once the training has ended, display the animation
        anim = animation.ArtistAnimation(self.fig, self.imgs, interval=10, blit=False)
        plt.show()
```

To apply this callback to your training procedure, simply provide the list of callbacks as an argument of `fit()`. All the callbacks given in that list are applied sequentially.

``` python
draw_weights = DrawWeights(figsize=(4, 4), layer_id=0, \
    param_id=0, weight_slice=(slice(None), 0))
model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epoch, \
    verbose=1, callbacks=[draw_weights])
```

Here is a sample animation obtained with this callback:

![mlp_weight](https://cloud.githubusercontent.com/assets/2018752/7872862/e085df78-059b-11e5-9e12-6fbd90a374a8.gif)
_Weight matrix of a MLP during training on MNIST_
",tristandeleu,None,2015-05-28T23:20:06Z,2017-02-15T15:21:08Z
163,Predicting sequence with recurrent output layer does not work,"I made a simple model with a 1 cell LSTM to predict the next number in a sequence given the current number (not for any practical reasons, this is just to demonstrate the bug). Here's the code:

```
from keras.models import Sequential
from keras.layers.recurrent import LSTM

import numpy

# Dataset has a single sample just to make things simpler
x1 = numpy.random.randn(100)
X_train = numpy.empty((1,len(x1)-1, 1)) #  (# samples, # timesteps, # features) 
Y_train = numpy.empty((1,len(x1)-1, 1))

X_train[0,:] = x1[:-1]
Y_train[0,:] = x1[1:]

model = Sequential()
model.add(LSTM(1, 1, activation='sigmoid', inner_activation='hard_sigmoid', return_sequences=True))

model.compile(loss='mean_squared_error', optimizer='sgd')
model.fit(X_train, Y_train, batch_size=1, nb_epoch=10)
```

But running this fails during the compile step, with the following error message:

```
TypeError: Cannot convert Type TensorType(float64, (False, True, True)) (of Variable 
IncSubtensor{Set;:int64:}.0) into Type TensorType(float64, (False, False, True)). You can try to manually
 convert IncSubtensor{Set;:int64:}.0 into a TensorType(float64, (False, False, True)).
```

I remember that a while ago we had to pass a parameter to `compile` to say how many dimensions the targets have, but it was removed and now `compile` uses `T.zeros_like(self.y_train)` to set the output dimension.

Am I doing something wrong or is this a bug?
",jfsantos,None,2015-05-26T19:43:41Z,2015-05-26T21:03:24Z
152,Merge fails on GPU but passes on CPU,"Hi,

I've noticed a problem using `Merge` on `Sequential` networks with flattened `Embedding`s. The context of the problem is as follows:

I have two embedding tables, for each example, I'd like to look up 1 embedding from table 1 and two embeddings from table 2 and concatenate the three embeddings together. While this works on the CPU, it fails on the GPU with the following error:

``` text
ValueError: GpuJoin: Wrong inputs for input 1 related to inputs 0.!
Apply node that caused the error: GpuJoin(TensorConstant{-1}, GpuReshape{2}.0, GpuReshape{2}.0)
Inputs types: [TensorType(int8, scalar), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix)]
Inputs shapes: [(), (2, 2), (2, 4)]
Inputs strides: [(), (2, 1), (4, 1)]
Inputs values: [array(-1, dtype=int8), <CudaNdarray object at 0x11766c0f0>, 'not shown']

HINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.
HINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.
```

I've made a unittest for my model demonstrating this problem [here](https://github.com/vzhong/keras/blob/master/test/test_embeddings). Using a GTX760, the first two tests (single embedding lookup and double embedding lookup) pass while the third test fails with the above error.

I think I've tracked down the discrepancy to `Merge`'s `T.concatenate(..., axis=-1)`. This problem goes away if `axis=1` in this particular case. I'm not sure that the cause of this particular error is a Keras issue, as it doesn't exist on the CPU.
",vzhong,None,2015-05-25T08:19:34Z,2015-05-25T16:42:07Z
124,Add theano_mode argument to models.compile. ,"This allows to specify a theano.compile.mode.Mode instance to use, for example to use a MonitorMode
with a post_func to debug nans.
",julienr,None,2015-05-13T09:38:57Z,2015-05-13T19:18:15Z
35,Fixed incorrect datatype in range function from the last commit,"Apologies, the `nb_batch` size fix from last time resulted in an unsuitable datatype for the `range` function - I missed that in the tests as I was working in another branch and just happen to notice the `nb_batch` bug.
",patyork,None,2015-04-05T18:24:42Z,2015-04-05T18:31:53Z
34,Fixed logic to determine the number of batches per epoch,"Fixed a bug wherein the number of batches that was calculated would be too large when `Num_Examples % batch_size == 0`
",patyork,None,2015-04-05T07:16:11Z,2015-04-05T17:53:54Z
