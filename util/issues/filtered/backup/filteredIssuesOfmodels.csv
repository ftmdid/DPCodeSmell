id,Title,Body,User,Label,Created At,Updated At
9342,TFLite for Tensorflow2 models,"<!--
As per our GitHub Policy (https://github.com/tensorflow/models/blob/master/ISSUES.md), we only address code bugs, documentation issues, and feature requests on GitHub.

We will automatically close questions and help related issues.

Please go to Stack Overflow (http://stackoverflow.com/questions/tagged/tensorflow-model-garden) for questions and help.

-->

Hi, I just got to know that TFLite now supports for SSD models in TF2. I was wondering if you could answer when EfficientDet models would be supported by TFLite approximately. Thank you so much in advance.",SukyoungCho,b'stat:awaiting response type:support',2020-10-06T05:19:50Z,2020-10-06T15:56:02Z,,,,,,,
9336,Bert checkpoint conversion tf1.x to tfhub2.x,"## 1. The entire URL of the file you are using

https://github.com/tensorflow/models/blob/master/official/nlp/bert/tf2_encoder_checkpoint_converter.py
https://github.com/tensorflow/models/blob/master/official/nlp/bert/export_tfhub.py

## 2. Describe the bug

Starting from a Tf1.X bert checkpoint (from https://github.com/google-research/bert) I tried to convert it to a Tf2.x checkpoint using tf2_encoder_checkpoint_converter.py. After this operation using export_tfhub.py I wanted to convert it again into a tfhub2.x format. 
I get errors from .assert_existing_objects_matched() in checkpoint restoration before the tfhub export. 
WARNING:tensorflow:Unresolved object in checkpoint: (root).bert_model.ckpt 
(same for each layer)
## 3. Steps to reproduce

Download a tf1.x checkpoint from from https://github.com/google-research/bert, run tf2_encoder_checkpoint_converter.py and then export_tfhub.py with appropriate file path at each step. 

## 4. Expected behavior

At the end of this (double) conversion from checkpoint tf1.x -> tfhub2.x the saved model should be consistent with the ones downloadable from https://github.com/tensorflow/models/tree/master/official/nlp/bert .

## 5. Additional context

I tried with both master (nightly) and v2.3.0 (tf2.3) branches obtaining same results.

## 6. System information

- OS Platform and Distribution: Ubuntu 18.04
- TensorFlow installed from source
- TensorFlow version 2.3.0 and Nightly (tried both)
- Python version 3.6 and 3.8
- CUDA/cuDNN version 10.1
- GPU model and memory V100 ",pretidav,b'models:official type:bug',2020-10-02T08:22:40Z,2020-10-06T17:28:52Z,,,,,,,
9325,research model bug,"# Prerequisites

Please answer the following questions for yourself before submitting an issue.

- [ ] I am using the latest TensorFlow Model Garden release and TensorFlow 2.
- [ ] I am reporting the issue to the correct repository. (Model Garden official or research directory)
- [ ] I checked to make sure that this issue has not already been filed.

## 1. The entire URL of the file you are using

https://github.com/tensorflow/models/tree/master/research/...

## 2. Describe the bug

A clear and concise description of what the bug is.

## 3. Steps to reproduce

Steps to reproduce the behavior.

## 4. Expected behavior

A clear and concise description of what you expected to happen.

## 5. Additional context

Include any logs that would be helpful to diagnose the problem.

## 6. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device name if the issue happens on a mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below):
- Python version:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

<!-- 
Collect system information using our environment capture script.
https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can also obtain the TensorFlow version with:

1. TensorFlow 1.0
`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

2. TensorFlow 2.0
`python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`
-->
",rthadur,b'models:research type:bug',2020-09-29T05:24:28Z,2020-09-29T05:24:50Z,,,,,,,
9324,Rename bot-config.yml to bot_config.yml,"# Description

> :memo: Please include a summary of the change. 
>  
> * Please also include relevant motivation and context.  
> * List any dependencies that are required for this change.  

## Type of change

For a new feature or function, please create an issue first to discuss it
with us before submitting a pull request.

Note: Please delete options that are not relevant.

- [ ] Bug fix (non-breaking change which fixes an issue)
- [ ] Documentation update
- [ ] TensorFlow 2 migration
- [ ] New feature (non-breaking change which adds functionality)
- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)
- [ ] A new research paper code implementation
- [ ] Other (Specify)

## Tests

> :memo: Please describe the tests that you ran to verify your changes.
>  
> * Provide instructions so we can reproduce.  
> * Please also list any relevant details for your test configuration.  

**Test Configuration**:

## Checklist

- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).
- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).
- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).
- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.
- [ ] I have commented my code, particularly in hard-to-understand areas.
- [ ] I have made corresponding changes to the documentation.
- [ ] My changes generate no new warnings.
- [ ] I have added tests that prove my fix is effective or that my feature works.
",rthadur,b'cla: yes',2020-09-29T05:17:52Z,2020-09-29T05:23:24Z,,,,,,,
9323,model bug,"# Prerequisites

Please answer the following questions for yourself before submitting an issue.

- [ ] I am using the latest TensorFlow Model Garden release and TensorFlow 2.
- [ ] I am reporting the issue to the correct repository. (Model Garden official or research directory)
- [ ] I checked to make sure that this issue has not been filed already.

## 1. The entire URL of the file you are using

https://github.com/tensorflow/models/tree/master/official/...

## 2. Describe the bug

A clear and concise description of what the bug is.

## 3. Steps to reproduce

Steps to reproduce the behavior.

## 4. Expected behavior

A clear and concise description of what you expected to happen.

## 5. Additional context

Include any logs that would be helpful to diagnose the problem.

## 6. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device name if the issue happens on a mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below):
- Python version:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

<!-- 
Collect system information using our environment capture script.
https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can also obtain the TensorFlow version with:

1. TensorFlow 1.0
`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

2. TensorFlow 2.0
`python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`
-->
",rthadur,b'models:official type:bug',2020-09-29T05:10:49Z,2020-09-29T05:24:09Z,,,,,,,
9319,ValueError: Cannot set tensor: Dimension mismatch. Got 3 but expected 4 for input 0.,"I trained the `ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8` model with my custom data. If I load the SavedModel (the .pb file) and inference with it, it works as expected. - the output is correct

Now I converted the model to a TFLite model. Using this model with the same image to inference I get an error saying: 
""ValueError: Cannot set tensor: Dimension mismatch. Got 3 but expected 4 for input 0"" 

The input details of the model are: 
`[{'name': 'serving_default_input:0', 'index': 0, 'shape': array([  1, 640, 640,   3]), 'shape_signature': array([  1, 640, 640,   3]), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]`

If I am not wrong the expected shape is `[  1, 640, 640,   3]` -> so 3 dimensions. But the error says it is expecting 4?

I am using the latest tf-nightly from source. I tried different tensorflow and tflite versions, it is the same error with every version.
Currently I am at '2.4.0-dev20200926'

EDIT:
I am using this script to create the saved model: 
`python export_tflite_graph_tf2.py --trained_checkpoint_dir ./training --output_directory ./inference_graph_tflite --pipeline_config_path ./training/ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8.config`

Then I use the standard code to convert it to a tflite model: 
```
converter = tf.lite.TFLiteConverter.from_saved_model(path + 'saved_model')
converter.optimizations = [tf.lite.Optimize.DEFAULT]
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8, tf.lite.OpsSet.TFLITE_BUILTINS]
tflite_model = converter.convert()

with open(path + 'final_detector.tflite', 'wb') as f:
  f.write(tflite_model)
```

As for testing the tflite model I am using this code:
```
interpreter = tf.lite.Interpreter(model_path=""final_detector.tflite"")

input_details = interpreter.get_input_details()
output_details = interpreter.get_output_details()

interpreter.allocate_tensors()
input_data = np.expand_dims(new_img, axis=0).astype(np.float32)
interpreter.set_tensor(input_details[0]['index'], input_data)

interpreter.invoke()
```
Of course I can expand the dimensions and feed it into the model, but it does not generate an output (the output array is empty).

Is there a link or code snippet on how to generate the SavedModel from the checkpoints for converting it to the TFLite model?",DeRealMorgan,b'models:research type:bug',2020-09-28T09:17:41Z,2020-10-02T08:35:58Z,,,,,,,
9297,"Training SSD-MobilenetV2 fails with Message type ""object_detection.protos.TrainConfig"" has no field named ""fine_tune_checkpoint_version""","# Prerequisites

Please answer the following questions for yourself before submitting an issue.

- [ ] I am using the latest TensorFlow Model Garden release and TensorFlow 2.
I am using the latest release and TensorFlow 2
- [ ] I am reporting the issue to the correct repository. (Model Garden official or research directory)
research directory
- [ ] I checked to make sure that this issue has not already been filed.
yes, by searching for key words

## 1. The entire URL of the file you are using

https://github.com/tensorflow/models/tree/master/research/...

## 2. Describe the bug

So i am trying to train a new model based on the SSD MobileNet V2 FPNLite 320x320 checkpoints with the help of the GCP AI Platform. I am using TPUs for it as mentioned under this page: [link](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_training_and_evaluation.md#training-with-tpu)

I am getting the following error:
`The replica master 0 exited with a non-zero status of 1. 
Traceback (most recent call last):
  [...]
  File ""/usr/local/lib/python3.7/dist-packages/absl/app.py"", line 300, in run
    _run_main(main, args)
  File ""/usr/local/lib/python3.7/dist-packages/absl/app.py"", line 251, in _run_main
    sys.exit(main(argv))
  File ""/root/.local/lib/python3.7/site-packages/object_detection/model_main_tf2.py"", line 110, in main
    record_summaries=FLAGS.record_summaries)
  File ""/root/.local/lib/python3.7/site-packages/object_detection/model_lib_v2.py"", line 470, in train_loop
    pipeline_config_path, config_override=config_override)
  File ""/root/.local/lib/python3.7/site-packages/object_detection/utils/config_util.py"", line 139, in get_configs_from_pipeline_file
    text_format.Merge(proto_str, pipeline_config)
  File ""/usr/local/lib/python3.7/dist-packages/google/protobuf/text_format.py"", line 734, in Merge
    allow_unknown_field=allow_unknown_field)
  File ""/usr/local/lib/python3.7/dist-packages/google/protobuf/text_format.py"", line 802, in MergeLines
    return parser.MergeLines(lines, message)
  File ""/usr/local/lib/python3.7/dist-packages/google/protobuf/text_format.py"", line 827, in MergeLines
    self._ParseOrMerge(lines, message)
  File ""/usr/local/lib/python3.7/dist-packages/google/protobuf/text_format.py"", line 849, in _ParseOrMerge
    self._MergeField(tokenizer, message)
  File ""/usr/local/lib/python3.7/dist-packages/google/protobuf/text_format.py"", line 974, in _MergeField
    merger(tokenizer, message, field)
  File ""/usr/local/lib/python3.7/dist-packages/google/protobuf/text_format.py"", line 1048, in _MergeMessageField
    self._MergeField(tokenizer, sub_message)
  File ""/usr/local/lib/python3.7/dist-packages/google/protobuf/text_format.py"", line 941, in _MergeField
    (message_descriptor.full_name, name))
google.protobuf.text_format.ParseError: 172:3 : Message type ""object_detection.protos.TrainConfig"" has no field named ""fine_tune_checkpoint_version"".`

## 3. Steps to reproduce

Follow the mentioned link and try it with the SSD MobileNet V2 FPNLite 320x320 checkpoints.
My pipeline-config looks like this:
`model {
  ssd {
    num_classes: 4
    image_resizer {
      fixed_shape_resizer {
        height: 320
        width: 320
      }
    }
    feature_extractor {
      type: ""ssd_mobilenet_v2_fpn_keras""
      depth_multiplier: 1.0
      min_depth: 16
      conv_hyperparams {
        regularizer {
          l2_regularizer {
            weight: 3.9999998989515007e-05
          }
        }
        initializer {
          random_normal_initializer {
            mean: 0.0
            stddev: 0.009999999776482582
          }
        }
        activation: RELU_6
        batch_norm {
          decay: 0.996999979019165
          scale: true
          epsilon: 0.0010000000474974513
        }
      }
      use_depthwise: true
      override_base_feature_extractor_hyperparams: true
      fpn {
        min_level: 3
        max_level: 7
        additional_layer_depth: 128
      }
    }
    box_coder {
      faster_rcnn_box_coder {
        y_scale: 10.0
        x_scale: 10.0
        height_scale: 5.0
        width_scale: 5.0
      }
    }
    matcher {
      argmax_matcher {
        matched_threshold: 0.5
        unmatched_threshold: 0.5
        ignore_thresholds: false
        negatives_lower_than_unmatched: true
        force_match_for_each_row: true
        use_matmul_gather: true
      }
    }
    similarity_calculator {
      iou_similarity {
      }
    }
    box_predictor {
      weight_shared_convolutional_box_predictor {
        conv_hyperparams {
          regularizer {
            l2_regularizer {
              weight: 3.9999998989515007e-05
            }
          }
          initializer {
            random_normal_initializer {
              mean: 0.0
              stddev: 0.009999999776482582
            }
          }
          activation: RELU_6
          batch_norm {
            decay: 0.996999979019165
            scale: true
            epsilon: 0.0010000000474974513
          }
        }
        depth: 128
        num_layers_before_predictor: 4
        kernel_size: 3
        class_prediction_bias_init: -4.599999904632568
        share_prediction_tower: true
        use_depthwise: true
      }
    }
    anchor_generator {
      multiscale_anchor_generator {
        min_level: 3
        max_level: 7
        anchor_scale: 4.0
        aspect_ratios: 1.0
        aspect_ratios: 2.0
        aspect_ratios: 0.5
        scales_per_octave: 2
      }
    }
    post_processing {
      batch_non_max_suppression {
        score_threshold: 9.99999993922529e-09
        iou_threshold: 0.6000000238418579
        max_detections_per_class: 100
        max_total_detections: 100
        use_static_shapes: false
      }
      score_converter: SIGMOID
    }
    normalize_loss_by_num_matches: true
    loss {
      localization_loss {
        weighted_smooth_l1 {
        }
      }
      classification_loss {
        weighted_sigmoid_focal {
          gamma: 2.0
          alpha: 0.25
        }
      }
      classification_weight: 1.0
      localization_weight: 1.0
    }
    encode_background_as_zeros: true
    normalize_loc_loss_by_codesize: true
    inplace_batchnorm_update: true
    freeze_batchnorm: false
  }
}
train_config {
  batch_size: 128
  data_augmentation_options {
    random_horizontal_flip {
    }
  }
  data_augmentation_options {
    random_crop_image {
      min_object_covered: 0.0
      min_aspect_ratio: 0.75
      max_aspect_ratio: 3.0
      min_area: 0.75
      max_area: 1.0
      overlap_thresh: 0.0
    }
  }
  sync_replicas: true
  optimizer {
    momentum_optimizer {
      learning_rate {
        cosine_decay_learning_rate {
          learning_rate_base: 0.07999999821186066
          total_steps: 50000
          warmup_learning_rate: 0.026666000485420227
          warmup_steps: 1000
        }
      }
      momentum_optimizer_value: 0.8999999761581421
    }
    use_moving_average: false
  }
  fine_tune_checkpoint: ""gs://tom-master-od-bucket/models/cocossdoid_output/checkpoint/ckpt-0""
  num_steps: 50000
  startup_delay_steps: 0.0
  replicas_to_aggregate: 8
  max_number_of_boxes: 100
  unpad_groundtruth_tensors: false
  fine_tune_checkpoint_type: ""classification""
  fine_tune_checkpoint_version: V2
}
train_input_reader {
  label_map_path: ""gs://tom-master-od-bucket/data/label_bbox.pbtxt""
  tf_record_input_reader {
    input_path: ""gs://tom-master-od-bucket/data/train.tfrecord""
  }
}
eval_config {
  metrics_set: ""coco_detection_metrics""
  use_moving_averages: false
}
eval_input_reader {
  label_map_path: ""gs://tom-master-od-bucket/data/label_bbox.pbtxt""
  shuffle: false
  num_epochs: 1
  tf_record_input_reader {
    input_path: ""gs://tom-master-od-bucket/data/validation.tfrecord""
  }
}
`
I call the gcloud command like this:
`gcloud ai-platform jobs submit training `whoami`_object_detection_`date +%m_%d_%Y_%H_%M_%S` \
    --job-dir=gs://${MODEL_DIR} \
    --package-path=./object_detection \
    --module-name=object_detection.model_main_tf2 \
    --runtime-version=2.2 \
    --python-version=3.7 \
    --scale-tier=BASIC_TPU \
    --region=us-central1 \
    -- \
    --distribution_strategy=tpu \
    --model_dir=gs://${MODEL_DIR} \
    --pipeline_config_path=gs://${PIPELINE_CONFIG_PATH}`


## 4. Expected behavior

The training starts.


Does anyone know what the problem is?

Thanks and best regards,
Tom",acidassassin,b'models:research type:bug',2020-09-24T12:11:09Z,2020-09-24T18:24:50Z,,,,,,,
9286,How the object detection API can be trained on multiple gpu's?,"

## The entire URL of the file you are using

https://github.com/tensorflow/models/tree/r1.12.0/research/object_detection


I'm using model_main.py to train my model on windows. It only works for a while and soon it will report errors about out of memory. I tried to add it in the code, but it doesn't seem to work.Because of the limitation of multiple GPUs, I can only set batchsize=4 at least. I could run the program multiple times to train it, but that doesn't seem like a good way to do it!
I tried to use model_main_tf2.py and had similar problems.

`  # config = tf.estimator.RunConfig(model_dir=FLAGS.model_dir)`
`  session_config = tf.ConfigProto(allow_soft_placement=True, log_device_placement=False)`
`  session_config.gpu_options.allow_growth = True
  session_config.gpu_options.per_process_gpu_memory_fraction = .3
  config=tf.estimator.RunConfig(model_dir=FLAGS.model_dir, session_config=session_config)`


## System information

- OS Platform and Distribution:  windows 10
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below):1.15.0
- Python version: 3.6 64bit
- CUDA/cuDNN version: CUDA10
- GPU model and memory: 1080TI *4 11G",x12901,b'models:research type:bug',2020-09-23T08:53:29Z,2020-09-24T14:50:07Z,,,,,,,
9275,VRAM/GPU memory allocation for tensors is larger than expected.,"Dear Tensorflow Team,

I have an issue with VRAM/GPU memory allocation. I tried to google this problem but I didnt find anything.

I was making a model which takes 128x128x1 images (greyscale pngs) as input. I was training this model on 20 000 dataset. However when I decided to try 100 000 dataset I encountered OOM(out of memory exception).

While debugging this issue I found out that the problem was occuring on a data loading step.(this is why the model code is not included below).

I am not an expert in Python and Tensorflow but I see two problems here:


1) I believe that VRAM allocations are enormously huge for the data I am using, as 100000x128x128x1 bytes should take around 1.638 GB of VRAM, but instead it takes way more that that. I was using GPU-Z tool for profiling and it seems like it needs way more than 4 GB. And I not using any training or model code, I am just creating tensors here.
2) It seems that when I try to load images from disk and transform them into tensors for training, tensors are allocated both on VRAM and RAM. Is this a correct behaviour?

Specs:

Python: 3.6.7
CUDA: 10.1
Tensorflow: 2.3.0
GPU: NVIDIA 2070 RTX SUPER 8 GB
OS: Windows 10

Code(change data_dir  variable to any valid image folder):
```
import tensorflow as tf
import pathlib

def allowGrowth():
    gpus = tf.config.experimental.list_physical_devices('GPU')
    if gpus:
        try:
            for gpu in gpus:
                print(gpu)
                tf.config.experimental.set_memory_growth(gpu, True)
            logical_gpus = tf.config.experimental.list_logical_devices('GPU')
            print(len(gpus), ""Physical GPUs,"", len(logical_gpus), ""Logical GPUs"")
        except RuntimeError as e:
            print(e)

def get_images():
    data_dir = ""dirToPngs""
    data_dir = pathlib.Path(data_dir)
    pathList = list(data_dir.glob('*.png'))
    listOfImages = []
    for p in pathList:

        img = tf.io.read_file(str(p))
        img = tf.image.decode_png(img, channels=1)
        img = tf.image.resize(img, [128, 128])
        img = tf.cast(img, tf.float32) / 255.0

        listOfImages.append(img)

    tensor = tf.convert_to_tensor(listOfImages, dtype=tf.float32)
    return tensor

allowGrowth()
get_images()

```",maxter2323,b'type:support',2020-09-21T10:08:06Z,2020-09-25T09:42:30Z,,,,,,,
9265,"reader.get_tensor() crashes with no Exception, how to fix it?","## Describe the bug

Im using an example  code of bert4keras with Tensorflow-gpu2.0.0 and CUDA10.0.
![image](https://user-images.githubusercontent.com/22270406/93542793-7dd3ed80-f98c-11ea-87e7-d3aac67baba1.png)
 When I use build_transform_model() the interpreter crashes with following error:
```
C:\Python35\python.exe D:/bert/test.py
2020-09-18 08:58:32.350829: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_100.dll
Using TensorFlow backend.
Tokenizer initial success!
Prepare to load model...
2020-09-18 08:58:35.506116: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library nvcuda.dll
2020-09-18 08:58:35.595480: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: GeForce GTX 1060 with Max-Q Design major: 6 minor: 1 memoryClockRate(GHz): 1.3415
pciBusID: 0000:01:00.0
2020-09-18 08:58:35.595743: I tensorflow/stream_executor/platform/default/dlopen_checker_stub.cc:25] GPU libraries are statically linked, skip dlopen check.
2020-09-18 08:58:35.596581: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
2020-09-18 08:58:35.596924: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2
2020-09-18 08:58:35.599880: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: GeForce GTX 1060 with Max-Q Design major: 6 minor: 1 memoryClockRate(GHz): 1.3415
pciBusID: 0000:01:00.0
2020-09-18 08:58:35.600136: I tensorflow/stream_executor/platform/default/dlopen_checker_stub.cc:25] GPU libraries are statically linked, skip dlopen check.
2020-09-18 08:58:35.601015: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
2020-09-18 08:58:36.214330: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-09-18 08:58:36.214497: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 
2020-09-18 08:58:36.214595: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N 
2020-09-18 08:58:36.215286: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 4708 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1060 with Max-Q Design, pci bus id: 0000:01:00.0, compute capability: 6.1)

Process finished with exit code -1073741819 (0xC0000005)
```
This error also created a .dmp file with over 700MB in windows crashdumps.
I traced this error and found it's tf.train.load_checkpoint() problem. I'm using the following code to analyze:
```
import tensorflow as tf
config_path = '../../chinese_L-12_H-768_A-12/bert_config.json'
checkpoint_path = '../../chinese_L-12_H-768_A-12/bert_model.ckpt'
dict_path = '../../chinese_L-12_H-768_A-12/vocab.txt'

reader=tf.train.load_checkpoint(checkpoint_path)
print(reader)
arr=reader.get_tensor(""bert/embeddings/word_embeddings"")
print(arr)
```
Unfortunately it crashes like this:
```
2020-09-18 09:10:19.136735: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_100.dll
Using TensorFlow backend.
<tensorflow.python.pywrap_tensorflow_internal.CheckpointReader; proxy of <Swig Object of type 'tensorflow::checkpoint::CheckpointReader *' at 0x000001653EEDA570> >
Process finished with exit code -1073741819 (0xC0000005)
```
Just want to know how can I successfully load the checkpoint file. Thanks in advance.
***
## System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- TensorFlow version (use command below):  Tensorflow-gpu-2.0.0
- Python version: Py35
- CUDA/cuDNN version: Cuda 10.0 cudnnv7.6.5.32
- GPU model and memory: GeForce GTX 1060 Max-Q Design 6GB",insomnia1996,b'models:official type:bug',2020-09-18T01:18:30Z,2020-09-21T03:02:27Z,,,,,,,
9263,How do I save and re-load a model after running the Colab Tutorial?,"# Prerequisites

Please answer the following questions for yourself before submitting an issue.

- [x] I am using the latest TensorFlow Model Garden release and TensorFlow 2.
- [x] I am reporting the issue to the correct repository. (Model Garden official or research directory)
- [x] I checked to make sure that this issue has not been filed already.

## 1. The entire URL of the file you are using

https://github.com/tensorflow/models/blob/master/research/object_detection/colab_tutorials/eager_few_shot_od_training_tf2_colab.ipynb

## 2. Describe the bug

I just want to save the model I trained and re-load it elsewhere. I can't use `model.save()` or anything. 

**I am not using anything custom. I just want to save the model resulting from running the Colab as it is.**",nicolas-gervais,b'models:research stalled stat:awaiting response type:bug',2020-09-17T12:43:38Z,2020-10-02T20:45:23Z,,,,,,,
9261,Object detection imports / error,"<!--
As per our GitHub Policy (https://github.com/tensorflow/models/blob/master/ISSUES.md), we only address code bugs, documentation issues, and feature requests on GitHub.

We will automatically close questions and help related issues.

Please go to Stack Overflow (http://stackoverflow.com/questions/tagged/tensorflow-model-garden) for questions and help.

-->
We want to do Object detection imports in jupyter.

I ran the following Python function, but I got an error

from utils import label_map_util

from utils import visualization_utils as vis_util

-------------------------------------------------- -------------------------
ModuleNotFoundError Traceback (most recent call last)
<ipython-input-3-aa270cd948af> in <module>
----> 1 from utils import label_map_util
       2
       3 from utils import visualization_utils as vis_util

ModuleNotFoundError: No module named'utils'

In the case of [No module named'utils'], I don't know which application to install.

Please help.
",YuByoungJoon,b'models:research type:support',2020-09-17T07:05:42Z,2020-09-25T05:11:08Z,,,,,,,
9260,"where can i find BERT-Base, Chinese model  ?","<!--
As per our GitHub Policy (https://github.com/tensorflow/models/blob/master/ISSUES.md), we only address code bugs, documentation issues, and feature requests on GitHub.

We will automatically close questions and help related issues.

Please go to Stack Overflow (http://stackoverflow.com/questions/tagged/tensorflow-model-garden) for questions and help.

-->

where can i find tf2.3 BERT-Base, Chinese model ? I want  BERT-Base, Chinese model  not Pretrained hub modules.",passion765,b'type:support',2020-09-17T06:46:53Z,2020-09-25T02:09:45Z,,,,,,,
9255,InvalidArgumentError: Index out of range using input dim 1; input has only 1 dims [Op:StridedSlice] name: strided_slice/,"# Prerequisites

Please answer the following questions for yourself before submitting an issue.

- [X] I am using the latest TensorFlow Model Garden release and TensorFlow 2.
- [X] I am reporting the issue to the correct repository. (Model Garden official or research directory)
- [X] I checked to make sure that this issue has not already been filed.

## 1. The entire URL of the file you are using
* The notebook: [Object Detection Tutorial Notebook](https://github.com/tensorflow/models/blob/master/research/object_detection/colab_tutorials/object_detection_tutorial.ipynb)

* The model used: http://download.tensorflow.org/models/object_detection/tf2/20200711/mask_rcnn_inception_resnet_v2_1024x1024_coco17_gpu-8.tar.gz

* The colab notebook that uses the same notebook and the model: [Colab Object Detection Tutorial Copy](https://colab.research.google.com/drive/1OUkIWVpaEnDaZL81Kmm2Jp5xd4fu45pK?usp=sharing)

## 2. Describe the bug
**Error Name** : InvalidArgumentError

**Error Description** : Index out of range using input dim 1; input has only 1 dims [Op:StridedSlice] name: strided_slice/

The code in the [Object Detection Tutorial Notebook](https://github.com/tensorflow/models/blob/master/research/object_detection/colab_tutorials/object_detection_tutorial.ipynb) successfully infers using object detection models but fails to infer using using Mask RCNN Inception Model and causes the above error. 

## 3. Steps to reproduce
Run the following Colab Notebook. It is same as the Object Detection Tutorial but is instead using Mask RCNN Inception Resnet v2 1024x1204 model. 

[Colab Object Detection Tutorial Copy](https://colab.research.google.com/drive/1OUkIWVpaEnDaZL81Kmm2Jp5xd4fu45pK?usp=sharing)

## 4. Expected behavior
Segmentation on the test images same the as the object detection on the test images in the notebook 

## 5. Additional context

The notebook crashes on the default segmentation model used in the [Object Detection Tutorial Notebook](https://github.com/tensorflow/models/blob/master/research/object_detection/colab_tutorials/object_detection_tutorial.ipynb) as well also models that have been further trained to segment or detect other objects

## 6. System information

All the work done was on Colab with GPU enabled

<!-- 
Collect system information using our environment capture script.
https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can also obtain the TensorFlow version with:

1. TensorFlow 1.0
`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

2. TensorFlow 2.0
`python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`
-->
",AliButtar,b'models:research type:bug',2020-09-16T13:48:39Z,2020-09-25T12:18:18Z,,,,,,,
9253,Adds Intel-optimized NLP and Recommender models to community README,"# Description

This PR adds the following Intel-optimized, TF2-compatible NLP and Recommender models to the community README:
- BERT
- GNMT
- Transformer-LT
- Wide & Deep

## Type of change

For a new feature or function, please create an issue first to discuss it
with us before submitting a pull request.

Note: Please delete options that are not relevant.

- [ ] Bug fix (non-breaking change which fixes an issue)
- [x] Documentation update
- [ ] TensorFlow 2 migration
- [ ] New feature (non-breaking change which adds functionality)
- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)
- [ ] A new research paper code implementation
- [ ] Other (Specify)

## Tests

> :memo: Please describe the tests that you ran to verify your changes.
>  
> * Provide instructions so we can reproduce.  
> * Please also list any relevant details for your test configuration.  

**Test Configuration**:

## Checklist

- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).
- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).
- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).
- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.
- [ ] I have commented my code, particularly in hard-to-understand areas.
- [x] I have made corresponding changes to the documentation.
- [x] My changes generate no new warnings.
- [ ] I have added tests that prove my fix is effective or that my feature works.
",mhbuehler,b'cla: yes stat:awaiting review',2020-09-15T21:43:51Z,2020-09-22T17:19:08Z,,,,,,,
9252,DELG: fix small typo on extractor.py,"# Description

Fix a small typo on DELG's extractor.py.

## Type of change

- [X] Bug fix (non-breaking change which fixes an issue)

## Tests

None. The typo wasn't a breaking issue, but an extra unnecessary `if` statement.

## Checklist

- [X] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).
- [X] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).
- [X] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).
- [X] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.
- [X] I have commented my code, particularly in hard-to-understand areas.
- [X] I have made corresponding changes to the documentation.
- [X] My changes generate no new warnings.
- [ ] I have added tests that prove my fix is effective or that my feature works.
",andrefaraujo,b'cla: yes',2020-09-15T16:50:57Z,2020-09-16T00:16:18Z,,,,,,,
9250,TF2 to TFLite: Restoring SavedModel freezes,"# Prerequisites

Please answer the following questions for yourself before submitting an issue.

- [Y] I am using the latest TensorFlow Model Garden release and TensorFlow 2.
- [Y] I am reporting the issue to the correct repository. (Model Garden official or research directory)
- [Y] I checked to make sure that this issue has not already been filed.

## 1. The entire URL of the file you are using

https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/running_on_mobile_tf2.md

## 2. Describe the bug

I'm trying to convert a TF2 model to TFLite.
I have downloaded ssd_resnet101_v1_fpn_640x640_coco17_tpu-8 from this link http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_resnet101_v1_fpn_640x640_coco17_tpu-8.tar.gz.

Using export_tflite_graph_tf2.py I have generated an intermediate SavedModel.
PB model is 9Mb ,  variables.data file is 125 Mb.
Too big to attach. (wetransfer link https://we.tl/t-vPUSTraLSV)


Next I'm trying to convert to TFLite using these two ways:

1. python script: 

converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)  
tflite_model = converter.convert()  -> code freezes here
with open('model.tflite', 'wb') as f:
        f.write(tflite_model)

2. tflite_convert command

In both cases the system freeze and the last log message is:

tensorflow/cc/saved_model/loader.cc:190] Restoring SavedModel bundle.

In case 1 code freezes here: tflite_model = converter.convert()

 Full logs:

2020-09-15 12:18:39.665457: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudart64_110.dll
2020-09-15 12:18:41.653614: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2020-09-15 12:18:41.654592: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library nvcuda.dll
2020-09-15 12:18:41.680174: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties:
pciBusID: 0000:01:00.0 name: Quadro RTX 4000 computeCapability: 7.5
coreClock: 1.545GHz coreCount: 36 deviceMemorySize: 8.00GiB deviceMemoryBandwidth: 387.49GiB/s
2020-09-15 12:18:41.680288: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudart64_110.dll
2020-09-15 12:18:41.685530: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cublas64_11.dll
2020-09-15 12:18:41.688669: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cufft64_10.dll
2020-09-15 12:18:41.690009: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library curand64_10.dll
2020-09-15 12:18:41.696408: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusolver64_10.dll
2020-09-15 12:18:41.698790: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusparse64_11.dll
2020-09-15 12:18:41.699572: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudnn64_8.dll
2020-09-15 12:18:41.699717: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2020-09-15 12:18:41.700121: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-09-15 12:18:41.769452: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties:
pciBusID: 0000:01:00.0 name: Quadro RTX 4000 computeCapability: 7.5
coreClock: 1.545GHz coreCount: 36 deviceMemorySize: 8.00GiB deviceMemoryBandwidth: 387.49GiB/s
2020-09-15 12:18:41.769588: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudart64_110.dll
2020-09-15 12:18:41.770786: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cublas64_11.dll
2020-09-15 12:18:41.777628: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cufft64_10.dll
2020-09-15 12:18:41.778754: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library curand64_10.dll
2020-09-15 12:18:41.779861: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusolver64_10.dll
2020-09-15 12:18:41.780981: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusparse64_11.dll
2020-09-15 12:18:41.782036: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudnn64_8.dll
2020-09-15 12:18:41.782948: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2020-09-15 12:18:42.224067: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-09-15 12:18:42.224194: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0
2020-09-15 12:18:42.225111: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N
2020-09-15 12:18:42.225779: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6625 MB memory) -> physical GPU (device: 0, name: Quadro RTX 4000, pci bus id: 0000:01:00.0, compute capability: 7.5)
2020-09-15 12:18:42.256543: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
loaded
2020-09-15 12:18:51.848846: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:315] Ignored output_format.
2020-09-15 12:18:51.849002: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:318] Ignored drop_control_dependency.
2020-09-15 12:18:51.850905: I tensorflow/cc/saved_model/reader.cc:32] Reading SavedModel from: ./saved_model
2020-09-15 12:18:51.919436: I tensorflow/cc/saved_model/reader.cc:55] Reading meta graph with tags { serve }
2020-09-15 12:18:51.919598: I tensorflow/cc/saved_model/reader.cc:93] Reading SavedModel debug info (if present) from: ./saved_model
2020-09-15 12:18:51.920771: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-09-15 12:18:51.927520: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]
2020-09-15 12:18:51.927824: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2020-09-15 12:18:52.156920: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:196] None of the MLIR optimization passes are enabled (registered 0 passes)
2020-09-15 12:18:52.188981: I tensorflow/cc/saved_model/loader.cc:190] Restoring SavedModel bundle.

 

## 6. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- TensorFlow installed from (source or binary): tf-nightly installed via pip
- TensorFlow version (use command below): 2.4.0-dev20200912
- Python version: python 3.7.3
- CUDA/cuDNN version: CUDA 11.0,2 - cuDNN 11.0 
- GPU model and memory: Quadro RTX 4000

",MediavoiceSrL,b'models:research stat:awaiting response type:bug',2020-09-15T10:38:44Z,2020-09-24T11:10:46Z,,,,,,,
9249,While training fasterRCNN with Tensoflow Object Detection API 2.(using a `tf.Tensor` as a Python `bool` is not allowed in Graph execution. Use Eager execution or decorate this function with @tf.function.),"**System information**
- OS Platform and Distribution: Linux Ubuntu 18.04
- TensorFlow installed from (source or binary): conda
- TensorFlow version (use command below): 2.2.0
- Python version: 3.6.10
- CUDA/cuDNN version: 10.1.243 / 7.6.5
- GPU model and memory: 1080ti 11GB

Command used to run training:
    python3 model_main_tf2.py     --pipeline_config_path=training/pipeline.config     --model_dir=training     --num_train_steps=10000     --sample_1_of_n_eval_examples=1     --alsologtostderr

Traceback:
2020-09-12 14:20:06.611317: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-12 14:20:07.902280: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2020-09-12 14:20:07.932835: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-09-12 14:20:07.933417: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.721GHz coreCount: 28 deviceMemorySize: 10.91GiB deviceMemoryBandwidth: 451.17GiB/s
2020-09-12 14:20:07.933439: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-12 14:20:07.934581: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-09-12 14:20:07.935660: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-09-12 14:20:07.935852: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-09-12 14:20:07.937035: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-09-12 14:20:07.937660: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-09-12 14:20:07.940093: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2020-09-12 14:20:07.940227: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-09-12 14:20:07.940860: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-09-12 14:20:07.941301: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2020-09-12 14:20:07.941543: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-09-12 14:20:07.945801: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 4200000000 Hz
2020-09-12 14:20:07.946049: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56548f8ff7c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-09-12 14:20:07.946060: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-09-12 14:20:08.017594: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-09-12 14:20:08.028832: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x565490ae2c00 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-09-12 14:20:08.028848: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce GTX 1080 Ti, Compute Capability 6.1
2020-09-12 14:20:08.029003: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-09-12 14:20:08.029293: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.721GHz coreCount: 28 deviceMemorySize: 10.91GiB deviceMemoryBandwidth: 451.17GiB/s
2020-09-12 14:20:08.029314: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-12 14:20:08.029341: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-09-12 14:20:08.029354: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-09-12 14:20:08.029367: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-09-12 14:20:08.029379: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-09-12 14:20:08.029392: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-09-12 14:20:08.029405: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2020-09-12 14:20:08.029445: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-09-12 14:20:08.029749: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-09-12 14:20:08.030020: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2020-09-12 14:20:08.030039: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-09-12 14:20:08.314944: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-09-12 14:20:08.314974: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 
2020-09-12 14:20:08.314995: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N 
2020-09-12 14:20:08.315166: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-09-12 14:20:08.315535: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-09-12 14:20:08.315849: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9866 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)
I0912 14:20:08.317715 140151783593792 mirrored_strategy.py:341] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)
INFO:tensorflow:Maybe overwriting train_steps: 10000
I0912 14:20:08.320816 140151783593792 config_util.py:552] Maybe overwriting train_steps: 10000
INFO:tensorflow:Maybe overwriting use_bfloat16: False
I0912 14:20:08.320905 140151783593792 config_util.py:552] Maybe overwriting use_bfloat16: False
WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.
W0912 14:20:08.454587 140151783593792 dataset_builder.py:83] num_readers has been reduced to 1 to match input file shards.
WARNING:tensorflow:From /home/convsys/anaconda3/envs/tf2/lib/python3.6/site-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_deterministic`.
W0912 14:20:08.457228 140151783593792 deprecation.py:323] From /home/convsys/anaconda3/envs/tf2/lib/python3.6/site-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_deterministic`.
WARNING:tensorflow:From /home/convsys/anaconda3/envs/tf2/lib/python3.6/site-packages/object_detection/builders/dataset_builder.py:175: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.map()
W0912 14:20:08.479154 140151783593792 deprecation.py:323] From /home/convsys/anaconda3/envs/tf2/lib/python3.6/site-packages/object_detection/builders/dataset_builder.py:175: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.map()
WARNING:tensorflow:AutoGraph could not transform <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f775eae7940>> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: module 'gast' has no attribute 'Constant'
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
W0912 14:20:08.549343 140151783593792 ag_logging.py:146] AutoGraph could not transform <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f775eae7940>> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: module 'gast' has no attribute 'Constant'
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
WARNING:tensorflow:AutoGraph could not transform <function train_input.<locals>.transform_and_pad_input_data_fn at 0x7f775eab3400> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: 'arguments' object has no attribute 'posonlyargs'
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
W0912 14:20:08.632742 140151783593792 ag_logging.py:146] AutoGraph could not transform <function train_input.<locals>.transform_and_pad_input_data_fn at 0x7f775eab3400> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: 'arguments' object has no attribute 'posonlyargs'
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
WARNING:tensorflow:From /home/convsys/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/util/dispatch.py:201: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.
W0912 14:20:08.635260 140151783593792 deprecation.py:323] From /home/convsys/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/util/dispatch.py:201: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.
Traceback (most recent call last):
  File ""/home/convsys/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py"", line 584, in converted_call
    converted_f = conversion.convert(target_entity, program_ctx)
  File ""/home/convsys/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/autograph/impl/conversion.py"", line 119, in convert
    entity, program_ctx.options, program_ctx, custom_vars)
  File ""/home/convsys/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/autograph/pyct/transpiler.py"", line 412, in transform_function
    extra_locals)
  File ""/home/convsys/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/autograph/pyct/transpiler.py"", line 373, in _transformed_factory
    nodes, ctx = self._transform_function(fn, user_context)
  File ""/home/convsys/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/autograph/pyct/transpiler.py"", line 339, in _transform_function
    node = self.transform_ast(node, context)
  File ""/home/convsys/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/autograph/impl/conversion.py"", line 70, in transform_ast
    node = activity.resolve(node, ctx, None)
  File ""/home/convsys/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/autograph/pyct/static_analysis/activity.py"", line 705, in resolve
    return ActivityAnalyzer(context, parent_scope).visit(node)
  File ""/home/convsys/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/autograph/pyct/transformer.py"", line 445, in visit
    result = super(Base, self).visit(node)
  File ""/home/convsys/anaconda3/envs/tf2/lib/python3.6/ast.py"", line 253, in visit
    return visitor(node)
  File ""/home/convsys/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/autograph/pyct/static_analysis/activity.py"", line 575, in visit_FunctionDef
    node = self._visit_arg_annotations(node)
  File ""/home/convsys/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/autograph/pyct/static_analysis/activity.py"", line 551, in _visit_arg_annotations
    node = self._visit_arg_declarations(node)
  File ""/home/convsys/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/autograph/pyct/static_analysis/activity.py"", line 556, in _visit_arg_declarations
    node.args.posonlyargs = self._visit_node_list(node.args.posonlyargs)
AttributeError: 'arguments' object has no attribute 'posonlyargs'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""model_main_tf2.py"", line 113, in <module>
    tf.compat.v1.app.run()
  File ""/home/convsys/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/platform/app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""/home/convsys/anaconda3/envs/tf2/lib/python3.6/site-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/home/convsys/anaconda3/envs/tf2/lib/python3.6/site-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""model_main_tf2.py"", line 110, in main
    record_summaries=FLAGS.record_summaries)
  File ""/home/convsys/anaconda3/envs/tf2/lib/python3.6/site-packages/object_detection/model_lib_v2.py"", line 526, in train_loop
    train_dataset_fn)
  File ""/home/convsys/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/distribute/distribute_lib.py"", line 1128, in experimental_distribute_datasets_from_function
    dataset_fn, options)
  File ""/home/convsys/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/distribute/mirrored_strategy.py"", line 503, in _experimental_distribute_datasets_from_function
    self._container_strategy())
  File ""/home/convsys/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/distribute/input_lib.py"", line 136, in get_distributed_datasets_from_function
    strategy)
  File ""/home/convsys/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/distribute/input_lib.py"", line 1183, in __init__
    dataset_fn))
  File ""/home/convsys/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/distribute/input_lib.py"", line 1767, in _create_datasets_per_worker_with_input_context
    dataset = dataset_fn(ctx)
  File ""/home/convsys/anaconda3/envs/tf2/lib/python3.6/site-packages/object_detection/model_lib_v2.py"", line 521, in train_dataset_fn
    input_context=input_context)
  File ""/home/convsys/anaconda3/envs/tf2/lib/python3.6/site-packages/object_detection/inputs.py"", line 838, in train_input
    reduce_to_frame_fn=reduce_to_frame_fn)
  File ""/home/convsys/anaconda3/envs/tf2/lib/python3.6/site-packages/object_detection/builders/dataset_builder.py"", line 196, in build
    batch_size, input_reader_config)
  File ""/home/convsys/anaconda3/envs/tf2/lib/python3.6/site-packages/object_detection/builders/dataset_builder.py"", line 175, in dataset_map_fn
    fn_to_map, num_parallel_calls=num_parallel_calls)
  File ""/home/convsys/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py"", line 324, in new_func
    return func(*args, **kwargs)
  File ""/home/convsys/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py"", line 2564, in map_with_legacy_function
    use_legacy_function=True))
  File ""/home/convsys/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py"", line 4084, in __init__
    use_legacy_function=use_legacy_function)
  File ""/home/convsys/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py"", line 3339, in __init__
    self._function.add_to_graph(ops.get_default_graph())
  File ""/home/convsys/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/framework/function.py"", line 544, in add_to_graph
    self._create_definition_if_needed()
  File ""/home/convsys/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/framework/function.py"", line 376, in _create_definition_if_needed
    self._create_definition_if_needed_impl()
  File ""/home/convsys/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/framework/function.py"", line 407, in _create_definition_if_needed_impl
    capture_resource_var_by_value=self._capture_resource_var_by_value)
  File ""/home/convsys/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/framework/function.py"", line 969, in func_graph_from_py_func
    outputs = func(*func_graph.inputs)
  File ""/home/convsys/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py"", line 3331, in wrapper_fn
    ret = _wrapper_helper(*args)
  File ""/home/convsys/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py"", line 3299, in _wrapper_helper
    ret = autograph.tf_convert(func, ag_ctx)(*nested_args)
  File ""/home/convsys/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py"", line 255, in wrapper
    return converted_call(f, args, kwargs, options=options)
  File ""/home/convsys/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py"", line 591, in converted_call
    return _fall_back_unconverted(f, args, kwargs, options, e)
  File ""/home/convsys/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py"", line 398, in _fall_back_unconverted
    return _call_unconverted(f, args, kwargs, options)
  File ""/home/convsys/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py"", line 339, in _call_unconverted
    return f(*args, **kwargs)
  File ""/home/convsys/anaconda3/envs/tf2/lib/python3.6/site-packages/object_detection/inputs.py"", line 819, in transform_and_pad_input_data_fn
    tensor_dict=transform_data_fn(tensor_dict),
  File ""/home/convsys/anaconda3/envs/tf2/lib/python3.6/site-packages/object_detection/inputs.py"", line 249, in transform_input_data
    out_tensor_dict = data_augmentation_fn(out_tensor_dict)
  File ""/home/convsys/anaconda3/envs/tf2/lib/python3.6/site-packages/object_detection/inputs.py"", line 577, in augment_input_data
    include_dense_pose=include_dense_pose))
  File ""/home/convsys/anaconda3/envs/tf2/lib/python3.6/site-packages/object_detection/core/preprocessor.py"", line 4591, in preprocess
    results = func(*args, **params)
  File ""/home/convsys/anaconda3/envs/tf2/lib/python3.6/site-packages/object_detection/core/preprocessor.py"", line 4093, in random_square_crop_by_scale
    if ymin == 0:
  File ""/home/convsys/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 877, in __bool__
    self._disallow_bool_casting()
  File ""/home/convsys/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 490, in _disallow_bool_casting
    self._disallow_in_graph_mode(""using a `tf.Tensor` as a Python `bool`"")
  File ""/home/convsys/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 479, in _disallow_in_graph_mode
    "" this function with @tf.function."".format(task))
tensorflow.python.framework.errors_impl.OperatorNotAllowedInGraphError: using a `tf.Tensor` as a Python `bool` is not allowed in Graph execution. Use Eager execution or decorate this function with @tf.function.

Config File
`

model {
  faster_rcnn {
    num_classes: 33
    image_resizer {
      keep_aspect_ratio_resizer {
        min_dimension: 800
        max_dimension: 1333
        pad_to_max_dimension: true
      }
    }
    feature_extractor {
      type: 'faster_rcnn_resnet101_keras'
    }
    first_stage_anchor_generator {
      grid_anchor_generator {
        scales: [0.25, 0.5, 1.0, 2.0]
        aspect_ratios: [0.5, 1.0, 2.0]
        height_stride: 16
        width_stride: 16
      }
    }
    first_stage_box_predictor_conv_hyperparams {
      op: CONV
      regularizer {
        l2_regularizer {
          weight: 0.0
        }
      }
      initializer {
        truncated_normal_initializer {
          stddev: 0.01
        }
      }
    }
    first_stage_nms_score_threshold: 0.0
    first_stage_nms_iou_threshold: 0.7
    first_stage_max_proposals: 300
    first_stage_localization_loss_weight: 2.0
    first_stage_objectness_loss_weight: 1.0
    initial_crop_size: 14
    maxpool_kernel_size: 2
    maxpool_stride: 2
    second_stage_box_predictor {
      mask_rcnn_box_predictor {
        use_dropout: false
        dropout_keep_probability: 1.0
        fc_hyperparams {
          op: FC
          regularizer {
            l2_regularizer {
              weight: 0.0
            }
          }
          initializer {
            variance_scaling_initializer {
              factor: 1.0
              uniform: true
              mode: FAN_AVG
            }
          }
        }
      }
    }
    second_stage_post_processing {
      batch_non_max_suppression {
        score_threshold: 0.0
        iou_threshold: 0.6
        max_detections_per_class: 100
        max_total_detections: 100
      }
      score_converter: SOFTMAX
    }
    second_stage_localization_loss_weight: 2.0
    second_stage_classification_loss_weight: 1.0
  }
}

train_config: {
  batch_size: 4
  num_steps: 200000
  optimizer {
    momentum_optimizer: {
      learning_rate: {
        cosine_decay_learning_rate {
          learning_rate_base: 0.01
          total_steps: 200000
          warmup_learning_rate: 0.0
          warmup_steps: 5000
        }
      }
      momentum_optimizer_value: 0.9
    }
    use_moving_average: false
  }
  gradient_clipping_by_norm: 10.0
  fine_tune_checkpoint_version: V2
  fine_tune_checkpoint: ""/media/convsys/c924758e-a96b-40c5-86de-4d47f53b16db/models-master/research/object_detection/faster_rcnn_resnet101_v1_800x1333_coco17_gpu-8/checkpoint/ckpt-0""
  fine_tune_checkpoint_type: ""classification""
  data_augmentation_options {
    random_horizontal_flip {
    }
  }

  data_augmentation_options {
    random_adjust_hue {
    }
  }

  data_augmentation_options {
    random_adjust_contrast {
    }
  }

  data_augmentation_options {
    random_adjust_saturation {
    }
  }

  data_augmentation_options {
     random_square_crop_by_scale {
      scale_min: 0.6
      scale_max: 1.3
    }
  }
}

train_input_reader: {
  label_map_path: ""training/fashion.pbtxt""
  tf_record_input_reader {
    input_path: ""training/train.record""
  }
}

eval_config: {
  metrics_set: ""coco_detection_metrics""
  use_moving_averages: false
  batch_size: 1;
}

eval_input_reader: {
  label_map_path: ""training/fashion.pbtxt""
  shuffle: false
  num_epochs: 1
  tf_record_input_reader {
    input_path: ""training/test.record""
  }
}`

",danial880,b'models:research type:support',2020-09-15T09:25:41Z,2020-09-18T12:59:15Z,,,,,,,
9242,UnicodeDecodeError: 'utf-8' codec can't decode byte 0xbe in position 135: invalid start byte,"I want to train with mask_rcnn. In order to train on multiple GPUs for win10, I added some code to the main.py line 89
`strategy = tf.distribute.MirroredStrategy(devices=[""/gpu:0"", ""/gpu:1""],
                                            cross_device_ops=tf.distribute.HierarchicalCopyAllReduce())
`
Then the program reported an error, and I tried the solution, but couldn't find anything in the Official directory to change
[https://github.com/tensorflow/models/issues/4082#issuecomment-404763408](url)
[https://github.com/tensorflow/models/issues/5857#issuecomment-447764871](url)


tf-models-nightly                  2.3.0.dev20200913
tf-models-official                 2.3.0
tf-nightly                         2.4.0.dev20200910
tensorflow                         2.3.0

> python official/vision/detection/main.py --strategy_type=mirrored --num_gpus=4 --model_dir=model_dir --mode=train --model=mask_rcnn --config_file=""my_maskrcnn.yaml""
2020-09-14 20:52:45.831075: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found
2020-09-14 20:52:45.837565: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
I0914 20:52:49.855386 22692 main.py:211] Model Parameters: {'anchor': {'anchor_size': 8,
            'aspect_ratios': [1.0, 2.0, 0.5],
            'num_scales': 1},
 'architecture': {'backbone': 'resnet',
                  'include_mask': True,
                  'mask_target_size': 28,
                  'max_level': 6,
                  'min_level': 2,
                  'multilevel_features': 'fpn',
                  'num_classes': 91,
                  'parser': 'maskrcnn_parser',
                  'use_bfloat16': False},
 'enable_summary': False,
 'eval': {'batch_size': 8,
          'eval_dataset_type': 'tfrecord',
          'eval_file_pattern': 'D:\\cwge\\models\\train\\obj-TFRecords-export',
          'eval_samples': 5000,
          'eval_timeout': None,
          'input_sharding': True,
          'min_eval_interval': 180,
          'num_images_to_visualize': 0,
          'num_steps_per_eval': 1000,
          'type': 'box_and_mask',
          'use_json_file': True,
          'val_json_file': 'D:\\cwge\\models\\train'},
 'fpn': {'fpn_feat_dims': 256,
         'use_batch_norm': True,
         'use_separable_conv': False},
 'frcnn_box_loss': {'huber_loss_delta': 1.0},
 'frcnn_head': {'fc_dims': 1024,
                'num_convs': 0,
                'num_fcs': 2,
                'num_filters': 256,
                'use_batch_norm': False,
                'use_separable_conv': False},
 'isolate_session_state': False,
 'mask_sampling': {'num_mask_samples_per_image': 128},
 'maskrcnn_parser': {'aug_rand_hflip': True,
                     'aug_scale_max': 1.0,
                     'aug_scale_min': 1.0,
                     'mask_crop_size': 112,
                     'max_num_instances': 100,
                     'num_channels': 3,
                     'output_size': [1024, 1024],
                     'rpn_batch_size_per_im': 256,
                     'rpn_fg_fraction': 0.5,
                     'rpn_match_threshold': 0.7,
                     'rpn_unmatched_threshold': 0.3,
                     'skip_crowd_during_training': True},
 'model_dir': 'model_dir',
 'mrcnn_head': {'num_convs': 4,
                'num_filters': 256,
                'use_batch_norm': False,
                'use_separable_conv': False},
 'norm_activation': {'activation': 'relu',
                     'batch_norm_epsilon': 0.0001,
                     'batch_norm_momentum': 0.997,
                     'batch_norm_trainable': True,
                     'use_sync_bn': False},
 'postprocess': {'max_total_size': 100,
                 'nms_iou_threshold': 0.5,
                 'pre_nms_num_boxes': 1000,
                 'score_threshold': 0.05,
                 'use_batched_nms': False},
 'predict': {'batch_size': 8},
 'resnet': {'resnet_depth': 50},
 'roi_proposal': {'rpn_min_size_threshold': 0.0,
                  'rpn_nms_threshold': 0.7,
                  'rpn_post_nms_top_k': 1000,
                  'rpn_pre_nms_top_k': 2000,
                  'rpn_score_threshold': 0.0,
                  'test_rpn_min_size_threshold': 0.0,
                  'test_rpn_nms_threshold': 0.7,
                  'test_rpn_post_nms_top_k': 1000,
                  'test_rpn_pre_nms_top_k': 1000,
                  'test_rpn_score_threshold': 0.0,
                  'use_batched_nms': False},
 'roi_sampling': {'bg_iou_thresh_hi': 0.5,
                  'bg_iou_thresh_lo': 0.0,
                  'fg_fraction': 0.25,
                  'fg_iou_thresh': 0.5,
                  'mix_gt_boxes': True,
                  'num_samples_per_image': 512},
 'rpn_box_loss': {'huber_loss_delta': 0.1111111111111111},
 'rpn_head': {'num_convs': 2,
              'num_filters': 256,
              'use_batch_norm': False,
              'use_separable_conv': False},
 'rpn_score_loss': {'rpn_batch_size_per_im': 256},
 'spinenet': {'model_id': '49'},
 'strategy_config': {'all_reduce_alg': None,
                     'distribution_strategy': 'mirrored',
                     'num_gpus': 4,
                     'num_packs': 1,
                     'task_index': -1,
                     'tpu': None,
                     'worker_hosts': None},
 'strategy_type': 'mirrored',
 'train': {'batch_size': 64,
           'checkpoint': {'path': '', 'prefix': ''},
           'frozen_variable_prefix': '',
           'gradient_clip_norm': 0.0,
           'input_partition_dims': None,
           'input_sharding': False,
           'iterations_per_loop': 100,
           'l2_weight_decay': 0.0001,
           'learning_rate': {'init_learning_rate': 0.08,
                             'learning_rate_levels': [0.008, 0.0008],
                             'learning_rate_steps': [15000, 20000],
                             'type': 'step',
                             'warmup_learning_rate': 0.0067,
                             'warmup_steps': 500},
           'num_cores_per_replica': None,
           'optimizer': {'momentum': 0.9, 'nesterov': True, 'type': 'momentum'},
           'regularization_variable_regex': '.*(kernel|weight):0$',
           'total_steps': 22500,
           'train_dataset_type': 'tfrecord',
           'train_file_pattern': 'D:\\cwge\\models\\train\\obj-TFRecords-export',
           'transpose_input': False},
 'type': 'mask_rcnn',
 'use_tpu': False}
I0914 20:52:49.948356 22692 losses.py:152] RpnBoxLoss huber_loss_delta 0.1111111111111111
I0914 20:52:49.956354 22692 losses.py:244] FastrcnnBoxLoss huber_loss_delta 1.0
2020-09-14 20:52:49.959090: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2020-09-14 20:52:49.964820: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library nvcuda.dll
2020-09-14 20:52:50.044086: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties:
pciBusID: 0000:02:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 11.00GiB deviceMemoryBandwidth: 451.17GiB/s
2020-09-14 20:52:50.058631: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 1 with properties:
pciBusID: 0000:03:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 11.00GiB deviceMemoryBandwidth: 451.17GiB/s
2020-09-14 20:52:50.071219: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 2 with properties:
pciBusID: 0000:82:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 11.00GiB deviceMemoryBandwidth: 451.17GiB/s
2020-09-14 20:52:50.086335: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 3 with properties:
pciBusID: 0000:83:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 11.00GiB deviceMemoryBandwidth: 451.17GiB/s
2020-09-14 20:52:50.099883: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found
2020-09-14 20:52:50.108890: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'cublas64_11.dll'; dlerror: cublas64_11.dll not found
2020-09-14 20:52:50.136729: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cufft64_10.dll
2020-09-14 20:52:50.155330: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library curand64_10.dll
2020-09-14 20:52:50.183535: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusolver64_10.dll
2020-09-14 20:52:50.190137: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'cusparse64_11.dll'; dlerror: cusparse64_11.dll not found
2020-09-14 20:52:50.196780: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudnn64_8.dll
2020-09-14 20:52:50.202229: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1753] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2020-09-14 20:52:50.234220: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-09-14 20:52:50.254524: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-09-14 20:52:50.270592: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]
2020-09-14 20:52:50.274777: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
WARNING:tensorflow:Some requested devices in `tf.distribute.Strategy` are not visible to TensorFlow: /job:localhost/replica:0/task:0/device:GPU:1,/job:localhost/replica:0/task:0/device:GPU:3,/job:localhost/replica:0/task:0/device:GPU:2,/job:localhost/replica:0/task:0/device:GPU:0
W0914 20:52:50.291249 22692 cross_device_ops.py:1173] Some requested devices in `tf.distribute.Strategy` are not visible to TensorFlow: /job:localhost/replica:0/task:0/device:GPU:1,/job:localhost/replica:0/task:0/device:GPU:3,/job:localhost/replica:0/task:0/device:GPU:2,/job:localhost/replica:0/task:0/device:GPU:0
INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')
I0914 20:52:50.293247 22692 mirrored_strategy.py:347] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')
INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')
I0914 20:52:50.297248 22692 mirrored_strategy.py:347] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')
I0914 20:52:50.298247 22692 main.py:101] Train num_replicas_in_sync 2 num_workers 1 is_multi_host False
W0914 20:52:50.300244 22692 distributed_executor.py:381] It is sematically wrong to run callbacks when iterations_per_loop is not one (100)
I0914 20:52:50.301245 22692 distributed_executor.py:181] Save config to model_dir model_dir.
WARNING:tensorflow:From C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\util\deprecation.py:574: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Use fn_output_signature instead
W0914 20:52:51.157972 22692 deprecation.py:506] From C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\util\deprecation.py:574: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Use fn_output_signature instead
2020-09-14 20:52:59.444012: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 1)
WARNING:tensorflow:`tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.
W0914 20:53:00.796903 22692 backend.py:428] `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.
INFO:tensorflow:batch_all_reduce: 1 all-reduces with algorithm = hierarchical_copy, num_packs = 1
I0914 20:53:00.833891 22692 cross_device_ops.py:742] batch_all_reduce: 1 all-reduces with algorithm = hierarchical_copy, num_packs = 1
INFO:tensorflow:batch_all_reduce: 1 all-reduces with algorithm = hierarchical_copy, num_packs = 1
I0914 20:53:00.837890 22692 cross_device_ops.py:742] batch_all_reduce: 1 all-reduces with algorithm = hierarchical_copy, num_packs = 1
INFO:tensorflow:batch_all_reduce: 1 all-reduces with algorithm = hierarchical_copy, num_packs = 1
I0914 20:53:00.843889 22692 cross_device_ops.py:742] batch_all_reduce: 1 all-reduces with algorithm = hierarchical_copy, num_packs = 1
INFO:tensorflow:batch_all_reduce: 1 all-reduces with algorithm = hierarchical_copy, num_packs = 1
I0914 20:53:00.849885 22692 cross_device_ops.py:742] batch_all_reduce: 1 all-reduces with algorithm = hierarchical_copy, num_packs = 1
INFO:tensorflow:batch_all_reduce: 1 all-reduces with algorithm = hierarchical_copy, num_packs = 1
I0914 20:53:00.866881 22692 cross_device_ops.py:742] batch_all_reduce: 1 all-reduces with algorithm = hierarchical_copy, num_packs = 1
INFO:tensorflow:batch_all_reduce: 1 all-reduces with algorithm = hierarchical_copy, num_packs = 1
I0914 20:53:00.897871 22692 cross_device_ops.py:742] batch_all_reduce: 1 all-reduces with algorithm = hierarchical_copy, num_packs = 1
INFO:tensorflow:batch_all_reduce: 1 all-reduces with algorithm = hierarchical_copy, num_packs = 1
I0914 20:53:00.970848 22692 cross_device_ops.py:742] batch_all_reduce: 1 all-reduces with algorithm = hierarchical_copy, num_packs = 1
INFO:tensorflow:batch_all_reduce: 1 all-reduces with algorithm = hierarchical_copy, num_packs = 1
I0914 20:53:00.975848 22692 cross_device_ops.py:742] batch_all_reduce: 1 all-reduces with algorithm = hierarchical_copy, num_packs = 1
INFO:tensorflow:batch_all_reduce: 1 all-reduces with algorithm = hierarchical_copy, num_packs = 1
I0914 20:53:00.981844 22692 cross_device_ops.py:742] batch_all_reduce: 1 all-reduces with algorithm = hierarchical_copy, num_packs = 1
INFO:tensorflow:batch_all_reduce: 1 all-reduces with algorithm = hierarchical_copy, num_packs = 1
I0914 20:53:00.984845 22692 cross_device_ops.py:742] batch_all_reduce: 1 all-reduces with algorithm = hierarchical_copy, num_packs = 1
I0914 20:54:39.201575 22692 distributed_executor.py:434] Checkpoint file model_dir\ctl_step_0.ckpt-1 found and restoring from checkpoint
WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.

Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.core.Dense object at 0x0000024A824D2A20> and <tensorflow.python.keras.engine.base_layer.TensorFlowOpLayer object at 0x0000024B0835D390>).
W0914 20:56:51.118577 22692 base.py:320] Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.

Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.core.Dense object at 0x0000024A824D2A20> and <tensorflow.python.keras.engine.base_layer.TensorFlowOpLayer object at 0x0000024B0835D390>).
WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.

Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.core.Dense object at 0x0000024A824D2C50> and <tensorflow.python.keras.engine.base_layer.TensorFlowOpLayer object at 0x0000024B08DC45F8>).
W0914 20:56:51.325511 22692 base.py:320] Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.

Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.core.Dense object at 0x0000024A824D2C50> and <tensorflow.python.keras.engine.base_layer.TensorFlowOpLayer object at 0x0000024B08DC45F8>).
WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.

Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.core.Dense object at 0x0000024A824F30F0> and <tensorflow.python.keras.engine.base_layer.TensorFlowOpLayer object at 0x0000024B09189EB8>).
W0914 20:56:51.513483 22692 base.py:320] Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.

Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.core.Dense object at 0x0000024A824F30F0> and <tensorflow.python.keras.engine.base_layer.TensorFlowOpLayer object at 0x0000024B09189EB8>).
WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.

Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.core.Dense object at 0x0000024A824D2EF0> and <tensorflow.python.keras.engine.base_layer.TensorFlowOpLayer object at 0x0000024B08973080>).
W0914 20:56:59.484933 22692 base.py:320] Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.

Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.core.Dense object at 0x0000024A824D2EF0> and <tensorflow.python.keras.engine.base_layer.TensorFlowOpLayer object at 0x0000024B08973080>).
WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.

Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x0000024A824F33C8> and <tensorflow.python.keras.engine.base_layer.TensorFlowOpLayer object at 0x0000024B4B7C8208>).
W0914 21:00:08.138855 22692 base.py:320] Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.

Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x0000024A824F33C8> and <tensorflow.python.keras.engine.base_layer.TensorFlowOpLayer object at 0x0000024B4B7C8208>).
WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.

Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x0000024A824F3550> and <tensorflow.python.keras.engine.base_layer.TensorFlowOpLayer object at 0x0000024B4B81C828>).
W0914 21:00:22.576261 22692 base.py:320] Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.

Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x0000024A824F3550> and <tensorflow.python.keras.engine.base_layer.TensorFlowOpLayer object at 0x0000024B4B81C828>).
WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.

Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x0000024A824F36D8> and <tensorflow.python.keras.engine.base_layer.TensorFlowOpLayer object at 0x0000024B4D497C18>).
W0914 21:00:36.712757 22692 base.py:320] Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.

Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x0000024A824F36D8> and <tensorflow.python.keras.engine.base_layer.TensorFlowOpLayer object at 0x0000024B4D497C18>).
WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.

Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x0000024A824F3860> and <tensorflow.python.keras.engine.base_layer.TensorFlowOpLayer object at 0x0000024B4B715AC8>).
W0914 21:00:57.225227 22692 base.py:320] Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.

Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x0000024A824F3860> and <tensorflow.python.keras.engine.base_layer.TensorFlowOpLayer object at 0x0000024B4B715AC8>).
WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.

Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.convolutional.Conv2DTranspose object at 0x0000024A824F3B00> and <tensorflow.python.keras.engine.base_layer.TensorFlowOpLayer object at 0x0000024B4ABED240>).
W0914 21:01:11.759604 22692 base.py:320] Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.

Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.convolutional.Conv2DTranspose object at 0x0000024A824F3B00> and <tensorflow.python.keras.engine.base_layer.TensorFlowOpLayer object at 0x0000024B4ABED240>).
WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.

Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x0000024B4A738160> and <tensorflow.python.keras.engine.base_layer.TensorFlowOpLayer object at 0x0000024B4ABED320>).
W0914 21:01:26.223995 22692 base.py:320] Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.

Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x0000024B4A738160> and <tensorflow.python.keras.engine.base_layer.TensorFlowOpLayer object at 0x0000024B4ABED320>).
I0914 21:01:35.866925 22692 distributed_executor.py:438] Loading from checkpoint file completed. Init step 0
I0914 21:01:36.035874 22692 detection_executor.py:65] Filter trainable variables from 213 to 213
E0914 21:01:36.036876 22692 detection_executor.py:71] Detection: train metric is not an instance of tf.keras.metrics.Metric.
I0914 21:01:36.038870 22692 distributed_executor.py:485] Training started
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0', '/job:localhost/replica:0/task:0/device:CPU:0').
I0914 21:02:06.800077 22692 cross_device_ops.py:477] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0', '/job:localhost/replica:0/task:0/device:CPU:0').
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0', '/job:localhost/replica:0/task:0/device:CPU:0').
I0914 21:02:06.806080 22692 cross_device_ops.py:477] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0', '/job:localhost/replica:0/task:0/device:CPU:0').
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0', '/job:localhost/replica:0/task:0/device:CPU:0').
I0914 21:02:06.810074 22692 cross_device_ops.py:477] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0', '/job:localhost/replica:0/task:0/device:CPU:0').
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0', '/job:localhost/replica:0/task:0/device:CPU:0').
I0914 21:02:06.816072 22692 cross_device_ops.py:477] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0', '/job:localhost/replica:0/task:0/device:CPU:0').
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0', '/job:localhost/replica:0/task:0/device:CPU:0').
I0914 21:02:06.820072 22692 cross_device_ops.py:477] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0', '/job:localhost/replica:0/task:0/device:CPU:0').
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0', '/job:localhost/replica:0/task:0/device:CPU:0').
I0914 21:02:06.825071 22692 cross_device_ops.py:477] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0', '/job:localhost/replica:0/task:0/device:CPU:0').
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0', '/job:localhost/replica:0/task:0/device:CPU:0').
I0914 21:02:06.829073 22692 cross_device_ops.py:477] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0', '/job:localhost/replica:0/task:0/device:CPU:0').
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0', '/job:localhost/replica:0/task:0/device:CPU:0').
I0914 21:02:06.832066 22692 cross_device_ops.py:477] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0', '/job:localhost/replica:0/task:0/device:CPU:0').
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0', '/job:localhost/replica:0/task:0/device:CPU:0').
I0914 21:02:06.845062 22692 cross_device_ops.py:477] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0', '/job:localhost/replica:0/task:0/device:CPU:0').
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0', '/job:localhost/replica:0/task:0/device:CPU:0').
I0914 21:02:06.848064 22692 cross_device_ops.py:477] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0', '/job:localhost/replica:0/task:0/device:CPU:0').
Traceback (most recent call last):
  File ""official/vision/detection/main.py"", line 264, in <module>
    app.run(main)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\absl\app.py"", line 300, in run
    _run_main(main, args)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\absl\app.py"", line 251, in _run_main
    sys.exit(main(argv))
  File ""official/vision/detection/main.py"", line 259, in main
    run()
  File ""official/vision/detection/main.py"", line 253, in run
    callbacks=callbacks)
  File ""official/vision/detection/main.py"", line 125, in run_executor
    save_config=True)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\official\modeling\training\distributed_executor.py"", line 492, in train
    tf.convert_to_tensor(num_steps, dtype=tf.int32))
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\eager\def_function.py"", line 787, in __call__
    result = self._call(*args, **kwds)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\eager\def_function.py"", line 847, in _call
    return self._stateless_fn(*args, **kwds)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\eager\function.py"", line 2929, in __call__
    filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\eager\function.py"", line 1920, in _call_flat
    ctx, args, cancellation_manager=cancellation_manager))
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\eager\function.py"", line 561, in call
    ctx=ctx)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\eager\execute.py"", line 60, in quick_execute
    inputs, attrs, num_outputs)
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xbe in position 135: invalid start byte",x12901,b'models:official type:bug',2020-09-14T13:13:18Z,2020-09-22T03:39:31Z,,,,,,,
9239, No OpKernel was registered to support Op 'NcclAllReduce',"I'm trying to train my model using mask_rcnn, but it's reporting an error.
`python official/vision/detection/main.py --strategy_type=mirrored --num_gpus=4 --model_dir=model_dir --mode=train --model=mask_rcnn --config_file=""my_maskrcnn.yaml""`
I tried training with 1 GPU and it didn't work.
`python official/vision/detection/main.py --strategy_type=one_device --num_gpus=1 --model_dir=model_dir --mode=train --model=mask_rcnn --config_file=""my_maskrcnn.yaml""`
I inquired about other solutions, upgraded my cuda. tried again and still no training success!
cuda   10.1
cudnn 8.0.3
tensorflow 2.3.0

> python official/vision/detection/main.py --strategy_type=mirrored --num_gpus=4 --model_dir=model_dir --mode=train --model=mask_rcnn --config_file=""my_maskrcnn.yaml""
2020-09-14 14:03:59.248261: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudart64_101.dll
C:\ProgramData\Anaconda3\lib\site-packages\official\modeling\hyperparams\params_dict.py:431: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  params_dict = yaml.load(dict_or_string_or_yaml_file)
C:\ProgramData\Anaconda3\lib\site-packages\official\modeling\hyperparams\params_dict.py:436: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  params.override(yaml.load(f), is_strict)
I0914 14:04:01.670982 14292 main.py:219] Model Parameters: {'anchor': {'anchor_size': 8,
            'aspect_ratios': [1.0, 2.0, 0.5],
            'num_scales': 1},
 'architecture': {'backbone': 'resnet',
                  'include_mask': True,
                  'mask_target_size': 28,
                  'max_level': 6,
                  'min_level': 2,
                  'multilevel_features': 'fpn',
                  'num_classes': 91,
                  'parser': 'maskrcnn_parser',
                  'use_bfloat16': False},
 'enable_summary': False,
 'eval': {'batch_size': 8,
          'eval_dataset_type': 'tfrecord',
          'eval_file_pattern': 'D:\\cwge\\models\\train\\obj-TFRecords-export',
          'eval_samples': 5000,
          'eval_timeout': None,
          'input_sharding': True,
          'min_eval_interval': 180,
          'num_images_to_visualize': 0,
          'num_steps_per_eval': 1000,
          'type': 'box_and_mask',
          'use_json_file': True,
          'val_json_file': 'D:\\cwge\\models\\train'},
 'fpn': {'fpn_feat_dims': 256,
         'use_batch_norm': True,
         'use_separable_conv': False},
 'frcnn_box_loss': {'huber_loss_delta': 1.0},
 'frcnn_head': {'fc_dims': 1024,
                'num_convs': 0,
                'num_fcs': 2,
                'num_filters': 256,
                'use_batch_norm': False,
                'use_separable_conv': False},
 'isolate_session_state': False,
 'mask_sampling': {'num_mask_samples_per_image': 128},
 'maskrcnn_parser': {'aug_rand_hflip': True,
                     'aug_scale_max': 1.0,
                     'aug_scale_min': 1.0,
                     'mask_crop_size': 112,
                     'max_num_instances': 100,
                     'num_channels': 3,
                     'output_size': [1024, 1024],
                     'rpn_batch_size_per_im': 256,
                     'rpn_fg_fraction': 0.5,
                     'rpn_match_threshold': 0.7,
                     'rpn_unmatched_threshold': 0.3,
                     'skip_crowd_during_training': True},
 'model_dir': 'model_dir',
 'mrcnn_head': {'num_convs': 4,
                'num_filters': 256,
                'use_batch_norm': False,
                'use_separable_conv': False},
 'norm_activation': {'activation': 'relu',
                     'batch_norm_epsilon': 0.0001,
                     'batch_norm_momentum': 0.997,
                     'batch_norm_trainable': True,
                     'use_sync_bn': False},
 'postprocess': {'max_total_size': 100,
                 'nms_iou_threshold': 0.5,
                 'pre_nms_num_boxes': 1000,
                 'score_threshold': 0.05,
                 'use_batched_nms': False},
 'predict': {'batch_size': 8},
 'resnet': {'resnet_depth': 50},
 'roi_proposal': {'rpn_min_size_threshold': 0.0,
                  'rpn_nms_threshold': 0.7,
                  'rpn_post_nms_top_k': 1000,
                  'rpn_pre_nms_top_k': 2000,
                  'rpn_score_threshold': 0.0,
                  'test_rpn_min_size_threshold': 0.0,
                  'test_rpn_nms_threshold': 0.7,
                  'test_rpn_post_nms_top_k': 1000,
                  'test_rpn_pre_nms_top_k': 1000,
                  'test_rpn_score_threshold': 0.0,
                  'use_batched_nms': False},
 'roi_sampling': {'bg_iou_thresh_hi': 0.5,
                  'bg_iou_thresh_lo': 0.0,
                  'fg_fraction': 0.25,
                  'fg_iou_thresh': 0.5,
                  'mix_gt_boxes': True,
                  'num_samples_per_image': 512},
 'rpn_box_loss': {'huber_loss_delta': 0.1111111111111111},
 'rpn_head': {'anchors_per_location': 3,
              'num_convs': 2,
              'num_filters': 256,
              'use_batch_norm': False,
              'use_separable_conv': False},
 'rpn_score_loss': {'rpn_batch_size_per_im': 256},
 'strategy_config': {'all_reduce_alg': None,
                     'distribution_strategy': 'mirrored',
                     'num_gpus': 4,
                     'num_packs': 1,
                     'task_index': -1,
                     'tpu': None,
                     'worker_hosts': None},
 'strategy_type': 'mirrored',
 'train': {'batch_size': 64,
           'checkpoint': {'path': '', 'prefix': ''},
           'frozen_variable_prefix': '',
           'gradient_clip_norm': 0.0,
           'input_partition_dims': None,
           'input_sharding': False,
           'iterations_per_loop': 100,
           'l2_weight_decay': 0.0001,
           'learning_rate': {'init_learning_rate': 0.08,
                             'learning_rate_levels': [0.008, 0.0008],
                             'learning_rate_steps': [15000, 20000],
                             'type': 'step',
                             'warmup_learning_rate': 0.0067,
                             'warmup_steps': 500},
           'num_cores_per_replica': None,
           'optimizer': {'momentum': 0.9, 'nesterov': True, 'type': 'momentum'},
           'regularization_variable_regex': '.*(kernel|weight):0$',
           'total_steps': 22500,
           'train_dataset_type': 'tfrecord',
           'train_file_pattern': 'D:\\cwge\\models\\train\\obj-TFRecords-export',
           'transpose_input': False},
 'type': 'mask_rcnn',
 'use_tpu': False}
I0914 14:04:01.770950 14292 losses.py:152] RpnBoxLoss huber_loss_delta 0.1111111111111111
I0914 14:04:01.770950 14292 losses.py:244] FastrcnnBoxLoss huber_loss_delta 1.0
2020-09-14 14:04:01.776499: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library nvcuda.dll
2020-09-14 14:04:01.894504: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties:
pciBusID: 0000:02:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 11.00GiB deviceMemoryBandwidth: 451.17GiB/s
2020-09-14 14:04:01.910350: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 1 with properties:
pciBusID: 0000:03:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 11.00GiB deviceMemoryBandwidth: 451.17GiB/s
2020-09-14 14:04:01.926693: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 2 with properties:
pciBusID: 0000:82:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 11.00GiB deviceMemoryBandwidth: 451.17GiB/s
2020-09-14 14:04:01.941732: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 3 with properties:
pciBusID: 0000:83:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 11.00GiB deviceMemoryBandwidth: 451.17GiB/s
2020-09-14 14:04:01.955368: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudart64_101.dll
2020-09-14 14:04:01.968628: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cublas64_10.dll
2020-09-14 14:04:01.979013: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cufft64_10.dll
2020-09-14 14:04:01.986508: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library curand64_10.dll
2020-09-14 14:04:01.997805: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusolver64_10.dll
2020-09-14 14:04:02.007622: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusparse64_10.dll
2020-09-14 14:04:02.027831: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudnn64_7.dll
2020-09-14 14:04:02.034248: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0, 1, 2, 3
2020-09-14 14:04:02.040587: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-09-14 14:04:02.071991: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x17bcbd2a1a0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-09-14 14:04:02.078745: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-09-14 14:04:02.838330: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties:
pciBusID: 0000:02:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 11.00GiB deviceMemoryBandwidth: 451.17GiB/s
2020-09-14 14:04:02.851809: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 1 with properties:
pciBusID: 0000:03:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 11.00GiB deviceMemoryBandwidth: 451.17GiB/s
2020-09-14 14:04:02.865257: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 2 with properties:
pciBusID: 0000:82:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 11.00GiB deviceMemoryBandwidth: 451.17GiB/s
2020-09-14 14:04:02.879649: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 3 with properties:
pciBusID: 0000:83:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 11.00GiB deviceMemoryBandwidth: 451.17GiB/s
2020-09-14 14:04:02.891302: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudart64_101.dll
2020-09-14 14:04:02.899479: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cublas64_10.dll
2020-09-14 14:04:02.907082: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cufft64_10.dll
2020-09-14 14:04:02.912780: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library curand64_10.dll
2020-09-14 14:04:02.919560: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusolver64_10.dll
2020-09-14 14:04:02.926127: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusparse64_10.dll
2020-09-14 14:04:02.933353: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudnn64_7.dll
2020-09-14 14:04:02.939169: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0, 1, 2, 3
2020-09-14 14:04:04.938483: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-09-14 14:04:04.948402: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 1 2 3
2020-09-14 14:04:04.954277: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N N N N
2020-09-14 14:04:04.961884: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 1:   N N N N
2020-09-14 14:04:04.968803: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 2:   N N N N
2020-09-14 14:04:04.974100: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 3:   N N N N
2020-09-14 14:04:04.979507: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 8678 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:02:00.0, compute capability: 6.1)
2020-09-14 14:04:04.993621: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 8678 MB memory) -> physical GPU (device: 1, name: GeForce GTX 1080 Ti, pci bus id: 0000:03:00.0, compute capability: 6.1)
2020-09-14 14:04:05.008754: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 8679 MB memory) -> physical GPU (device: 2, name: GeForce GTX 1080 Ti, pci bus id: 0000:82:00.0, compute capability: 6.1)
2020-09-14 14:04:05.022460: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:3 with 8678 MB memory) -> physical GPU (device: 3, name: GeForce GTX 1080 Ti, pci bus id: 0000:83:00.0, compute capability: 6.1)
2020-09-14 14:04:05.043731: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x17c2c4b1c30 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-09-14 14:04:05.051100: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce GTX 1080 Ti, Compute Capability 6.1
2020-09-14 14:04:05.057392: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (1): GeForce GTX 1080 Ti, Compute Capability 6.1
2020-09-14 14:04:05.065059: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (2): GeForce GTX 1080 Ti, Compute Capability 6.1
2020-09-14 14:04:05.071924: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (3): GeForce GTX 1080 Ti, Compute Capability 6.1
INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')
I0914 14:04:05.084040 14292 mirrored_strategy.py:341] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')
I0914 14:04:05.085038 14292 main.py:109] Train num_replicas_in_sync 4 num_workers 1 is_multi_host False
W0914 14:04:05.551125 14292 distributed_executor.py:386] It is sematically wrong to run callbacks when iterations_per_loop is not one (100)
I0914 14:04:05.551125 14292 distributed_executor.py:187] Save config to model_dir model_dir.
WARNING:tensorflow:From C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\util\deprecation.py:574: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Use fn_output_signature instead
W0914 14:04:06.674531 14292 deprecation.py:506] From C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\util\deprecation.py:574: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Use fn_output_signature instead
WARNING:tensorflow:From C:\ProgramData\Anaconda3\lib\site-packages\official\modeling\training\distributed_executor.py:422: set_learning_phase (from tensorflow.python.keras.backend) is deprecated and will be removed after 2020-10-11.
Instructions for updating:
Simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.
W0914 14:04:14.898379 14292 deprecation.py:323] From C:\ProgramData\Anaconda3\lib\site-packages\official\modeling\training\distributed_executor.py:422: set_learning_phase (from tensorflow.python.keras.backend) is deprecated and will be removed after 2020-10-11.
Instructions for updating:
Simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
I0914 14:04:14.967356 14292 cross_device_ops.py:443] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
I0914 14:04:14.975355 14292 cross_device_ops.py:443] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
I0914 14:04:15.026335 14292 cross_device_ops.py:443] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
I0914 14:04:15.034337 14292 cross_device_ops.py:443] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
I0914 14:04:15.077326 14292 cross_device_ops.py:443] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
I0914 14:04:15.085321 14292 cross_device_ops.py:443] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
I0914 14:04:15.131283 14292 cross_device_ops.py:443] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
I0914 14:04:15.139305 14292 cross_device_ops.py:443] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
I0914 14:04:15.182301 14292 cross_device_ops.py:443] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
I0914 14:04:15.190292 14292 cross_device_ops.py:443] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
I0914 14:05:32.890244 14292 distributed_executor.py:439] Checkpoint file model_dir\ctl_step_0.ckpt-1 found and restoring from checkpoint
I0914 14:11:06.265516 14292 distributed_executor.py:443] Loading from checkpoint file completed. Init step 0
I0914 14:11:06.947770 14292 detection_executor.py:65] Filter trainable variables from 213 to 213
E0914 14:11:06.947770 14292 detection_executor.py:71] Detection: train metric is not an instance of tf.keras.metrics.Metric.
I0914 14:11:06.948742 14292 distributed_executor.py:491] Training started
INFO:tensorflow:batch_all_reduce: 213 all-reduces with algorithm = nccl, num_packs = 1
I0914 14:11:42.760163 14292 cross_device_ops.py:702] batch_all_reduce: 213 all-reduces with algorithm = nccl, num_packs = 1
INFO:tensorflow:batch_all_reduce: 213 all-reduces with algorithm = nccl, num_packs = 1
I0914 14:12:20.195042 14292 cross_device_ops.py:702] batch_all_reduce: 213 all-reduces with algorithm = nccl, num_packs = 1
INFO:tensorflow:batch_all_reduce: 213 all-reduces with algorithm = nccl, num_packs = 1
I0914 14:13:25.904150 14292 cross_device_ops.py:702] batch_all_reduce: 213 all-reduces with algorithm = nccl, num_packs = 1
INFO:tensorflow:batch_all_reduce: 213 all-reduces with algorithm = nccl, num_packs = 1
I0914 14:14:05.912061 14292 cross_device_ops.py:702] batch_all_reduce: 213 all-reduces with algorithm = nccl, num_packs = 1
Traceback (most recent call last):
  File ""official/vision/detection/main.py"", line 272, in <module>
    app.run(main)
  File ""C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\absl\app.py"", line 300, in run
    _run_main(main, args)
  File ""C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\absl\app.py"", line 251, in _run_main
    sys.exit(main(argv))
  File ""official/vision/detection/main.py"", line 267, in main
    run()
  File ""official/vision/detection/main.py"", line 261, in run
    callbacks=callbacks)
  File ""official/vision/detection/main.py"", line 133, in run_executor
    save_config=True)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\official\modeling\training\distributed_executor.py"", line 498, in train
    tf.convert_to_tensor(num_steps, dtype=tf.int32))
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\eager\def_function.py"", line 780, in __call__
    result = self._call(*args, **kwds)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\eager\def_function.py"", line 840, in _call
    return self._stateless_fn(*args, **kwds)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\eager\function.py"", line 2829, in __call__
    return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\eager\function.py"", line 1848, in _filtered_call
    cancellation_manager=cancellation_manager)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\eager\function.py"", line 1924, in _call_flat
    ctx, args, cancellation_manager=cancellation_manager))
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\eager\function.py"", line 550, in call
    ctx=ctx)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\eager\execute.py"", line 60, in quick_execute
    inputs, attrs, num_outputs)
tensorflow.python.framework.errors_impl.InvalidArgumentError: No OpKernel was registered to support Op 'NcclAllReduce' used by {{node SGD/NcclAllReduce}} with these attrs: [reduction=""sum"", shared_name=""c2"", T=DT_FLOAT, num_devices=4]
Registered devices: [CPU, GPU, XLA_CPU, XLA_GPU]
Registered kernels:
  <no registered kernels>

         [[SGD/NcclAllReduce]] [Op:__inference_train_step_456253]",x12901,b'models:official type:bug',2020-09-14T06:15:45Z,2020-09-14T16:38:58Z,,,,,,,
9237,Issue with Training CenterNet Resnet50 V2 Keypoints 512x512 with TF2 object detection api,"<!--
As per our GitHub Policy (https://github.com/tensorflow/models/blob/master/ISSUES.md), we only address code bugs, documentation issues, and feature requests on GitHub.

We will automatically close questions and help related issues.

Please go to Stack Overflow (http://stackoverflow.com/questions/tagged/tensorflow-model-garden) for questions and help.

-->
Hello i am trying to train CenterNet Resnet50 V2 Keypoints 512x512 with hand dataset 'https://www.robots.ox.ac.uk/~vgg/data/hands/downloads/hand_dataset.tar.gz' on TF2 Object Detection Api  but facing issue with label_map.pbxt and don't know how to resolve this issue.

Errors i got during training:
File ""/usr/local/lib/python3.6/dist-packages/object_detection/builders/model_builder.py"", line 991, in _build_center_net_model
kp_params = keypoint_proto_to_params(task, keypoint_map_dict)
File ""/usr/local/lib/python3.6/dist-packages/object_detection/builders/model_builder.py"", line 809, in keypoint_proto_to_params
label_map_item = keypoint_map_dict[kp_config.keypoint_class_name]
KeyError: '/m/01g317'",pardeep-kesnani1234,b'stalled stat:awaiting response type:support',2020-09-13T12:40:12Z,2020-09-28T10:45:19Z,,,,,,,
9235,ValueError: call() should not modify its Python input arguments,"# Prerequisites

Please answer the following questions for yourself before submitting an issue.

- [yes] I am using the latest TensorFlow Model Garden release and TensorFlow 2.
- [yes] I am reporting the issue to the correct repository. (Model Garden official or research directory)
- [yes] I checked to make sure that this issue has not been filed already.

## 1. The entire URL of the file you are using

https://github.com/tensorflow/models/tree/master/official/nlp/transformer/transformer_main.py

## 2. Describe the bug

I need a "".pb"" model(savedModel) for tf.serving. 

I trained and saved the model(save_weights_only=True), and successfully restored the weights in the prediction mode(by setting mode=""predict"").

Then I tried to save the model in the protocol buffer format(savedModel), but the error occured:

""**ValueError: call() should not modify its Python input arguments. Check if it modifies any lists or dicts passed as arguments. Modifying a copy is allowed.**""

## 3. Steps to reproduce

I just followed the tutorial. 

I trained and saved a model(.ckpt), then restored its weights in the prediction mode(by setting mode=""predict""). I tried to save the inference model in savedModel format for tf.serving.

my code:
```
with tf.name_scope(""model""):
    model = transformer.create_model(params, is_train=False)
    self._load_weights_if_possible(model, tf.train.latest_checkpoint(self.flags_obj.model_dir))  
    model.summary()

# I tried to save the inference model in .pb format for tf.serving
logging.info(""Save inference graph into the .pb format."")
model.save(os.path.join(flags_obj.model_dir, ""1""), 
                    include_optimizer=False, options=save_options_lib.SaveOptions())  #  ----> error here
logging.info(""successfully."")
```

## 4. Expected behavior

The inference model can be saved as a .pb model for tf.serving.

## 5. Additional context
**pycharm logs, it seems the ""decoder_stack"" is the source of the error:**

Traceback (most recent call last):
  File ""/home/xxx/pycharm_proj/models-master-0907/official/nlp/transformer/transformer_main.py"", line 955, in <module>
    app.run(main)
  File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""/home/xxx/pycharm_proj/models-master-0907/official/nlp/transformer/transformer_main.py"", line 944, in main
    task.predict(chunk_list, line=line, use_bsrule=False)
  File ""/home/xxx/pycharm_proj/models-master-0907/official/nlp/transformer/transformer_main.py"", line 541, in predict
    options=save_options_lib.SaveOptions())
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py"", line 1950, in save
    signatures, options)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/save.py"", line 135, in save_model
    signatures, options)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/saved_model/save.py"", line 80, in save
    save_lib.save(model, filepath, signatures, options)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/save.py"", line 1000, in save
    obj, export_dir, signatures, options, meta_graph_def)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/save.py"", line 1148, in _build_meta_graph
    meta_graph_def)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/save.py"", line 1095, in _build_meta_graph_impl
    checkpoint_graph_view)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/signature_serialization.py"", line 75, in find_function_to_export
    functions = saveable_view.list_functions(saveable_view.root)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/save.py"", line 147, in list_functions
    self._serialization_cache)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py"", line 2561, in _list_functions_for_serialization
    Model, self)._list_functions_for_serialization(serialization_cache)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py"", line 3047, in _list_functions_for_serialization
    .list_functions_for_serialization(serialization_cache))
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/saved_model/base_serialization.py"", line 87, in list_functions_for_serialization
    fns = self.functions_to_serialize(serialization_cache)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/saved_model/layer_serialization.py"", line 79, in functions_to_serialize
    serialization_cache).functions_to_serialize)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/saved_model/layer_serialization.py"", line 95, in _get_serialized_attributes
    serialization_cache)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/saved_model/model_serialization.py"", line 57, in _get_serialized_attributes_internal
    serialization_cache))
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/saved_model/layer_serialization.py"", line 104, in _get_serialized_attributes_internal
    functions = save_impl.wrap_layer_functions(self.obj, serialization_cache)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/saved_model/save_impl.py"", line 155, in wrap_layer_functions
    original_fns = _replace_child_layer_functions(layer, serialization_cache)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/saved_model/save_impl.py"", line 274, in _replace_child_layer_functions
    serialization_cache).functions)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/saved_model/layer_serialization.py"", line 95, in _get_serialized_attributes
    serialization_cache)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/saved_model/model_serialization.py"", line 57, in _get_serialized_attributes_internal
    serialization_cache))
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/saved_model/layer_serialization.py"", line 104, in _get_serialized_attributes_internal
    functions = save_impl.wrap_layer_functions(self.obj, serialization_cache)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/saved_model/save_impl.py"", line 165, in wrap_layer_functions
    '{}_layer_call_and_return_conditional_losses'.format(layer.name))
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/saved_model/save_impl.py"", line 505, in add_function
    self.add_trace(*self._input_signature)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/saved_model/save_impl.py"", line 420, in add_trace
    trace_with_training(True)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/saved_model/save_impl.py"", line 418, in trace_with_training
    fn.get_concrete_function(*args, **kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/saved_model/save_impl.py"", line 549, in get_concrete_function
    return super(LayerCall, self).get_concrete_function(*args, **kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py"", line 1176, in get_concrete_function
    concrete = self._get_concrete_function_garbage_collected(*args, **kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py"", line 1082, in _get_concrete_function_garbage_collected
    self._initialize(args, kwargs, add_initializers_to=initializers)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py"", line 717, in _initialize
    *args, **kwds))
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py"", line 2955, in _get_concrete_function_internal_garbage_collected
    graph_function, _, _ = self._maybe_define_function(args, kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py"", line 3333, in _maybe_define_function
    graph_function = self._create_graph_function(args, kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py"", line 3188, in _create_graph_function
    capture_by_value=self._capture_by_value),
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py"", line 987, in func_graph_from_py_func
    func_outputs = python_func(*func_args, **func_kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py"", line 625, in wrapped_fn
    out = weak_wrapped_fn().__wrapped__(*args, **kwds)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/saved_model/save_impl.py"", line 526, in wrapper
    ret = method(*args, **kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/saved_model/utils.py"", line 169, in wrap_with_training_arg
    lambda: replace_training_and_call(False))
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/control_flow_util.py"", line 113, in smart_cond
    pred, true_fn=true_fn, false_fn=false_fn, name=name)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/smart_cond.py"", line 54, in smart_cond
    return true_fn()
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/saved_model/utils.py"", line 168, in <lambda>
    training, lambda: replace_training_and_call(True),
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/saved_model/utils.py"", line 165, in replace_training_and_call
    return wrapped_call(*args, **kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/saved_model/save_impl.py"", line 569, in call_and_return_conditional_losses
    call_output = layer_call(inputs, *args, **kwargs)
  File ""/home/xxx/pycharm_proj/models-master-0907/official/nlp/transformer/transformer.py"", line 154, in call
    return self.predict(encoder_outputs, attention_bias, training)
  File ""/home/xxx/pycharm_proj/models-master-0907/official/nlp/transformer/transformer.py"", line 349, in predict
    dtype=self.params[""dtype""])
  File ""/home/xxx/pycharm_proj/models-master-0907/official/nlp/modeling/ops/beam_search.py"", line 635, in sequence_beam_search
    return sbs.search(initial_ids, initial_cache)
  File ""/home/xxx/pycharm_proj/models-master-0907/official/nlp/modeling/ops/beam_search.py"", line 414, in search
    parallel_iterations=1))
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py"", line 574, in new_func
    return func(*args, **kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/control_flow_ops.py"", line 2499, in while_loop_v2
    return_same_structure=True)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/control_flow_ops.py"", line 2696, in while_loop
    back_prop=back_prop)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/while_v2.py"", line 196, in while_loop
    add_control_dependencies=add_control_dependencies)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py"", line 987, in func_graph_from_py_func
    func_outputs = python_func(*func_args, **func_kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/while_v2.py"", line 174, in wrapped_body
    outputs = body(*_pack_sequence_as(orig_loop_vars, args))
  File ""/home/xxx/pycharm_proj/models-master-0907/official/nlp/modeling/ops/beam_search.py"", line 390, in _search_step
    new_seq, new_log_probs, topk_ids, new_cache = _grow_alive_seq(state)
  File ""/home/xxx/pycharm_proj/models-master-0907/official/nlp/modeling/ops/beam_search.py"", line 238, in _grow_alive_seq
    flat_ids, i, flat_cache)
  **File ""/home/xxx/pycharm_proj/models-master-0907/official/nlp/transformer/transformer.py"", line 287, in symbols_to_logits_fn
    decode_loop_step=i if self.params[""padded_decode""] else None)**
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py"", line 990, in __call__
    outputs = call_fn(inputs, *args, **kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/saved_model/utils.py"", line 71, in return_outputs_and_add_losses
    outputs, losses = fn(inputs, *args, **kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/saved_model/utils.py"", line 169, in wrap_with_training_arg
    lambda: replace_training_and_call(False))
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/control_flow_util.py"", line 113, in smart_cond
    pred, true_fn=true_fn, false_fn=false_fn, name=name)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/smart_cond.py"", line 54, in smart_cond
    return true_fn()
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/saved_model/utils.py"", line 168, in <lambda>
    training, lambda: replace_training_and_call(True),
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/saved_model/utils.py"", line 165, in replace_training_and_call
    return wrapped_call(*args, **kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/saved_model/save_impl.py"", line 543, in __call__
    self.call_collection.add_trace(*args, **kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/saved_model/save_impl.py"", line 420, in add_trace
    trace_with_training(True)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/saved_model/save_impl.py"", line 418, in trace_with_training
    fn.get_concrete_function(*args, **kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/saved_model/save_impl.py"", line 549, in get_concrete_function
    return super(LayerCall, self).get_concrete_function(*args, **kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py"", line 1176, in get_concrete_function
    concrete = self._get_concrete_function_garbage_collected(*args, **kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py"", line 1082, in _get_concrete_function_garbage_collected
    self._initialize(args, kwargs, add_initializers_to=initializers)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py"", line 717, in _initialize
    *args, **kwds))
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py"", line 2955, in _get_concrete_function_internal_garbage_collected
    graph_function, _, _ = self._maybe_define_function(args, kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py"", line 3333, in _maybe_define_function
    graph_function = self._create_graph_function(args, kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py"", line 3188, in _create_graph_function
    capture_by_value=self._capture_by_value),
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py"", line 994, in func_graph_from_py_func
    check_mutation(func_args_before, func_args, original_func)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py"", line 1078, in check_mutation
    raise ValueError(errmsg)
ValueError: call() should not modify its Python input arguments. Check if it modifies any lists or dicts passed as arguments. Modifying a copy is allowed.


## 6. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  Ubuntu 18.04.3 LTS
- Mobile device name if the issue happens on a mobile device:  None
- TensorFlow installed from (source or binary):  pip
- TensorFlow version (use command below):  tensorflow-gpu 2.3.0
- Python version:  3.6.8
- Bazel version (if compiling from source):  None
- GCC/Compiler version (if compiling from source):  None
- CUDA/cuDNN version:  CUDA 10.1   Driver Version: 430.50
- GPU model and memory:  one GTX1080TI, 11G memory

<!-- 
Collect system information using our environment capture script.
https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can also obtain the TensorFlow version with:

1. TensorFlow 1.0
`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

2. TensorFlow 2.0
`python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`
-->
",2020zyc,b'models:official type:bug',2020-09-13T05:09:23Z,2020-09-18T19:43:52Z,,,,,,,
9232,Loading trained DELG model problem,"# Prerequisites

Please answer the following questions for yourself before submitting an issue.

- [x] I am using the latest TensorFlow Model Garden release and TensorFlow 2.
- [x] I am reporting the issue to the correct repository. (Model Garden official or research directory)
- [x] I checked to make sure that this issue has not already been filed.

## 1. The entire URL of the file you are using

https://github.com/tensorflow/models/blob/master/research/delf/delf/python/training/README.md

## 2. Describe the bug

I was trying to train DELG model and extract local and global feature. The process of training and extracting model was fine. However, when I tried to load saved model with [GLRec2020 Baseline](https://www.kaggle.com/camaskew/host-baseline-example) code, I got error in the following line:
```
GLOBAL_FEATURE_EXTRACTION_FN = DELG_MODEL.prune(DELG_INPUT_TENSOR_NAMES,
                                                ['global_descriptors:0'])
```
```
AttributeError: '_UserObject' object has no attribute 'prune'
```

## 3. Steps to reproduce

I followed the code to train DELG model. I did 2 steps:
- Training with Local and Global Features
- Extracting DELG local+global feature model

Next, I tried to load model with code from [GLRec2020 Baseline](https://www.kaggle.com/camaskew/host-baseline-example) and problem came in the following line:
```
GLOBAL_FEATURE_EXTRACTION_FN = DELG_MODEL.prune(DELG_INPUT_TENSOR_NAMES,
                                                ['global_descriptors:0'])
```

## 4. Expected behavior

I will really appreciate any help if you point out where I do wrong or what to do to fix the problem.

## 5. Additional context

## 6. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux (Kaggle kernel)
- Mobile device name if the issue happens on a mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below): 2.3.0
- Python version: python 3.7.6
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 10.1
- GPU model and memory: Tesla P100
",ngokhoa96,b'models:research type:bug',2020-09-11T20:14:39Z,2020-09-12T18:55:27Z,,,,,,,
9231,"Custom Training, no custom code - checkpoint won't load for training but will for evaluation","# Prerequisites

Please answer the following questions for yourself before submitting an issue.

- [x] I am using the latest TensorFlow Model Garden release and TensorFlow 2.
- [x] I am reporting the issue to the correct repository. (Model Garden official or research directory)
- [x] I checked to make sure that this issue has not already been filed.

## 1. The entire URL of the file you are using

https://github.com/tensorflow/models/tree/master/research/...


## 2. Describe the bug

When running in training mode using:
python object_detection/model_main_tf2.py  --pipeline_config_path=${PIPELINE_CONFIG_PATH}  --model_dir=${MODEL_DIR}  --alsologtostder

I run into the following error:
RuntimeError: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for xxxxx/ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/checkpoint/model.ckpt

(NOTE: model.ckpt has been tried as resnet101.ckpt, model.ckpt-0, ckpt, resnet101.ckpt-00000, resnet.ckpt-00000, and model.ckpt-00000 and resnet101.ckpt-1 based on sample config files found online. I have also attempted to point it at the checkpoint directory. Error remains the same.)

When all information on a fine_tune_checkpoint is removed from the config file to attempt a ""from scratch"" training session the following error is given:

tensorflow.python.framework.errors_impl.FailedPreconditionError: xxxxxx/models-09-08-20/research/object_detection/ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/checkpoint.tmp166c5c2524dc4ab68f02f82edc5b0c11; Is a directory

I do not know how it was directed to this path. I have unset the CHECKPOINT_DIR and results remain the same.

When running in evaluation mode, the checkpoint is detected, but all output is set to 0 (as expected as custom dataset does not correspond to typical images).

## 3. Steps to reproduce

Download model directory from 09/08/2020, pull the SSD_resnet101 model from the TF2 model detection zoo. Modify the config file as shown below:

 fine_tune_checkpoint: ""/xxxxx/models-09-08-20/research/object_detection/ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/checkpoint/model.ckpt""
  num_steps: 25000
  startup_delay_steps: 0.0
  replicas_to_aggregate: 8
  max_number_of_boxes: 100
  unpad_groundtruth_tensors: false
  fine_tune_checkpoint_type: ""detection""
  use_bfloat16: true
  fine_tune_checkpoint_version: V2
}
train_input_reader {
  label_map_path: ""/xxxxx/models-09-08-20/research/object_detection/data/object-detection.pbtxt""
  tf_record_input_reader {
    input_path: ""/xxxxx/models-09-08-20/research/object_detection/data/train.record""
  }
}
eval_config {
  metrics_set: ""coco_detection_metrics""
  use_moving_averages: false
}
eval_input_reader {
  label_map_path: ""/xxxxx/models-09-08-20/research/object_detection/data""
  shuffle: false
  num_epochs: 1
  tf_record_input_reader {
    input_path: ""/xxxxx/models-09-08-20/research/object_detection/data/test.record""
  }
}



Move test.record, train.record, object-detection.pbtxt to the data directory.

Move images directory to the object detection directory.


Set the following via command line from the research directory:
PIPELINE_CONFIG_PATH=/xxxxx/models-09-08-20/research/object_detection/ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/pipeline.config

MODEL_DIR=/xxxxx/models-09-08-20/research/object_detection/ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/

run the following command from the research directory:
python object_detection/model_main_tf2.py \
    --pipeline_config_path=${PIPELINE_CONFIG_PATH} \
    --model_dir=${MODEL_DIR} \
    --alsologtostder

## 4. Expected behavior

I expect that the code would begin training on my custom dataset.

## 5. Additional context

(SSD) USER$ python object_detection/model_main_tf2.py     --pipeline_config_path=${PIPELINE_CONFIG_PATH}     --model_dir=${MODEL_DIR}     --alsologtostder
2020-09-10 09:38:48.794458: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-09-10 09:38:48.806430: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fb7c6883500 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-09-10 09:38:48.806468: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.
W0910 09:38:48.807556 4723258816 cross_device_ops.py:1175] There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.
INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)
I0910 09:38:48.807872 4723258816 mirrored_strategy.py:500] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)
INFO:tensorflow:Maybe overwriting record_summaries: True
I0910 09:38:48.811570 4723258816 config_util.py:552] Maybe overwriting record_summaries: True
INFO:tensorflow:Ignoring config override key: record_summaries
I0910 09:38:48.811643 4723258816 config_util.py:562] Ignoring config override key: record_summaries
INFO:tensorflow:Maybe overwriting train_steps: None
I0910 09:38:48.811934 4723258816 config_util.py:552] Maybe overwriting train_steps: None
INFO:tensorflow:Maybe overwriting use_bfloat16: False
I0910 09:38:48.812007 4723258816 config_util.py:552] Maybe overwriting use_bfloat16: False
Traceback (most recent call last):
  File ""/xxxxx/opt/anaconda3/envs/SSD/lib/python3.6/site-packages/tensorflow/python/training/py_checkpoint_reader.py"", line 95, in NewCheckpointReader
    return CheckpointReader(compat.as_bytes(filepattern))
RuntimeError: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for /xxxxx/models-09-08-20/research/object_detection/ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8/checkpoint/model.ckpt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""object_detection/model_main_tf2.py"", line 113, in <module>
    tf.compat.v1.app.run()
  File ""/xxxxx/opt/anaconda3/envs/SSD/lib/python3.6/site-packages/tensorflow/python/platform/app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""/xxxxx/opt/anaconda3/envs/SSD/lib/python3.6/site-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/xxxxx/opt/anaconda3/envs/SSD/lib/python3.6/site-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""object_detection/model_main_tf2.py"", line 110, in main
    record_summaries=FLAGS.record_summaries)
  File ""/xxxxx/opt/anaconda3/envs/SSD/lib/python3.6/site-packages/object_detection/model_lib_v2.py"", line 554, in train_loop
    unpad_groundtruth_tensors)
  File ""/xxxxx/opt/anaconda3/envs/SSD/lib/python3.6/site-packages/object_detection/model_lib_v2.py"", line 335, in load_fine_tune_checkpoint
    if not is_object_based_checkpoint(checkpoint_path):
  File ""/xxxxx/opt/anaconda3/envs/SSD/lib/python3.6/site-packages/object_detection/model_lib_v2.py"", line 298, in is_object_based_checkpoint
    var_names = [var[0] for var in tf.train.list_variables(checkpoint_path)]
  File ""/xxxxx/opt/anaconda3/envs/SSD/lib/python3.6/site-packages/tensorflow/python/training/checkpoint_utils.py"", line 98, in list_variables
    reader = load_checkpoint(ckpt_dir_or_file)
  File ""/xxxxx/opt/anaconda3/envs/SSD/lib/python3.6/site-packages/tensorflow/python/training/checkpoint_utils.py"", line 67, in load_checkpoint
    return py_checkpoint_reader.NewCheckpointReader(filename)
  File ""/xxxxx/opt/anaconda3/envs/SSD/lib/python3.6/site-packages/tensorflow/python/training/py_checkpoint_reader.py"", line 99, in NewCheckpointReader
    error_translator(e)
  File ""/xxxxx/opt/anaconda3/envs/SSD/lib/python3.6/site-packages/tensorflow/python/training/py_checkpoint_reader.py"", line 35, in error_translator
    raise errors_impl.NotFoundError(None, None, error_message)
tensorflow.python.framework.errors_impl.NotFoundError: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for /xxxxx/Desktop/models-09-08-20/research/object_detection/ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8/checkpoint/model.ckpt



## 6. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Mojave 10.14.6
- TensorFlow installed from (source or binary): pypi
- TensorFlow version (use command below): 2.2.0
- Python version: 3.6.10
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A",mgon5170,b'models:research type:bug',2020-09-11T16:32:12Z,2020-09-24T13:00:02Z,,,,,,,
9222,replace tf.compat.v1.logging with absl.logging for deep_speech,"# Description

> :memo: Please include a summary of the change. 
>  
> * Please also include relevant motivation and context.  
> * List any dependencies that are required for this change.  

## Type of change

For a new feature or function, please create an issue first to discuss it
with us before submitting a pull request.

Note: Please delete options that are not relevant.

- [ ] Bug fix (non-breaking change which fixes an issue)
- [ ] Documentation update
- [x] TensorFlow 2 migration
- [ ] New feature (non-breaking change which adds functionality)
- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)
- [ ] A new research paper code implementation
- [ ] Other (Specify)

## Tests

> :memo: Please describe the tests that you ran to verify your changes.
>  
> * Provide instructions so we can reproduce.  
> * Please also list any relevant details for your test configuration.  

**Test Configuration**:

## Checklist

- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).
- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).
- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).
- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.
- [ ] I have commented my code, particularly in hard-to-understand areas.
- [ ] I have made corresponding changes to the documentation.
- [x] My changes generate no new warnings.
- [ ] I have added tests that prove my fix is effective or that my feature works.
",moneypi,b'cla: yes stat:awaiting testing',2020-09-10T15:46:51Z,2020-09-30T00:05:33Z,,,,,,,
9218,8-bit Quantization of RetinaNet,"# Prerequisites
## 1. The entire URL of the file you are using

https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md

## 2. Describe the bug

Applying 8-bit quantization to RetinaNet produces the following error:
```
RuntimeError: Quantization not yet supported for op: 'CUSTOM'.
```
I am using the new converter and have `allow_custom_ops` set to `True`, so this is unexpected. 

## 3. Steps to reproduce
1. Download the ssd resnet50 640x640 retinanet model from the [model zoo](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md)
2. Convert the model to a frozen graph using @srjoglekar246 's new script [here](https://github.com/tensorflow/models/blob/master/research/object_detection/export_tflite_ssd_graph.py)
3. Convert the frozen graph to a quantized tflite file with the new MLIR converter, with the following parameters: 
```
converter.allow_custom_ops = True
converter.representative_dataset = representative_dataset_gen
converter.optimizations = [tf.lite.Optimize.DEFAULT]
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]    # Problematic
```

## 4. Expected behavior

The script should successfully produce a quantized model by emitting a ""custom"" op for each custom operation. 

It would also be helpful if a member of the team could elucidate what these custom operations are, so that they can be passed to the tflite runtime.

## 5. Additional context

The TFLiteConverter successfully emits when quantization is disabled and when the experimental 8/16 quantization happens. It's the 8-bit-only-quantization that causes the crash. 

Include any logs that would be helpful to diagnose the problem.
```
  File ""quantize.py"", line 39, in <module>
    tflite_quant_model = converter.convert()
  File ""/home/rsaini/.pyenv/versions/tf2/lib/python3.7/site-packages/tensorflow/lite/python/lite.py"", line 726, in convert
    output_tensors)
  File ""/home/rsaini/.pyenv/versions/tf2/lib/python3.7/site-packages/tensorflow/lite/python/lite.py"", line 648, in convert
    result = self._calibrate_quantize_model(result, **flags)
  File ""/home/rsaini/.pyenv/versions/tf2/lib/python3.7/site-packages/tensorflow/lite/python/lite.py"", line 476, in _calibrate_quantize_model
    inference_output_type, allow_float, activations_type)
  File ""/home/rsaini/.pyenv/versions/tf2/lib/python3.7/site-packages/tensorflow/lite/python/optimize/calibrator.py"", line 98, in calibrate_and_quantize
    np.dtype(activations_type.as_numpy_dtype()).num)
RuntimeError: Quantization not yet supported for op: 'CUSTOM'.
```
## 6. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 20.04
- Mobile device name if the issue happens on a mobile device: N/A (targeting Google Coral)
- TensorFlow installed from (source or binary): Binary (pip)
- TensorFlow version (use command below): 2.4.0-dev20200908
- Python version: 3.7.7
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: 11
- GPU model and memory:
",rajansaini691,b'models:research type:bug',2020-09-09T23:18:38Z,2020-09-09T23:39:37Z,,,,,,,
9211,AttributeError: use_cpu_nms,"
## 1. The entire URL of the file you are using

https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2.md

## 2. Describe the bug

I followed instructions to install tensorflow 2 as described in the link above in ""Python Package Installation"" section.
The installation ends whitout errors.

## 3. Steps to reproduce

When I try to run test 

python object_detection/builders/model_builder_tf2_test.py 

I obtain the following errors:

AttributeError: use_cpu_nms

======================================================================
ERROR: test_create_faster_rcnn_from_config_with_crop_feature(True) (__main__.ModelBuilderTF2Test)
test_create_faster_rcnn_from_config_with_crop_feature(True) (__main__.ModelBuilderTF2Test)
test_create_faster_rcnn_from_config_with_crop_feature(True)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""C:\Users\deep-user\.conda\envs\tensorflow2\lib\site-packages\absl\testing\parameterized.py"", line 267, in bound_param_test
    test_method(self, testcase_params)
  File ""D:\faster_rcnn\models\research\object_detection\builders\model_builder_test.py"", line 292, in test_create_faster_rcnn_from_config_with_crop_feature
    _ = model_builder.build(model_proto, is_training=True)
  File ""D:\faster_rcnn\models\research\object_detection\builders\model_builder.py"", line 1062, in build
    add_summaries)
  File ""D:\faster_rcnn\models\research\object_detection\builders\model_builder.py"", line 663, in _build_faster_rcnn_model
    ) = post_processing_builder.build(frcnn_config.second_stage_post_processing)
  File ""D:\faster_rcnn\models\research\object_detection\builders\post_processing_builder.py"", line 59, in build
    post_processing_config.batch_non_max_suppression)
  File ""D:\faster_rcnn\models\research\object_detection\builders\post_processing_builder.py"", line 107, in _build_non_max_suppressor
    use_cpu_nms=nms_config.use_cpu_nms)
AttributeError: use_cpu_nms

======================================================================
ERROR: test_create_faster_rcnn_from_config_with_crop_feature(False) (__main__.ModelBuilderTF2Test)
test_create_faster_rcnn_from_config_with_crop_feature(False) (__main__.ModelBuilderTF2Test)
test_create_faster_rcnn_from_config_with_crop_feature(False)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""C:\Users\deep-user\.conda\envs\tensorflow2\lib\site-packages\absl\testing\parameterized.py"", line 267, in bound_param_test
    test_method(self, testcase_params)
  File ""D:\faster_rcnn\models\research\object_detection\builders\model_builder_test.py"", line 292, in test_create_faster_rcnn_from_config_with_crop_feature
    _ = model_builder.build(model_proto, is_training=True)
  File ""D:\faster_rcnn\models\research\object_detection\builders\model_builder.py"", line 1062, in build
    add_summaries)
  File ""D:\faster_rcnn\models\research\object_detection\builders\model_builder.py"", line 663, in _build_faster_rcnn_model
    ) = post_processing_builder.build(frcnn_config.second_stage_post_processing)
  File ""D:\faster_rcnn\models\research\object_detection\builders\post_processing_builder.py"", line 59, in build
    post_processing_config.batch_non_max_suppression)
  File ""D:\faster_rcnn\models\research\object_detection\builders\post_processing_builder.py"", line 107, in _build_non_max_suppressor
    use_cpu_nms=nms_config.use_cpu_nms)
AttributeError: use_cpu_nms

======================================================================
ERROR: test_create_faster_rcnn_model_from_config_with_example_miner (__main__.ModelBuilderTF2Test)
test_create_faster_rcnn_model_from_config_with_example_miner (__main__.ModelBuilderTF2Test)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""D:\faster_rcnn\models\research\object_detection\builders\model_builder_test.py"", line 271, in test_create_faster_rcnn_model_from_config_with_example_miner
    model = model_builder.build(model_proto, is_training=True)
  File ""D:\faster_rcnn\models\research\object_detection\builders\model_builder.py"", line 1062, in build
    add_summaries)
  File ""D:\faster_rcnn\models\research\object_detection\builders\model_builder.py"", line 663, in _build_faster_rcnn_model
    ) = post_processing_builder.build(frcnn_config.second_stage_post_processing)
  File ""D:\faster_rcnn\models\research\object_detection\builders\post_processing_builder.py"", line 59, in build
    post_processing_config.batch_non_max_suppression)
  File ""D:\faster_rcnn\models\research\object_detection\builders\post_processing_builder.py"", line 107, in _build_non_max_suppressor
    use_cpu_nms=nms_config.use_cpu_nms)
AttributeError: use_cpu_nms

======================================================================
ERROR: test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul (__main__.ModelBuilderTF2Test)
test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul (__main__.ModelBuilderTF2Test)
test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul(use_matmul_crop_and_resize=False, enable_mask_prediction=False)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""C:\Users\deep-user\.conda\envs\tensorflow2\lib\site-packages\absl\testing\parameterized.py"", line 263, in bound_param_test
    test_method(self, **testcase_params)
  File ""D:\faster_rcnn\models\research\object_detection\builders\model_builder_test.py"", line 262, in test_create_faster_rcnn_models_from_config
    model = model_builder.build(model_proto, is_training=True)
  File ""D:\faster_rcnn\models\research\object_detection\builders\model_builder.py"", line 1062, in build
    add_summaries)
  File ""D:\faster_rcnn\models\research\object_detection\builders\model_builder.py"", line 663, in _build_faster_rcnn_model
    ) = post_processing_builder.build(frcnn_config.second_stage_post_processing)
  File ""D:\faster_rcnn\models\research\object_detection\builders\post_processing_builder.py"", line 59, in build
    post_processing_config.batch_non_max_suppression)
  File ""D:\faster_rcnn\models\research\object_detection\builders\post_processing_builder.py"", line 107, in _build_non_max_suppressor
    use_cpu_nms=nms_config.use_cpu_nms)
AttributeError: use_cpu_nms

======================================================================
ERROR: test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul (__main__.ModelBuilderTF2Test)
test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul (__main__.ModelBuilderTF2Test)
test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul(use_matmul_crop_and_resize=True, enable_mask_prediction=False)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""C:\Users\deep-user\.conda\envs\tensorflow2\lib\site-packages\absl\testing\parameterized.py"", line 263, in bound_param_test
    test_method(self, **testcase_params)
  File ""D:\faster_rcnn\models\research\object_detection\builders\model_builder_test.py"", line 262, in test_create_faster_rcnn_models_from_config
    model = model_builder.build(model_proto, is_training=True)
  File ""D:\faster_rcnn\models\research\object_detection\builders\model_builder.py"", line 1062, in build
    add_summaries)
  File ""D:\faster_rcnn\models\research\object_detection\builders\model_builder.py"", line 663, in _build_faster_rcnn_model
    ) = post_processing_builder.build(frcnn_config.second_stage_post_processing)
  File ""D:\faster_rcnn\models\research\object_detection\builders\post_processing_builder.py"", line 59, in build
    post_processing_config.batch_non_max_suppression)
  File ""D:\faster_rcnn\models\research\object_detection\builders\post_processing_builder.py"", line 107, in _build_non_max_suppressor
    use_cpu_nms=nms_config.use_cpu_nms)
AttributeError: use_cpu_nms

======================================================================
ERROR: test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul (__main__.ModelBuilderTF2Test)
test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul (__main__.ModelBuilderTF2Test)
test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul(use_matmul_crop_and_resize=False, enable_mask_prediction=True)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""C:\Users\deep-user\.conda\envs\tensorflow2\lib\site-packages\absl\testing\parameterized.py"", line 263, in bound_param_test
    test_method(self, **testcase_params)
  File ""D:\faster_rcnn\models\research\object_detection\builders\model_builder_test.py"", line 262, in test_create_faster_rcnn_models_from_config
    model = model_builder.build(model_proto, is_training=True)
  File ""D:\faster_rcnn\models\research\object_detection\builders\model_builder.py"", line 1062, in build
    add_summaries)
  File ""D:\faster_rcnn\models\research\object_detection\builders\model_builder.py"", line 663, in _build_faster_rcnn_model
    ) = post_processing_builder.build(frcnn_config.second_stage_post_processing)
  File ""D:\faster_rcnn\models\research\object_detection\builders\post_processing_builder.py"", line 59, in build
    post_processing_config.batch_non_max_suppression)
  File ""D:\faster_rcnn\models\research\object_detection\builders\post_processing_builder.py"", line 107, in _build_non_max_suppressor
    use_cpu_nms=nms_config.use_cpu_nms)
AttributeError: use_cpu_nms

======================================================================
ERROR: test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul (__main__.ModelBuilderTF2Test)
test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul (__main__.ModelBuilderTF2Test)
test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul(use_matmul_crop_and_resize=True, enable_mask_prediction=True)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""C:\Users\deep-user\.conda\envs\tensorflow2\lib\site-packages\absl\testing\parameterized.py"", line 263, in bound_param_test
    test_method(self, **testcase_params)
  File ""D:\faster_rcnn\models\research\object_detection\builders\model_builder_test.py"", line 262, in test_create_faster_rcnn_models_from_config
    model = model_builder.build(model_proto, is_training=True)
  File ""D:\faster_rcnn\models\research\object_detection\builders\model_builder.py"", line 1062, in build
    add_summaries)
  File ""D:\faster_rcnn\models\research\object_detection\builders\model_builder.py"", line 663, in _build_faster_rcnn_model
    ) = post_processing_builder.build(frcnn_config.second_stage_post_processing)
  File ""D:\faster_rcnn\models\research\object_detection\builders\post_processing_builder.py"", line 59, in build
    post_processing_config.batch_non_max_suppression)
  File ""D:\faster_rcnn\models\research\object_detection\builders\post_processing_builder.py"", line 107, in _build_non_max_suppressor
    use_cpu_nms=nms_config.use_cpu_nms)
AttributeError: use_cpu_nms

======================================================================
ERROR: test_create_rfcn_model_from_config (__main__.ModelBuilderTF2Test)
test_create_rfcn_model_from_config (__main__.ModelBuilderTF2Test)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""D:\faster_rcnn\models\research\object_detection\builders\model_builder_test.py"", line 282, in test_create_rfcn_model_from_config
    model = model_builder.build(model_proto, is_training=True)
  File ""D:\faster_rcnn\models\research\object_detection\builders\model_builder.py"", line 1062, in build
    add_summaries)
  File ""D:\faster_rcnn\models\research\object_detection\builders\model_builder.py"", line 663, in _build_faster_rcnn_model
    ) = post_processing_builder.build(frcnn_config.second_stage_post_processing)
  File ""D:\faster_rcnn\models\research\object_detection\builders\post_processing_builder.py"", line 59, in build
    post_processing_config.batch_non_max_suppression)
  File ""D:\faster_rcnn\models\research\object_detection\builders\post_processing_builder.py"", line 107, in _build_non_max_suppressor
    use_cpu_nms=nms_config.use_cpu_nms)
AttributeError: use_cpu_nms

======================================================================
ERROR: test_create_ssd_fpn_model_from_config (__main__.ModelBuilderTF2Test)
test_create_ssd_fpn_model_from_config (__main__.ModelBuilderTF2Test)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""D:\faster_rcnn\models\research\object_detection\builders\model_builder_test.py"", line 220, in test_create_ssd_fpn_model_from_config
    model = model_builder.build(model_proto, is_training=True)
  File ""D:\faster_rcnn\models\research\object_detection\builders\model_builder.py"", line 1062, in build
    add_summaries)
  File ""D:\faster_rcnn\models\research\object_detection\builders\model_builder.py"", line 402, in _build_ssd_model
    ssd_config.post_processing)
  File ""D:\faster_rcnn\models\research\object_detection\builders\post_processing_builder.py"", line 59, in build
    post_processing_config.batch_non_max_suppression)
  File ""D:\faster_rcnn\models\research\object_detection\builders\post_processing_builder.py"", line 107, in _build_non_max_suppressor
    use_cpu_nms=nms_config.use_cpu_nms)
AttributeError: use_cpu_nms

======================================================================
ERROR: test_create_ssd_models_from_config (__main__.ModelBuilderTF2Test)
test_create_ssd_models_from_config (__main__.ModelBuilderTF2Test)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""D:\faster_rcnn\models\research\object_detection\builders\model_builder_test.py"", line 212, in test_create_ssd_models_from_config
    model = model_builder.build(model_proto, is_training=True)
  File ""D:\faster_rcnn\models\research\object_detection\builders\model_builder.py"", line 1062, in build
    add_summaries)
  File ""D:\faster_rcnn\models\research\object_detection\builders\model_builder.py"", line 402, in _build_ssd_model
    ssd_config.post_processing)
  File ""D:\faster_rcnn\models\research\object_detection\builders\post_processing_builder.py"", line 59, in build
    post_processing_config.batch_non_max_suppression)
  File ""D:\faster_rcnn\models\research\object_detection\builders\post_processing_builder.py"", line 107, in _build_non_max_suppressor
    use_cpu_nms=nms_config.use_cpu_nms)
AttributeError: use_cpu_nms

----------------------------------------------------------------------
Ran 20 tests in 2.246s

FAILED (errors=11, skipped=1)
 

## 6. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
 
- TensorFlow installed from (source or binary): tensorflow installed using ""python -m pip install --use-feature=2020-resolver ."" as described in ""https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2.md""
- TensorFlow version: 2.4.0-dev20200907
- Python version: 3.6

- CUDA/cuDNN version: 10.1
- GPU model and memory: NVIDIA Quadro RTX4000 8Gb


",MediavoiceSrL,b'models:research type:bug',2020-09-08T14:14:15Z,2020-09-15T09:51:15Z,,,,,,,
9207,fix `base_url`,"The previous `base_url` led to 404 errors. This commit uses the correct base URL.

# Description

> :memo: Please include a summary of the change. 
>  
> * Please also include relevant motivation and context.  
> * List any dependencies that are required for this change.  

My motivation for this change arose from answering [this StackOverflow question](https://stackoverflow.com/q/63728740/5666087).

## Type of change

For a new feature or function, please create an issue first to discuss it
with us before submitting a pull request.

Note: Please delete options that are not relevant.

- [x] Bug fix (non-breaking change which fixes an issue)

## Tests

> :memo: Please describe the tests that you ran to verify your changes.
>  
> * Provide instructions so we can reproduce.  
> * Please also list any relevant details for your test configuration. 

**Test Configuration**:

I have not provided tests.

## Checklist

- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).
- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).
- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).
- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.
- [x] I have commented my code, particularly in hard-to-understand areas.
- [x] I have made corresponding changes to the documentation.
- [x] My changes generate no new warnings.
- [ ] I have added tests that prove my fix is effective or that my feature works.
",kaczmarj,b'cla: yes',2020-09-07T17:05:01Z,2020-09-18T21:14:26Z,,,,,,,
9202,gpuoptions in ConfigProto is not applied properly while running transformer model.,"# Prerequisites

Please answer the following questions for yourself before submitting an issue.

- [ ] I am using the latest TensorFlow Model Garden release and TensorFlow 2.
- [x] I am reporting the issue to the correct repository. (Model Garden official or research directory)
- [x] I checked to make sure that this issue has not been filed already.

## 1. The entire URL of the file you are using

https://github.com/tensorflow/models/tree/v1.13.0/official/transformer

## 2. Describe the bug

I want to add gpuoptions through ConfigProto such as ""allow_growth"" or ""per_process_gpu_memory_fraction"". I manually add this options into the transformer_main.py. Transformer is implemented via tf.Estimator so I followed Estimator API to insert ConfigProto. However, it is not applied.
Here is my code
![image](https://user-images.githubusercontent.com/20127356/92301385-65340280-ef9e-11ea-81a4-66e7571c6915.png)
 
After doing it, model training takes up the whole GPU memory which is supposed to take up only around 6GB. (base model)

## 3. Steps to reproduce

Just insert codes I attached in ""2. Describe the bug"" and run ""base"" transformer model and check gpu memory consumption using ""nvidia-smi -l 1"".

## 4. Expected behavior

It should have taken up the gpu memory only around 6GB.

## 5. Additional context

Include any logs that would be helpful to diagnose the problem.

## 6. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- Mobile device name if the issue happens on a mobile device:
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): 1.13.1
- Python version: 3.7
- Bazel version (if compiling from source): 0.21.0
- GCC/Compiler version (if compiling from source): 7.4.0
- CUDA/cuDNN version: 10.0 / 7
- GPU model and memory: NVIDIA Tesla V100, 32GB

<!-- 
Collect system information using our environment capture script.
https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can also obtain the TensorFlow version with:

1. TensorFlow 1.0
`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

2. TensorFlow 2.0
`python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`
-->
",gangmuk,b'models:official type:bug',2020-09-05T08:41:01Z,2020-09-25T19:45:49Z,,,,,,,
9194,Ep/mlflow,"# Description

> :memo: Please include a summary of the change. 
>  
> * Please also include relevant motivation and context.  
> * List any dependencies that are required for this change.  

## Type of change

For a new feature or function, please create an issue first to discuss it
with us before submitting a pull request.

Note: Please delete options that are not relevant.

- [ ] Bug fix (non-breaking change which fixes an issue)
- [ ] Documentation update
- [ ] TensorFlow 2 migration
- [ ] New feature (non-breaking change which adds functionality)
- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)
- [ ] A new research paper code implementation
- [ ] Other (Specify)

## Tests

> :memo: Please describe the tests that you ran to verify your changes.
>  
> * Provide instructions so we can reproduce.  
> * Please also list any relevant details for your test configuration.  

**Test Configuration**:

## Checklist

- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).
- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).
- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).
- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.
- [ ] I have commented my code, particularly in hard-to-understand areas.
- [ ] I have made corresponding changes to the documentation.
- [ ] My changes generate no new warnings.
- [ ] I have added tests that prove my fix is effective or that my feature works.
",epark-miovision,b'cla: no',2020-09-03T14:59:05Z,2020-09-03T14:59:29Z,,,,,,,
9193,there has the bug when use keras,"https://github.com/tensorflow/models/blob/f2c76e41f668b30cc6714ed8a866c07cc2f2275a/official/nlp/modeling/networks/bert_encoder.py#L215
The right code should be:
```
def get_config(self):
    base_config = super(TransformerEncoder, self).get_config()
    return dict(list(base_config.items()) + list(self._config_dict.items()))
```
tf.keras.models.load_model(
    filepath, custom_objects=None, compile=True, options=None
)
The api should work fine with this code rewrite",ImMrMa,b'models:official type:bug',2020-09-03T07:55:54Z,2020-09-06T06:22:55Z,,,,,,,
9186,"TypeError: ('Not JSON Serializable:', tf.float32)","# Prerequisites

Please answer the following questions for yourself before submitting an issue.

- [yes] I am using the latest TensorFlow Model Garden release and TensorFlow 2.
- [yes] I am reporting the issue to the correct repository. (Model Garden official or research directory)
- [yes] I checked to make sure that this issue has not been filed already.

## 1. The entire URL of the file you are using

https://github.com/tensorflow/models/tree/master/official/nlp/transformer/transformer_main.py

## 2. Describe the bug
I need a "".pb"" model(savedModel) for tf.serving, not just a "".ckpt"" model created by save_weights_only=TRUE.
When changed the ""save_weights_only"" option(in line 418) from ""True"" to ""False"",
the error occured: TypeError: ('Not JSON Serializable:', tf.float32)
![image](https://user-images.githubusercontent.com/7539692/91956469-45e76c00-ed37-11ea-8c1a-f215d0b2f063.png)


## 3. Steps to reproduce

I just ran the code in the URL above following its example tutorial. 
Two params were changed: hidden_size=256(default 512) AND filter_size=512(default 2048)
With the above configuration, weights could be saved successfully with the default ""save_weights_only=True"".

## 4. Expected behavior

if save_weights_only=False, a savedModel(not ckpt) would be generated.

## 5. Additional context

pycharm logs:

> 2020-09-02 07:46:07.054060: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
I0902 07:47:15.653520 140510663464768 keras_utils.py:122] TimeHistory: 87.05 seconds, 2352.78 examples/second between steps 0 and 100
2020-09-02 07:47:19.791337: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.
**INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(None, None, 256), dtype=tf.float32, name='inputs'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fc97e2fcc88>), {}).**
I0902 07:47:26.516451 140510663464768 def_function.py:1038] Unsupported signature for serialization: ((TensorSpec(shape=(None, None, 256), dtype=tf.float32, name='inputs'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fc97e2fcc88>), {}).
**INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(None, None), dtype=tf.int64, name='inputs'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fc97e7d0d68>), {}).**
I0902 07:47:26.516770 140510663464768 def_function.py:1038] Unsupported signature for serialization: ((TensorSpec(shape=(None, None), dtype=tf.int64, name='inputs'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fc97e7d0d68>), {}).
INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(None, None), dtype=tf.int64, name='inputs'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fc97e7e5a20>), {}).
I0902 07:47:26.516961 140510663464768 def_function.py:1038] Unsupported signature for serialization: ((TensorSpec(shape=(None, None), dtype=tf.int64, name='inputs'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fc97e7e5a20>), {}).
INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(None, None, 256), dtype=tf.float32, name='inputs'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fc97e30d860>), {}).
I0902 07:47:26.517098 140510663464768 def_function.py:1038] Unsupported signature for serialization: ((TensorSpec(shape=(None, None, 256), dtype=tf.float32, name='inputs'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fc97e30d860>), {}).
INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(None, None), dtype=tf.int64, name='inputs'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fc97e7e5a20>), {}).
I0902 07:47:27.793794 140510663464768 def_function.py:1038] Unsupported signature for serialization: ((TensorSpec(shape=(None, None), dtype=tf.int64, name='inputs'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fc97e7e5a20>), {}).
INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(None, None, 256), dtype=tf.float32, name='inputs'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fc97e30d860>), {}).
I0902 07:47:27.794195 140510663464768 def_function.py:1038] Unsupported signature for serialization: ((TensorSpec(shape=(None, None, 256), dtype=tf.float32, name='inputs'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fc97e30d860>), {}).
INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(None, None, 256), dtype=tf.float32, name='inputs'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fc97e2fcc88>), {}).
I0902 07:47:27.794377 140510663464768 def_function.py:1038] Unsupported signature for serialization: ((TensorSpec(shape=(None, None, 256), dtype=tf.float32, name='inputs'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fc97e2fcc88>), {}).
INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(None, None), dtype=tf.int64, name='inputs'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fc97e7d0d68>), {}).
I0902 07:47:27.794553 140510663464768 def_function.py:1038] Unsupported signature for serialization: ((TensorSpec(shape=(None, None), dtype=tf.int64, name='inputs'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fc97e7d0d68>), {}).
INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(None, None, 256), dtype=tf.float32, name='inputs'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fc97e2fcc88>), {}).
I0902 07:47:27.794695 140510663464768 def_function.py:1038] Unsupported signature for serialization: ((TensorSpec(shape=(None, None, 256), dtype=tf.float32, name='inputs'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fc97e2fcc88>), {}).
INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(None, None), dtype=tf.int64, name='inputs'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fc97e7d0d68>), {}).
I0902 07:47:27.794836 140510663464768 def_function.py:1038] Unsupported signature for serialization: ((TensorSpec(shape=(None, None), dtype=tf.int64, name='inputs'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fc97e7d0d68>), {}).
INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(None, None, 256), dtype=tf.float32, name='inputs'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fc97e2fcc88>), {}).
I0902 07:47:28.309843 140510663464768 def_function.py:1038] Unsupported signature for serialization: ((TensorSpec(shape=(None, None, 256), dtype=tf.float32, name='inputs'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fc97e2fcc88>), {}).
INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(None, None), dtype=tf.int64, name='inputs'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fc97e7d0d68>), {}).
I0902 07:47:28.310060 140510663464768 def_function.py:1038] Unsupported signature for serialization: ((TensorSpec(shape=(None, None), dtype=tf.int64, name='inputs'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fc97e7d0d68>), {}).
INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(None, None), dtype=tf.int64, name='inputs'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fc97e7e5a20>), {}).
I0902 07:47:28.310272 140510663464768 def_function.py:1038] Unsupported signature for serialization: ((TensorSpec(shape=(None, None), dtype=tf.int64, name='inputs'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fc97e7e5a20>), {}).
INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(None, None, 256), dtype=tf.float32, name='inputs'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fc97e30d860>), {}).
I0902 07:47:28.310407 140510663464768 def_function.py:1038] Unsupported signature for serialization: ((TensorSpec(shape=(None, None, 256), dtype=tf.float32, name='inputs'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fc97e30d860>), {}).
INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(None, None), dtype=tf.int64, name='inputs'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fc97e7e5a20>), {}).
I0902 07:47:28.359903 140510663464768 def_function.py:1038] Unsupported signature for serialization: ((TensorSpec(shape=(None, None), dtype=tf.int64, name='inputs'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fc97e7e5a20>), {}).
INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(None, None, 256), dtype=tf.float32, name='inputs'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fc97e30d860>), {}).
I0902 07:47:28.360061 140510663464768 def_function.py:1038] Unsupported signature for serialization: ((TensorSpec(shape=(None, None, 256), dtype=tf.float32, name='inputs'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fc97e30d860>), {}).
INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(None, None, 256), dtype=tf.float32, name='inputs'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fc97e2fcc88>), {}).
I0902 07:47:28.360238 140510663464768 def_function.py:1038] Unsupported signature for serialization: ((TensorSpec(shape=(None, None, 256), dtype=tf.float32, name='inputs'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fc97e2fcc88>), {}).
INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(None, None), dtype=tf.int64, name='inputs'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fc97e7d0d68>), {}).
I0902 07:47:28.360367 140510663464768 def_function.py:1038] Unsupported signature for serialization: ((TensorSpec(shape=(None, None), dtype=tf.int64, name='inputs'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fc97e7d0d68>), {}).
INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(None, None, 256), dtype=tf.float32, name='inputs'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fc97e2fcc88>), {}).
I0902 07:47:28.360511 140510663464768 def_function.py:1038] Unsupported signature for serialization: ((TensorSpec(shape=(None, None, 256), dtype=tf.float32, name='inputs'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fc97e2fcc88>), {}).
INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(None, None), dtype=tf.int64, name='inputs'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fc97e7d0d68>), {}).
I0902 07:47:28.360628 140510663464768 def_function.py:1038] Unsupported signature for serialization: ((TensorSpec(shape=(None, None), dtype=tf.int64, name='inputs'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7fc97e7d0d68>), {}).
Traceback (most recent call last):
  File ""/home/xxx/pycharm_proj/models-master/official/nlp/transformer/transformer_main.py"", line 628, in <module>
    app.run(main)
  File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""/home/xxx/pycharm_proj/models-master/official/nlp/transformer/transformer_main.py"", line 609, in main
    task.train()
  File ""/home/xxx/pycharm_proj/models-master/official/nlp/transformer/transformer_main.py"", line 437, in train
    verbose=(2 if flags_obj.enable_time_history else 1))
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py"", line 108, in _method_wrapper
    return method(self, *args, **kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py"", line 1137, in fit
    callbacks.on_epoch_end(epoch, epoch_logs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py"", line 412, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py"", line 1249, in on_epoch_end
    self._save_model(epoch=epoch, logs=logs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py"", line 1313, in _save_model
    self.model.save(filepath, overwrite=True, options=self._options)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py"", line 1979, in save
    signatures, options)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/save.py"", line 134, in save_model
    signatures, options)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/saved_model/save.py"", line 80, in save
    save_lib.save(model, filepath, signatures, options)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/save.py"", line 976, in save
    obj, export_dir, signatures, options, meta_graph_def)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/save.py"", line 1076, in _build_meta_graph
    asset_info.asset_index)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/save.py"", line 721, in _serialize_object_graph
    saveable_view.function_name_map)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/save.py"", line 761, in _write_object_proto
    metadata=obj._tracking_metadata)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py"", line 3011, in _tracking_metadata
    return self._trackable_saved_model_saver.tracking_metadata
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/saved_model/base_serialization.py"", line 54, in tracking_metadata
    return json_utils.Encoder().encode(self.python_properties)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/saved_model/json_utils.py"", line 44, in encode
    return super(Encoder, self).encode(_encode_tuple(obj))
  File ""/usr/lib/python3.6/json/encoder.py"", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File ""/usr/lib/python3.6/json/encoder.py"", line 257, in iterencode
    return _iterencode(o, 0)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/saved_model/json_utils.py"", line 41, in default
    return serialization.get_json_type(obj)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/serialization.py"", line 72, in get_json_type
    raise TypeError('Not JSON Serializable:', obj)
TypeError: ('Not JSON Serializable:', tf.float32)

## 6. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  Ubuntu 18.04.3 LTS
- Mobile device name if the issue happens on a mobile device:  None
- TensorFlow installed from (source or binary):  pip
- TensorFlow version (use command below):  tensorflow-gpu 2.3.0
- Python version:  3.6.8
- Bazel version (if compiling from source):  None
- GCC/Compiler version (if compiling from source):  None
- CUDA/cuDNN version:  CUDA 10.1   Driver Version: 430.50
- GPU model and memory:  one GTX1080TI, 11G memory

<!-- 
Collect system information using our environment capture script.
https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can also obtain the TensorFlow version with:

1. TensorFlow 1.0
`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

2. TensorFlow 2.0
`python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`
-->
",2020zyc,b'models:official type:bug',2020-09-02T08:26:47Z,2020-09-14T01:54:45Z,,,,,,,
9185,Export Inference Graph feature in TF2 and create frozen inference graph and how test on new image,"I am working with tensorflow 2. I could run completely but the problem is that I can't create frozen inference graph in tf2. so how should I test on new image without having frozen inference graph and what should I use instead of it, since exporter_main_v2.py does not create inference graph.













<!--
As per our GitHub Policy (https://github.com/tensorflow/models/blob/master/ISSUES.md), we only address code bugs, documentation issues, and feature requests on GitHub.

We will automatically close questions and help related issues.

Please go to Stack Overflow (http://stackoverflow.com/questions/tagged/tensorflow-model-garden) for questions and help.

-->
",matinslh,b'stalled stat:awaiting response type:support',2020-09-02T07:45:52Z,2020-09-18T16:17:55Z,,,,,,,
9184,fix broken url for attention_ocr README.md,"# Description

> :memo: Please include a summary of the change. 
>  
research/street does not exist in master branch, so some url is not available.
And we should not rely on that model, so I copy file ""fsns_urls.txt"" here.


## Type of change

For a new feature or function, please create an issue first to discuss it
with us before submitting a pull request.

Note: Please delete options that are not relevant.

- [ ] Bug fix (non-breaking change which fixes an issue)
- [x] Documentation update
- [ ] TensorFlow 2 migration
- [ ] New feature (non-breaking change which adds functionality)
- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)
- [ ] A new research paper code implementation
- [ ] Other (Specify)

## Tests

> :memo: Please describe the tests that you ran to verify your changes.
>  
> * Provide instructions so we can reproduce.  
> * Please also list any relevant details for your test configuration.  

**Test Configuration**:

## Checklist

- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).
- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).
- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).
- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.
- [ ] I have commented my code, particularly in hard-to-understand areas.
- [x] I have made corresponding changes to the documentation.
- [x] My changes generate no new warnings.
- [ ] I have added tests that prove my fix is effective or that my feature works.
",moneypi,b'cla: yes',2020-09-02T06:45:55Z,2020-09-09T16:34:41Z,,,,,,,
9183,"[TF 2 Object Detection API] Unable to run evaluation - TypeError: expected str, bytes or os.PathLike object, not NoneType","# Prerequisites

Please answer the following questions for yourself before submitting an issue.

- [ Y ] I am using the latest TensorFlow Model Garden release and TensorFlow 2.
- [ Y ] I am reporting the issue to the correct repository. (Model Garden official or research directory)
- [ Y ] I checked to make sure that this issue has not already been filed.

## 1. The entire URL of the file you are using

https://github.com/tensorflow/models/blob/master/research/object_detection/model_main_tf2.py

## 2. Describe the bug

When I run model_main_tf2.py using the steps mentioned in the official guide [(here)](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_training_and_evaluation.md) and execute following code (I left out references to my local files):

```
python model_main_tf2.py \
--pipeline_config_path=C:/Users/User/Documents/TensorFlow/workspace/mgr_holes/pre-trained/faster_rcnn_resnet50_v1_640x640_coco17_tpu-8/pipeline.config \
--checkpoint_dir=models/faster_rcnn_resnet50_v1_640x640_coco17_tpu-8_groceries \
 --alsologtostderr 

```
The TF2 initializes correctly, load the model, latest checkpoint is loaded and then I get the below error message:

```
I0901 22:21:48.011265 49544 checkpoint_utils.py:134] Found new checkpoint at kodels/faster_rcnn_resnet50_v1_640x640_coco17_tpu-8_groceries\ckpt-30
Traceback (most recent call last):
  File ""model_main_tf2.py"", line 113, in <module>
    tf.compat.v1.app.run()
  File ""C:\Users\User\anaconda3\envs\Mgr_TF2_P8\lib\site-packages\tensorflow\python\platform\app.py"", line 40, in run
_run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""C:\Users\User\anaconda3\envs\Mgr_TF2_P8\lib\site-packages\absl\app.py"", line 300, in run
    _run_main(main, args)
  File ""C:\Users\User\anaconda3\envs\Mgr_TF2_P8\lib\site-packages\absl\app.py"", line 251, in _run_main
    sys.exit(main(argv))
  File ""model_main_tf2.py"", line 80, in main
    model_lib_v2.eval_continuously(
  File ""C:\Users\User\anaconda3\envs\Mgr_TF2_P8\lib\site-packages\object_detection\model_lib_v2.py"", line 974, in eval_continuously
    os.path.join(model_dir, 'eval', eval_name))
  File ""C:\Users\User\anaconda3\envs\Mgr_TF2_P8\lib\ntpath.py"", line 78, in join
    path = os.fspath(path)
TypeError: expected str, bytes or os.PathLike object, not NoneType
```

This error message is consistent across my 3 conda environments (on python 3.7, python 3.8 with TF 2.2 and python 3.8 with TF 2.3). I am able to execute the training just as expected but evaluation, no matter what model is used and what evaluation metric is specified in the config file, always fails on the below message.

## 3. Steps to reproduce

As stated above, the script which I execute is following the below template:

```
# From the tensorflow/models/research/ directory
PIPELINE_CONFIG_PATH=""XXXX/models/research/object_detection/configs/tf2/uhuru.config""
MODEL_DIR=""XXXX""
CHECKPOINT_DIR=${MODEL_DIR}
SAMPLE_1_OF_N_EVAL_EXAMPLES=1
nohup python XXXX/models/research/object_detection/model_main_tf2.py \
        --pipeline_config_path=${PIPELINE_CONFIG_PATH} \
        --model_dir=${MODEL_DIR} \
        --checkpoint_dir=${CHECKPOINT_DIR} \
        --alsologtostderr 
```

Below I have also attached example of one of the config files used during training and when trying to execute eval:

```
# Faster R-CNN with Resnet-50 (v1)
# Trained on COCO, initialized from Imagenet classification checkpoint

# Achieves -- mAP on COCO14 minival dataset.

# This config is TPU compatible.

model {
  faster_rcnn {
    num_classes: 4
    image_resizer {
      keep_aspect_ratio_resizer {
        min_dimension: 640
        max_dimension: 640
        pad_to_max_dimension: true
      }
    }
    feature_extractor {
      type: 'faster_rcnn_resnet50_keras'
      batch_norm_trainable: true
    }
    first_stage_anchor_generator {
      grid_anchor_generator {
        scales: [0.25, 0.5, 1.0, 2.0]
        aspect_ratios: [0.5, 1.0, 2.0]
        height_stride: 16
        width_stride: 16
      }
    }
    first_stage_box_predictor_conv_hyperparams {
      op: CONV
      regularizer {
        l2_regularizer {
          weight: 0.0
        }
      }
      initializer {
        truncated_normal_initializer {
          stddev: 0.01
        }
      }
    }
    first_stage_nms_score_threshold: 0.0
    first_stage_nms_iou_threshold: 0.7
    first_stage_max_proposals: 300
    first_stage_localization_loss_weight: 2.0
    first_stage_objectness_loss_weight: 1.0
    initial_crop_size: 14
    maxpool_kernel_size: 2
    maxpool_stride: 2
    second_stage_box_predictor {
      mask_rcnn_box_predictor {
        use_dropout: false
        dropout_keep_probability: 1.0
        fc_hyperparams {
          op: FC
          regularizer {
            l2_regularizer {
              weight: 0.0
            }
          }
          initializer {
            variance_scaling_initializer {
              factor: 1.0
              uniform: true
              mode: FAN_AVG
            }
          }
        }
        share_box_across_classes: true
      }
    }
    second_stage_post_processing {
      batch_non_max_suppression {
        score_threshold: 0.0
        iou_threshold: 0.6
        max_detections_per_class: 100
        max_total_detections: 300
      }
      score_converter: SOFTMAX
    }
    second_stage_localization_loss_weight: 2.0
    second_stage_classification_loss_weight: 1.0
    use_static_shapes: true
    use_matmul_crop_and_resize: true
    clip_anchors_to_image: true
    use_static_balanced_label_sampler: true
    use_matmul_gather_in_matcher: true
  }
}

train_config: {
  batch_size: 1
  sync_replicas: true
  startup_delay_steps: 0
  replicas_to_aggregate: 8
  num_steps: 250000
  optimizer {
    momentum_optimizer: {
      learning_rate: {
        cosine_decay_learning_rate {
          learning_rate_base: .04
          total_steps: 25000
          warmup_learning_rate: .013333
          warmup_steps: 2000
        }
      }
      momentum_optimizer_value: 0.9
    }
    use_moving_average: false
  }
  fine_tune_checkpoint_version: V2
  fine_tune_checkpoint: ""C:/Users/User/Documents/TensorFlow/workspace/mgr_holes/pre-trained/faster_rcnn_resnet50_v1_640x640_coco17_tpu-8_groceries/checkpoint/ckpt-0""
  fine_tune_checkpoint_type: ""detection""
  data_augmentation_options {
    random_horizontal_flip {
    }
  }

  max_number_of_boxes: 100
  unpad_groundtruth_tensors: false
  use_bfloat16: false  # works only on TPUs
}

train_input_reader: {
  label_map_path: ""C:/Users/User/Documents/TensorFlow/workspace/mgr_training_demo/annotations/label_map.pbtxt""
  tf_record_input_reader {
    input_path: ""C:/Users/User/Documents/TensorFlow/workspace/mgr_training_demo/annotations/train.record""
  }
}

eval_config: {
  metrics_set: ""oid_V2_detection_metrics""
  use_moving_averages: false
  batch_size: 1;
}

eval_input_reader: {
  label_map_path: ""C:/Users/User/Documents/TensorFlow/workspace/mgr_training_demo/annotations/label_map.pbtxt""
  shuffle: true
  num_epochs: 1
  tf_record_input_reader {
    input_path: ""C:/Users/User/Documents/TensorFlow/workspace/mgr_holes/annotations/test.record""
  }
}

```
## 4. Expected behavior

I expect the evaluation process to start and print evaluation metrics (like mAP) to the Tensorboard. Currently, even during the training, no evaluation data is visible.

## 5. Additional context

Training works perfectly as expected. Evaluation cannot be launched and even when eval options are added when launching model_main_tf2.py, no evaluation metrics are printed to the Tensorflow.
Only loss, steps and train images are visible in the Tensorboard.

## 6. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- Mobile device name if the issue happens on a mobile device:
- TensorFlow installed from (source or binary): TF installed in conda environment via pip
- TensorFlow version (use command below): v2.3.0-rc2-23-gb36436b087 2.3.0
- Python version: 3.8
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 10.1.243
- GPU model and memory: NVIDIA GeForce RTX 2060

<!-- 
Collect system information using our environment capture script.
https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can also obtain the TensorFlow version with:

1. TensorFlow 1.0
`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

2. TensorFlow 2.0
`python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`
-->
",Panaroja,b'models:research type:bug',2020-09-01T22:03:53Z,2020-09-01T22:41:41Z,,,,,,,
9181,W0901 18:59:43.630363 140028609734464 deprecation.py:317] From /home/ayennam/.virtualenvs/sensable3_8/lib/python3.8/site-packages/object_detection/inputs.py:259: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating: Use `tf.cast` instead.,"

## 6. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):18.04
- Mobile device name if the issue happens on a mobile device:
- TensorFlow installed from (source or binary):na
- TensorFlow version (use command below):2.2.0
- Python version:3.8
- Bazel version (if compiling from source):na
- GCC/Compiler version (if compiling from source):na
- CUDA/cuDNN version: 10.1/7.6.5
- GPU model and memory: 2080ti 





",angyee,b'models:research stalled stat:awaiting response type:bug',2020-09-01T13:40:08Z,2020-10-06T05:09:27Z,,,,,,,
9179,DELG export model problem,"# Trianing

`python3 train.py \
  --train_file_pattern=gldv2_dataset/tfrecord/train* \
  --validation_file_pattern=gldv2_dataset/tfrecord/validation* \
  --imagenet_checkpoint=resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5 \
  --dataset_version=gld_v2_clean \
  --logdir=gldv2_training/ \
  --delg_global_features`

# Export model
`python3 model/export_global_model.py --ckpt_path=gldv3_training_delg/delf_weights --export_path=delg_gldv3_model_global --input_scales_list=0.70710677,1.0,1.4142135 --multi_scale_pool_type=sum --normalize_global_descriptor
`

Below is my export model logs.

`2020-09-01 17:58:00.038762: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 11210 MB memory) -> physical GPU (device: 1, name: TITAN Xp COLLECTORS EDITION, pci bus id: 0000:08:00.0, compute capability: 6.1)
Checkpoint loaded from  gldv3_training_delg/delf_weights
multi_scale_pool_type is  sum
multi_scale_pool_type is  sum
WARNING:tensorflow:Skipping full serialization of Keras layer <delf.python.training.model.delf_model.Delf object at 0x7f38f3b58c88>, because it is not built.
W0901 17:58:03.413664 139884055152384 save_impl.py:78] Skipping full serialization of Keras layer <delf.python.training.model.delf_model.Delf object at 0x7f38f3b58c88>, because it is not built.
WARNING:tensorflow:Skipping full serialization of Keras layer <delf.python.training.model.resnet50.ResNet50 object at 0x7f38e0369780>, because it is not built.
W0901 17:58:03.413844 139884055152384 save_impl.py:78] Skipping full serialization of Keras layer <delf.python.training.model.resnet50.ResNet50 object at 0x7f38e0369780>, because it is not built.
WARNING:tensorflow:Skipping full serialization of Keras layer <delf.python.training.model.delf_model.AttentionModel object at 0x7f38e024ab38>, because it is not built.
W0901 17:58:03.413996 139884055152384 save_impl.py:78] Skipping full serialization of Keras layer <delf.python.training.model.delf_model.AttentionModel object at 0x7f38e024ab38>, because it is not built.
WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.pooling.AveragePooling2D object at 0x7f38e024a908>, because it is not built.
W0901 17:58:06.836568 139884055152384 save_impl.py:78] Skipping full serialization of Keras layer <tensorflow.python.keras.layers.pooling.AveragePooling2D object at 0x7f38e024a908>, because it is not built.
WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f38e024ae80>, because it is not built.
W0901 17:58:06.836720 139884055152384 save_impl.py:78] Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f38e024ae80>, because it is not built.
WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f38e0257198>, because it is not built.
W0901 17:58:06.836797 139884055152384 save_impl.py:78] Skipping full serialization of Keras layer <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f38e0257198>, because it is not built.
WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f38e0257400>, because it is not built.
W0901 17:58:06.836868 139884055152384 save_impl.py:78] Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f38e0257400>, because it is not built.
WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Activation object at 0x7f38e0257668>, because it is not built.
W0901 17:58:06.836937 139884055152384 save_impl.py:78] Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Activation object at 0x7f38e0257668>, because it is not built.
2020-09-01 17:58:06.927586: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.
INFO:tensorflow:Assets written to: delg_gldv3_model_global/assets
I0901 17:58:12.971750 139884055152384 builder_impl.py:775] Assets written to: delg_gldv3_model_global/assets
WARNING:tensorflow:Unresolved object in checkpoint: (root).cosine_weights
W0901 17:58:13.241488 139884055152384 util.py:150] Unresolved object in checkpoint: (root).cosine_weights
WARNING:tensorflow:Unresolved object in checkpoint: (root).scale_factor
W0901 17:58:13.241673 139884055152384 util.py:150] Unresolved object in checkpoint: (root).scale_factor
WARNING:tensorflow:Unresolved object in checkpoint: (root).attn_classification
W0901 17:58:13.241752 139884055152384 util.py:150] Unresolved object in checkpoint: (root).attn_classification
WARNING:tensorflow:Unresolved object in checkpoint: (root).backbone.subsampling_layer
W0901 17:58:13.241827 139884055152384 util.py:150] Unresolved object in checkpoint: (root).backbone.subsampling_layer
WARNING:tensorflow:Unresolved object in checkpoint: (root).backbone.embedding_layer
W0901 17:58:13.241896 139884055152384 util.py:150] Unresolved object in checkpoint: (root).backbone.embedding_layer
WARNING:tensorflow:Unresolved object in checkpoint: (root).attn_classification.kernel
W0901 17:58:13.241961 139884055152384 util.py:150] Unresolved object in checkpoint: (root).attn_classification.kernel
WARNING:tensorflow:Unresolved object in checkpoint: (root).attn_classification.bias
W0901 17:58:13.241998 139884055152384 util.py:150] Unresolved object in checkpoint: (root).attn_classification.bias
WARNING:tensorflow:Unresolved object in checkpoint: (root).backbone.embedding_layer.kernel
W0901 17:58:13.242039 139884055152384 util.py:150] Unresolved object in checkpoint: (root).backbone.embedding_layer.kernel
WARNING:tensorflow:Unresolved object in checkpoint: (root).backbone.embedding_layer.bias
W0901 17:58:13.242076 139884055152384 util.py:150] Unresolved object in checkpoint: (root).backbone.embedding_layer.bias
WARNING:tensorflow:Unresolved object in checkpoint: (root).attention.conv1.kernel
W0901 17:58:13.242113 139884055152384 util.py:150] Unresolved object in checkpoint: (root).attention.conv1.kernel
WARNING:tensorflow:Unresolved object in checkpoint: (root).attention.conv1.bias
W0901 17:58:13.242150 139884055152384 util.py:150] Unresolved object in checkpoint: (root).attention.conv1.bias
WARNING:tensorflow:Unresolved object in checkpoint: (root).attention.bn_conv1.axis
W0901 17:58:13.242186 139884055152384 util.py:150] Unresolved object in checkpoint: (root).attention.bn_conv1.axis
WARNING:tensorflow:Unresolved object in checkpoint: (root).attention.bn_conv1.gamma
W0901 17:58:13.242222 139884055152384 util.py:150] Unresolved object in checkpoint: (root).attention.bn_conv1.gamma
WARNING:tensorflow:Unresolved object in checkpoint: (root).attention.bn_conv1.beta
W0901 17:58:13.242258 139884055152384 util.py:150] Unresolved object in checkpoint: (root).attention.bn_conv1.beta
WARNING:tensorflow:Unresolved object in checkpoint: (root).attention.bn_conv1.moving_mean
W0901 17:58:13.242294 139884055152384 util.py:150] Unresolved object in checkpoint: (root).attention.bn_conv1.moving_mean
WARNING:tensorflow:Unresolved object in checkpoint: (root).attention.bn_conv1.moving_variance
W0901 17:58:13.242329 139884055152384 util.py:150] Unresolved object in checkpoint: (root).attention.bn_conv1.moving_variance
WARNING:tensorflow:Unresolved object in checkpoint: (root).attention.conv2.kernel
W0901 17:58:13.242365 139884055152384 util.py:150] Unresolved object in checkpoint: (root).attention.conv2.kernel
WARNING:tensorflow:Unresolved object in checkpoint: (root).attention.conv2.bias
W0901 17:58:13.242400 139884055152384 util.py:150] Unresolved object in checkpoint: (root).attention.conv2.bias
WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.
W0901 17:58:13.242486 139884055152384 util.py:158] A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.`

# Extract Features
` python ../examples/extract_features.py --config_path ../delg/delg_gld_config.pbtxt --list_images_path ../examples/list_images.txt --output_dir ../delg/features
`

Below is my extract features error logs.

`2020-09-01 18:00:25.127793: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
Reading list of images...
done! Found 2 images
2020-09-01 18:00:26.965288: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 11210 MB memory) -> physical GPU (device: 1, name: TITAN Xp COLLECTORS EDITION, pci bus id: 0000:08:00.0, compute capability: 6.1)
Traceback (most recent call last):
  File ""../examples/extract_features.py"", line 144, in <module>
    app.run(main=main, argv=[sys.argv[0]] + unparsed)
  File ""/home/ss/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/platform/app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""/home/ss/anaconda3/envs/tf/lib/python3.6/site-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/home/ss/anaconda3/envs/tf/lib/python3.6/site-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""../examples/extract_features.py"", line 81, in main
    extractor_fn = extractor.MakeExtractor(config)
  File ""/home/ss/ai-competition/models/research/delf/delf/python/examples/extractor.py"", line 132, in MakeExtractor
    model = model.prune(feeds=feeds, fetches=fetches)
AttributeError: '_UserObject' object has no attribute 'prune'`

How to solve this error? Thanks in advance.
",ChenYingpeng,b'models:research type:bug',2020-09-01T10:03:10Z,2020-09-11T16:47:48Z,,,,,,,
9178,training deeplab on cityscapes dataset,"<!--
As per our GitHub Policy (https://github.com/tensorflow/models/blob/master/ISSUES.md), we only address code bugs, documentation issues, and feature requests on GitHub.

We will automatically close questions and help related issues.

Please go to Stack Overflow (http://stackoverflow.com/questions/tagged/tensorflow-model-garden) for questions and help.

-->
I'm trying to train deeplab on cityscapes dataset,
I've converted the dataset to tfrecord successfully but there is a problem running the train.py
`
Traceback (most recent call last):
  File ""train.py"", line 23, in <module>
    from deeplab.datasets import segmentation_dataset
ImportError: cannot import name 'segmentation_dataset' from 'deeplab.datasets' (/home/rahbinsanat/tensorflow/models/research/deeplab/datasets/__init__.py)
`
I got this error. I would be glad to know what's going wrong.",malekiamir,b'type:support',2020-09-01T07:33:08Z,2020-09-01T10:24:40Z,,,,,,,
9175,Converting SSD MobileNet v2 320x320 From Saved Model to TFLite - tensorflow.lite.python.convert.ConverterError: requires all operands and results to have compatible element types,"# Prerequisites

Please answer the following questions for yourself before submitting an issue.

- [x] I am using the latest TensorFlow Model Garden release and TensorFlow 2.
- [x] I am reporting the issue to the correct repository. (Model Garden official or research directory)
- [x] I checked to make sure that this issue has not already been filed.

## 1. The entire URL of the file you are using

Python file below which is based upon https://www.tensorflow.org/lite/convert/python_api#converting_a_savedmodel_

## 2. Describe the bug

When I am trying to convert the `SSD MobileNet v2 320x320` from `saved_model` to a `TFLite file`, it gives me an error when calling `converter.convert()` (Python file under the Steps to Reproduce section) `ConverterError: <unknown>:0: error: loc(""Func/StatefulPartitionedCall/input/_0""): requires all operands and results to have compatible element types`

```
raceback (most recent call last):
  File ""/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/lite/python/convert.py"", line 196, in toco_convert_protos
    model_str = wrap_toco.wrapped_toco_convert(model_flags_str,
  File ""/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/lite/python/wrap_toco.py"", line 32, in wrapped_toco_convert
    return _pywrap_toco_api.TocoConvert(
Exception: <unknown>:0: error: loc(""Func/StatefulPartitionedCall/input/_0""): requires all operands and results to have compatible element types
<unknown>:0: note: loc(""Func/StatefulPartitionedCall/input/_0""): see current operation: %1 = ""tf.Identity""(%arg0) {device = """"} : (tensor<1x?x?x3x!tf.quint8>) -> tensor<1x?x?x3xui8>


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/Users/Data/TFOD/tf2convertTest.py"", line 7, in <module>
    tflite_quant_model = converter.convert()
  File ""/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/lite/python/lite.py"", line 1076, in convert
    return super(TFLiteConverterV2, self).convert()
  File ""/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/lite/python/lite.py"", line 899, in convert
    return super(TFLiteFrozenGraphConverterV2,
  File ""/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/lite/python/lite.py"", line 629, in convert
    result = _toco_convert_impl(
  File ""/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/lite/python/convert.py"", line 569, in toco_convert_impl
    data = toco_convert_protos(
  File ""/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/lite/python/convert.py"", line 202, in toco_convert_protos
    raise ConverterError(str(e))
tensorflow.lite.python.convert.ConverterError: <unknown>:0: error: loc(""Func/StatefulPartitionedCall/input/_0""): requires all operands and results to have compatible element types
<unknown>:0: note: loc(""Func/StatefulPartitionedCall/input/_0""): see current operation: %1 = ""tf.Identity""(%arg0) {device = """"} : (tensor<1x?x?x3x!tf.quint8>) -> tensor<1x?x?x3xui8>
```

## 3. Steps to reproduce

I downloaded the [SSD MobileNet v2 320x320](http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_320x320_coco17_tpu-8.tar.gz) model from the TensorFlow Object Detection 2 API and wanted to test converting just the base model to a TFLite model, but when I run the following Python script, it gives the error that it `requires all operands and results to have compatible element types`.

Here is the Python File:

```
import tensorflow as tf

converter = tf.lite.TFLiteConverter.from_saved_model('ssd_mobilenet_v2_320x320_coco17_tpu-8/saved_model')
converter.optimizations = [tf.lite.Optimize.DEFAULT]
converter.experimental_new_converter = True
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]
tflite_model = converter.convert()
with tf.io.gfile.GFile('model.tflite', 'wb') as f:
  f.write(tflite_model)
```

## 4. Expected behavior

The base model should be able to convert to a TFLite without error and I have also tested with a custom trained model and both give the same error when using this same exact file to convert.

## 5. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Tested on both Windows 10 and MacOS 10.15.6
- Mobile device name if the issue happens on a mobile device: None
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.3.0
- Python version: 3.8.5
- Bazel version (if compiling from source): None
- GCC/Compiler version (if compiling from source): None
- CUDA/cuDNN version: None
- GPU model and memory: None

<!-- 
Collect system information using our environment capture script.
https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can also obtain the TensorFlow version with:

1. TensorFlow 1.0
`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

2. TensorFlow 2.0
`python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`
-->
",mihir-chauhan,b'models:research type:bug',2020-09-01T04:17:11Z,2020-09-02T07:34:45Z,,,,,,,
9169,TFLiteConverter (Saved Model -> TFLite) NameError: name 'graph_matcher' is not defined,"# Prerequisites

Please answer the following questions for yourself before submitting an issue.

- [x] I am using the latest TensorFlow Model Garden release and TensorFlow 2.
- [x] I am reporting the issue to the correct repository. (Model Garden official or research directory)
- [x] I checked to make sure that this issue has not already been filed.

## 1. The entire URL of the file you are using

https://github.com/tensorflow/models/blob/master/research/object_detection/export_tflite_ssd_graph.py

## 2. Describe the bug

When I use the export_tflite_ssd_graph.py file, it gives an error that `NameError: name 'graph_matcher' is not defined` when calling `input_pattern = graph_matcher.OpTypePattern(` in `File ""C:\Users\me\AppData\Roaming\Python\Python38\site-packages\object_detection\exporter.py"", line 100, in remove_nn`.

Here is the entire Traceback:

```
Traceback (most recent call last):
  File ""C:\models\research\object_detection\export_tflite_ssd_graph.py"", line 146, in <module>
    tf.app.run(main)
  File ""C:\Users\me\AppData\Roaming\Python\Python38\site-packages\tensorflow\python\platform\app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""C:\Users\me\AppData\Roaming\Python\Python38\site-packages\absl\app.py"", line 299, in run
    _run_main(main, args)
  File ""C:\Users\me\AppData\Roaming\Python\Python38\site-packages\absl\app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""C:\models\research\object_detection\export_tflite_ssd_graph.py"", line 139, in main
    export_tflite_ssd_graph_lib.export_tflite_graph(
  File ""C:\Users\me\AppData\Roaming\Python\Python38\site-packages\object_detection\export_tflite_ssd_graph_lib.py"", line 282, in export_tflite_graph
    exporter.rewrite_nn_resize_op(is_quantized)
  File ""C:\Users\me\AppData\Roaming\Python\Python38\site-packages\object_detection\exporter.py"", line 145, in rewrite_nn_resize_op
    while remove_nn():
  File ""C:\Users\me\AppData\Roaming\Python\Python38\site-packages\object_detection\exporter.py"", line 100, in remove_nn
    input_pattern = graph_matcher.OpTypePattern(
NameError: name 'graph_matcher' is not defined
```

## 3. Steps to reproduce

I am using `model_main_tf2.py` to train my model and then I use `exporter_main_v2` to convert the ckpt files to a saved model from which I then use `export_tflite_ssd_graph.py` and then would use `tflite_convert.exe` (if the bug were not there).

## 4. Expected behavior

The expected behavior is that it should run both python files without getting an error. Since `export_tflite_ssd_graph.py` gives an error of `NameError: name 'graph_matcher' is not defined`, I cannot use `tflite_convert.exe` because the first file didn't execute without errors

## 6. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- Mobile device name if the issue happens on a mobile device: None
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.3.0
- Python version: 3.8
- Bazel version (if compiling from source): None
- GCC/Compiler version (if compiling from source): None
- CUDA/cuDNN version: None
- GPU model and memory: No GPU

<!-- 
Collect system information using our environment capture script.
https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can also obtain the TensorFlow version with:

1. TensorFlow 1.0
`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

2. TensorFlow 2.0
`python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`
-->
",mihir-chauhan,b'models:research type:bug',2020-08-30T20:16:20Z,2020-09-04T15:35:03Z,,,,,,,
9163,fix ValueError for adversarial_text,"# Description

> :memo: Please include a summary of the change. 
>  When I run script:
``` bash
python pretrain.py \
    --train_dir=$PRETRAIN_DIR \
    --data_dir=$IMDB_DATA_DIR \
    --vocab_size=86934 \
    --embedding_dims=256 \
    --rnn_cell_size=1024 \
    --num_candidate_samples=1024 \
    --batch_size=256 \
    --learning_rate=0.001 \
    --learning_rate_decay_factor=0.9999 \
    --max_steps=100000 \
    --max_grad_norm=1.0 \
    --num_timesteps=400 \
    --keep_prob_emb=0.5 \
    --normalize_embeddings
```
I will get error:
```
Traceback (most recent call last):
  File ""pretrain.py"", line 46, in <module>
    tf.app.run()
  File ""/home/luke/miniconda3/lib/python3.7/site-packages/tensorflow/python/platform/app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""/home/luke/miniconda3/lib/python3.7/site-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/home/luke/miniconda3/lib/python3.7/site-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""pretrain.py"", line 40, in main
    model = graphs.get_model()
  File ""/home/luke/Download/models/research/adversarial_text/graphs.py"", line 100, in get_model
    return VatxtModel()
  File ""/home/luke/Download/models/research/adversarial_text/graphs.py"", line 122, in __init__
    self.vocab_freqs = _get_vocab_freqs()
  File ""/home/luke/Download/models/research/adversarial_text/graphs.py"", line 661, in _get_vocab_freqs
    (len(freqs), FLAGS.vocab_size))
ValueError: Frequency file length 87007 != vocab size 86934
```


## Type of change

Note: Please delete options that are not relevant.

- [x] Bug fix (non-breaking change which fixes an issue)
- [x] Documentation update
- [ ] TensorFlow 2 migration
- [ ] New feature (non-breaking change which adds functionality)
- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)
- [ ] A new research paper code implementation
- [ ] Other (Specify)

## Tests

> :memo: Please describe the tests that you ran to verify your changes.
>  


**Test Configuration**:

## Checklist

- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).
- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).
- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).
- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.
- [ ] I have commented my code, particularly in hard-to-understand areas.
- [x] I have made corresponding changes to the documentation.
- [x] My changes generate no new warnings.
- [ ] I have added tests that prove my fix is effective or that my feature works.
",moneypi,b'cla: yes',2020-08-29T10:58:10Z,2020-08-31T21:58:35Z,,,,,,,
9153,Initial checkin of sequence_projection,"# Description

> :memo: Please include a summary of the change. 
>  
> * Please also include relevant motivation and context.  
> * List any dependencies that are required for this change.  

## Type of change

For a new feature or function, please create an issue first to discuss it
with us before submitting a pull request.

Note: Please delete options that are not relevant.

- [ ] Bug fix (non-breaking change which fixes an issue)
- [ ] Documentation update
- [ ] TensorFlow 2 migration
- [ ] New feature (non-breaking change which adds functionality)
- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)
- [ ] A new research paper code implementation
- [ ] Other (Specify)

## Tests

> :memo: Please describe the tests that you ran to verify your changes.
>  
> * Provide instructions so we can reproduce.  
> * Please also list any relevant details for your test configuration.  

**Test Configuration**:

## Checklist

- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).
- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).
- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).
- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.
- [ ] I have commented my code, particularly in hard-to-understand areas.
- [ ] I have made corresponding changes to the documentation.
- [ ] My changes generate no new warnings.
- [ ] I have added tests that prove my fix is effective or that my feature works.
",thunderfyc,b'cla: yes',2020-08-25T23:37:17Z,2020-08-26T21:34:57Z,,,,,,,
9149,.config file eval_config,"What do the num_examples and max_evals parameter mean in the eval_config of .config file?
If I use the data in TF Record format, the num_examples need to be the number of test data or the number of TF Record files?
And when I run the model_ main.py, after a few training steps, evaluation process evaluate indefinitely.
So, how to set the parameters for evaluation process
<!--
As per our GitHub Policy (https://github.com/tensorflow/models/blob/master/ISSUES.md), we only address code bugs, documentation issues, and feature requests on GitHub.

We will automatically close questions and help related issues.

Please go to Stack Overflow (http://stackoverflow.com/questions/tagged/tensorflow-model-garden) for questions and help.

-->
",ivs-pychen,b'type:support',2020-08-25T16:06:13Z,2020-08-27T04:41:42Z,,,,,,,
9147,Customize log_steps for object detection model,"I am using latest TF with the latest TF models. I am trying to run object detection models (Retinanet and maskrcnn). I want to check the performance after each step. That's why I put the flag --log_steps=1, but for some reason it's showing performance result after 100 steps. Then I tried to change the default value

/official/utils/flags/_benchmark.py

def define_log_steps():
  flags.DEFINE_integer(
      name=""log_steps"",
      default=1,
      help=""Frequency with which to log timing information with TimeHistory."")

But didn't work.

Any suggestions?",ashiqimranintel,b'models:official type:bug',2020-08-25T00:03:01Z,2020-08-25T04:12:05Z,,,,,,,
9138,How to know if I am correctly loading checkpoint?,"# Prerequisites

Please answer the following questions for yourself before submitting an issue.

- [Y] I am using the latest TensorFlow Model Garden release and TensorFlow 2.
- [Y] I am reporting the issue to the correct repository. (Model Garden official or research directory)
- [Y] I checked to make sure that this issue has not already been filed.

## 1. The entire URL of the file you are using

https://github.com/tensorflow/models/tree/master/research/object_detection

## 2. Describe the bug

I am trying to train an OD model from a downloaded model checkpoint. The model is able to train. However it does not seem to be loading the checkpoint file. I say this since (1) there is no message in the output describing loading the checkpoint (2) performance is the same with and without the specifying the checkpoint in the config file (3) if I put in a nonexistant filename for the checkpoint in the config file, there is no error message. 

Here are the relevant sections of the config file:
```
fine_tune_checkpoint: ""/media/wwang/WorkDir/projects/SANATA2/pretrained_models/ssd_mobilenet_v3_large_coco_2020_01_14/model.ckpt""
fine_tune_checkpoint_type:  ""detection""
# set below to true to restore ALL variables in model checkpoint 
load_all_detection_checkpoint_vars: true 
```

The output I see is:
```
(.venv) rsandler@SIGMA-ARS:/media/wwang/WorkDir/projects/SANATA2$ ./train.sh -m=results/rMN3_1 -c=configs/ssdlite_mobilenet_v3_SANATA.config
MODEL_DIR = results/rMN3_1
PIPELINE_CONFIG_PATH = configs/ssdlite_mobilenet_v3_SANATA.config
Model directory results/rMN3_1 already exists. Are you sure you want to overwrite? (y/n)y

WARNING:tensorflow:Forced number of epochs for all eval validations to be 1.
W0821 17:20:29.301205 140525398734592 model_lib.py:758] Forced number of epochs for all eval validations to be 1.
INFO:tensorflow:Maybe overwriting train_steps: None
I0821 17:20:29.301373 140525398734592 config_util.py:552] Maybe overwriting train_steps: None
INFO:tensorflow:Maybe overwriting use_bfloat16: False
I0821 17:20:29.301445 140525398734592 config_util.py:552] Maybe overwriting use_bfloat16: False
INFO:tensorflow:Maybe overwriting sample_1_of_n_eval_examples: 1
I0821 17:20:29.301509 140525398734592 config_util.py:552] Maybe overwriting sample_1_of_n_eval_examples: 1
INFO:tensorflow:Maybe overwriting eval_num_epochs: 1
I0821 17:20:29.301573 140525398734592 config_util.py:552] Maybe overwriting eval_num_epochs: 1
WARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.
W0821 17:20:29.301655 140525398734592 model_lib.py:774] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.
INFO:tensorflow:create_estimator_and_inputs: use_tpu False, export_to_tpu None
I0821 17:20:29.301735 140525398734592 model_lib.py:809] create_estimator_and_inputs: use_tpu False, export_to_tpu None
INFO:tensorflow:Using config: {'_model_dir': 'results/rMN3_1', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true
graph_options {
  rewrite_options {
    meta_optimizer_iterations: ONE
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fce06dfc400>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0821 17:20:29.302065 140525398734592 estimator.py:212] Using config: {'_model_dir': 'results/rMN3_1', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true
graph_options {
  rewrite_options {
    meta_optimizer_iterations: ONE
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fce06dfc400>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
WARNING:tensorflow:Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7fce06dfba60>) includes params argument, but params are not passed to Estimator.
W0821 17:20:29.302607 140525398734592 model_fn.py:630] Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7fce06dfba60>) includes params argument, but params are not passed to Estimator.
INFO:tensorflow:Not using Distribute Coordinator.
I0821 17:20:29.303130 140525398734592 estimator_training.py:186] Not using Distribute Coordinator.
INFO:tensorflow:Running training and evaluation locally (non-distributed).
I0821 17:20:29.303284 140525398734592 training.py:612] Running training and evaluation locally (non-distributed).
INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.
I0821 17:20:29.303488 140525398734592 training.py:700] Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.
WARNING:tensorflow:From /media/wwang/WorkDir/projects/SANATA2/.venv/lib/python3.6/site-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0821 17:20:29.307874 140525398734592 deprecation.py:323] From /media/wwang/WorkDir/projects/SANATA2/.venv/lib/python3.6/site-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.
W0821 17:20:29.334903 140525398734592 dataset_builder.py:83] num_readers has been reduced to 1 to match input file shards.
WARNING:tensorflow:From /media/wwang/WorkDir/projects/SANATA2/models/research/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0821 17:20:29.339357 140525398734592 deprecation.py:323] From /media/wwang/WorkDir/projects/SANATA2/models/research/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
WARNING:tensorflow:From /media/wwang/WorkDir/projects/SANATA2/models/research/object_detection/builders/dataset_builder.py:175: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.map()
W0821 17:20:29.358630 140525398734592 deprecation.py:323] From /media/wwang/WorkDir/projects/SANATA2/models/research/object_detection/builders/dataset_builder.py:175: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.map()
WARNING:tensorflow:From /media/wwang/WorkDir/projects/SANATA2/models/research/object_detection/inputs.py:77: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.
W0821 17:20:40.323007 140525398734592 deprecation.py:323] From /media/wwang/WorkDir/projects/SANATA2/models/research/object_detection/inputs.py:77: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.
WARNING:tensorflow:From /media/wwang/WorkDir/projects/SANATA2/models/research/object_detection/utils/ops.py:493: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
W0821 17:20:40.419775 140525398734592 deprecation.py:323] From /media/wwang/WorkDir/projects/SANATA2/models/research/object_detection/utils/ops.py:493: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
WARNING:tensorflow:From /media/wwang/WorkDir/projects/SANATA2/.venv/lib/python3.6/site-packages/tensorflow_core/python/autograph/operators/control_flow.py:1004: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.
Instructions for updating:
`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.
W0821 17:20:46.696362 140525398734592 api.py:332] From /media/wwang/WorkDir/projects/SANATA2/.venv/lib/python3.6/site-packages/tensorflow_core/python/autograph/operators/control_flow.py:1004: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.
Instructions for updating:
`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.
WARNING:tensorflow:From /media/wwang/WorkDir/projects/SANATA2/models/research/object_detection/inputs.py:259: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
W0821 17:20:50.138358 140525398734592 deprecation.py:323] From /media/wwang/WorkDir/projects/SANATA2/models/research/object_detection/inputs.py:259: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
INFO:tensorflow:Calling model_fn.
I0821 17:20:53.348967 140525398734592 estimator.py:1148] Calling model_fn.
WARNING:tensorflow:From /media/wwang/WorkDir/projects/SANATA2/.venv/lib/python3.6/site-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
Please use `layer.__call__` method instead.
W0821 17:20:53.360917 140525398734592 deprecation.py:323] From /media/wwang/WorkDir/projects/SANATA2/.venv/lib/python3.6/site-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
Please use `layer.__call__` method instead.
INFO:tensorflow:depth of additional conv before box predictor: 0
I0821 17:20:55.618030 140525398734592 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0
INFO:tensorflow:depth of additional conv before box predictor: 0
I0821 17:20:55.695748 140525398734592 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0
INFO:tensorflow:depth of additional conv before box predictor: 0
I0821 17:20:55.874124 140525398734592 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0
INFO:tensorflow:depth of additional conv before box predictor: 0
I0821 17:20:55.950246 140525398734592 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0
INFO:tensorflow:depth of additional conv before box predictor: 0
I0821 17:20:56.026594 140525398734592 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0
INFO:tensorflow:depth of additional conv before box predictor: 0
I0821 17:20:56.105797 140525398734592 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0
INFO:tensorflow:Done calling model_fn.
I0821 17:21:04.007520 140525398734592 estimator.py:1150] Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
I0821 17:21:04.008645 140525398734592 basic_session_run_hooks.py:541] Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
I0821 17:21:06.821338 140525398734592 monitored_session.py:240] Graph was finalized.
2020-08-21 17:21:06.821628: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-08-21 17:21:06.844416: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3298175000 Hz
2020-08-21 17:21:06.845073: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x106e3d20 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-08-21 17:21:06.845116: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-08-21 17:21:06.849686: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-08-21 17:21:06.993536: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x107883c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-08-21 17:21:06.993589: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce RTX 2080 Ti, Compute Capability 7.5
2020-08-21 17:21:06.996031: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties:
name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.635
pciBusID: 0000:05:00.0
2020-08-21 17:21:06.996486: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2020-08-21 17:21:06.998573: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2020-08-21 17:21:07.000359: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2020-08-21 17:21:07.000884: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2020-08-21 17:21:07.003328: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2020-08-21 17:21:07.005205: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2020-08-21 17:21:07.009647: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-08-21 17:21:07.011651: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
2020-08-21 17:21:07.011689: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2020-08-21 17:21:07.013123: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-08-21 17:21:07.013140: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0
2020-08-21 17:21:07.013146: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N
2020-08-21 17:21:07.015179: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10120 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:05:00.0, compute capability: 7.5)
INFO:tensorflow:Running local_init_op.
I0821 17:21:10.164166 140525398734592 session_manager.py:500] Running local_init_op.
INFO:tensorflow:Done running local_init_op.
I0821 17:21:10.526486 140525398734592 session_manager.py:502] Done running local_init_op.
INFO:tensorflow:Saving checkpoints for 0 into results/rMN3_1/model.ckpt.
I0821 17:21:18.740669 140525398734592 basic_session_run_hooks.py:606] Saving checkpoints for 0 into results/rMN3_1/model.ckpt.
2020-08-21 17:21:28.352517: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2020-08-21 17:21:29.413230: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
INFO:tensorflow:loss = 49.43353, step = 0
I0821 17:21:32.033897 140525398734592 basic_session_run_hooks.py:262] loss = 49.43353, step = 0
```

## 3. Steps to reproduce

See above config specifications. Otherwise, I used the MobileNet V3 config sample [here](https://github.com/tensorflow/models/blob/master/research/object_detection/samples/configs/ssdlite_mobilenet_v3_large_320x320_coco.config)

## 4. Expected behavior

There should be a log message that the checkpoint was successfully loaded and performance should hopefully improve

## 5. Additional context

See above log

## 6. System information
```

== check python ===================================================
python version: 3.6.11
python branch: 
python build version: ('default', 'Jun 29 2020 05:15:03')
python compiler version: GCC 5.4.0 20160609
python implementation: CPython


== check os platform ===============================================
os: Linux
os kernel version: #113~16.04.1-Ubuntu SMP Fri Jul 10 04:37:08 UTC 2020
os release version: 4.15.0-112-generic
os platform: Linux-4.15.0-112-generic-x86_64-with-Ubuntu-16.04-xenial
linux distribution: ('Ubuntu', '16.04', 'xenial')
linux os distribution: ('Ubuntu', '16.04', 'xenial')
mac version: ('', ('', '', ''), '')
uname: uname_result(system='Linux', node='SIGMA-ARS', release='4.15.0-112-generic', version='#113~16.04.1-Ubuntu SMP Fri Jul 10 04:37:08 UTC 2020', machine='x86_64', processor='x86_64')
architecture: ('64bit', 'ELF')
machine: x86_64


== are we in docker =============================================
No

== compiler =====================================================
c++ (Ubuntu 5.5.0-12ubuntu1~16.04) 5.5.0 20171010
Copyright (C) 2015 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.


== check pips ===================================================
numpy                1.19.0
protobuf             3.12.2
tensorflow-estimator 1.15.1
tensorflow-gpu       1.15.0

== check for virtualenv =========================================
False

== tensorflow import ============================================
tf.version.VERSION = 1.15.0
tf.version.GIT_VERSION = v1.15.0-rc3-22-g590d6ee
tf.version.COMPILER_VERSION = 7.3.1 20180303

== env ==========================================================
LD_LIBRARY_PATH /usr/lib/x86_64-linux-gnu:/usr/local/cuda-10.0/lib64:/usr/local/cuda-10.0/extras/CUPTI/lib64:
DYLD_LIBRARY_PATH is unset

== nvidia-smi ===================================================
Fri Aug 21 17:55:01 2020       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 418.87.01    Driver Version: 418.87.01    CUDA Version: 10.1     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  GeForce RTX 208...  Off  | 00000000:05:00.0  On |                  N/A |
| 51%   65C    P0   123W / 260W |    171MiB / 10988MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID   Type   Process name                             Usage      |
|=============================================================================|
|    0      1751      G   /usr/lib/xorg/Xorg                           169MiB |
+-----------------------------------------------------------------------------+

== cuda libs  ===================================================
/usr/local/cuda-10.0/doc/man/man7/libcudart.7
/usr/local/cuda-10.0/doc/man/man7/libcudart.so.7
/usr/local/cuda-10.0/lib64/libcudart.so.10.0.130
/usr/local/cuda-10.0/lib64/libcudart_static.a
/usr/local/cuda-old/cuda-9.0/doc/man/man7/libcudart.7
/usr/local/cuda-old/cuda-9.0/doc/man/man7/libcudart.so.7
/usr/local/cuda-old/cuda-9.0/targets/aarch64-linux/lib/libcudart_static.a
/usr/local/cuda-old/cuda-9.0/targets/aarch64-linux/lib/libcudart.so.9.0.252
/usr/local/cuda-old/cuda-9.0/targets/x86_64-linux/lib/libcudart_static.a
/usr/local/cuda-old/cuda-9.0/targets/x86_64-linux/lib/libcudart.so.9.0.252
/usr/local/cuda-10.2/doc/man/man7/libcudart.7
/usr/local/cuda-10.2/doc/man/man7/libcudart.so.7
/usr/local/cuda-10.2/targets/aarch64-linux/lib/libcudart.so.10.2.89
/usr/local/cuda-10.2/targets/aarch64-linux/lib/libcudart_static.a
/usr/local/cuda-10.2/targets/x86_64-linux/lib/libcudart.so.10.2.89
/usr/local/cuda-10.2/targets/x86_64-linux/lib/libcudart_static.a

== tensorflow installed from info ==================

== python version  ==============================================
(major, minor, micro, releaselevel, serial)
(3, 6, 11, 'final', 0)

== bazel version  ===============================================
Build label: 0.21.0- (@non-git)
Build time: Tue Feb 26 20:43:53 2019 (1551213833)
Build timestamp: 1551213833
Build timestamp as int: 1551213833
```",rsandler00,b'models:research stalled stat:awaiting response type:support',2020-08-22T00:59:29Z,2020-09-17T04:28:03Z,,,,,,,
9126,ValueError: ssd_mobilenet_v2 is not supported. See `model_builder.py` for features extractors compatible with different versions of Tensorflow,"# Prerequisites

Please answer the following questions for yourself before submitting an issue.

- [x] I am using the latest TensorFlow Model Garden release and TensorFlow 2.
- [ ] I am reporting the issue to the correct repository. (Model Garden official or research directory)
- [ ] I checked to make sure that this issue has not already been filed.

## 1. The entire URL of the file you are using

https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf1_detection_zoo.md **ssd_mobilenet_v2_coco**
The same issue happened with **ssd_mobilenet_v1_coco** and **faster_rcnn_inception_v2_coco_2018_01_28**

## 2. Describe the bug

After issuing the comand 
**$ python train.py --logtostderr --train_dir=training/ --pipeline_config_path=training/ssd_mobilenet_v2_coco.config**

I get a Traceback:

Traceback (most recent call last):
  File ""train.py"", line 186, in <module>
    tf.app.run()
  File ""/home/quad/anaconda3/envs/gputest/lib/python3.6/site-packages/tensorflow/python/platform/app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""/home/quad/anaconda3/envs/gputest/lib/python3.6/site-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/home/quad/anaconda3/envs/gputest/lib/python3.6/site-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""/home/quad/anaconda3/envs/gputest/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py"", line 324, in new_func
    return func(*args, **kwargs)
  File ""train.py"", line 182, in main
    graph_hook_fn=graph_rewriter_fn)
  File ""/home/quad/tensorflow1/models/research/object_detection/legacy/trainer.py"", line 248, in train
    detection_model = create_model_fn()
  File ""/home/quad/tensorflow1/models/research/object_detection/builders/model_builder.py"", line 1062, in build
    add_summaries)
  File ""/home/quad/tensorflow1/models/research/object_detection/builders/model_builder.py"", line 369, in _build_ssd_model
    _check_feature_extractor_exists(ssd_config.feature_extractor.type)
  File ""/home/quad/tensorflow1/models/research/object_detection/builders/model_builder.py"", line 243, in _check_feature_extractor_exists
    'Tensorflow'.format(feature_extractor_type))
ValueError: ssd_mobilenet_v2 is not supported. See `model_builder.py` for features extractors compatible with different versions of Tensorflow

## 3. Steps to reproduce
1. Configure $PYTHONPATH with following:  $ export PYTHONPATH=$PYTHONPATH~/models:~/models/research:~/models/research/slim
2. Configure ~/models/research/object_detection/training/ssd_mobilenet_v2_coco.config with path to _test.record, train.record, label.pbtxt, num of examples, num of classes_
3. From directory ~/models/research/object_detection issue the comand: **$ python train.py --logtostderr --train_dir=training/ --pipeline_config_path=training/ssd_mobilenet_v2_coco.config**

## 4. Expected behavior

The network must start training process.

## 5. Additional context

Traceback (most recent call last):
  File ""train.py"", line 186, in <module>
    tf.app.run()
  File ""/home/quad/anaconda3/envs/gputest/lib/python3.6/site-packages/tensorflow/python/platform/app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""/home/quad/anaconda3/envs/gputest/lib/python3.6/site-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/home/quad/anaconda3/envs/gputest/lib/python3.6/site-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""/home/quad/anaconda3/envs/gputest/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py"", line 324, in new_func
    return func(*args, **kwargs)
  File ""train.py"", line 182, in main
    graph_hook_fn=graph_rewriter_fn)
  File ""/home/quad/tensorflow1/models/research/object_detection/legacy/trainer.py"", line 248, in train
    detection_model = create_model_fn()
  File ""/home/quad/tensorflow1/models/research/object_detection/builders/model_builder.py"", line 1062, in build
    add_summaries)
  File ""/home/quad/tensorflow1/models/research/object_detection/builders/model_builder.py"", line 369, in _build_ssd_model
    _check_feature_extractor_exists(ssd_config.feature_extractor.type)
  File ""/home/quad/tensorflow1/models/research/object_detection/builders/model_builder.py"", line 243, in _check_feature_extractor_exists
    'Tensorflow'.format(feature_extractor_type))
ValueError: ssd_mobilenet_v2 is not supported. See `model_builder.py` for features extractors compatible with different versions of Tensorflow

## 6. System information

- OS Platform and Distribution : Ubuntu 18.04
- TensorFlow installed from (source or binary): With CONDA, object_detection_tutorial.ipynb is working
- TensorFlow version (use command below): 2.2.0 (but the file train.py is set to use **tensorflow.compat.v1**)
- Python version: 3.6.10
- CUDA/cuDNN version: CUDA 10.1/ cuDNN 7.6.5
- GPU model and memory: NVIDIA GeForce 710

!PLEASE don`t link me to another issue, some of those links are looped and opened, which don`t help at all
Thank You
",Kosta404,b'models:research stat:awaiting response type:bug',2020-08-19T08:59:01Z,2020-09-11T12:28:04Z,,,,,,,
9125,DELF GLDv2 build_image_dataset.py make error: KeyError: 'image_path',"<!--
As per our GitHub Policy (https://github.com/tensorflow/models/blob/master/ISSUES.md), we only address code bugs, documentation issues, and feature requests on GitHub.

We will automatically close questions and help related issues.

Please go to Stack Overflow (http://stackoverflow.com/questions/tagged/tensorflow-model-garden) for questions and help.

-->

Hi.

I run `python3 build_image_dataset.py \
  --train_csv_path=gldv2_dataset/train/train.csv \
  --train_clean_csv_path=gldv2_dataset/train/train_clean.csv \
  --train_directory=gldv2_dataset/train/*/*/*/ \
  --output_directory=gldv2_dataset/tfrecord/ \
  --num_shards=128 \
  --generate_train_validation_splits \
  --validation_split_size=0.2`

 (https://github.com/tensorflow/models/tree/master/research/delf/delf/python/training)

But, It makes this error:

Traceback (most recent call last):
  File ""build_image_dataset.py"", line 490, in <module>
    app.run(main)
  File ""/home/smart02/anaconda3/lib/python3.6/site-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/home/smart02/anaconda3/lib/python3.6/site-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""build_image_dataset.py"", line 484, in main
    FLAGS.seed)
  File ""build_image_dataset.py"", line 439, in _build_train_tfrecord_dataset
    image_dir)
  File ""build_image_dataset.py"", line 167, in _get_clean_train_image_files_and_labels
    image_paths.append(value['image_path'])
KeyError: 'image_path'

Someone upload same error before, but he doesn't say anything about solution. (https://github.com/tensorflow/models/issues/8924)

How to fix this error?


",PeterKim1,b'models:research type:support',2020-08-19T05:48:31Z,2020-10-07T06:23:39Z,,,,,,,
9124,[Deeplab] Cityscapes tutorial -> Windows fatal exception: Access violation,"<!--
As per our GitHub Policy (https://github.com/tensorflow/models/blob/master/ISSUES.md), we only address code bugs, documentation issues, and feature requests on GitHub.

We will automatically close questions and help related issues.

Please go to Stack Overflow (http://stackoverflow.com/questions/tagged/tensorflow-model-garden) for questions and help.

-->

I have an issue with the deeplab model that I am trying to fix for over 3 days now. I've followed the instructions on Github using the cityscapes dataset and checked multiple issues but none of them have the answer for my problem. Whenever I run the train.py with the command used in the cityscapes tutorial:

> python train.py \
>     --logtostderr \
>     --training_number_of_steps=90000 \
>     --train_split=""train_fine"" \
>     --model_variant=""xception_65"" \
>     --atrous_rates=6 \
>     --atrous_rates=12 \
>     --atrous_rates=18 \
>     --output_stride=16 \
>     --decoder_output_stride=4 \
>     --train_crop_size=""769,769"" \
>     --train_batch_size=1 \
>     --dataset=""cityscapes"" \
>     --tf_initial_checkpoint= ""C:\Users\Blank\Documents\master_thesis_deeplab\models_1\research\deeplab\models\model.ckpt"" \
>     --train_logdir=""C:\Users\Blank\Documents\master_thesis_deeplab\models_1\research\deeplab\log"" \
>     --dataset_dir=""C:\Users\Blank\Documents\master_thesis_deeplab\models_1\research\deeplab\datasets\cityscapes""


I get a Windows Fatal Exception: Access Violation when the program starts queueing (See below for error). I've tried pretty much everything but I cannot solve this problem. Do I have a wrong config file pointing to a wrong folder? Or do I have problems with access to my GPU?

My installed libraries are:

tensorflow-estimator: 1.15.1
tensorflow-gpu: 1.15.0
Pillow: 7.2.0
matplotlib: 3.3.0
jupyter: 1.0.0
numpy: 1.18.5

My Installed CUDA version:
CUDA v10.0
CudNN 7.4

I have the correct folder setup in my dataset/cityscapes folder, I have succesfully ran the model_test.py. I've also correctly placed the correct model in my model folder. What am I doing wrong? Do I use a wrong library version?

> 2020-08-18 15:15:56.535694: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6283 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2070 SUPER, pci bus id: 0000:01:00.0, compute capability: 7.5)
> INFO:tensorflow:Running local_init_op.
> I0818 15:16:00.145851  8236 session_manager.py:500] Running local_init_op.
> INFO:tensorflow:Done running local_init_op.
> I0818 15:16:01.015424  8236 session_manager.py:502] Done running local_init_op.
> INFO:tensorflow:Starting Session.
> I0818 15:16:22.278688  8236 learning.py:754] Starting Session.
> INFO:tensorflow:Saving checkpoint to path C:\Users\Blank\Documents\master_thesis_deeplab\models_1\research\deeplab\log\model.ckpt
> I0818 15:16:22.564429  9704 supervisor.py:1117] Saving checkpoint to path C:\Users\Blank\Documents\master_thesis_deeplab\models_1\research\deeplab\log\model.ckpt
> INFO:tensorflow:Starting Queues.
> I0818 15:16:22.564429  8236 learning.py:768] Starting Queues.
> Windows fatal exception: access violation
> 
> Thread 0x000025e8 (most recent call first):
>   File ""C:\Users\Blank\anaconda3\envs\tf-gpu\lib\site-packages\tensorflow_core\python\client\session.py"", line 1443 in _call_tf_sessionrun
>   File ""C:\Users\Blank\anaconda3\envs\tf-gpu\lib\site-packages\tensorflow_core\python\client\session.py"", line 1350 in _run_fn
>   File ""C:\Users\Blank\anaconda3\envs\tf-gpu\lib\site-packages\tensorflow_core\python\client\session.py"", line 1365 in _do_call
>   File ""C:\Users\Blank\anaconda3\envs\tf-gpu\lib\site-packages\tensorflow_core\python\client\session.py"", line 1359 in _do_run
>   File ""C:\Users\Blank\anaconda3\envs\tf-gpu\lib\site-packages\tensorflow_core\python\client\session.py"", line 1180 in _run
>   File ""C:\Users\Blank\anaconda3\envs\tf-gpu\lib\site-packages\tensorflow_core\python\client\session.py"", line 956 in run
>   File ""C:\Users\Blank\anaconda3\envs\tf-gpu\lib\site-packages\tensorflow_core\python\training\saver.py"", line 1176 in save
>   File ""C:\Users\Blank\anaconda3\envs\tf-gpu\lib\site-packages\tensorflow_core\python\training\supervisor.py"", line 1119 in run_loop
>   File ""C:\Users\Blank\anaconda3\envs\tf-gpu\lib\site-packages\tensorflow_core\python\training\coordinator.py"", line 495 in run
>   File ""C:\Users\Blank\anaconda3\envs\tf-gpu\lib\threading.py"", line 926 in _bootstrap_inner
>   File ""C:\Users\Blank\anaconda3\envs\tf-gpu\lib\threading.py"", line 890 in _bootstrap
> 
> Thread 0x000043c4 (most recent call first):
>   File ""C:\Users\Blank\anaconda3\envs\tf-gpu\lib\site-packages\tensorflow_core\python\client\session.py"", line 1443 in _call_tf_sessionrun
>   File ""C:\Users\Blank\anaconda3\envs\tf-gpu\lib\site-packages\tensorflow_core\python\client\session.py"", line 1350 in _run_fn
>   File ""C:\Users\Blank\anaconda3\envs\tf-gpu\lib\site-packages\tensorflow_core\python\client\session.py"", line 1365 in _do_call
>   File ""C:\Users\Blank\anaconda3\envs\tf-gpu\lib\site-packages\tensorflow_core\python\client\session.py"", line 1359 in _do_run
>   File ""C:\Users\Blank\anaconda3\envs\tf-gpu\lib\site-packages\tensorflow_core\python\client\session.py"", line 1180 in _run
>   File ""C:\Users\Blank\anaconda3\envs\tf-gpu\lib\site-packages\tensorflow_core\python\client\session.py"", line 956 in run
>   File ""C:\Users\Blank\anaconda3\envs\tf-gpu\lib\site-packages\tensorflow_core\python\training\training_util.py"", line 68 in global_step
>   File ""C:\Users\Blank\anaconda3\envs\tf-gpu\lib\site-packages\tensorflow_core\python\training\supervisor.py"", line 1081 in run_loop
>   File ""C:\Users\Blank\anaconda3\envs\tf-gpu\lib\site-packages\tensorflow_core\python\training\coordinator.py"", line 495 in run
>   File ""C:\Users\Blank\anaconda3\envs\tf-gpu\lib\threading.py"", line 926 in _bootstrap_inner
>   File ""C:\Users\Blank\anaconda3\envs\tf-gpu\lib\threading.py"", line 890 in _bootstrap
> 
> Thread 0x00003e24 (most recent call first):
>   File ""C:\Users\Blank\anaconda3\envs\tf-gpu\lib\site-packages\tensorflow_core\python\client\session.py"", line 1443 in _call_tf_sessionrun
>   File ""C:\Users\Blank\anaconda3\envs\tf-gpu\lib\site-packages\tensorflow_core\python\client\session.py"", line 1350 in _run_fn
>   File ""C:\Users\Blank\anaconda3\envs\tf-gpu\lib\site-packages\tensorflow_core\python\client\session.py"", line 1365 in _do_call
>   File ""C:\Users\Blank\anaconda3\envs\tf-gpu\lib\site-packages\tensorflow_core\python\client\session.py"", line 1359 in _do_run
>   File ""C:\Users\Blank\anaconda3\envs\tf-gpu\lib\site-packages\tensorflow_core\python\client\session.py"", line 1180 in _run
>   File ""C:\Users\Blank\anaconda3\envs\tf-gpu\lib\site-packages\tensorflow_core\python\client\session.py"", line 956 in run
>   File ""C:\Users\Blank\anaconda3\envs\tf-gpu\lib\site-packages\tensorflow_core\python\training\supervisor.py"", line 1045 in run_loop
>   File ""C:\Users\Blank\anaconda3\envs\tf-gpu\lib\site-packages\tensorflow_core\python\training\coordinator.py"", line 495 in run
>   File ""C:\Users\Blank\anaconda3\envs\tf-gpu\lib\threading.py"", line 926 in _bootstrap_inner
>   File ""C:\Users\Blank\anaconda3\envs\tf-gpu\lib\threading.py"", line 890 in _bootstrap
> 
> Thread 0x00001744 (most recent call first):
>   File ""C:\Users\Blank\anaconda3\envs\tf-gpu\lib\threading.py"", line 296 in wait
>   File ""C:\Users\Blank\anaconda3\envs\tf-gpu\lib\queue.py"", line 170 in get
>   File ""C:\Users\Blank\anaconda3\envs\tf-gpu\lib\site-packages\tensorflow_core\python\summary\writer\event_file_writer.py"", line 159 in run
>   File ""C:\Users\Blank\anaconda3\envs\tf-gpu\lib\threading.py"", line 926 in _bootstrap_inner
>   File ""C:\Users\Blank\anaconda3\envs\tf-gpu\lib\threading.py"", line 890 in _bootstrap
> 
> Thread 0x0000202c (most recent call first):
>   File ""C:\Users\Blank\anaconda3\envs\tf-gpu\lib\site-packages\tensorflow_core\python\client\session.py"", line 1443 in _call_tf_sessionrun
>   File ""C:\Users\Blank\anaconda3\envs\tf-gpu\lib\site-packages\tensorflow_core\python\client\session.py"", line 1350 in _run_fn
>   File ""C:\Users\Blank\anaconda3\envs\tf-gpu\lib\site-packages\tensorflow_core\python\client\session.py"", line 1365 in _do_call
>   File ""C:\Users\Blank\anaconda3\envs\tf-gpu\lib\site-packages\tensorflow_core\python\client\session.py"", line 1359 in _do_run
>   File ""C:\Users\Blank\anaconda3\envs\tf-gpu\lib\site-packages\tensorflow_core\python\client\session.py"", line 1180 in _run
>   File ""C:\Users\Blank\anaconda3\envs\tf-gpu\lib\site-packages\tensorflow_core\python\client\session.py"", line 956 in run
>   File ""C:\Users\Blank\anaconda3\envs\tf-gpu\lib\site-packages\tensorflow_core\contrib\slim\python\slim\learning.py"", line 490 in train_step
>   File ""C:\Users\Blank\anaconda3\envs\tf-gpu\lib\site-packages\tensorflow_core\contrib\slim\python\slim\learning.py"", line 775 in train
>   File ""train.py"", line 462 in main
>   File ""C:\Users\Blank\anaconda3\envs\tf-gpu\lib\site-packages\absl\app.py"", line 250 in _run_main
>   File ""C:\Users\Blank\anaconda3\envs\tf-gpu\lib\site-packages\absl\app.py"", line 299 in run
>   File ""C:\Users\Blank\anaconda3\envs\tf-gpu\lib\site-packages\tensorflow_core\python\platform\app.py"", line 40 in run
>   File ""train.py"", line 468 in <module>
> 

 I have tried to use Deeplab with Tensorflow 2.3.0 but I can't manage to run anything. Only when I use tensorflow 1.15.0 the model_test.py and train.py works.
",thegendolz,b'models:research type:support',2020-08-18T15:35:28Z,2020-08-19T11:37:44Z,,,,,,,
9122,Update tf2.md - Add Open in Colab,"Added ""Open in Colab"" button for the Google Colab projects.

# Description

> :memo: Please include a summary of the change. 
>  
> * Please also include relevant motivation and context.  
> * List any dependencies that are required for this change.  

## Type of change

For a new feature or function, please create an issue first to discuss it
with us before submitting a pull request.

Note: Please delete options that are not relevant.

- [ ] Bug fix (non-breaking change which fixes an issue)
- [x] Documentation update
- [ ] TensorFlow 2 migration
- [ ] New feature (non-breaking change which adds functionality)
- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)
- [ ] A new research paper code implementation
- [ ] Other (Specify)

## Tests

> :memo: Please describe the tests that you ran to verify your changes.
>  
> * Provide instructions so we can reproduce.  
> * Please also list any relevant details for your test configuration.  

**Test Configuration**:

## Checklist

- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).
- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).
- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).
- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.
- [ ] I have commented my code, particularly in hard-to-understand areas.
- [ ] I have made corresponding changes to the documentation.
- [x] My changes generate no new warnings.
- [ ] I have added tests that prove my fix is effective or that my feature works.
",ibaiGorordo,b'cla: yes',2020-08-18T06:20:10Z,2020-09-01T12:07:17Z,,,,,,,
9121,AttributeError: 'AutoTrackable' object has no attribute 'output_shapes',"versions:
tensorflow - 2.3.0
conda - 4.8.4
python - 3.8.3
pip - 20.2.2

I am having an issue with getting a tensorflow python model to work jupyter. I am running a tutorial.ipynb file and only get one error toward the end


```
# In [19]

masking_model.output_shapes
AttributeError                            Traceback (most recent call last)
<ipython-input-19-31bf89ff98cf> in <module>
----> 1 masking_model.output_shapes

AttributeError: 'AutoTrackable' object has no attribute 'output_shapes'
```

I do not know how to get past this and seeing as this is the second to last code segment to execute it is rather frustrating",NFeruch,b'models:official stat:awaiting response type:bug',2020-08-18T02:24:53Z,2020-09-10T06:54:26Z,,,,,,,
9120,Context R-CNN TF 2: move batch norm between dense and activation,"Another bugfix, missed this in the first bugfix.

# Description

> :memo: Please include a summary of the change. 
>  
> * Please also include relevant motivation and context.  
> * List any dependencies that are required for this change.  

## Type of change

For a new feature or function, please create an issue first to discuss it
with us before submitting a pull request.

Note: Please delete options that are not relevant.

- [ ] Bug fix (non-breaking change which fixes an issue)
- [ ] Documentation update
- [ ] TensorFlow 2 migration
- [ ] New feature (non-breaking change which adds functionality)
- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)
- [ ] A new research paper code implementation
- [ ] Other (Specify)

## Tests

> :memo: Please describe the tests that you ran to verify your changes.
>  
> * Provide instructions so we can reproduce.  
> * Please also list any relevant details for your test configuration.  

**Test Configuration**:

## Checklist

- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).
- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).
- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).
- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.
- [ ] I have commented my code, particularly in hard-to-understand areas.
- [ ] I have made corresponding changes to the documentation.
- [ ] My changes generate no new warnings.
- [ ] I have added tests that prove my fix is effective or that my feature works.
",kmindspark,b'cla: yes ready to pull',2020-08-17T20:27:49Z,2020-08-17T22:42:13Z,,,,,,,
9117,ValueError: Could not find matching function to call loaded from the SavedModel,"# Prerequisites

Please answer the following questions for yourself before submitting an issue.

- [ 1 ] I am using the latest TensorFlow Model Garden release and TensorFlow 2.
- [ 1 ] I am reporting the issue to the correct repository. (Model Garden official or research directory)
- [ 1 ] I checked to make sure that this issue has not been filed already.

## 1. The entire URL of the file you are using

https://github.com/tensorflow/models/tree/master/official/...

## 2. Describe the bug

I was using BERT to do text classification task. I have already trained the model. I used to use the ckpt to reload which is totally ok in code:
`
classifier_model = bert_models.classifier_model(
          bert_config, input_meta_data['num_labels'])[0]
checkpoint = tf.train.Checkpoint(model=classifier_model)
latest_checkpoint_file = (
          FLAGS.predict_checkpoint_path or
          tf.train.latest_checkpoint(FLAGS.model_dir))
assert latest_checkpoint_file
logging.info('Checkpoint file %s found and restoring from '
                   'checkpoint', latest_checkpoint_file)
checkpoint.restore(
          latest_checkpoint_file).assert_existing_objects_matched()
preds, _ = get_predictions_and_labels(
          strategy, classifier_model, eval_input_fn, return_probs=True)
`

When I want to use savedModel in the way of colab mentioned before:

`
reloaded_model = tf.saved_model.load(MODEL_PATH)
`

I get this error:
`
ValueError: Could not find matching function to call loaded from the SavedModel. Got:

      Positional arguments (3 total):
        * {'input_word_ids': <tf.Tensor 'inputs_2:0' shape=(None, 128) dtype=int32>, 'input_mask': <tf.Tensor 'inputs:0' shape=(None, 128) dtype=int32>, 'input_type_ids': <tf.Tensor 'inputs_1:0' shape=(None, 128) dtype=int32>}
        * False
        * None
      Keyword arguments: {}
 
    Expected these arguments to match one of the following 4 option(s):
    
    Option 1:
      Positional arguments (3 total):
        * [TensorSpec(shape=(None, 128), dtype=tf.int32, name='inputs/0'), TensorSpec(shape=(None, 128), dtype=tf.int32, name='inputs/1'), TensorSpec(shape=(None, 128), dtype=tf.int32, name='inputs/2')]
        * True
        * None
      Keyword arguments: {}
    
    Option 2:
      Positional arguments (3 total):
        * [TensorSpec(shape=(None, 128), dtype=tf.int32, name='inputs/0'), TensorSpec(shape=(None, 128), dtype=tf.int32, name='inputs/1'), TensorSpec(shape=(None, 128), dtype=tf.int32, name='inputs/2')]
        * False
        * None
      Keyword arguments: {}
    
    Option 3:
      Positional arguments (3 total):
        * [TensorSpec(shape=(None, 128), dtype=tf.int32, name='input_word_ids'), TensorSpec(shape=(None, 128), dtype=tf.int32, name='input_mask'), TensorSpec(shape=(None, 128), dtype=tf.int32, name='input_type_ids')]
        * True
        * None
      Keyword arguments: {}
    
    Option 4:
      Positional arguments (3 total):
        * [TensorSpec(shape=(None, 128), dtype=tf.int32, name='input_word_ids'), TensorSpec(shape=(None, 128), dtype=tf.int32, name='input_mask'), TensorSpec(shape=(None, 128), dtype=tf.int32, name='input_type_ids')]
        * False
        * None
      Keyword arguments: {}
`

## 3. Steps to reproduce

Steps to reproduce the behavior.

## 4. Expected behavior

A clear and concise description of what you expected to happen.

## 5. Additional context

Include any logs that would be helpful to diagnose the problem.

## 6. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):CentOs7
- Mobile device name if the issue happens on a mobile device:
- TensorFlow installed from (source or binary):tf-nightly
- TensorFlow version (use command below):
- Python version:py3.6
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:10.1
- GPU model and memory:GTX 1080

<!-- 
Collect system information using our environment capture script.
https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can also obtain the TensorFlow version with:

1. TensorFlow 1.0
`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

2. TensorFlow 2.0
`python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`
-->
",monologue1107,b'models:official type:bug',2020-08-17T06:52:43Z,2020-09-06T06:54:53Z,,,,,,,
9116,"Using model_ main.py training will appear midway stop phenomenon, but use train.py Will not appear","<!--
As per our GitHub Policy (https://github.com/tensorflow/models/blob/master/ISSUES.md), we only address code bugs, documentation issues, and feature requests on GitHub.

We will automatically close questions and help related issues.

Please go to Stack Overflow (http://stackoverflow.com/questions/tagged/tensorflow-model-garden) for questions and help.

-->WARNING:tensorflow:From C:\Users\dw\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow_core\python\training\saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to delete files with this prefix.
W0817 10:25:09.366577  1052 deprecation.py:323] From C:\Users\dw\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow_core\python\training\saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to delete files with this prefix.
Windows fatal exception: access violation

Thread 0x000023dc (most recent call first):
  File ""C:\Users\dw\Anaconda3\envs\tensorflow\lib\threading.py"", line 295 in wait
  File ""C:\Users\dw\Anaconda3\envs\tensorflow\lib\queue.py"", line 164 in get
  File ""C:\Users\dw\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow_core\python\summary\writer\event_file_writer.py"", line 159 in run
  File ""C:\Users\dw\Anaconda3\envs\tensorflow\lib\threading.py"", line 916 in _bootstrap_inner
  File ""C:\Users\dw\Anaconda3\envs\tensorflow\lib\threading.py"", line 884 in _bootstrap

Current thread 0x0000041c (most recent call first):
  File ""C:\Users\dw\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow_core\python\lib\io\file_io.py"", line 392 in <listcomp>
  File ""C:\Users\dw\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow_core\python\lib\io\file_io.py"", line 390 in get_matching_files_v2
  File ""C:\Users\dw\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow_core\python\lib\io\file_io.py"", line 363 in get_matching_files
  File ""D:\tf_train\models\research\object_detection\builders\dataset_builder.py"", line 75 in read_dataset
  File ""D:\tf_train\models\research\object_detection\builders\dataset_builder.py"", line 184 in build
  File ""D:\tf_train\models\research\object_detection\inputs.py"", line 992 in eval_input
  File ""D:\tf_train\models\research\object_detection\inputs.py"", line 856 in _eval_input_fn
  File ""C:\Users\dw\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow_estimator\python\estimator\estimator.py"", line 1116 in _call_input_fn
  File ""C:\Users\dw\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow_estimator\python\estimator\estimator.py"", line 1025 in _get_features_and_labels_from_input_fn
  File ""C:\Users\dw\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow_estimator\python\estimator\estimator.py"", line 1544 in _call_model_fn_eval
  File ""C:\Users\dw\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow_estimator\python\estimator\estimator.py"", line 1511 in _evaluate_build_graph
  File ""C:\Users\dw\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow_estimator\python\estimator\estimator.py"", line 504 in _evaluate
  File ""C:\Users\dw\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow_estimator\python\estimator\estimator.py"", line 522 in _actual_eval
  File ""C:\Users\dw\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow_estimator\python\estimator\estimator.py"", line 480 in evaluate
  File ""C:\Users\dw\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow_estimator\python\estimator\training.py"", line 920 in evaluate_and_export
  File ""C:\Users\dw\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow_estimator\python\estimator\training.py"", line 539 in _evaluate
  File ""C:\Users\dw\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow_estimator\python\estimator\training.py"", line 519 in after_save
  File ""C:\Users\dw\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow_core\python\training\basic_session_run_hooks.py"", line 619 in _save
  File ""C:\Users\dw\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow_core\python\training\basic_session_run_hooks.py"", line 594 in after_run
  File ""C:\Users\dw\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow_core\python\training\monitored_session.py"", line 1426 in run
  File ""C:\Users\dw\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow_core\python\training\monitored_session.py"", line 1345 in run
  File ""C:\Users\dw\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow_core\python\training\monitored_session.py"", line 1259 in run
  File ""C:\Users\dw\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow_core\python\training\monitored_session.py"", line 754 in run
  File ""C:\Users\dw\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow_estimator\python\estimator\estimator.py"", line 1494 in _train_with_estimator_spec
  File ""C:\Users\dw\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow_estimator\python\estimator\estimator.py"", line 1195 in _train_model_default
  File ""C:\Users\dw\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow_estimator\python\estimator\estimator.py"", line 1161 in _train_model
  File ""C:\Users\dw\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow_estimator\python\estimator\estimator.py"", line 370 in train
  File ""C:\Users\dw\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow_estimator\python\estimator\training.py"", line 714 in run_local
  File ""C:\Users\dw\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow_estimator\python\estimator\training.py"", line 613 in run
  File ""C:\Users\dw\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow_estimator\python\estimator\training.py"", line 473 in train_and_evaluate
  File ""model_main.py"", line 105 in main
  File ""C:\Users\dw\Anaconda3\envs\tensorflow\lib\site-packages\absl\app.py"", line 250 in _run_main
  File ""C:\Users\dw\Anaconda3\envs\tensorflow\lib\site-packages\absl\app.py"", line 299 in run
  File ""C:\Users\dw\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow_core\python\platform\app.py"", line 40 in run
  File ""model_main.py"", line 109 in <module>








(tensorflow) D:\tf_train\workspaces\my_training_demo3>python
Python 3.6.2 |Continuum Analytics, Inc.| (default, Jul 20 2017, 12:30:02) [MSC v.1900 64 bit (AMD64)] on win32
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import tensorflow as tf
2020-08-17 10:25:54.426740: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_100.dll
>>> tf.test.is_built_with_cuda()
True
>>> tf.test.is_gpu_available(cuda_only=False,min_cuda_compute_capability=None)
2020-08-17 10:26:03.990248: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2
2020-08-17 10:26:04.016429: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library nvcuda.dll
2020-08-17 10:26:04.091491: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties:
name: GeForce RTX 2070 major: 7 minor: 5 memoryClockRate(GHz): 1.62
pciBusID: 0000:65:00.0
2020-08-17 10:26:04.108600: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_100.dll
2020-08-17 10:26:04.143000: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_100.dll
2020-08-17 10:26:04.180673: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_100.dll
2020-08-17 10:26:04.200179: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_100.dll
2020-08-17 10:26:04.237160: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_100.dll
2020-08-17 10:26:04.259150: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_100.dll
2020-08-17 10:26:04.319001: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll
2020-08-17 10:26:04.327782: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
2020-08-17 10:26:05.132927: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-08-17 10:26:05.141458: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0
2020-08-17 10:26:05.146601: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N
2020-08-17 10:26:05.152222: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/device:GPU:0 with 6306 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2070, pci bus id: 0000:65:00.0, compute capability: 7.5)
True
>>> exit()",dreamitpossible1,b'stalled stat:awaiting response type:support',2020-08-17T02:35:07Z,2020-09-15T04:36:56Z,,,,,,,
9106,"Training stucks at ""Instructions for updating: Use fn_output_signature instead""","### Prerequisites

Please answer the following questions for yourself before submitting an issue.

    [Yes ] I am using the latest TensorFlow Model Garden release and TensorFlow 2.
    [ Yes] I am reporting the issue to the correct repository. (Model Garden official or research directory)
    [ Yes] I checked to make sure that this issue has not been filed already.

### 1. The entire URL of the file you are using

python3 model_main_tf2.py --pipeline_config_path=/models/tf2/20200804_faster_rcnn_resnet50/pipeline.config --model_dir=checkpoints/20200804_faster_rcnn_resnet50 --alsologtostderr

### 2. Describe the bug

It seems like the training stucks at the point ""Instructions for updating: Use fn_output_signature instead"". It only creates one checkpoint and afterwards it seems like the training is frozen.

**LOG-OUTPUT:**

2020-08-14 08:42:33.110709: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-08-14 08:42:34.463497: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2020-08-14 08:42:34.488920: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:05:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.91GiB deviceMemoryBandwidth: 451.17GiB/s
2020-08-14 08:42:34.489845: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 1 with properties: 
pciBusID: 0000:09:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s
2020-08-14 08:42:34.489875: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-08-14 08:42:34.491363: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-08-14 08:42:34.492656: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-08-14 08:42:34.492904: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-08-14 08:42:34.494458: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-08-14 08:42:34.495275: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-08-14 08:42:34.495369: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64
2020-08-14 08:42:34.495385: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1753] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2020-08-14 08:42:34.495673: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-08-14 08:42:34.519294: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 3597555000 Hz
2020-08-14 08:42:34.519885: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4a7c2d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-08-14 08:42:34.519919: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-08-14 08:42:34.521380: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-08-14 08:42:34.521405: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      
WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.
W0814 08:42:34.522547 140702927255360 cross_device_ops.py:1202] There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.
INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)
I0814 08:42:34.522814 140702927255360 mirrored_strategy.py:341] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)
INFO:tensorflow:Maybe overwriting train_steps: None
I0814 08:42:34.528091 140702927255360 config_util.py:552] Maybe overwriting train_steps: None
INFO:tensorflow:Maybe overwriting use_bfloat16: False
I0814 08:42:34.528242 140702927255360 config_util.py:552] Maybe overwriting use_bfloat16: False
WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.
W0814 08:42:34.570969 140702927255360 dataset_builder.py:83] num_readers has been reduced to 1 to match input file shards.
WARNING:tensorflow:From /home/bastianbernhardt/safeai/image-detection/imagedetect/models/tf2/research/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_deterministic`.
W0814 08:42:34.574131 140702927255360 deprecation.py:323] From /home/bastianbernhardt/safeai/image-detection/imagedetect/models/tf2/research/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_deterministic`.
WARNING:tensorflow:From /home/bastianbernhardt/safeai/image-detection/imagedetect/models/tf2/research/object_detection/builders/dataset_builder.py:175: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.map()
W0814 08:42:34.660002 140702927255360 deprecation.py:323] From /home/bastianbernhardt/safeai/image-detection/imagedetect/models/tf2/research/object_detection/builders/dataset_builder.py:175: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.map()
WARNING:tensorflow:From /home/bastianbernhardt/.local/lib/python3.6/site-packages/tensorflow/python/util/dispatch.py:201: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.
W0814 08:42:39.970870 140702927255360 deprecation.py:323] From /home/bastianbernhardt/.local/lib/python3.6/site-packages/tensorflow/python/util/dispatch.py:201: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.
WARNING:tensorflow:From /home/bastianbernhardt/safeai/image-detection/imagedetect/models/tf2/research/object_detection/inputs.py:259: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
W0814 08:42:43.646067 140702927255360 deprecation.py:323] From /home/bastianbernhardt/safeai/image-detection/imagedetect/models/tf2/research/object_detection/inputs.py:259: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
WARNING:tensorflow:From /home/bastianbernhardt/safeai/image-detection/imagedetect/models/tf2/research/object_detection/model_lib_v2.py:347: set_learning_phase (from tensorflow.python.keras.backend) is deprecated and will be removed after 2020-10-11.
Instructions for updating:
Simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.
W0814 08:42:47.524089 140696258332416 deprecation.py:323] From /home/bastianbernhardt/safeai/image-detection/imagedetect/models/tf2/research/object_detection/model_lib_v2.py:347: set_learning_phase (from tensorflow.python.keras.backend) is deprecated and will be removed after 2020-10-11.
Instructions for updating:
Simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.
INFO:tensorflow:depth of additional conv before box predictor: 0
I0814 08:42:51.386824 140696258332416 convolutional_keras_box_predictor.py:154] depth of additional conv before box predictor: 0
WARNING:tensorflow:From /home/bastianbernhardt/.local/lib/python3.6/site-packages/tensorflow/python/util/dispatch.py:201: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.
Instructions for updating:
box_ind is deprecated, use box_indices instead
W0814 08:42:57.259847 140696258332416 deprecation.py:506] From /home/bastianbernhardt/.local/lib/python3.6/site-packages/tensorflow/python/util/dispatch.py:201: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.
Instructions for updating:
box_ind is deprecated, use box_indices instead
WARNING:tensorflow:From /home/bastianbernhardt/safeai/image-detection/imagedetect/models/tf2/research/object_detection/utils/model_util.py:57: Tensor.experimental_ref (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use ref() instead.
W0814 08:42:57.738880 140696258332416 deprecation.py:323] From /home/bastianbernhardt/safeai/image-detection/imagedetect/models/tf2/research/object_detection/utils/model_util.py:57: Tensor.experimental_ref (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use ref() instead.
WARNING:tensorflow:From /home/bastianbernhardt/.local/lib/python3.6/site-packages/tensorflow/python/util/dispatch.py:201: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.
Instructions for updating:

Future major versions of TensorFlow will allow gradients to flow
into the labels input on backprop by default.

See `tf.nn.softmax_cross_entropy_with_logits_v2`.

W0814 08:43:02.355147 140696258332416 deprecation.py:323] From /home/bastianbernhardt/.local/lib/python3.6/site-packages/tensorflow/python/util/dispatch.py:201: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.
Instructions for updating:

Future major versions of TensorFlow will allow gradients to flow
into the labels input on backprop by default.

See `tf.nn.softmax_cross_entropy_with_logits_v2`.

WARNING:tensorflow:Unresolved object in checkpoint: (root).model._groundtruth_lists
W0814 08:43:26.824852 140702927255360 util.py:150] Unresolved object in checkpoint: (root).model._groundtruth_lists
WARNING:tensorflow:Unresolved object in checkpoint: (root).model._first_stage_box_predictor_first_conv
W0814 08:43:26.825030 140702927255360 util.py:150] Unresolved object in checkpoint: (root).model._first_stage_box_predictor_first_conv
WARNING:tensorflow:Unresolved object in checkpoint: (root).model._first_stage_box_predictor
W0814 08:43:26.825097 140702927255360 util.py:150] Unresolved object in checkpoint: (root).model._first_stage_box_predictor
WARNING:tensorflow:Unresolved object in checkpoint: (root).model._maxpool_layer
W0814 08:43:26.825157 140702927255360 util.py:150] Unresolved object in checkpoint: (root).model._maxpool_layer
WARNING:tensorflow:Unresolved object in checkpoint: (root).model._mask_rcnn_box_predictor
W0814 08:43:26.825212 140702927255360 util.py:150] Unresolved object in checkpoint: (root).model._mask_rcnn_box_predictor
WARNING:tensorflow:Unresolved object in checkpoint: (root).model._batched_prediction_tensor_names
W0814 08:43:26.825268 140702927255360 util.py:150] Unresolved object in checkpoint: (root).model._batched_prediction_tensor_names
WARNING:tensorflow:Unresolved object in checkpoint: (root).model.endpoints
W0814 08:43:26.825321 140702927255360 util.py:150] Unresolved object in checkpoint: (root).model.endpoints
WARNING:tensorflow:Unresolved object in checkpoint: (root).model._first_stage_box_predictor_first_conv.layer_with_weights-0
W0814 08:43:26.825373 140702927255360 util.py:150] Unresolved object in checkpoint: (root).model._first_stage_box_predictor_first_conv.layer_with_weights-0
WARNING:tensorflow:Unresolved object in checkpoint: (root).model._first_stage_box_predictor_first_conv.layer-1
W0814 08:43:26.825427 140702927255360 util.py:150] Unresolved object in checkpoint: (root).model._first_stage_box_predictor_first_conv.layer-1
WARNING:tensorflow:Unresolved object in checkpoint: (root).model._first_stage_box_predictor_first_conv.layer-2
W0814 08:43:26.825478 140702927255360 util.py:150] Unresolved object in checkpoint: (root).model._first_stage_box_predictor_first_conv.layer-2
WARNING:tensorflow:Unresolved object in checkpoint: (root).model._first_stage_box_predictor._prediction_heads
W0814 08:43:26.825530 140702927255360 util.py:150] Unresolved object in checkpoint: (root).model._first_stage_box_predictor._prediction_heads
WARNING:tensorflow:Unresolved object in checkpoint: (root).model._first_stage_box_predictor._sorted_head_names
W0814 08:43:26.825581 140702927255360 util.py:150] Unresolved object in checkpoint: (root).model._first_stage_box_predictor._sorted_head_names
WARNING:tensorflow:Unresolved object in checkpoint: (root).model._first_stage_box_predictor._shared_nets
W0814 08:43:26.825633 140702927255360 util.py:150] Unresolved object in checkpoint: (root).model._first_stage_box_predictor._shared_nets
WARNING:tensorflow:Unresolved object in checkpoint: (root).model._mask_rcnn_box_predictor._box_prediction_head
W0814 08:43:26.825684 140702927255360 util.py:150] Unresolved object in checkpoint: (root).model._mask_rcnn_box_predictor._box_prediction_head
WARNING:tensorflow:Unresolved object in checkpoint: (root).model._mask_rcnn_box_predictor._class_prediction_head
W0814 08:43:26.825735 140702927255360 util.py:150] Unresolved object in checkpoint: (root).model._mask_rcnn_box_predictor._class_prediction_head
WARNING:tensorflow:Unresolved object in checkpoint: (root).model._mask_rcnn_box_predictor._third_stage_heads
W0814 08:43:26.825786 140702927255360 util.py:150] Unresolved object in checkpoint: (root).model._mask_rcnn_box_predictor._third_stage_heads
WARNING:tensorflow:Unresolved object in checkpoint: (root).model._first_stage_box_predictor_first_conv.layer_with_weights-0._inbound_nodes
W0814 08:43:26.825849 140702927255360 util.py:150] Unresolved object in checkpoint: (root).model._first_stage_box_predictor_first_conv.layer_with_weights-0._inbound_nodes
WARNING:tensorflow:Unresolved object in checkpoint: (root).model._first_stage_box_predictor_first_conv.layer_with_weights-0.kernel
W0814 08:43:26.825902 140702927255360 util.py:150] Unresolved object in checkpoint: (root).model._first_stage_box_predictor_first_conv.layer_with_weights-0.kernel
WARNING:tensorflow:Unresolved object in checkpoint: (root).model._first_stage_box_predictor_first_conv.layer_with_weights-0.bias
W0814 08:43:26.825955 140702927255360 util.py:150] Unresolved object in checkpoint: (root).model._first_stage_box_predictor_first_conv.layer_with_weights-0.bias
WARNING:tensorflow:Unresolved object in checkpoint: (root).model._first_stage_box_predictor_first_conv.layer-1._inbound_nodes
W0814 08:43:26.826007 140702927255360 util.py:150] Unresolved object in checkpoint: (root).model._first_stage_box_predictor_first_conv.layer-1._inbound_nodes
WARNING:tensorflow:Unresolved object in checkpoint: (root).model._first_stage_box_predictor_first_conv.layer-2._inbound_nodes
W0814 08:43:26.826058 140702927255360 util.py:150] Unresolved object in checkpoint: (root).model._first_stage_box_predictor_first_conv.layer-2._inbound_nodes
WARNING:tensorflow:Unresolved object in checkpoint: (root).model._first_stage_box_predictor._prediction_heads.box_encodings
W0814 08:43:26.826109 140702927255360 util.py:150] Unresolved object in checkpoint: (root).model._first_stage_box_predictor._prediction_heads.box_encodings
WARNING:tensorflow:Unresolved object in checkpoint: (root).model._first_stage_box_predictor._prediction_heads.class_predictions_with_background
W0814 08:43:26.826160 140702927255360 util.py:150] Unresolved object in checkpoint: (root).model._first_stage_box_predictor._prediction_heads.class_predictions_with_background
WARNING:tensorflow:Unresolved object in checkpoint: (root).model._first_stage_box_predictor._shared_nets.0
W0814 08:43:26.826212 140702927255360 util.py:150] Unresolved object in checkpoint: (root).model._first_stage_box_predictor._shared_nets.0
WARNING:tensorflow:Unresolved object in checkpoint: (root).model._mask_rcnn_box_predictor._box_prediction_head._box_encoder_layers
W0814 08:43:26.826264 140702927255360 util.py:150] Unresolved object in checkpoint: (root).model._mask_rcnn_box_predictor._box_prediction_head._box_encoder_layers
WARNING:tensorflow:Unresolved object in checkpoint: (root).model._mask_rcnn_box_predictor._class_prediction_head._class_predictor_layers
W0814 08:43:26.826315 140702927255360 util.py:150] Unresolved object in checkpoint: (root).model._mask_rcnn_box_predictor._class_prediction_head._class_predictor_layers
WARNING:tensorflow:Unresolved object in checkpoint: (root).model._first_stage_box_predictor._prediction_heads.box_encodings.0
W0814 08:43:26.826394 140702927255360 util.py:150] Unresolved object in checkpoint: (root).model._first_stage_box_predictor._prediction_heads.box_encodings.0
WARNING:tensorflow:Unresolved object in checkpoint: (root).model._first_stage_box_predictor._prediction_heads.class_predictions_with_background.0
W0814 08:43:26.826448 140702927255360 util.py:150] Unresolved object in checkpoint: (root).model._first_stage_box_predictor._prediction_heads.class_predictions_with_background.0
WARNING:tensorflow:Unresolved object in checkpoint: (root).model._mask_rcnn_box_predictor._box_prediction_head._box_encoder_layers.0
W0814 08:43:26.826501 140702927255360 util.py:150] Unresolved object in checkpoint: (root).model._mask_rcnn_box_predictor._box_prediction_head._box_encoder_layers.0
WARNING:tensorflow:Unresolved object in checkpoint: (root).model._mask_rcnn_box_predictor._box_prediction_head._box_encoder_layers.1
W0814 08:43:26.826553 140702927255360 util.py:150] Unresolved object in checkpoint: (root).model._mask_rcnn_box_predictor._box_prediction_head._box_encoder_layers.1
WARNING:tensorflow:Unresolved object in checkpoint: (root).model._mask_rcnn_box_predictor._box_prediction_head._box_encoder_layers.2
W0814 08:43:26.826604 140702927255360 util.py:150] Unresolved object in checkpoint: (root).model._mask_rcnn_box_predictor._box_prediction_head._box_encoder_layers.2
WARNING:tensorflow:Unresolved object in checkpoint: (root).model._mask_rcnn_box_predictor._class_prediction_head._class_predictor_layers.0
W0814 08:43:26.826656 140702927255360 util.py:150] Unresolved object in checkpoint: (root).model._mask_rcnn_box_predictor._class_prediction_head._class_predictor_layers.0
WARNING:tensorflow:Unresolved object in checkpoint: (root).model._mask_rcnn_box_predictor._class_prediction_head._class_predictor_layers.1
W0814 08:43:26.826708 140702927255360 util.py:150] Unresolved object in checkpoint: (root).model._mask_rcnn_box_predictor._class_prediction_head._class_predictor_layers.1
WARNING:tensorflow:Unresolved object in checkpoint: (root).model._mask_rcnn_box_predictor._class_prediction_head._class_predictor_layers.2
W0814 08:43:26.826760 140702927255360 util.py:150] Unresolved object in checkpoint: (root).model._mask_rcnn_box_predictor._class_prediction_head._class_predictor_layers.2
WARNING:tensorflow:Unresolved object in checkpoint: (root).model._first_stage_box_predictor._prediction_heads.box_encodings.0._box_encoder_layers
W0814 08:43:26.826811 140702927255360 util.py:150] Unresolved object in checkpoint: (root).model._first_stage_box_predictor._prediction_heads.box_encodings.0._box_encoder_layers
WARNING:tensorflow:Unresolved object in checkpoint: (root).model._first_stage_box_predictor._prediction_heads.class_predictions_with_background.0._class_predictor_layers
W0814 08:43:26.826862 140702927255360 util.py:150] Unresolved object in checkpoint: (root).model._first_stage_box_predictor._prediction_heads.class_predictions_with_background.0._class_predictor_layers
WARNING:tensorflow:Unresolved object in checkpoint: (root).model._mask_rcnn_box_predictor._box_prediction_head._box_encoder_layers.1.kernel
W0814 08:43:26.826914 140702927255360 util.py:150] Unresolved object in checkpoint: (root).model._mask_rcnn_box_predictor._box_prediction_head._box_encoder_layers.1.kernel
WARNING:tensorflow:Unresolved object in checkpoint: (root).model._mask_rcnn_box_predictor._box_prediction_head._box_encoder_layers.1.bias
W0814 08:43:26.826966 140702927255360 util.py:150] Unresolved object in checkpoint: (root).model._mask_rcnn_box_predictor._box_prediction_head._box_encoder_layers.1.bias
WARNING:tensorflow:Unresolved object in checkpoint: (root).model._mask_rcnn_box_predictor._class_prediction_head._class_predictor_layers.1.kernel
W0814 08:43:26.827017 140702927255360 util.py:150] Unresolved object in checkpoint: (root).model._mask_rcnn_box_predictor._class_prediction_head._class_predictor_layers.1.kernel
WARNING:tensorflow:Unresolved object in checkpoint: (root).model._mask_rcnn_box_predictor._class_prediction_head._class_predictor_layers.1.bias
W0814 08:43:26.827068 140702927255360 util.py:150] Unresolved object in checkpoint: (root).model._mask_rcnn_box_predictor._class_prediction_head._class_predictor_layers.1.bias
WARNING:tensorflow:Unresolved object in checkpoint: (root).model._first_stage_box_predictor._prediction_heads.box_encodings.0._box_encoder_layers.0
W0814 08:43:26.827129 140702927255360 util.py:150] Unresolved object in checkpoint: (root).model._first_stage_box_predictor._prediction_heads.box_encodings.0._box_encoder_layers.0
WARNING:tensorflow:Unresolved object in checkpoint: (root).model._first_stage_box_predictor._prediction_heads.class_predictions_with_background.0._class_predictor_layers.0
W0814 08:43:26.827180 140702927255360 util.py:150] Unresolved object in checkpoint: (root).model._first_stage_box_predictor._prediction_heads.class_predictions_with_background.0._class_predictor_layers.0
WARNING:tensorflow:Unresolved object in checkpoint: (root).model._first_stage_box_predictor._prediction_heads.box_encodings.0._box_encoder_layers.0.kernel
W0814 08:43:26.827233 140702927255360 util.py:150] Unresolved object in checkpoint: (root).model._first_stage_box_predictor._prediction_heads.box_encodings.0._box_encoder_layers.0.kernel
WARNING:tensorflow:Unresolved object in checkpoint: (root).model._first_stage_box_predictor._prediction_heads.box_encodings.0._box_encoder_layers.0.bias
W0814 08:43:26.827289 140702927255360 util.py:150] Unresolved object in checkpoint: (root).model._first_stage_box_predictor._prediction_heads.box_encodings.0._box_encoder_layers.0.bias
WARNING:tensorflow:Unresolved object in checkpoint: (root).model._first_stage_box_predictor._prediction_heads.class_predictions_with_background.0._class_predictor_layers.0.kernel
W0814 08:43:26.827340 140702927255360 util.py:150] Unresolved object in checkpoint: (root).model._first_stage_box_predictor._prediction_heads.class_predictions_with_background.0._class_predictor_layers.0.kernel
WARNING:tensorflow:Unresolved object in checkpoint: (root).model._first_stage_box_predictor._prediction_heads.class_predictions_with_background.0._class_predictor_layers.0.bias
W0814 08:43:26.827392 140702927255360 util.py:150] Unresolved object in checkpoint: (root).model._first_stage_box_predictor._prediction_heads.class_predictions_with_background.0._class_predictor_layers.0.bias
WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.
W0814 08:43:26.827444 140702927255360 util.py:158] A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.
WARNING:tensorflow:From /home/bastianbernhardt/.local/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py:574: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Use fn_output_signature instead
W0814 08:43:40.411885 140696283510528 deprecation.py:506] From /home/bastianbernhardt/.local/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py:574: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Use fn_output_signature instead

### 3. Steps to reproduce

I followed all the steps from this guide: https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/index.html
Installation works fine and now I want to train my own dataset.
What i already did so far:
- created tf-record files
- created labelmap
- configured the pipeline.config file (from pre-trained-model)
- every single thing you need to train your own model

I already tried 2 pre-trained models:
ssd_resnet50_v1_fpn_640x640_coco17_tpu-8
faster_rcnn_resnet50_v1_800x1333_coco17_gpu-8


### 4. Expected behavior

A running training process

### 5. Additional context


### 6. System information

    Linux
    TensorFlow installed from pip 2.3.0
    Python version: 3.6.9
    CUDA 10.1
    GPU model: GeForce GTX 1080 Ti
",Berbas95,b'models:research type:support',2020-08-14T09:00:47Z,2020-09-24T07:48:38Z,,,,,,,
9100,"Mean, std normalization inconsistent","# Prerequisites

Please answer the following questions for yourself before submitting an issue.

- [y] I am using the latest TensorFlow Model Garden release and TensorFlow 2.
- [y] I am reporting the issue to the correct repository. (Model Garden official or research directory)
- [y] I checked to make sure that this issue has not been filed already.

## 1. The entire URL of the file to debug:
https://github.com/tensorflow/models/blob/master/research/object_detection/model_lib_v2.py

## 2. Describe the bug:
The mean and std normalization of COCO images after preprocessing is still not in normal range in CenterNet. On `efficientdet_d0_coco17_tpu-32` behaviour is normal and preprocessing is giving close to 0 mean and 1 std. 
I have tried two ways to experiment with CenterNet by using `centernet_resnet_v1_50_fpn_512x512_coco17` config from the model zoo (without any checkpoint):

**1. By mentioning means and std in config:**
Means and stds taken as is from pre-trained model config file in the model zoo:
```
channel_means: [104.01362025, 114.03422265, 119.9165958 ]
channel_stds: [73.6027665 , 69.89082075, 70.9150767 ]
```
The mean and std of images _after_ normalization are computed from: https://github.com/tensorflow/models/blob/3f6fe2aa410d901aae8829597a65d084bffc20d3/research/object_detection/model_lib_v2.py#L598

```
features['image'].numpy().mean()
-115.607056
features['image'].numpy().std()
8.1939125
```
Notice the very negative value of mean and large value of std (batch size: 64).

**2. By mean:0, std:1 or not mentioning mean, std in config:**
```
channel_means: [0, 0, 0]
channel_stds: [1, 1, 1]
```

```
features['image'].numpy().mean()
-54.237076
features['image'].numpy().std()
80.218575
```

**3. If using `efficientdet_d0_coco17_tpu-32` not containing any mean, std info:**

```
features['image'].numpy().mean()
-0.9214938
features['image'].numpy().std()
1.362439
```

## 3. Steps to reproduce

Run https://github.com/tensorflow/models/blob/master/research/object_detection/model_main_tf2.py on config file of `centernet_resnet_v1_50_fpn_512x512_coco17` from TF model zoo and coco dataset. 

## 4. Expected behavior

Mean and std normalization should be consistent and inner workings documented. After standardization mean and std should be 0 and 1 respectively.

## 6. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 18.04): 18.04
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.3.0
- Python version: 3.7
",aabbas90,b'models:research type:bug',2020-08-13T19:29:36Z,2020-08-14T10:09:15Z,,,,,,,
9097,context R-CNN bugfix and documentation fix,"# Description

> :memo: Please include a summary of the change. 
>  
> * Please also include relevant motivation and context.  
> * List any dependencies that are required for this change.  

## Type of change

For a new feature or function, please create an issue first to discuss it
with us before submitting a pull request.

Note: Please delete options that are not relevant.

- [ ] Bug fix (non-breaking change which fixes an issue)
- [ ] Documentation update
- [ ] TensorFlow 2 migration
- [ ] New feature (non-breaking change which adds functionality)
- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)
- [ ] A new research paper code implementation
- [ ] Other (Specify)

## Tests

> :memo: Please describe the tests that you ran to verify your changes.
>  
> * Provide instructions so we can reproduce.  
> * Please also list any relevant details for your test configuration.  

**Test Configuration**:

## Checklist

- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).
- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).
- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).
- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.
- [ ] I have commented my code, particularly in hard-to-understand areas.
- [ ] I have made corresponding changes to the documentation.
- [ ] My changes generate no new warnings.
- [ ] I have added tests that prove my fix is effective or that my feature works.
",kmindspark,b'cla: yes ready to pull',2020-08-13T07:03:37Z,2020-08-13T19:05:49Z,,,,,,,
9093,Training stops after 0 step or 1,"WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/absl/app.py:250: main (from __main__) is deprecated and will be removed in a future version.
Instructions for updating:
Use object_detection/model_main.py.
W0812 08:59:19.918551 140042794891136 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/absl/app.py:250: main (from __main__) is deprecated and will be removed in a future version.
Instructions for updating:
Use object_detection/model_main.py.
WARNING:tensorflow:From /content/gdrive/My Drive/tensorflow/models/research/object_detection/legacy/trainer.py:265: create_global_step (from tf_slim.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Please switch to tf.train.create_global_step
W0812 08:59:19.940863 140042794891136 deprecation.py:323] From /content/gdrive/My Drive/tensorflow/models/research/object_detection/legacy/trainer.py:265: create_global_step (from tf_slim.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Please switch to tf.train.create_global_step
WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.
W0812 08:59:19.959898 140042794891136 dataset_builder.py:83] num_readers has been reduced to 1 to match input file shards.
WARNING:tensorflow:From /content/gdrive/My Drive/tensorflow/models/research/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0812 08:59:19.966951 140042794891136 deprecation.py:323] From /content/gdrive/My Drive/tensorflow/models/research/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
WARNING:tensorflow:From /content/gdrive/My Drive/tensorflow/models/research/object_detection/builders/dataset_builder.py:175: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.map()
W0812 08:59:19.987934 140042794891136 deprecation.py:323] From /content/gdrive/My Drive/tensorflow/models/research/object_detection/builders/dataset_builder.py:175: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.map()
WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f5dd1eb8780>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'
W0812 08:59:20.021534 140042794891136 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f5dd1eb8780>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'
WARNING:tensorflow:From /content/gdrive/My Drive/tensorflow/models/research/object_detection/builders/dataset_builder.py:48: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0812 08:59:20.193757 140042794891136 deprecation.py:323] From /content/gdrive/My Drive/tensorflow/models/research/object_detection/builders/dataset_builder.py:48: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
WARNING:tensorflow:From /content/gdrive/My Drive/tensorflow/models/research/object_detection/core/preprocessor.py:199: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.
Instructions for updating:
`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.
W0812 08:59:20.305646 140042794891136 deprecation.py:323] From /content/gdrive/My Drive/tensorflow/models/research/object_detection/core/preprocessor.py:199: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.
Instructions for updating:
`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.
WARNING:tensorflow:From /content/gdrive/My Drive/tensorflow/models/research/object_detection/core/box_list_ops.py:231: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
W0812 08:59:20.328324 140042794891136 deprecation.py:323] From /content/gdrive/My Drive/tensorflow/models/research/object_detection/core/box_list_ops.py:231: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
WARNING:tensorflow:From /content/gdrive/My Drive/tensorflow/models/research/object_detection/core/batcher.py:101: batch (from tensorflow.python.training.input) is deprecated and will be removed in a future version.
Instructions for updating:
Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.batch(batch_size)` (or `padded_batch(...)` if `dynamic_pad=True`).
W0812 08:59:21.043752 140042794891136 deprecation.py:323] From /content/gdrive/My Drive/tensorflow/models/research/object_detection/core/batcher.py:101: batch (from tensorflow.python.training.input) is deprecated and will be removed in a future version.
Instructions for updating:
Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.batch(batch_size)` (or `padded_batch(...)` if `dynamic_pad=True`).
WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/input.py:752: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.
Instructions for updating:
To construct input pipelines, use the `tf.data` module.
W0812 08:59:21.047419 140042794891136 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/input.py:752: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.
Instructions for updating:
To construct input pipelines, use the `tf.data` module.
WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/input.py:752: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.
Instructions for updating:
To construct input pipelines, use the `tf.data` module.
W0812 08:59:21.048484 140042794891136 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/input.py:752: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.
Instructions for updating:
To construct input pipelines, use the `tf.data` module.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
Please use `layer.__call__` method instead.
W0812 08:59:21.124046 140042794891136 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
Please use `layer.__call__` method instead.
INFO:tensorflow:depth of additional conv before box predictor: 0
I0812 08:59:22.979651 140042794891136 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0
INFO:tensorflow:depth of additional conv before box predictor: 0
I0812 08:59:23.009804 140042794891136 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0
INFO:tensorflow:depth of additional conv before box predictor: 0
I0812 08:59:23.038867 140042794891136 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0
INFO:tensorflow:depth of additional conv before box predictor: 0
I0812 08:59:23.067934 140042794891136 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0
INFO:tensorflow:depth of additional conv before box predictor: 0
I0812 08:59:23.097702 140042794891136 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0
INFO:tensorflow:depth of additional conv before box predictor: 0
I0812 08:59:23.127435 140042794891136 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0
WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0812 08:59:24.421999 140042794891136 deprecation.py:506] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/moving_averages.py:433: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0812 08:59:25.628363 140042794891136 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/moving_averages.py:433: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tf_slim/learning.py:734: Supervisor.__init__ (from tensorflow.python.training.supervisor) is deprecated and will be removed in a future version.
Instructions for updating:
Please switch to tf.train.MonitoredTrainingSession
W0812 08:59:29.347536 140042794891136 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/learning.py:734: Supervisor.__init__ (from tensorflow.python.training.supervisor) is deprecated and will be removed in a future version.
Instructions for updating:
Please switch to tf.train.MonitoredTrainingSession
2020-08-12 08:59:29.971342: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz
2020-08-12 08:59:29.971576: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0xf8bbc00 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-08-12 08:59:29.971608: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-08-12 08:59:29.973499: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-08-12 08:59:30.067230: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-12 08:59:30.067930: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0xf8bbdc0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-08-12 08:59:30.067965: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5
2020-08-12 08:59:30.068180: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-12 08:59:30.068700: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: 
name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59
pciBusID: 0000:00:04.0
2020-08-12 08:59:30.068999: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-08-12 08:59:30.070713: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-08-12 08:59:30.072333: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-08-12 08:59:30.072671: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-08-12 08:59:30.074361: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-08-12 08:59:30.075109: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-08-12 08:59:30.078601: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-08-12 08:59:30.078727: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-12 08:59:30.079331: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-12 08:59:30.079845: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0
2020-08-12 08:59:30.079916: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-08-12 08:59:30.081099: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-08-12 08:59:30.081127: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 
2020-08-12 08:59:30.081138: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N 
2020-08-12 08:59:30.081253: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-12 08:59:30.081805: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-12 08:59:30.082312: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2020-08-12 08:59:30.082360: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14125 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)
INFO:tensorflow:Restoring parameters from training/model.ckpt-0
I0812 08:59:30.087265 140042794891136 saver.py:1284] Restoring parameters from training/model.ckpt-0
WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/saver.py:1069: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file utilities to get mtimes.
W0812 08:59:33.396662 140042794891136 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/saver.py:1069: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file utilities to get mtimes.
INFO:tensorflow:Running local_init_op.
I0812 08:59:33.398859 140042794891136 session_manager.py:500] Running local_init_op.
INFO:tensorflow:Done running local_init_op.
I0812 08:59:33.711531 140042794891136 session_manager.py:502] Done running local_init_op.
INFO:tensorflow:Starting Session.
I0812 08:59:38.368438 140042794891136 learning.py:746] Starting Session.
INFO:tensorflow:Saving checkpoint to path training/model.ckpt
I0812 08:59:38.552260 140039141066496 supervisor.py:1117] Saving checkpoint to path training/model.ckpt
INFO:tensorflow:Starting Queues.
I0812 08:59:38.560002 140042794891136 learning.py:760] Starting Queues.
INFO:tensorflow:global_step/sec: 0
I0812 08:59:46.872894 140039132673792 supervisor.py:1099] global_step/sec: 0
2020-08-12 08:59:53.324476: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-08-12 08:59:58.749219: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
INFO:tensorflow:Recording summary at step 0.
I0812 09:00:01.116931 140039124281088 supervisor.py:1050] Recording summary at step 0.
INFO:tensorflow:global step 1: loss = 15.7697 (25.591 sec/step)
I0812 09:00:06.143113 140042794891136 learning.py:512] global step 1: loss = 15.7697 (25.591 sec/step)
^C

",ryhanahmedtamim,b'models:research type:support',2020-08-12T09:05:18Z,2020-09-10T06:51:19Z,,,,,,,
9091,a small typo in the read me file,"Project name seems that have changed to project ID. Just changed the project names to project Id.

# Description

> :memo: Please include a summary of the change. 
>  
> * Please also include relevant motivation and context.  
> * List any dependencies that are required for this change.  

## Type of change

For a new feature or function, please create an issue first to discuss it
with us before submitting a pull request.

Note: Please delete options that are not relevant.

- [ ] Bug fix (non-breaking change which fixes an issue)
- [ ] Documentation update
- [ ] TensorFlow 2 migration
- [ ] New feature (non-breaking change which adds functionality)
- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)
- [ ] A new research paper code implementation
- [ ] Other (Specify)

## Tests

> :memo: Please describe the tests that you ran to verify your changes.
>  
> * Provide instructions so we can reproduce.  
> * Please also list any relevant details for your test configuration.  

**Test Configuration**:

## Checklist

- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).
- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).
- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).
- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.
- [ ] I have commented my code, particularly in hard-to-understand areas.
- [ ] I have made corresponding changes to the documentation.
- [ ] My changes generate no new warnings.
- [ ] I have added tests that prove my fix is effective or that my feature works.
",sshahrokhi,b'cla: yes ready to pull',2020-08-11T21:20:16Z,2020-08-13T22:40:24Z,,,,,,,
9089,Support fine_tune in all CenterNet feature extractors.,"# Description
Support fine_tune for all CenterNet feature extractors.
Fixes
https://github.com/tensorflow/models/issues/8967#issuecomment-665082686

> :memo: Please include a summary of the change. 
>  
> * Please also include relevant motivation and context.  
> * List any dependencies that are required for this change.  

## Type of change

For a new feature or function, please create an issue first to discuss it
with us before submitting a pull request.

Note: Please delete options that are not relevant.

- [x] Bug fix (non-breaking change which fixes an issue)
- [ ] Documentation update
- [ ] TensorFlow 2 migration
- [ ] New feature (non-breaking change which adds functionality)
- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)
- [ ] A new research paper code implementation
- [ ] Other (Specify)


",vighneshbirodkar,b'cla: yes',2020-08-11T14:26:51Z,2020-08-14T07:22:41Z,,,,,,,
9086,exporter final version,"# Description

> :memo: Please include a summary of the change. 
>  
> * Please also include relevant motivation and context.  
> * List any dependencies that are required for this change.  

## Type of change

For a new feature or function, please create an issue first to discuss it
with us before submitting a pull request.

Note: Please delete options that are not relevant.

- [ ] Bug fix (non-breaking change which fixes an issue)
- [ ] Documentation update
- [ ] TensorFlow 2 migration
- [ ] New feature (non-breaking change which adds functionality)
- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)
- [ ] A new research paper code implementation
- [ ] Other (Specify)

## Tests

> :memo: Please describe the tests that you ran to verify your changes.
>  
> * Provide instructions so we can reproduce.  
> * Please also list any relevant details for your test configuration.  

**Test Configuration**:

## Checklist

- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).
- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).
- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).
- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.
- [ ] I have commented my code, particularly in hard-to-understand areas.
- [ ] I have made corresponding changes to the documentation.
- [ ] My changes generate no new warnings.
- [ ] I have added tests that prove my fix is effective or that my feature works.
",kmindspark,b'cla: yes ready to pull',2020-08-10T22:36:23Z,2020-08-13T19:32:11Z,,,,,,,
9085,Remove benchmark folder from the master branch. They are stale.,"Remove benchmark folder from the master branch. They are stale after sync config change.

For a new feature or function, please create an issue first to discuss it
with us before submitting a pull request.

Note: Please delete options that are not relevant.

- [ ] Bug fix (non-breaking change which fixes an issue)
- [ ] Documentation update
- [ ] TensorFlow 2 migration
- [ ] New feature (non-breaking change which adds functionality)
- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)
- [ ] A new research paper code implementation
- [x ] Other (Specify)

## Tests

> :memo: Please describe the tests that you ran to verify your changes.
>  
> * Provide instructions so we can reproduce.  
> * Please also list any relevant details for your test configuration.  

**Test Configuration**:

## Checklist

- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).
- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).
- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).
- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.
- [ ] I have commented my code, particularly in hard-to-understand areas.
- [ ] I have made corresponding changes to the documentation.
- [ ] My changes generate no new warnings.
- [ ] I have added tests that prove my fix is effective or that my feature works.
",saberkun,b'cla: yes',2020-08-10T19:02:02Z,2020-08-11T15:42:38Z,,,,,,,
9080,"VGGish embeddings are pre-activation, not post-activation.","Fixed a long-standing bug where the released VGGish model used
post-activation embedding output while the released embeddings
were pre-activation. There are still discrepancies due to
other reasons: differences in choice of YouTube transcode,
repeated resamplings with different resamplers, slight differences
in feature computation, etc.

This can break existing code that assumes post-activation embedding
values, but those can be easily fixed by passing the embeddings
through a ReLU.

# Description

> :memo: Please include a summary of the change. 
>  
> * Please also include relevant motivation and context.  
> * List any dependencies that are required for this change.  

## Type of change

For a new feature or function, please create an issue first to discuss it
with us before submitting a pull request.

Note: Please delete options that are not relevant.

- [x] Bug fix (non-breaking change which fixes an issue)
- [x] Documentation update
- [x] TensorFlow 2 migration
- [x] Breaking change (fix or feature that would cause existing functionality to not work as expected)

## Tests

> :memo: Please describe the tests that you ran to verify your changes.
>  
> * Provide instructions so we can reproduce.  
> * Please also list any relevant details for your test configuration.  

**Test Configuration**:

Ran vggish_{smoke_test, inference_demo, train_demo}.py

## Checklist

- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).
- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).
- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).
- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.
- [x] I have commented my code, particularly in hard-to-understand areas.
- [x] I have made corresponding changes to the documentation.
- [x] My changes generate no new warnings.
",plakal,b'cla: yes',2020-08-10T02:55:13Z,2020-08-10T13:29:09Z,,,,,,,
9076,Unable to install python3-tk. Exiting.,"While installing delf - !bash install_delf.sh

getting the below error.

What could be the issue?



Traceback is as below - 

Downloading Protobuf compiler from https://github.com/google/protobuf/releases/download/v3.3.0/protoc-3.3.0-linux-x86_64.zip
Archive:  protoc-3.3.0-linux-x86_64.zip
   creating: protoc/include/
   creating: protoc/include/google/
   creating: protoc/include/google/protobuf/
  inflating: protoc/include/google/protobuf/any.proto  
  inflating: protoc/include/google/protobuf/api.proto  
   creating: protoc/include/google/protobuf/compiler/
  inflating: protoc/include/google/protobuf/compiler/plugin.proto  
  inflating: protoc/include/google/protobuf/descriptor.proto  
  inflating: protoc/include/google/protobuf/duration.proto  
  inflating: protoc/include/google/protobuf/empty.proto  
  inflating: protoc/include/google/protobuf/field_mask.proto  
  inflating: protoc/include/google/protobuf/source_context.proto  
  inflating: protoc/include/google/protobuf/struct.proto  
  inflating: protoc/include/google/protobuf/timestamp.proto  
  inflating: protoc/include/google/protobuf/type.proto  
  inflating: protoc/include/google/protobuf/wrappers.proto  
   creating: protoc/bin/
  inflating: protoc/bin/protoc       
  inflating: protoc/readme.txt       
Compiling DELF Protobufs
Cleaning up Protobuf compiler download
Installing matplotlib, numpy, scikit-image, scipy and python3-tk
Requirement already satisfied: matplotlib in /opt/conda/lib/python3.7/site-packages (3.2.1)
Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (1.18.5)
Requirement already satisfied: scikit-image in /opt/conda/lib/python3.7/site-packages (0.16.2)
Requirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (1.4.1)
Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib) (0.10.0)
Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib) (2.8.1)
Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib) (2.4.7)
Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib) (1.2.0)
Requirement already satisfied: networkx>=2.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image) (2.4)
Requirement already satisfied: pillow>=4.3.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image) (7.2.0)
Requirement already satisfied: imageio>=2.3.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image) (2.8.0)
Requirement already satisfied: PyWavelets>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image) (1.1.1)
Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from cycler>=0.10->matplotlib) (1.14.0)
Requirement already satisfied: decorator>=4.3.0 in /opt/conda/lib/python3.7/site-packages (from networkx>=2.0->scikit-image) (4.4.2)
WARNING: You are using pip version 20.1.1; however, version 20.2.1 is available.
You should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.
install_delf.sh: line 101: sudo: command not found
Unable to install python3-tk. Exiting.





",pn12,b'models:research stat:awaiting response type:bug',2020-08-08T07:47:57Z,2020-08-10T14:41:02Z,,,,,,,
9072,Update losses.proto,"extending iou loss options

# Description

> :memo: Please include a summary of the change. 
>  
> * Please also include relevant motivation and context.  
> * List any dependencies that are required for this change.  

## Type of change

For a new feature or function, please create an issue first to discuss it
with us before submitting a pull request.

Note: Please delete options that are not relevant.

- [ ] Bug fix (non-breaking change which fixes an issue)
- [ ] Documentation update
- [ ] TensorFlow 2 migration
- [x] New feature (non-breaking change which adds functionality)
- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)
- [ ] A new research paper code implementation
- [ ] Other (Specify)

## Tests

> :memo: Please describe the tests that you ran to verify your changes.
>  
> * Provide instructions so we can reproduce.  
> * Please also list any relevant details for your test configuration.  

**Test Configuration**:

## Checklist

- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).
- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).
- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).
- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.
- [ ] I have commented my code, particularly in hard-to-understand areas.
- [ ] I have made corresponding changes to the documentation.
- [ ] My changes generate no new warnings.
- [ ] I have added tests that prove my fix is effective or that my feature works.
",johnpjust,b'cla: no',2020-08-07T19:38:44Z,2020-08-10T04:23:21Z,,,,,,,
9070,Consider regression model in predict mode,"# Description

The key `input_meta_data['num_labels']` doesn't always exist, it is defaulted to 1 when the Bert model is a regression model. In both modes `train_and_eval` and `export`, the ""default to 1"" setting is considered but not in `predict` mode.

Another issue this PR tries to solve is the unnecessary softmax applied to logit for regression model.

## Type of change

- [x] Bug fix (non-breaking change which fixes an issue)

## Tests

Create a customized `DataProcessor` class with attribute `is_regression = True`, the output meta data will look something like follows where key `num_labels` is absent.

```
{
    ""processor_type"": ""RegressionDataProcessor"",
    ""train_data_size"": 19765218,
    ""max_seq_length"": 128,
    ""task_type"": ""bert_regression"",
    ""label_type"": ""int"",
    ""eval_data_size"": 1260452
}
```

This lets the finetuning process to create a regression Bert model. Finetuning finished without issue, prediction ran fine too after the proposed change, otherwise prediction will raise exception as follows.

```
KeyError: 'num_labels'
```

**Test Configuration**:

With `tf_models_nightly-2.2.0.dev20200720`

## Checklist

- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).
- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).
- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).
- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.
- [x] I have commented my code, particularly in hard-to-understand areas.
- [x] I have made corresponding changes to the documentation.
- [x] My changes generate no new warnings.
- [x] I have added tests that prove my fix is effective or that my feature works.
",NivekNey,b'cla: yes models:official ready to pull',2020-08-07T14:49:31Z,2020-08-17T19:20:52Z,,,,,,,
9069,Update bert README,"# Description

> :memo: Please include a summary of the change. 
>  add a note about creating fine-tuning data with SQUAD 2.0 in bert README
> * Please also include relevant motivation and context.  
> * List any dependencies that are required for this change.  

## Type of change

For a new feature or function, please create an issue first to discuss it
with us before submitting a pull request.

Note: Please delete options that are not relevant.

- [ ] Bug fix (non-breaking change which fixes an issue)
- [x] Documentation update
- [ ] TensorFlow 2 migration
- [ ] New feature (non-breaking change which adds functionality)
- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)
- [ ] A new research paper code implementation
- [ ] Other (Specify)

## Tests

> :memo: Please describe the tests that you ran to verify your changes.
>  
> * Provide instructions so we can reproduce.  
> * Please also list any relevant details for your test configuration.  

**Test Configuration**:

## Checklist

- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).
- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).
- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).
- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.
- [ ] I have commented my code, particularly in hard-to-understand areas.
- [ ] I have made corresponding changes to the documentation.
- [ ] My changes generate no new warnings.
- [ ] I have added tests that prove my fix is effective or that my feature works.
",ChAnYaNG97,b'cla: yes ready to pull',2020-08-07T11:42:55Z,2020-08-08T05:42:05Z,,,,,,,
9066,Update losses.proto,"adding more iou loss options

# Description

> :memo: Please include a summary of the change. 
>  
> * Please also include relevant motivation and context.  
> * List any dependencies that are required for this change.  

## Type of change

For a new feature or function, please create an issue first to discuss it
with us before submitting a pull request.

Note: Please delete options that are not relevant.

- [ ] Bug fix (non-breaking change which fixes an issue)
- [ ] Documentation update
- [ ] TensorFlow 2 migration
- [ ] New feature (non-breaking change which adds functionality)
- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)
- [ ] A new research paper code implementation
- [ ] Other (Specify)

## Tests

> :memo: Please describe the tests that you ran to verify your changes.
>  
> * Provide instructions so we can reproduce.  
> * Please also list any relevant details for your test configuration.  

**Test Configuration**:

## Checklist

- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).
- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).
- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).
- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.
- [ ] I have commented my code, particularly in hard-to-understand areas.
- [ ] I have made corresponding changes to the documentation.
- [ ] My changes generate no new warnings.
- [ ] I have added tests that prove my fix is effective or that my feature works.
",johnpjust,b'cla: no',2020-08-07T08:31:46Z,2020-08-07T08:34:55Z,,,,,,,
9065,“No such layer” error,"Hi,

I am trying to train a network for object detection (a pre-trained network from the research folder), starting from the main python file:
[https://github.com/tensorflow/models/tree/master/research/object_detection/model_main_tf2](https://github.com/tensorflow/models/tree/master/research/object_detection/model_main_tf2)

I am executing it with this command:
`python model_main_tf2.py --model_dir=../models_tf2/my_faster_rcnn_resnet50 --pipeline_config_path=../models_tf2/my_faster_rcnn_resnet50/pipeline.config`

And I obtain this weird error:
`ValueError: No such layer: conv4_block6_out`
(and obtain the same error when I try to do it with another network architecture)

The complete traceback is:

```
    (…)/models/tf2/research/object_detection/model_lib_v2.py:355 _dummy_computation_fn
        labels)
    (…)/models/tf2/research/object_detection/model_lib_v2.py:122 _compute_losses_and_predictions_dicts
        **model.get_side_inputs(features))
    (…)/models/tf2/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py:824 predict
        prediction_dict = self._predict_first_stage(preprocessed_inputs)
    (…)/models/tf2/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py:877 _predict_first_stage
        image_shape) = self._extract_rpn_feature_maps(preprocessed_inputs)
    (…)/models/tf2/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py:1318 _extract_rpn_feature_maps
        preprocessed_inputs)
    (…)/models/tf2/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py:1334 _extract_proposal_features
        name=self.first_stage_feature_extractor_scope))
    (…)/models/tf2/research/object_detection/models/faster_rcnn_resnet_keras_feature_extractor.py:125 get_proposal_feature_extractor_model
        name=conv4_last_layer).output
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/network.py:569 get_layer
        raise ValueError('No such layer: ' + name)

    ValueError: No such layer: conv4_block6_out
```

",Mengant29,b'models:research stat:awaiting response type:bug',2020-08-07T07:37:38Z,2020-09-10T06:52:32Z,,,,,,,
9064,DELF ImportError: cannot import name 'aggregation_config_pb2'(when I running in Google Colab),"<!--
As per our GitHub Policy (https://github.com/tensorflow/models/blob/master/ISSUES.md), we only address code bugs, documentation issues, and feature requests on GitHub.

We will automatically close questions and help related issues.

Please go to Stack Overflow (http://stackoverflow.com/questions/tagged/tensorflow-model-garden) for questions and help.

-->

Hi, I want to run DELF in Google Colab(Becuz I don't have linux), but some errors occur.

In https://github.com/tensorflow/models/blob/master/research/delf/INSTALL_INSTRUCTIONS.md , 

I run from first code( `pip3 install 'tensorflow>=2.2.0'` ) to this code (`pip3 install -e . # Install ""delf"" package.` ).

when I run `pip3 install -e`, code result is this:

![image](https://user-images.githubusercontent.com/57930520/89609544-27ff2680-d8b3-11ea-9a70-45b2f4c01c4b.png)

![image](https://user-images.githubusercontent.com/57930520/89609551-2d5c7100-d8b3-11ea-976c-0eb5156e0bff.png)

Google Colab said ""Successfully installed delf"", so I think successfully installed delf.

But, the next code result is: 

![image](https://user-images.githubusercontent.com/57930520/89609638-6a286800-d8b3-11ea-86a1-c56de597a3c2.png)

How I fix this error? 

(refer to https://github.com/tensorflow/models/issues/8773, I guess my code didn't properly install the libary, but I can't fix it... I'm newbie in deep learning and DELF, so I need to help)







",PeterKim1,b'models:research type:support',2020-08-07T04:53:58Z,2020-08-26T06:22:30Z,,,,,,,
9063,Checkpoint reading error during training!,"# Prerequisites

Please answer the following questions for yourself before submitting an issue.

- [x] I am using the latest TensorFlow Model Garden release and TensorFlow 2.
- [x] I am reporting the issue to the correct repository. (Model Garden official or research directory)
- [x] I checked to make sure that this issue has not been filed already.


Please help! I am following the tutorial at 
https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_training_and_evaluation.md

and keep getting this error during training
```
tensorflow.python.framework.errors_impl.DataLossError: Unable to open table file TRAIN/models/my_model_dir: 
Failed precondition: TRAIN/models/my_model_dir;
 Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?
```

i am following the object detection tutorial exactly and formatted my file tree as shown. Is the tuorial provided file structure correct ? After checking the config file, it seemed like the fine_tune_checkpoint parameter was looking for a single .ckpt file. I just input the entire directory instead. Currently, the checkpoint link provided downloads a folder with multiple checkpoint files (checkpoint/ckpt-0.data-00000-of-00001/ckpt-0.index). I don't know if this makes any difference or if this is just the same thing in a different format, but trying to figure out why I'm getting this error!
",jrash33,b'models:research type:bug',2020-08-06T22:55:17Z,2020-08-08T07:00:49Z,,,,,,,
9062,"Error indices[0] = 0 is not in [0, 0) with mask-rcnn object-detection model with tensorflow 2","# Prerequisites

Please answer the following questions for yourself before submitting an issue.

- [ x] I am using the latest TensorFlow Model Garden release and TensorFlow 2.
- [ x] I am reporting the issue to the correct repository. (Model Garden official or research directory)
- [ x] I checked to make sure that this issue has not already been filed.

## 2. Describe the bug
Please help! I am following the tutorial at https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_training_and_evaluation.md

everything has went smoothly until training. I keep getting this error below. I have seen forums with this error before but none as recently as now and using tensorflow 2
```
  File ""/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/executor.py"", line 67, in wait
    pywrap_tfe.TFE_ExecutorWaitForAllPendingNodes(self._handle)
tensorflow.python.framework.errors_impl.InvalidArgumentError: indices[0] = 0 is not in [0, 0)
	 [[{{node GatherV2_4}}]]
	 [[MultiDeviceIteratorGetNextFromShard]]
	 [[RemoteCall]]
```

## 3. Steps to reproduce
Here is my config file:
```
# Mask R-CNN with Inception Resnet v2 (no atrous)
# Sync-trained on COCO (with 8 GPUs) with batch size 16 (1024x1024 resolution)
# Initialized from Imagenet classification checkpoint
#
# Train on GPU-8
#
# Achieves 40.4 box mAP and 35.5 mask mAP on COCO17 val

model {
  faster_rcnn {
    number_of_stages: 3
    num_classes: 90
    image_resizer {
      fixed_shape_resizer {
        height: 1024
        width: 1024
      }
    }
    feature_extractor {
      type: 'faster_rcnn_inception_resnet_v2_keras'
    }
    first_stage_anchor_generator {
      grid_anchor_generator {
        scales: [0.25, 0.5, 1.0, 2.0]
        aspect_ratios: [0.5, 1.0, 2.0]
        height_stride: 16
        width_stride: 16
      }
    }
    first_stage_box_predictor_conv_hyperparams {
      op: CONV
      regularizer {
        l2_regularizer {
          weight: 0.0
        }
      }
      initializer {
        truncated_normal_initializer {
          stddev: 0.01
        }
      }
    }
    first_stage_nms_score_threshold: 0.0
    first_stage_nms_iou_threshold: 0.7
    first_stage_max_proposals: 300
    first_stage_localization_loss_weight: 2.0
    first_stage_objectness_loss_weight: 1.0
    initial_crop_size: 17
    maxpool_kernel_size: 1
    maxpool_stride: 1
    second_stage_box_predictor {
      mask_rcnn_box_predictor {
        use_dropout: false
        dropout_keep_probability: 1.0
        fc_hyperparams {
          op: FC
          regularizer {
            l2_regularizer {
              weight: 0.0
            }
          }
          initializer {
            variance_scaling_initializer {
              factor: 1.0
              uniform: true
              mode: FAN_AVG
            }
          }
        }
        mask_height: 33
        mask_width: 33
        mask_prediction_conv_depth: 0
        mask_prediction_num_conv_layers: 4
        conv_hyperparams {
          op: CONV
          regularizer {
            l2_regularizer {
              weight: 0.0
            }
          }
          initializer {
            truncated_normal_initializer {
              stddev: 0.01
            }
          }
        }
        predict_instance_masks: true
      }
    }
    second_stage_post_processing {
      batch_non_max_suppression {
        score_threshold: 0.0
        iou_threshold: 0.6
        max_detections_per_class: 100
        max_total_detections: 100
      }
      score_converter: SOFTMAX
    }
    second_stage_localization_loss_weight: 2.0
    second_stage_classification_loss_weight: 1.0
    second_stage_mask_prediction_loss_weight: 4.0
    resize_masks: false
  }
}

train_config: {
  batch_size: 16
  num_steps: 200000
  optimizer {
    momentum_optimizer: {
      learning_rate: {
        cosine_decay_learning_rate {
          learning_rate_base: 0.008
          total_steps: 200000
          warmup_learning_rate: 0.0
          warmup_steps: 5000
        }
      }
      momentum_optimizer_value: 0.9
    }
    use_moving_average: false
  }
  gradient_clipping_by_norm: 10.0
  fine_tune_checkpoint_version: V2
  fine_tune_checkpoint: ""TRAIN/models/my_model_dir/mask_rcnn_checkpoints""
  fine_tune_checkpoint_type: ""detection""
  data_augmentation_options {
    random_horizontal_flip {
    }
  }
}

train_input_reader: {
  label_map_path: ""TRAIN/data/pet_label_map.pbtxt""
  tf_record_input_reader {
    input_path: ""TRAIN/data/train_dataset/pet_faces_train.record-?????-of-00010""
  }
  load_instance_masks: true
  mask_type: PNG_MASKS
}

eval_config: {
  metrics_set: ""coco_detection_metrics""
  metrics_set: ""coco_mask_metrics""
  eval_instance_masks: true
  use_moving_averages: false
  batch_size: 1
  include_metrics_per_category: true
}

eval_input_reader: {
  label_map_path: ""TRAIN/data/pet_label_map.pbtxt""
  shuffle: false
  num_epochs: 1
  tf_record_input_reader {
    input_path: ""TRAIN/data/eval_dataset/pet_faces_val.record-?????-of-00010""
  }
  load_instance_masks: true
  mask_type: PNG_MASKS
}
```

I have created the pets data set tf records as indicated in the tutorial and running the below code, everything goes well until i get this error a couple times: 

```
python object_detection/model_main_tf2.py    
 --pipeline_config_path=TRAIN/models/my_model_dir/mask_rcnn_inception_resnet_v2_1024x1024_coco17_gpu-8.config     
--model_dir=TRAIN/models/my_model_dir     
--alsologtostderr
```


Any direction at all would be a huge help as I have been stuck on this for quite awhile!

",jrash33,b'models:research type:bug',2020-08-06T21:15:49Z,2020-08-06T22:46:13Z,,,,,,,
9061,ValueError: Tensor's shape is not compatible with supplied shape custom dataset using ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8,"# Prerequisites

Please answer the following questions for yourself before submitting an issue.

- [x] I am using the latest TensorFlow Model Garden release and TensorFlow 2.
- [x] I am reporting the issue to the correct repository. (Model Garden official or research directory)
- [x] I checked to make sure that this issue has not already been filed.

## 1. The entire URL of the file you are using

https://github.com/tensorflow/models/blob/master/research/object_detection/configs/tf2/ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8.config
https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md

## 2. Describe the bug

When attempting to train a custom model using the config file and the corresponding model from the model zoo I receive the following error:   ValueError: Tensor's shape (3, 3, 256, 546) is not compatible with supplied shape (3, 3, 256, 12). Full output listed below. I am having difficult identifying what the source of this error is.

## 3. Steps to reproduce

Add custom dataset into the object_detection directory, download the config file and model from the links above, move the model to the object_detection directory, config gets placed into a object_detection/training directory, and edit the config file as shown below. Then run the command: 

MEG:object_detection meg$ python model_main_tf2.py --pipeline_config_path ./trainingpython model_main_tf2.py --pipeline_config_path=training/ssd_mobilenet_v1_fpn_shared_box_predictor_640x64


## 4. Expected behavior

I expect when I run the following command that I will begin to train an object detection model:

MEG:object_detection meg$ python model_main_tf2.py --pipeline_config_path ./trainingpython model_main_tf2.py --pipeline_config_path=training/ssd_mobilenet_v1_fpn_shared_box_predictor_640x64




## 5. Additional context
 SSD with Mobilenet v1 FPN feature extractor, shared box predictor and focal
 loss (a.k.a Retinanet).
 See Lin et al, https://arxiv.org/abs/1708.02002
 Trained on COCO, initialized from Imagenet classification checkpoint

 Achieves 29.7 mAP on COCO14 minival dataset.


--------config file --------------
 This config is TPU compatible

model {
  ssd {
    inplace_batchnorm_update: true
    freeze_batchnorm: false
    num_classes: 1
    box_coder {
      faster_rcnn_box_coder {
        y_scale: 10.0
        x_scale: 10.0
        height_scale: 5.0
        width_scale: 5.0
      }
    }
    matcher {
      argmax_matcher {
        matched_threshold: 0.5
        unmatched_threshold: 0.5
        ignore_thresholds: false
        negatives_lower_than_unmatched: true
        force_match_for_each_row: true
        use_matmul_gather: true
      }
    }
    similarity_calculator {
      iou_similarity {
      }
    }
    encode_background_as_zeros: true
    anchor_generator {
      multiscale_anchor_generator {
        min_level: 3
        max_level: 7
        anchor_scale: 4.0
        aspect_ratios: [1.0, 2.0, 0.5]
        scales_per_octave: 2
      }
    }
    image_resizer {
      fixed_shape_resizer {
        height: 640
        width: 640
      }
    }
    box_predictor {
      weight_shared_convolutional_box_predictor {
        depth: 256
        class_prediction_bias_init: -4.6
        conv_hyperparams {
          activation: RELU_6,
          regularizer {
            l2_regularizer {
              weight: 0.00004
            }
          }
          initializer {
            random_normal_initializer {
              stddev: 0.01
              mean: 0.0
            }
          }
          batch_norm {
            scale: true,
            decay: 0.997,
            epsilon: 0.001,
          }
        }
        num_layers_before_predictor: 4
        kernel_size: 3
      }
    }
    feature_extractor {
      type: 'ssd_mobilenet_v1_fpn_keras'
      fpn {
        min_level: 3
        max_level: 7
      }
      min_depth: 16
      depth_multiplier: 1.0
      conv_hyperparams {
        activation: RELU_6,
        regularizer {
          l2_regularizer {
            weight: 0.00004
          }
        }
        initializer {
          random_normal_initializer {
            stddev: 0.01
            mean: 0.0
          }
        }
        batch_norm {
          scale: true,
          decay: 0.997,
          epsilon: 0.001,
        }
      }
      override_base_feature_extractor_hyperparams: true
    }
    loss {
      classification_loss {
        weighted_sigmoid_focal {
          alpha: 0.25
          gamma: 2.0
        }
      }
      localization_loss {
        weighted_smooth_l1 {
        }
      }
      classification_weight: 1.0
      localization_weight: 1.0
    }
    normalize_loss_by_num_matches: true
    normalize_loc_loss_by_codesize: true
    post_processing {
      batch_non_max_suppression {
        score_threshold: 1e-8
        iou_threshold: 0.6
        max_detections_per_class: 100
        max_total_detections: 100
      }
      score_converter: SIGMOID
    }
  }
}

train_config: {
  fine_tune_checkpoint: ""ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8/checkpoint/model.ckpt""
  batch_size: 20
  sync_replicas: true
  startup_delay_steps: 0
  replicas_to_aggregate: 8
  num_steps: 25000
  data_augmentation_options {
    random_horizontal_flip {
    }
  }
  data_augmentation_options {
    random_crop_image {
      min_object_covered: 0.0
      min_aspect_ratio: 0.75
      max_aspect_ratio: 3.0
      min_area: 0.75
      max_area: 1.0
      overlap_thresh: 0.0
    }
  }
  optimizer {
    momentum_optimizer: {
      learning_rate: {
        cosine_decay_learning_rate {
          learning_rate_base: .04
          total_steps: 25000
          warmup_learning_rate: .013333
          warmup_steps: 2000
        }
      }
      momentum_optimizer_value: 0.9
    }
    use_moving_average: false
  }
  max_number_of_boxes: 100
  unpad_groundtruth_tensors: false
}

train_input_reader: {
  tf_record_input_reader {
    input_path: ""data/train.record""
  }
  label_map_path: ""data/object-detection.pbtxt""
}

eval_config: {
  metrics_set: ""coco_detection_metrics""
  use_moving_averages: false
  num_examples: 8000
}

eval_input_reader: {
  tf_record_input_reader {
    input_path: ""data/test.record""
  }
  label_map_path: ""training/object-detection.pbtxt""
  shuffle: false
  num_readers: 1
}

--------ERROR OUTPUT----------

(SSD) MEG:object_detection meg$ python model_main_tf2.py --pipeline_config_path ./trainingpython model_main_tf2.py --pipeline_config_path=training/ssd_mobilenet_v1_fpn_shared_box_predictor_640x640_coco14_sync.config  --model_dir results --checkpoint_dir ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8/checkpoint/
WARNING:tensorflow:Forced number of epochs for all eval validations to be 1.
W0806 10:46:35.252889 4634940864 model_lib_v2.py:905] Forced number of epochs for all eval validations to be 1.
INFO:tensorflow:Maybe overwriting sample_1_of_n_eval_examples: None
I0806 10:46:35.253049 4634940864 config_util.py:552] Maybe overwriting sample_1_of_n_eval_examples: None
INFO:tensorflow:Maybe overwriting use_bfloat16: False
I0806 10:46:35.253113 4634940864 config_util.py:552] Maybe overwriting use_bfloat16: False
INFO:tensorflow:Maybe overwriting eval_num_epochs: 1
I0806 10:46:35.253171 4634940864 config_util.py:552] Maybe overwriting eval_num_epochs: 1
WARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.
W0806 10:46:35.253251 4634940864 model_lib_v2.py:920] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.
2020-08-06 10:46:35.342232: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-08-06 10:46:35.360943: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fae5731f580 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-08-06 10:46:35.360963: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
WARNING:tensorflow:From /Users/meg/opt/anaconda3/envs/SSD/lib/python3.6/site-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_deterministic`.
W0806 10:46:35.394832 4634940864 deprecation.py:323] From /Users/meg/opt/anaconda3/envs/SSD/lib/python3.6/site-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_deterministic`.
WARNING:tensorflow:From /Users/meg/opt/anaconda3/envs/SSD/lib/python3.6/site-packages/object_detection/builders/dataset_builder.py:175: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.map()
W0806 10:46:35.418838 4634940864 deprecation.py:323] From /Users/meg/opt/anaconda3/envs/SSD/lib/python3.6/site-packages/object_detection/builders/dataset_builder.py:175: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.map()
WARNING:tensorflow:From /Users/meg/opt/anaconda3/envs/SSD/lib/python3.6/site-packages/object_detection/inputs.py:79: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.
W0806 10:46:40.934005 4634940864 deprecation.py:323] From /Users/meg/opt/anaconda3/envs/SSD/lib/python3.6/site-packages/object_detection/inputs.py:79: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.
WARNING:tensorflow:From /Users/meg/opt/anaconda3/envs/SSD/lib/python3.6/site-packages/object_detection/inputs.py:259: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
W0806 10:46:42.502683 4634940864 deprecation.py:323] From /Users/meg/opt/anaconda3/envs/SSD/lib/python3.6/site-packages/object_detection/inputs.py:259: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
INFO:tensorflow:Waiting for new checkpoint at ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8/checkpoint/
I0806 10:46:46.062254 4634940864 checkpoint_utils.py:125] Waiting for new checkpoint at ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8/checkpoint/
INFO:tensorflow:Found new checkpoint at ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8/checkpoint/ckpt-0
I0806 10:46:46.079427 4634940864 checkpoint_utils.py:134] Found new checkpoint at ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8/checkpoint/ckpt-0
Traceback (most recent call last):
  File ""model_main_tf2.py"", line 106, in <module>
    tf.compat.v1.app.run()
  File ""/Users/meg/opt/anaconda3/envs/SSD/lib/python3.6/site-packages/tensorflow/python/platform/app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""/Users/meg/opt/anaconda3/envs/SSD/lib/python3.6/site-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/Users/meg/opt/anaconda3/envs/SSD/lib/python3.6/site-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""model_main_tf2.py"", line 83, in main
    wait_interval=300, timeout=FLAGS.eval_timeout)
  File ""/Users/meg/opt/anaconda3/envs/SSD/lib/python3.6/site-packages/object_detection/model_lib_v2.py"", line 959, in eval_continuously
    global_step=global_step)
  File ""/Users/meg/opt/anaconda3/envs/SSD/lib/python3.6/site-packages/object_detection/model_lib_v2.py"", line 774, in eager_eval_loop
    eval_dict, losses_dict, class_agnostic = compute_eval_dict(features, labels)
  File ""/Users/meg/opt/anaconda3/envs/SSD/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py"", line 580, in __call__
    result = self._call(*args, **kwds)
  File ""/Users/meg/opt/anaconda3/envs/SSD/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py"", line 627, in _call
    self._initialize(args, kwds, add_initializers_to=initializers)
  File ""/Users/meg/opt/anaconda3/envs/SSD/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py"", line 506, in _initialize
    *args, **kwds))
  File ""/Users/meg/opt/anaconda3/envs/SSD/lib/python3.6/site-packages/tensorflow/python/eager/function.py"", line 2446, in _get_concrete_function_internal_garbage_collected
    graph_function, _, _ = self._maybe_define_function(args, kwargs)
  File ""/Users/meg/opt/anaconda3/envs/SSD/lib/python3.6/site-packages/tensorflow/python/eager/function.py"", line 2777, in _maybe_define_function
    graph_function = self._create_graph_function(args, kwargs)
  File ""/Users/meg/opt/anaconda3/envs/SSD/lib/python3.6/site-packages/tensorflow/python/eager/function.py"", line 2667, in _create_graph_function
    capture_by_value=self._capture_by_value),
  File ""/Users/meg/opt/anaconda3/envs/SSD/lib/python3.6/site-packages/tensorflow/python/framework/func_graph.py"", line 981, in func_graph_from_py_func
    func_outputs = python_func(*func_args, **func_kwargs)
  File ""/Users/meg/opt/anaconda3/envs/SSD/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py"", line 441, in wrapped_fn
    return weak_wrapped_fn().__wrapped__(*args, **kwds)
  File ""/Users/meg/opt/anaconda3/envs/SSD/lib/python3.6/site-packages/tensorflow/python/framework/func_graph.py"", line 968, in wrapper
    raise e.ag_error_metadata.to_exception(e)
ValueError: in user code:

    /Users/meg/opt/anaconda3/envs/SSD/lib/python3.6/site-packages/object_detection/model_lib_v2.py:721 compute_eval_dict  *
        losses_dict, prediction_dict = _compute_losses_and_predictions_dicts(
    /Users/meg/opt/anaconda3/envs/SSD/lib/python3.6/site-packages/object_detection/model_lib_v2.py:118 _compute_losses_and_predictions_dicts  *
        prediction_dict = model.predict(
    /Users/meg/opt/anaconda3/envs/SSD/lib/python3.6/site-packages/object_detection/meta_architectures/ssd_meta_arch.py:591 predict  *
        predictor_results_dict = self._box_predictor(feature_maps)
    /Users/meg/opt/anaconda3/envs/SSD/lib/python3.6/site-packages/object_detection/core/box_predictor.py:202 call  *
        return self._predict(image_features, **kwargs)
    /Users/meg/opt/anaconda3/envs/SSD/lib/python3.6/site-packages/object_detection/predictors/convolutional_keras_box_predictor.py:484 _predict  *
        prediction = head_obj(head_tower_feature)
    /Users/meg/opt/anaconda3/envs/SSD/lib/python3.6/site-packages/object_detection/predictors/heads/head.py:69 call  *
        return self._predict(features)
    /Users/meg/opt/anaconda3/envs/SSD/lib/python3.6/site-packages/object_detection/predictors/heads/keras_class_head.py:340 _predict  *
        class_predictions_with_background = layer(
    /Users/meg/opt/anaconda3/envs/SSD/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py:897 __call__  **
        self._maybe_build(inputs)
    /Users/meg/opt/anaconda3/envs/SSD/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py:2416 _maybe_build
        self.build(input_shapes)  # pylint:disable=not-callable
    /Users/meg/opt/anaconda3/envs/SSD/lib/python3.6/site-packages/tensorflow/python/keras/layers/convolutional.py:163 build
        dtype=self.dtype)
    /Users/meg/opt/anaconda3/envs/SSD/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py:577 add_weight
        caching_device=caching_device)
    /Users/meg/opt/anaconda3/envs/SSD/lib/python3.6/site-packages/tensorflow/python/training/tracking/base.py:724 _add_variable_with_custom_getter
        name=name, shape=shape)
    /Users/meg/opt/anaconda3/envs/SSD/lib/python3.6/site-packages/tensorflow/python/training/tracking/base.py:791 _preload_simple_restoration
        checkpoint_position=checkpoint_position, shape=shape)
    /Users/meg/opt/anaconda3/envs/SSD/lib/python3.6/site-packages/tensorflow/python/training/tracking/base.py:75 __init__
        self.wrapped_value.set_shape(shape)
    /Users/meg/opt/anaconda3/envs/SSD/lib/python3.6/site-packages/tensorflow/python/framework/ops.py:1107 set_shape
        (self.shape, shape))

    ValueError: Tensor's shape (3, 3, 256, 546) is not compatible with supplied shape (3, 3, 256, 12)




## 6. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS Mojave 10.14.6
- Mobile device name if the issue happens on a mobile device:
- TensorFlow installed from (source or binary): command line? I used the setup file
- TensorFlow version (use command below): 2.2.0
- Python version: 3.6.10
- Bazel version (if compiling from source): n/a
- GCC/Compiler version (if compiling from source): n/a
- CUDA/cuDNN version: n/a
- GPU model and memory: n/a

<!-- 
Collect system information using our environment capture script.
https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can also obtain the TensorFlow version with:

1. TensorFlow 1.0
`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

2. TensorFlow 2.0
`python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`
-->
",mgon5170,b'models:research type:bug',2020-08-06T20:39:31Z,2020-08-20T15:55:29Z,,,,,,,
9057,Converting tf2 ssd_mobilenet-v1 object detection model to tflite model,"I am using Google Colab to run the training and conversion.

When I run the script 

!python /content/models/research/object_detection/export_tflite_ssd_graph.py \
--pipeline_config=/content/workspace/training/pipeline.config \
--trained_checkpoint=/content/workspace/training/model.ckpt \
--output_dir=/content/workspace/hands_detection \
--add_postprocessing_op=true

I get this error:

Traceback (most recent call last):
  File ""/content/models/research/object_detection/export_tflite_ssd_graph.py"", line 144, in <module>
    tf.app.run(main)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""/content/models/research/object_detection/export_tflite_ssd_graph.py"", line 135, in main
    text_format.Merge(f.read(), pipeline_config)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/lib/io/file_io.py"", line 116, in read
    self._preread_check()
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/lib/io/file_io.py"", line 79, in _preread_check
    self.__name, 1024 * 512)
TypeError: __init__(): incompatible constructor arguments. The following argument types are supported:
    1. tensorflow.python._pywrap_file_io.BufferedInputStream(arg0: str, arg1: int)

Invoked with: None, 524288

I traced the error to a pre_reading check for pipeline.config file. But it doesn't seem to be changed at all and all paths are correct.",Raphaeal19,b'models:research type:bug',2020-08-06T07:34:58Z,2020-08-31T11:51:38Z,,,,,,,
9055,add config file for faster rcnn resnet 50 fpn on dataset coco17 using tpu-8,"# Description

> :memo: add config file for faster rcnn resnet 50 fpn on dataset coco17 using tpu-8


## Type of change

For a new feature or function, please create an issue first to discuss it
with us before submitting a pull request.

Note: Please delete options that are not relevant.

- [ ] Bug fix (non-breaking change which fixes an issue)
- [ ] Documentation update
- [ ] TensorFlow 2 migration
- [ ] New feature (non-breaking change which adds functionality)
- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)
- [ ] A new research paper code implementation
- [x] Other (New config file)

## Tests

> :memo: Please describe the tests that you ran to verify your changes.
>  
> * Provide instructions so we can reproduce.  
> * Please also list any relevant details for your test configuration.  

**Test Configuration**:

## Checklist

- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).
- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).
- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).
- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.
- [x] I have commented my code, particularly in hard-to-understand areas.
- [x] I have made corresponding changes to the documentation.
- [x] My changes generate no new warnings.
- [x] I have added tests that prove my fix is effective or that my feature works.
",syiming,b'cla: yes ready to pull',2020-08-05T19:34:12Z,2020-08-11T15:23:53Z,,,,,,,
9054,Pre-trained model for Efficient net B0 implementation,"# Prerequisites

Please answer the following questions for yourself before submitting an issue.

- [X] I am using the latest TensorFlow Model Garden release and TensorFlow 2.
- [X] I am reporting the issue to the correct repository. (Model Garden official or research directory)
- [X] I checked to make sure that this issue has not been filed already.

## 1. The entire URL of the file you are using

https://github.com/tensorflow/models/tree/master/official/vision/image_classification

## 2. Describe the bug

For efficient net implementation (classifier_trainer.py), is the [TFHUB](https://tfhub.dev/tensorflow/efficientnet/b0/classification/1 ) saved model or pretrained weights expected to work ? I'm a bit confused as the [README.md](https://github.com/tensorflow/models/tree/master/official/vision/image_classification#efficientnet) says efficient net is work in progress.

I'm evaluating the saved_model.pb provided in the tfhub for B0 model and my accuracy on Imagenet is close to zero. 

The way I'm evaluating is as follows:
In the classifer_trainer.py, I add `model = tf.keras.models.load_model('eff_b0_checkpoint/')` (directory which has saved_model.pb)
and comment out the training part and skip to 

> validation_output = model.evaluate(validation_dataset, steps=validation_steps, verbose=2)

Can you please let me know if this is right ? Thank you !! 
",peri044,b'models:official type:bug',2020-08-05T19:17:47Z,2020-08-24T22:59:20Z,,,,,,,
9050,vision >> classifier_trainer.py >> dataset,"# Prerequisites

Please answer the following questions for yourself before submitting an issue.

I am using the latest TensorFlow Model Garden release2.3.0 and TensorFlow 2.3.0
I am reporting the issue to the correct repository. (Model Garden official or research directory
I checked to make sure that this issue has not been filed already.

## 1. The entire URL of the file you are using

https://github.com/tensorflow/models/blob/r2.3.0/official/vision/image_classification/classifier_trainer.py

## 2. Describe the bug

When I run classifier_trainer.py to training resnet50, it always stopping at:
```shell
dataset_factory >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>tfds.builder()
2020-08-05 11:52:32.953550: W tensorflow/core/platform/cloud/google_auth_provider.cc:184] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with ""Not found: Could not locate the credentials file."". Retrieving token from GCE failed with ""Failed precondition: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Couldn't resolve host 'metadata'"".
2020-08-05 11:53:48.123025: E tensorflow/core/platform/cloud/curl_http_request.cc:611] The transmission  of request 0x55c74a5687f0 (URI: https://www.googleapis.com/storage/v1/b/tfds-data/o/dataset_info%2Fimagenet2012%2F5.0.0?fields=size%2Cgeneration%2Cupdated) has been stuck at 0 of 0 bytes for 61 seconds and will be aborted. CURL timing information: lookup time: 0.010172 (No error), connect time: 0.066656 (No error), pre-transfer time: 0 (No error), start-transfer time: 0 (No error)
```

and I find this url is 404 :
https://www.googleapis.com/storage/v1/b/tfds-data/o/dataset_info%2Fimagenet2012%2F5.0.0?fields=size%2Cgeneration%2Cupdated

So tfds.builder() will not work (in dataset_factory.py )
## 3. Steps to reproduce

training script:
```shell
export CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
MODEL_DIR=../output
DATA_DIR=/datasets/ImageNet/tfrecord

python3 classifier_trainer.py \
  --mode=train_and_eval \
  --model_type=resnet \
  --dataset=imagenet \
  --model_dir=$MODEL_DIR \
  --data_dir=$DATA_DIR \
  --config_file=configs/examples/resnet/imagenet/gpu.yaml \
  --params_override='runtime.num_gpus=8'
```

## 4. Expected behavior

A clear and concise description of what you expected to happen.

## 5. Additional context

Include any logs that would be helpful to diagnose the problem.

## 6. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device name if the issue happens on a mobile device:
- TensorFlow installed from pip install tensorflow):
- TensorFlow version (use command below): 2.3.0
- Python version: 3.7.7
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source): gcc (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609
- CUDA/cuDNN version: 10.2
- GPU model and memory: 8× v100(16GB)

<!-- 
Collect system information using our environment capture script.
https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can also obtain the TensorFlow version with:

1. TensorFlow 1.0
`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

2. TensorFlow 2.0
`python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`
-->
",Flowingsun007,b'models:official type:bug',2020-08-05T04:36:56Z,2020-08-06T06:52:21Z,,,,,,,
9043,Losses and ops with giou -- new pr,"# Description

> :memo: Please include a summary of the change. 
>  
> * Please also include relevant motivation and context.  
> * List any dependencies that are required for this change.  

## Type of change

For a new feature or function, please create an issue first to discuss it
with us before submitting a pull request.

Note: Please delete options that are not relevant.

- [ ] Bug fix (non-breaking change which fixes an issue)
- [ ] Documentation update
- [ ] TensorFlow 2 migration
- [ ] New feature (non-breaking change which adds functionality)
- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)
- [ ] A new research paper code implementation
- [ ] Other (Specify)

## Tests

> :memo: Please describe the tests that you ran to verify your changes.
>  
> * Provide instructions so we can reproduce.  
> * Please also list any relevant details for your test configuration.  

**Test Configuration**:

## Checklist

- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).
- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).
- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).
- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.
- [ ] I have commented my code, particularly in hard-to-understand areas.
- [ ] I have made corresponding changes to the documentation.
- [ ] My changes generate no new warnings.
- [ ] I have added tests that prove my fix is effective or that my feature works.
",kmindspark,b'cla: yes ready to pull',2020-08-04T20:09:34Z,2020-08-06T21:05:25Z,,,,,,,
9039,"Invoked with: <tensorflow.python._pywrap_tfe.TFE_MonitoringIntGaugeCell object at 0x00000199C670A6C0>, None","TypeError: TFE_MonitoringIntGaugeCellSet(): incompatible function arguments. The following argument types are supported:
    1. (arg0: tensorflow.python._pywrap_tfe.TFE_MonitoringIntGaugeCell, arg1: int) -> None

I'm using transformer on translation(zh-en) task, but got this error,   i'm using tensorflow==2.3.0 ",barton-wa,b'models:official stat:awaiting response type:bug',2020-08-04T09:39:18Z,2020-08-05T07:33:40Z,,,,,,,
9036,Exporter v2 with side inputs,"# Description

> :memo: Please include a summary of the change. 
>  
> * Please also include relevant motivation and context.  
> * List any dependencies that are required for this change.  

## Type of change

For a new feature or function, please create an issue first to discuss it
with us before submitting a pull request.

Note: Please delete options that are not relevant.

- [ ] Bug fix (non-breaking change which fixes an issue)
- [ ] Documentation update
- [ ] TensorFlow 2 migration
- [ ] New feature (non-breaking change which adds functionality)
- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)
- [ ] A new research paper code implementation
- [ ] Other (Specify)

## Tests

> :memo: Please describe the tests that you ran to verify your changes.
>  
> * Provide instructions so we can reproduce.  
> * Please also list any relevant details for your test configuration.  

**Test Configuration**:

## Checklist

- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).
- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).
- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).
- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.
- [x] I have commented my code, particularly in hard-to-understand areas.
- [x] I have made corresponding changes to the documentation.
- [x] My changes generate no new warnings.
- [x] I have added tests that prove my fix is effective or that my feature works.
",kmindspark,b'cla: yes',2020-08-03T20:41:55Z,2020-08-11T19:03:17Z,,,,,,,
9031,Converting TF 2 Object Detection Model to TFLite,"# Prerequisites

Please answer the following questions for yourself before submitting an issue.

- [X] I am using the latest TensorFlow Model Garden release and TensorFlow 2.
- [X] I am reporting the issue to the correct repository. (Model Garden official or research directory)
- [X] I checked to make sure that this issue has not already been filed.

## 1. The entire URL of the file you are using

https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md

## 2. Describe the bug

I am trying to Convert the SSD ResNet50 V1 FPN 640x640 (RetinaNet50) of the TF 2 Object Detection Zoo to TFLite. My Code is the following: 
```python
converter = tf.lite.TFLiteConverter.from_saved_model('ssd_resnet50_v1_fpn_640x640_coco17_tpu-8/saved_model/',signature_keys=['serving_default'])
converter.optimizations = [tf.lite.Optimize.DEFAULT]
converter.experimental_new_converter = True
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]

tflite_model = converter.convert()

with tf.io.gfile.GFile('model.tflite', 'wb') as f:
  f.write(tflite_model)

```

The Convertion is running without any Errors, but when I try to use the TFLite Model with the following Code

```python
interpreter = tf.lite.Interpreter(model_path=""./model.tflite"")
interpreter.allocate_tensors()

input_details = interpreter.get_input_details()
output_details = interpreter.get_output_details()

input_shape = input_details[0]['shape']
input_data = np.array(np.random.random_sample((1,640,640,3)), dtype=np.uint8)
interpreter.set_tensor(input_details[0]['index'], input_data)

interpreter.invoke()
output_data = interpreter.get_tensor(output_details[0]['index'])
print(output_data)
```

I am getting this Error: 
```
ValueError                                Traceback (most recent call last)
<ipython-input-17-44fd9cb644ae> in <module>
     20 rdm_img = np.array(np.random.random_sample((1,640,640,3)), dtype=np.uint8)
     21 # input_data = np.array(np.random.random_sample(input_shape), dtype=np.uint8)
---> 22 interpreter.set_tensor(input_details[0]['index'], rdm_img)
     23 
     24 interpreter.invoke()

/usr/lib/python3.6/site-packages/tensorflow/lite/python/interpreter.py in set_tensor(self, tensor_index, value)
    406       ValueError: If the interpreter could not set the tensor.
    407     """"""
--> 408     self._interpreter.SetTensor(tensor_index, value)
    409 
    410   def resize_tensor_input(self, input_index, tensor_size, strict=False):

ValueError: Cannot set tensor: Dimension mismatch. Got 640 but expected 1 for dimension 1 of input 0.
```

It seems that there are some Problems with the Dimensions of the converted Model. 
Thanks for your help!


## 6. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- TensorFlow version (use command below): 2.4.0
- Python version: 3.7
",Snixells,b'models:research type:bug',2020-08-03T15:49:31Z,2020-08-28T11:27:42Z,,,,,,,
9027,Create new PR with losses and box list ops,"# Description

> :memo: Please include a summary of the change. 
>  
> * Please also include relevant motivation and context.  
> * List any dependencies that are required for this change.  

## Type of change

For a new feature or function, please create an issue first to discuss it
with us before submitting a pull request.

Note: Please delete options that are not relevant.

- [ ] Bug fix (non-breaking change which fixes an issue)
- [ ] Documentation update
- [ ] TensorFlow 2 migration
- [ ] New feature (non-breaking change which adds functionality)
- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)
- [ ] A new research paper code implementation
- [ ] Other (Specify)

## Tests

> :memo: Please describe the tests that you ran to verify your changes.
>  
> * Provide instructions so we can reproduce.  
> * Please also list any relevant details for your test configuration.  

**Test Configuration**:

## Checklist

- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).
- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).
- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).
- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.
- [ ] I have commented my code, particularly in hard-to-understand areas.
- [ ] I have made corresponding changes to the documentation.
- [ ] My changes generate no new warnings.
- [ ] I have added tests that prove my fix is effective or that my feature works.
",kmindspark,b'cla: yes',2020-08-03T01:10:50Z,2020-08-05T00:03:50Z,,,,,,,
9024,Fix Mobilenetv3 edgetpu bugs,Fix Mobilenetv3 edgetpu residual definition bug.,luotigerlsx,b'cla: yes help wanted:paper implementation',2020-08-01T17:15:21Z,2020-08-01T17:15:35Z,,,,,,,
9023,Error with shape mismatch when changing `num_scales` for mask rcnn,"## 1. The entire URL of the file you are using

https://github.com/tensorflow/models/tree/master/official/vision/detection/ops/roi_ops.py

## 2. Describe the bug

In the `multilevel_propose_rois` function, the returned `selected_rois` should have shape [batch_size, rpn_post_nms_top_k, 4]. However, if the `params.anchor.num_scales` argument is anything other that 1, the `batch_size` of the returned `selected_rois` is actually `batch_size` * `num_scales`. The reason for this is because when calculating ""this_level_anchors"", a -1 is used to fill in the shape: 

```
        this_level_anchors = tf.cast(
            tf.reshape(anchor_boxes[level], [-1, num_boxes, 4]),
            dtype=this_level_scores.dtype)
```

I assume this should instead be something like ...
```        
        this_level_anchors = tf.cast(
            tf.reshape(anchor_boxes[level], [-1, num_boxes*num_scales, 4]),
            dtype=this_level_scores.dtype)
``` 

but this introduces shape mismatch errors in other parts of the code as well. For example, after making the above changes, I see a new error:

```
ValueError: Dimensions must be equal, but are 49152 and 147456 for '{{node multilevel_propose_rois/level_2/decode_boxes/mul_2}} = Mul[T=DT_FLOAT](multilevel_propose_rois/level_2/decode_boxes/strided_slice, multilevel_propose_rois/level_2/decode_boxes/add)' with input shapes: [1,49152,1], [1,147456,1].
```

This is referring to a size mismatch in the `official/vision/detection/utils/box_utils.py` script, for the line `decoded_boxes_yc = dy * anchor_h + anchor_yc`, in which `dy` has shape (1, 49152, 1), while `anchor_h` has shape (1, 147456, 1). Here, we see the same factor of three that comes from the `num_scales` value.

## 3. Steps to reproduce

Set the `params.anchors.num_scales` to something larger than 1. I was trying this with 3.

## 4. Expected behavior

I expect the returned `selected_rois` to have shape [batch_size, rpn_post_nms_top_k, 4], but it actually has shape  [batch_size*num_scales, rpn_post_nms_top_k, 4].

## 5. Additional context
-- 

## 6. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Debian GNU/Linux 9.11
- Mobile device name if the issue happens on a mobile device: N/A
- TensorFlow installed from (source or binary): binary (pip)
- TensorFlow version (use command below): 2.3.0
- Python version: 3.7.3
- CUDA/cuDNN version: 10.1/7.6.4
- GPU model and memory: NVIDIA Tesla K80
",roserustowicz,b'models:official type:bug',2020-08-01T06:19:04Z,2020-08-13T21:39:33Z,,,,,,,
9021,Bugfix in context r-cnn scripts,"# Description

> :memo: Please include a summary of the change. 
>  
> * Please also include relevant motivation and context.  
> * List any dependencies that are required for this change.  

## Type of change

For a new feature or function, please create an issue first to discuss it
with us before submitting a pull request.

Note: Please delete options that are not relevant.

- [x] Bug fix (non-breaking change which fixes an issue)
- [ ] Documentation update
- [ ] TensorFlow 2 migration
- [ ] New feature (non-breaking change which adds functionality)
- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)
- [ ] A new research paper code implementation
- [ ] Other (Specify)

## Tests

> :memo: Please describe the tests that you ran to verify your changes.
>  
> * Provide instructions so we can reproduce.  
> * Please also list any relevant details for your test configuration.  

**Test Configuration**:

## Checklist

- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).
- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).
- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).
- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.
- [ ] I have commented my code, particularly in hard-to-understand areas.
- [ ] I have made corresponding changes to the documentation.
- [ ] My changes generate no new warnings.
- [ ] I have added tests that prove my fix is effective or that my feature works.
",kmindspark,b'cla: yes ready to pull',2020-07-31T19:00:33Z,2020-08-01T06:24:09Z,,,,,,,
9020,Fixed doc strings and typos,"# Description
Fixed doc strings and typos

## Type of change

For a new feature or function, please create an issue first to discuss it
with us before submitting a pull request.

Note: Please delete options that are not relevant.

- [ ] Bug fix (non-breaking change which fixes an issue)
- [x] Documentation update
- [ ] TensorFlow 2 migration
- [ ] New feature (non-breaking change which adds functionality)
- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)
- [ ] A new research paper code implementation
- [ ] Other (Specify)

## Checklist

- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).
- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).
- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).
- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.
- [ ] I have commented my code, particularly in hard-to-understand areas.
- [x] I have made corresponding changes to the documentation.
- [x] My changes generate no new warnings.
- [ ] I have added tests that prove my fix is effective or that my feature works.
",srihari-humbarwadi,b'cla: yes ready to pull',2020-07-31T14:34:48Z,2020-07-31T18:20:05Z,,,,,,,
9016,"Hi All, I'm training custom data set in TF2 and now i have finished training the model. To test my model with the test image what should i do??","<!--
As per our GitHub Policy (https://github.com/tensorflow/models/blob/master/ISSUES.md), we only address code bugs, documentation issues, and feature requests on GitHub.

We will automatically close questions and help related issues.

Please go to Stack Overflow (http://stackoverflow.com/questions/tagged/tensorflow-model-garden) for questions and help.

-->
",Deepthi-Jain,b'type:support',2020-07-31T00:34:12Z,2020-07-31T00:34:34Z,,,,,,,
9015,Bugfix: keep highest N candidates instead of removing,"# Description

The comment says ""select the last self.beam_size"", but `[:-self.beam_size]` actually means the opposite, i.e., removing the last self.beam_size.

## Type of change

- [x] Bug fix (non-breaking change which fixes an issue)

## Tests

Before the bugfix, the output was not a sentence:

```
Captions for image COCO_val2014_000000224477.jpg:
  0)  (p=0.000001)
  1) surfer (p=0.000000)
  2) two (p=0.000000)
```

After the bugfix, the output looks good:

```
Captions for image COCO_val2014_000000224477.jpg:
  0) a man riding a wave on top of a surfboard . (p=0.035869)
  1) a person riding a surf board on a wave (p=0.018637)
  2) a man riding a wave on a surfboard in the ocean . (p=0.004625)
```

**Test Configuration**:

* Python 3.6
* TensorFlow 1.0
* Pretrained model from [KranthiGV/Pretrained-Show-and-Tell-model](https://github.com/KranthiGV/Pretrained-Show-and-Tell-model)

## Checklist

- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).
- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).
- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).
- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.
- [x] I have commented my code, particularly in hard-to-understand areas.
- [x] I have made corresponding changes to the documentation.
- [x] My changes generate no new warnings.
- [x] I have added tests that prove my fix is effective or that my feature works.
",abcdabcd987,b'cla: yes',2020-07-30T22:40:54Z,2020-08-14T20:39:32Z,,,,,,,
9009,Use distirbuted dataset for NCF evaluation.,"PiperOrigin-RevId: 323948101

# Description
Cherry pick for Master branch to fix NCF performance regression on GPUs and TPU donuts.

## Type of change

- [ ] Bug fix (non-breaking change which fixes an issue)

## Tests
Run on a TPU pod.

",gagika,b'cla: yes',2020-07-30T07:42:28Z,2020-07-30T21:01:45Z,,,,,,,
9008,DELF local feature model,"@andrefaraujo 

I have run this command to export local feature model but getting below error 👍 

command : 
python3 model/export_model.py \
  --ckpt_path=gldv2_training/delf_weights \
  --export_path=gldv2_model_local \
  --block3_strides

Error 

2020-07-30 12:50:59.844301: W tensorflow/python/util/util.cc:329] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.
Traceback (most recent call last):
  File ""models/research/delf/delf/python/training/model/export_model.py"", line 111, in <module>
    app.run(main)
  File ""/home/chhokarpardeep/.local/lib/python3.8/site-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/home/chhokarpardeep/.local/lib/python3.8/site-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""models/research/delf/delf/python/training/model/export_model.py"", line 107, in main
    tf.saved_model.save(module, export_path)
  File ""/home/chhokarpardeep/.local/lib/python3.8/site-packages/tensorflow/python/saved_model/save.py"", line 950, in save
    _, exported_graph, object_saver, asset_info = _build_meta_graph(
  File ""/home/chhokarpardeep/.local/lib/python3.8/site-packages/tensorflow/python/saved_model/save.py"", line 1007, in _build_meta_graph
    signatures = signature_serialization.find_function_to_export(
  File ""/home/chhokarpardeep/.local/lib/python3.8/site-packages/tensorflow/python/saved_model/signature_serialization.py"", line 85, in find_function_to_export
    concrete = _get_signature(function)
  File ""/home/chhokarpardeep/.local/lib/python3.8/site-packages/tensorflow/python/saved_model/signature_serialization.py"", line 42, in _get_signature
    function = function._get_concrete_function_garbage_collected()  # pylint: disable=protected-access
  File ""/home/chhokarpardeep/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py"", line 865, in _get_concrete_function_garbage_collected
    self._initialize(args, kwargs, add_initializers_to=initializers)
  File ""/home/chhokarpardeep/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py"", line 505, in _initialize
    self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access
  File ""/home/chhokarpardeep/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py"", line 2446, in _get_concrete_function_internal_garbage_collected
    graph_function, _, _ = self._maybe_define_function(args, kwargs)
  File ""/home/chhokarpardeep/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py"", line 2777, in _maybe_define_function
    graph_function = self._create_graph_function(args, kwargs)
  File ""/home/chhokarpardeep/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py"", line 2657, in _create_graph_function
    func_graph_module.func_graph_from_py_func(
  File ""/home/chhokarpardeep/.local/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py"", line 981, in func_graph_from_py_func
    func_outputs = python_func(*func_args, **func_kwargs)
  File ""/home/chhokarpardeep/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py"", line 441, in wrapped_fn
    return weak_wrapped_fn().__wrapped__(*args, **kwds)
  File ""/home/chhokarpardeep/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py"", line 3299, in bound_method_wrapper
    return wrapped_fn(*args, **kwargs)
  File ""/home/chhokarpardeep/.local/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py"", line 968, in wrapper
    raise e.ag_error_metadata.to_exception(e)
TypeError: in user code:

    models/research/delf/delf/python/training/model/export_model.py:73 ExtractFeatures  *
        extracted_features = export_model_utils.ExtractLocalFeatures(
    /mnt/d/models/research/delf/delf/python/training/model/export_model_utils.py:167 ExtractLocalFeatures  *
        final_boxes = box_list_ops.non_max_suppression(feature_boxes, iou,
    /home/chhokarpardeep/.local/lib/python3.8/site-packages/object_detection/core/box_list_ops.py:739 non_max_suppression  *
        with tf.name_scope(scope, 'NonMaxSuppression'):

    TypeError: __init__() takes 2 positional arguments but 3 were given

<!--
As per our GitHub Policy (https://github.com/tensorflow/models/blob/master/ISSUES.md), we only address code bugs, documentation issues, and feature requests on GitHub.

We will automatically close questions and help related issues.

Please go to Stack Overflow (http://stackoverflow.com/questions/tagged/tensorflow-model-garden) for questions and help.

-->
",chhokarpardeep,b'models:research type:support',2020-07-30T07:35:59Z,2020-07-31T20:25:20Z,,,,,,,
9007,Fix notebook URL,"There's an extraneous `colab_tutorials/` in there.

# Description

Just a simple typo fix.

## Type of change

- [ ] Bug fix (non-breaking change which fixes an issue)
- [X] Documentation update
- [ ] TensorFlow 2 migration
- [ ] New feature (non-breaking change which adds functionality)
- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)
- [ ] A new research paper code implementation
- [ ] Other (Specify)

## Tests

N/A

**Test Configuration**:

## Checklist

- [X] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).
- [X] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).
- [X] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).
- [X] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.
- [X] I have commented my code, particularly in hard-to-understand areas.
- [X] I have made corresponding changes to the documentation.
- [X] My changes generate no new warnings.
- [X] I have added tests that prove my fix is effective or that my feature works.
",mgalgs,b'cla: yes ready to pull',2020-07-29T21:49:52Z,2020-08-02T21:50:39Z,,,,,,,
9003,DELF GLDv2 training with tpu error,"Hi,  i am training delf follow [this ](https://github.com/tensorflow/models/tree/master/research/delf/delf/python/training) tutorial.
it works well on gpu, i switch to tpu for speed up training by following code.
```bash
!python3 /content/models/research/delf/delf/python/training/train.py \
  --train_file_pattern=gs://xxx/train* \
  --validation_file_pattern=gs://xxx/validation* \
  --imagenet_checkpoint=gs://xxx/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5 \
  --dataset_version=gld_v2_clean \
  --batch_size=256 \
  --logdir=gs://save_bucket 
```
and change in train.py
```Python
#   strategy = tf.distribute.MirroredStrategy()
#   logging.info('Number of devices: %d', strategy.num_replicas_in_sync)
#   if FLAGS.debug:
#     print('Number of devices:', strategy.num_replicas_in_sync)
  print(""connecting to TPU..."")
  tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection
  print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])
  tf.config.experimental_connect_to_cluster(tpu)
  tf.tpu.experimental.initialize_tpu_system(tpu)
  strategy = tf.distribute.experimental.TPUStrategy(tpu)
```
got these error, i am new to tensorflow and tpu,  please give some advice  ^_^ .
``` bash
Traceback (most recent call last):
  File ""/content/models/research/delf/delf/python/training/train.py"", line 482, in <module>
    app.run(main)
  File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""/content/models/research/delf/delf/python/training/train.py"", line 410, in main
    'loss/desc/crossentropy', desc_dist_loss, step=global_step)
  File ""/usr/local/lib/python3.6/dist-packages/tensorboard/plugins/scalar/summary_v2.py"", line 63, in scalar
    tf.debugging.assert_scalar(data)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/check_ops.py"", line 2096, in assert_scalar_v2
    assert_scalar(tensor=tensor, message=message, name=name)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/check_ops.py"", line 2122, in assert_scalar
    shape = tensor.get_shape()
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py"", line 1073, in get_shape
    return self.shape
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py"", line 1067, in shape
    six.raise_from(core._status_to_exception(e.code, e.message), None)
  File ""<string>"", line 3, in raise_from
tensorflow.python.framework.errors_impl.InternalError: RET_CHECK failure (learning/brain/google/xla/distributed_tpu_rewrite_pass.cc:1256) arg_shape.handle_type != DT_INVALID 
2020-07-29 15:49:57.433326: W ./tensorflow/core/distributed_runtime/eager/destroy_tensor_handle_node.h:58] Ignoring an error encountered when deleting remote tensors handles: Invalid argument: Unable to find the relevant tensor remote_handle: Op ID: 32935, Output num: 0
Additional GRPC error information:
{""created"":""@1596037797.418826461"",""description"":""Error received from peer ipv4:10.76.245.42:8470"",""file"":""external/com_github_grpc_grpc/src/core/lib/surface/call.cc"",""file_line"":1056,""grpc_message"":""Unable to find the relevant tensor remote_handle: Op ID: 32935, Output num: 0"",""grpc_status"":3}
```",feiwofeifeixiaowo,b'models:research',2020-07-29T16:11:24Z,2020-08-16T15:19:18Z,,,,,,,
9001,convert pb to tflite,"i trained ssd_mobilenet_v3_large_coco_2020_01_14 model. and it worked.
then i convert (saved_model.pb | saved_model.pbtxt) to tflite file.
using 3 ways: 
```
toco --saved_model_dir=saved_model --output_file=tflite/tflite_mobile.tflite --input_shapes=1,320,320,3 --output_arrays='TFLite_Detection_PostProcess','TFLite_Detection_PostProcess:1','TFLite_Detection_PostProcess:2','TFLite_Detection_PostProcess:3' --inference_type=FLOAT --allow_custom_ops
```

```
!tflite_convert --saved_model_dir=inference_graph/saved_model --output_file=detect.tflite --output_format=TFLITE --input_shapes=1,320,320,3 --input_arrays=normalized_input_image_tensor output_arrays='TFLite_Detection_PostProcess','TFLite_Detection_PostProcess:1','TFLite_Detection_PostProcess:2','TFLite_Detection_PostProcess:3' --inference_type=QUANTIZED_UINT8 --enable_v1_converter --mean_values=128 --std_dev_values=127 --change_concat_input_ranges=false --allow_custom_ops
```
```
converter = tf.lite.TFLiteConverter.from_saved_model(""saved_model"")
tflite_model = converter.convert()
open(""converted_model.tflite"", ""wb"").write(tflite_model)
```

but get errors:
```
RuntimeError: MetaGraphDef associated with tags {'serve'} could not be found in SavedModel. To inspect available tag-sets in the SavedModel, please use the SavedModel CLI: `saved_model_cli`
available_tags: [set()]
```
```
ValueError: Invalid tensors 'normalized_input_image_tensor' were found
```
```
None is only supported in the 1st dimension. Tensor 'image_tensor' has invalid shape '[None, None, None, 3]'.
```

please help",sajjadaemmi,b'models:research type:bug',2020-07-29T12:31:12Z,2020-08-10T09:48:36Z,,,,,,,
8999,Eval doesn't work in TF2 OD API when batch_size != 1,"# Prerequisites


## 1. The entire URL of the file you are using

https://github.com/tensorflow/models/blob/master/research/object_detection/model_main_tf2.py

## 2. Describe the bug

Performing evaluation using `batch_size: 1` works fine using `efficientdet_d0_coco17_tpu-32` model. When I change `batch_size` to some other number, I get the error that is c/p in ""Additional context"".

## 3. Steps to reproduce

Try evaluating the  `efficientdet_d0_coco17_tpu-32` model using `batch_size: 8`.

## 4. Expected behavior

Eval should work when `batch_size` is changed.

## 5. Additional context

> Traceback (most recent call last):
  File ""model_main_tf2.py"", line 119, in <module>
    tf.compat.v1.app.run()
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""model_main_tf2.py"", line 94, in main
    wait_interval=300, timeout=FLAGS.eval_timeout)
  File ""/usr/local/lib/python3.6/dist-packages/object_detection/model_lib_v2.py"", line 976, in eval_continuously
    global_step=global_step)
  File ""/usr/local/lib/python3.6/dist-packages/object_detection/model_lib_v2.py"", line 783, in eager_eval_loop
    eval_dict, losses_dict, class_agnostic = compute_eval_dict(features, labels)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py"", line 780, in __call__
    result = self._call(*args, **kwds)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py"", line 840, in _call
    return self._stateless_fn(*args, **kwds)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py"", line 2829, in __call__
    return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py"", line 1848, in _filtered_call
    cancellation_manager=cancellation_manager)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py"", line 1924, in _call_flat
    ctx, args, cancellation_manager=cancellation_manager))
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py"", line 550, in call
    ctx=ctx)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py"", line 60, in quick_execute
    inputs, attrs, num_outputs)
tensorflow.python.framework.errors_impl.InvalidArgumentError: 2 root error(s) found.
  (0) Invalid argument:  Shapes of all inputs must match: values[0].shape = [10] != values[1].shape = [1]
         [[node stack_32 (defined at /usr/local/lib/python3.6/dist-packages/object_detection/model_lib.py:153) ]]
         [[Postprocessor/BatchMultiClassNonMaxSuppression/MultiClassNonMaxSuppression_3/Reshape_86/_952]]
  (1) Invalid argument:  Shapes of all inputs must match: values[0].shape = [10] != values[1].shape = [1]
         [[node stack_32 (defined at /usr/local/lib/python3.6/dist-packages/object_detection/model_lib.py:153) ]]
0 successful operations.
0 derived errors ignored. [Op:__inference_compute_eval_dict_78603]
> 
> 
> Errors may have originated from an input operation.
> Input Source operations connected to node stack_32:
>  Slice_5 (defined at /usr/local/lib/python3.6/dist-packages/object_detection/model_lib.py:265)
> 
> Input Source operations connected to node stack_32:
>  Slice_5 (defined at /usr/local/lib/python3.6/dist-packages/object_detection/model_lib.py:265)
> 
> Function call stack:
> compute_eval_dict -> compute_eval_dict



## 6. System information

== check python ===================================================
python version: 3.6.9
python branch: 
python build version: ('default', 'Apr 18 2020 01:56:04')
python compiler version: GCC 8.4.0
python implementation: CPython


== check os platform ===============================================
os: Linux
os kernel version: #123-Ubuntu SMP Sat Jul 4 02:03:15 UTC 2020
os release version: 4.4.0-1111-aws
os platform: Linux-4.4.0-1111-aws-x86_64-with-Ubuntu-18.04-bionic
linux distribution: ('Ubuntu', '18.04', 'bionic')
linux os distribution: ('Ubuntu', '18.04', 'bionic')
mac version: ('', ('', '', ''), '')
uname: uname_result(system='Linux', node='e456acec5a2f', release='4.4.0-1111-aws', version='#123-Ubuntu SMP Sat Jul 4 02:03:15 UTC 2020', machine='x86_64', processor='x86_64')
architecture: ('64bit', '')
machine: x86_64


== are we in docker =============================================
Yes

== compiler =====================================================
c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
Copyright (C) 2017 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.


== check pips ===================================================
numpy                         1.18.4
protobuf                      3.11.3
tensorflow                    2.3.0
tensorflow-addons             0.10.0
tensorflow-datasets           3.2.1
tensorflow-estimator          2.3.0
tensorflow-gpu                2.2.0
tensorflow-hub                0.8.0
tensorflow-metadata           0.22.2
tensorflow-model-optimization 0.4.0

== check for virtualenv =========================================
False

== tensorflow import ============================================
tf.version.VERSION = 2.3.0
tf.version.GIT_VERSION = v2.3.0-rc2-23-gb36436b087
tf.version.COMPILER_VERSION = 7.3.1 20180303

== env ==========================================================
LD_LIBRARY_PATH /usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64
DYLD_LIBRARY_PATH is unset

== nvidia-smi ===================================================
Wed Jul 29 11:12:20 2020       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 410.104      Driver Version: 410.104      CUDA Version: 10.1     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  Tesla K80           On   | 00000000:00:1E.0 Off |                    0 |
| N/A   45C    P8    26W / 149W |      0MiB / 11441MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID   Type   Process name                             Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+

== cuda libs  ===================================================
/usr/local/cuda-10.1/targets/x86_64-linux/lib/libcudart.so.10.1.243
/usr/local/cuda-10.1/targets/x86_64-linux/lib/libcudart_static.a

== tensorflow installed from info ==================
Name: tensorflow
Version: 2.3.0
Summary: TensorFlow is an open source machine learning framework for everyone.
Home-page: https://www.tensorflow.org/
Author-email: packages@tensorflow.org
License: Apache 2.0
Location: /usr/local/lib/python3.6/dist-packages
Required-by: tf-models-official

== python version  ==============================================
(major, minor, micro, releaselevel, serial)
(3, 6, 9, 'final', 0)

== bazel version  ===============================================




",qraleq,b'models:research stat:awaiting response type:support',2020-07-29T11:15:55Z,2020-09-19T08:23:14Z,,,,,,,
8994,'tensorflow.keras.activations' has no attribute 'gelu',"I set up a new clean conda environment with python 3.6. 

I installed tf-nightly, tensorflow-addons and tensorflow_hup as requested. But I cannot run the examples (but with a external trained BERT model for my language) and get the following:

```

Traceback (most recent call last):
  File ""run_classifier.py"", line 506, in <module>
    app.run(main)
  File ""C:\Users\\Anaconda3\envs\tf-nightly\lib\site-packages\absl\app.py"", line 299, in run
    _run_main(main, args)
  File ""C:\Users\\Anaconda3\envs\tf-nightly\lib\site-packages\absl\app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""run_classifier.py"", line 499, in main
    custom_main(custom_callbacks=None, custom_metrics=None)
  File ""run_classifier.py"", line 495, in custom_main
    custom_metrics=custom_metrics)
  File ""run_classifier.py"", line 410, in run_bert
    custom_metrics=custom_metrics)
  File ""run_classifier.py"", line 199, in run_bert_classifier
    custom_callbacks=custom_callbacks)
  File ""run_classifier.py"", line 221, in run_keras_compile_fit
    bert_model, sub_model = model_fn()
  File ""run_classifier.py"", line 149, in _get_classifier_model
    hub_module_trainable=FLAGS.hub_module_trainable))
  File ""C:\Users\\Corona_Bot\models-master\official\nlp\bert\bert_models.py"", line 344, in classifier_model
    bert_config, max_seq_length, output_range=1)
  File ""C:\Users\\Anaconda3\envs\tf-nightly\lib\site-packages\gin\config.py"", line 1078, in gin_wrapper
    utils.augment_exception_message_and_reraise(e, err_str)
  File ""C:\Users\\Anaconda3\envs\tf-nightly\lib\site-packages\gin\utils.py"", line 49, in augment_exception_message_and_reraise
    six.raise_from(proxy.with_traceback(exception.__traceback__), None)
  File ""<string>"", line 3, in raise_from
  File ""C:\Users\\Anaconda3\envs\tf-nightly\lib\site-packages\gin\config.py"", line 1055, in gin_wrapper
    return fn(*new_args, **new_kwargs)
  File ""C:\Users\\Corona_Bot\models-master\official\nlp\bert\bert_models.py"", line 175, in get_transformer_encoder
    return networks.TransformerEncoder(**kwargs)
  File ""C:\Users\\Corona_Bot\models-master\official\nlp\modeling\networks\transformer_encoder.py"", line 199, in __init__
    data = layer([data, attention_mask])
  File ""C:\Users\\Anaconda3\envs\tf-nightly\lib\site-packages\tensorflow\python\keras\engine\base_layer.py"", line 926, in __call__
    input_list)
  File ""C:\Users\\Anaconda3\envs\tf-nightly\lib\site-packages\tensorflow\python\keras\engine\base_layer.py"", line 1117, in _functional_construction_call
    outputs = call_fn(cast_inputs, *args, **kwargs)
  File ""C:\Users\\Anaconda3\envs\tf-nightly\lib\site-packages\tensorflow\python\autograph\impl\api.py"", line 667, in wrapper
    raise e.ag_error_metadata.to_exception(e)
AttributeError: in user code:

    C:\Users\\Corona_Bot\models-master\official\nlp\modeling\layers\transformer.py:214 call  *
        intermediate_output = self._intermediate_activation_layer(
    C:\Users\\Anaconda3\envs\tf-nightly\lib\site-packages\tensorflow\python\keras\engine\base_layer.py:926 __call__  **
        input_list)
    C:\Users\\Anaconda3\envs\tf-nightly\lib\site-packages\tensorflow\python\keras\engine\base_layer.py:1117 _functional_construction_call
        outputs = call_fn(cast_inputs, *args, **kwargs)
    C:\Users\\Anaconda3\envs\tf-nightly\lib\site-packages\tensorflow\python\keras\layers\core.py:427 call
        return self.activation(inputs)
    C:\Users\\Corona_Bot\models-master\official\modeling\activations\gelu.py:32 gelu
        return tf.keras.activations.gelu(x, approximate=True)

    AttributeError: module 'tensorflow.keras.activations' has no attribute 'gelu'

  In call to configurable 'get_transformer_encoder' (<function get_transformer_encoder at 0x00000274B249BB70>)
```",datistiquo,b'models:official type:bug',2020-07-29T07:57:44Z,2020-07-31T03:50:32Z,,,,,,,
8987, CODE_OF_CONDUCT,"# Description

> :memo: Please include a summary of the change. 
>  
> * Please also include relevant motivation and context.  
> * List any dependencies that are required for this change.  

## Type of change

For a new feature or function, please create an issue first to discuss it
with us before submitting a pull request.

Note: Please delete options that are not relevant.

- [ ] Bug fix (non-breaking change which fixes an issue)
- [ ] Documentation update
- [ ] TensorFlow 2 migration
- [ ] New feature (non-breaking change which adds functionality)
- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)
- [ ] A new research paper code implementation
- [ ] Other (Specify)

## Tests

> :memo: Please describe the tests that you ran to verify your changes.
>  
> * Provide instructions so we can reproduce.  
> * Please also list any relevant details for your test configuration.  

**Test Configuration**:

## Checklist

- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).
- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).
- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).
- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.
- [ ] I have commented my code, particularly in hard-to-understand areas.
- [ ] I have made corresponding changes to the documentation.
- [ ] My changes generate no new warnings.
- [ ] I have added tests that prove my fix is effective or that my feature works.
",gaushikmr,b'cla: no',2020-07-28T16:15:22Z,2020-07-28T16:16:16Z,,,,,,,
8985,fix links for research/object_detection/colab_tutorials/object_detection_tutorial.ipynb,"# Description

> :memo: fix links for research/object_detection/colab_tutorials/object_detection_tutorial.ipynb  

## Type of change

For a new feature or function, please create an issue first to discuss it
with us before submitting a pull request.

Note: Please delete options that are not relevant.

- [x] Bug fix (non-breaking change which fixes an issue)
- [ ] Documentation update
- [ ] TensorFlow 2 migration
- [ ] New feature (non-breaking change which adds functionality)
- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)
- [ ] A new research paper code implementation
- [ ] Other (Specify)

## Tests

> :memo: Please describe the tests that you ran to verify your changes.
>  
> * Provide instructions so we can reproduce.  
> * Please also list any relevant details for your test configuration.  

**Test Configuration**:

## Checklist

- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).
- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).
- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).
- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.
- [x] I have commented my code, particularly in hard-to-understand areas.
- [x] I have made corresponding changes to the documentation.
- [x] My changes generate no new warnings.
- [x] I have added tests that prove my fix is effective or that my feature works.
",syiming,b'cla: yes',2020-07-28T14:19:02Z,2020-08-02T20:43:29Z,,,,,,,
8984,frozen inference graphs tf 1 documentation update,"# Description

> :memo: Update documentation for research/object_detection/g3doc/tf1_detection_zoo.md
>  
> * frozen inference graphs are generated using the [v1.12.0](https://github.com/tensorflow/tensorflow/tree/v1.12.0) release
    version of TensorFlow
> * remove “we do not guarantee that these will work with other versions”

## Type of change

For a new feature or function, please create an issue first to discuss it
with us before submitting a pull request.

Note: Please delete options that are not relevant.

- [ ] Bug fix (non-breaking change which fixes an issue)
- [x] Documentation update
- [ ] TensorFlow 2 migration
- [ ] New feature (non-breaking change which adds functionality)
- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)
- [ ] A new research paper code implementation
- [ ] Other (Specify)

## Tests

> :memo: Please describe the tests that you ran to verify your changes.
>  
> * Provide instructions so we can reproduce.  
> * Please also list any relevant details for your test configuration.  

**Test Configuration**:

## Checklist

- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).
- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).
- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).
- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.
- [x] I have commented my code, particularly in hard-to-understand areas.
- [x] I have made corresponding changes to the documentation.
- [x] My changes generate no new warnings.
- [x] I have added tests that prove my fix is effective or that my feature works.
",syiming,b'cla: yes ready to pull',2020-07-28T13:46:07Z,2020-08-08T22:42:02Z,,,,,,,
8979,Change NCF eval_input_dataset not to use experimental_distribute_dataset.,"PiperOrigin-RevId: 322844988

# Description

This is [a cherry pick](https://github.com/tensorflow/models/commit/a829e6480d88bc19ac6f25fe6cbc3da702eb1bfa) from a master branch.

Changed eval_input_dataset not to use experimental_distribute_dataset as it was failing on TPU pods

## Type of change


-  Bug fix (non-breaking change which fixes an issue)

## Tests

Added to our tests for TPU and GPUs.


## Checklist

A [cherry pick](https://github.com/tensorflow/models/commit/a829e6480d88bc19ac6f25fe6cbc3da702eb1bfa) from master branch.
",gagika,b'cla: yes',2020-07-27T21:13:13Z,2020-07-27T23:07:35Z,,,,,,,
8976,tensorflow.python.framework.errors_impl.NotFoundError: /content/train/cells_label_map.pbtxt; No such file or directory,"# Prerequisites

Please answer the following questions for yourself before submitting an issue.

- [x] I am using the latest TensorFlow Model Garden release and TensorFlow 2.
- [x] I am reporting the issue to the correct repository. (Model Garden official or research directory)
- [x] I checked to make sure that this issue has not been filed already.

## 1. The entire URL of the file you are using

https://github.com/tensorflow/models/tree/master/official/...

## 2. Describe the bug

A clear and concise description of what the bug is.

## 3. Steps to reproduce

Steps to reproduce the behavior.

## 4. Expected behavior

A clear and concise description of what you expected to happen.

## 5. Additional context

Include any logs that would be helpful to diagnose the problem.

## 6. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device name if the issue happens on a mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below):
- Python version:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

<!-- 
Collect system information using our environment capture script.
https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can also obtain the TensorFlow version with:

1. TensorFlow 1.0
`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

2. TensorFlow 2.0
`python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`
-->
",haivamsieee,b'stat:awaiting response type:support',2020-07-27T18:14:20Z,2020-09-10T06:46:45Z,,,,,,,
8975,NotFoundError: /content/train/cells_label_map.pbtxt; No such file or directory,"# Prerequisites

Please answer the following questions for yourself before submitting an issue.

- [x] I am using the latest TensorFlow Model Garden release and TensorFlow 2.
- [x] I am reporting the issue to the correct repository. (Model Garden official or research directory)
- [x] I checked to make sure that this issue has not been filed already.

## 1. The entire URL of the file you are using

https://github.com/tensorflow/models/tree/master/official/...

## 2. Describe the bug

A clear and concise description of what the bug is.

## 3. Steps to reproduce

Steps to reproduce the behavior.

## 4. Expected behavior

A clear and concise description of what you expected to happen.

## 5. Additional context

Include any logs that would be helpful to diagnose the problem.

## 6. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device name if the issue happens on a mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below):
- Python version:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

<!-- 
Collect system information using our environment capture script.
https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can also obtain the TensorFlow version with:

1. TensorFlow 1.0
`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

2. TensorFlow 2.0
`python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`
-->
",haivamsieee,b'models:official stat:awaiting response type:bug',2020-07-27T17:41:29Z,2020-09-08T07:24:34Z,,,,,,,
8973,Add Mobilenet v3 Edge TPU implementation,"- Add Mobilenet v3 Edge TPU implementation
- Fix a few bugs",luotigerlsx,b'cla: yes help wanted:paper implementation',2020-07-27T15:35:16Z,2020-07-28T04:22:22Z,,,,,,,
8970,deeplab tflite model can not run a long time,"# Prerequisites

Please answer the following questions for yourself before submitting an issue.

- [ ] I am using the tensorflow-lite-1.15.0.aar for Android Device
- [ ] I am reporting the issue to the correct repository. (Model Garden official or research directory)
- [ ] I checked to make sure that this issue has not been filed already.

## 1. The entire URL of the file you are using

http://download.tensorflow.org/models/object_detection/ssdlite_mobilenet_v2_coco_2018_05_09.tar.gz

## 2. Describe the bug

A clear and concise description of what the bug is.

## 3. Steps to reproduce

Steps to reproduce the behavior.

## 4. Expected behavior

A clear and concise description of what you expected to happen.

## 5. Additional context

Include any logs that would be helpful to diagnose the problem.

## 6. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device name if the issue happens on a mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below):
- Python version:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

<!-- 
Collect system information using our environment capture script.
https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can also obtain the TensorFlow version with:

1. TensorFlow 1.0
`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

2. TensorFlow 2.0
`python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`
-->
",WindowsDriver,b'models:official type:bug',2020-07-27T05:23:58Z,2020-07-27T05:25:24Z,,,,,,,
8967,TF2 Object Detect API with CenterNet Resnet101 V1 FPN 512x512 ,"# Prerequisites

Please answer the following questions for yourself before submitting an issue.

- [Y] I am using the latest TensorFlow Model Garden release and TensorFlow 2.
- [Y] I am reporting the issue to the correct repository. (Model Garden official or research directory)
- [Y] I checked to make sure that this issue has not been filed already.

## 1. The entire URL of the file you are using

https://github.com/tensorflow/models/tree/master/official/...

## 2. Describe the bug

Training on a custom dataset using CenterNet Resnet101 V1 FPN 512x512 model has issues.  The checkpoint and pipeline.config were downloaded from the zoo and slightly modified to suit the custom dataset (e.g. number of classes changed).  The outcome depends on the fine_tune_checkpoint_type setting in the pipeline.config file:

fine_tune_checkpoint: ""centernet_resnet101_v1_fpn_512x512_coco17_tpu-8/checkpoint/ckpt-0

i. fine_tune_checkpoint_type: ""fine_tune""
   -runs successfully


ii. fine_tune_checkpoint_type: ""detection""
   -fails with the following error:

File ""tf2odapi/models/research/object_detection/meta_architectures/center_net_meta_arch.py"", line 2769, in restore_from_objects
    return {'feature_extractor': self._feature_extractor.get_model()}
AttributeError: 'CenterNetResnetV1FpnFeatureExtractor' object has no attribute 'get_model'


iii. fine_tune_checkpoint_type: ""classification""
   -gives a long string of warning saying it can't resolve model objects, then stops without giving an error:

...
WARNING:tensorflow:Unresolved object in checkpoint: (root).model._prediction_head_dict.box/offset.0.layer_with_weights-1.kernel
W0725 09:28:17.464377 140311093167936 util.py:143] Unresolved object in checkpoint: (root).model._prediction_head_dict.box/offset.0.layer_with_weights-1.kernel
WARNING:tensorflow:Unresolved object in checkpoint: (root).model._prediction_head_dict.box/offset.0.layer_with_weights-1.bias
W0725 09:28:17.464425 140311093167936 util.py:143] Unresolved object in checkpoint: (root).model._prediction_head_dict.box/offset.0.layer_with_weights-1.bias
WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.
W0725 09:28:17.464480 140311093167936 util.py:151] A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.


## 3. Steps to reproduce

Involves a custom dataset, so it can't be replicated here.

## 4. Expected behavior

Training should run smoothly for all three settings of fine_tune_checkpoint_type.

## 5. Additional context

Include any logs that would be helpful to diagnose the problem.

## 6. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- Mobile device name if the issue happens on a mobile device: 
- TensorFlow installed from (source or binary): pip
- TensorFlow version (use command below): 2.2.0
- Python version: 3.8
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 10.1, 7.6.5
- GPU model and memory: GE Force RTX 2080 11GB

<!-- 
Collect system information using our environment capture script.
https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can also obtain the TensorFlow version with:

1. TensorFlow 1.0
`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

2. TensorFlow 2.0
`python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`
-->
",mm7721,b'models:research type:bug',2020-07-25T16:32:06Z,2020-08-11T12:22:36Z,,,,,,,
8965,AttributeError: module 'tensorflow_core.compat.v1' has no attribute 'contrib',"# Prerequisites

Please answer the following questions for yourself before submitting an issue.

- [ ] I am using the latest TensorFlow Model Garden release and TensorFlow 2.
- [ ] I am reporting the issue to the correct repository. (Model Garden official or research directory)
- [ ] I checked to make sure that this issue has not been filed already.

## 1. The entire URL of the file you are using

https://github.com/tensorflow/models/tree/master/official/...

## 2. Describe the bug

2020-07-25 10:07:11.122491: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll
WARNING:tensorflow:From C:\Users\dw\Anaconda3\envs\TF2.2\lib\site-packages\tensorflow_core\python\compat\v2_compat.py:88: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.
Instructions for updating:
non-resource variables are not supported in the long term
Traceback (most recent call last):
  File ""model_main_tf2.py"", line 31, in <module>
    from object_detection import model_lib_v2
  File ""D:\tf_train\models\research\object_detection\model_lib_v2.py"", line 27, in <module>
    from object_detection import eval_util
  File ""D:\tf_train\models\research\object_detection\eval_util.py"", line 36, in <module>
    slim = tf.contrib.slim
AttributeError: module 'tensorflow_core.compat.v1' has no attribute 'contrib'

## 3. Steps to reproduce

python model_main_tf2.py --model_dir=training --pipeline_config_path=training/center_net_hourglass104_1024x1024_coco17_tpu-32.config --alsologtostderr

## 4. Expected behavior

Start training the model

## 5. Additional context

(TF2.1) D:\tf_train\workspaces\my_training_demo1>python model_main_tf2.py --model_dir=training --pipeline_config_path=training/center_net_hourglass104_1024x1024_coco17_tpu-32.config --alsologtostderr
2020-07-25 10:13:58.091313: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll
WARNING:tensorflow:From C:\Users\dw\Anaconda3\envs\TF2.2\lib\site-packages\tensorflow_core\python\compat\v2_compat.py:88: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.
Instructions for updating:
non-resource variables are not supported in the long term
Traceback (most recent call last):
  File ""model_main_tf2.py"", line 31, in <module>
    from object_detection import model_lib_v2
  File ""D:\tf_train\models\research\object_detection\model_lib_v2.py"", line 27, in <module>
    from object_detection import eval_util
  File ""D:\tf_train\models\research\object_detection\eval_util.py"", line 36, in <module>
    slim = tf.contrib.slim
AttributeError: module 'tensorflow_core.compat.v1' has no attribute 'contrib'

## 6. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Windows 10 professional workstation
- TensorFlow installed from (source or binary)：anaconda
- TensorFlow version (use command below):tensorflow-gpu=2.1
- Python version:3.6.10
- CUDA/cuDNN version: cudatoolkit=10.1  cudnn=7.6.5
- GPU model and memory: GTX2070,  39.8G

<!-- 
Collect system information using our environment capture script.
https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can also obtain the TensorFlow version with:

1. TensorFlow 1.0
`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

2. TensorFlow 2.0
`python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`
-->unknown 2.1.0
",dreamitpossible1,b'models:research stat:awaiting response type:bug',2020-07-25T02:26:07Z,2020-09-19T20:41:48Z,,,,,,,
8962,"Identity box coder, similarity calculator, target assigner","# Description

> :memo: Please include a summary of the change. 
>  
> * Please also include relevant motivation and context.  
> * List any dependencies that are required for this change.  

## Type of change

For a new feature or function, please create an issue first to discuss it
with us before submitting a pull request.

Note: Please delete options that are not relevant.

- [ ] Bug fix (non-breaking change which fixes an issue)
- [ ] Documentation update
- [ ] TensorFlow 2 migration
- [x] New feature (non-breaking change which adds functionality)
- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)
- [ ] A new research paper code implementation
- [ ] Other (Specify)

## Tests

> :memo: Please describe the tests that you ran to verify your changes.
>  
> * Provide instructions so we can reproduce.  
> * Please also list any relevant details for your test configuration.  

**Test Configuration**:

## Checklist

- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).
- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).
- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).
- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.
- [ ] I have commented my code, particularly in hard-to-understand areas.
- [ ] I have made corresponding changes to the documentation.
- [ ] My changes generate no new warnings.
- [ ] I have added tests that prove my fix is effective or that my feature works.
",kmindspark,b'cla: yes ready to pull',2020-07-24T20:46:36Z,2020-09-15T16:26:49Z,,,,,,,
8961,Fixed typos,"> :memo: Fixed typos in anchor.py

## Type of change
- [ ] Bug fix (non-breaking change which fixes an issue)
- [x] Documentation update
- [ ] TensorFlow 2 migration
- [ ] New feature (non-breaking change which adds functionality)
- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)
- [ ] A new research paper code implementation
- [ ] Other (Specify)

## Checklist

- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).
- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).
- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).
- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.
- [ ] I have commented my code, particularly in hard-to-understand areas.
- [x] I have made corresponding changes to the documentation.
- [x] My changes generate no new warnings.
- [x] I have added tests that prove my fix is effective or that my feature works.
",srihari-humbarwadi,b'cla: yes ready to pull',2020-07-24T15:42:53Z,2020-07-28T04:26:40Z,,,,,,,
8957,Predictions  for different images are same for  the model which is loaded from frozen_inference_graph.,"<!--
As per our GitHub Policy (https://github.com/tensorflow/models/blob/master/ISSUES.md), we only address code bugs, documentation issues, and feature requests on GitHub.

We will automatically close questions and help related issues.

Please go to Stack Overflow (http://stackoverflow.com/questions/tagged/tensorflow-model-garden) for questions and help.

-->
I trained an object detection model with ssd_mobilenet_v2_coco model with Guns images. I checked evaluation results in tensorboard predictions are good with 100% accuracy. But, after loading the frozen model I checked with few test images which are there in evaluation data. I am getting same score for all the test images, with same bounding box.
To refer the code please check the below coalb file.
https://colab.research.google.com/drive/1im-LRkW8OaGQMPvzztLUBa_E-3NaUyG2?usp=sharing

![download (1)](https://user-images.githubusercontent.com/20368402/88361716-99a98180-cd97-11ea-9961-373ceeef3a0b.png)
![download](https://user-images.githubusercontent.com/20368402/88361726-a037f900-cd97-11ea-9091-4d8a5572c005.png)
![download (2)](https://user-images.githubusercontent.com/20368402/88361705-8f878300-cd97-11ea-98b4-c237dca4505c.png)

Thanks in advance


",sumathi16,b'models:research stalled stat:awaiting response type:support',2020-07-24T05:02:06Z,2020-09-18T16:17:54Z,,,,,,,
8956,Some Error in models/official/nlp/transformer/,"# Prerequisites

Please answer the following questions for yourself before submitting an issue.

- [YES ] I am using the latest TensorFlow Model Garden release and TensorFlow 2.
- [YES ] I am reporting the issue to the correct repository. (Model Garden official or research directory)
- [YES] I checked to make sure that this issue has not been filed already.

## 1. The entire URL of the file you are using

https://github.com/tensorflow/models/tree/master/official/nlp/transformer/data_download.py

## 2. Describe the bug

**When !python3 data_download.py --data_dir=$DATA_DIR in Colab.
I get a Error:**

2020-07-24 01:51:24.447754: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
I0724 01:51:26.636575 140448915650432 data_download.py:375] Creating directory /tmp/translate_ende_raw
I0724 01:51:26.636913 140448915650432 data_download.py:375] Creating directory 
I0724 01:51:26.637027 140448915650432 data_download.py:385] Step 1/5: Downloading test data
I0724 01:51:26.637138 140448915650432 data_download.py:170] Downloading from https://storage.googleapis.com/tf-perf-public/official_transformer/test_data/newstest2014.tgz to newstest2014.tgz.
101% completed
I0724 01:51:27.189940 140448915650432 data_download.py:209] Extracting newstest2014.tgz.
Traceback (most recent call last):
  File ""data_download.py"", line 439, in <module>
    absl_app.run(main)
  File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""data_download.py"", line 386, in main
    get_raw_files(FLAGS.data_dir, _TEST_DATA_SOURCES)
  File ""data_download.py"", line 138, in get_raw_files
    raw_dir, d[""url""], d[""input""], d[""target""])
  File ""data_download.py"", line 221, in download_and_extract
    (url, path))
OSError: Download/extraction failed for url https://storage.googleapis.com/tf-perf-public/official_transformer/test_data/newstest2014.tgz to path 

## 3. Steps to reproduce

Steps to reproduce the behavior.
**Also in Colab:**
```
!git clone https://github.com/tensorflow/models.git
cd /content/models/
!pip3 install tf-nightly
!pip install tf-models-nightly
!pip3 install --user -r official/requirements.txt
import os
os.environ['PYTHONPATH'] += "":/content/models""
cd /content/models/official/nlp/transformer
# Export variables
!PARAM_SET=big
!DATA_DIR=$HOME/transformer/data
!MODEL_DIR=$HOME/transformer/model_$PARAM_SET
!VOCAB_FILE=$DATA_DIR/vocab.ende.32768
!python3 data_download.py --data_dir=$DATA_DIR
```

## 4. Expected behavior

I just want to normally run a Transormer example.

## 5. Additional context

No.

## 6. System information

Colab GPU environment.

",iimlearning,b'models:official stat:awaiting response type:bug',2020-07-24T02:09:59Z,2020-10-07T18:19:42Z,,,,,,,
8954,remove unused import within image_resizer.proto,"# Description

> :memo: remove unused import within image_resizer.proto
> fix warning: object_detection/protos/input_reader.proto:5:1: warning: Import object_detection/protos/image_resizer.proto is unused.

## Type of change

For a new feature or function, please create an issue first to discuss it
with us before submitting a pull request.

Note: Please delete options that are not relevant.

- [x] Bug fix (non-breaking change which fixes an issue)
- [ ] Documentation update
- [ ] TensorFlow 2 migration
- [ ] New feature (non-breaking change which adds functionality)
- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)
- [ ] A new research paper code implementation
- [ ] Other (Specify)

## Tests

> :memo: Please describe the tests that you ran to verify your changes.
>  
> * Provide instructions so we can reproduce.  
> * Please also list any relevant details for your test configuration.  

**Test Configuration**:

## Checklist

- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).
- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).
- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).
- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.
- [x] I have commented my code, particularly in hard-to-understand areas.
- [x] I have made corresponding changes to the documentation.
- [x] My changes generate no new warnings.
- [ ] I have added tests that prove my fix is effective or that my feature works.
",syiming,b'cla: yes',2020-07-24T00:38:04Z,2020-07-25T18:14:34Z,,,,,,,
8952,download_dataset.sh doesn't unpack the .tar files when downloading the GLDv2 Dataset.,"# Prerequisites
- [x] I am using the latest TensorFlow Model Garden release and TensorFlow 2.2.
- [x] I am reporting the issue to the correct repository. (Model Garden official or research directory)
- [x] I checked to make sure that this issue has not already been filed.

## 1. The entire URL of the file you are using

https://github.com/tensorflow/models/tree/master/research/delf/delf/python/training#prepare-the-data-for-training/download_dataset.sh

## 2. Describe the bug

I have downloaded the model exactly as the documentation and for some reason whenever the file tries to check the md5 checksums it says that they don't match and the files just stay there as .tar files instead of unpacking into neat little folders.  The only thing that I can think of that I have done differently is that I have installed the files to an external drive. (Maybe I need to give my computer certain permissions?)

I am using linux 20.04 with a Seagate external USB hard drive.
",Fateh-Aliyev,b'models:research type:bug',2020-07-23T22:00:47Z,2020-07-27T16:18:32Z,,,,,,,
8947,Not possible to train Object Detection 2.0 in Colab using TPU,"# Prerequisites

Please answer the following questions for yourself before submitting an issue.

- [x] I am using the latest TensorFlow Model Garden release and TensorFlow 2.
- [x] I am reporting the issue to the correct repository. (Model Garden official or research directory)
- [x] I checked to make sure that this issue has not already been filed.

## 1. The entire URL of the file you are using

https://github.com/tensorflow/models/tree/master/research/object_detection

## 2. Describe the bug

I'm familiar with the need to use gcs buckets for training data for colab TPUs. I have buckets setup to do this.
I'm trying to port my OD colab notebooks to tf2.0. I thought I'd try and use the TPUs available in Colab.

The issue is that the fine tuned checkpoint files in the config need to be on the local VM for the OD scripts to run - otherwise model_main_tf2.py will error almost immediately if a gs:// url is used. Changing the config location to a local VM drive will prevent this. However, soon afterwards, tensorflow will error when trying to access the checkpoint, saying that 'local storage' isn't implemented, which is the correct behavior since TPUs must use GCS buckets.

So I don't know how to have the config file point at both a local checkpoint and a gs:// resource. I'm assuming the same error will occur for the training/validation data tf records as well

## 3. Steps to reproduce
Create a colab
upload config files pointing to either local (colab drive) or gs:// locations for the fine tuning checkpoint.
run model_main_tf2.py with --use_tpu set to True

## 4. Expected behavior

TPU training should be possible somehow from colab?

## 5. Additional context

Error for gs:// content is 
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/py_checkpoint_reader.py"", line 95, in NewCheckpointReader
    return CheckpointReader(compat.as_bytes(filepattern))
RuntimeError: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for gs://MYBUCKET/checkpoint/ckpt-0
During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/content/models/research/object_detection/model_main_tf2.py"", line 106, in <module>
    tf.compat.v1.app.run()
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""/content/models/research/object_detection/model_main_tf2.py"", line 103, in main
    use_tpu=FLAGS.use_tpu)
  File ""/content/models/research/object_detection/model_lib_v2.py"", line 554, in train_loop
    unpad_groundtruth_tensors)
  File ""/content/models/research/object_detection/model_lib_v2.py"", line 335, in load_fine_tune_checkpoint
    if not is_object_based_checkpoint(checkpoint_path):
  File ""/content/models/research/object_detection/model_lib_v2.py"", line 298, in is_object_based_checkpoint
    var_names = [var[0] for var in tf.train.list_variables(checkpoint_path)]
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/checkpoint_utils.py"", line 98, in list_variables
    reader = load_checkpoint(ckpt_dir_or_file)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/checkpoint_utils.py"", line 67, in load_checkpoint
    return py_checkpoint_reader.NewCheckpointReader(filename)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/py_checkpoint_reader.py"", line 99, in NewCheckpointReader
    error_translator(e)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/py_checkpoint_reader.py"", line 35, in error_translator
    raise errors_impl.NotFoundError(None, None, error_message)

## 6. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Google Colab
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below): 2.2
- Python version: 3.6
",martinlyons,b'models:research stat:awaiting response type:bug',2020-07-23T05:38:04Z,2020-07-23T16:53:25Z,,,,,,,
8945,Local changes to tfrecords file,"# Description

> :memo: Please include a summary of the change. 
>  
> * Please also include relevant motivation and context.  
> * List any dependencies that are required for this change.  

## Type of change

For a new feature or function, please create an issue first to discuss it
with us before submitting a pull request.

Note: Please delete options that are not relevant.

- [ ] Bug fix (non-breaking change which fixes an issue)
- [ ] Documentation update
- [ ] TensorFlow 2 migration
- [ ] New feature (non-breaking change which adds functionality)
- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)
- [ ] A new research paper code implementation
- [ ] Other (Specify)

## Tests

> :memo: Please describe the tests that you ran to verify your changes.
>  
> * Provide instructions so we can reproduce.  
> * Please also list any relevant details for your test configuration.  

**Test Configuration**:

## Checklist

- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).
- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).
- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).
- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.
- [ ] I have commented my code, particularly in hard-to-understand areas.
- [ ] I have made corresponding changes to the documentation.
- [ ] My changes generate no new warnings.
- [ ] I have added tests that prove my fix is effective or that my feature works.
",kuldeepbrd1,b'cla: no',2020-07-23T02:05:39Z,2020-07-23T02:05:56Z,,,,,,,
8943,Hungarian Matcher,"# Hungarian Matcher in TF 2, for Detection Transformer

> :memo: Please include a summary of the change. 
>  
> * Please also include relevant motivation and context.  
> * List any dependencies that are required for this change.  

## Type of change

For a new feature or function, please create an issue first to discuss it
with us before submitting a pull request.

Note: Please delete options that are not relevant.

- [ ] Bug fix (non-breaking change which fixes an issue)
- [ ] Documentation update
- [ ] TensorFlow 2 migration
- [x] New feature (non-breaking change which adds functionality)
- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)
- [x] A new research paper code implementation
- [ ] Other (Specify)

## Tests

> :memo: Please describe the tests that you ran to verify your changes.
>  Used a very similar set of tests to the other matchers.
> * Provide instructions so we can reproduce.  
> * Please also list any relevant details for your test configuration.  

**Test Configuration**:

## Checklist

- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).
- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).
- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).
- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.
- [x] I have commented my code, particularly in hard-to-understand areas.
- [x] I have made corresponding changes to the documentation.
- [x] My changes generate no new warnings.
- [x] I have added tests that prove my fix is effective or that my feature works.
",kmindspark,b'cla: yes ready to pull',2020-07-23T00:22:44Z,2020-08-03T16:54:34Z,,,,,,,
8942,"running model/research/object_detection/builders/model_builder_tf2_test.py yields error "" tensorflow has not attribute contrib""","# Prerequisites

Please answer the following questions for yourself before submitting an issue.

- [ x] I am using the latest TensorFlow Model Garden release and TensorFlow 2.
- [ x] I am reporting the issue to the correct repository. (Model Garden official or research directory)
- [ x] I checked to make sure that this issue has not already been filed.

## 1. The entire URL of the file you are using

https://github.com/tensorflow/models/tree/master/research/object_detection/builders/model_builder_tf2_test.py

## 2. Describe the bug

trying to run model_builder.py file using 
`python model_builder_tf2_test.py`

and get the following error:
`Traceback (most recent call last):
  File ""model_builder_tf2_test.py"", line 24, in <module>
    from object_detection.builders import model_builder
  File ""C:\tensorflow\models\research\object_detection\builders\model_builder.py"", line 19, in <module>
    from object_detection.builders import box_predictor_builder
  File ""C:\tensorflow\models\research\object_detection\builders\box_predictor_builder.py"", line 18, in <module>
    from object_detection.core import box_predictor
  File ""C:\tensorflow\models\research\object_detection\core\box_predictor.py"", line 36, in <module>
    slim = tf.contrib.slim
AttributeError: module 'tensorflow' has no attribute 'contrib'`

## 3. Steps to reproduce

run from command line the \models\research\object_detection\builders\model_builder.py   script and get the error reported above

## 4. Expected behavior

Expect no error.  This error was previously reported when Object Detection API was not supported in TF2 but, it is now.

## 5. Additional context

Include any logs that would be helpful to diagnose the problem.

## 6. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- Mobile device name if the issue happens on a mobile device:
- TensorFlow installed from (source or binary): pip install
- TensorFlow version (use command below): 2.3.0-rc
- Python version: 3.7.4
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

<!-- 
Collect system information using our environment capture script.
https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.shrunn

You can also obtain the TensorFlow version with:

1. TensorFlow 1.0
`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

2. TensorFlow 2.0
`python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`
-->
",grewe,b'models:research stat:awaiting response type:bug',2020-07-22T21:45:11Z,2020-09-08T07:20:04Z,,,,,,,
8940,DELF GLDv2 training error: `Fatal Python error: Segmentation fault.`,"I might be interrupting. @andrefaraujo 

## 1. The entire URL of the file you are using
https://github.com/tensorflow/models/tree/master/research/delf/delf/python/training

## 2. Describe the bug
I run the train.py followed the instruction and an error occurs.
`Fatal Python error: Segmentation fault.`

Details are below. The problem may between [363](https://github.com/tensorflow/models/blob/567bd18d4e6c1e31e4e58d3ffee0127f81bc1ab8/research/delf/delf/python/training/train.py#L362)-[367](https://github.com/tensorflow/models/blob/567bd18d4e6c1e31e4e58d3ffee0127f81bc1ab8/research/delf/delf/python/training/train.py#L366) in train.py by following the output of `logging.info()`.


I0722 08:21:29.993298 140327930558272 train.py:120] Running training script with

I0722 08:21:29.993462 140327930558272 train.py:121] logdir= gldv2_training
I0722 08:21:29.993936 140327930558272 train.py:122] initial_lr= 0.010000
I0722 08:21:29.994389 140327930558272 train.py:123] block3_strides= True
2020-07-22 08:21:29.995690: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-07-22 08:21:30.064180: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties:
pciBusID: 0000:04:00.0 name: Tesla P40 computeCapability: 6.1
coreClock: 1.531GHz coreCount: 30 deviceMemorySize: 23.88GiB deviceMemoryBandwidth: 323.21GiB/s
2020-07-22 08:21:30.066700: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 1 with properties:
pciBusID: 0000:06:00.0 name: Tesla P40 computeCapability: 6.1
coreClock: 1.531GHz coreCount: 30 deviceMemorySize: 23.88GiB deviceMemoryBandwidth: 323.21GiB/s
2020-07-22 08:21:30.069208: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 2 with properties:
pciBusID: 0000:07:00.0 name: Tesla P40 computeCapability: 6.1
coreClock: 1.531GHz coreCount: 30 deviceMemorySize: 23.88GiB deviceMemoryBandwidth: 323.21GiB/s
2020-07-22 08:21:30.071704: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 3 with properties:
pciBusID: 0000:08:00.0 name: Tesla P40 computeCapability: 6.1
coreClock: 1.531GHz coreCount: 30 deviceMemorySize: 23.88GiB deviceMemoryBandwidth: 323.21GiB/s
2020-07-22 08:21:30.074091: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 4 with properties:
pciBusID: 0000:0c:00.0 name: Tesla P40 computeCapability: 6.1
coreClock: 1.531GHz coreCount: 30 deviceMemorySize: 23.88GiB deviceMemoryBandwidth: 323.21GiB/s
2020-07-22 08:21:30.076454: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 5 with properties:
pciBusID: 0000:0d:00.0 name: Tesla P40 computeCapability: 6.1
coreClock: 1.531GHz coreCount: 30 deviceMemorySize: 23.88GiB deviceMemoryBandwidth: 323.21GiB/s
2020-07-22 08:21:30.078852: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 6 with properties:
pciBusID: 0000:0e:00.0 name: Tesla P40 computeCapability: 6.1
coreClock: 1.531GHz coreCount: 30 deviceMemorySize: 23.88GiB deviceMemoryBandwidth: 323.21GiB/s
2020-07-22 08:21:30.081129: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 7 with properties:
pciBusID: 0000:0f:00.0 name: Tesla P40 computeCapability: 6.1
coreClock: 1.531GHz coreCount: 30 deviceMemorySize: 23.88GiB deviceMemoryBandwidth: 323.21GiB/s
2020-07-22 08:21:30.081347: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-07-22 08:21:30.083051: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-07-22 08:21:30.084738: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-07-22 08:21:30.085027: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-07-22 08:21:30.086848: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-07-22 08:21:30.087870: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-07-22 08:21:30.091821: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-07-22 08:21:30.130943: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0, 1, 2, 3, 4, 5, 6, 7
2020-07-22 08:21:30.131306: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-07-22 08:21:30.146241: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 2199885000 Hz
2020-07-22 08:21:30.150533: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56131c7b91b0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-07-22 08:21:30.150559: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-07-22 08:21:31.578771: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56131c0f1340 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-07-22 08:21:31.578812: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla P40, Compute Capability 6.1
2020-07-22 08:21:31.578822: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (1): Tesla P40, Compute Capability 6.1
2020-07-22 08:21:31.578830: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (2): Tesla P40, Compute Capability 6.1
2020-07-22 08:21:31.578837: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (3): Tesla P40, Compute Capability 6.1
2020-07-22 08:21:31.578844: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (4): Tesla P40, Compute Capability 6.1
2020-07-22 08:21:31.578851: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (5): Tesla P40, Compute Capability 6.1
2020-07-22 08:21:31.578859: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (6): Tesla P40, Compute Capability 6.1
2020-07-22 08:21:31.578866: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (7): Tesla P40, Compute Capability 6.1
2020-07-22 08:21:31.622038: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties:
pciBusID: 0000:04:00.0 name: Tesla P40 computeCapability: 6.1
coreClock: 1.531GHz coreCount: 30 deviceMemorySize: 23.88GiB deviceMemoryBandwidth: 323.21GiB/s
2020-07-22 08:21:31.624129: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 1 with properties:
pciBusID: 0000:06:00.0 name: Tesla P40 computeCapability: 6.1
coreClock: 1.531GHz coreCount: 30 deviceMemorySize: 23.88GiB deviceMemoryBandwidth: 323.21GiB/s
2020-07-22 08:21:31.626215: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 2 with properties:
pciBusID: 0000:07:00.0 name: Tesla P40 computeCapability: 6.1
coreClock: 1.531GHz coreCount: 30 deviceMemorySize: 23.88GiB deviceMemoryBandwidth: 323.21GiB/s
2020-07-22 08:21:31.628316: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 3 with properties:
pciBusID: 0000:08:00.0 name: Tesla P40 computeCapability: 6.1
coreClock: 1.531GHz coreCount: 30 deviceMemorySize: 23.88GiB deviceMemoryBandwidth: 323.21GiB/s
2020-07-22 08:21:31.630404: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 4 with properties:
pciBusID: 0000:0c:00.0 name: Tesla P40 computeCapability: 6.1
coreClock: 1.531GHz coreCount: 30 deviceMemorySize: 23.88GiB deviceMemoryBandwidth: 323.21GiB/s
2020-07-22 08:21:31.632471: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 5 with properties:
pciBusID: 0000:0d:00.0 name: Tesla P40 computeCapability: 6.1
coreClock: 1.531GHz coreCount: 30 deviceMemorySize: 23.88GiB deviceMemoryBandwidth: 323.21GiB/s
2020-07-22 08:21:31.634446: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 6 with properties:
pciBusID: 0000:0e:00.0 name: Tesla P40 computeCapability: 6.1
coreClock: 1.531GHz coreCount: 30 deviceMemorySize: 23.88GiB deviceMemoryBandwidth: 323.21GiB/s
2020-07-22 08:21:31.636402: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 7 with properties:
pciBusID: 0000:0f:00.0 name: Tesla P40 computeCapability: 6.1
coreClock: 1.531GHz coreCount: 30 deviceMemorySize: 23.88GiB deviceMemoryBandwidth: 323.21GiB/s
2020-07-22 08:21:31.636453: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-07-22 08:21:31.636473: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-07-22 08:21:31.636489: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-07-22 08:21:31.636506: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-07-22 08:21:31.636522: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-07-22 08:21:31.636537: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-07-22 08:21:31.636554: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-07-22 08:21:31.668968: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0, 1, 2, 3, 4, 5, 6, 7
2020-07-22 08:21:31.669017: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-07-22 08:21:31.686490: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-07-22 08:21:31.686513: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 1 2 3 4 5 6 7
2020-07-22 08:21:31.686525: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N Y Y Y Y Y Y Y
2020-07-22 08:21:31.686533: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 1:   Y N Y Y Y Y Y Y
2020-07-22 08:21:31.686541: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 2:   Y Y N Y Y Y Y Y
2020-07-22 08:21:31.686548: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 3:   Y Y Y N Y Y Y Y
2020-07-22 08:21:31.686563: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 4:   Y Y Y Y N Y Y Y
2020-07-22 08:21:31.686571: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 5:   Y Y Y Y Y N Y Y
2020-07-22 08:21:31.686578: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 6:   Y Y Y Y Y Y N Y
2020-07-22 08:21:31.686586: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 7:   Y Y Y Y Y Y Y N
2020-07-22 08:21:31.710870: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 22837 MB memory) -> physical GPU (device: 0, name: Tesla P40, pci
bus id: 0000:04:00.0, compute capability: 6.1)
2020-07-22 08:21:31.713223: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 22837 MB memory) -> physical GPU (device: 1, name: Tesla P40, pci
bus id: 0000:06:00.0, compute capability: 6.1)
2020-07-22 08:21:31.715586: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 22837 MB memory) -> physical GPU (device: 2, name: Tesla P40, pci
bus id: 0000:07:00.0, compute capability: 6.1)
2020-07-22 08:21:31.717907: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:3 with 22837 MB memory) -> physical GPU (device: 3, name: Tesla P40, pci
bus id: 0000:08:00.0, compute capability: 6.1)
2020-07-22 08:21:31.720255: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:4 with 22837 MB memory) -> physical GPU (device: 4, name: Tesla P40, pci
bus id: 0000:0c:00.0, compute capability: 6.1)
2020-07-22 08:21:31.722603: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:5 with 22837 MB memory) -> physical GPU (device: 5, name: Tesla P40, pci
bus id: 0000:0d:00.0, compute capability: 6.1)
2020-07-22 08:21:31.724940: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:6 with 22837 MB memory) -> physical GPU (device: 6, name: Tesla P40, pci
bus id: 0000:0e:00.0, compute capability: 6.1)
2020-07-22 08:21:31.727318: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:7 with 22837 MB memory) -> physical GPU (device: 7, name: Tesla P40, pci
bus id: 0000:0f:00.0, compute capability: 6.1)
INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3', '/job:localhost/replica:0/task:0/device:GPU:4', '/job:localhost/replica:0/task:0/device:GPU:5', '/job:localhost/replica:0/task:0/device:GPU:6', '/job:localhost/replica:0/task:0/device:GPU:7')
I0722 08:21:31.735625 140327930558272 mirrored_strategy.py:500] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3', '/job:localhost/replica:0/task:0/device:GPU:4', '/job:localhost/replica:0/task:0/device:GPU:5', '/job:localhost/replica:0/task:0/device:GPU:6', '/job:localhost/replica:0/task:0/device:GPU:7')
I0722 08:21:31.735947 140327930558272 train.py:128] Number of devices: 8
WARNING:tensorflow:From /home/xinkong/.local/lib/python3.6/site-packages/tensorflow/python/ops/image_ops_impl.py:2827: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.
Instructions for updating:
`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.
W0722 08:21:33.257451 140327930558272 deprecation.py:323] From /home/xinkong/.local/lib/python3.6/site-packages/tensorflow/python/ops/image_ops_impl.py:2827: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.
Instructions for updating:
`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.
I0722 08:21:41.587657 140327930558272 train.py:210] Model, datasets loaded.
num_classes= 81313
I0722 08:21:41.596926 140327930558272 train.py:363] Attempting to load ImageNet pretrained weights.
INFO:tensorflow:batch_all_reduce: 214 all-reduces with algorithm = nccl, num_packs = 1
I0722 08:22:10.150980 140327930558272 cross_device_ops.py:698] batch_all_reduce: 214 all-reduces with algorithm = nccl, num_packs = 1
INFO:tensorflow:batch_all_reduce: 8 all-reduces with algorithm = nccl, num_packs = 1
I0722 08:22:20.667220 140327930558272 cross_device_ops.py:698] batch_all_reduce: 8 all-reduces with algorithm = nccl, num_packs = 1
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
I0722 08:22:22.086211 140327930558272 cross_device_ops.py:440] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
I0722 08:22:22.087918 140327930558272 cross_device_ops.py:440] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:batch_all_reduce: 214 all-reduces with algorithm = nccl, num_packs = 1
I0722 08:22:47.857083 140327930558272 cross_device_ops.py:698] batch_all_reduce: 214 all-reduces with algorithm = nccl, num_packs = 1
INFO:tensorflow:batch_all_reduce: 8 all-reduces with algorithm = nccl, num_packs = 1
I0722 08:22:57.193145 140327930558272 cross_device_ops.py:698] batch_all_reduce: 8 all-reduces with algorithm = nccl, num_packs = 1
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
I0722 08:22:58.614024 140327930558272 cross_device_ops.py:440] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
I0722 08:22:58.616227 140327930558272 cross_device_ops.py:440] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
2020-07-22 08:23:27.528045: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-07-22 08:23:27.791325: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
Fatal Python error: Segmentation fault

Thread 0x00007fa0a473f740 (most recent call first):
  File ""/home/xinkong/.local/lib/python3.6/site-packages/tensorflow/python/eager/execute.py"", line 60 in quick_execute
  File ""/home/xinkong/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py"", line 598 in call
  File ""/home/xinkong/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py"", line 1746 in _call_flat
  File ""/home/xinkong/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py"", line 1665 in _filtered_call
  File ""/home/xinkong/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py"", line 2420 in __call__
  File ""/home/xinkong/.local/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py"", line 644 in _call
  File ""/home/xinkong/.local/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py"", line 580 in __call__
  File ""train.py"", line 365 in main
  File ""/home/xinkong/.local/lib/python3.6/site-packages/absl/app.py"", line 250 in _run_main
  File ""/home/xinkong/.local/lib/python3.6/site-packages/absl/app.py"", line 299 in run
  File ""train.py"", line 472 in <module>
Segmentation fault (core dumped)

## 6. System information

- OS Platform and Distribution: gcc version 4.8.2 20140120 (Red Hat 4.8.2-16)
- TensorFlow installed from (source or binary): pip install tensorflow-gpu
- TensorFlow version (use command below):  the latest version
- Python version: 3.6
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 10
- GPU model and memory: P40, 24G, 8 in total

Could anyone help me? Thanks! ",kxhit,b'models:research type:bug',2020-07-22T08:43:37Z,2020-07-27T16:59:18Z,,,,,,,
8934,Deprecate old research models,"# Description
Deprecate old research models as we announced several months ago.

People can still access archived models in the archive branch.

## Type of change

For a new feature or function, please create an issue first to discuss it
with us before submitting a pull request.

Note: Please delete options that are not relevant.

- [ ] Bug fix (non-breaking change which fixes an issue)
- [ ] Documentation update
- [ ] TensorFlow 2 migration
- [ ] New feature (non-breaking change which adds functionality)
- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)
- [ ] A new research paper code implementation
- [x] Other (Specify)

## Tests
N/A

## Checklist

- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).
- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).
- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).
- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.
- [ ] I have commented my code, particularly in hard-to-understand areas.
- [ ] I have made corresponding changes to the documentation.
- [x] My changes generate no new warnings.
- [ ] I have added tests that prove my fix is effective or that my feature works.
",jaeyounkim,b'cla: yes stat:awaiting review',2020-07-22T00:12:54Z,2020-07-31T04:14:22Z,,,,,,,
8933,ERROR: No matching distribution found for opencv-python-headless,"# Prerequisites

Please answer the following questions for yourself before submitting an issue.

- [x ] I am using the latest TensorFlow Model Garden release and TensorFlow 2.
- [x ] I am reporting the issue to the correct repository. (Model Garden official or research directory)
- [x ] I checked to make sure that this issue has not been filed already.

## 1. The entire URL of the file you are using

git clone https://github.com/tensorflow/models.git

## 2. Describe the bug

""ERROR: Could not find a version that satisfies the requirement opencv-python-headless (from tf-models-official->object-detection==0.1) (from versions: none)
ERROR: No matching distribution found for opencv-python-headless (from tf-models-official->object-detection==0.1)""

## 3. Steps to reproduce

Followed the Object Detection API with Tensorflow 2 instructions [here](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2.md)

After a successful ""Compile protos."" I began the ""Install TensorFlow Object Detection API."" 
The python pip install ran smoothly until I encountered the ""Error"" described above.

## 4. Expected behavior

Did not expect the ""No matching distribution found for opencv-python-headless""
I am presently running opencv-python 4.1.2 and did not see a requirement to be running opencv-python-headless in the requirements list.

## 5. Additional context

Include any logs that would be helpful to diagnose the problem.

## 6. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): NVIDIA Jetpack 4.3 (Ubuntu 18.04 Desktop) 
- Mobile device name if the issue happens on a mobile device:
- TensorFlow installed from (source or binary): pip
- TensorFlow version (use command below): 2.1.0 (NVIDIA Tensorflow package install)
- Python version: 3.6.9
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 10.0.326/7.6
- GPU model and memory: Jetson Nano 4GB
",TCIII,b'models:research stat:awaiting response type:bug',2020-07-21T23:03:04Z,2020-07-24T11:26:32Z,,,,,,,
8931,Mask RCNN with Distributed Strategy,"Having the following issue on MaskRCNN with Distributed Strategy. 

tensorflow.python.framework.errors_impl.InvalidArgumentError:  indices[0] = 0 is not in [0, 0)
         [[{{node parser/GatherV2_2}}]]
         [[MultiDeviceIteratorGetNextFromShard]]
         [[RemoteCall]]
         [[IteratorGetNext]] [Op:__inference_train_step_234790]
",ashiqimranintel,b'models:official stat:awaiting model gardener type:bug',2020-07-21T16:55:56Z,2020-08-05T16:42:55Z,,,,,,,
8927,"IF i want to know about bounding_boxes,  Should  i modify the code?","<!--
As per our GitHub Policy (https://github.com/tensorflow/models/blob/master/ISSUES.md), we only address code bugs, documentation issues, and feature requests on GitHub.

We will automatically close questions and help related issues.

Please go to Stack Overflow (http://stackoverflow.com/questions/tagged/tensorflow-model-garden) for questions and help.

-->
i customize the code to detect face. and i want to use the detected face to  verify  the person. 
But, there are no codes to let know about bounding box(width,hegiht,x,y)  .
I read the github code  and i find where the bounding_box is stored  .
I make the code know bounding_box
Is there any method to know bounding_box?
",woongjoonchoi,b'stat:awaiting response type:support',2020-07-21T10:45:27Z,2020-09-01T13:35:11Z,,,,,,,
8925,Module in util not found ,"When i try to install util there are error pop up even i already install the util

----> 8 from utils import plot_bbs
      9 
     10 

ImportError: cannot import name 'plot_bbs'

I already install utils by
pip install utils",archy44,b'stat:awaiting response type:bug',2020-07-21T08:37:22Z,2020-09-01T13:33:20Z,,,,,,,
8924,DELF GLDv2 build_image_dataset error: KeyError: 'image_path',"Hi! When I run `python3 build_image_dataset.py \
  --train_csv_path=gldv2_dataset/train/train.csv \
  --train_clean_csv_path=gldv2_dataset/train/train_clean.csv \
  --train_directory=gldv2_dataset/train/*/*/*/ \
  --output_directory=gldv2_dataset/tfrecord/ \
  --num_shards=128 \
  --generate_train_validation_splits \
  --validation_split_size=0.2`, an error occurs. `KeyError: 'image_path'` 

I read the code and find if it goes to else, 'image_path' will not assigned a value. https://github.com/tensorflow/models/blob/f05df686e4736f6d984253e5792f0c54b80e8db3/research/delf/delf/python/training/build_image_dataset.py#L159
https://github.com/tensorflow/models/blob/f05df686e4736f6d984253e5792f0c54b80e8db3/research/delf/delf/python/training/build_image_dataset.py#L167
Why is that? Is this a bug or something wrong with my data. However my data is prepared well by the provided script (download_dataset.sh).  Could anyone help me? Thanks a lot!!!
",kxhit,b'models:research type:support',2020-07-21T08:09:58Z,2020-07-21T16:56:58Z,,,,,,,
8922,the lenet not right,"# Prerequisites

Please answer the following questions for yourself before submitting an issue.

- [ ] I am using the latest TensorFlow Model Garden release and TensorFlow 2.
1.13
- [ ] I am reporting the issue to the correct repository. (Model Garden official or research directory)
models/research/slim/nets/lenet.py 
- [ ] I checked to make sure that this issue has not already been filed.
yes

## 1. The entire URL of the file you are using

https://github.com/tensorflow/models/tree/master/research/slim/nets/lenet.py 

## 2. Describe the bug
the lenet out of line with the original doc 《Gradient-Based Learning Applied to Document Recognition》


",djh123,b'models:research type:bug',2020-07-21T02:01:42Z,2020-07-21T02:26:35Z,,,,,,,
8919,object_detection_tutorial.ipynb not found,"Dear all,
I am using Tensorflow latest version for the Object Detection API. I followed all installation steps and explanations on Github and Youtube and everything worked fine with only one problem. There should be a file named object_detection_tutorial.ipynb in Tensorflow1\models\research\object_detection, but I cant find it I dont know why. I have looked almost every where to solve this issue but I didnt solve it. 
Is there a place where I can download the file separately? or I missed something ?",mohammed-ab99,b'models:official type:bug',2020-07-20T16:16:17Z,2020-07-20T19:20:14Z,,,,,,,
8917,Object detection obtain a mAP value so low,"# 1. The entire URL of the file you are using
https://github.com/tensorflow/models/tree/master/research/object_detection

# 2. Describe the bug
I train any detection model and get a very low mAP. Besides, I've tried 50,000-step workouts and it doesn't exceed 0.001% mAP. The complete output:

> WARNING:tensorflow:Forced number of epochs for all eval validations to be 1.
> W0720 11:29:32.074273 140109352376128 model_lib_v2.py:908] Forced number of epochs for all eval validations to be 1.
> INFO:tensorflow:Maybe overwriting sample_1_of_n_eval_examples: None
> I0720 11:29:32.074583 140109352376128 config_util.py:552] Maybe overwriting sample_1_of_n_eval_examples: None
> INFO:tensorflow:Maybe overwriting use_bfloat16: False
> I0720 11:29:32.074677 140109352376128 config_util.py:552] Maybe overwriting use_bfloat16: False
> INFO:tensorflow:Maybe overwriting eval_num_epochs: 1
> I0720 11:29:32.074805 140109352376128 config_util.py:552] Maybe overwriting eval_num_epochs: 1
> WARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.
> W0720 11:29:32.074969 140109352376128 model_lib_v2.py:923] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.
> WARNING:tensorflow:num_readers has been reduced to 10 to match input file shards.
> W0720 11:29:32.631196 140109352376128 dataset_builder.py:83] num_readers has been reduced to 10 to match input file shards.
> WARNING:tensorflow:`shuffle` is false, but the input data stream is still slightly shuffled since `num_readers` > 1.
> W0720 11:29:32.636519 140109352376128 dataset_builder.py:89] `shuffle` is false, but the input data stream is still slightly shuffled since `num_readers` > 1.
> WARNING:tensorflow:From /home/fperez/.local/lib/python3.6/site-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
> Instructions for updating:
> Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_deterministic`.
> W0720 11:29:32.637072 140109352376128 deprecation.py:323] From /home/fperez/.local/lib/python3.6/site-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
> Instructions for updating:
> Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_deterministic`.
> WARNING:tensorflow:From /home/fperez/.local/lib/python3.6/site-packages/object_detection/builders/dataset_builder.py:175: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
> Instructions for updating:
> Use `tf.data.Dataset.map()
> W0720 11:29:32.665079 140109352376128 deprecation.py:323] From /home/fperez/.local/lib/python3.6/site-packages/object_detection/builders/dataset_builder.py:175: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
> Instructions for updating:
> Use `tf.data.Dataset.map()
> WARNING:tensorflow:From /home/fperez/.local/lib/python3.6/site-packages/object_detection/inputs.py:79: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.
> Instructions for updating:
> Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.
> W0720 11:29:43.398945 140109352376128 deprecation.py:323] From /home/fperez/.local/lib/python3.6/site-packages/object_detection/inputs.py:79: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.
> Instructions for updating:
> Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.
> WARNING:tensorflow:From /home/fperez/.local/lib/python3.6/site-packages/object_detection/inputs.py:259: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
> Instructions for updating:
> Use `tf.cast` instead.
> W0720 11:29:46.477952 140109352376128 deprecation.py:323] From /home/fperez/.local/lib/python3.6/site-packages/object_detection/inputs.py:259: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
> Instructions for updating:
> Use `tf.cast` instead.
> INFO:tensorflow:Waiting for new checkpoint at outPet/
> I0720 11:29:54.265453 140109352376128 checkpoint_utils.py:125] Waiting for new checkpoint at outPet/
> INFO:tensorflow:Found new checkpoint at outPet/ckpt-2
> I0720 11:29:54.270009 140109352376128 checkpoint_utils.py:134] Found new checkpoint at outPet/ckpt-2
> INFO:tensorflow:depth of additional conv before box predictor: 0
> I0720 11:30:11.928930 140109352376128 convolutional_keras_box_predictor.py:154] depth of additional conv before box predictor: 0
> WARNING:tensorflow:From /home/fperez/.local/lib/python3.6/site-packages/object_detection/utils/model_util.py:57: Tensor.experimental_ref (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
> Instructions for updating:
> Use ref() instead.
> W0720 11:30:30.643754 140109352376128 deprecation.py:323] From /home/fperez/.local/lib/python3.6/site-packages/object_detection/utils/model_util.py:57: Tensor.experimental_ref (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
> Instructions for updating:
> Use ref() instead.
> WARNING:tensorflow:From /home/fperez/.local/lib/python3.6/site-packages/object_detection/core/losses.py:345: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.
> Instructions for updating:
> 
> Future major versions of TensorFlow will allow gradients to flow
> into the labels input on backprop by default.
> 
> See `tf.nn.softmax_cross_entropy_with_logits_v2`.
> 
> W0720 11:30:42.288070 140109352376128 deprecation.py:323] From /home/fperez/.local/lib/python3.6/site-packages/object_detection/core/losses.py:345: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.
> Instructions for updating:
> 
> Future major versions of TensorFlow will allow gradients to flow
> into the labels input on backprop by default.
> 
> See `tf.nn.softmax_cross_entropy_with_logits_v2`.
> 
> WARNING:tensorflow:From /home/fperez/.local/lib/python3.6/site-packages/object_detection/eval_util.py:854: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
> Instructions for updating:
> Use `tf.cast` instead.
> W0720 11:30:57.214376 140109352376128 deprecation.py:323] From /home/fperez/.local/lib/python3.6/site-packages/object_detection/eval_util.py:854: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
> Instructions for updating:
> Use `tf.cast` instead.
> INFO:tensorflow:Finished eval step 0
> I0720 11:31:09.808830 140109352376128 model_lib_v2.py:782] Finished eval step 0
> WARNING:tensorflow:From /home/fperez/.local/lib/python3.6/site-packages/object_detection/utils/visualization_utils.py:618: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
> Instructions for updating:
> tf.py_func is deprecated in TF V2. Instead, there are two
>     options available in V2.
>     - tf.py_function takes a python function which manipulates tf eager
>     tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
>     an ndarray (just call tensor.numpy()) but having access to eager tensors
>     means `tf.py_function`s can use accelerators such as GPUs as well as
>     being differentiable using a gradient tape.
>     - tf.numpy_function maintains the semantics of the deprecated tf.py_func
>     (it is not differentiable, and manipulates numpy arrays). It drops the
>     stateful argument making all functions stateful.
>     
> W0720 11:31:09.827720 140109352376128 deprecation.py:323] From /home/fperez/.local/lib/python3.6/site-packages/object_detection/utils/visualization_utils.py:618: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
> Instructions for updating:
> tf.py_func is deprecated in TF V2. Instead, there are two
>     options available in V2.
>     - tf.py_function takes a python function which manipulates tf eager
>     tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
>     an ndarray (just call tensor.numpy()) but having access to eager tensors
>     means `tf.py_function`s can use accelerators such as GPUs as well as
>     being differentiable using a gradient tape.
>     - tf.numpy_function maintains the semantics of the deprecated tf.py_func
>     (it is not differentiable, and manipulates numpy arrays). It drops the
>     stateful argument making all functions stateful.
>     
> INFO:tensorflow:Finished eval step 100
> I0720 11:31:20.294619 140109352376128 model_lib_v2.py:782] Finished eval step 100
> INFO:tensorflow:Finished eval step 200
> I0720 11:31:29.942643 140109352376128 model_lib_v2.py:782] Finished eval step 200
> INFO:tensorflow:Finished eval step 300
> I0720 11:31:39.213092 140109352376128 model_lib_v2.py:782] Finished eval step 300
> INFO:tensorflow:Finished eval step 400
> I0720 11:31:48.495120 140109352376128 model_lib_v2.py:782] Finished eval step 400
> Corrupt JPEG data: 240 extraneous bytes before marker 0xd9
> INFO:tensorflow:Finished eval step 500
> I0720 11:31:58.040935 140109352376128 model_lib_v2.py:782] Finished eval step 500
> INFO:tensorflow:Finished eval step 600
> I0720 11:32:07.354710 140109352376128 model_lib_v2.py:782] Finished eval step 600
> INFO:tensorflow:Finished eval step 700
> I0720 11:32:16.727011 140109352376128 model_lib_v2.py:782] Finished eval step 700
> INFO:tensorflow:Finished eval step 800
> I0720 11:32:26.361072 140109352376128 model_lib_v2.py:782] Finished eval step 800
> INFO:tensorflow:Finished eval step 900
> I0720 11:32:36.103276 140109352376128 model_lib_v2.py:782] Finished eval step 900
> INFO:tensorflow:Finished eval step 1000
> I0720 11:32:45.385483 140109352376128 model_lib_v2.py:782] Finished eval step 1000
> INFO:tensorflow:Finished eval step 1100
> I0720 11:32:55.078747 140109352376128 model_lib_v2.py:782] Finished eval step 1100
> INFO:tensorflow:Performing evaluation on 1103 images.
> I0720 11:32:55.279253 140109352376128 coco_evaluation.py:237] Performing evaluation on 1103 images.
> creating index...
> index created!
> INFO:tensorflow:Loading and preparing annotation results...
> I0720 11:32:55.283011 140109352376128 coco_tools.py:116] Loading and preparing annotation results...
> INFO:tensorflow:DONE (t=0.25s)
> I0720 11:32:55.528823 140109352376128 coco_tools.py:138] DONE (t=0.25s)
> creating index...
> index created!
> Running per image evaluation...
> Evaluate annotation type *bbox*
> DONE (t=10.34s).
> Accumulating evaluation results...
> DONE (t=4.38s).
>  Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000
>  Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000
>  Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000
>  Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000
>  Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000
>  Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000
>  Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000
>  Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000
>  Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000
>  Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000
>  Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000
>  Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000
> INFO:tensorflow:Eval metrics at step 5000
> I0720 11:33:10.692985 140109352376128 model_lib_v2.py:836] Eval metrics at step 5000
> INFO:tensorflow:	+ DetectionBoxes_Precision/mAP: 0.000000
> I0720 11:33:10.699979 140109352376128 model_lib_v2.py:839] 	+ DetectionBoxes_Precision/mAP: 0.000000
> INFO:tensorflow:	+ DetectionBoxes_Precision/mAP@.50IOU: 0.000000
> I0720 11:33:10.701123 140109352376128 model_lib_v2.py:839] 	+ DetectionBoxes_Precision/mAP@.50IOU: 0.000000
> INFO:tensorflow:	+ DetectionBoxes_Precision/mAP@.75IOU: 0.000000
> I0720 11:33:10.702188 140109352376128 model_lib_v2.py:839] 	+ DetectionBoxes_Precision/mAP@.75IOU: 0.000000
> INFO:tensorflow:	+ DetectionBoxes_Precision/mAP (small): -1.000000
> I0720 11:33:10.703368 140109352376128 model_lib_v2.py:839] 	+ DetectionBoxes_Precision/mAP (small): -1.000000
> INFO:tensorflow:	+ DetectionBoxes_Precision/mAP (medium): 0.000000
> I0720 11:33:10.704531 140109352376128 model_lib_v2.py:839] 	+ DetectionBoxes_Precision/mAP (medium): 0.000000
> INFO:tensorflow:	+ DetectionBoxes_Precision/mAP (large): 0.000000
> I0720 11:33:10.705590 140109352376128 model_lib_v2.py:839] 	+ DetectionBoxes_Precision/mAP (large): 0.000000
> INFO:tensorflow:	+ DetectionBoxes_Recall/AR@1: 0.000000
> I0720 11:33:10.706640 140109352376128 model_lib_v2.py:839] 	+ DetectionBoxes_Recall/AR@1: 0.000000
> INFO:tensorflow:	+ DetectionBoxes_Recall/AR@10: 0.000000
> I0720 11:33:10.707696 140109352376128 model_lib_v2.py:839] 	+ DetectionBoxes_Recall/AR@10: 0.000000
> INFO:tensorflow:	+ DetectionBoxes_Recall/AR@100: 0.000000
> I0720 11:33:10.708901 140109352376128 model_lib_v2.py:839] 	+ DetectionBoxes_Recall/AR@100: 0.000000
> INFO:tensorflow:	+ DetectionBoxes_Recall/AR@100 (small): -1.000000
> I0720 11:33:10.709911 140109352376128 model_lib_v2.py:839] 	+ DetectionBoxes_Recall/AR@100 (small): -1.000000
> INFO:tensorflow:	+ DetectionBoxes_Recall/AR@100 (medium): 0.000000
> I0720 11:33:10.710905 140109352376128 model_lib_v2.py:839] 	+ DetectionBoxes_Recall/AR@100 (medium): 0.000000
> INFO:tensorflow:	+ DetectionBoxes_Recall/AR@100 (large): 0.000000
> I0720 11:33:10.711957 140109352376128 model_lib_v2.py:839] 	+ DetectionBoxes_Recall/AR@100 (large): 0.000000
> INFO:tensorflow:	+ Loss/RPNLoss/localization_loss: 7.681094
> I0720 11:33:10.712861 140109352376128 model_lib_v2.py:839] 	+ Loss/RPNLoss/localization_loss: 7.681094
> INFO:tensorflow:	+ Loss/RPNLoss/objectness_loss: 2.543328
> I0720 11:33:10.713802 140109352376128 model_lib_v2.py:839] 	+ Loss/RPNLoss/objectness_loss: 2.543328
> INFO:tensorflow:	+ Loss/BoxClassifierLoss/localization_loss: 0.000000
> I0720 11:33:10.714702 140109352376128 model_lib_v2.py:839] 	+ Loss/BoxClassifierLoss/localization_loss: 0.000000
> INFO:tensorflow:	+ Loss/BoxClassifierLoss/classification_loss: 0.003473
> I0720 11:33:10.715607 140109352376128 model_lib_v2.py:839] 	+ Loss/BoxClassifierLoss/classification_loss: 0.003473
> INFO:tensorflow:	+ Loss/regularization_loss: 0.000000
> I0720 11:33:10.716584 140109352376128 model_lib_v2.py:839] 	+ Loss/regularization_loss: 0.000000
> INFO:tensorflow:	+ Loss/total_loss: 10.227891
> I0720 11:33:10.717467 140109352376128 model_lib_v2.py:839] 	+ Loss/total_loss: 10.227891
> 

# 3. Steps to reproduce
Start protoc and make the test
`cd models/research/`
`protoc object_detection/protos/*.proto --python_out=.`
`python object_detection/builders/model_builder_tf2_test.py`
Download Pet images and annotations and the faster_rcnn model
`wget http://www.robots.ox.ac.uk/~vgg/data/pets/data/images.tar.gz`
`wget http://www.robots.ox.ac.uk/~vgg/data/pets/data/annotations.tar.gz`
`wget http://download.tensorflow.org/models/object_detection/tf2/20200711/faster_rcnn_resnet101_v1_1024x1024_coco17_tpu-8.tar.gz`
`tar -xvf annotations.tar.gz`
`tar -xvf images.tar.gz`
`tar -xvf faster_rcnn_resnet101_v1_1024x1024_coco17_tpu-8.tar.gz`
Create tf_record
`python object_detection/dataset_tools/create_pet_tf_record.py \
    --label_map_path=object_detection/data/pet_label_map.pbtxt \
    --data_dir=`pwd` \
    --output_dir=dataPet`
Configure config file
`cp object_detection/dataPet/pet_label_map.pbtxt data/`
`cp object_detection/configs/tf2/faster_rcnn_resnet101_v1_1024x1024_coco17_tpu-8.config dataPet/`
And change: 
> num_classes = 37
> batch_size = 1
> fine_tune_checkpoint: ""faster_rcnn_resnet101_v1_1024x1024_coco17_tpu-8/checkpoint/ckpt-0""
> fine_tune_checkpoint_type: ""detection""
> label_map_path: ""dataPet/pet_label_map.pbtxt""
> input_path: ""dataPet/pet_faces_train.record-?????-of-00010""
> label_map_path: ""dataPet/pet_label_map.pbtxt""
> input_path: ""dataPet/pet_faces_val.record-?????-of-00010""

Train the model:
`PIPELINE_CONFIG_PATH='dataPet/faster_rcnn_resnet101_v1_1024x1024_coco17_tpu-8.config'`
`MODEL_DIR='outPet/'`
`NUM_TRAIN_STEPS=5000`
`python object_detection/model_main_tf2.py \
    --pipeline_config_path=${PIPELINE_CONFIG_PATH} \
    --model_dir=${MODEL_DIR} \
    --num_train_steps=${NUM_TRAIN_STEPS} \
    --alsologtostderr`
Test the model:
`python object_detection/model_main_tf2.py \
    --pipeline_config_path=${PIPELINE_CONFIG_PATH} \
    --model_dir=${MODEL_DIR} \
    --checkpoint_dir=${MODEL_DIR} \
    --alsologtostderr`

# 4. Expected behavior
Get a higher mAP value.

# 5. Additional context
Training more steps doesn't produce a better mAP.

# 6. System information
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04.4
- Mobile device name if the issue happens on a mobile device: None
- TensorFlow installed from (source or binary): docker
- TensorFlow version (use command below): 2.2.0
- Python version: 3.6.9
- Bazel version (if compiling from source): None
- GCC/Compiler version (if compiling from source): None
- CUDA/cuDNN version: CUDA v10.1
- GPU model and memory: NVIDIA Tesla V100 32GB",FPerezHernandez92,b'models:research type:support',2020-07-20T11:36:05Z,2020-08-06T07:57:12Z,,,,,,,
8916,Is tensorflow usable in a thread (C++) ?," Hi everyone, I'm using tensorflow in my own C++ object detection script and since I decided to use thread to maximize the performance of it, my ""session-> run"" command is not working anymore even if the argument are exactly the same. I'm using my own object detection model so i cannot provide any link of it.


   Have I written custom code (as opposed to using a stock example script provided in TensorFlow):yes
    OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Ubuntu 18.04
    Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
    TensorFlow installed from (source or binary):source
    TensorFlow version (use command below):1.15.2
    Python version:3.8
    Bazel version (if compiling from source):0.26.1
    GCC/Compiler version (if compiling from source):5.5
    CUDA/cuDNN version:10.1/7.5
    GPU model and memory:Jetson Xavier

Describe the current behavior
I'm working on creating an object detection script using Tensorflow in C++. For this, I've used https://github.com/lysukhin/tensorflow-object-detection-cpp as a start and after some changes to make it faster, I'm able to run it at a very good speed on the Jetson Xavier. But today, I would like to separate the capture and inference task to let them run by themself as threads. The problem is that my ""session ->run"" instruction is not giving me any information about what is going on. The only thing that I know is that my session->run is not working properly because it should output a tensorflow::Status and I'm getting nothing (neither an error). Since there is no error, It is pretty hard for me to find why my run instruction is not doing anything.

Thanks for the futur help !
",Kmarconi,b'models:research type:bug',2020-07-20T08:51:32Z,2020-07-29T13:34:58Z,,,,,,,
8914,AssertionError: Some Python objects were not bound to checkpointed values when trying to save models from checkpoints,"# Prerequisites

Please answer the following questions for yourself before submitting an issue.

- [ ] I am using the latest TensorFlow Model Garden release and TensorFlow 2.
- [ ] I am reporting the issue to the correct repository. (Model Garden official or research directory)
- [ ] I checked to make sure that this issue has not been filed already.

## 1. The entire URL of the file you are using

https://github.com/tensorflow/models/tree/master/official/...

## 2. Describe the bug

I have trained the classification and have some checkpoints in 'train and eval' model. In order to get the saved model in tf2, I start the run_classification.py in 'export_only' mode which are aimed to transfer my checkpoints to model.
I run the code
'''''''''''
python run_classifier.py \
  --mode='export_only' \
  --input_meta_data_path=${GLUE_DIR}/${TASK}_meta_data \
  --bert_config_file=${BERT_DIR}/bert_config.json \
  --model_dir=${MODEL_DIR} \
  --model_export_path=${SAVED_MODEL_DIR}
''''''''''''
with the error: 
AssertionError: Some Python objects were not bound to checkpointed values, likely due to changes in the Python program: [<tf.Variable 'transformer/layer_2/output_layer_norm/gamma:0' shape=(768,) dtype=float32, numpy

## 3. Steps to reproduce



## 4. Expected behavior

model exported.

## 5. Additional context

None

## 6. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):CentOS 7
- Mobile device name if the issue happens on a mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below): tf-nightly(tf2.0)
- Python version:3.6
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:10.1
- GPU model and memory:GTX 1080Ti 16GB
",monologue1107,b'models:official stat:awaiting response type:bug',2020-07-20T08:42:48Z,2020-07-31T06:58:16Z,,,,,,,
8910,Trouble Installing TensorFlow,"<!--
As per our GitHub Policy (https://github.com/tensorflow/models/blob/master/ISSUES.md), we only address code bugs, documentation issues, and feature requests on GitHub.

We will automatically close questions and help related issues.

Please go to Stack Overflow (http://stackoverflow.com/questions/tagged/tensorflow-model-garden) for questions and help.

-->
Hello.

I am trying to install this tensorflow repository on a raspberry pi using pip. My python version is 3.7.3. When I run python -m pip install ., I get the error 

""Error: Could not find a version that satisfies the requirement tensorflow-addons (from tf-models-official->object-detection==0.1) (from versions: none)""
""Error: No matching distribution found for tensorflow-addons (from tf-models-official->object-detection==0.1)""

Any help would be appreciated. Thanks.",rahulram70,b'type:support',2020-07-20T03:15:26Z,2020-08-07T08:07:13Z,,,,,,,
8909,adding option to select specific frame index,"# Description

> :memo: Please include a summary of the change. 
>  
> * Please also include relevant motivation and context.  
> * List any dependencies that are required for this change.  

## Type of change

For a new feature or function, please create an issue first to discuss it
with us before submitting a pull request.

Note: Please delete options that are not relevant.

- [ ] Bug fix (non-breaking change which fixes an issue)
- [ ] Documentation update
- [ ] TensorFlow 2 migration
- [x] New feature (non-breaking change which adds functionality)
- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)
- [ ] A new research paper code implementation
- [ ] Other (Specify)

## Tests

> :memo: Please describe the tests that you ran to verify your changes.
>  
> * Provide instructions so we can reproduce.  
> * Please also list any relevant details for your test configuration.  

**Test Configuration**:

## Checklist

- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).
- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).
- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).
- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.
- [x] I have commented my code, particularly in hard-to-understand areas.
- [x] I have made corresponding changes to the documentation.
- [x] My changes generate no new warnings.
- [x] I have added tests that prove my fix is effective or that my feature works.
",kmindspark,b'cla: yes ready to pull',2020-07-19T23:34:12Z,2020-07-20T22:08:41Z,,,,,,,
8908,"CenterNet ValueError: Dimensions must be equal, but are 90601 and 92416 for '{{node Loss/mul_1}} = Mul[T=DT_FLOAT](Loss/Pow_1, Loss/Pow_2)' with input shapes: [1,90601,1], [1,92416,1].","I was trying to use CenterNet for my dataset. Upon changing the dimensions in `image_resizer`, I'm getting following error:

```
Traceback (most recent call last):
  File ""object_detection/model_main_tf2.py"", line 106, in <module>
    tf.compat.v1.app.run()
  File ""/home/deploy/.local/lib/python3.6/site-packages/tensorflow/python/platform/app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""/usr/local/lib/python3.6/site-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/usr/local/lib/python3.6/site-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""object_detection/model_main_tf2.py"", line 103, in main
    use_tpu=FLAGS.use_tpu)
  File ""/home/deploy/.local/lib/python3.6/site-packages/object_detection/model_lib_v2.py"", line 622, in train_loop
    loss = _dist_train_step(train_input_iter)
  File ""/home/deploy/.local/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py"", line 580, in __call__
    result = self._call(*args, **kwds)
  File ""/home/deploy/.local/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py"", line 627, in _call
    self._initialize(args, kwds, add_initializers_to=initializers)
  File ""/home/deploy/.local/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py"", line 506, in _initialize
    *args, **kwds))
  File ""/home/deploy/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py"", line 2446, in _get_concrete_function_internal_garbage_collected
    graph_function, _, _ = self._maybe_define_function(args, kwargs)
  File ""/home/deploy/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py"", line 2777, in _maybe_define_function
    graph_function = self._create_graph_function(args, kwargs)
  File ""/home/deploy/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py"", line 2667, in _create_graph_function
    capture_by_value=self._capture_by_value),
  File ""/home/deploy/.local/lib/python3.6/site-packages/tensorflow/python/framework/func_graph.py"", line 981, in func_graph_from_py_func
    func_outputs = python_func(*func_args, **func_kwargs)
  File ""/home/deploy/.local/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py"", line 441, in wrapped_fn
    return weak_wrapped_fn().__wrapped__(*args, **kwds)
  File ""/home/deploy/.local/lib/python3.6/site-packages/tensorflow/python/framework/func_graph.py"", line 968, in wrapper
    raise e.ag_error_metadata.to_exception(e)
ValueError: in user code:

    /home/deploy/.local/lib/python3.6/site-packages/object_detection/model_lib_v2.py:608 _dist_train_step  *
        return _sample_and_train(strategy, train_step_fn, data_iterator)
    /home/deploy/.local/lib/python3.6/site-packages/object_detection/model_lib_v2.py:590 _sample_and_train  *
        per_replica_losses = strategy.run(
    /home/deploy/.local/lib/python3.6/site-packages/object_detection/model_lib_v2.py:573 train_step_fn  *
        loss = eager_train_step(
    /home/deploy/.local/lib/python3.6/site-packages/object_detection/model_lib_v2.py:246 eager_train_step  *
        losses_dict, _ = _compute_losses_and_predictions_dicts(
    /home/deploy/.local/lib/python3.6/site-packages/object_detection/model_lib_v2.py:123 _compute_losses_and_predictions_dicts  *
        losses_dict = model.loss(
    /home/deploy/.local/lib/python3.6/site-packages/object_detection/meta_architectures/center_net_meta_arch.py:2325 loss  *
        object_center_loss = self._compute_object_center_loss(
    /home/deploy/.local/lib/python3.6/site-packages/object_detection/meta_architectures/center_net_meta_arch.py:1745 _compute_object_center_loss  *
        loss += object_center_loss(
    /home/deploy/.local/lib/python3.6/site-packages/object_detection/core/losses.py:92 __call__  *
        return self._compute_loss(prediction_tensor, target_tensor, **params)
    /home/deploy/.local/lib/python3.6/site-packages/object_detection/core/losses.py:741 _compute_loss  *
        negative_loss = (tf.math.pow((1 - target_tensor), self._beta)*
    /home/deploy/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:984 binary_op_wrapper
        return func(x, y, name=name)
    /home/deploy/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:1283 _mul_dispatch
        return gen_math_ops.mul(x, y, name=name)
    /home/deploy/.local/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py:6092 mul
        ""Mul"", x=x, y=y, name=name)
    /home/deploy/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:744 _apply_op_helper
        attrs=attr_protos, op_def=op_def)
    /home/deploy/.local/lib/python3.6/site-packages/tensorflow/python/framework/func_graph.py:595 _create_op_internal
        compute_device)
    /home/deploy/.local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py:3327 _create_op_internal
        op_def=op_def)
    /home/deploy/.local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py:1817 __init__
        control_input_ops, op_def)
    /home/deploy/.local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py:1657 _create_c_op
        raise ValueError(str(e))

    ValueError: Dimensions must be equal, but are 90601 and 92416 for '{{node Loss/mul_1}} = Mul[T=DT_FLOAT](Loss/Pow_1, Loss/Pow_2)' with input shapes: [1,90601,1], [1,92416,1].
```

Here, is my config I used for training:

```
# CenterNet meta-architecture from the ""Objects as Points"" [1] paper
# with the ResNet-v2-101 backbone. The ResNet backbone has a few differences
# as compared to the one mentioned in the paper, hence the performance is
# slightly worse. This config is TPU comptatible.
# [1]: https://arxiv.org/abs/1904.07850

model {
  center_net {
    num_classes: 1
    feature_extractor {
      type: ""resnet_v2_50""
    }
    image_resizer {
      keep_aspect_ratio_resizer {
        min_dimension: 360
        max_dimension: 1205
        pad_to_max_dimension: true
      }
    }
    object_detection_task {
      task_loss_weight: 1.0
      offset_loss_weight: 1.0
      scale_loss_weight: 0.1
      localization_loss {
        l1_localization_loss {
        }
      }
    }
    object_center_params {
      object_center_loss_weight: 1.0
      min_box_overlap_iou: 0.7
      max_box_predictions: 100
      classification_loss {
        penalty_reduced_logistic_focal_loss {
          alpha: 2.0
          beta: 4.0
        }
      }
    }
    # mask_estimation_task{
    #   task_loss_weight: 4.0
    #   classification_loss {
    #     penalty_reduced_logistic_focal_loss {
    #       alpha: 2.0
    #       beta: 4.0
    #     }
    #   }
    # }
  }
}

train_config: {
  batch_size: 1
  num_steps: 150000

  data_augmentation_options {
    random_horizontal_flip {
    }
  }
  data_augmentation_options {
    random_crop_image {
      min_object_covered: 0.0
      min_aspect_ratio: 0.75
      max_aspect_ratio: 3.0
      min_area: 0.75
      max_area: 1.0
      overlap_thresh: 0.0
    }
  }

  optimizer {
    adam_optimizer: {
      epsilon: 1e-7  # Match tf.keras.optimizers.Adam's default.
      learning_rate: {
        cosine_decay_learning_rate {
          learning_rate_base: 1e-3
          total_steps: 150000
          warmup_learning_rate: 2.5e-4
          warmup_steps: 5000
        }
      }
    }
    use_moving_average: false
  }
  max_number_of_boxes: 100
  unpad_groundtruth_tensors: false

  fine_tune_checkpoint_version: V2
  #fine_tune_checkpoint: ""/home/deploy/ved/centernet_resnet101_v1_fpn_512x512_coco17_tpu-8/checkpoint/ckpt-0""
  fine_tune_checkpoint_type: ""detection""
}

train_input_reader: {
  label_map_path: ""/home/deploy/ved/label_map_potato_l1.pbtxt""
  tf_record_input_reader {
    input_path: ""/home/deploy/ved/potato_l1_3x1_11_train.record""
  }
  load_instance_masks: true
  mask_type: PNG_MASKS
}

eval_config: {
  metrics_set: ""coco_detection_metrics""
  use_moving_averages: false
  num_visualizations: 100
  batch_size: 1
}

eval_input_reader: {
  label_map_path: ""/home/deploy/ved/label_map_potato_l1.pbtxt""
  shuffle: false
  num_epochs: 1
  tf_record_input_reader {
    input_path: ""/home/deploy/ved/potato_l1_3x1_11_val.record""
  }
  mask_type: PNG_MASKS
  load_instance_masks: true
}
```

I was expecting to train the model with different input size.

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Debian 4.9.144-3.1
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): v2.2.0-rc4-8-g2b96f3662b
- Python version: 3.6.3
- CUDA/cuDNN version: 10.1
- GPU model and memory: 11441MiB",anshkumar,b'models:research type:bug',2020-07-19T14:19:18Z,2020-08-03T16:31:01Z,,,,,,,
8907,object detection api train label error,"# Prerequisites

Please answer the following questions for yourself before submitting an issue.

- [ NO] I am using the latest TensorFlow Model Garden release and TensorFlow 2.
- [YES ] I am reporting the issue to the correct repository. (Model Garden official or research directory)
- [YES ] I checked to make sure that this issue has not already been filed.

## 1. The entire URL of the file you are using

https://github.com/tensorflow/models/tree/master/research/...

## 2. Describe the bug

I found out during the object detection api training
The label on some pictures does not match the data I wrote to tfrecord. Even the right picture in the images of TensorBoard is the wrong label. But I used the tfrecord tool to detect and found no wrong label.
The error looks like this:
I have 3 kinds of pictures, the first kind of picture has 3 labels, and the second kind of picture also has three labels, but these three are different from the first kind of label. But when I went to check the images of TensorBoard, I found that the word displayed on the label of the second picture is the word of the label of the first picture, but the position of the box is the correct position of the label of the second picture. the thrid kind  picture still has this problem.

## 3. Steps to reproduce

I again confirmed the tfrecord generation script and regenerated tfrecord, and then deleted all the checkpoints for retraining.
There is still a problem with the picture displayed by TensorBoard.
Then I saved the model from the last checkpoint and directly performed object detection. Like the result of TensorBoard, only the object recognition of the first picture is normal, and only one label of the second picture is normal. The remaining two The label is not displayed, and the third image does not display the label. The results are the same as those displayed by TensorBoard.

## 4. Expected behavior

the data of object detection api receive should is which is the data I store in tfrecord

## 5. Additional context

Include any logs that would be helpful to diagnose the problem.

## 6. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows10
- Mobile device name if the issue happens on a mobile device: None
- TensorFlow installed from (source or binary): pip
- TensorFlow version (use command below): 1.15.0
- Python version: 3.7.7
- Bazel version (if compiling from source): None
- GCC/Compiler version (if compiling from source): None
- CUDA/cuDNN version: CUDA v10.0
- GPU model and memory: 8G

<!-- 
Collect system information using our environment capture script.
https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can also obtain the TensorFlow version with:

1. TensorFlow 1.0
`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

2. TensorFlow 2.0
`python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`
-->
",JiXiaoYao,b'models:research type:bug',2020-07-18T17:57:04Z,2020-07-22T13:55:05Z,,,,,,,
8902,Update README.md,"# Description

> :memo: Please include a summary of the change. 
>  
> * Please also include relevant motivation and context.  
> * List any dependencies that are required for this change.  

## Type of change

For a new feature or function, please create an issue first to discuss it
with us before submitting a pull request.

Note: Please delete options that are not relevant.

- [ ] Bug fix (non-breaking change which fixes an issue)
- [ ] Documentation update
- [ ] TensorFlow 2 migration
- [ ] New feature (non-breaking change which adds functionality)
- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)
- [ ] A new research paper code implementation
- [ ] Other (Specify)

## Tests

> :memo: Please describe the tests that you ran to verify your changes.
>  
> * Provide instructions so we can reproduce.  
> * Please also list any relevant details for your test configuration.  

**Test Configuration**:

## Checklist

- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).
- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).
- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).
- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.
- [ ] I have commented my code, particularly in hard-to-understand areas.
- [ ] I have made corresponding changes to the documentation.
- [ ] My changes generate no new warnings.
- [ ] I have added tests that prove my fix is effective or that my feature works.
",saberkun,b'cla: yes ready to pull',2020-07-18T00:45:47Z,2020-07-18T03:55:27Z,,,,,,,
8895,Adjust frcnn meta arch to multilevel rpn feature,"# Description

> :memo: Adjust frcnn meta arch to multilevel rpn feature.
>  
> * Please also include relevant motivation and context.  
> * List any dependencies that are required for this change.  

## Type of change

For a new feature or function, please create an issue first to discuss it
with us before submitting a pull request.

Note: Please delete options that are not relevant.

- [ ] Bug fix (non-breaking change which fixes an issue)
- [ ] Documentation update
- [ ] TensorFlow 2 migration
- [ ] New feature (non-breaking change which adds functionality)
- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)
- [ ] A new research paper code implementation
- [ ] Other (Specify)

## Tests

> :memo: Please describe the tests that you ran to verify your changes.
>  
> * Provide instructions so we can reproduce.  
> * Please also list any relevant details for your test configuration.  

**Test Configuration**:

## Checklist

- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).
- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).
- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).
- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.
- [x] I have commented my code, particularly in hard-to-understand areas.
- [x] I have made corresponding changes to the documentation.
- [ ] My changes generate no new warnings.
- [x] I have added tests that prove my fix is effective or that my feature works.
",syiming,b'cla: yes ready to pull',2020-07-17T05:38:16Z,2020-08-07T04:22:14Z,,,,,,,
8894,moving fpn message to fpn.proto,"# Description

> :memo: moving fpn message to fpn.proto
>  
> * Please also include relevant motivation and context.  
> * List any dependencies that are required for this change.  

## Type of change

For a new feature or function, please create an issue first to discuss it
with us before submitting a pull request.

Note: Please delete options that are not relevant.

- [ ] Bug fix (non-breaking change which fixes an issue)
- [ ] Documentation update
- [ ] TensorFlow 2 migration
- [ ] New feature (non-breaking change which adds functionality)
- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)
- [ ] A new research paper code implementation
- [x] Other (Adjust proto file for faster rcnn fpn feature extractor)

## Tests

> :memo: Please describe the tests that you ran to verify your changes.
>  
> * Provide instructions so we can reproduce.  
> * Please also list any relevant details for your test configuration.  

**Test Configuration**:

## Checklist

- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).
- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).
- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).
- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.
- [x] I have commented my code, particularly in hard-to-understand areas.
- [x] I have made corresponding changes to the documentation.
- [x] My changes generate no new warnings.
- [x] I have added tests that prove my fix is effective or that my feature works.
",syiming,b'cla: yes ready to pull',2020-07-17T04:59:07Z,2020-08-02T20:35:05Z,,,,,,,
8893,Move to keraslayers fasterrcnn fpn keras feature extractor,"# Description

> :memo: Return keras layers instead of keras models for fasterrcnn fpn keras feature extractor
>  
> * Please also include relevant motivation and context.  
> * List any dependencies that are required for this change.  

## Type of change

For a new feature or function, please create an issue first to discuss it
with us before submitting a pull request.

Note: Please delete options that are not relevant.

- [ ] Bug fix (non-breaking change which fixes an issue)
- [ ] Documentation update
- [ ] TensorFlow 2 migration
- [ ] New feature (non-breaking change which adds functionality)
- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)
- [ ] A new research paper code implementation
- [x] Other (Fix 'unknow graph' error)

## Tests

> :memo: Please describe the tests that you ran to verify your changes.
>  
> * Provide instructions so we can reproduce.  
> * Please also list any relevant details for your test configuration.  

**Test Configuration**:

## Checklist

- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).
- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).
- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).
- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.
- [x] I have commented my code, particularly in hard-to-understand areas.
- [x] I have made corresponding changes to the documentation.
- [ ] My changes generate no new warnings.
- [x] I have added tests that prove my fix is effective or that my feature works.
",syiming,b'cla: yes ready to pull',2020-07-17T04:43:14Z,2020-08-03T18:02:33Z,,,,,,,
8892,"Object Detection API 2.0, error with load checkpoints:  A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used.","# Prerequisites

Please answer the following questions for yourself before submitting an issue.

- [ ] I am using the latest TensorFlow Model Garden release and TensorFlow 2.
- [ ] I am reporting the issue to the correct repository. (Model Garden official or research directory)
- [ ] I checked to make sure that this issue has not already been filed.

## 1. The entire URL of the file you are using

https://github.com/tensorflow/models/tree/master/research/object_detection

## 2. Describe the bug

Thanks for releasing the Object Detection API 2.0. I am trying to build the model on my own dataset. I downloaded the trained file from model zoo [CenterNet HourGlass104 512x512](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md). Then changed the configure file and test the code. A bug comes.
```
WARNING:tensorflow:Unresolved object in checkpoint: (root).model._feature_extractor._network.hourglass_network.1.inner_block.0.inner_block.0.inner_block.0.inner_block.0.decoder_block.1.conv_block.norm.moving_variance
W0716 19:56:53.424076 140587994642240 util.py:144] Unresolved object in checkpoint: (root).model._feature_extractor._network.hourglass_network.1.inner_block.0.inner_block.0.inner_block.0.inner_block.0.decoder_block.1.conv_block.norm.moving_variance
WARNING:tensorflow:Unresolved object in checkpoint: (root).model._feature_extractor._network.hourglass_network.1.inner_block.0.inner_block.0.inner_block.0.inner_block.0.decoder_block.1.skip.conv.kernel
W0716 19:56:53.424108 140587994642240 util.py:144] Unresolved object in checkpoint: (root).model._feature_extractor._network.hourglass_network.1.inner_block.0.inner_block.0.inner_block.0.inner_block.0.decoder_block.1.skip.conv.kernel
WARNING:tensorflow:Unresolved object in checkpoint: (root).model._feature_extractor._network.hourglass_network.1.inner_block.0.inner_block.0.inner_block.0.inner_block.0.decoder_block.1.skip.norm.axis
W0716 19:56:53.424140 140587994642240 util.py:144] Unresolved object in checkpoint: (root).model._feature_extractor._network.hourglass_network.1.inner_block.0.inner_block.0.inner_block.0.inner_block.0.decoder_block.1.skip.norm.axis
WARNING:tensorflow:Unresolved object in checkpoint: (root).model._feature_extractor._network.hourglass_network.1.inner_block.0.inner_block.0.inner_block.0.inner_block.0.decoder_block.1.skip.norm.gamma
W0716 19:56:53.424172 140587994642240 util.py:144] Unresolved object in checkpoint: (root).model._feature_extractor._network.hourglass_network.1.inner_block.0.inner_block.0.inner_block.0.inner_block.0.decoder_block.1.skip.norm.gamma
WARNING:tensorflow:Unresolved object in checkpoint: (root).model._feature_extractor._network.hourglass_network.1.inner_block.0.inner_block.0.inner_block.0.inner_block.0.decoder_block.1.skip.norm.beta
W0716 19:56:53.424204 140587994642240 util.py:144] Unresolved object in checkpoint: (root).model._feature_extractor._network.hourglass_network.1.inner_block.0.inner_block.0.inner_block.0.inner_block.0.decoder_block.1.skip.norm.beta
WARNING:tensorflow:Unresolved object in checkpoint: (root).model._feature_extractor._network.hourglass_network.1.inner_block.0.inner_block.0.inner_block.0.inner_block.0.decoder_block.1.skip.norm.moving_mean
W0716 19:56:53.424236 140587994642240 util.py:144] Unresolved object in checkpoint: (root).model._feature_extractor._network.hourglass_network.1.inner_block.0.inner_block.0.inner_block.0.inner_block.0.decoder_block.1.skip.norm.moving_mean
WARNING:tensorflow:Unresolved object in checkpoint: (root).model._feature_extractor._network.hourglass_network.1.inner_block.0.inner_block.0.inner_block.0.inner_block.0.decoder_block.1.skip.norm.moving_variance
W0716 19:56:53.424268 140587994642240 util.py:144] Unresolved object in checkpoint: (root).model._feature_extractor._network.hourglass_network.1.inner_block.0.inner_block.0.inner_block.0.inner_block.0.decoder_block.1.skip.norm.moving_variance
WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.
W0716 19:56:53.424301 140587994642240 util.py:152] **A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.**
```
**A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.**

I do not know how to resolve this issue!


## 6. System information

- OS Platform and Distribution: Linux Ubuntu 18.04
- TensorFlow installed from (source or binary): installed as the official guide and no error occurs.
- TensorFlow version (use command below): tensorflow 2.2.0
- Python version: 3.6
- CUDA/cuDNN version: CUDA 10.2, CuDNN 7.6
- GPU model and memory: 2x 2080 Ti

",Derekabc,b'models:research type:bug',2020-07-17T00:49:44Z,2020-09-29T02:01:22Z,,,,,,,
8891,Add another open source colab,"# Description

> :memo: Please include a summary of the change. 
>  
> * Please also include relevant motivation and context.  
> * List any dependencies that are required for this change.  

## Type of change

For a new feature or function, please create an issue first to discuss it
with us before submitting a pull request.

Note: Please delete options that are not relevant.

- [ ] Bug fix (non-breaking change which fixes an issue)
- [ ] Documentation update
- [ ] TensorFlow 2 migration
- [ ] New feature (non-breaking change which adds functionality)
- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)
- [ ] A new research paper code implementation
- [ ] Other (Specify)

## Tests

> :memo: Please describe the tests that you ran to verify your changes.
>  
> * Provide instructions so we can reproduce.  
> * Please also list any relevant details for your test configuration.  

**Test Configuration**:

## Checklist

- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).
- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).
- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).
- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.
- [ ] I have commented my code, particularly in hard-to-understand areas.
- [ ] I have made corresponding changes to the documentation.
- [ ] My changes generate no new warnings.
- [ ] I have added tests that prove my fix is effective or that my feature works.
",kmindspark,b'cla: yes ready to pull',2020-07-16T19:56:30Z,2020-07-18T02:54:11Z,,,,,,,
8890,Images 2,"# Description

> :memo: Please include a summary of the change. 
>  
> * Please also include relevant motivation and context.  
> * List any dependencies that are required for this change.  

## Type of change

For a new feature or function, please create an issue first to discuss it
with us before submitting a pull request.

Note: Please delete options that are not relevant.

- [ ] Bug fix (non-breaking change which fixes an issue)
- [ ] Documentation update
- [ ] TensorFlow 2 migration
- [ ] New feature (non-breaking change which adds functionality)
- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)
- [ ] A new research paper code implementation
- [ ] Other (Specify)

## Tests

> :memo: Please describe the tests that you ran to verify your changes.
>  
> * Provide instructions so we can reproduce.  
> * Please also list any relevant details for your test configuration.  

**Test Configuration**:

## Checklist

- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).
- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).
- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).
- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.
- [ ] I have commented my code, particularly in hard-to-understand areas.
- [ ] I have made corresponding changes to the documentation.
- [ ] My changes generate no new warnings.
- [ ] I have added tests that prove my fix is effective or that my feature works.
",milnar,b'cla: no',2020-07-16T19:33:56Z,2020-07-16T19:35:06Z,,,,,,,
8889,Image,"# Description

> :memo: Please include a summary of the change. 
>  
> * Please also include relevant motivation and context.  
> * List any dependencies that are required for this change.  

## Type of change

For a new feature or function, please create an issue first to discuss it
with us before submitting a pull request.

Note: Please delete options that are not relevant.

- [ ] Bug fix (non-breaking change which fixes an issue)
- [ ] Documentation update
- [ ] TensorFlow 2 migration
- [ ] New feature (non-breaking change which adds functionality)
- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)
- [ ] A new research paper code implementation
- [ ] Other (Specify)

## Tests

> :memo: Please describe the tests that you ran to verify your changes.
>  
> * Provide instructions so we can reproduce.  
> * Please also list any relevant details for your test configuration.  

**Test Configuration**:

## Checklist

- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).
- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).
- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).
- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.
- [ ] I have commented my code, particularly in hard-to-understand areas.
- [ ] I have made corresponding changes to the documentation.
- [ ] My changes generate no new warnings.
- [ ] I have added tests that prove my fix is effective or that my feature works.
",milnar,b'cla: no',2020-07-16T19:29:13Z,2020-08-14T20:53:45Z,,,,,,,
8888,Object Detection API Demo: Instance Segmentation example doesn't work,"# Prerequisites

Please answer the following questions for yourself before submitting an issue.

- [x] I am using the latest TensorFlow Model Garden release and TensorFlow 2.
- [x] I am reporting the issue to the correct repository. (Model Garden official or research directory)
- [x] I checked to make sure that this issue has not already been filed.

## 1. The entire URL of the file you are using

https://github.com/tensorflow/models/blob/master/research/object_detection/colab_tutorials/object_detection_tutorial.ipynb

## 2. Describe the bug

The last section of the colab notebook is supposed to show inference using a pretrained Mask-RCNN. However, it throws the following errors:

 ---------------------------------------------------------------------------
> AttributeError                            Traceback (most recent call last)
> <ipython-input-20-31bf89ff98cf> in <module>()
> ----> 1 masking_model.output_shapes

>AttributeError: 'AutoTrackable' object has no attribute 'output_shapes'

and,

 ---------------------------------------------------------------------------

> TypeError                                 Traceback (most recent call last)
> <ipython-input-21-25f0f9a75087> in <module>()
>      1 for image_path in TEST_IMAGE_PATHS:
> ----> 2   show_inference(masking_model, image_path)

> 2 frames
> /usr/local/lib/python3.6/dist-packages/object_detection/utils/ops.py in reframe_box_masks_to_image_masks(box_masks, >boxes, image_height, image_width, resize_method)
>    823     as `box_masks`.
>    824   """"""
>--> 825   resize_method = 'nearest' if box_masks.dtype == tf.uint8 else resize_method
>    826   # TODO(rathodv): Make this a public function.
>    827   def reframe_box_masks_to_image_masks_default():

>TypeError: data type not understood

## 3. Steps to reproduce

Run the colab.

",khanx169,b'models:research stat:awaiting response type:bug',2020-07-16T18:43:02Z,2020-07-28T04:32:06Z,,,,,,,
8883,TF2 Object Detection API training script model_main_t2 not working - Stuck on Waiting for new checkpoint - Timed-out waiting for a checkpoint,"# Prerequisites

Please answer the following questions for yourself before submitting an issue.

- [Y ] I am using the latest TensorFlow Model Garden release and TensorFlow 2.
- [Y ] I am reporting the issue to the correct repository. (Model Garden official or research directory)
- [ Y] I checked to make sure that this issue has not been filed already.

## 1. The entire URL of the file you are using

https://github.com/tensorflow/models/tree/master/research/object_detection/model_main_tf2.py

## 2. Describe the bug

After running for a while, model_main_t2 get stuck on ""Waiting for new checkpoint"". Then ends with error: ""Timed-out waiting for a checkpoint""

## 3. Steps to reproduce

https://github.com/IvanBrasilico/ajna_bbox
The steps of tf2 installation are on the project README. Basically the steps described in the documentation (generate tf_records for training, download a model definition and check-point, edit pipeline.config with paths of tfrecord, run model_main_tf2.

## 4. Expected behavior

The expected behavior was to do the training procedure or at least pop an error message.

## 5. Additional context

The complete model_main_tf2.py console output is on the end of report

## 6. System information

Important to register that the example colab repository eager_few_shot_od_training_tf2.ipynb is running and training the same model, in the same virtualenv of the same machine.

- Linux Ubuntu 16.04:
- Python 3.6 ven
- Tensorlow 2.2 installed by pip
- CUDA/cuDNN version: Cuda 11 installed by apt
- GPU model and memory: 1050ti 4GB

Complete environment information:

https://github.com/IvanBrasilico/ajna_bbox/blob/master/tf_env.txt


**Complete model_main_tf2 output:**

(venv) ivan@ivan-G7-7588:~/PycharmProjects/ajna_bbox$ python models/research/object_detection/model_main_tf2.py --model_dir=/home/ivan/PycharmProjects/ajna_bbox/bases/models/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8/ --checkpoint_dir=/home/ivan/PycharmProjects/ajna_bbox/bases/models/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8/checkpoint --alsologtostderr  --pipeline_config_path=bases/models/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8/pipeline.config --use-tpu=true
WARNING:tensorflow:Forced number of epochs for all eval validations to be 1.
W0715 23:32:23.856509 140079432734464 model_lib_v2.py:905] Forced number of epochs for all eval validations to be 1.
INFO:tensorflow:Maybe overwriting sample_1_of_n_eval_examples: None
I0715 23:32:23.856632 140079432734464 config_util.py:552] Maybe overwriting sample_1_of_n_eval_examples: None
INFO:tensorflow:Maybe overwriting use_bfloat16: False
I0715 23:32:23.856686 140079432734464 config_util.py:552] Maybe overwriting use_bfloat16: False
INFO:tensorflow:Maybe overwriting eval_num_epochs: 1
I0715 23:32:23.856735 140079432734464 config_util.py:552] Maybe overwriting eval_num_epochs: 1
WARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.
W0715 23:32:23.856801 140079432734464 model_lib_v2.py:920] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.
2020-07-15 23:32:23.881471: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-07-15 23:32:23.923686: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-15 23:32:23.924041: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce GTX 1050 Ti computeCapability: 6.1
coreClock: 1.62GHz coreCount: 6 deviceMemorySize: 3.95GiB deviceMemoryBandwidth: 104.43GiB/s
2020-07-15 23:32:23.924195: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/cuda-9.0/lib64:/usr/local/cuda/extras/CUPTI/lib64
2020-07-15 23:32:23.924305: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcublas.so.10'; dlerror: libcublas.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/cuda-9.0/lib64:/usr/local/cuda/extras/CUPTI/lib64
2020-07-15 23:32:23.925568: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-07-15 23:32:23.925901: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-07-15 23:32:23.928778: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-07-15 23:32:23.928903: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusparse.so.10'; dlerror: libcusparse.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/cuda-9.0/lib64:/usr/local/cuda/extras/CUPTI/lib64
2020-07-15 23:32:23.932572: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-07-15 23:32:23.932610: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1598] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2020-07-15 23:32:23.932881: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-07-15 23:32:23.939320: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 2299965000 Hz
2020-07-15 23:32:23.939775: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x657f610 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-07-15 23:32:23.939791: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-07-15 23:32:23.941028: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-07-15 23:32:23.941041: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      
WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.
W0715 23:32:23.947229 140079432734464 dataset_builder.py:83] num_readers has been reduced to 1 to match input file shards.
WARNING:tensorflow:From /home/ivan/PycharmProjects/ajna_bbox/venv/lib/python3.6/site-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_deterministic`.
W0715 23:32:23.949348 140079432734464 deprecation.py:323] From /home/ivan/PycharmProjects/ajna_bbox/venv/lib/python3.6/site-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_deterministic`.
WARNING:tensorflow:From /home/ivan/PycharmProjects/ajna_bbox/venv/lib/python3.6/site-packages/object_detection/builders/dataset_builder.py:175: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.map()
W0715 23:32:23.965300 140079432734464 deprecation.py:323] From /home/ivan/PycharmProjects/ajna_bbox/venv/lib/python3.6/site-packages/object_detection/builders/dataset_builder.py:175: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.map()
WARNING:tensorflow:From /home/ivan/PycharmProjects/ajna_bbox/venv/lib/python3.6/site-packages/object_detection/inputs.py:79: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.
W0715 23:32:29.178085 140079432734464 deprecation.py:323] From /home/ivan/PycharmProjects/ajna_bbox/venv/lib/python3.6/site-packages/object_detection/inputs.py:79: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.
WARNING:tensorflow:From /home/ivan/PycharmProjects/ajna_bbox/venv/lib/python3.6/site-packages/object_detection/inputs.py:259: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
W0715 23:32:30.630500 140079432734464 deprecation.py:323] From /home/ivan/PycharmProjects/ajna_bbox/venv/lib/python3.6/site-packages/object_detection/inputs.py:259: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
INFO:tensorflow:Waiting for new checkpoint at /home/ivan/PycharmProjects/ajna_bbox/bases/models/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8/checkpoint
I0715 23:32:33.767113 140079432734464 checkpoint_utils.py:125] Waiting for new checkpoint at /home/ivan/PycharmProjects/ajna_bbox/bases/models/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8/checkpoint
INFO:tensorflow:Found new checkpoint at /home/ivan/PycharmProjects/ajna_bbox/bases/models/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8/checkpoint/ckpt-0
I0715 23:32:33.767870 140079432734464 checkpoint_utils.py:134] Found new checkpoint at /home/ivan/PycharmProjects/ajna_bbox/bases/models/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8/checkpoint/ckpt-0
WARNING:tensorflow:From /home/ivan/PycharmProjects/ajna_bbox/venv/lib/python3.6/site-packages/object_detection/eval_util.py:854: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
W0715 23:33:02.120177 140079432734464 deprecation.py:323] From /home/ivan/PycharmProjects/ajna_bbox/venv/lib/python3.6/site-packages/object_detection/eval_util.py:854: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
INFO:tensorflow:Finished eval step 0
I0715 23:33:11.245014 140079432734464 model_lib_v2.py:782] Finished eval step 0
WARNING:tensorflow:From /home/ivan/PycharmProjects/ajna_bbox/venv/lib/python3.6/site-packages/object_detection/utils/visualization_utils.py:618: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0715 23:33:11.261951 140079432734464 deprecation.py:323] From /home/ivan/PycharmProjects/ajna_bbox/venv/lib/python3.6/site-packages/object_detection/utils/visualization_utils.py:618: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
INFO:tensorflow:Performing evaluation on 21 images.
I0715 23:33:30.778897 140079432734464 coco_evaluation.py:237] Performing evaluation on 21 images.
creating index...
index created!
INFO:tensorflow:Loading and preparing annotation results...
I0715 23:33:30.779220 140079432734464 coco_tools.py:116] Loading and preparing annotation results...
INFO:tensorflow:DONE (t=0.00s)
I0715 23:33:30.780228 140079432734464 coco_tools.py:138] DONE (t=0.00s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=0.03s).
Accumulating evaluation results...
DONE (t=0.00s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.024
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.024
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.024
INFO:tensorflow:Eval metrics at step 0
I0715 23:33:30.815683 140079432734464 model_lib_v2.py:836] Eval metrics at step 0
INFO:tensorflow:        + DetectionBoxes_Precision/mAP: 0.000143
I0715 23:33:30.818211 140079432734464 model_lib_v2.py:839]      + DetectionBoxes_Precision/mAP: 0.000143
INFO:tensorflow:        + DetectionBoxes_Precision/mAP@.50IOU: 0.000286
I0715 23:33:30.818874 140079432734464 model_lib_v2.py:839]      + DetectionBoxes_Precision/mAP@.50IOU: 0.000286
INFO:tensorflow:        + DetectionBoxes_Precision/mAP@.75IOU: 0.000000
I0715 23:33:30.819247 140079432734464 model_lib_v2.py:839]      + DetectionBoxes_Precision/mAP@.75IOU: 0.000000
INFO:tensorflow:        + DetectionBoxes_Precision/mAP (small): -1.000000
I0715 23:33:30.819588 140079432734464 model_lib_v2.py:839]      + DetectionBoxes_Precision/mAP (small): -1.000000
INFO:tensorflow:        + DetectionBoxes_Precision/mAP (medium): -1.000000
I0715 23:33:30.819919 140079432734464 model_lib_v2.py:839]      + DetectionBoxes_Precision/mAP (medium): -1.000000
INFO:tensorflow:        + DetectionBoxes_Precision/mAP (large): 0.000215
I0715 23:33:30.820254 140079432734464 model_lib_v2.py:839]      + DetectionBoxes_Precision/mAP (large): 0.000215
INFO:tensorflow:        + DetectionBoxes_Recall/AR@1: 0.000000
I0715 23:33:30.820581 140079432734464 model_lib_v2.py:839]      + DetectionBoxes_Recall/AR@1: 0.000000
INFO:tensorflow:        + DetectionBoxes_Recall/AR@10: 0.023810
I0715 23:33:30.820914 140079432734464 model_lib_v2.py:839]      + DetectionBoxes_Recall/AR@10: 0.023810
INFO:tensorflow:        + DetectionBoxes_Recall/AR@100: 0.023810
I0715 23:33:30.821241 140079432734464 model_lib_v2.py:839]      + DetectionBoxes_Recall/AR@100: 0.023810
INFO:tensorflow:        + DetectionBoxes_Recall/AR@100 (small): -1.000000
I0715 23:33:30.821578 140079432734464 model_lib_v2.py:839]      + DetectionBoxes_Recall/AR@100 (small): -1.000000
INFO:tensorflow:        + DetectionBoxes_Recall/AR@100 (medium): -1.000000
I0715 23:33:30.821907 140079432734464 model_lib_v2.py:839]      + DetectionBoxes_Recall/AR@100 (medium): -1.000000
INFO:tensorflow:        + DetectionBoxes_Recall/AR@100 (large): 0.023810
I0715 23:33:30.822265 140079432734464 model_lib_v2.py:839]      + DetectionBoxes_Recall/AR@100 (large): 0.023810
INFO:tensorflow:        + Loss/localization_loss: 0.189787
I0715 23:33:30.822557 140079432734464 model_lib_v2.py:839]      + Loss/localization_loss: 0.189787
INFO:tensorflow:        + Loss/classification_loss: 1.298645
I0715 23:33:30.822857 140079432734464 model_lib_v2.py:839]      + Loss/classification_loss: 1.298645
INFO:tensorflow:        + Loss/regularization_loss: 0.176113
I0715 23:33:30.823152 140079432734464 model_lib_v2.py:839]      + Loss/regularization_loss: 0.176113
INFO:tensorflow:        + Loss/total_loss: 1.664544
I0715 23:33:30.823446 140079432734464 model_lib_v2.py:839]      + Loss/total_loss: 1.664544
INFO:tensorflow:Waiting for new checkpoint at /home/ivan/PycharmProjects/ajna_bbox/bases/models/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8/checkpoint
I0715 23:37:33.829480 140079432734464 checkpoint_utils.py:125] Waiting for new checkpoint at /home/ivan/PycharmProjects/ajna_bbox/bases/models/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8/checkpoint
INFO:tensorflow:Timed-out waiting for a checkpoint.
I0716 00:37:33.181403 140079432734464 checkpoint_utils.py:188] Timed-out waiting for a checkpoint.
",IvanBrasilico,b'models:research type:bug',2020-07-16T12:13:23Z,2020-07-30T11:03:32Z,,,,,,,
8877,ModuleNotFoundError: No module named 'tensorflow.compat.v1',"# Prerequisites

Please answer the following questions for yourself before submitting an issue.

- [ ] I am using the latest TensorFlow Model Garden release and TensorFlow 2.
- [x] I am reporting the issue to the correct repository. (Model Garden official or research directory)
- [x] I checked to make sure that this issue has not already been filed.

## 1. The entire URL of the file you are using

https://github.com/tensorflow/models/tree/master/research/feelvos

## 2. Describe the bug

I got the following error when running `bash train.sh`.
The README doesn't tell us which TF to use.

The backward compatibility of TF **is REALLY AWFUL**.

```
Traceback (most recent call last):
  File ""/mnt/lustre/xiehaozhe/Development/feelvos/train.py"", line 24, in <module>
    from feelvos import model
  File ""/mnt/lustre/xiehaozhe/Development/feelvos/model.py"", line 58, in <module>
    from deeplab import model
  File ""/mnt/lustre/xiehaozhe/Development/feelvos/deeplab/model.py"", line 58, in <module>
    from deeplab.core import feature_extractor
  File ""/mnt/lustre/xiehaozhe/Development/feelvos/deeplab/core/feature_extractor.py"", line 21, in <module>
    import tensorflow.compat.v1 as tf
ModuleNotFoundError: No module named 'tensorflow.compat.v1'
```

## 3. Steps to reproduce

```bash
bash train.sh
```

## 4. Expected behavior

The program runs normally without raising `ModuleNotFoundError: No module named 'tensorflow.compat.v1'`.

## 5. Additional context

None

## 6. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Cent OS 7.3
- Mobile device name if the issue happens on a mobile device: N/a
- TensorFlow installed from (source or binary): Binary
- TensorFlow version (use command below): 1.12.3
- Python version: 3.6.5
- Bazel version (if compiling from source): N/a
- GCC/Compiler version (if compiling from source): 5.4.0
- CUDA/cuDNN version: 9.0
- GPU model and memory: NVIDIA TITAN Xp / 12GB

<!-- 
Collect system information using our environment capture script.
https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can also obtain the TensorFlow version with:

1. TensorFlow 1.0
`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

2. TensorFlow 2.0
`python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`
-->
",hzxie,b'models:research type:bug',2020-07-16T08:05:40Z,2020-07-17T02:46:20Z,,,,,,,
8870,DeepLab: Cityscapes splits refactoring,"# Description

Refactoring, follow-up for https://github.com/tensorflow/models/pull/8866

## Type of change

- [x] Bug fix (non-breaking change which fixes an issue)

## Tests

```
python deeplab/train.py \
    --logtostderr \
    --training_number_of_steps=100 \
    --train_split=""train_fine"" \
    --model_variant=""xception_65"" \
    --fine_tune_batch_norm=False \
    --atrous_rates=6 \
    --atrous_rates=12 \
    --atrous_rates=18 \
    --output_stride=16 \
    --decoder_output_stride=4 \
    --train_crop_size=""769,769"" \
    --train_batch_size=1 \
    --dataset=""cityscapes"" \
    --tf_initial_checkpoint=${PATH_TO_INITIAL_CHECKPOINT} \
    --train_logdir=${PATH_TO_TRAIN_DIR} \
    --dataset_dir=${PATH_TO_DATASET}
```

```
python deeplab/eval.py \
    --logtostderr \
    --eval_split=""val_fine"" \
    --model_variant=""xception_65"" \
    --atrous_rates=6 \
    --atrous_rates=12 \
    --atrous_rates=18 \
    --output_stride=16 \
    --decoder_output_stride=4 \
    --eval_crop_size=""1025,2049"" \
    --dataset=""cityscapes"" \
    --max_number_of_evaluations=1 \
    --checkpoint_dir=${PATH_TO_CHECKPOINT} \
    --eval_logdir=${PATH_TO_EVAL_DIR} \
    --dataset_dir=${PATH_TO_DATASET}
```

```
python deeplab/vis.py \
    --logtostderr \
    --vis_split=""val_fine"" \
    --model_variant=""xception_65"" \
    --atrous_rates=6 \
    --atrous_rates=12 \
    --atrous_rates=18 \
    --output_stride=16 \
    --decoder_output_stride=4 \
    --vis_crop_size=""1025,2049"" \
    --dataset=""cityscapes"" \
    --max_number_of_iterations=1 \
    --colormap_type=""cityscapes"" \
    --checkpoint_dir=${PATH_TO_CHECKPOINT} \
    --vis_logdir=${PATH_TO_VIS_DIR} \
    --dataset_dir=${PATH_TO_DATASET}
```

- Ubuntu 18.04.4
- CUDA 10.2
- Tensorflow 1.15.2

## Checklist

- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).
- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).
- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).
- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.
- [ ] I have commented my code, particularly in hard-to-understand areas.
- [ ] I have made corresponding changes to the documentation.
- [x] My changes generate no new warnings.
- [ ] I have added tests that prove my fix is effective or that my feature works.
",ruslo,b'cla: yes',2020-07-15T05:47:15Z,2020-07-16T16:36:32Z,,,,,,,
8868,Issues with models/official/nlp/bert/run_pretraining.py,"Hello,

I'm using 
https://github.com/tensorflow/models/blob/master/official/nlp/bert/run_pretraining.py
to pre-train bert on my custom data. I'm using tf-nightly and training the model on cloud TPU. 

The code uses model_training_utils.run_customized_training_loop(), which has been deprecated and I get ""Unable to destroy remote tensor handles. If you are running a tf.function, it usually indicates some op in the graph gets an error"" from a line in that function.

Here is the error log:

```
***** Number of cores used :  32
I0715 00:59:07.309198 140290240782464 run_pretraining.py:178] Training using customized training loop TF 2.0 with distributedstrategy.
WARNING:tensorflow:From research/bert/pretraining/training/run_pretraining.py:165: run_customized_training_loop (from official.nlp.bert.model_training_utils) is deprecated and will be removed in a future version.
Instructions for updating:
This function is deprecated and we do not expect adding new functionalities. Please do not have your code depending on this library.
W0715 00:59:07.309652 140290240782464 deprecation.py:323] From research/bert/pretraining/training/run_pretraining.py:165: run_customized_training_loop (from official.nlp.bert.model_training_utils) is deprecated and will be removed in a future version.
Instructions for updating:
This function is deprecated and we do not expect adding new functionalities. Please do not have your code depending on this library.
I0715 00:59:36.497698 140290240782464 optimization.py:89] using Adamw optimizer
2020-07-15 00:59:37.604910: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'steps' with dtype int32
	 [[{{node steps}}]]
2020-07-15 01:00:20.527288: W tensorflow/core/common_runtime/executor.cc:1086] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'steps' with dtype int32
	 [[{{node steps}}]]
Traceback (most recent call last):
  File ""research/bert/pretraining/training/run_pretraining.py"", line 219, in <module>
    app.run(main)
  File ""/opt/virtualenv/pretrain/lib/python3.6/site-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/opt/virtualenv/pretrain/lib/python3.6/site-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""research/bert/pretraining/training/run_pretraining.py"", line 215, in main
    run_bert_pretrain(strategy)
  File ""research/bert/pretraining/training/run_pretraining.py"", line 201, in run_bert_pretrain
    custom_callbacks=custom_callbacks)
  File ""research/bert/pretraining/training/run_pretraining.py"", line 165, in run_customized_training
    custom_callbacks=custom_callbacks)
  File ""/opt/virtualenv/pretrain/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py"", line 324, in new_func
    return func(*args, **kwargs)
  File ""/opt/virtualenv/pretrain/lib/python3.6/site-packages/official/nlp/bert/model_training_utils.py"", line 482, in run_customized_training_loop
    train_loss = _float_metric_value(train_loss_metric)
  File ""/opt/virtualenv/pretrain/lib/python3.6/site-packages/official/nlp/bert/model_training_utils.py"", line 75, in _float_metric_value
    return metric.result().numpy().astype(float)
  File ""/opt/virtualenv/pretrain/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 1064, in numpy
    maybe_arr = self._numpy()  # pylint: disable=protected-access
  File ""/opt/virtualenv/pretrain/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 1032, in _numpy
2020-07-15 01:02:01.903083: W tensorflow/core/distributed_runtime/eager/remote_tensor_handle_data.cc:76] Unable to destroy remote tensor handles. If you are running a tf.function, it usually indicates some op in the graph gets an error: 3 root error(s) found.
  (0) Out of range: {{function_node __inference_train_steps_217694}} {{function_node __inference_train_steps_217694_15939018961085879472_10}} End of sequence
	 [[{{node while/body/_1/while/IteratorGetNext_18}}]]
	 [[while/cluster_while_body_198928/_execute_22_0/_964]]
	 [[while/LoopCond/_1251/_244]]
Additional GRPC error information from remote target /job:worker/replica:0/task:2/device:TPU:5:
:{""created"":""@1594774842.995987202"",""description"":""Error received from peer ipv4:10.240.1.5:8470"",""file"":""third_party/grpc/src/core/lib/surface/call.cc"",""file_line"":1062,""grpc_message"":""{{function_node __inference_train_steps_217694_15939018961085879472_10}} End of sequence\n\t [[{{node while/body/_1/while/IteratorGetNext_18}}]]\n\t [[while/cluster_while_body_198928/_execute_22_0/_964]]\n\t [[while/LoopCond/_1251/_244]]"",""grpc_status"":11}
  (1) Out of range: {{function_node __inference_train_steps_217694}} End of sequence
	 [[{{node while/body/_1/while/IteratorGetNext_18}}]]
Additional GRPC error information from remote target /job:worker/replica:0/task:2:
:{""created"":""@1594774842.994945378"",""description"":""Error received from peer ipv4:10.240.1.5:8470"",""file"":""third_party/grpc/src/core/lib/surface/call.cc"",""file_line"":1062,""grpc_message"":""End of sequence\n\t [[{{node while/body/_1/while/IteratorGetNext_18}}]]"",""grpc_status"":11}
	 [[GroupCrossDeviceControlEdges_0/TPUVariableReshard/last_iteration/_16617246711369326259/_7/_796]]
	 [[tpu_compile_succeeded_assert/_6992992333505467331/_3/_832]]
  (2) Out of range: {{function_node __inference_train_steps_217694}} End of sequence
	 [[{{node while/body/_1/while/IteratorGetNext_18}}]]
Additional GRPC error information from remote target /job:worker/replica:0/task:2:
:{""created"":""@1594774842.994945378"",""description"":""Error received from peer ipv4:10.240.1.5:8470"",""file"":""third_party/grpc/src/core/lib/surface/call.cc"",""file_line"":1062,""grpc_message"":""End of sequence\n\t [[{{node while/body/_1/while/IteratorGetNext_18}}]]"",""grpc_status"":11}
	 [[GroupCrossDeviceControlEdges_0/TPUVariableReshard/last_iteration/_16617246711369326259/_7/_796]]
0 successful operations.
30 derived errors ignored.
    six.raise_from(core._status_to_exception(e.code, e.message), None)  # pylint: disable=protected-access
  File ""<string>"", line 3, in raise_from
tensorflow.python.framework.errors_impl.OutOfRangeError: 3 root error(s) found.
  (0) Out of range: {{function_node __inference_train_steps_217694}} {{function_node __inference_train_steps_217694_15939018961085879472_10}} End of sequence
	 [[{{node while/body/_1/while/IteratorGetNext_18}}]]
	 [[while/cluster_while_body_198928/_execute_22_0/_964]]
	 [[while/LoopCond/_1251/_244]]
Additional GRPC error information from remote target /job:worker/replica:0/task:2/device:TPU:5:
:{""created"":""@1594774842.995987202"",""description"":""Error received from peer ipv4:10.240.1.5:8470"",""file"":""third_party/grpc/src/core/lib/surface/call.cc"",""file_line"":1062,""grpc_message"":""{{function_node __inference_train_steps_217694_15939018961085879472_10}} End of sequence\n\t [[{{node while/body/_1/while/IteratorGetNext_18}}]]\n\t [[while/cluster_while_body_198928/_execute_22_0/_964]]\n\t [[while/LoopCond/_1251/_244]]"",""grpc_status"":11}
  (1) Out of range: {{function_node __inference_train_steps_217694}} End of sequence
	 [[{{node while/body/_1/while/IteratorGetNext_18}}]]
Additional GRPC error information from remote target /job:worker/replica:0/task:2:
:{""created"":""@1594774842.994945378"",""description"":""Error received from peer ipv4:10.240.1.5:8470"",""file"":""third_party/grpc/src/core/lib/surface/call.cc"",""file_line"":1062,""grpc_message"":""End of sequence\n\t [[{{node while/body/_1/while/IteratorGetNext_18}}]]"",""grpc_status"":11}
	 [[GroupCrossDeviceControlEdges_0/TPUVariableReshard/last_iteration/_16617246711369326259/_7/_796]]
	 [[tpu_compile_succeeded_assert/_6992992333505467331/_3/_832]]
  (2) Out of range: {{function_node __inference_train_steps_217694}} End of sequence
	 [[{{node while/body/_1/while/IteratorGetNext_18}}]]
Additional GRPC error information from remote target /job:worker/replica:0/task:2:
:{""created"":""@1594774842.994945378"",""description"":""Error received from peer ipv4:10.240.1.5:8470"",""file"":""third_party/grpc/src/core/lib/surface/call.cc"",""file_line"":1062,""grpc_message"":""End of sequence\n\t [[{{node while/body/_1/while/IteratorGetNext_18}}]]"",""grpc_status"":11}
	 [[GroupCrossDeviceControlEdges_0/TPUVariableReshard/last_iteration/_16617246711369326259/_7/_796]]
0 successful operations.

```

I've also tried using Tensorflow 2.2.0 and the r 2.2.0 branch codes, I get a similar error. 

I didn't have this issue when running the run_classifer.py and that did run ok. 

Any thoughts are appreciated. Thank you.",aidad,b'models:official type:bug',2020-07-15T01:55:12Z,2020-07-24T19:44:30Z,,,,,,,
8866,DeepLab: Fix generation of tfrecord for Cityscapes,"# Description

Fix generation of tfrecord for Cityscapes and update documentation to use the correct split `--train_split=""train_fine""`/`--eval_split=""val_fine""`.

## Type of change

- [x] Bug fix (non-breaking change which fixes an issue)

## Tests

```
python deeplab/train.py \
    --logtostderr \
    --training_number_of_steps=100 \
    --train_split=""train_fine"" \
    --model_variant=""xception_65"" \
    --fine_tune_batch_norm=False \
    --atrous_rates=6 \
    --atrous_rates=12 \
    --atrous_rates=18 \
    --output_stride=16 \
    --decoder_output_stride=4 \
    --train_crop_size=""769,769"" \
    --train_batch_size=1 \
    --dataset=""cityscapes"" \
    --tf_initial_checkpoint=${PATH_TO_INITIAL_CHECKPOINT} \
    --train_logdir=${PATH_TO_TRAIN_DIR} \
    --dataset_dir=${PATH_TO_DATASET}
```

```
python deeplab/eval.py \
    --logtostderr \
    --eval_split=""val_fine"" \
    --model_variant=""xception_65"" \
    --atrous_rates=6 \
    --atrous_rates=12 \
    --atrous_rates=18 \
    --output_stride=16 \
    --decoder_output_stride=4 \
    --eval_crop_size=""1025,2049"" \
    --dataset=""cityscapes"" \
    --max_number_of_evaluations=1 \
    --checkpoint_dir=${PATH_TO_CHECKPOINT} \
    --eval_logdir=${PATH_TO_EVAL_DIR} \
    --dataset_dir=${PATH_TO_DATASET}
```

```
python deeplab/vis.py \
    --logtostderr \
    --vis_split=""val_fine"" \
    --model_variant=""xception_65"" \
    --atrous_rates=6 \
    --atrous_rates=12 \
    --atrous_rates=18 \
    --output_stride=16 \
    --decoder_output_stride=4 \
    --vis_crop_size=""1025,2049"" \
    --dataset=""cityscapes"" \
    --max_number_of_iterations=1 \
    --colormap_type=""cityscapes"" \
    --checkpoint_dir=${PATH_TO_CHECKPOINT} \
    --vis_logdir=${PATH_TO_VIS_DIR} \
    --dataset_dir=${PATH_TO_DATASET}
```

- Ubuntu 18.04.4
- CUDA 10.2
- Tensorflow 1.15.2

## Checklist

- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).
- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).
- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).
- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.
- [ ] I have commented my code, particularly in hard-to-understand areas.
- [x] I have made corresponding changes to the documentation.
- [x] My changes generate no new warnings.
- [ ] I have added tests that prove my fix is effective or that my feature works.
",ruslo,b'cla: yes',2020-07-14T20:26:35Z,2020-07-15T18:12:03Z,,,,,,,
8863,Model Zoo Not found,"# Prerequisites

Please answer the following questions for yourself before submitting an issue.

- [No] I am using the latest TensorFlow Model Garden release and TensorFlow 2.
- [Yes] I am reporting the issue to the correct repository. (Model Garden official or research directory)
- [Yes] I checked to make sure that this issue has not already been filed.

## 1. The entire URL of the file you are using

https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md

## 2. Describe the bug

I tried to download a checkpoint from the detection model zoo but it is showing Error 404 now. The model zoo was available a few days ago.

## 3. Steps to reproduce

1. Copy the following URL in your browser:
https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md

## 4. Expected behavior

I expected a model zoo there where I would find a model for fine-tuning my network.

## 5. Additional context

Include any logs that would be helpful to diagnose the problem.

## 6. System information

- OS Platform and Distribution: (Linux Ubuntu 16.04
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): 1.14
- Python version: 3.5.2
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 10.0.130
- GPU model and memory: RTX 2080Ti 12 GB

<!-- 
Collect system information using our environment capture script.
https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can also obtain the TensorFlow version with:

1. TensorFlow 1.0
`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

2. TensorFlow 2.0
`python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`
-->


",mnbrshd,b'models:research type:bug',2020-07-14T09:35:18Z,2020-07-14T11:59:39Z,,,,,,,
8855,AttributeError: 'SSDResNet50V1FpnKerasFeatureExtractor' object has no attribute 'restore_from_classification_checkpoint_fn',"# Prerequisites

Please answer the following questions for yourself before submitting an issue.

- [x] I am using the latest TensorFlow Model Garden release and TensorFlow 2.
- [x] I am reporting the issue to the correct repository. (Model Garden official or research directory)
- [x] I checked to make sure that this issue has not been filed already.

## 1. The entire URL of the file you are using

https://github.com/tensorflow/models/tree/master/official/...

## 2. Describe the bug

I followed this official documentation:
https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/training.html#training-the-model

I am using training/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8, have edited its config file and all as  per the docs.
When I run train.py I get the error
```I0713 11:22:44.929779 139813510887232 sync_replicas_optimizer.py:187] SyncReplicasV2: replicas_to_aggregate=8; total_num_replicas=1
Traceback (most recent call last):
  File ""train.py"", line 186, in <module>
    tf.app.run()
  File ""/opt/anaconda3/envs/cdsl/lib/python3.6/site-packages/tensorflow/python/platform/app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""/opt/anaconda3/envs/cdsl/lib/python3.6/site-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/opt/anaconda3/envs/cdsl/lib/python3.6/site-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""/opt/anaconda3/envs/cdsl/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py"", line 324, in new_func
    return func(*args, **kwargs)
  File ""train.py"", line 182, in main
    graph_hook_fn=graph_rewriter_fn)
  File ""/home/yaser.sakkaf/Object_Detection/TensorFlow/models/research/object_detection/legacy/trainer.py"", line 392, in train
    train_config.load_all_detection_checkpoint_vars))
  File ""/home/yaser.sakkaf/Object_Detection/TensorFlow/models/research/object_detection/meta_architectures/ssd_meta_arch.py"", line 1277, in restore_map
    return self._feature_extractor.restore_from_classification_checkpoint_fn(
AttributeError: 'SSDResNet50V1FpnKerasFeatureExtractor' object has no attribute 'restore_from_classification_checkpoint_fn'
ERROR:tensorflow:==================================
Object was never used (type <class 'tensorflow.python.framework.ops.Tensor'>):
<tf.Tensor 'report_uninitialized_variables/boolean_mask/GatherV2:0' shape=(None,) dtype=string>
If you want to mark it as used call its ""mark_used()"" method.
It was originally created here:
  File ""/opt/anaconda3/envs/cdsl/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py"", line 324, in new_func
    return func(*args, **kwargs)  File ""train.py"", line 182, in main
    graph_hook_fn=graph_rewriter_fn)  File ""/home/yaser.sakkaf/Object_Detection/TensorFlow/models/research/object_detection/legacy/trainer.py"", line 415, in train
    saver=saver)  File ""/opt/anaconda3/envs/cdsl/lib/python3.6/site-packages/tensorflow/python/training/sync_replicas_optimizer.py"", line 358, in apply_gradients
    return train_op  File ""/opt/anaconda3/envs/cdsl/lib/python3.6/site-packages/tensorflow/python/util/tf_should_use.py"", line 237, in wrapped
    error_in_function=error_in_function)
==================================
E0713 11:22:55.322450 139813510887232 tf_should_use.py:92] ==================================
Object was never used (type <class 'tensorflow.python.framework.ops.Tensor'>):
<tf.Tensor 'report_uninitialized_variables/boolean_mask/GatherV2:0' shape=(None,) dtype=string>
If you want to mark it as used call its ""mark_used()"" method.
It was originally created here:
  File ""/opt/anaconda3/envs/cdsl/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py"", line 324, in new_func
    return func(*args, **kwargs)  File ""train.py"", line 182, in main
    graph_hook_fn=graph_rewriter_fn)  File ""/home/yaser.sakkaf/Object_Detection/TensorFlow/models/research/object_detection/legacy/trainer.py"", line 415, in train
    saver=saver)  File ""/opt/anaconda3/envs/cdsl/lib/python3.6/site-packages/tensorflow/python/training/sync_replicas_optimizer.py"", line 358, in apply_gradients
    return train_op  File ""/opt/anaconda3/envs/cdsl/lib/python3.6/site-packages/tensorflow/python/util/tf_should_use.py"", line 237, in wrapped
    error_in_function=error_in_function)
==================================
```

## 3. Steps to reproduce

python train.py --logtostderr --train_dir=training/ --pipeline_config_path=training/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8.config

## 4. Expected behavior

The training should start

## 5. Additional context

Have a look at my config file: **ssd_resnet50_v1_fpn_640x640_coco17_tpu-8.config**

```
# SSD with Resnet 50 v1 FPN feature extractor, shared box predictor and focal
# loss (a.k.a Retinanet).
# See Lin et al, https://arxiv.org/abs/1708.02002
# Trained on COCO, initialized from Imagenet classification checkpoint
# Train on TPU-8
#
# Achieves 34.3 mAP on COCO17 Val

model {
  ssd {
    inplace_batchnorm_update: true
    freeze_batchnorm: false
    num_classes: 8
    box_coder {
      faster_rcnn_box_coder {
        y_scale: 10.0
        x_scale: 10.0
        height_scale: 5.0
        width_scale: 5.0
      }
    }
    matcher {
      argmax_matcher {
        matched_threshold: 0.5
        unmatched_threshold: 0.5
        ignore_thresholds: false
        negatives_lower_than_unmatched: true
        force_match_for_each_row: true
        use_matmul_gather: true
      }
    }
    similarity_calculator {
      iou_similarity {
      }
    }
    encode_background_as_zeros: true
    anchor_generator {
      multiscale_anchor_generator {
        min_level: 3
        max_level: 7
        anchor_scale: 4.0
        aspect_ratios: [1.0, 2.0, 0.5]
        scales_per_octave: 2
      }
    }
    image_resizer {
      fixed_shape_resizer {
        height: 640
        width: 640
      }
    }
    box_predictor {
      weight_shared_convolutional_box_predictor {
        depth: 256
        class_prediction_bias_init: -4.6
        conv_hyperparams {
          activation: RELU_6,
          regularizer {
            l2_regularizer {
              weight: 0.0004
            }
          }
          initializer {
            random_normal_initializer {
              stddev: 0.01
              mean: 0.0
            }
          }
          batch_norm {
            scale: true,
            decay: 0.997,
            epsilon: 0.001,
          }
        }
        num_layers_before_predictor: 4
        kernel_size: 3
      }
    }
    feature_extractor {
      type: 'ssd_resnet50_v1_fpn_keras'
      fpn {
        min_level: 3
        max_level: 7
      }
      min_depth: 16
      depth_multiplier: 1.0
      conv_hyperparams {
        activation: RELU_6,
        regularizer {
          l2_regularizer {
            weight: 0.0004
          }
        }
        initializer {
          truncated_normal_initializer {
            stddev: 0.03
            mean: 0.0
          }
        }
        batch_norm {
          scale: true,
          decay: 0.997,
          epsilon: 0.001,
        }
      }
      override_base_feature_extractor_hyperparams: true
    }
    loss {
      classification_loss {
        weighted_sigmoid_focal {
          alpha: 0.25
          gamma: 2.0
        }
      }
      localization_loss {
        weighted_smooth_l1 {
        }
      }
      classification_weight: 1.0
      localization_weight: 1.0
    }
    normalize_loss_by_num_matches: true
    normalize_loc_loss_by_codesize: true
    post_processing {
      batch_non_max_suppression {
        score_threshold: 1e-8
        iou_threshold: 0.6
        max_detections_per_class: 100
        max_total_detections: 100
      }
      score_converter: SIGMOID
    }
  }
}

train_config: {
  fine_tune_checkpoint_version: V2
  fine_tune_checkpoint: ""/home/yaser.sakkaf/Object_Detection/TensorFlow/workspace/training_demo/pre-trained-model/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8/resnet50.ckpt-1""
  fine_tune_checkpoint_type: ""classification""
  batch_size: 64
  sync_replicas: true
  startup_delay_steps: 0
  replicas_to_aggregate: 8
  use_bfloat16: true
  num_steps: 25000
  data_augmentation_options {
    random_horizontal_flip {
    }
  }
  data_augmentation_options {
    random_crop_image {
      min_object_covered: 0.0
      min_aspect_ratio: 0.75
      max_aspect_ratio: 3.0
      min_area: 0.75
      max_area: 1.0
      overlap_thresh: 0.0
    }
  }
  optimizer {
    momentum_optimizer: {
      learning_rate: {
        cosine_decay_learning_rate {
          learning_rate_base: .04
          total_steps: 25000
          warmup_learning_rate: .013333
          warmup_steps: 2000
        }
      }
      momentum_optimizer_value: 0.9
    }
    use_moving_average: false
  }
  max_number_of_boxes: 100
  unpad_groundtruth_tensors: false
}

train_input_reader: {
  label_map_path: ""/home/yaser.sakkaf/Object_Detection/TensorFlow/workspace/training_demo/training/kyc_label_map.pbtxt""
  tf_record_input_reader {
    input_path: ""/home/yaser.sakkaf/Object_Detection/TensorFlow/workspace/training_demo/annotations/train.tfrecord-00000-of-00001""
  }
}

eval_config: {
  metrics_set: ""coco_detection_metrics""
  use_moving_averages: false
}

eval_input_reader: {
  label_map_path: ""/home/yaser.sakkaf/Object_Detection/TensorFlow/workspace/training_demo/training/kyc_label_map.pbtxt""
  shuffle: false
  num_epochs: 1
  tf_record_input_reader {
    input_path: ""/home/yaser.sakkaf/Object_Detection/TensorFlow/workspace/training_demo/annotations/test.tfrecord-00000-of-00001""
  }
}
```
## 6. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
NAME=""Red Hat Enterprise Linux""
VERSION=""8.2 (Ootpa)""

- Mobile device name if the issue happens on a mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): '2.2.0'
- Python version: Python 3.6.10
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: V10.1.243/ MAJOR 7
- GPU model and memory: Tesla P100 16 GB

<!-- 
Collect system information using our environment capture script.
https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can also obtain the TensorFlow version with:

1. TensorFlow 1.0
`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

2. TensorFlow 2.0
`python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`
-->
",yasersakkaf,b'models:research type:bug',2020-07-13T11:34:24Z,2020-07-31T16:55:23Z,,,,,,,
8854,"object_detection Shape mismatch after adjusting the pipeline config, anything missing?","# Prerequisites

Please answer the following questions for yourself before submitting an issue.

- [x] I am using the latest TensorFlow Model Garden release and TensorFlow 2.
- [x] I am reporting the issue to the correct repository. (Model Garden official or research directory)
- [x] I checked to make sure that this issue has not already been filed.

## 1. The entire URL of the file you are using

Base config file: https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/configs/tf2/faster_rcnn_resnet101_v1_640x640_coco17_tpu-8.config

Base checkpoints: http://download.tensorflow.org/models/object_detection/tf2/20200711/faster_rcnn_resnet101_v1_640x640_coco17_tpu-8.tar.gz

## 2. Describe the bug

This is related to fine-tuning a detection model, in my case, it is based on Faster R-CNN. I have changed all the necessary parameters in the configuration file with respect to the dataset I have. The config file can be found [here](https://gist.github.com/sayakpaul/0171f5647219e8d41df63f3b1a6b2374#file-faster_rcnn_resnet101_v1_640x640_coco17_tpu-8-config). 

I am launching the training locally with the following command:

```
python ~/models/research/object_detection/model_main_tf2.py \
    --pipeline_config_path=${PIPELINE_CONFIG_PATH} \
    --model_dir=${MODEL_DIR} \
    --alsologtostderrv
```

Where, `PIPELINE_CONFIG_PATH` is defined as `home/jupyter/ssds_and_rcnn/lisa/experiments/training/faster_rcnn_resnet101_v1_640x640_coco17_tpu-8.config` and `MODEL_DIR` is defined as `/home/jupyter/ssds_and_rcnn/lisa/experiments/training/faster_rcnn_resnet101_v1_640x640_coco17_tpu-8/checkpoint`. 

Contents of `faster_rcnn_resnet101_v1_640x640_coco17_tpu-8/checkpoint`:

```
total 182M
-rw-r----- 1 jupyter jupyter  166 Jul 10 03:56 checkpoint
-rw-r----- 1 jupyter jupyter 182M Jul 10 03:58 ckpt-0.data-00000-of-00001
-rw-r----- 1 jupyter jupyter 8.7K Jul 10 03:56 ckpt-0.index
```

Now, upon launching the training I am getting:

```
Traceback (most recent call last):
  File ""/home/jupyter/models/research/object_detection/model_main_tf2.py"", line 106, in <module>
    tf.compat.v1.app.run()
  File ""/home/jupyter/.local/bin/.virtualenvs/tfod_api/lib/python3.7/site-packages/tensorflow/python/platform/app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""/home/jupyter/.local/bin/.virtualenvs/tfod_api/lib/python3.7/site-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/home/jupyter/.local/bin/.virtualenvs/tfod_api/lib/python3.7/site-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""/home/jupyter/models/research/object_detection/model_main_tf2.py"", line 103, in main
    use_tpu=FLAGS.use_tpu)
  File ""/home/jupyter/.local/bin/.virtualenvs/tfod_api/lib/python3.7/site-packages/object_detection/model_lib_v2.py"", line 569, in train_loop
    ckpt.restore(latest_checkpoint)
  File ""/home/jupyter/.local/bin/.virtualenvs/tfod_api/lib/python3.7/site-packages/tensorflow/python/training/tracking/util.py"", line 2009, in restore
    status = self._saver.restore(save_path=save_path)
  File ""/home/jupyter/.local/bin/.virtualenvs/tfod_api/lib/python3.7/site-packages/tensorflow/python/training/tracking/util.py"", line 1304, in restore
    checkpoint=checkpoint, proto_id=0).restore(self._graph_view.root)
  File ""/home/jupyter/.local/bin/.virtualenvs/tfod_api/lib/python3.7/site-packages/tensorflow/python/training/tracking/base.py"", line 209, in restore
    restore_ops = trackable._restore_from_checkpoint_position(self)  # pylint: disable=protected-access
  File ""/home/jupyter/.local/bin/.virtualenvs/tfod_api/lib/python3.7/site-packages/tensorflow/python/training/tracking/base.py"", line 907, in _restore_from_checkpoint_position
    tensor_saveables, python_saveables))
  File ""/home/jupyter/.local/bin/.virtualenvs/tfod_api/lib/python3.7/site-packages/tensorflow/python/training/tracking/util.py"", line 289, in restore_saveables
    validated_saveables).restore(self.save_path_tensor)
  File ""/home/jupyter/.local/bin/.virtualenvs/tfod_api/lib/python3.7/site-packages/tensorflow/python/training/saving/functional_saver.py"", line 281, in restore
    restore_ops.update(saver.restore(file_prefix))
  File ""/home/jupyter/.local/bin/.virtualenvs/tfod_api/lib/python3.7/site-packages/tensorflow/python/training/saving/functional_saver.py"", line 103, in restore
    restored_tensors, restored_shapes=None)
  File ""/home/jupyter/.local/bin/.virtualenvs/tfod_api/lib/python3.7/site-packages/tensorflow/python/distribute/values.py"", line 647, in restore
    for v in self._mirrored_variable.values))
  File ""/home/jupyter/.local/bin/.virtualenvs/tfod_api/lib/python3.7/site-packages/tensorflow/python/distribute/values.py"", line 647, in <genexpr>
    for v in self._mirrored_variable.values))
  File ""/home/jupyter/.local/bin/.virtualenvs/tfod_api/lib/python3.7/site-packages/tensorflow/python/distribute/values.py"", line 392, in _assign_on_device
    return variable.assign(tensor)
  File ""/home/jupyter/.local/bin/.virtualenvs/tfod_api/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py"", line 846, in assign
    self._shape.assert_is_compatible_with(value_tensor.shape)
  File ""/home/jupyter/.local/bin/.virtualenvs/tfod_api/lib/python3.7/site-packages/tensorflow/python/framework/tensor_shape.py"", line 1117, in assert_is_compatible_with
    raise ValueError(""Shapes %s and %s are incompatible"" % (self, other))
**ValueError: Shapes (4,) and (91,) are incompatible**
```

Am I missing something? 

## 3. Steps to reproduce

If needed I can supply the tfrecords files. 

## 4. Expected behavior

The training should not raise the shape mismatch error given I have done everything correctly before launching the training. 

## 5. Additional context

None

## 6. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- Mobile device name if the issue happens on a mobile device:
- TensorFlow installed from (source or binary): Binary
- TensorFlow version (use command below): 2.2.0
- Python version: Python 3.7
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 10.1 
- GPU model and memory: Tesla T4
",sayakpaul,b'models:research type:bug',2020-07-13T11:03:21Z,2020-07-14T06:54:19Z,,,,,,,
8848,AttributeError: module 'object_detection.meta_architectures.faster_rcnn_meta_arch' has no attribute 'FasterRCNNInceptionV2FeatureExtractor,"I have been trying to train my custom object_detector through TensorFlow. I have run into a bunch of errors of which I debugged my way through. I have the latest version of cuda and cudnn. I am running everything in a virtual anaconda environment. I have python version 3.6.3 in the anaconda prompt. I am trying to run the train.py however, the feature extractor code for faster rcnn inception V2 feature extractor is giving the error stated above. I am unable to figure out the solution, please help within this week. It would be great if you could tell me which meta architecture is supported by faster rcnn inception v2 feature extractor or another model that can support faster rcnn meta arch. Thanks to anyone who replies!
<!--
As per our GitHub Policy (https://github.com/tensorflow/models/blob/master/ISSUES.md), we only address code bugs, documentation issues, and feature requests on GitHub. We will automatically close questions and help related issues.

Please go to Stack Overflow (http://stackoverflow.com/questions/tagged/tensorflow-model-garden) for questions and help.

-->
",Dasinator21,b'models:research type:support',2020-07-12T20:27:16Z,2020-07-13T20:57:44Z,,,,,,,
8847,AttributeError: module 'tensorflow.python.ops.special_math_ops' has no attribute 'bessel_i0e' ,"Please make sure that this is a build/installation issue. As per our GitHub Policy, we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template

System information

OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 64-bit
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
TensorFlow installed from (source or binary):
TensorFlow version: 2.2.0
Python version: 3.7.6
Installed using virtualenv? pip? conda?: pip
Bazel version (if compiling from source):
GCC/Compiler version (if compiling from source):
CUDA/cuDNN version:
GPU model and memory: AMD RX-580
Describe the problem
AttributeError: module 'tensorflow.python.ops.special_math_ops' has no attribute 'bessel_i0e' arises when trying to use tensorflow's object detection API to fine-tune EfficientDet to detect a custom class I created a dataset and matching test/train TFrecord files.

Provide the exact sequence of commands / steps that you executed before running into the problem

I followed the instructions on https://github.com/tensorflow/models/tree/master/official#running-the-models under ""How to get started with the official models"" to install dependencies, clone the models repo, and add the models folder to my python path. The last part I accomplished by adding a sys.path.append(r'C:\Users\user\models') line to the beginning of model_main_tf2.py, which is the file I was under the impression runs the training loop. I also installed protoc-3.12.3-win64.zip and ran ""C:/Program Files/protoc/bin/protoc"" object_detection/protos/*.proto --python_out=. in the models directory.

I downloaded and configured the config files for EfficientDet D7 from https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md to point to my TFrecord test/train files, the checkpoint/ckpt-0 file and label_map.txt files.

I ran the following command in an anaconda powershell which prompted the AttributeError: module 'tensorflow.python.ops.special_math_ops' has no attribute 'bessel_i0e':

python model_main_tf2.py --model_dir=C:\Users\user\efficientdet_d7_coco17_tpu-32\training --num_train_steps=10000 --sample_1_of_n_eval_examples=1 --pipeline_config_path=C:\Users\user\efficientdet_d7_coco17_tpu-32\pipeline.config --alsologtostderr

I also tried it with and without the --checkpoint_dir = C:\Users\user\efficientdet_d7_coco17_tpu-32\checkpoint flag

Any other info / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

(base) C:\Users\user\models\research\object_detection>python model_main_tf2.py --model_dir=C:\Users\user\efficientdet_d7_coco17_tpu-32\training --num_train_steps=10000 --sample_1_of_n_eval_examples=1 --pipeline_config_path=C:\Users\user\efficientdet_d7_coco17_tpu-32\pipeline.config --alsologtostderr
2020-07-12 02:03:31.351897: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'cudart64_101.dll'; dlerror: cudart64_101.dll not found
2020-07-12 02:03:31.356039: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
Traceback (most recent call last):
File ""model_main_tf2.py"", line 35, in
import tensorflow.compat.v2 as tf
File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_init_.py"", line 41, in
from tensorflow.python.tools import module_util as module_util
File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python_init.py"", line 74, in
from tensorflow.python.ops.standard_ops import *
File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\ops\standard_ops.py"", line 27, in
from tensorflow.python.training.experimental import loss_scaling_gradient_tape
File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\training\experimental\loss_scaling_gradient_tape.py"", line 21, in
from tensorflow.python.distribute import distribution_strategy_context
File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\distribute_init_.py"", line 28, in
from tensorflow.python.distribute.experimental import collective_all_reduce_strategy
File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\distribute\experimental_init_.py"", line 25, in
from tensorflow.python.distribute import tpu_strategy
File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\distribute\tpu_strategy.py"", line 28, in
from tensorflow.compiler.xla.experimental.xla_sharding import xla_sharding
File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\compiler\xla\experimental\xla_sharding\xla_sharding.py"", line 23, in
from tensorflow.compiler.tf2xla.python import xla as tf2xla
File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\compiler\tf2xla\python\xla.py"", line 107, in
bessel_i0e = _unary_op(special_math_ops.bessel_i0e)
AttributeError: module 'tensorflow.python.ops.special_math_ops' has no attribute 'bessel_i0e'

Please let me know if there is any other info I can provide, any help would be much appreciated. Thanks.",attianopp,b'type:support',2020-07-12T18:16:45Z,2020-07-13T08:25:40Z,,,,,,,
8840,Fixed Object Detection Colab Tutorial,"Check https://colab.research.google.com/drive/1b7iIzHw6m9lCcNqR1EMjp_rbu0icIZ-K?usp=sharing for more information.This is the content for this PR.

# Description

On running the given notebook tutorial for object tutorial on Colab I found bugs on two places .
One at the the masking_model plotting , other at the model was not assigned a serving_default signature for the same.
For better understanding of where the issue was, please run the original NB on colab. 
Also solves #8839 

## Type of change

For a new feature or function, please create an issue first to discuss it
with us before submitting a pull request.

Note: Please delete options that are not relevant.

- [x] Bug fix (non-breaking change which fixes an issue)
- [ ] Documentation update
- [ ] TensorFlow 2 migration
- [ ] New feature (non-breaking change which adds functionality)
- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)
- [ ] A new research paper code implementation
- [ ] Other (Specify)

## Tests

> :memo: Please describe the tests that you ran to verify your changes.
>  
> * Provide instructions so we can reproduce.  
> * Please also list any relevant details for your test configuration.  

**Test Configuration**:

## Checklist

- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).
- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).
- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).
- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.
- [ ] I have commented my code, particularly in hard-to-understand areas.
- [ ] I have made corresponding changes to the documentation.
- [x] My changes generate no new warnings.
- [ ] I have added tests that prove my fix is effective or that my feature works.
",ucalyptus,b'cla: no',2020-07-11T15:14:28Z,2020-08-03T17:55:38Z,,,,,,,
8838,loss is increasing??,"# Prerequisites

Please answer the following questions for yourself before submitting an issue.

- [ ] I am using the latest TensorFlow Model Garden release and TensorFlow 2.
- [ ] I am reporting the issue to the correct repository. (Model Garden official or research directory)
- [ ] I checked to make sure that this issue has not already been filed.

## 1. The entire URL of the file you are using

https://github.com/tensorflow/models/tree/master/research/...

## 2. Describe the bug

A clear and concise description of what the bug is.

## 3. Steps to reproduce

Steps to reproduce the behavior.

## 4. Expected behavior

A clear and concise description of what you expected to happen.

## 5. Additional context

Include any logs that would be helpful to diagnose the problem.

## 6. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device name if the issue happens on a mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below):
- Python version:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

<!-- 
Collect system information using our environment capture script.
https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can also obtain the TensorFlow version with:

1. TensorFlow 1.0
`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

2. TensorFlow 2.0
`python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`
-->
",erolgerceker,b'models:research stat:awaiting review type:bug',2020-07-11T10:50:44Z,2020-07-13T05:32:17Z,,,,,,,
8834,Merged commit includes the following changes:,"320711412  by rathodv:

    Internal change

--
320707201  by lzc:

    Internal change

320690704  by TF Object Detection Team:

    Purely Google refactor

--
320665573  by TF Object Detection Team:

    Fallback to deprecated `experimental_run_v2` method if `run` does not exist.

--

PiperOrigin-RevId: 320711412

# Description

> :memo: Please include a summary of the change. 
>  
> * Please also include relevant motivation and context.  
> * List any dependencies that are required for this change.  

## Type of change

For a new feature or function, please create an issue first to discuss it
with us before submitting a pull request.

Note: Please delete options that are not relevant.

- [ ] Bug fix (non-breaking change which fixes an issue)
- [ ] Documentation update
- [ ] TensorFlow 2 migration
- [ ] New feature (non-breaking change which adds functionality)
- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)
- [ ] A new research paper code implementation
- [ ] Other (Specify)

## Tests

> :memo: Please describe the tests that you ran to verify your changes.
>  
> * Provide instructions so we can reproduce.  
> * Please also list any relevant details for your test configuration.  

**Test Configuration**:

## Checklist

- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).
- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).
- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).
- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.
- [ ] I have commented my code, particularly in hard-to-understand areas.
- [ ] I have made corresponding changes to the documentation.
- [ ] My changes generate no new warnings.
- [ ] I have added tests that prove my fix is effective or that my feature works.
",tombstone,b'cla: yes',2020-07-11T01:41:32Z,2020-07-11T01:45:58Z,,,,,,,
8833,Remove references to borg in ducks colab,"# Description

> :memo: Please include a summary of the change. 
>  
> * Please also include relevant motivation and context.  
> * List any dependencies that are required for this change.  

## Type of change

For a new feature or function, please create an issue first to discuss it
with us before submitting a pull request.

Note: Please delete options that are not relevant.

- [ ] Bug fix (non-breaking change which fixes an issue)
- [ ] Documentation update
- [ ] TensorFlow 2 migration
- [ ] New feature (non-breaking change which adds functionality)
- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)
- [ ] A new research paper code implementation
- [ ] Other (Specify)

## Tests

> :memo: Please describe the tests that you ran to verify your changes.
>  
> * Provide instructions so we can reproduce.  
> * Please also list any relevant details for your test configuration.  

**Test Configuration**:

## Checklist

- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).
- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).
- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).
- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.
- [ ] I have commented my code, particularly in hard-to-understand areas.
- [ ] I have made corresponding changes to the documentation.
- [ ] My changes generate no new warnings.
- [ ] I have added tests that prove my fix is effective or that my feature works.
",kmindspark,b'cla: yes',2020-07-10T19:02:20Z,2020-07-10T19:34:57Z,,,,,,,
8832,Merged commit includes the following changes:,"320640208  by vighneshb:

    Make model zoo links prominent.

--

PiperOrigin-RevId: 320640208

# Description

> :memo: Please include a summary of the change. 
>  
> * Please also include relevant motivation and context.  
> * List any dependencies that are required for this change.  

## Type of change

For a new feature or function, please create an issue first to discuss it
with us before submitting a pull request.

Note: Please delete options that are not relevant.

- [ ] Bug fix (non-breaking change which fixes an issue)
- [ ] Documentation update
- [ ] TensorFlow 2 migration
- [ ] New feature (non-breaking change which adds functionality)
- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)
- [ ] A new research paper code implementation
- [ ] Other (Specify)

## Tests

> :memo: Please describe the tests that you ran to verify your changes.
>  
> * Provide instructions so we can reproduce.  
> * Please also list any relevant details for your test configuration.  

**Test Configuration**:

## Checklist

- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).
- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).
- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).
- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.
- [ ] I have commented my code, particularly in hard-to-understand areas.
- [ ] I have made corresponding changes to the documentation.
- [ ] My changes generate no new warnings.
- [ ] I have added tests that prove my fix is effective or that my feature works.
",tombstone,b'cla: yes',2020-07-10T18:56:33Z,2020-07-10T19:35:51Z,,,,,,,
8831,Inference colab with updated checkpoints,"# Description

> :memo: Please include a summary of the change. 
>  
> * Please also include relevant motivation and context.  
> * List any dependencies that are required for this change.  

## Type of change

For a new feature or function, please create an issue first to discuss it
with us before submitting a pull request.

Note: Please delete options that are not relevant.

- [ ] Bug fix (non-breaking change which fixes an issue)
- [ ] Documentation update
- [ ] TensorFlow 2 migration
- [ ] New feature (non-breaking change which adds functionality)
- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)
- [ ] A new research paper code implementation
- [ ] Other (Specify)

## Tests

> :memo: Please describe the tests that you ran to verify your changes.
>  
> * Provide instructions so we can reproduce.  
> * Please also list any relevant details for your test configuration.  

**Test Configuration**:

## Checklist

- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).
- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).
- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).
- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.
- [ ] I have commented my code, particularly in hard-to-understand areas.
- [ ] I have made corresponding changes to the documentation.
- [ ] My changes generate no new warnings.
- [ ] I have added tests that prove my fix is effective or that my feature works.
",kmindspark,b'cla: yes',2020-07-10T18:55:58Z,2020-07-10T18:57:33Z,,,,,,,
8830,Merged commit includes the following changes:,"320622111  by rathodv:

    Internal Change.

--

PiperOrigin-RevId: 320622111

# Description
TensorFlow 2 meets Object Detection API. 

Blog → https://blog.tensorflow.org/2020/07/tensorflow-2-meets-object-detection-api.html
Twitter → https://twitter.com/TensorFlow/status/1281634713065500673

> :memo: Please include a summary of the change. 
>  
> * Please also include relevant motivation and context.  
> * List any dependencies that are required for this change.  

## Type of change

For a new feature or function, please create an issue first to discuss it
with us before submitting a pull request.

Note: Please delete options that are not relevant.

- [ ] Bug fix (non-breaking change which fixes an issue)
- [ ] Documentation update
- [ ] TensorFlow 2 migration
- [ ] New feature (non-breaking change which adds functionality)
- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)
- [ ] A new research paper code implementation
- [ ] Other (Specify)

## Tests

> :memo: Please describe the tests that you ran to verify your changes.
>  
> * Provide instructions so we can reproduce.  
> * Please also list any relevant details for your test configuration.  

**Test Configuration**:

## Checklist

- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).
- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).
- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).
- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.
- [ ] I have commented my code, particularly in hard-to-understand areas.
- [ ] I have made corresponding changes to the documentation.
- [ ] My changes generate no new warnings.
- [ ] I have added tests that prove my fix is effective or that my feature works.
",tombstone,b'cla: yes',2020-07-10T17:01:03Z,2020-07-10T17:05:10Z,,,,,,,
8829,Merged commit includes the following changes:,"320618558  by rathodv:

    Internal Change.

--
320597532  by ronnyvotel:

    Exposing DensePose visualizations to model_lib_v2.py.

--
320533669  by ronnyvotel:

    Adding utilities to visualize DensePose outputs.

--
320529647  by lzc:

    Fix saved_model issue in object_detection_tutorial notebook.

--
320510127  by aom:

    Internal change.

--
320490236  by derekjchow:

    Update Dockerfiles to use setup.py

--
320443572  by rathodv:

    Update `Tensorflow` to `TensorFlow` in documentation.

--
320426460  by ronnyvotel:

    DensePose proto and model builder.

--
320352611  by rathodv:

    Update documentation to reflect the support for TF1 and TF2. Provide separate sets of instructions to reduce confusion.

--
320350724  by rathodv:

    Internal Change.

--

PiperOrigin-RevId: 320618558

# Description

> :memo: Please include a summary of the change. 
>  
> * Please also include relevant motivation and context.  
> * List any dependencies that are required for this change.  

## Type of change

For a new feature or function, please create an issue first to discuss it
with us before submitting a pull request.

Note: Please delete options that are not relevant.

- [ ] Bug fix (non-breaking change which fixes an issue)
- [ ] Documentation update
- [ ] TensorFlow 2 migration
- [ ] New feature (non-breaking change which adds functionality)
- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)
- [ ] A new research paper code implementation
- [ ] Other (Specify)

## Tests

> :memo: Please describe the tests that you ran to verify your changes.
>  
> * Provide instructions so we can reproduce.  
> * Please also list any relevant details for your test configuration.  

**Test Configuration**:

## Checklist

- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).
- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).
- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).
- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.
- [ ] I have commented my code, particularly in hard-to-understand areas.
- [ ] I have made corresponding changes to the documentation.
- [ ] My changes generate no new warnings.
- [ ] I have added tests that prove my fix is effective or that my feature works.
",tombstone,b'cla: yes',2020-07-10T16:41:45Z,2020-07-10T16:52:34Z,,,,,,,
8828,Updated to include information about orbit.,"# Description

> :memo: Please include a summary of the change. 
>  
> * Please also include relevant motivation and context.  
> * List any dependencies that are required for this change.  

## Type of change

For a new feature or function, please create an issue first to discuss it
with us before submitting a pull request.

Note: Please delete options that are not relevant.

- [ ] Bug fix (non-breaking change which fixes an issue)
- [ ] Documentation update
- [ ] TensorFlow 2 migration
- [ ] New feature (non-breaking change which adds functionality)
- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)
- [ ] A new research paper code implementation
- [ ] Other (Specify)

## Tests

> :memo: Please describe the tests that you ran to verify your changes.
>  
> * Provide instructions so we can reproduce.  
> * Please also list any relevant details for your test configuration.  

**Test Configuration**:

## Checklist

- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).
- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).
- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).
- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.
- [ ] I have commented my code, particularly in hard-to-understand areas.
- [ ] I have made corresponding changes to the documentation.
- [ ] My changes generate no new warnings.
- [ ] I have added tests that prove my fix is effective or that my feature works.
",dynamicwebpaige,b'cla: yes',2020-07-10T16:25:23Z,2020-07-10T18:01:49Z,,,,,,,
8825,"ValueError: Tensor-typed variable initializers must either be wrapped in an init_scope or callable (e.g., `tf.Variable(lambda : tf.truncated_normal([10, 40]))`) when building functions. ","### Version ###
- OS Platform
Python 3.7.6
tensorflow 2.2.0
keras 2.3.0-tf
mem 64247.95703125
cpu 16

### Try to reproduce this work ###
https://www.kaggle.com/devang/transfer-learning-with-keras-and-mobilenet-v2

### Bug description ### 
The error occurs when I try to define layers and compile model using:

epochs = 100
batch_size = 150
testsplit = .2
targetx = 224
targety = 224
learning_rate = 0.0001
classes = 120
seed = random.randint(1, 1000)

shape=(targetx, targety, 3))

x = base_model.output
x = GlobalAveragePooling2D()(x)
# x = Dropout(rate = .2)(x)
x = BatchNormalization()(x)
x = Dense(1280, activation='relu',  kernel_initializer=glorot_uniform(seed), bias_initializer='zeros')(x)
# x = Dropout(rate = .2)(x)
x = BatchNormalization()(x)
predictions = Dense(classes, activation='softmax', kernel_initializer='random_uniform', bias_initializer='zeros')(x)

model = Model(inputs=base_model.input, outputs=predictions)


### Error report ###
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
<ipython-input-64-19962c4ddb53> in <module>
     12 """"""
     13 
---> **_14 x = Dense(1280, activation='relu',  kernel_initializer=glorot_uniform(seed), bias_initializer='zeros')(x)_**
     15 x = Dropout(rate = .2)(x)
     16 x = BatchNormalization()(x)

/apps/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py in symbolic_fn_wrapper(*args, **kwargs)
     73         if _SYMBOLIC_SCOPE.value:
     74             with get_graph().as_default():
---> 75                 return func(*args, **kwargs)
     76         else:
     77             return func(*args, **kwargs)

/apps/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/keras/engine/base_layer.py in __call__(self, inputs, **kwargs)
    461                                          'You can build it manually via: '
    462                                          '`layer.build(batch_input_shape)`')
--> 463                 self.build(unpack_singleton(input_shapes))
    464                 self.built = True
    465 

/apps/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/keras/layers/core.py in build(self, input_shape)
    893                                       name='kernel',
    894                                       regularizer=self.kernel_regularizer,
--> 895                                       constraint=self.kernel_constraint)
    896         if self.use_bias:
    897             self.bias = self.add_weight(shape=(self.units,),

/apps/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/keras/engine/base_layer.py in add_weight(self, name, shape, dtype, initializer, regularizer, trainable, constraint)
    280                             dtype=dtype,
    281                             name=name,
--> 282                             constraint=constraint)
    283         if regularizer is not None:
    284             with K.name_scope('weight_regularizer'):

/apps/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py in variable(value, dtype, name, constraint)
    618     """"""
    619     v = tf_keras_backend.variable(
--> 620         value, dtype=dtype, name=name, constraint=constraint)
    621     if hasattr(value, 'tocoo'):
    622         v._keras_shape = value.tocoo().shape

/apps/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/keras/backend.py in variable(value, dtype, name, constraint)
    843       dtype=dtypes_module.as_dtype(dtype),
    844       name=name,
--> 845       constraint=constraint)
    846   if isinstance(value, np.ndarray):
    847     v._keras_shape = value.shape

/apps/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/ops/variables.py in __call__(cls, *args, **kwargs)
    259       return cls._variable_v1_call(*args, **kwargs)
    260     elif cls is Variable:
--> 261       return cls._variable_v2_call(*args, **kwargs)
    262     else:
    263       return super(VariableMetaclass, cls).__call__(*args, **kwargs)

/apps/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/ops/variables.py in _variable_v2_call(cls, initial_value, trainable, validate_shape, caching_device, name, variable_def, dtype, import_scope, constraint, synchronization, aggregation, shape)
    253         synchronization=synchronization,
    254         aggregation=aggregation,
--> 255         shape=shape)
    256 
    257   def __call__(cls, *args, **kwargs):

/apps/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/ops/variables.py in <lambda>(**kws)
    234                         shape=None):
    235     """"""Call on Variable class. Useful to force the signature.""""""
--> 236     previous_getter = lambda **kws: default_variable_creator_v2(None, **kws)
    237     for _, getter in ops.get_default_graph()._variable_creator_stack:  # pylint: disable=protected-access
    238       previous_getter = _make_getter(getter, previous_getter)

/apps/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/ops/variable_scope.py in default_variable_creator_v2(next_creator, **kwargs)
   2645       synchronization=synchronization,
   2646       aggregation=aggregation,
-> 2647       shape=shape)
   2648 
   2649 

/apps/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/ops/variables.py in __call__(cls, *args, **kwargs)
    261       return cls._variable_v2_call(*args, **kwargs)
    262     else:
--> 263       return super(VariableMetaclass, cls).__call__(*args, **kwargs)
    264 
    265 

/apps/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py in __init__(self, initial_value, trainable, collections, validate_shape, caching_device, name, dtype, variable_def, import_scope, constraint, distribute_strategy, synchronization, aggregation, shape)
   1432           aggregation=aggregation,
   1433           shape=shape,
-> 1434           distribute_strategy=distribute_strategy)
   1435 
   1436   def _init_from_args(self,

/apps/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py in _init_from_args(self, initial_value, trainable, collections, caching_device, name, dtype, constraint, synchronization, aggregation, distribute_strategy, shape)
   1515     if isinstance(initial_value, ops.Tensor) and hasattr(
   1516         initial_value, ""graph"") and initial_value.graph.building_function:
-> 1517       raise ValueError(""Tensor-typed variable initializers must either be ""
   1518                        ""wrapped in an init_scope or callable ""
   1519                        ""(e.g., `tf.Variable(lambda : ""

ValueError: Tensor-typed variable initializers must either be wrapped in an init_scope or callable (e.g., `tf.Variable(lambda : tf.truncated_normal([10, 40]))`) when building functions. Please file a feature request if this restriction inconveniences you.

---------------------------------------------------------------------------
I had a few go on changing the 'seed' to the following:

* [1, seed]
* tf.constant(np.random.rand(2, 2)) 
* tf.keras.Variable(lambda : tf.truncated_normal([1, seed]))

However, I still can't manage to convert 'seed' to a tensor. 

Can anyone help me please ?

Any suggestions/feedback will be much appreiciated!

",Isabellaleesln,b'models:official stat:awaiting response type:bug',2020-07-10T14:14:07Z,2020-07-13T11:33:49Z,,,,,,,
8822,Updated inference colab with downloaded checkpoints ,"# Description

> :memo: Please include a summary of the change. 
>  
> * Please also include relevant motivation and context.  
> * List any dependencies that are required for this change.  

## Type of change

For a new feature or function, please create an issue first to discuss it
with us before submitting a pull request.

Note: Please delete options that are not relevant.

- [ ] Bug fix (non-breaking change which fixes an issue)
- [ ] Documentation update
- [ ] TensorFlow 2 migration
- [ ] New feature (non-breaking change which adds functionality)
- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)
- [ ] A new research paper code implementation
- [ ] Other (Specify)

## Tests

> :memo: Please describe the tests that you ran to verify your changes.
>  
> * Provide instructions so we can reproduce.  
> * Please also list any relevant details for your test configuration.  

**Test Configuration**:

## Checklist

- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).
- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).
- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).
- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.
- [ ] I have commented my code, particularly in hard-to-understand areas.
- [ ] I have made corresponding changes to the documentation.
- [ ] My changes generate no new warnings.
- [ ] I have added tests that prove my fix is effective or that my feature works.
",kmindspark,b'cla: yes',2020-07-10T08:49:27Z,2020-07-10T18:55:19Z,,,,,,,
8821,Interactive Ducks Colab,"# Description
Interactive Ducks Colab
> :memo: Please include a summary of the change. 
>  
> * Please also include relevant motivation and context.  
> * List any dependencies that are required for this change.  

## Type of change

For a new feature or function, please create an issue first to discuss it
with us before submitting a pull request.

Note: Please delete options that are not relevant.

- [ ] Bug fix (non-breaking change which fixes an issue)
- [ ] Documentation update
- [ ] TensorFlow 2 migration
- [x] New feature (non-breaking change which adds functionality)
- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)
- [ ] A new research paper code implementation
- [ ] Other (Specify)

## Tests

> :memo: Please describe the tests that you ran to verify your changes.
>  
> * Provide instructions so we can reproduce.  
> * Please also list any relevant details for your test configuration.  

**Test Configuration**:

## Checklist

- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).
- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).
- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).
- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.
- [ ] I have commented my code, particularly in hard-to-understand areas.
- [ ] I have made corresponding changes to the documentation.
- [ ] My changes generate no new warnings.
- [ ] I have added tests that prove my fix is effective or that my feature works.
",kmindspark,b'cla: yes',2020-07-10T07:20:27Z,2020-07-10T09:17:16Z,,,,,,,
8819,With keypoints: Inference colab,"# Description
Inference colab with keypoints
> :memo: Please include a summary of the change. 
>  Adding keypoint support to inference colab
> * Please also include relevant motivation and context.  
> * List any dependencies that are required for this change.  

## Type of change

For a new feature or function, please create an issue first to discuss it
with us before submitting a pull request.

Note: Please delete options that are not relevant.

- [ ] Bug fix (non-breaking change which fixes an issue)
- [ ] Documentation update
- [ ] TensorFlow 2 migration
- [x] New feature (non-breaking change which adds functionality)
- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)
- [ ] A new research paper code implementation
- [ ] Other (Specify)

## Tests

> :memo: Please describe the tests that you ran to verify your changes.
>  
> * Provide instructions so we can reproduce.  
> * Please also list any relevant details for your test configuration.  

**Test Configuration**:

## Checklist

- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).
- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).
- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).
- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.
- [x] I have commented my code, particularly in hard-to-understand areas.
- [x] I have made corresponding changes to the documentation.
- [x] My changes generate no new warnings.
- [x] I have added tests that prove my fix is effective or that my feature works.
",kmindspark,b'cla: yes',2020-07-10T00:12:34Z,2020-07-10T01:58:36Z,,,,,,,
8818,Added *_pb2.py to object_detection gitignore.,"# Description

> :memo: Please include a summary of the change. 
>  
> Added *_pb2.py to object_detection gitignore.


## Type of change
Bug fix

## Tests

",vighneshbirodkar,b'cla: yes',2020-07-09T18:01:28Z,2020-07-09T18:04:00Z,,,,,,,
8813,DEEPLAB TF2.1  compatibility,"# Prerequisites

Please answer the following questions for yourself before submitting an issue.

- [yes ] I am using the latest TensorFlow Model Garden release and TensorFlow 2.
- [yes ] I am reporting the issue to the correct repository. (Model Garden official or research directory)
- [yes ] I checked to make sure that this issue has not already been filed.

## 1. The entire URL of the file you are using

https://github.com/tensorflow/models/blob/master/research/deeplab/datasets/build_voc2012_data.py

## 2. Describe the bug

tf 2.1|2.0 does not support ""tf.app.flags"". maybe using tf.compat.v1 can resolve the problem
 
## 3. Steps to reproduce

when I wanted to execute the build_voc2012_data.py file to produce the ""tfrecord"" data

## 4. Expected behavior

trouble-free code execution

## 5. Additional context

**

> Traceback (most recent call last):
>   File ""build_voc2012_data.py"", line 60, in <module>
>     import build_data
>   File "".../deeplab/datasets/build_data.py"", line 36, in <module>
>     FLAGS = tf.app.flags.FLAGS
> AttributeError: module 'tensorflow' has no attribute 'app'

**

## 6. System information

- OS Platform and Distribution : Linux Ubuntu 18.04
- TensorFlow 2.1 installed from conda cloud 
- Python version: 3.7.7 



",hxfdanger,b'models:research type:bug',2020-07-09T09:18:15Z,2020-07-17T09:18:47Z,,,,,,,
8810,Inference Colab for External,"# Description
Inference colab for open source.
> :memo: Please include a summary of the change. 
>  
> * Please also include relevant motivation and context.  
> * List any dependencies that are required for this change.  

## Type of change

For a new feature or function, please create an issue first to discuss it
with us before submitting a pull request.

Note: Please delete options that are not relevant.

- [ ] Bug fix (non-breaking change which fixes an issue)
- [ ] Documentation update
- [ ] TensorFlow 2 migration
- [x] New feature (non-breaking change which adds functionality)
- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)
- [ ] A new research paper code implementation
- [ ] Other (Specify)

## Tests

> :memo: Please describe the tests that you ran to verify your changes.
>  Ran through the Colab, it works.
> * Provide instructions so we can reproduce.  
> * Please also list any relevant details for your test configuration.  

**Test Configuration**:

## Checklist

- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).
- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).
- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).
- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.
- [x] I have commented my code, particularly in hard-to-understand areas.
- [x] I have made corresponding changes to the documentation.
- [x] My changes generate no new warnings.
- [x] I have added tests that prove my fix is effective or that my feature works.
",kmindspark,b'cla: yes',2020-07-09T06:48:32Z,2020-07-09T07:39:20Z,,,,,,,
8809,Merged commit includes the following changes:,"320335495  by rathodv:

    Remove hparams support form TF1 main binaries as its not available in TF1.15 runtime on cloud ai platform.

--
320278161  by ronnyvotel:

    Exposing DensePose fields to model libraries.

--
320277319  by rathodv:

    Remove TPU Name check since TPU is automatically inferred under cloud AI platform.

--
320258215  by rathodv:

    Internal Change.

--
320245458  by yuhuic:

    Updated the CenterNet restore_from_objects function to be compatible with
    existing configs that load converted checkpoints.

--
320225405  by jonathanhuang:

    Small change to Keras box predictor and box heads to fix export errors for SSD and Faster R-CNN.

--
320145077  by aom:

    Implements EfficientDet feature extractor.

--

PiperOrigin-RevId: 320335495

# Description

> :memo: Please include a summary of the change. 
>  
> * Please also include relevant motivation and context.  
> * List any dependencies that are required for this change.  

## Type of change

For a new feature or function, please create an issue first to discuss it
with us before submitting a pull request.

Note: Please delete options that are not relevant.

- [ ] Bug fix (non-breaking change which fixes an issue)
- [ ] Documentation update
- [x] TensorFlow 2 migration
- [ ] New feature (non-breaking change which adds functionality)
- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)
- [ ] A new research paper code implementation
- [ ] Other (Specify)

## Tests

> :memo: Please describe the tests that you ran to verify your changes.
>  
> * Provide instructions so we can reproduce.  
> * Please also list any relevant details for your test configuration.  

**Test Configuration**:

## Checklist

- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).
- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).
- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).
- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.
- [ ] I have commented my code, particularly in hard-to-understand areas.
- [ ] I have made corresponding changes to the documentation.
- [ ] My changes generate no new warnings.
- [ ] I have added tests that prove my fix is effective or that my feature works.
",tombstone,b'cla: yes',2020-07-09T06:18:13Z,2020-07-09T06:28:13Z,,,,,,,
8806,object_detection_tutorial -- ModuleNotFoundError: No module named 'tensorflow.contrib',"# Prerequisites

Please answer the following questions for yourself before submitting an issue.

- [x] I am using the latest TensorFlow Model Garden release and TensorFlow 2.
- [x] I am reporting the issue to the correct repository. (Model Garden official or research directory)
- [x] I checked to make sure that this issue has not already been filed.

## 1. The entire URL of the file you are using

https://github.com/tensorflow/models/blob/master/research/object_detection/colab_tutorials/object_detection_tutorial.ipynb

## 2. Describe the bug

The object_detection_tutorial is set to use tensorflow 2 but relies on tensorflow.contrib which has been removed from tensorflow 2.

## 3. Steps to reproduce

1. Pull the recent version of the tensorflow models
2. install all dependencies
3. run the object detection tutorial line by line
4. Error will occur in the ""Import the object detection module"" section.

## 4. Expected behavior

https://github.com/tensorflow/tensorflow/issues/30794 indicates that this code does not exist in tensorflow 2. The tutorial is set up to run on tensorflow 2. I would expect this to either be set to use tensorflow 1 or to be modified to work with tensorflow 2.

## 5. Additional context

I---------------------------------------------------------------------------
ModuleNotFoundError                       Traceback (most recent call last)
<ipython-input-5-7035655b948a> in <module>
----> 1 from object_detection.utils import ops as utils_ops
      2 from object_detection.utils import label_map_util
      3 from object_detection.utils import visualization_utils as vis_util

~/opt/anaconda3/envs/SSD/lib/python3.6/site-packages/object_detection/utils/ops.py in <module>
     26 from six.moves import zip
     27 import tensorflow.compat.v1 as tf
---> 28 import tf_slim as slim
     29 from object_detection.core import standard_fields as fields
     30 from object_detection.utils import shape_utils

~/opt/anaconda3/envs/SSD/lib/python3.6/site-packages/tf_slim/__init__.py in <module>
     21 
     22 # pylint: disable=unused-import,line-too-long,g-importing-member,wildcard-import
---> 23 from tf_slim import evaluation
     24 from tf_slim import learning
     25 from tf_slim import model_analyzer

~/opt/anaconda3/envs/SSD/lib/python3.6/site-packages/tf_slim/evaluation.py in <module>
    129 from __future__ import print_function
    130 
--> 131 from tensorflow.contrib.training.python.training import evaluation
    132 # pylint:disable=g-direct-tensorflow-import
    133 from tensorflow.python.summary import summary

ModuleNotFoundError: No module named 'tensorflow.contrib'

## 6. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS Mojave 10.14.6
- TensorFlow version (use command below): 2.0.0
- Python version: 3.6.10
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source): 
- CUDA/cuDNN version: n/a
- GPU model and memory: n/a

# Name                    Version                   Build  Channel
_tflow_select             2.3.0                       mkl  
absl-py                   0.9.0                    py36_0    conda-forge
appnope                   0.1.0           py36h9f0ad1d_1001    conda-forge
astor                     0.8.1              pyh9f0ad1d_0    conda-forge
attrs                     19.3.0                     py_0    conda-forge
backcall                  0.2.0              pyh9f0ad1d_0    conda-forge
bleach                    3.1.5              pyh9f0ad1d_0    conda-forge
brotlipy                  0.7.0           py36h37b9a7d_1000    conda-forge
c-ares                    1.15.0            h01d97ff_1001    conda-forge
ca-certificates           2020.6.20            hecda079_0    conda-forge
certifi                   2020.6.20        py36h9f0ad1d_0    conda-forge
cffi                      1.14.0           py36h356ff06_0    conda-forge
chardet                   3.0.4           py36h9f0ad1d_1006    conda-forge
contextlib2               0.6.0.post1                py_0    conda-forge
cryptography              2.9.2            py36hc9d8292_0    conda-forge
cycler                    0.10.0                     py_2    conda-forge
cython                    0.29.20          py36h0130604_0    conda-forge
dbus                      1.13.6               h2f22bb5_0    conda-forge
decorator                 4.4.2                      py_0    conda-forge
defusedxml                0.6.0                      py_0    conda-forge
entrypoints               0.3             py36h9f0ad1d_1001    conda-forge
expat                     2.2.9                h4a8c4bd_2    conda-forge
freetype                  2.10.2               h8da9a1a_0    conda-forge
gast                      0.2.2                      py_0    conda-forge
gettext                   0.19.8.1          h46ab8bc_1002    conda-forge
glib                      2.65.0               h577aef8_0    conda-forge
google-pasta              0.2.0              pyh8c360ce_0    conda-forge
grpcio                    1.27.2           py36h7c1f37e_0    conda-forge
h5py                      2.10.0          nompi_py36hdec09d9_103    conda-forge
hdf5                      1.10.6          nompi_h3e39495_100    conda-forge
icu                       64.2                 h6de7cb9_1    conda-forge
idna                      2.10               pyh9f0ad1d_0    conda-forge
importlib-metadata        1.7.0            py36h9f0ad1d_0    conda-forge
importlib_metadata        1.7.0                         0    conda-forge
ipykernel                 5.3.1            py36h95af2a2_0    conda-forge
ipython                   7.16.1           py36h95af2a2_0    conda-forge
ipython_genutils          0.2.0                      py_1    conda-forge
ipywidgets                7.5.1                      py_0    conda-forge
jedi                      0.17.1           py36h9f0ad1d_0    conda-forge
jinja2                    2.11.2             pyh9f0ad1d_0    conda-forge
jpeg                      9d                   h0b31af3_0    conda-forge
json5                     0.9.4              pyh9f0ad1d_0    conda-forge
jsonschema                3.2.0            py36h9f0ad1d_1    conda-forge
jupyter                   1.0.0                      py_2    conda-forge
jupyter_client            6.1.5                      py_0    conda-forge
jupyter_console           6.1.0                      py_1    conda-forge
jupyter_core              4.6.3            py36h9f0ad1d_1    conda-forge
jupyterlab                2.1.5                      py_0    conda-forge
jupyterlab_server         1.2.0                      py_0    conda-forge
keras-applications        1.0.8                      py_1    conda-forge
keras-preprocessing       1.1.0                      py_0    conda-forge
kiwisolver                1.2.0            py36h863e41a_0    conda-forge
krb5                      1.17.1               h14dd6a4_1    conda-forge
libblas                   3.8.0               17_openblas    conda-forge
libcblas                  3.8.0               17_openblas    conda-forge
libclang                  9.0.1           default_hf57f61e_0    conda-forge
libcxx                    10.0.0               h1af66ff_2    conda-forge
libedit                   3.1.20191231         hed1e85f_0    conda-forge
libffi                    3.2.1             h4a8c4bd_1007    conda-forge
libgfortran               4.0.0                         2    conda-forge
libiconv                  1.15              h0b31af3_1006    conda-forge
liblapack                 3.8.0               17_openblas    conda-forge
libllvm9                  9.0.1                h7475705_1    conda-forge
libopenblas               0.3.10               h3d69b6c_0    conda-forge
libpng                    1.6.37               hbbe82c9_1    conda-forge
libpq                     12.2                 h489d428_1    conda-forge
libprotobuf               3.12.3               hd174df1_0    conda-forge
libsodium                 1.0.17               h01d97ff_0    conda-forge
libtiff                   4.1.0                h2ae36a8_6    conda-forge
libwebp-base              1.1.0                h0b31af3_3    conda-forge
libxml2                   2.9.10               h53d96d6_0    conda-forge
libxslt                   1.1.33               h320ff13_0    conda-forge
llvm-openmp               10.0.0               h28b9765_0    conda-forge
lxml                      4.5.1            py36h2ab0afd_0    conda-forge
lz4-c                     1.9.2                h4a8c4bd_1    conda-forge
markdown                  3.2.2                      py_0    conda-forge
markupsafe                1.1.1            py36h37b9a7d_1    conda-forge
matplotlib                3.2.2                         1    conda-forge
matplotlib-base           3.2.2            py36h83d3ec1_1    conda-forge
mistune                   0.8.4           py36h37b9a7d_1001    conda-forge
nbconvert                 5.6.1            py36h9f0ad1d_1    conda-forge
nbformat                  5.0.7                      py_0    conda-forge
ncurses                   6.1               h0a44026_1002    conda-forge
notebook                  6.0.3            py36h9f0ad1d_1    conda-forge
nspr                      4.20              h0a44026_1000    conda-forge
nss                       3.47                 hc0980d9_0    conda-forge
numpy                     1.18.5           py36hdc5ca10_0    conda-forge
object-detection          0.1                      pypi_0    pypi
olefile                   0.46                       py_0    conda-forge
openssl                   1.1.1g               h0b31af3_0    conda-forge
opt_einsum                3.2.1                      py_0    conda-forge
packaging                 20.4               pyh9f0ad1d_0    conda-forge
pandoc                    2.10                          0    conda-forge
pandocfilters             1.4.2                      py_1    conda-forge
parso                     0.7.0              pyh9f0ad1d_0    conda-forge
pcre                      8.44                 h4a8c4bd_0    conda-forge
pexpect                   4.8.0            py36h9f0ad1d_1    conda-forge
pickleshare               0.7.5           py36h9f0ad1d_1001    conda-forge
pillow                    7.2.0            py36h2ae5dfa_0    conda-forge
pip                       20.1.1                     py_1    conda-forge
prometheus_client         0.8.0              pyh9f0ad1d_0    conda-forge
prompt-toolkit            3.0.5                      py_1    conda-forge
prompt_toolkit            3.0.5                         1    conda-forge
protobuf                  3.12.3           py36h0130604_0    conda-forge
ptyprocess                0.6.0                   py_1001    conda-forge
pycocotools               2.0.1            py36h37b9a7d_1    conda-forge
pycparser                 2.20               pyh9f0ad1d_2    conda-forge
pygments                  2.6.1                      py_0    conda-forge
pyopenssl                 19.1.0                     py_1    conda-forge
pyparsing                 2.4.7              pyh9f0ad1d_0    conda-forge
pyqt                      5.12.3           py36haa9e2f4_3    conda-forge
pyqt5-sip                 4.19.18                  pypi_0    pypi
pyqtchart                 5.12                     pypi_0    pypi
pyqtwebengine             5.12.1                   pypi_0    pypi
pyrsistent                0.16.0           py36h37b9a7d_0    conda-forge
pysocks                   1.7.1            py36h9f0ad1d_1    conda-forge
python                    3.6.10          h4334963_1011_cpython    conda-forge
python-dateutil           2.8.1                      py_0    conda-forge
python_abi                3.6                     1_cp36m    conda-forge
pyzmq                     19.0.1           py36h820b253_0    conda-forge
qt                        5.12.5               h514805e_3    conda-forge
qtconsole                 4.7.5              pyh9f0ad1d_0    conda-forge
qtpy                      1.9.0                      py_0    conda-forge
readline                  8.0                  hcfe32e1_0    conda-forge
requests                  2.24.0             pyh9f0ad1d_0    conda-forge
scipy                     1.5.0            py36h1dac7e4_0    conda-forge
send2trash                1.5.0                      py_0    conda-forge
setuptools                47.3.1           py36h9f0ad1d_0    conda-forge
six                       1.15.0             pyh9f0ad1d_0    conda-forge
sqlite                    3.32.3               h93121df_0    conda-forge
tensorboard               2.0.0              pyhb38c66f_1  
tensorflow                2.0.0           mkl_py36ha38f243_0  
tensorflow-base           2.0.0           mkl_py36h66b1bf0_0  
tensorflow-estimator      2.0.0              pyh2649769_0  
termcolor                 1.1.0                      py_2    conda-forge
terminado                 0.8.3            py36h9f0ad1d_1    conda-forge
testpath                  0.4.4                      py_0    conda-forge
tf_slim                   1.0                        py_1    conda-forge
tk                        8.6.10               hbbe82c9_0    conda-forge
tornado                   6.0.4            py36h37b9a7d_1    conda-forge
traitlets                 4.3.3            py36h9f0ad1d_1    conda-forge
urllib3                   1.25.9                     py_0    conda-forge
wcwidth                   0.2.5              pyh9f0ad1d_0    conda-forge
webencodings              0.5.1                      py_1    conda-forge
werkzeug                  1.0.1              pyh9f0ad1d_0    conda-forge
wheel                     0.34.2                     py_1    conda-forge
widgetsnbextension        3.5.1                    py36_0    conda-forge
wrapt                     1.12.1           py36h37b9a7d_1    conda-forge
xz                        5.2.5                h0b31af3_0    conda-forge
zeromq                    4.3.2                h6de7cb9_2    conda-forge
zipp                      3.1.0                      py_0    conda-forge
zlib                      1.2.11            h0b31af3_1006    conda-forge
zstd                      1.4.4                h4b3e974_3    conda-forge


",mgon5170,b'models:research stat:awaiting response type:bug',2020-07-08T15:45:13Z,2020-09-10T13:59:51Z,,,,,,,
8803,Merged commit includes the following changes:,"320117767  by ronnyvotel:

    DensePose postprocessing implementation.

--
320065853  by ronnyvotel:

    Updating how masks are reframed, so that it works on float and uint8 masks.

--
320061717  by yuhuic:

    Updated CenterNet restore_from_objects to allow the model to load the
    checkpoints saved during training.

--
319835172  by ronnyvotel:

    Updating how the DensePose UV Symmetries MAT file path is constructed and loaded.

--
319834678  by ronnyvotel:

    First update to CenterNetMetaArch for DensePose. Adding prediction and loss functionality.

--
319810261  by rathodv:

    Create a setup.py file to simplify installation.

    Usage:
    ""python object_detection/packages/tf1/setup.py install"" for TF1.
    ""python object_detection/packages/tf2/setup.py install"" for TF2.

    or to create source distribution
    ""python object_detection/packages/tf1/setup.py sdist"" for TF1.
    ""python object_detection/packages/tf2/setup.py sdist"" for TF2.

--
319803041  by sbeery:

    Updating documentation for export

--
319688087  by rathodv:

    Update as_matrix() to to_numpy() to avoid failures with python3.6

--
319686183  by vighneshb:

    Require tpu_name when use_tpu is set.

--
319613327  by aom:

    EfficientDet-style Data Augmentation.

--
319572180  by rathodv:

    Add TF2 SSD FPN (a.k.a RetinaNet) configs.

--
319553823  by rathodv:

    Internal Change.

--

PiperOrigin-RevId: 320117767

# Description

> :memo: Please include a summary of the change. 
>  
> * Please also include relevant motivation and context.  
> * List any dependencies that are required for this change.  

## Type of change

For a new feature or function, please create an issue first to discuss it
with us before submitting a pull request.

Note: Please delete options that are not relevant.

- [ ] Bug fix (non-breaking change which fixes an issue)
- [ ] Documentation update
- [ ] TensorFlow 2 migration
- [ ] New feature (non-breaking change which adds functionality)
- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)
- [ ] A new research paper code implementation
- [ ] Other (Specify)

## Tests

> :memo: Please describe the tests that you ran to verify your changes.
>  
> * Provide instructions so we can reproduce.  
> * Please also list any relevant details for your test configuration.  

**Test Configuration**:

## Checklist

- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).
- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).
- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).
- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.
- [ ] I have commented my code, particularly in hard-to-understand areas.
- [ ] I have made corresponding changes to the documentation.
- [ ] My changes generate no new warnings.
- [ ] I have added tests that prove my fix is effective or that my feature works.
",tombstone,b'cla: yes',2020-07-08T07:05:00Z,2020-07-08T07:09:01Z,,,,,,,
8800,Add Retinanet colab tutorial with rubber ducks data,"# Description
Retinanet colab tutorial with rubber ducks test data created by @jch1, modified to work externally
> :memo: Please include a summary of the change. 
>  Adding the colab, test images, and config
> * Please also include relevant motivation and context.  
> * List any dependencies that are required for this change.  

## Type of change

For a new feature or function, please create an issue first to discuss it
with us before submitting a pull request.

Note: Please delete options that are not relevant.

- [ ] Bug fix (non-breaking change which fixes an issue)
- [ ] Documentation update
- [ ] TensorFlow 2 migration
- [x] New feature (non-breaking change which adds functionality)
- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)
- [ ] A new research paper code implementation
- [ ] Other (Specify)

## Tests

> :memo: Please describe the tests that you ran to verify your changes.
>  The colab notebook runs end-to-end.
> * Provide instructions so we can reproduce.  
> * Please also list any relevant details for your test configuration.  

**Test Configuration**: Colab CPU & GPU environments

## Checklist

- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).
- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).
- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).
- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.
- [x] I have commented my code, particularly in hard-to-understand areas.
- [x] I have made corresponding changes to the documentation.
- [x] My changes generate no new warnings.
- [ ] I have added tests that prove my fix is effective or that my feature works.
",kmindspark,b'cla: yes',2020-07-07T17:56:34Z,2020-07-08T19:55:20Z,,,,,,,
8795,Create tensorflow1,"image training

# Description

> :memo: Please include a summary of the change. 
>  
> * Please also include relevant motivation and context.  
> * List any dependencies that are required for this change.  

## Type of change

For a new feature or function, please create an issue first to discuss it
with us before submitting a pull request.

Note: Please delete options that are not relevant.

- [x] Bug fix (non-breaking change which fixes an issue)
- [ ] Documentation update
- [x] TensorFlow 2 migration
- [ ] New feature (non-breaking change which adds functionality)
- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)
- [ ] A new research paper code implementation
- [ ] Other (Specify)

## Tests

> :memo: Please describe the tests that you ran to verify your changes.
>  
> * Provide instructions so we can reproduce.  
> * Please also list any relevant details for your test configuration.  

**Test Configuration**:

## Checklist

- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).
- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).
- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).
- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.
- [ ] I have commented my code, particularly in hard-to-understand areas.
- [ ] I have made corresponding changes to the documentation.
- [x] My changes generate no new warnings.
- [ ] I have added tests that prove my fix is effective or that my feature works.
",DaudYakub,b'cla: no',2020-07-07T06:13:13Z,2020-07-07T06:20:15Z,,,,,,,
8792,[Deeplab] eval.py/vis.py not working for custom dataset,"# Prerequisites

## 1. The entire URL of the file you are using

https://github.com/tensorflow/models/tree/master/research/deeplab

## 2. Describe the bug

I am training deeplab with my custom dataset that has 25 images for training and 11 for testing. It has only one class to detect, so num_classes=2. Image size is 720x2000. Training works fine and I've also set the crop_size to 721x2001. When running eval.py, I get the following error: (0) Invalid argument: assertion failed: [`labels` out of bound] [Condition x < y did not hold element-wise:] [x (mean_iou/confusion_matrix/control_dependency:0) = ] [0 0 0...] [y (mean_iou/Cast_1:0) = ] [2]
         [[node mean_iou/confusion_matrix/assert_less/Assert/AssertGuard/Assert (defined at /mnt/abandrei/anaconda3/envs/deeplab_tf/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:1748) ]]
         [[mean_iou/confusion_matrix/stack_1/_4491]]
  (1) Invalid argument: assertion failed: [`labels` out of bound] [Condition x < y did not hold element-wise:] [x (mean_iou/confusion_matrix/control_dependency:0) = ] [0 0 0...] [y (mean_iou/Cast_1:0) = ] [2]
         [[node mean_iou/confusion_matrix/assert_less/Assert/AssertGuard/Assert (defined at /mnt/abandrei/anaconda3/envs/deeplab_tf/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:1748) ]]

I've also tried to do the changes in https://github.com/tensorflow/models/issues/4203#issuecomment-407952737, but then I get the following error: (0) Invalid argument: Incompatible shapes: [1442721] vs. [1442684]
         [[{{node false_negatives_1/Mul}}]]
         [[mean_iou/AssignAdd/_4507]]
  (1) Invalid argument: Incompatible shapes: [1442721] vs. [1442684]
         [[{{node false_negatives_1/Mul}}]]

In this case, I understand that 1442721 is actually 721x2001, but I am not sure about the second shape and what causes it. 

## 3. Steps to reproduce

python3 eval.py   --logtostderr   --eval_split=""val""   --model_variant=""xception_65""   --atrous_rates=6   --atrous_rates=12   --atrous_rates=18   --output_stride=16   --decoder_output_stride=4   --eval_crop_size=""721,2001"" --eval_logdir=datasets/mydataset/exp/train_on_trainval_set/eval --checkpoint_dir=datasets/mydataset/exp/train_on_trainval_set/train  --dataset_dir=datasets/mydataset/tfrecord --eval_batch_size=1 --max_number_of_evaluations=1 --dataset=""mydataset""

_mydataset_INFORMATION = DatasetDescriptor(
    splits_to_sizes={
        'train': 25,  # num of samples in images/training
        'val': 11,  # num of samples in images/validation
    },
    num_classes=2,
    ignore_label=255,
)

## 4. Expected behavior

The evaluation should be performed.

## 6. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04
- TensorFlow installed from (source or binary): binary (pip)
- TensorFlow version (use command below): v1.15.0-rc3-22-g590d6ee 1.15.0
- Python version: 3.7.7
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:10.0/ no cudnn
- GPU model and memory: Tesla P4
",AndreiBaraian,b'models:research type:bug',2020-07-06T17:46:23Z,2020-08-24T15:23:13Z,,,,,,,
8790,AttributeError: 'SSDMobileNetV2KerasFeatureExtractor' object has no attribute 'restore_from_classification_checkpoint_fn',"[<!--]([url](url
<img width=""896"" alt=""Screen Shot 2020-07-06 at 11 53 41 AM"" src=""https://user-images.githubusercontent.com/60193765/86619150-a482aa80-bf7f-11ea-8533-5cbc52d8c8e2.png"">
))
As per our GitHub Policy (https://github.com/tensorflow/models/blob/master/ISSUES.md), we only address code bugs, documentation issues, and feature requests on GitHub.

We will automatically close questions and help related issues.

Please go to Stack Overflow (http://stackoverflow.com/questions/tagged/tensorflow-model-garden) for questions and help.

-->
",purveshsharma50,b'models:research type:support',2020-07-06T16:56:59Z,2020-07-14T23:27:23Z,,,,,,,
8781,Retrieval questions and help,"Hi @BasiaFusinska/@andrefaraujo


I have some questions regarding the retrieval process for the Delf model. Please consider the below scenarios.

How can we retrieve the landmark class corresponding to query images with matching scores?

Thanks,
Pardeep

<!--
As per our GitHub Policy (https://github.com/tensorflow/models/blob/master/ISSUES.md), we only address code bugs, documentation issues, and feature requests on GitHub.

We will automatically close questions and help related issues.

Please go to Stack Overflow (http://stackoverflow.com/questions/tagged/tensorflow-model-garden) for questions and help.

-->
",chhokarpardeep,b'type:support',2020-07-04T11:15:47Z,2020-07-06T10:34:28Z,,,,,,,
8779,Merged commit includes the following changes:,"319539052  by rathodv:

    Internal Change.

--
319537186  by rathodv:

    Internal Change

--
319320800  by jonathanhuang:

    Internal changes.

--
319260368  by ronnyvotel:

    Adding a target assigner for DensePose.

--
319240476  by sbeery:

    switching to main() for argparse

--

PiperOrigin-RevId: 319539052

# Description

> :memo: Please include a summary of the change. 
>  
> * Please also include relevant motivation and context.  
> * List any dependencies that are required for this change.  

## Type of change

For a new feature or function, please create an issue first to discuss it
with us before submitting a pull request.

Note: Please delete options that are not relevant.

- [ ] Bug fix (non-breaking change which fixes an issue)
- [ ] Documentation update
- [ ] TensorFlow 2 migration
- [ ] New feature (non-breaking change which adds functionality)
- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)
- [ ] A new research paper code implementation
- [ ] Other (Specify)

## Tests

> :memo: Please describe the tests that you ran to verify your changes.
>  
> * Provide instructions so we can reproduce.  
> * Please also list any relevant details for your test configuration.  

**Test Configuration**:

## Checklist

- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).
- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).
- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).
- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.
- [ ] I have commented my code, particularly in hard-to-understand areas.
- [ ] I have made corresponding changes to the documentation.
- [ ] My changes generate no new warnings.
- [ ] I have added tests that prove my fix is effective or that my feature works.
",tombstone,b'cla: yes',2020-07-04T00:59:36Z,2020-07-04T02:18:01Z,,,,,,,
8777,DELF: absl.flags._exceptions.DuplicateFlagError: The flag 'seed' is defined twice,"# Prerequisites
- I am using the latest TensorFlow Model Garden release and TensorFlow 2.
- I am reporting the issue to the correct repository. ( research directory)
- I checked to make sure that this issue has not already been filed.

I followed the instructuins for Delf instalaltion from the link:
https://github.com/tensorflow/models/blob/master/research/delf/INSTALL_INSTRUCTIONS.md 

Then used the follwing instruction to train the model
https://github.com/tensorflow/models/blob/master/research/delf/delf/python/training/README.md

## 2. Describe the bug
Traceback (most recent call last):
  File ""models/research/delf/delf/python/training/train.py"", line 50, in <module>
    flags.DEFINE_integer('seed', 0, 'Seed to training dataset.')
  File ""/opt/conda/lib/python3.7/site-packages/absl/flags/_defines.py"", line 315, in DEFINE_integer
    DEFINE(parser, name, default, help, flag_values, serializer, **args)
  File ""/opt/conda/lib/python3.7/site-packages/absl/flags/_defines.py"", line 82, in DEFINE
    flag_values, module_name)
  File ""/opt/conda/lib/python3.7/site-packages/absl/flags/_defines.py"", line 104, in DEFINE_flag
    fv[flag.name] = flag
  File ""/opt/conda/lib/python3.7/site-packages/absl/flags/_flagvalues.py"", line 430, in __setitem__
    raise _exceptions.DuplicateFlagError.from_flag(name, self)
absl.flags._exceptions.DuplicateFlagError: The flag 'seed' is defined twice. First from delf.python.training.build_image_dataset, Second from models/research/delf/delf/python/training/train.py.  Description from first occurrence: (Optional) The seed to be used while shuffling the traindataset when generating the TRAIN and VALIDATION splits.Recommended for splits reproducibility purposes.

A clear and concise description of what the bug is.
first I executed the script python3 delf/python/training/build_image_dataset.py 
then python3 delf/python/training/train.py
I think the flag is redefined  in the second script and for that, there is flag duplicate 
",waelkht,b'models:research type:bug',2020-07-03T10:31:48Z,2020-08-15T21:15:20Z,,,,,,,
8776,"Message type ""object_detection.protos.DetectionModel"" has no field named ""loss""","I am training model ssd_mobilenet_v2_quantized_coco
tensorflow = 1.15.0
protobuf = 3.12.3
Can you fix me this error? thank you


WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py:125: main (from main) is deprecated and will be removed in a future version.
Instructions for updating:
Use object_detection/model_main.py.
Traceback (most recent call last):
File ""train.py"", line 184, in 
tf.app.run()
File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 125, in run
_sys.exit(main(argv))
File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py"", line 324, in new_func
return func(*args, **kwargs)
File ""train.py"", line 93, in main
FLAGS.pipeline_config_path)
File ""/content/tensorflow1/models/research/object_detection/utils/config_util.py"", line 96, in get_configs_from_pipeline_file
text_format.Merge(proto_str, pipeline_config)
File ""/usr/local/lib/python3.6/dist-packages/google/protobuf/text_format.py"", line 693, in Merge
allow_unknown_field=allow_unknown_field)
File ""/usr/local/lib/python3.6/dist-packages/google/protobuf/text_format.py"", line 760, in MergeLines
return parser.MergeLines(lines, message)
File ""/usr/local/lib/python3.6/dist-packages/google/protobuf/text_format.py"", line 785, in MergeLines
self._ParseOrMerge(lines, message)
File ""/usr/local/lib/python3.6/dist-packages/google/protobuf/text_format.py"", line 807, in _ParseOrMerge
self._MergeField(tokenizer, message)
File ""/usr/local/lib/python3.6/dist-packages/google/protobuf/text_format.py"", line 932, in _MergeField
merger(tokenizer, message, field)
File ""/usr/local/lib/python3.6/dist-packages/google/protobuf/text_format.py"", line 1006, in _MergeMessageField
self._MergeField(tokenizer, sub_message)
File ""/usr/local/lib/python3.6/dist-packages/google/protobuf/text_format.py"", line 899, in _MergeField
(message_descriptor.full_name, name))
google.protobuf.text_format.ParseError: 109:5 : Message type ""object_detection.protos.DetectionModel"" has no field named ""loss""
",sirvnvu98,b'models:research type:bug',2020-07-03T10:26:44Z,2020-07-24T08:51:46Z,,,,,,,
8774,How can I find a Colab example of using Tensorflow 2 to train for Object Detection?,"<!--
As per our GitHub Policy (https://github.com/tensorflow/models/blob/master/ISSUES.md), we only address code bugs, documentation issues, and feature requests on GitHub.

We will automatically close questions and help related issues.

Please go to Stack Overflow (http://stackoverflow.com/questions/tagged/tensorflow-model-garden) for questions and help.

-->
",contractorwolf,b'models:research type:support',2020-07-03T00:22:01Z,2020-07-14T23:29:21Z,,,,,,,
8765,Protos for object detection contain errors,"- I am using the latest TensorFlow Model Garden release and TensorFlow 2.
- I am reporting the issue to the correct repository. (Model Garden official or research directory)
- I checked to make sure that this issue has not already been filed.

## 1. The entire URL of the file you are using

https://github.com/tensorflow/models/tree/master/research/object_detection/protos

## 2. Describe the bug

I couldn't solve an error in a previous version of the object detection directory where a link seems to be broken. So I attempted to create a clean instance.

Following the install instructions found here:
https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/installation.md

I ran the following from models/research/: 
protoc object_detection/protos/*.proto --python_out=.


I received the following messages:
object_detection/protos/flexible_grid_anchor_generator.proto: File not found.
object_detection/protos/grid_anchor_generator.proto: File not found.
object_detection/protos/multiscale_anchor_generator.proto: File not found.
object_detection/protos/ssd_anchor_generator.proto: File not found.
research/object_detection/protos/anchor_generator.proto:5:1: Import ""object_detection/protos/flexible_grid_anchor_generator.proto"" was not found or had errors.
research/object_detection/protos/anchor_generator.proto:6:1: Import ""object_detection/protos/grid_anchor_generator.proto"" was not found or had errors.
research/object_detection/protos/anchor_generator.proto:7:1: Import ""object_detection/protos/multiscale_anchor_generator.proto"" was not found or had errors.
research/object_detection/protos/anchor_generator.proto:8:1: Import ""object_detection/protos/ssd_anchor_generator.proto"" was not found or had errors.
research/object_detection/protos/anchor_generator.proto:14:5: ""GridAnchorGenerator"" is not defined.
research/object_detection/protos/anchor_generator.proto:15:5: ""SsdAnchorGenerator"" is not defined.
research/object_detection/protos/anchor_generator.proto:16:5: ""MultiscaleAnchorGenerator"" is not defined.
research/object_detection/protos/anchor_generator.proto:17:5: ""FlexibleGridAnchorGenerator"" is not defined.

I verified flexible_grid_anchor_generator.proto, grid_anchor_generator.proto, multiscale_anchor_generator.proto, and ssd_anchor_generator.proto are in the proto directory. 

## 3. Steps to reproduce

1. Clone from https://github.com/tensorflow/models
2. run protoc object_detection/protos/*.proto --python_out=. from models/research
3. Receive errors.

## 4. Expected behavior

When running protoc object_detection/protos/*.proto --python_out=. I expected for all files to be processed and .py files to be generated.

## 5. Additional context

Include any logs that would be helpful to diagnose the problem.

## 6. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS Mojave 10.14.6
- TensorFlow installed from (source or binary): 2.3.0
- TensorFlow version (use command below):
- Python version: 3.6.10
-conda version: 4.8.3


<!-- 
Collect system information using our environment capture script.
https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can also obtain the TensorFlow version with:

1. TensorFlow 1.0
`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

2. TensorFlow 2.0
`python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`
-->
",mgon5170,b'models:research type:bug',2020-07-01T16:34:23Z,2020-07-10T18:53:24Z,,,,,,,
8764,Adjust faster rcnn meta arch rpn feature to multilevel feature,"# Description

> :memo: Adjust faster rcnn meta arch rpn feature to multilevel feature.
>  
> * Please also include relevant motivation and context.  
> * List any dependencies that are required for this change.  

## Type of change

For a new feature or function, please create an issue first to discuss it
with us before submitting a pull request.

Note: Please delete options that are not relevant.

- [ ] Bug fix (non-breaking change which fixes an issue)
- [ ] Documentation update
- [ ] TensorFlow 2 migration
- [ ] New feature (non-breaking change which adds functionality)
- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)
- [ ] A new research paper code implementation
- [x] Other (Change meta arch file.)

## Tests

> :memo: Please describe the tests that you ran to verify your changes.
>  
> * Provide instructions so we can reproduce.  
> * Please also list any relevant details for your test configuration.  

**Test Configuration**:

## Checklist

- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).
- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).
- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).
- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.
- [ ] I have commented my code, particularly in hard-to-understand areas.
- [ ] I have made corresponding changes to the documentation.
- [ ] My changes generate no new warnings.
- [ ] I have added tests that prove my fix is effective or that my feature works.
",syiming,b'cla: yes',2020-07-01T15:31:24Z,2020-08-26T06:15:56Z,,,,,,,
8762,Remove extraneous spaces in FasterRCNN Resnet keras fpn feature extractor,"# Description

> :memo: Remove extraneous spaces in FasterRCNN Resnet fpn Keras feature extractor


## Type of change

For a new feature or function, please create an issue first to discuss it
with us before submitting a pull request.

Note: Please delete options that are not relevant.

- [ ] Bug fix (non-breaking change which fixes an issue)
- [ ] Documentation update
- [ ] TensorFlow 2 migration
- [ ] New feature (non-breaking change which adds functionality)
- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)
- [ ] A new research paper code implementation
- [x] Other (Format)

## Tests

> :memo: Please describe the tests that you ran to verify your changes.
>  
> * Provide instructions so we can reproduce.  
> * Please also list any relevant details for your test configuration.  

**Test Configuration**:

## Checklist

- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).
- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).
- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).
- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.
- [x] I have commented my code, particularly in hard-to-understand areas.
- [x] I have made corresponding changes to the documentation.
- [x] My changes generate no new warnings.
- [x] I have added tests that prove my fix is effective or that my feature works.
",syiming,b'cla: yes',2020-07-01T07:16:43Z,2020-07-01T18:58:17Z,,,,,,,
8761,Merged commit includes the following changes:,"319125512  by aom:

    Internal change

--
319108395  by rathodv:

    Internal Change

--
319106259  by ronnyvotel:

    Updating input pipeline to return DensePose labels.

--

PiperOrigin-RevId: 319125512

# Description

> :memo: Please include a summary of the change. 
>  
> * Please also include relevant motivation and context.  
> * List any dependencies that are required for this change.  

## Type of change

For a new feature or function, please create an issue first to discuss it
with us before submitting a pull request.

Note: Please delete options that are not relevant.

- [ ] Bug fix (non-breaking change which fixes an issue)
- [ ] Documentation update
- [ ] TensorFlow 2 migration
- [ ] New feature (non-breaking change which adds functionality)
- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)
- [ ] A new research paper code implementation
- [ ] Other (Specify)

## Tests

> :memo: Please describe the tests that you ran to verify your changes.
>  
> * Provide instructions so we can reproduce.  
> * Please also list any relevant details for your test configuration.  

**Test Configuration**:

## Checklist

- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).
- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).
- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).
- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.
- [ ] I have commented my code, particularly in hard-to-understand areas.
- [ ] I have made corresponding changes to the documentation.
- [ ] My changes generate no new warnings.
- [ ] I have added tests that prove my fix is effective or that my feature works.
",tombstone,b'cla: yes',2020-07-01T06:12:27Z,2020-07-01T06:15:44Z,,,,,,,
8758,object_detection not supported in TF 2,"# Prerequisites

Please answer the following questions for yourself before submitting an issue.

- [X] I am using the latest TensorFlow Model Garden release and TensorFlow 2.
- [X] I am reporting the issue to the correct repository. (Model Garden official or research directory)
- [X] I checked to make sure that this issue has not already been filed.

## 1. The entire URL of the file you are using

https://github.com/tensorflow/models/tree/master/research/object_detection

## 2. Describe the bug

The `object_detection` API isn't supported under TensorFlow 2, which is a problem in general. In my specific case, I'm trying to create an object detection model and use `tflite` to deploy it on mobile, but due to [this bug in tflite](https://github.com/tensorflow/tensorflow/issues/38558) I'm stuck using `tf-nightly`. However, I also depend on the `object_detection` API, which is stuck on TF 1.x.

## 3. Steps to reproduce

1. Create a model using the `object_detection` API (TensorFlow 1.15).
1. Try to convert that model to a mobile format using `tflite` (TensorFlow 2). It will fail to convert (presumably due to mismatched TF versions).

## 4. Expected behavior

I should be able to use the `object_detection` API with the latest TensorFlow releases.

## 5. Additional context

N/A

## 6. System information

N/A",mgalgs,b'models:research type:bug',2020-06-30T21:38:44Z,2020-07-10T18:14:18Z,,,,,,,
8755,Merged commit includes the following changes:,"319052168  by rathodv:

    Change assertAllEqual to assertAllClose for Position Sensitive Crop and Resize to avoid flaky tests.

--
319044492  by rathodv:

    Internal change.

--
319039033  by ronnyvotel:

    Preprocessor ops for DensePose.

--
319035440  by sbeery:

    External beam code with DataFlow Support

--
318899436  by ronnyvotel:

    DensePose library for common operations like scaling, coordinate transformations, and flipping.

--
318833308  by Vivek Rathod:

      Internal Change

--

PiperOrigin-RevId: 319052168

# Description

> :memo: Please include a summary of the change. 
>  
> * Please also include relevant motivation and context.  
> * List any dependencies that are required for this change.  

## Type of change

For a new feature or function, please create an issue first to discuss it
with us before submitting a pull request.

Note: Please delete options that are not relevant.

- [ ] Bug fix (non-breaking change which fixes an issue)
- [ ] Documentation update
- [ ] TensorFlow 2 migration
- [ ] New feature (non-breaking change which adds functionality)
- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)
- [ ] A new research paper code implementation
- [ ] Other (Specify)

## Tests

> :memo: Please describe the tests that you ran to verify your changes.
>  
> * Provide instructions so we can reproduce.  
> * Please also list any relevant details for your test configuration.  

**Test Configuration**:

## Checklist

- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).
- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).
- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).
- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.
- [ ] I have commented my code, particularly in hard-to-understand areas.
- [ ] I have made corresponding changes to the documentation.
- [ ] My changes generate no new warnings.
- [ ] I have added tests that prove my fix is effective or that my feature works.
",tombstone,b'cla: yes',2020-06-30T17:47:02Z,2020-06-30T19:19:35Z,,,,,,,
8754,I was working with the VGGish model train_demo python file and could not understand the last part of function - _get_examples_batch,"<!--
As per our GitHub Policy (https://github.com/tensorflow/models/blob/master/ISSUES.md), we only address code bugs, documentation issues, and feature requests on GitHub.

We will automatically close questions and help related issues.

Please go to Stack Overflow (http://stackoverflow.com/questions/tagged/tensorflow-model-garden) for questions and help.

-->
I was working with the VGGish model train_demo python file. I could not understand why we are returning all the labels and spectrograms each time for training in the function _get_examples_batch. The question I had was since we have batch number shouldn't we supply a different subset of the data each time we train the same model?   
",tusharpoddar,b'stat:awaiting response type:support',2020-06-30T14:47:24Z,2020-07-29T07:38:22Z,,,,,,,
8752,"COCO-trained models for tf2,where can download?","# Prerequisites

Please answer the following questions for yourself before submitting an issue.

- [ X] I am using the latest TensorFlow Model Garden release and TensorFlow 2.

## 1. The entire URL of the file you are using

https://github.com/tensorflow/models/tree/master/research/...

## 2. Describe the bug
python3 legacy/train.py --logtostderr --train_dir=voc --pipeline_config_path=voc_lib/faster_rcnn_resnet101_pets.config

ValueError: faster_rcnn_resnet101 is not supported. See `model_builder.py` for features extractors compatible with different versions of Tensorflow


## 3. Steps to reproduce

WARNING:tensorflow:From /home/c/.local/lib/python3.6/site-packages/absl/app.py:250: main (from __main__) is deprecated and will be removed in a future version.
Instructions for updating:
Use object_detection/model_main.py.
W0630 14:38:04.062839 140272845739840 deprecation.py:323] From /home/c/.local/lib/python3.6/site-packages/absl/app.py:250: main (from __main__) is deprecated and will be removed in a future version.
Instructions for updating:
Use object_detection/model_main.py.
Traceback (most recent call last):
  File ""legacy/train.py"", line 186, in <module>
    tf.app.run()
  File ""/home/c/.local/lib/python3.6/site-packages/tensorflow/python/platform/app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""/home/c/.local/lib/python3.6/site-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/home/c/.local/lib/python3.6/site-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""/home/c/.local/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py"", line 324, in new_func
    return func(*args, **kwargs)
  File ""legacy/train.py"", line 182, in main
    graph_hook_fn=graph_rewriter_fn)
  File ""/usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/legacy/trainer.py"", line 248, in train
    detection_model = create_model_fn()
  File ""/usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/builders/model_builder.py"", line 950, in build
    add_summaries)
  File ""/usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/builders/model_builder.py"", line 510, in _build_faster_rcnn_model
    _check_feature_extractor_exists(frcnn_config.feature_extractor.type)
  File ""/usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/builders/model_builder.py"", line 208, in _check_feature_extractor_exists
    'Tensorflow'.format(feature_extractor_type))


## 4. Expected behavior



## 5. Additional context


## 6. System information

<!-- 
Collect system information using our environment capture script.
https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can also obtain the TensorFlow version with:

1. TensorFlow 1.0
`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

2. TensorFlow 2.0
`python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`
-->
>>> import tensorflow as tf
>>> print(tf.version.GIT_VERSION, tf.version.VERSION)
v2.2.0-rc4-8-g2b96f3662b 2.2.0

##according to model_builder.py, where is pretraining model for tf2?
",xpdrycry,b'models:research type:bug',2020-06-30T06:48:14Z,2020-07-14T23:30:54Z,,,,,,,
8751,Proper os path join for eval,"# Description

> :memo: Please include a summary of the change. 
>  
> * Please also include relevant motivation and context.  
> * List any dependencies that are required for this change.  

## Type of change

For a new feature or function, please create an issue first to discuss it
with us before submitting a pull request.

Note: Please delete options that are not relevant.

- [x] Bug fix (non-breaking change which fixes an issue)
- [ ] Documentation update
- [ ] TensorFlow 2 migration
- [ ] New feature (non-breaking change which adds functionality)
- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)
- [ ] A new research paper code implementation
- [ ] Other (Specify)

## Tests

> :memo: Please describe the tests that you ran to verify your changes.
>  
> * Provide instructions so we can reproduce.  
> * Please also list any relevant details for your test configuration.  

**Test Configuration**:

## Checklist

- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).
- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).
- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).
- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.
- [x] I have commented my code, particularly in hard-to-understand areas.
- [x] I have made corresponding changes to the documentation.
- [x] My changes generate no new warnings.
- [x] I have added tests that prove my fix is effective or that my feature works.

@tombstone ",kmindspark,b'cla: yes',2020-06-30T00:28:19Z,2020-06-30T00:29:17Z,,,,,,,
8749,Context RCNN TF 2 support,"# Description
Add support for Context R-CNN in TF 2.0. Still passes the TF 1.0 tests.

> :memo: Change projection layers to keras custom layer rather than tf slim. 
>  
> * Please also include relevant motivation and context.  
> * List any dependencies that are required for this change.  

## Type of change

For a new feature or function, please create an issue first to discuss it
with us before submitting a pull request.

Note: Please delete options that are not relevant.

- [ ] Bug fix (non-breaking change which fixes an issue)
- [ ] Documentation update
- [x] TensorFlow 2 migration
- [ ] New feature (non-breaking change which adds functionality)
- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)
- [ ] A new research paper code implementation
- [ ] Other (Specify)

## Tests

> :memo: Please describe the tests that you ran to verify your changes.
>  The context_rcnn unit tests in meta_architectures.
> * Provide instructions so we can reproduce.  
> * Please also list any relevant details for your test configuration.  

**Test Configuration**:

## Checklist

- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).
- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).
- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).
- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.
- [x] I have commented my code, particularly in hard-to-understand areas.
- [x] I have made corresponding changes to the documentation.
- [x] My changes generate no new warnings.
- [x] I have added tests that prove my fix is effective or that my feature works.
",kmindspark,b'cla: yes ready to pull',2020-06-29T18:43:25Z,2020-07-23T16:31:15Z,,,,,,,
8748,Add trainer and utilities to load TF1 checkpoints,"This is part of effort addressing issue #8537 but not complete.

1. Add trainer to train mobilenet; 
2. Add loader to load tf1 checkpoints;
3. Perform evaluation with loaded tf1 checkpoints;
4. Fix various bugs;

Current result is of evaluation on loaded tf1 checkpoints:

Checkpoint | Evaluation Top1 Accuracy
-- | --
mobilenet_v1_1.0_224 | 0.710099995136261
mobilenet_v2_1.0_224 | 0.7184000015258789
mobilenet_v3_large_224_1.0_float | 0.7521799802780151",luotigerlsx,b'cla: yes help wanted:paper implementation',2020-06-29T16:30:39Z,2020-06-30T01:37:33Z,,,,,,,
8746,Add multilevel crop and resize functions,"# Description

> :memo: Add funtions to perform multilevel crop and resize. 
>  
> * Add multilevel_native_crop_and_resize.
> * Add multilevel_matmul_crop_and_resize
> * Change faster rcnn meta arch function that use _crop_and_resize_fn

## Type of change

For a new feature or function, please create an issue first to discuss it
with us before submitting a pull request.

Note: Please delete options that are not relevant.

- [ ] Bug fix (non-breaking change which fixes an issue)
- [ ] Documentation update
- [ ] TensorFlow 2 migration
- [ ] New feature (non-breaking change which adds functionality)
- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)
- [ ] A new research paper code implementation
- [x] Other (Add functions support faster rcnn fpn feature extractor)

## Tests

> :memo: Please describe the tests that you ran to verify your changes.
>  
> * Simple unittest for both functions.

**Test Configuration**:

## Checklist

- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).
- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).
- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).
- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.
- [x] I have commented my code, particularly in hard-to-understand areas.
- [x] I have made corresponding changes to the documentation.
- [x] My changes generate no new warnings.
- [x] I have added tests that prove my fix is effective or that my feature works.
",syiming,b'cla: yes ready to pull',2020-06-28T19:02:13Z,2020-07-20T20:39:21Z,,,,,,,
8742,Merged commit includes the following changes:,"318569851  by jonathanhuang:

    Fix for fine-tuning from classification checkpoints in the v2 binary.

--

PiperOrigin-RevId: 318569851

# Description

> :memo: Please include a summary of the change. 
>  
> * Please also include relevant motivation and context.  
> * List any dependencies that are required for this change.  

## Type of change

For a new feature or function, please create an issue first to discuss it
with us before submitting a pull request.

Note: Please delete options that are not relevant.

- [ ] Bug fix (non-breaking change which fixes an issue)
- [ ] Documentation update
- [ ] TensorFlow 2 migration
- [ ] New feature (non-breaking change which adds functionality)
- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)
- [ ] A new research paper code implementation
- [ ] Other (Specify)

## Tests

> :memo: Please describe the tests that you ran to verify your changes.
>  
> * Provide instructions so we can reproduce.  
> * Please also list any relevant details for your test configuration.  

**Test Configuration**:

## Checklist

- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).
- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).
- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).
- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.
- [ ] I have commented my code, particularly in hard-to-understand areas.
- [ ] I have made corresponding changes to the documentation.
- [ ] My changes generate no new warnings.
- [ ] I have added tests that prove my fix is effective or that my feature works.
",tombstone,b'cla: yes',2020-06-27T00:27:57Z,2020-06-27T00:29:24Z,,,,,,,
8741,Merged commit includes the following changes:,"318545448  by jonathanhuang:

    Modifies visualization code in TF2 evaluation loop so that we don't write out image summaries to disk for every single image.  This change will reduce summary file sizes by ~2 orders of magnitude on average and speed up evaluation cycles (20 minutes per COCO eval cycle vs 2 hours for RetinaNet).

--
318514741  by sbeery:

    Adding link to the blog post

--

PiperOrigin-RevId: 318545448

# Description

> :memo: Please include a summary of the change. 
>  
> * Please also include relevant motivation and context.  
> * List any dependencies that are required for this change.  

## Type of change

For a new feature or function, please create an issue first to discuss it
with us before submitting a pull request.

Note: Please delete options that are not relevant.

- [ ] Bug fix (non-breaking change which fixes an issue)
- [ ] Documentation update
- [ ] TensorFlow 2 migration
- [ ] New feature (non-breaking change which adds functionality)
- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)
- [ ] A new research paper code implementation
- [ ] Other (Specify)

## Tests

> :memo: Please describe the tests that you ran to verify your changes.
>  
> * Provide instructions so we can reproduce.  
> * Please also list any relevant details for your test configuration.  

**Test Configuration**:

## Checklist

- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).
- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).
- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).
- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.
- [ ] I have commented my code, particularly in hard-to-understand areas.
- [ ] I have made corresponding changes to the documentation.
- [ ] My changes generate no new warnings.
- [ ] I have added tests that prove my fix is effective or that my feature works.
",tombstone,b'cla: yes',2020-06-26T21:44:09Z,2020-06-26T22:01:18Z,,,,,,,
8740,Merged commit includes the following changes:,"318497061  by rathodv:

    1. Replace strategy.run() with strategy.experimental_run_v2() and replace tensor.ref() with tensor.experimental_ref() to be compatible with TF2.1 runtime on cloud.
    2. Fix expected string in failing PY3 tests.

--
318493408  by aom:

    Implements ""Bidirectional Feature Pyramid Network Generators"" for BiFPN-based feature extractors (e.g. EfficientDet).

--

PiperOrigin-RevId: 318497061

# Description

> :memo: Please include a summary of the change. 
>  
> * Please also include relevant motivation and context.  
> * List any dependencies that are required for this change.  

## Type of change

For a new feature or function, please create an issue first to discuss it
with us before submitting a pull request.

Note: Please delete options that are not relevant.

- [ ] Bug fix (non-breaking change which fixes an issue)
- [ ] Documentation update
- [ ] TensorFlow 2 migration
- [ ] New feature (non-breaking change which adds functionality)
- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)
- [ ] A new research paper code implementation
- [ ] Other (Specify)

## Tests

> :memo: Please describe the tests that you ran to verify your changes.
>  
> * Provide instructions so we can reproduce.  
> * Please also list any relevant details for your test configuration.  

**Test Configuration**:

## Checklist

- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).
- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).
- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).
- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.
- [ ] I have commented my code, particularly in hard-to-understand areas.
- [ ] I have made corresponding changes to the documentation.
- [ ] My changes generate no new warnings.
- [ ] I have added tests that prove my fix is effective or that my feature works.
",tombstone,b'cla: yes',2020-06-26T17:30:50Z,2020-06-26T17:45:38Z,,,,,,,
8739,Merged commit includes the following changes:,"318417714  by jonathanhuang:

    Internal change.

--
318367213  by sbeery:

    Pointing users to more documentation for beam

--
318358685  by sbeery:

    Context R-CNN sample config for GPU

--
318309800  by rathodv:

    Internal

--
318303364  by ronnyvotel:

    Adding the option for parsing and including DensePose annotations. http://densepose.org/

--
318291319  by aom:

    Adds conv_bn_act conv_block option, and naming convention changes for BiFPN utils.

--
318200598  by ronnyvotel:

    Updating the TF Example Decoder to parse DensePose annotations.

--
318174065  by jonathanhuang:

    Internal change.

--
318167805  by rathodv:

    Add use_tpu flag to TF2 binary.

--
318145285  by aom:

    Adds option for convolutional keras box predictor to force use_bias.

--

PiperOrigin-RevId: 318417714

# Description

> :memo: Please include a summary of the change. 
>  
> * Please also include relevant motivation and context.  
> * List any dependencies that are required for this change.  

## Type of change

For a new feature or function, please create an issue first to discuss it
with us before submitting a pull request.

Note: Please delete options that are not relevant.

- [ ] Bug fix (non-breaking change which fixes an issue)
- [ ] Documentation update
- [ ] TensorFlow 2 migration
- [ ] New feature (non-breaking change which adds functionality)
- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)
- [ ] A new research paper code implementation
- [ ] Other (Specify)

## Tests

> :memo: Please describe the tests that you ran to verify your changes.
>  
> * Provide instructions so we can reproduce.  
> * Please also list any relevant details for your test configuration.  

**Test Configuration**:

## Checklist

- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).
- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).
- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).
- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.
- [ ] I have commented my code, particularly in hard-to-understand areas.
- [ ] I have made corresponding changes to the documentation.
- [ ] My changes generate no new warnings.
- [ ] I have added tests that prove my fix is effective or that my feature works.
",tombstone,b'cla: yes',2020-06-26T15:57:42Z,2020-06-26T16:55:10Z,,,,,,,
8738,Merge TF2 changes and Context R-CNN config,"

> :memo: Please include a summary of the change. 
>  
> * Please also include relevant motivation and context.  
> * List any dependencies that are required for this change.  

## Type of change

For a new feature or function, please create an issue first to discuss it
with us before submitting a pull request.

Note: Please delete options that are not relevant.

- [ ] Bug fix (non-breaking change which fixes an issue)
- [ ] Documentation update
- [x] TensorFlow 2 migration
- [ ] New feature (non-breaking change which adds functionality)
- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)
- [ ] A new research paper code implementation
- [ ] Other (Specify)

## Tests

> :memo: Please describe the tests that you ran to verify your changes.
>  
> * Provide instructions so we can reproduce.  
> * Please also list any relevant details for your test configuration.  

**Test Configuration**:

## Checklist

- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).
- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).
- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).
- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.
- [ ] I have commented my code, particularly in hard-to-understand areas.
- [ ] I have made corresponding changes to the documentation.
- [ ] My changes generate no new warnings.
- [ ] I have added tests that prove my fix is effective or that my feature works.
",tombstone,b'cla: no',2020-06-26T15:40:00Z,2020-06-26T15:45:58Z,,,,,,,
8728,Merged commit includes the following changes:,"318106429  by derekjchow:

    Add Dockerfiles for TF-OD API.

    1.15 and 2.2 supported currently.

--
318083650  by rathodv:

    Internal Change.

--
317893148  by Zhichao Lu:

    Fix mapping from proto fields to parameters of the data augmentation functions for horizontal flip, vertical flip and 90 degree rotations.

--
317753117  by Zhichao Lu:

    Adds keras hyperparam option to force use_bias to True, even when using batch norm.

--
317613986  by Zhichao Lu:

    Improves Keypoints support for data augmentation by means of 90 degree rotation adding an option to permute keypoints.

    Unify the interfaces among flip and rotation ops for data augmentation by exposing additional properties to the user.

--
317136881  by Zhichao Lu:

    Clarifying documentation

--
317097141  by Zhichao Lu:

    Adding Context R-CNN Release to TFODAPI ReadMe

--
316999744  by Zhichao Lu:

    Add import tensorflow.compat.v2 as tf2 in the model_lib to
    ensure tf1 compatibility.

--
316964482  by Zhichao Lu:

    adding a note about a config change needed for exporting detection features

--
316944293  by Zhichao Lu:

    Adding install instructions for apache beam

--
316917592  by lzc:

    Internal change.

--

PiperOrigin-RevId: 318106429

# Description

> :memo: Please include a summary of the change. 
>  
> * Please also include relevant motivation and context.  
> * List any dependencies that are required for this change.  

## Type of change

For a new feature or function, please create an issue first to discuss it
with us before submitting a pull request.

Note: Please delete options that are not relevant.

- [ ] Bug fix (non-breaking change which fixes an issue)
- [ ] Documentation update
- [ ] TensorFlow 2 migration
- [ ] New feature (non-breaking change which adds functionality)
- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)
- [ ] A new research paper code implementation
- [ ] Other (Specify)

## Tests

> :memo: Please describe the tests that you ran to verify your changes.
>  
> * Provide instructions so we can reproduce.  
> * Please also list any relevant details for your test configuration.  

**Test Configuration**:

## Checklist

- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).
- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).
- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).
- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.
- [ ] I have commented my code, particularly in hard-to-understand areas.
- [ ] I have made corresponding changes to the documentation.
- [ ] My changes generate no new warnings.
- [ ] I have added tests that prove my fix is effective or that my feature works.
",tombstone,b'cla: yes',2020-06-24T21:08:56Z,2020-06-24T21:18:03Z,,,,,,,
8725,Work on fixing TF2 issues for the OD API,"# Description

> :memo: Please include a summary of the change. 
>  
> * Please also include relevant motivation and context.  
> * List any dependencies that are required for this change.  

## Type of change

For a new feature or function, please create an issue first to discuss it
with us before submitting a pull request.

Note: Please delete options that are not relevant.

- [x] Bug fix (non-breaking change which fixes an issue)
- [ ] Documentation update
- [ ] TensorFlow 2 migration
- [ ] New feature (non-breaking change which adds functionality)
- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)
- [ ] A new research paper code implementation
- [ ] Other (Specify)

## Tests

> :memo: Please describe the tests that you ran to verify your changes.
>  
> * Provide instructions so we can reproduce.  
> * Please also list any relevant details for your test configuration.  

**Test Configuration**:
Was able to train a model whereas previously unable, but the Unit Test needs to still be fixed.

## Checklist

- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).
- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).
- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).
- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.
- [x] I have commented my code, particularly in hard-to-understand areas.
- [x] I have made corresponding changes to the documentation.
- [x] My changes generate no new warnings.
- [ ] I have added tests that prove my fix is effective or that my feature works.
",kmindspark,b'cla: yes kokoro:force-run',2020-06-23T21:46:44Z,2020-06-29T19:25:03Z,,,,,,,
8724,q,"# Description

> :memo: Please include a summary of the change. 
>  
> * Please also include relevant motivation and context.  
> * List any dependencies that are required for this change.  

## Type of change

For a new feature or function, please create an issue first to discuss it
with us before submitting a pull request.

Note: Please delete options that are not relevant.

- [x] Bug fix (non-breaking change which fixes an issue)
- [ ] Documentation update
- [ ] TensorFlow 2 migration
- [ ] New feature (non-breaking change which adds functionality)
- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)
- [ ] A new research paper code implementation
- [ ] Other (Specify)

## Tests

> :memo: Please describe the tests that you ran to verify your changes.
>  
> * Provide instructions so we can reproduce.  
> * Please also list any relevant details for your test configuration.  

**Test Configuration**:

## Checklist

- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).
- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).
- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).
- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.
- [x] I have commented my code, particularly in hard-to-understand areas.
- [x] I have made corresponding changes to the documentation.
- [x] My changes generate no new warnings.
- [x] I have added tests that prove my fix is effective or that my feature works.
",kmindspark,b'cla: no',2020-06-23T20:11:12Z,2020-06-24T20:55:48Z,,,,,,,
8722,Fix TypeError when calculating normalized_error,"Update agent.py according to changes noted https://github.com/tensorflow/models/issues/7719 
to overcome the following error:
`TypeError: x and y must have the same dtype, got tf.float32 != tf.float64
  In call to configurable 'train_uvf' (<function train_uvf at 0x7f0b2e5ef320>)`

# Description

> :memo: Please include a summary of the change. 
>  
> * Please also include relevant motivation and context.  
> * List any dependencies that are required for this change.  

## Type of change

For a new feature or function, please create an issue first to discuss it
with us before submitting a pull request.

Note: Please delete options that are not relevant.

- [x] Bug fix (non-breaking change which fixes an issue)
- [ ] Documentation update
- [ ] TensorFlow 2 migration
- [ ] New feature (non-breaking change which adds functionality)
- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)
- [ ] A new research paper code implementation
- [ ] Other (Specify)

## Tests

> :memo: Please describe the tests that you ran to verify your changes.
>  
> * Provide instructions so we can reproduce.  
> * Please also list any relevant details for your test configuration.  

**Test Configuration**:

## Checklist

- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).
- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).
- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).
- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.
- [x] I have commented my code, particularly in hard-to-understand areas.
- [ ] I have made corresponding changes to the documentation.
- [x] My changes generate no new warnings.
- [ ] I have added tests that prove my fix is effective or that my feature works.
",ian-cannon,b'cla: yes',2020-06-23T14:45:48Z,2020-06-23T15:22:56Z,,,,,,,
8721,"Error: cannot import name ""center_net_pb2""","# Prerequisites

Please answer the following questions for yourself before submitting an issue.

Traceback (most recent call last):
  File ""export_inference_graph.py"", line 109, in <module>
    from object_detection import exporter
  File ""/content/models/research/object_detection/exporter.py"", line 24, in <module>
    from object_detection.builders import model_builder
  File ""/content/models/research/object_detection/builders/model_builder.py"", line 38, in <module>
    from object_detection.protos import model_pb2
  File ""/content/models/research/object_detection/protos/model_pb2.py"", line 16, in <module>
    from object_detection.protos import center_net_pb2 as object__detection_dot_protos_dot_center__net__pb2
ImportError: cannot import name 'center_net_pb2'

-I am using tensorflow 1
- I am reporting this for the models research
- I checked to make sure that this issue has not already been filed.

## 1. The entire URL of the file you are using

https://github.com/EdjeElectronics/TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10

## 2. Describe the bug

For this repository, I copied train.py from tensorflow models' legacy directory to the object_detection directory.  When I run that command, it searches the protos folder for center_net_pb2.py, which does not exist.  It asks for 2 other _pb2.py files, which do exist and are imported perfectly.

## 3. Steps to reproduce

1.  Clone tensorflow models
2.  Pull object_detection/legacy/train.py into the object_detection folder and run with parameters
3.  Script attempts to import one proto that does not exist. 

## 4. Expected behavior

I expected the training script to run and train a model based on my generated tf records.  I did this just a few days ago and it worked perfectly.

## 5. Additional context

Include any logs that would be helpful to diagnose the problem.

## 6. System information

-Google Colab
- TensorFlow version 1:
-GPU instance
",Tylersuard,b'models:research type:bug',2020-06-22T23:43:50Z,2020-08-25T19:48:52Z,,,,,,,
8719,'MovingAverage' object has no attribute '_average_weights',"# Prerequisites

Please answer the following questions for yourself before submitting an issue.

- [x] I am using the latest TensorFlow Model Garden release and TensorFlow 2.
- [x] I am reporting the issue to the correct repository. (Model Garden official or research directory)
- [x] I checked to make sure that this issue has not been filed already.

## 1. The entire URL of the file you are using

https://github.com/tensorflow/models/tree/master/official/...

## 2. Describe the bug

A clear and concise description of what the bug is.

## 3. Steps to reproduce

Steps to reproduce the behavior.

## 4. Expected behavior

A clear and concise description of what you expected to happen.

## 5. Additional context

Include any logs that would be helpful to diagnose the problem.

## 6. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device name if the issue happens on a mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below):
- Python version:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

<!-- 
Collect system information using our environment capture script.
https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can also obtain the TensorFlow version with:

1. TensorFlow 1.0
`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

2. TensorFlow 2.0
`python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`
-->
",dipendra009,b'models:official type:bug',2020-06-22T18:46:59Z,2020-06-30T18:19:29Z,,,,,,,
8717,Update maskrcnn_parser.py,"Fix a small spelling error

# Description

> :memo: Please include a summary of the change. 
>  
> * Please also include relevant motivation and context.  
> * List any dependencies that are required for this change.  

## Type of change

For a new feature or function, please create an issue first to discuss it
with us before submitting a pull request.

Note: Please delete options that are not relevant.

- [ ] Bug fix (non-breaking change which fixes an issue)
- [ ] Documentation update
- [ ] TensorFlow 2 migration
- [ ] New feature (non-breaking change which adds functionality)
- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)
- [ ] A new research paper code implementation
- [ ] Other (Specify)

## Tests

> :memo: Please describe the tests that you ran to verify your changes.
>  
> * Provide instructions so we can reproduce.  
> * Please also list any relevant details for your test configuration.  

**Test Configuration**:

## Checklist

- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).
- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).
- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).
- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.
- [ ] I have commented my code, particularly in hard-to-understand areas.
- [ ] I have made corresponding changes to the documentation.
- [x] My changes generate no new warnings.
- [ ] I have added tests that prove my fix is effective or that my feature works.
",freezestudio,b'cla: yes ready to pull',2020-06-22T14:29:15Z,2020-06-25T00:44:58Z,,,,,,,
8716,Add Faster RCNN Resnet V1 FPN Keras feature extractor,"# Description

> :memo: Add faster RCNN Resnet V1 FPN Keras feature extractor
>  
> * Add faster RCNN Resnet {50, 101, 152} FPN Keras feature extractor.
> * Add unit test to ensure the size for proposal and box classifier features are correct.
> * Add model to model_builder.py
> * Need to further modify faster_rcnn_meta_arch.py to make the extractor work

## Type of change

For a new feature or function, please create an issue first to discuss it
with us before submitting a pull request.

Note: Please delete options that are not relevant.

- [ ] Bug fix (non-breaking change which fixes an issue)
- [ ] Documentation update
- [ ] TensorFlow 2 migration
- [x] New feature (non-breaking change which adds functionality)
- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)
- [ ] A new research paper code implementation
- [ ] Other (Specify)

## Tests

> :memo: Please describe the tests that you ran to verify your changes.
>  
> * Provide instructions so we can reproduce.  
> * Please also list any relevant details for your test configuration.  

**Test Configuration**:

## Checklist

- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).
- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).
- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).
- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.
- [x] I have commented my code, particularly in hard-to-understand areas.
- [ ] I have made corresponding changes to the documentation.
- [ ] My changes generate no new warnings.
- [x] I have added tests that prove my fix is effective or that my feature works.
",syiming,b'cla: yes stat:awaiting review',2020-06-22T07:12:42Z,2020-06-30T21:41:57Z,,,,,,,
8698,Tensorflow 2.0 object detection API colab tutorial not working,"# Prerequisites

Please answer the following questions for yourself before submitting an issue.

- [x] I am using the latest TensorFlow Model Garden release and TensorFlow 2.
- [x] I am reporting the issue to the correct repository. (Model Garden official or research directory)
- [x] I checked to make sure that this issue has not been filed already.

## 1. The entire URL of the file you are using

https://github.com/tensorflow/models/blob/master/research/object_detection/object_detection_tutorial.ipynb

## 2. Describe the bug

The object detection API in tensorflow 2.0  colab notebook is redirecting to page not found github page

## 3. Steps to reproduce

1.https://www.tensorflow.org/tutorials/
2. Advanced-> Images-> object detection API
3.https://github.com/tensorflow/models/blob/master/research/object_detection/object_detection_tutorial.ipynb
## 4. Expected behavior

I was expecting a colab notebook tutorial of object detection API in tensorflow 2.0

## 5. Additional context

Few days back it was working fine .Now I observed this problem

## 6. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): windows 7 chrome
- Mobile device name if the issue happens on a mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below):
- Python version:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

<!-- 
Collect system information using our environment capture script.
https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can also obtain the TensorFlow version with:

1. TensorFlow 1.0
`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

2. TensorFlow 2.0
`python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`
-->
",jyothiRamilla,b'models:research type:bug',2020-06-19T07:52:31Z,2020-07-28T14:22:13Z,,,,,,,
8697,Release Context RCNN code and pre-trained model.,"Release Context RCNN code and pre-trained model.

--

PiperOrigin-RevId: 317136881

# Description

> :memo: Please include a summary of the change. 
>  
> * Please also include relevant motivation and context.  
> * List any dependencies that are required for this change.  

## Type of change

For a new feature or function, please create an issue first to discuss it
with us before submitting a pull request.

Note: Please delete options that are not relevant.

- [ ] Bug fix (non-breaking change which fixes an issue)
- [ ] Documentation update
- [ ] TensorFlow 2 migration
- [ ] New feature (non-breaking change which adds functionality)
- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)
- [ ] A new research paper code implementation
- [ ] Other (Specify)

## Tests

> :memo: Please describe the tests that you ran to verify your changes.
>  
> * Provide instructions so we can reproduce.  
> * Please also list any relevant details for your test configuration.  

**Test Configuration**:

## Checklist

- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).
- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).
- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).
- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.
- [ ] I have commented my code, particularly in hard-to-understand areas.
- [ ] I have made corresponding changes to the documentation.
- [ ] My changes generate no new warnings.
- [ ] I have added tests that prove my fix is effective or that my feature works.
",pkulzc,b'cla: yes',2020-06-18T22:04:44Z,2020-06-18T22:10:04Z,,,,,,,
8696,1. update to tf2.x for deep_speech,"2. compatible with tf1.14

# Description

> :memo: Please include a summary of the change. 
>  
> * Please also include relevant motivation and context.  
> * List any dependencies that are required for this change.  

## Type of change

For a new feature or function, please create an issue first to discuss it
with us before submitting a pull request.

Note: Please delete options that are not relevant.

- [ ] Bug fix (non-breaking change which fixes an issue)
- [ ] Documentation update
- [x] TensorFlow 2 migration
- [ ] New feature (non-breaking change which adds functionality)
- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)
- [ ] A new research paper code implementation
- [ ] Other (Specify)

## Tests

> :memo: Please describe the tests that you ran to verify your changes.
>  
> * Provide instructions so we can reproduce.  
> * Please also list any relevant details for your test configuration.  

**Test Configuration**:

## Checklist

- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).
- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).
- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).
- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.
- [ ] I have commented my code, particularly in hard-to-understand areas.
- [ ] I have made corresponding changes to the documentation.
- [ ] My changes generate no new warnings.
- [ ] I have added tests that prove my fix is effective or that my feature works.
",moneypi,b'cla: yes stat:awaiting testing',2020-06-18T11:17:50Z,2020-08-14T19:43:38Z,,,,,,,
8694,Remove logger dependency from deep speech,"# Description

> :memo: Please include a summary of the change. 
>  
> * Please also include relevant motivation and context.  
> * List any dependencies that are required for this change.  

## Type of change

For a new feature or function, please create an issue first to discuss it
with us before submitting a pull request.

Note: Please delete options that are not relevant.

- [ ] Bug fix (non-breaking change which fixes an issue)
- [ ] Documentation update
- [ ] TensorFlow 2 migration
- [ ] New feature (non-breaking change which adds functionality)
- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)
- [ ] A new research paper code implementation
- [ ] Other (Specify)

## Tests

> :memo: Please describe the tests that you ran to verify your changes.
>  
> * Provide instructions so we can reproduce.  
> * Please also list any relevant details for your test configuration.  

**Test Configuration**:

## Checklist

- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).
- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).
- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).
- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.
- [ ] I have commented my code, particularly in hard-to-understand areas.
- [ ] I have made corresponding changes to the documentation.
- [ ] My changes generate no new warnings.
- [ ] I have added tests that prove my fix is effective or that my feature works.
",saberkun,b'cla: yes',2020-06-18T05:00:11Z,2020-06-18T19:22:22Z,,,,,,,
8693,Add an option to select a specific frame index rather than a random one from a SequenceExample,"# Description

> :memo: Please include a summary of the change. 
>  
> * Please also include relevant motivation and context.  
> * List any dependencies that are required for this change.  

## Type of change

For a new feature or function, please create an issue first to discuss it
with us before submitting a pull request.

Note: Please delete options that are not relevant.

- [ ] Bug fix (non-breaking change which fixes an issue)
- [ ] Documentation update
- [ ] TensorFlow 2 migration
- [x] New feature (non-breaking change which adds functionality)
- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)
- [ ] A new research paper code implementation
- [ ] Other (Specify)

## Tests

> :memo: Please describe the tests that you ran to verify your changes.
>  
> * Provide instructions so we can reproduce.  
> * Please also list any relevant details for your test configuration.  

**Test Configuration**:

## Checklist

- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).
- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).
- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).
- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.
- [x] I have commented my code, particularly in hard-to-understand areas.
- [x] I have made corresponding changes to the documentation.
- [x] My changes generate no new warnings.
- [x] I have added tests that prove my fix is effective or that my feature works.
",kmindspark,b'cla: no',2020-06-18T00:23:12Z,2020-07-19T23:01:21Z,,,,,,,
8688,Refactor tests for Object Detection API.,"Internal changes.

--

PiperOrigin-RevId: 316825723

# Description

> :memo: Please include a summary of the change. 
>  
> * Please also include relevant motivation and context.  
> * List any dependencies that are required for this change.  

## Type of change

For a new feature or function, please create an issue first to discuss it
with us before submitting a pull request.

Note: Please delete options that are not relevant.

- [x] Bug fix (non-breaking change which fixes an issue)
- [ ] Documentation update
- [x] TensorFlow 2 migration
- [ ] New feature (non-breaking change which adds functionality)
- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)
- [ ] A new research paper code implementation
- [ ] Other (Specify)

## Tests

> :memo: Please describe the tests that you ran to verify your changes.
>  
> * Provide instructions so we can reproduce.  
> * Please also list any relevant details for your test configuration.  

**Test Configuration**:

## Checklist

- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).
- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).
- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).
- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.
- [ ] I have commented my code, particularly in hard-to-understand areas.
- [ ] I have made corresponding changes to the documentation.
- [ ] My changes generate no new warnings.
- [ ] I have added tests that prove my fix is effective or that my feature works.
",pkulzc,b'cla: yes',2020-06-17T05:48:31Z,2020-06-17T08:01:06Z,,,,,,,
8687,"fix ""No module named 'official.utils.logs'"" for deep_speech","# Description

> :memo: Please include a summary of the change. 
>  
> * Please also include relevant motivation and context.  
> * List any dependencies that are required for this change.  

## Type of change

For a new feature or function, please create an issue first to discuss it
with us before submitting a pull request.

Note: Please delete options that are not relevant.

- [x] Bug fix (non-breaking change which fixes an issue)
- [ ] Documentation update
- [ ] TensorFlow 2 migration
- [ ] New feature (non-breaking change which adds functionality)
- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)
- [ ] A new research paper code implementation
- [ ] Other (Specify)

## Tests

> :memo: Please describe the tests that you ran to verify your changes.
>  
> * Provide instructions so we can reproduce.  
> * Please also list any relevant details for your test configuration.  

**Test Configuration**:

## Checklist

- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).
- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).
- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).
- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.
- [ ] I have commented my code, particularly in hard-to-understand areas.
- [ ] I have made corresponding changes to the documentation.
- [x] My changes generate no new warnings.
- [ ] I have added tests that prove my fix is effective or that my feature works.
",moneypi,b'cla: yes',2020-06-17T04:56:26Z,2020-06-18T04:55:11Z,,,,,,,
8682,[deeplab][mobilenetV3] ValueError '%s is not decorated with @add_arg_scope' on training,"<!--
As per our GitHub Policy (https://github.com/tensorflow/models/blob/master/ISSUES.md), we only address code bugs, documentation issues, and feature requests on GitHub.

We will automatically close questions and help related issues.

Please go to Stack Overflow (http://stackoverflow.com/questions/tagged/tensorflow-model-garden) for questions and help.

-->

I faced a problem on the training of deeplab with mobilenetV3 models.
Only when using mobilenetV3, the error occured and could not be resolved yet.
I wonder if you could tell me how to solve the problem.

Thank you for your help in advance

Conditions:
OS: Mac OS Mojave 10.14.6
Python: 3.6.8
Tensorflow: 1.14.0
tf-slim: 1.2.0

What I tried.
1, Clone the models repo (commit:b3ef7ae9)
2, Download and convert ADE20K with bash script
3, Prepare initial_checkpoint (mobilenetv3_large_cityscapes_trainfine and xception65_coco_voc_trainval from deeplab model zoo)
4, Run training according to the ""Running DeepLab on ADE20K Semantic Segmentation Dataset""
with following commands

For Xception:(Succeeded)
python train.py --logtostderr --training_number_of_steps=30 --train_split=""train"" --model_variant=""xception_65"" --atrous_rates=6 --atrous_rates=12 --atrous_rates=18 --output_stride=16 --decoder_output_stride=4 --train_crop_size=""513,513"" --train_batch_size=4 --min_resize_value=513 --max_resize_value=513 --resize_factor=16 --dataset=""ade20k"" --tf_initial_checkpoint=datasets/deeplabv3_pascal_trainval/model.ckpt --train_logdir=datasets/trained_checkpoints/testv3 --dataset_dir=datasets/ADE20K/tfrecord --initialize_last_layer=false

For mobilenetV3:(**Failed**)
python train.py --logtostderr --training_number_of_steps=30 --train_split=""train"" --model_variant=""mobilenet_v3_large_seg"" --atrous_rates=6 --atrous_rates=12 --atrous_rates=18 --output_stride=16 --decoder_output_stride=4 --train_crop_size=""513,513"" --train_batch_size=4 --min_resize_value=513 --max_resize_value=513 --resize_factor=16 --dataset=""ade20k"" --tf_initial_checkpoint=datasets/deeplab_mnv3_large_cityscapes_trainfine/model.ckpt --train_logdir=datasets/trained_checkpoints/testv3 --dataset_dir=datasets/ADE20K/tfrecord --initialize_last_layer=false **--image_pooling_crop_size=769,769 --image_pooling_stride=4,5 --add_image_level_feature=1 --aspp_convs_filters=128 --aspp_with_concat_projection=0 --aspp_with_squeeze_and_excitation=1 --decoder_use_sum_merge=1 --decoder_filters=19 --decoder_output_is_logits=1 --image_se_uses_qsigmoid=1 --decoder_output_stride=8 --output_stride=32 --image_pyramid=1**

Bold arguments were added according to the model zoo comments and some issues.

Results:
Only when using mobilenetV3, the value error occurred and could not train the model.
The trace back is as shown below:

Traceback (most recent call last):
  File ""train.py"", line 464, in <module>
    tf.app.run()
  File ""/Users/XXX/.pyenv/versions/3.6.8/envs/common368/lib/python3.6/site-packages/tensorflow/python/platform/app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""/Users/XXX/.pyenv/versions/3.6.8/envs/common368/lib/python3.6/site-packages/absl/app.py"", line 300, in run
    _run_main(main, args)
  File ""/Users/XXX/.pyenv/versions/3.6.8/envs/common368/lib/python3.6/site-packages/absl/app.py"", line 251, in _run_main
    sys.exit(main(argv))
  File ""train.py"", line 321, in main
    clones = model_deploy.create_clones(config, model_fn, args=model_args)
  File ""/Users/XXX/version_control/models/research/slim/deployment/model_deploy.py"", line 192, in create_clones
    outputs = model_fn(*args, **kwargs)
  File ""train.py"", line 252, in _build_deeplab
    'total_training_steps': FLAGS.training_number_of_steps,
  File ""/Users/XXX/version_control/models/research/deeplab/model.py"", line 323, in multi_scale_logits
    nas_training_hyper_parameters=nas_training_hyper_parameters)
  File ""/Users/XXX/version_control/models/research/deeplab/model.py"", line 577, in _get_logits
    nas_training_hyper_parameters=nas_training_hyper_parameters)
  File ""/Users/XXX/version_control/models/research/deeplab/model.py"", line 404, in extract_features
    use_bounded_activation=model_options.use_bounded_activation)
  File ""/Users/XXX/version_control/models/research/deeplab/core/feature_extractor.py"", line 649, in extract_features
    weight_decay=weight_decay)
  File ""/Users/XXX/version_control/models/research/deeplab/core/feature_extractor.py"", line 308, in mobilenet_v2_arg_scope
    [conv_blocks.expanded_conv], normalizer_fn=slim.batch_norm), \
  File ""/Users/XXX/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 81, in __enter__
    return next(self.gen)
  File ""/Users/XXX/.pyenv/versions/3.6.8/envs/common368/lib/python3.6/site-packages/tensorflow/contrib/framework/python/ops/arg_scope.py"", line 152, in arg_scope
    _name_op(op))
ValueError: ('%s is not decorated with @add_arg_scope', ('nets.mobilenet.conv_blocks', 'expanded_conv'))


",limonene51,b'models:research type:support',2020-06-16T06:37:00Z,2020-07-15T12:48:21Z,,,,,,,
8679,Fix to DELF package,"# Description

Removed reference to delf_v1 from the  DELF package following TF 2 migration.

## Type of change

- [x] Bug fix (non-breaking change which fixes an issue)
- [x] TensorFlow 2 migration

## Tests

- Installation of the DELF package
- Training with the DELF package

## Checklist

- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).
- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).
- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).
- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.
- [x] I have commented my code, particularly in hard-to-understand areas.
- [x] I have made corresponding changes to the documentation.
- [x] My changes generate no new warnings.
- [x] I have added tests that prove my fix is effective or that my feature works.
",dan-anghel,b'cla: yes',2020-06-16T00:32:46Z,2020-06-16T00:47:02Z,,,,,,,
8676,"KeyError: ""Registering two gradient with name 'BlockLSTM'! (Previous registration was in register /home/sreenu/.local/lib/python3.6/site-packages/tensorflow_core/python/framework/registry.py:66)""","<!--
As per our GitHub Policy (https://github.com/tensorflow/models/blob/master/ISSUES.md), we only address code bugs, documentation issues, and feature requests on GitHub.

We will automatically close questions and help related issues.

Please go to Stack Overflow (http://stackoverflow.com/questions/tagged/tensorflow-model-garden) for questions and help.

-->
",sreenupadidapu,b'stat:awaiting response type:support',2020-06-15T03:48:40Z,2020-07-02T09:31:43Z,,,,,,,
8672,Error when trying to use protoc compiler,"Hi, I'm using a MacBook OS for installing the latest version of the library and protoc.
Whenever I try running the command 
protoc object_detection/protos/*.proto --python_out=. 

in th /research directory, I ALWAYS get the error:
warning: Import object_detection/protos/image_resizer.proto is unused

I've tried looking online for answers but couldn't find any. Would appreciate any help, thanks!",shahriyarhabib,b'models:research type:bug',2020-06-14T07:19:59Z,2020-07-31T16:51:06Z,,,,,,,
8671,transformer_main.py - Low TPU usage V3-8,"# Prerequisites

Please answer the following questions for yourself before submitting an issue.

- [X] I am using the latest TensorFlow Model Garden release and TensorFlow 2.
- [X] I am reporting the issue to the correct repository. (Model Garden official or research directory)
- [X] I checked to make sure that this issue has not been filed already.

## 1. The entire URL of the file you are using

https://github.com/tensorflow/models/blob/master/official/nlp/transformer/transformer_main.py

## 2. Describe the bug

I followed the instructions to use TPUs to train a transformer model, but I only get around 12% of TPU utilization when running the code.

## 3. Steps to reproduce

```
export PYTHONPATH=""$PYTHONPATH:/path/to/models""

cd /path/to/models/official/nlp/transformer

# Export variables
PARAM_SET=big
DATA_DIR=$HOME/transformer/data
MODEL_DIR=$HOME/transformer/model_$PARAM_SET
VOCAB_FILE=$DATA_DIR/vocab.ende.32768

# Download training/evaluation/test datasets
python3 data_download.py --data_dir=$DATA_DIR

# Train the model for 100000 steps and evaluate every 5000 steps on a single GPU.
# Each train step, takes 4096 tokens as a batch budget with 64 as sequence
# maximal length.

python transformer_main.py \
--tpu=$TPU_NAME \
--model_dir=$MODEL_DIR \
--data_dir=$DATA_DIR \
--vocab_file=$DATA_DIR/vocab.ende.32768 \
--batch_size=10048 \
--train_steps=200000 \
--static_batch=true \
--use_ctl=true \
--param_set=big \
--steps_between_evals=30000 \
--max_length=64 \
--decode_batch_size=1024 \
--decode_max_length=97 \
--padded_decode=true \
--distribution_strategy=tpu \
--enable_metrics_in_training=true \
--enable_tensorboard=true 

capture_tpu_profile --tpu=$TPU_NAME  --monitoring_level=2
```

   TPU type: TPU v3
  Number of TPU cores: 8 (Replica count = 8, num cores per replica = 1)
  TPU idle time (lower is better): 0.058%
  Utilization of TPU Matrix Units (higher is better): 11.9%
  Step time: 209ms (avg), 209ms (min), 209ms (max)
  Infeed percentage: 0.048% (avg), 0.048% (min), 0.048% (max)

## 4. Expected behavior

I would expect TPU usage to be higher, it does seem to be using only 1 TPU core.

## 5. Additional context

Memory usage is also low, around 12GB, which again seems to be using just 1 TPU core.

## 6. System information


== check python ===================================================
python version: 3.7.3
python branch: 
python build version: ('default', 'Dec 20 2019 18:57:59')
python compiler version: GCC 8.3.0
python implementation: CPython
== check os platform ===============================================
os: Linux
os kernel version: #1 SMP Debian 4.19.118-2+deb10u1 (2020-06-07)
os release version: 4.19.0-9-cloud-amd64
os platform: Linux-4.19.0-9-cloud-amd64-x86_64-with-debian-10.4
linux distribution: ('debian', '10.4', '')
linux os distribution: ('debian', '10.4', '')
mac version: ('', ('', '', ''), '')
uname: uname_result(system='Linux', node='garden', release='4.19.0-9-cloud-amd64', version='#1 SMP Debian 4.19.11
8-2+deb10u1 (2020-06-07)', machine='x86_64', processor='')
architecture: ('64bit', 'ELF')
machine: x86_64
== are we in docker =============================================
No
== compiler =====================================================
c++ (Debian 8.3.0-6) 8.3.0
Copyright (C) 2018 Free Software Foundation, Inc.

",soares-f,b'models:official type:bug',2020-06-13T14:54:33Z,2020-08-28T05:22:22Z,,,,,,,
8665,type object 'Config' has no attribute 'resize'. I am using data generator,"At yesterday, when I run the coding below, there was no problem:

```
def preprocessing(img,label):

    img = cv2.resize(img,(Config.resize,Config.resize))
    img = img/255
    label = np_utils.to_categorical(label, Config.num_classes)
    num_classes=7
    labels_to_class = {0:'alif',1:'ba',2:'ta',3:'tsa',4:'jim',5:'hha',6:'kha'}
    class_to_labels = {'alif':0,'ba':1,'ta':2,'tsa':3,'jim':4,'hha':5,'kha':6}
    resize = 224	
    num_epochs =10
    batch_size =10
    return img,label
```
```
train_datagen = data_generator(samples,batch_size=8)

x,y = next(train_datagen)
print ('x_shape: ', x.shape)
print ('labels shape: ', y.shape)
print ('labels: ', y)
```
but then today when I run again with the coding below, this error happened:
AttributeError: type object 'Config' has no attribute 'resize'

 can someone tell me what happened to this? is there any bug???",xueqing311,b'models:research stat:awaiting response type:bug',2020-06-12T08:59:10Z,2020-08-08T02:23:39Z,,,,,,,
8661,Make quantizable_separable_conv2d initializer explicitly configurable…,"…. (otherwise we could use slim.arg_scope to config the initializer)

PiperOrigin-RevId: 315732759

# Description
New feature.

> :memo: Please include a summary of the change. 
>  
> * Please also include relevant motivation and context.  
> * List any dependencies that are required for this change.  

## Type of change

For a new feature or function, please create an issue first to discuss it
with us before submitting a pull request.

Note: Please delete options that are not relevant.

- [ ] Bug fix (non-breaking change which fixes an issue)
- [ ] Documentation update
- [ ] TensorFlow 2 migration
- [x] New feature (non-breaking change which adds functionality)
- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)
- [ ] A new research paper code implementation
- [ ] Other (Specify)

## Tests

> :memo: Please describe the tests that you ran to verify your changes.
>  
> * Provide instructions so we can reproduce.  
> * Please also list any relevant details for your test configuration.  

**Test Configuration**:

## Checklist

- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).
- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).
- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).
- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.
- [ ] I have commented my code, particularly in hard-to-understand areas.
- [ ] I have made corresponding changes to the documentation.
- [ ] My changes generate no new warnings.
- [ ] I have added tests that prove my fix is effective or that my feature works.
",yuanliangzhe,b'cla: yes',2020-06-11T02:41:48Z,2020-06-11T02:43:47Z,,,,,,,
8660,Update mscoco_label_map.pbtxt,"# Description

> :memo: Please include a summary of the change. 
>  
> * Please also include relevant motivation and context.  
> * List any dependencies that are required for this change.  

## Type of change

For a new feature or function, please create an issue first to discuss it
with us before submitting a pull request.

Note: Please delete options that are not relevant.

- [ ] Bug fix (non-breaking change which fixes an issue)
- [ ] Documentation update
- [ ] TensorFlow 2 migration
- [ ] New feature (non-breaking change which adds functionality)
- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)
- [ ] A new research paper code implementation
- [ ] Other (Specify)

## Tests

> :memo: Please describe the tests that you ran to verify your changes.
>  
> * Provide instructions so we can reproduce.  
> * Please also list any relevant details for your test configuration.  

**Test Configuration**:

## Checklist

- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).
- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).
- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).
- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.
- [ ] I have commented my code, particularly in hard-to-understand areas.
- [ ] I have made corresponding changes to the documentation.
- [ ] My changes generate no new warnings.
- [ ] I have added tests that prove my fix is effective or that my feature works.
",anuvratsinghal,b'cla: no',2020-06-10T20:27:53Z,2020-06-19T07:07:28Z,,,,,,,
8658,Loading a pretrained checkpoint of a QAT model (Resnet 50),"# Prerequisites

Please answer the following questions for yourself before submitting an issue.

- [x] I am using the latest TensorFlow Model Garden release and TensorFlow 2.
- [x] I am reporting the issue to the correct repository. (Model Garden official or research directory)
- [x] I checked to make sure that this issue has not been filed already.

I'm using TF 2.2.0-dev20200506

## 1. The entire URL of the file you are using

https://github.com/tensorflow/models/tree/master/official/vision/image_classification/resnet

## 2. Describe the bug

I trained a Resnet-50 model with quantization aware training. However when I try to load the final checkpoint to export to a saved model, I see ""Unresolved object in checkpoint"" issues.  Please check the complete log [here ](https://gist.github.com/peri044/d78c6ff6f96db1ac0e899738a97b293b)
I perform QAT on the resnet by adding the following snippet of code in resnet_runnable.py [here](https://github.com/tensorflow/models/blob/master/official/vision/image_classification/resnet/resnet_runnable.py#L76)

`import tensorflow_model_optimization as tfmot` 
` quantize_model = tfmot.quantization.keras.quantize_model`
` self.model = quantize_model(self.model)`

I'm trying to export the saved model and face the above unresolved object in checkpoint error when loading weights https://gist.github.com/peri044/6decce75fb94c3ae3a2dee20eb5dd7a2#file-load-py-L47

Is there something obvious that I'm missing here ? Please advise. Thank you !!

## 3. Additional context

My checkpoint has the variable names under layer_with_weights and I see the kernel_min and kernel_max values for the quantization nodes. But the variables TF is looking for are `quant_bn2a_branch1` etc. Is this the right way for topological loading? 


",peri044,b'models:official type:bug',2020-06-10T07:20:25Z,2020-09-18T16:53:02Z,,,,,,,
8656,Where can I download the pretrained model or .ckpt file?,"<!--
As per our GitHub Policy (https://github.com/tensorflow/models/blob/master/ISSUES.md), we only address code bugs, documentation issues, and feature requests on GitHub.

We will automatically close questions and help related issues.

Please go to Stack Overflow (http://stackoverflow.com/questions/tagged/tensorflow-model-garden) for questions and help.

-->
I am learning tensorflow (version1)，and I am looking to download pretrained models here accoding to  the guide blog which I am looking at  . But I found that everything changed here, and there is not pretrained models. And I have try to search in github to find a pretrain resnet34 models with basic block and bottleneck block for several days, but failed which made me very frustrated.

So could someone tell me that can I download pretrained reset34/50 models with basic block and bottleneck block? I don't know if it's ok to ask this quesiton here? pardon me if I make some stupid mistakes. Thanks a lot!!
",DumnBird,b'models:research type:support',2020-06-10T02:54:23Z,2020-06-18T23:59:46Z,,,,,,,
8648, Context feature 'id' is required but could not be found,"Hi,

I try to use the YouTube-8M Starter Code to train the google audioset. But I met the problem.

python3 train.py --frame_features --model=FrameLevelLogisticModel \
--feature_names='rgb,audio' --feature_sizes='1024,128' \
--train_data_pattern=/home/yt8m/audioset_v1_embeddings/bal_train/*.tfrecord \
--train_dir=/home/yt8m/train_model \
--start_new_model

` File ""/usr/local/lib/python3.6/site-packages/tensorflow_core/python/platform/app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""/usr/local/lib/python3.6/site-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/usr/local/lib/python3.6/site-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""train.py"", line 706, in main
    FLAGS.export_model_steps).run(start_new_model=FLAGS.start_new_model)
  File ""train.py"", line 520, in run
    task_as_string(self.task))
  File ""/usr/local/lib/python3.6/contextlib.py"", line 88, in __exit__
    next(self.gen)
  File ""/usr/local/lib/python3.6/site-packages/tensorflow_core/python/training/supervisor.py"", line 1014, in managed_session
    self.stop(close_summary_writer=close_summary_writer)
  File ""/usr/local/lib/python3.6/site-packages/tensorflow_core/python/training/supervisor.py"", line 839, in stop
    ignore_live_threads=ignore_live_threads)
  File ""/usr/local/lib/python3.6/site-packages/tensorflow_core/python/training/coordinator.py"", line 389, in join
    six.reraise(*self._exc_info_to_raise)
  File ""/usr/local/lib/python3.6/site-packages/six.py"", line 703, in reraise
    raise value
  File ""/usr/local/lib/python3.6/site-packages/tensorflow_core/python/training/queue_runner_impl.py"", line 257, in _run
    enqueue_callable()
  File ""/usr/local/lib/python3.6/site-packages/tensorflow_core/python/client/session.py"", line 1287, in _single_operation_run
    self._call_tf_sessionrun(None, {}, [], target_list, None)
  File ""/usr/local/lib/python3.6/site-packages/tensorflow_core/python/client/session.py"", line 1443, in _call_tf_sessionrun
    run_metadata)
tensorflow.python.framework.errors_impl.InvalidArgumentError: Name: , Context feature 'id' is required but could not be found.
         [[{{node train_input/ParseSingleSequenceExample/ParseSingleSequenceExample}}]]`

I would really appreciate your help.
Best wishes",xiaoluobu,b'models:research type:bug',2020-06-08T19:22:10Z,2020-06-10T01:06:26Z,,,,,,,
8646,AttributeError: module 'tensorflow._api.v1.compat' has no attribute 'v2',"<!--
As per our GitHub Policy (https://github.com/tensorflow/models/blob/master/ISSUES.md), we only address code bugs, documentation issues, and feature requests on GitHub.

We will automatically close questions and help related issues.

Please go to Stack Overflow (http://stackoverflow.com/questions/tagged/tensorflow-model-garden) for questions and help.

-->
AttributeError: module 'tensorflow._api.v1.compat' has no attribute 'v2'
I have tried many versions of tensorflow and this problem occurs。",vlzzhou,b'type:support',2020-06-08T07:10:04Z,2020-06-08T07:48:27Z,,,,,,,
8641,object_detection stopped automatically soon after I started training,"URL：https://github.com/tensorflow/models/tree/master/research/object_detection
 - Windows 10
 - Python 3.7
 - Tensorflow-gpu 1.15.3
 - ssdlite_mobilenet_v2

Training was suspended soon after it began. Is this a bug in Tensorflow1.15.0?
```
I0608 08:32:28.426066  2940 basic_session_run_hooks.py:262] loss = 1.0046523, step = 140854
INFO:tensorflow:global_step/sec: 1.97309
I0608 08:33:19.126070  2940 basic_session_run_hooks.py:692] global_step/sec: 1.97309
INFO:tensorflow:loss = 1.2582233, step = 140954 (50.702 sec)
I0608 08:33:19.128067  2940 basic_session_run_hooks.py:260] loss = 1.2582233, step = 140954 (50.702 sec)
```
",yeyupiaoling,b'models:research type:support',2020-06-08T01:00:46Z,2020-08-18T08:41:26Z,,,,,,,
8634,Quantization of LeNET model using MNIST dataset breaks during model freeze,"I'm trying to train Lenet-net using the MNIST dataset from [here](http://yann.lecun.com/exdb/mnist/ ) and to quantize its float model. My steps are the following:

Firstly, I have applied MNIST dataset to train the classifier which works fines. 

```
python3 train_image_classifier.py --dataset_dir=tmp/mnist --dataset_name=mnist --train_dir=train/mnist --model_name=lenet --clone_on_cpu=true --max_number_of_steps=50000 --quantize_delay=40000
```

Secondly, I have exported the trained model to the pb format and it works well.

```
python3 export_inference_graph.py --dataset_dir=tmp/mnist --dataset_name=mnist --train_dir=train/mnist --model_name=lenet --checkpoint=train/mnist/model.ckpt-50000 --quantize --output_file=mnist.pb 
```

Finally, I try to freeze graph using 
```
freeze_graph --input_graph=mnist.pb --input_checkpoint=train/mnist/model.ckpt-50000 --output_graph=mnist_frozen.pb --input_binary=true --output_node_names=Predictions/Reshape_1 
``` 

but the following error occurred

```
InvalidArgumentError: Restoring from checkpoint failed. This is most likely due to a mismatch between the current graph and the graph from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:

Assign requires shapes of both tensors to match. lhs shape= [5,5,3,32] rhs shape= [5,5,1,32] 
```

Please can you advise how to freeze it correctly?


BTW, I have tried other models like CIFAR10 and all process works fine.
",peter197321,b'models:research type:bug',2020-06-05T21:28:37Z,2020-06-08T13:35:14Z,,,,,,,
8632,model detects only 1 class,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution : Linux Ubuntu 18.04

- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 1.15.0
- Python version: 3.7.4 

- CUDA/cuDNN version: 10.2 
- GPU model and memory: GeForce GTX 1050



**Describe the current behavior**
Hello, i ran a 3 classes object detection model on cloud but it only detects 1 classes
it's return a good loss and mAP but only for one
since i ran it on model_main so the evaluation is included, checked tensorboard everything(GT and detections) looks good but only for one class
i tried swapping classes in the label map it detects only the last one, 

**Dataset**
3 classes dataset with around 100 images per class
20 for evaluation

**Data prep**
Annotation : using labelImg
**Generating csv**
```
 import os
import glob
import pandas as pd
import xml.etree.ElementTree as ET


def xml_to_csv(path):
    xml_list = []
    for xml_file in glob.glob(path + '/*.xml'):
        tree = ET.parse(xml_file)
        root = tree.getroot()
        for member in root.findall('object'):
            value = (root.find('filename').text,
                     int(root.find('size')[0].text),
                     int(root.find('size')[1].text),
                     member[0].text,
                     int(member[4][0].text),
                     int(member[4][1].text),
                     int(member[4][2].text),
                     int(member[4][3].text)
                     )
            xml_list.append(value)
    column_name = ['filename', 'width', 'height', 'class', 'xmin', 'ymin', 'xmax', 'ymax']
    xml_df = pd.DataFrame(xml_list, columns=column_name)
    return xml_df


def main():
  for directory in ['train','test'] :
    image_path = os.path.join(os.getcwd(), 'images/{}'.format(directory))
    xml_df = xml_to_csv(image_path)
    xml_df.to_csv('data/{}_labels.csv'.format(directory), index=None)
    print('Successfully converted xml to csv.')


main()
```
**Generating TFRecords**

```
from __future__ import division
from __future__ import print_function
from __future__ import absolute_import
from random import shuffle
import os
import io
import pandas as pd
import tensorflow as tf

from PIL import Image
from object_detection.utils import dataset_util
from collections import namedtuple, OrderedDict

flags = tf.app.flags
flags.DEFINE_string('csv_input', '', 'Path to the CSV input')
flags.DEFINE_string('output_path', '', 'Path to output TFRecord')
flags.DEFINE_string('image_dir', '', 'Path to images')
FLAGS = flags.FLAGS


# TO-DO replace this with label map
def class_text_to_int(row_label):
    if row_label == 'orange':
        return 1
    elif row_label == 'tunisie_telecom' :
        return 2
    elif row_label == 'ooredoo' :
        return 3
    else:
        None


def split(df, group):
    data = namedtuple('data', ['filename', 'object'])
    gb = df.groupby(group)
    return [data(filename, gb.get_group(x)) for filename, x in zip(gb.groups.keys(), gb.groups)]


def create_tf_example(group, path):
    with tf.gfile.GFile(os.path.join(path, '{}'.format(group.filename)), 'rb') as fid:
        encoded_jpg = fid.read()
    encoded_jpg_io = io.BytesIO(encoded_jpg)
    image = Image.open(encoded_jpg_io)
    width, height = image.size

    filename = group.filename.encode('utf8')
    image_format = b'jpg'
    xmins = []
    xmaxs = []
    ymins = []
    ymaxs = []
    classes_text = []
    classes = []

    for index, row in group.object.iterrows():
        xmins.append(row['xmin'] / width)
        xmaxs.append(row['xmax'] / width)
        ymins.append(row['ymin'] / height)
        ymaxs.append(row['ymax'] / height)
        classes_text.append(row['class'].encode('utf8'))
        classes.append(class_text_to_int(row['class']))

    tf_example = tf.train.Example(features=tf.train.Features(feature={
        'image/height': dataset_util.int64_feature(height),
        'image/width': dataset_util.int64_feature(width),
        'image/filename': dataset_util.bytes_feature(filename),
        'image/source_id': dataset_util.bytes_feature(filename),
        'image/encoded': dataset_util.bytes_feature(encoded_jpg),
        'image/format': dataset_util.bytes_feature(image_format),
        'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),
        'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),
        'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),
        'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),
        'image/object/class/text': dataset_util.bytes_list_feature(classes_text),
        'image/object/class/label': dataset_util.int64_list_feature(classes),
    }))
    return tf_example


def main(_):
    writer = tf.python_io.TFRecordWriter(FLAGS.output_path)
    path = os.path.join(FLAGS.image_dir)
    examples = pd.read_csv(FLAGS.csv_input)
    grouped = split(examples, 'filename')
    shuffle(grouped)
    for group in grouped:
        tf_example = create_tf_example(group, path)
        writer.write(tf_example.SerializeToString())

    writer.close()
    output_path = os.path.join(os.getcwd(), FLAGS.output_path)
    print('Successfully created the TFRecords: {}'.format(output_path))


if __name__ == '__main__':
    tf.app.run()
```
**Label map**
```
item {
  id: 1
  name: 'orange'

  id: 2

  name: 'tunisie_telecom'

  id: 3

  name: 'ooredoo'
}
```
**Config file**
```

# R-FCN with Resnet-101 (v1),  configuration for MSCOCO Dataset.
# Users should configure the fine_tune_checkpoint field in the train config as
# well as the label_map_path and input_path fields in the train_input_reader and
# eval_input_reader. Search for ""PATH_TO_BE_CONFIGURED"" to find the fields that
# should be configured.

model {
  faster_rcnn {
    num_classes: 3
    image_resizer {
      keep_aspect_ratio_resizer {
        min_dimension: 600
        max_dimension: 1024
      }
    }
    feature_extractor {
      type: 'faster_rcnn_resnet101'
      first_stage_features_stride: 16
    }
    first_stage_anchor_generator {
      grid_anchor_generator {
        scales: [0.25, 0.5, 1.0, 2.0]
        aspect_ratios: [0.5, 1.0, 2.0]
        height_stride: 16
        width_stride: 16
      }
    }
    first_stage_box_predictor_conv_hyperparams {
      op: CONV
      regularizer {
        l2_regularizer {
          weight: 0.0
        }
      }
      initializer {
        truncated_normal_initializer {
          stddev: 0.01
        }
      }
    }
    first_stage_nms_score_threshold: 0.0
    first_stage_nms_iou_threshold: 0.7
    first_stage_max_proposals: 300
    first_stage_localization_loss_weight: 2.0
    first_stage_objectness_loss_weight: 1.0
    second_stage_box_predictor {
      rfcn_box_predictor {
        conv_hyperparams {
          op: CONV
          regularizer {
            l2_regularizer {
              weight: 0.0
            }
          }
          initializer {
            truncated_normal_initializer {
              stddev: 0.01
            }
          }
        }
        crop_height: 18
        crop_width: 18
        num_spatial_bins_height: 3
        num_spatial_bins_width: 3
      }
    }
    second_stage_post_processing {
      batch_non_max_suppression {
        score_threshold: 0.0
        iou_threshold: 0.6
        max_detections_per_class: 100
        max_total_detections: 300
      }
      score_converter: SOFTMAX
    }
    second_stage_localization_loss_weight: 2.0
    second_stage_classification_loss_weight: 1.0
  }
}

train_config: {
  batch_size: 1
  optimizer {
    adam_optimizer: {
      learning_rate: {
        manual_step_learning_rate {
          initial_learning_rate: 0.0001
          schedule {
            step: 1
            learning_rate: .00001
          }
          schedule {
            step: 4000
            learning_rate: .000001
          }
          schedule {
            step: 8000
            learning_rate: .0000001
          }
          schedule {
            step: 12000
            learning_rate: .00000001
          }
          schedule {
            step: 16000
            learning_rate: .000000001
          }
          schedule {
            step: 18000
            learning_rate: .0000000001
          }

        }
      }
      #momentum_optimizer_value: 0.9
    }
    use_moving_average: false
  }
  gradient_clipping_by_norm: 10.0
  fine_tune_checkpoint: ""gs://nidham3/pfe/backbone/rfcn/model.ckpt""
  from_detection_checkpoint: true
  fine_tune_checkpoint_type:'detection'
  # Note: The below line limits the training process to 200K steps, which we
  # empirically found to be sufficient enough to train the pets dataset. This
  # effectively bypasses the learning rate schedule (the learning rate will
  # never decay). Remove the below line to train indefinitely.
  num_steps: 20000
  data_augmentation_options {
    random_horizontal_flip {
    }
  }
  data_augmentation_options {
    random_image_scale {
      min_scale_ratio: 0.3
      max_scale_ratio: 1.5
    }
  }
  data_augmentation_options {
    random_adjust_saturation {
    }
  }
  data_augmentation_options {
    random_adjust_contrast {
    }
  }
  data_augmentation_options {
    random_adjust_hue {
    }
  }
  data_augmentation_options {
    random_pixel_value_scale {
    }
  }
  data_augmentation_options {
    random_crop_image {
    }
  }
}

train_input_reader: {
  tf_record_input_reader {
    input_path: ""gs://nidham3/pfe/data/train.record""
  }
  label_map_path: ""gs://nidham3/pfe/data/logos.pbtxt""
}

eval_config: {
  num_examples: 20
  # Note: The below line limits the evaluation process to 10 evaluations.
  # Remove the below line to evaluate indefinitely.
  max_evals: 20
}

eval_input_reader: {
  tf_record_input_reader {
    input_path: ""gs://nidham3/pfe/data/test.record""
  }
  label_map_path: ""gs://nidham3/pfe/data/logos.pbtxt""
  shuffle: false
  num_readers: 1
}
```
** from models/research i ran :**
```
gcloud ml-engine jobs submit training pfe_train_`date +%m_%d_%Y_%H_%M_%S` \
    --runtime-version 1.15 \
    --job-dir=gs://nidham3/pfe/job_dir/pfe_train_`date +%m_%d_%Y_%H` \
    --packages dist/object_detection-0.1.tar.gz,slim/dist/slim-0.1.tar.gz,/tmp/pycocotools/pycocotools-2.0.tar.gz \
    --module-name object_detection.model_main \
    --region us-central1 \
    --config /home/milos/Desktop/cloud_train/gcp_train.yaml \
    -- \
    --model_dir=gs://nidham3/pfe/model/resnet101_training \
    --pipeline_config_path=gs://nidham3/pfe/pipeline/rfcn.config
```
**with gcp_train.yaml:**
```
trainingInput:
  scaleTier: BASIC_GPU
  pythonVersion: ""3.5""
```
I doubled check  every configurable num classes i know it's all set to 3 ",TekayaNidham,b'models:research type:bug',2020-06-05T13:06:49Z,2020-06-06T01:51:41Z,,,,,,,
8630,Transfer Learning with delf,"<!--


As per our GitHub Policy (https://github.com/tensorflow/models/blob/master/ISSUES.md), we only address code bugs, documentation issues, and feature requests on GitHub.

We will automatically close questions and help related issues.

Please go to Stack Overflow (http://stackoverflow.com/questions/tagged/tensorflow-model-garden) for questions and help.

-->
Hi Team,
 
I want to use DELF per-trained model and retrain that with more data. I'm go through code but not able to find any transfer learning option in delf model. Please help to achieved this.",chhokarpardeep,b'models:research type:support',2020-06-05T07:43:10Z,2020-06-12T05:21:58Z,,,,,,,
8619,"Revert ""Add relative positional embedding to KerasBERT (#8617)""","This reverts commit c3c2386ca1b0b7fff18e30b0d055486761de6be0.

# Description

> :memo: Please include a summary of the change. 
>  
> * Please also include relevant motivation and context.  
> * List any dependencies that are required for this change.  

## Type of change

For a new feature or function, please create an issue first to discuss it
with us before submitting a pull request.

Note: Please delete options that are not relevant.

- [ ] Bug fix (non-breaking change which fixes an issue)
- [ ] Documentation update
- [ ] TensorFlow 2 migration
- [ ] New feature (non-breaking change which adds functionality)
- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)
- [ ] A new research paper code implementation
- [ ] Other (Specify)

## Tests

> :memo: Please describe the tests that you ran to verify your changes.
>  
> * Provide instructions so we can reproduce.  
> * Please also list any relevant details for your test configuration.  

**Test Configuration**:

## Checklist

- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).
- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).
- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).
- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.
- [ ] I have commented my code, particularly in hard-to-understand areas.
- [ ] I have made corresponding changes to the documentation.
- [ ] My changes generate no new warnings.
- [ ] I have added tests that prove my fix is effective or that my feature works.
",saberkun,b'cla: yes',2020-06-03T18:39:29Z,2020-06-03T18:43:40Z,,,,,,,
8614,Pack node (RandomCropToAspectRatio/stack) axis attribute is out of bounds,"Hello

Using tf 1.13.rc0, python 2.7.12 on docker image, 16GB ram 4 core.

Im trying to recompile facessd_mobilenet_v2_quantized_320x320_open_image_v4 model but im having problems with the config file https://github.com/tensorflow/models/blob/master/research/object_detection/samples/configs/facessd_mobilenet_v2_quantized_320x320_open_image_v4.config

`./tensorflow/core/grappler/optimizers/graph_optimizer_stage.h:241 Faield to run ArithmetricOptimizer, stage RemoveStackStrideSliceSameAxis node RandomCropToAspectRatio/ChangeCoordinateFrame/strided_slice. Pack node (RandomCropToAspectRatio/stack) axis attribute is out of bounds`

",natxopedreira,b'models:official type:bug',2020-06-03T07:52:33Z,2020-06-03T07:53:21Z,,,,,,,
8613,assertion failed: [max value is lower than 1.01: ] [0],"## 1. The entire URL of the file you are using

git clone https://github.com/tensorflow/models --single-branch --branch r1.13.0

## 2. Describe the bug

It always crashes after step 800 with the following message
tensorflow.python.framework.errors_impl.InvalidArgumentError: 2 root error(s) found.
  (0) Invalid argument: assertion failed: [max value is lower than 1.01: ] [0]
	 [[node Loss/BoxClassifierLoss/ToNormalizedCoordinates/Assert/AssertGuard/Assert (defined at /home/asgtech/anaconda3/envs/training/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py:1748) ]]
	 [[control_dependency/_5517]]
  (1) Invalid argument: assertion failed: [max value is lower than 1.01: ] [0]
	 [[node Loss/BoxClassifierLoss/ToNormalizedCoordinates/Assert/AssertGuard/Assert (defined at /home/asgtech/anaconda3/envs/training/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py:1748) ]]
0 successful operations.
0 derived errors ignored.


## 3. Steps to reproduce

Installed models/research following this
https://gilberttanner.com/blog/installing-the-tensorflow-object-detection-api

Have been trying to reproduce this
https://gilberttanner.com/blog/train-a-mask-r-cnn-model-with-the-tensorflow-object-detection-api

## 4. Expected behavior

It should train for 2000 steps

## 5. Additional context

Attached log and config
[log file.txt](https://github.com/tensorflow/models/files/4721380/log.file.txt)

[mask_rcnn_inception_v2_coco.config.txt](https://github.com/tensorflow/models/files/4721386/mask_rcnn_inception_v2_coco.config.txt)

## 6. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 1.15
- Python version: 3.6.9
- CUDA/cuDNN version: cuda-command-line-tools-10-0/unknown,now 10.0.130-1 amd64 [installed,automatic]
                                       libcudnn7/now 7.6.5.32-1+cuda10.0 amd64 [installed,local]
- GPU model and memory: RTX 2070 8GB

<!-- 
Collect system information using our environment capture script.
https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can also obtain the TensorFlow version with:

1. TensorFlow 1.0
`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

2. TensorFlow 2.0
`python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`
-->
",asgtech,b'models:research type:bug',2020-06-03T06:40:45Z,2020-08-28T21:04:03Z,,,,,,,
8611,appear 160 ops no flops stats due to incomplete  shape  when convert ckpt to pd,"the model is ssd-mobilenet-v2 that trained by my own dataset  .when run  export_inference_graph.py ,  appear 160 ops no flops stats due to incomplete  shape，and the pd of produce is only 19M . the tensorflow's vesion is 1.13.   how to solve it?",DENESTY,b'models:research type:bug',2020-06-02T20:38:45Z,2020-06-05T09:23:41Z,,,,,,,
8605,Xinliu,"# Add RelativePositionEmbedding under kerasBERT

> :memo: Please include a summary of the change. 
>  
> * Please also include relevant motivation and context.  
> * List any dependencies that are required for this change.  

## Type of change

For a new feature or function, please create an issue first to discuss it
with us before submitting a pull request.

Note: Please delete options that are not relevant.

- [ ] Bug fix (non-breaking change which fixes an issue)
- [ ] Documentation update
- [ ] TensorFlow 2 migration
- [ ] New feature (non-breaking change which adds functionality)
- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)
- [ ] A new research paper code implementation
- [ ] Other (Specify)

## Tests

> :memo: Please describe the tests that you ran to verify your changes.
>  
> * Provide instructions so we can reproduce.  
> * Please also list any relevant details for your test configuration.  

**Test Configuration**:

## Checklist

- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).
- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).
- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).
- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.
- [ ] I have commented my code, particularly in hard-to-understand areas.
- [ ] I have made corresponding changes to the documentation.
- [ ] My changes generate no new warnings.
- [ ] I have added tests that prove my fix is effective or that my feature works.
",xinliupitt,b'cla: no',2020-06-01T21:15:13Z,2020-06-01T21:19:08Z,,,,,,,
8599,Add dependency of tf_slim for Object detection API tutorial,"# Description
The OD API is dependent on `tf_slim` which is not pre-installed on colab, as shown in #8598.
> :memo: Please include a summary of the change. 
>  
> * Please also include relevant motivation and context.  
> * List any dependencies that are required for this change.  

## Type of change

For a new feature or function, please create an issue first to discuss it
with us before submitting a pull request.

Note: Please delete options that are not relevant.

- [x] Bug fix (non-breaking change which fixes an issue)

## Tests

> :memo: Please describe the tests that you ran to verify your changes.
>  
> * Provide instructions so we can reproduce.  
> * Please also list any relevant details for your test configuration.  

**Test Configuration**:

## Checklist

- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).
- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).
- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).
- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.
- [x] I have commented my code, particularly in hard-to-understand areas.
- [x] I have made corresponding changes to the documentation.
- [x] My changes generate no new warnings.
- [x] I have added tests that prove my fix is effective or that my feature works.
",djdongjin,b'cla: yes',2020-05-31T11:01:30Z,2020-06-19T01:39:41Z,,,,,,,
8598,ModuleNotFoundError: No module named 'tf_slim',"# Prerequisites

Please answer the following questions for yourself before submitting an issue.

- [ ] I am using the latest TensorFlow Model Garden release and TensorFlow 2.
- [x] I am reporting the issue to the correct repository. (Model Garden official or research directory)
- [x] I checked to make sure that this issue has not already been filed.

## 1. The entire URL of the file you are using

https://github.com/tensorflow/models/blob/master/research/object_detection/utils/ops.py

## 2. Describe the bug

Well, I was using the same code as from the object_detection_tutorial.ipynb on Monday (May 25 2020) and it was working fine. Today (May 31 2020) when I am running the code again I am getting **ModuleNotFoundError: No module named 'tf_slim'**

## 3. Steps to reproduce

Steps to reproduce the behavior.

1. Run object_detection_tutorial.ipynb
2. Run the cell with the line: from object_detection.utils import ops as utils_ops

## 4. Expected behavior

A clean run of that specific cell with no issues.

## 5. Additional context

No logs. Easy to reproduce.

## 6. System information

- OS Platform and Distribution (Windows 10):
- Run in Coolab the tutorial, nbno changes to the tutorial

<!-- 
Collect system information using our environment capture script.
https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can also obtain the TensorFlow version with:

1. TensorFlow 1.0
`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

2. TensorFlow 2.0
`python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`
-->
",ISimion,b'models:research type:bug',2020-05-31T07:36:49Z,2020-06-18T17:51:40Z,,,,,,,
8595,tensorflow.python.framework.errors_impl.InvalidArgumentError: Invalid argument: assertion failed:,"# Prerequisites

Please answer the following questions for yourself before submitting an issue.

- [Yes, Research Directory. No, TF1.x ] I am using the latest TensorFlow Model Garden release and TensorFlow 2.
- [Yes, research directory. ] I am reporting the issue to the correct repository. (Model Garden official or research directory)
- [Yes ] I checked to make sure that this issue has not already been filed.

## 1. The entire URL of the file you are using

https://github.com/tensorflow/models/tree/master/research/object_detection/model_main.py

## 2. Describe the bug
While training a custom object detector using TensorFlow Object Detection API on Colab I got this error. I was using `tensorflow-gpu==1.15.0`  and for fine tuning I was using `ssd_mobilenet_v2_coco` . Following is the verbose along with the error I got:
```

WARNING:tensorflow:Forced number of epochs for all eval validations to be 1.
W0528 21:13:21.113062 140292083513216 model_lib.py:717] Forced number of epochs for all eval validations to be 1.
INFO:tensorflow:Maybe overwriting train_steps: 200000
I0528 21:13:21.113316 140292083513216 config_util.py:523] Maybe overwriting train_steps: 200000
INFO:tensorflow:Maybe overwriting use_bfloat16: False
I0528 21:13:21.113430 140292083513216 config_util.py:523] Maybe overwriting use_bfloat16: False
INFO:tensorflow:Maybe overwriting sample_1_of_n_eval_examples: 1
I0528 21:13:21.113519 140292083513216 config_util.py:523] Maybe overwriting sample_1_of_n_eval_examples: 1
INFO:tensorflow:Maybe overwriting eval_num_epochs: 1
I0528 21:13:21.113614 140292083513216 config_util.py:523] Maybe overwriting eval_num_epochs: 1
INFO:tensorflow:Maybe overwriting load_pretrained: True
I0528 21:13:21.113696 140292083513216 config_util.py:523] Maybe overwriting load_pretrained: True
INFO:tensorflow:Ignoring config override key: load_pretrained
I0528 21:13:21.113776 140292083513216 config_util.py:533] Ignoring config override key: load_pretrained
WARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.
W0528 21:13:21.114626 140292083513216 model_lib.py:733] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.
INFO:tensorflow:create_estimator_and_inputs: use_tpu False, export_to_tpu False
I0528 21:13:21.114744 140292083513216 model_lib.py:768] create_estimator_and_inputs: use_tpu False, export_to_tpu False
INFO:tensorflow:Using config: {'_model_dir': 'training/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true
graph_options {
  rewrite_options {
    meta_optimizer_iterations: ONE
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f97ed4dd128>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0528 21:13:21.115245 140292083513216 estimator.py:212] Using config: {'_model_dir': 'training/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true
graph_options {
  rewrite_options {
    meta_optimizer_iterations: ONE
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f97ed4dd128>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
WARNING:tensorflow:Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7f97d328dbf8>) includes params argument, but params are not passed to Estimator.
W0528 21:13:21.115487 140292083513216 model_fn.py:630] Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7f97d328dbf8>) includes params argument, but params are not passed to Estimator.
INFO:tensorflow:Not using Distribute Coordinator.
I0528 21:13:21.116259 140292083513216 estimator_training.py:186] Not using Distribute Coordinator.
INFO:tensorflow:Running training and evaluation locally (non-distributed).
I0528 21:13:21.116456 140292083513216 training.py:612] Running training and evaluation locally (non-distributed).
INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.
I0528 21:13:21.116694 140292083513216 training.py:700] Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0528 21:13:21.124795 140292083513216 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.
W0528 21:13:21.162153 140292083513216 dataset_builder.py:84] num_readers has been reduced to 1 to match input file shards.
WARNING:tensorflow:From /content/models/research/object_detection/builders/dataset_builder.py:101: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.experimental.parallel_interleave(...)`.
W0528 21:13:21.167545 140292083513216 deprecation.py:323] From /content/models/research/object_detection/builders/dataset_builder.py:101: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.experimental.parallel_interleave(...)`.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/data/python/ops/interleave_ops.py:77: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0528 21:13:21.167754 140292083513216 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/data/python/ops/interleave_ops.py:77: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
2020-05-28 21:13:22.910301: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-05-28 21:13:22.953259: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-28 21:13:22.953875: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59
pciBusID: 0000:00:04.0
2020-05-28 21:13:22.960996: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2020-05-28 21:13:22.967688: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2020-05-28 21:13:22.977811: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2020-05-28 21:13:22.985131: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2020-05-28 21:13:22.995549: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2020-05-28 21:13:23.004617: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2020-05-28 21:13:23.025234: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-05-28 21:13:23.025382: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-28 21:13:23.026101: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-28 21:13:23.026693: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
WARNING:tensorflow:From /content/models/research/object_detection/inputs.py:77: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.
W0528 21:13:33.109247 140292083513216 deprecation.py:323] From /content/models/research/object_detection/inputs.py:77: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.
WARNING:tensorflow:From /content/models/research/object_detection/utils/ops.py:493: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
W0528 21:13:33.221111 140292083513216 deprecation.py:323] From /content/models/research/object_detection/utils/ops.py:493: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/operators/control_flow.py:1004: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.
Instructions for updating:
`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.
W0528 21:13:39.145547 140292083513216 api.py:332] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/operators/control_flow.py:1004: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.
Instructions for updating:
`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.
WARNING:tensorflow:From /content/models/research/object_detection/inputs.py:259: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
W0528 21:13:42.865469 140292083513216 deprecation.py:323] From /content/models/research/object_detection/inputs.py:259: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
WARNING:tensorflow:From /content/models/research/object_detection/builders/dataset_builder.py:174: batch_and_drop_remainder (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.batch(..., drop_remainder=True)`.
W0528 21:13:46.217640 140292083513216 deprecation.py:323] From /content/models/research/object_detection/builders/dataset_builder.py:174: batch_and_drop_remainder (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.batch(..., drop_remainder=True)`.
INFO:tensorflow:Calling model_fn.
I0528 21:13:46.233859 140292083513216 estimator.py:1148] Calling model_fn.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
Please use `layer.__call__` method instead.
W0528 21:13:46.430602 140292083513216 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
Please use `layer.__call__` method instead.
INFO:tensorflow:depth of additional conv before box predictor: 0
I0528 21:13:49.101978 140292083513216 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0
INFO:tensorflow:depth of additional conv before box predictor: 0
I0528 21:13:49.133970 140292083513216 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0
INFO:tensorflow:depth of additional conv before box predictor: 0
I0528 21:13:49.165436 140292083513216 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0
INFO:tensorflow:depth of additional conv before box predictor: 0
I0528 21:13:49.343221 140292083513216 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0
INFO:tensorflow:depth of additional conv before box predictor: 0
I0528 21:13:49.377842 140292083513216 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0
INFO:tensorflow:depth of additional conv before box predictor: 0
I0528 21:13:49.414346 140292083513216 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0
W0528 21:13:49.456603 140292083513216 variables_helper.py:161] Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/weights] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[1, 1, 256, 512]], model variable shape: [[3, 3, 256, 512]]. This variable will not be initialized from the checkpoint.
W0528 21:13:49.456816 140292083513216 variables_helper.py:161] Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/weights] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[1, 1, 128, 256]], model variable shape: [[3, 3, 128, 256]]. This variable will not be initialized from the checkpoint.
W0528 21:13:49.456997 140292083513216 variables_helper.py:161] Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/weights] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[1, 1, 128, 256]], model variable shape: [[3, 3, 128, 256]]. This variable will not be initialized from the checkpoint.
W0528 21:13:49.457174 140292083513216 variables_helper.py:161] Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/weights] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[1, 1, 64, 128]], model variable shape: [[3, 3, 64, 128]]. This variable will not be initialized from the checkpoint.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0528 21:13:54.449208 140292083513216 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
INFO:tensorflow:Done calling model_fn.
I0528 21:14:00.871218 140292083513216 estimator.py:1150] Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
I0528 21:14:00.872715 140292083513216 basic_session_run_hooks.py:541] Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
I0528 21:14:04.557027 140292083513216 monitored_session.py:240] Graph was finalized.
2020-05-28 21:14:04.557485: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2020-05-28 21:14:04.562729: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2000165000 Hz
2020-05-28 21:14:04.563012: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1771800 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-05-28 21:14:04.563048: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-05-28 21:14:04.666903: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-28 21:14:04.667672: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1770d80 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-05-28 21:14:04.667705: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5
2020-05-28 21:14:04.668018: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-28 21:14:04.668594: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59
pciBusID: 0000:00:04.0
2020-05-28 21:14:04.668682: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2020-05-28 21:14:04.668724: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2020-05-28 21:14:04.668747: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2020-05-28 21:14:04.668769: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2020-05-28 21:14:04.668796: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2020-05-28 21:14:04.668819: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2020-05-28 21:14:04.668842: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-05-28 21:14:04.668951: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-28 21:14:04.669555: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-28 21:14:04.670109: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
2020-05-28 21:14:04.670229: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2020-05-28 21:14:04.671546: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-05-28 21:14:04.671575: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 
2020-05-28 21:14:04.671585: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N 
2020-05-28 21:14:04.671747: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-28 21:14:04.672416: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-28 21:14:04.672994: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2020-05-28 21:14:04.673037: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14221 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)
INFO:tensorflow:Running local_init_op.
I0528 21:14:09.605103 140292083513216 session_manager.py:500] Running local_init_op.
INFO:tensorflow:Done running local_init_op.
I0528 21:14:09.941666 140292083513216 session_manager.py:502] Done running local_init_op.
INFO:tensorflow:Saving checkpoints for 0 into training/model.ckpt.
I0528 21:14:18.960145 140292083513216 basic_session_run_hooks.py:606] Saving checkpoints for 0 into training/model.ckpt.
2020-05-28 21:14:36.916392: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:145] Filling up shuffle buffer (this may take a while): 1074 of 2048
2020-05-28 21:14:46.905139: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:145] Filling up shuffle buffer (this may take a while): 2026 of 2048
2020-05-28 21:14:46.910085: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:195] Shuffle buffer filled.
2020-05-28 21:14:47.284742: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-05-28 21:14:53.420068: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
INFO:tensorflow:loss = 12.133639, step = 0
I0528 21:14:56.692664 140292083513216 basic_session_run_hooks.py:262] loss = 12.133639, step = 0
Traceback (most recent call last):
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1365, in _do_call
    return fn(*args)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1350, in _run_fn
    target_list, run_metadata)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1443, in _call_tf_sessionrun
    run_metadata)
tensorflow.python.framework.errors_impl.InvalidArgumentError: 2 root error(s) found.
  (0) Invalid argument: {{function_node __inference_Dataset_map_transform_and_pad_input_data_fn_3047}} assertion failed: [[0.748][0.758]] [[0.67][0.67]]
     [[{{node Assert/AssertGuard/else/_123/Assert}}]]
     [[IteratorGetNext]]
  (1) Invalid argument: {{function_node __inference_Dataset_map_transform_and_pad_input_data_fn_3047}} assertion failed: [[0.748][0.758]] [[0.67][0.67]]
     [[{{node Assert/AssertGuard/else/_123/Assert}}]]
     [[IteratorGetNext]]
     [[IteratorGetNext/_8451]]
0 successful operations.
0 derived errors ignored.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/content/models/research/object_detection/model_main.py"", line 114, in <module>
    tf.app.run()
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""/content/models/research/object_detection/model_main.py"", line 110, in main
    tf.estimator.train_and_evaluate(estimator, train_spec, eval_specs[0])
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py"", line 473, in train_and_evaluate
    return executor.run()
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py"", line 613, in run
    return self.run_local()
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py"", line 714, in run_local
    saving_listeners=saving_listeners)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 370, in train
    loss = self._train_model(input_fn, hooks, saving_listeners)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1161, in _train_model
    return self._train_model_default(input_fn, hooks, saving_listeners)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1195, in _train_model_default
    saving_listeners)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1494, in _train_with_estimator_spec
    _, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 754, in run
    run_metadata=run_metadata)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1259, in run
    run_metadata=run_metadata)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1360, in run
    raise six.reraise(*original_exc_info)
  File ""/usr/local/lib/python3.6/dist-packages/six.py"", line 693, in reraise
    raise value
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1345, in run
    return self._sess.run(*args, **kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1418, in run
    run_metadata=run_metadata)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1176, in run
    return self._sess.run(*args, **kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 956, in run
    run_metadata_ptr)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1180, in _run
    feed_dict_tensor, options, run_metadata)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1359, in _do_run
    run_metadata)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1384, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.InvalidArgumentError: 2 root error(s) found.
  (0) Invalid argument:  assertion failed: [[0.748][0.758]] [[0.67][0.67]]
     [[{{node Assert/AssertGuard/else/_123/Assert}}]]
     [[IteratorGetNext]]
  (1) Invalid argument:  assertion failed: [[0.748][0.758]] [[0.67][0.67]]
     [[{{node Assert/AssertGuard/else/_123/Assert}}]]
     [[IteratorGetNext]]
     [[IteratorGetNext/_8451]]
0 successful operations.
0 derived errors ignored.
```

## 3. Steps to reproduce

Training using `model_main.py` file while using `tensorflow-gpu==1.15.0` along with `ssd_mobilenet_v2_coco` produces this.

**EDIT:** I have tried both `tensorflow-gpu==1.15.0` (with pip installation) and version `1.15.2` (by specifying  `%tensorflow_version 1.x` Colab automatically installed version `1.15.2`). While working with both of them I got this error. I also encountered the no module found error for `tf-slim` which I fixed by installing `!pip install git+https://github.com/google-research/tf-slim` during my work. Finally, before I began training I executed `model_builder_test.py` to make sure everything is okay. And `model_builder_test.py` also didn't report any problem. But still I am getting this error.
I also asked the question on `Stack Overflow` and there I got comments like: "".......I uninstalled tensorflow-gpu 1.15, and installed 1.14, and it started the training. Sometimes after steps 200, sometimes after steps 1900, I still get the same error"". Here is the [link](https://stackoverflow.com/questions/62075321/tensorflow-python-framework-errors-impl-invalidargumenterror-invalid-argument).

## 4. Expected behavior

A clear and concise description of what you expected to happen.

## 5. Additional context

Include any logs that would be helpful to diagnose the problem.

## 6. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device name if the issue happens on a mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below):
- Python version:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

<!-- 
Collect system information using our environment capture script.
https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can also obtain the TensorFlow version with:

1. TensorFlow 1.0
`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

2. TensorFlow 2.0
`python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`
-->
",hafiz031,b'models:research type:bug',2020-05-30T19:04:08Z,2020-09-28T19:51:04Z,,,,,,,
8590,"how to freeze, convert and compile ssdlite mobiledet model","<!--
As per our GitHub Policy (https://github.com/tensorflow/models/blob/master/ISSUES.md), we only address code bugs, documentation issues, and feature requests on GitHub.

We will automatically close questions and help related issues.

Please go to Stack Overflow (http://stackoverflow.com/questions/tagged/tensorflow-model-garden) for questions and help.

-->
How to run a trained ssdlite mobiledets model on coral USB edge TPU?   
Can you provide a step-by-step tutorial?

",Aspirinkb,b'models:research type:support',2020-05-29T10:51:55Z,2020-06-10T17:49:57Z,,,,,,,
8578,Jpeg Image Issues,"<!--
As per our GitHub Policy (https://github.com/tensorflow/models/blob/master/ISSUES.md), we only address code bugs, documentation issues, and feature requests on GitHub.

We will automatically close questions and help related issues.

Please go to Stack Overflow (http://stackoverflow.com/questions/tagged/tensorflow-model-garden) for questions and help.

-->
Hello all,

I am working on an object detection problem on my custom dataset. The dataset contains around 80000 images. I am creating TFRecords and building a tf.Dataset for the same. But, I am facing issues related to jpeg images. Sometimes in tf.io.decode_jpeg functions. I am getting errors like ""Invalid Jpeg Image"", ""Can not resize jpeg image"" and ""Premature end of jpeg files"". I am getting errors in only few of them. So, I want to ignore such images and continue my training. So, is there any way where I can know whether there is any problem in the image beforehand and do exceptional handling of such images and can continue training?
",hardik22317,b'stat:awaiting response type:support',2020-05-27T10:23:57Z,2020-07-02T09:37:30Z,,,,,,,
8577,fork update,"# Description

> :memo: Please include a summary of the change. 
>  
> * Please also include relevant motivation and context.  
> * List any dependencies that are required for this change.  

## Type of change

For a new feature or function, please create an issue first to discuss it
with us before submitting a pull request.

Note: Please delete options that are not relevant.

- [ ] Bug fix (non-breaking change which fixes an issue)
- [ ] Documentation update
- [ ] TensorFlow 2 migration
- [ ] New feature (non-breaking change which adds functionality)
- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)
- [ ] A new research paper code implementation
- [ ] Other (Specify)

## Tests

> :memo: Please describe the tests that you ran to verify your changes.
>  
> * Provide instructions so we can reproduce.  
> * Please also list any relevant details for your test configuration.  

**Test Configuration**:

## Checklist

- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).
- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).
- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).
- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.
- [ ] I have commented my code, particularly in hard-to-understand areas.
- [ ] I have made corresponding changes to the documentation.
- [ ] My changes generate no new warnings.
- [ ] I have added tests that prove my fix is effective or that my feature works.
",mir-of,b'cla: no',2020-05-27T08:28:35Z,2020-05-27T08:29:00Z,,,,,,,
8575,The following classes have no ground truth,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution : Linux Ubuntu 18.04

- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 1.15.0
- Python version: 3.7.4 

- CUDA/cuDNN version: 10.2 
- GPU model and memory: GeForce GTX 1050



**Describe the current behavior**
hey guys, i'm trying to train an object detection 3 classes model using resnet101 faster rcnn using train.py from legacy folder from object detection api,
the losses looks very good but when running eval.py i get a very low mAP of the 3rd one only
with this warning : 
object_detection_evaluation.py:1279] The following classes have no ground truth examples: [1 2]

label map : 

```
item {
  id: 1
  name: 'ooredoo'
  id: 2
  name: 'tt'
  id: 3
  name: 'orange'
}
```


config file  : 

```
# Faster R-CNN with Resnet-101 (v1), configuration for MSCOCO Dataset.
# Users should configure the fine_tune_checkpoint field in the train config as
# well as the label_map_path and input_path fields in the train_input_reader and
# eval_input_reader. Search for ""PATH_TO_BE_CONFIGURED"" to find the fields that
# should be configured.

model {
  faster_rcnn {
    num_classes: 3
    image_resizer {
      keep_aspect_ratio_resizer {
        min_dimension: 600
        max_dimension: 1024
      }
    }
    feature_extractor {
      type: 'faster_rcnn_resnet101'
      first_stage_features_stride: 16
    }
    first_stage_anchor_generator {
      grid_anchor_generator {
        scales: [0.25, 0.5, 1.0, 2.0]
        aspect_ratios: [0.5, 1.0, 2.0]
        height_stride: 16
        width_stride: 16
      }
    }
    first_stage_box_predictor_conv_hyperparams {
      op: CONV
      regularizer {
        l2_regularizer {
          weight: 0.0
        }
      }
      initializer {
        truncated_normal_initializer {
          stddev: 0.01
        }
      }
    }
    first_stage_nms_score_threshold: 0.0
    first_stage_nms_iou_threshold: 0.7
    first_stage_max_proposals: 300
    first_stage_localization_loss_weight: 2.0
    first_stage_objectness_loss_weight: 1.0
    initial_crop_size: 14
    maxpool_kernel_size: 2
    maxpool_stride: 2
    second_stage_box_predictor {
      mask_rcnn_box_predictor {
        use_dropout: false
        dropout_keep_probability: 1.0
        fc_hyperparams {
          op: FC
          regularizer {
            l2_regularizer {
              weight: 0.0
            }
          }
          initializer {
            variance_scaling_initializer {
              factor: 1.0
              uniform: true
              mode: FAN_AVG
            }
          }
        }
      }
    }
    second_stage_post_processing {
      batch_non_max_suppression {
        score_threshold: 0.0
        iou_threshold: 0.6
        max_detections_per_class: 100
        max_total_detections: 300
      }
      score_converter: SOFTMAX
    }
    second_stage_localization_loss_weight: 2.0
    second_stage_classification_loss_weight: 1.0
  }
}

train_config: {
  batch_size: 1
  optimizer {
    momentum_optimizer: {
      learning_rate: {
        manual_step_learning_rate {
          initial_learning_rate: 0.0003
          schedule {
            step: 300
            learning_rate: .00003
          }
          schedule {
            step: 600
            learning_rate: .000003
          }
        }
      }
      momentum_optimizer_value: 0.9
    }
    use_moving_average: false
  }
  gradient_clipping_by_norm: 10.0
  fine_tune_checkpoint: ""faster_rcnn_resnet101_coco_2018_01_28/model.ckpt""
  from_detection_checkpoint: true
  data_augmentation_options {
    random_horizontal_flip {
    }
  }
}

train_input_reader: {
  tf_record_input_reader {
    input_path: ""data/train.record""
  }
  label_map_path: ""data/comm.pbtxt""
}

eval_config: {
  num_examples: 22
  # Note: The below line limits the evaluation process to 10 evaluations.
  # Remove the below line to evaluate indefinitely.
  max_evals: 10
}

eval_input_reader: {
  tf_record_input_reader {
    input_path: ""data/test.record""
  }
  label_map_path: ""data/comm.pbtxt""
  shuffle: false
  num_readers: 1
}

```

already checked https://github.com/tensorflow/models/issues/1936 and https://github.com/tensorflow/models/issues/1696 
 ",TekayaNidham,b'models:research type:bug',2020-05-26T17:52:05Z,2020-06-19T00:04:39Z,,,,,,,
8572,"""ImportError: cannot import name tf2"" when doing Object Detection Model Training in Google Cloud","# Prerequisites

Please answer the following questions for yourself before submitting an issue.

- [no] I am using the latest TensorFlow Model Garden release and TensorFlow 2.
- [yes] I am reporting the issue to the correct repository. (Model Garden official or research directory)
- [yes] I checked to make sure that this issue has not been filed already.

## 1. The entire URL of the file you are using

https://github.com/tensorflow/models

## 2. Describe the bug

Starting a training job on google cloud for my object detection dataset. Job stops after ~7 minutes giving this error:
```
Traceback (most recent call last): File ""/usr/lib/python2.7/runpy.py"", line 174, in _run_module_as_main ""__main__"", fname, loader, pkg_name) 
File ""/usr/lib/python2.7/runpy.py"", line 72, in _run_code exec code in run_globals 
File ""/root/.local/lib/python2.7/site-packages/object_detection/model_main.py"", line 26, in <module> from object_detection import model_lib 
File ""/root/.local/lib/python2.7/site-packages/object_detection/model_lib.py"", line 28, in <module> from object_detection import exporter as exporter_lib 
File ""/root/.local/lib/python2.7/site-packages/object_detection/exporter.py"", line 23, in <module> from object_detection.builders import model_builder 
File ""/root/.local/lib/python2.7/site-packages/object_detection/builders/model_builder.py"", line 39, in <module> from object_detection.utils import tf_version
 File ""/root/.local/lib/python2.7/site-packages/object_detection/utils/tf_version.py"", line 17, in <module> from tensorflow.python import tf2 # pylint: disable=import-outside-toplevel ImportError: cannot import name tf2
```
Local training however works fine, but is really slow and will take at least a week.

## 3. Steps to reproduce

Install Tensorflow 1.14 with pip, all other libraries for the API, model repository, pycocotools, protobuf 3.11.4 -> testing the API installation works fine.
Create dataset including tfrecord files, training pipeline, googlecloud yaml file, ...
Run google cloud training job with:
# in models/research
```
gcloud ai-platform jobs submit training balls200_training_260520a     --runtime-version 1.12     --job-dir=gs://200balls_model/train     --packages dist/object_detection-0.1.tar.gz,slim/dist/slim-0.1.tar.gz,tmp/pycocotools/pycocotools-2.0.tar.gz     --module-name object_detection.model_main     --region us-central1     --config /home/ubuntu/Documents/200balls_modeltraining/cloud.yml     --     --model_dir=gs://200balls_model/train     --pipeline_config_path=gs://200balls_model/pipeline.config
```
getting the error
uninstalling tensorflow 1.14 and installing 1.15 as it is required for the API

## 4. Expected behavior

training job should run without any errors as I'm using tf 1.15 which is required for the object detection API

## 5. Additional context

## 6. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):ubuntu 16
- Mobile device name if the issue happens on a mobile device:-
- TensorFlow installed from (source or binary):pip install
- TensorFlow version (use command below):('v1.15.0-rc3-22-g590d6ee', '1.15.0')
- Python version:2.7.12
- Bazel version (if compiling from source):-
- GCC/Compiler version (if compiling from source):gcc (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 
- CUDA/cuDNN version:
- GPU model and memory:
",sohartma,b'models:research type:bug',2020-05-26T13:19:15Z,2020-05-27T15:01:08Z,,,,,,,
8569,[DeepLab] ImageNet pre-trained checkpoints are missing variables,"## 1. The entire URL of the file you are using

https://github.com/tensorflow/models/blob/master/research/deeplab/train.py

## 2. Describe the bug

When trying to train from ImageNet pretrained weights, most (all?) variables are reported missing:
```
INFO:tensorflow:Initializing model from path: deeplab/download/xception/model.ckpt
I0525 10:58:58.676074 140291237205824 train_utils.py:207] Initializing model from path: deeplab/download/xception/model.ckpt
WARNING:tensorflow:Checkpoint is missing variable [image_pooling/weights]
W0525 10:59:00.488656 140291237205824 variables.py:676] Checkpoint is missing variable [image_pooling/weights]
WARNING:tensorflow:Checkpoint is missing variable [image_pooling/BatchNorm/gamma]
W0525 10:59:00.488829 140291237205824 variables.py:676] Checkpoint is missing variable [image_pooling/BatchNorm/gamma]
WARNING:tensorflow:Checkpoint is missing variable [image_pooling/BatchNorm/beta]
W0525 10:59:00.488880 140291237205824 variables.py:676] Checkpoint is missing variable [image_pooling/BatchNorm/beta]
WARNING:tensorflow:Checkpoint is missing variable [image_pooling/BatchNorm/moving_mean]
W0525 10:59:00.488926 140291237205824 variables.py:676] Checkpoint is missing variable [image_pooling/BatchNorm/moving_mean]
WARNING:tensorflow:Checkpoint is missing variable [image_pooling/BatchNorm/moving_variance]
W0525 10:59:00.488965 140291237205824 variables.py:676] Checkpoint is missing variable [image_pooling/BatchNorm/moving_variance]
WARNING:tensorflow:Checkpoint is missing variable [aspp0/weights]
....
```
## 3. Steps to reproduce
I'm running the following command:
```bash
 python deeplab/train.py --logtostderr --training_number_of_steps=30000 --train_split=""train_aug""     --model_variant=""xception_65"" --atrous_rates=6 --atrous_rates=12 --atrous_rates=18 --output_stride=16 --decoder_output_stride=4 --train_crop_size=""513,513"" --train_batch_size=16     --dataset=""pascal_voc_seg""     --tf_initial_checkpoint=deeplab/download/xception/model.ckpt    --train_logdir=train_deeplab     --dataset_dir=deeplab/datasets/pascal_voc_seg/tfrecord/     --fine_tune_batch_norm=True     --num_clones=2     --base_learning_rate=0.007
```
which is almost identical to the example provided in the docs.
The only things I have changed are the train_split (I added tf-records for the SBD dataset to create the ""train_aug"" split) and the base_learning_rate. The file in the tf_initial_checkpoint argument is the extracted model checkpoint from [here](http://download.tensorflow.org/models/deeplabv3_xception_2018_01_04.tar.gz)

If I change the model_variant to ResNet or another version of xception I run into the same issue.

## 4. Expected behavior

I expect the model to load the weights from the pre-trained ImageNet model.

## 5. Additional context

The full output log until training starts is:
```
/home/stammes/development/envs/tf-deeplabv3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([(""qint8"", np.int8, 1)])
/home/stammes/development/envs/tf-deeplabv3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([(""quint8"", np.uint8, 1)])
/home/stammes/development/envs/tf-deeplabv3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([(""qint16"", np.int16, 1)])
/home/stammes/development/envs/tf-deeplabv3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([(""quint16"", np.uint16, 1)])
/home/stammes/development/envs/tf-deeplabv3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([(""qint32"", np.int32, 1)])
/home/stammes/development/envs/tf-deeplabv3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([(""resource"", np.ubyte, 1)])
/home/stammes/development/envs/tf-deeplabv3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([(""qint8"", np.int8, 1)])
/home/stammes/development/envs/tf-deeplabv3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([(""quint8"", np.uint8, 1)])
/home/stammes/development/envs/tf-deeplabv3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([(""qint16"", np.int16, 1)])
/home/stammes/development/envs/tf-deeplabv3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([(""quint16"", np.uint16, 1)])
/home/stammes/development/envs/tf-deeplabv3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([(""qint32"", np.int32, 1)])
/home/stammes/development/envs/tf-deeplabv3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([(""resource"", np.ubyte, 1)])
WARNING:tensorflow:From /home/stammes/development/models/research/deeplab/core/conv2d_ws.py:40: The name tf.layers.Layer is deprecated. Please use tf.compat.v1.layers.Layer instead.

WARNING:tensorflow:From deeplab/train.py:464: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.

WARNING:tensorflow:From deeplab/train.py:274: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.

W0525 11:08:29.822635 140689338758976 deprecation_wrapper.py:119] From deeplab/train.py:274: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.

WARNING:tensorflow:From deeplab/train.py:274: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.

W0525 11:08:29.822928 140689338758976 deprecation_wrapper.py:119] From deeplab/train.py:274: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.

WARNING:tensorflow:From deeplab/train.py:289: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.

W0525 11:08:29.823206 140689338758976 deprecation_wrapper.py:119] From deeplab/train.py:289: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.

WARNING:tensorflow:From deeplab/train.py:290: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.

W0525 11:08:29.823446 140689338758976 deprecation_wrapper.py:119] From deeplab/train.py:290: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.

INFO:tensorflow:Training on train_aug set
I0525 11:08:29.823647 140689338758976 train.py:290] Training on train_aug set
WARNING:tensorflow:From deeplab/train.py:314: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.

W0525 11:08:29.825254 140689338758976 deprecation_wrapper.py:119] From deeplab/train.py:314: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.

WARNING:tensorflow:From /home/stammes/development/models/research/deeplab/datasets/data_generator.py:350: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.

W0525 11:08:29.831180 140689338758976 deprecation_wrapper.py:119] From /home/stammes/development/models/research/deeplab/datasets/data_generator.py:350: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.

WARNING:tensorflow:From /home/stammes/development/models/research/deeplab/datasets/data_generator.py:221: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.

W0525 11:08:29.857454 140689338758976 deprecation_wrapper.py:119] From /home/stammes/development/models/research/deeplab/datasets/data_generator.py:221: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.

WARNING:tensorflow:From /home/stammes/development/models/research/deeplab/datasets/data_generator.py:236: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

W0525 11:08:29.857678 140689338758976 deprecation_wrapper.py:119] From /home/stammes/development/models/research/deeplab/datasets/data_generator.py:236: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

2020-05-25 11:08:29.886698: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2020-05-25 11:08:30.100392: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: Tesla V100-SXM2-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:1a:00.0
2020-05-25 11:08:30.102558: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 1 with properties: 
name: Tesla V100-SXM2-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:1b:00.0
2020-05-25 11:08:30.104418: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2020-05-25 11:08:30.107183: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2020-05-25 11:08:30.109918: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2020-05-25 11:08:30.115403: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2020-05-25 11:08:30.119125: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2020-05-25 11:08:30.122577: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2020-05-25 11:08:30.132241: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2020-05-25 11:08:30.140754: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0, 1
WARNING:tensorflow:From /home/stammes/development/models/research/deeplab/core/preprocess_utils.py:351: The name tf.lin_space is deprecated. Please use tf.linspace instead.

W0525 11:08:30.168017 140689338758976 deprecation_wrapper.py:119] From /home/stammes/development/models/research/deeplab/core/preprocess_utils.py:351: The name tf.lin_space is deprecated. Please use tf.linspace instead.

WARNING:tensorflow:From /home/stammes/development/models/research/deeplab/core/preprocess_utils.py:352: The name tf.random_shuffle is deprecated. Please use tf.random.shuffle instead.

W0525 11:08:30.170604 140689338758976 deprecation_wrapper.py:119] From /home/stammes/development/models/research/deeplab/core/preprocess_utils.py:352: The name tf.random_shuffle is deprecated. Please use tf.random.shuffle instead.

WARNING:tensorflow:From /home/stammes/development/models/research/deeplab/core/preprocess_utils.py:377: The name tf.image.resize_bilinear is deprecated. Please use tf.compat.v1.image.resize_bilinear instead.

W0525 11:08:30.184353 140689338758976 deprecation_wrapper.py:119] From /home/stammes/development/models/research/deeplab/core/preprocess_utils.py:377: The name tf.image.resize_bilinear is deprecated. Please use tf.compat.v1.image.resize_bilinear instead.

WARNING:tensorflow:From /home/stammes/development/models/research/deeplab/core/preprocess_utils.py:314: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.

W0525 11:08:30.310308 140689338758976 deprecation_wrapper.py:119] From /home/stammes/development/models/research/deeplab/core/preprocess_utils.py:314: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.

WARNING:tensorflow:From /home/stammes/development/models/research/deeplab/datasets/data_generator.py:339: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.
W0525 11:08:30.395894 140689338758976 deprecation.py:323] From /home/stammes/development/models/research/deeplab/datasets/data_generator.py:339: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.
WARNING:tensorflow:From /home/stammes/development/models/research/deeplab/core/feature_extractor.py:490: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
W0525 11:08:30.411961 140689338758976 deprecation.py:323] From /home/stammes/development/models/research/deeplab/core/feature_extractor.py:490: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
WARNING:tensorflow:From /home/stammes/development/models/research/deeplab/utils/train_utils.py:158: The name tf.losses.add_loss is deprecated. Please use tf.compat.v1.losses.add_loss instead.

W0525 11:08:35.227229 140689338758976 deprecation_wrapper.py:119] From /home/stammes/development/models/research/deeplab/utils/train_utils.py:158: The name tf.losses.add_loss is deprecated. Please use tf.compat.v1.losses.add_loss instead.

WARNING:tensorflow:From deeplab/train.py:333: The name tf.summary.histogram is deprecated. Please use tf.compat.v1.summary.histogram instead.

W0525 11:08:37.335386 140689338758976 deprecation_wrapper.py:119] From deeplab/train.py:333: The name tf.summary.histogram is deprecated. Please use tf.compat.v1.summary.histogram instead.

WARNING:tensorflow:From deeplab/train.py:361: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.

W0525 11:08:37.994565 140689338758976 deprecation_wrapper.py:119] From deeplab/train.py:361: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.

INFO:tensorflow:Setting decay_steps to total training steps.
I0525 11:08:37.997147 140689338758976 train_utils.py:327] Setting decay_steps to total training steps.
WARNING:tensorflow:From /home/stammes/development/models/research/deeplab/utils/train_utils.py:337: The name tf.train.polynomial_decay is deprecated. Please use tf.compat.v1.train.polynomial_decay instead.

W0525 11:08:37.997281 140689338758976 deprecation_wrapper.py:119] From /home/stammes/development/models/research/deeplab/utils/train_utils.py:337: The name tf.train.polynomial_decay is deprecated. Please use tf.compat.v1.train.polynomial_decay instead.

WARNING:tensorflow:From /home/stammes/development/envs/tf-deeplabv3/lib/python3.7/site-packages/tensorflow/python/keras/optimizer_v2/learning_rate_schedule.py:409: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Deprecated in favor of operator or tf.math.divide.
W0525 11:08:38.000476 140689338758976 deprecation.py:323] From /home/stammes/development/envs/tf-deeplabv3/lib/python3.7/site-packages/tensorflow/python/keras/optimizer_v2/learning_rate_schedule.py:409: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Deprecated in favor of operator or tf.math.divide.
WARNING:tensorflow:From /home/stammes/development/models/research/deeplab/utils/train_utils.py:372: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
W0525 11:08:38.004090 140689338758976 deprecation.py:323] From /home/stammes/development/models/research/deeplab/utils/train_utils.py:372: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
WARNING:tensorflow:From deeplab/train.py:380: The name tf.train.MomentumOptimizer is deprecated. Please use tf.compat.v1.train.MomentumOptimizer instead.

W0525 11:08:38.005710 140689338758976 deprecation_wrapper.py:119] From deeplab/train.py:380: The name tf.train.MomentumOptimizer is deprecated. Please use tf.compat.v1.train.MomentumOptimizer instead.

WARNING:tensorflow:From deeplab/train.py:424: The name tf.summary.merge is deprecated. Please use tf.compat.v1.summary.merge instead.

W0525 11:08:43.557871 140689338758976 deprecation_wrapper.py:119] From deeplab/train.py:424: The name tf.summary.merge is deprecated. Please use tf.compat.v1.summary.merge instead.

INFO:tensorflow:Ignoring initialization; other checkpoint exists
I0525 11:08:43.580271 140689338758976 train_utils.py:204] Ignoring initialization; other checkpoint exists
WARNING:tensorflow:From /home/stammes/development/envs/tf-deeplabv3/lib/python3.7/site-packages/tensorflow/contrib/slim/python/slim/learning.py:742: Supervisor.__init__ (from tensorflow.python.training.supervisor) is deprecated and will be removed in a future version.
Instructions for updating:
Please switch to tf.train.MonitoredTrainingSession
W0525 11:08:44.982430 140689338758976 deprecation.py:323] From /home/stammes/development/envs/tf-deeplabv3/lib/python3.7/site-packages/tensorflow/contrib/slim/python/slim/learning.py:742: Supervisor.__init__ (from tensorflow.python.training.supervisor) is deprecated and will be removed in a future version.
Instructions for updating:
Please switch to tf.train.MonitoredTrainingSession
2020-05-25 11:08:45.925250: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2020-05-25 11:08:45.967727: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
2020-05-25 11:08:45.967964: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0xfe943a0 executing computations on platform Host. Devices:
2020-05-25 11:08:45.967992: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2020-05-25 11:08:46.248227: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: Tesla V100-SXM2-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:1a:00.0
2020-05-25 11:08:46.249768: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 1 with properties: 
name: Tesla V100-SXM2-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:1b:00.0
2020-05-25 11:08:46.249842: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2020-05-25 11:08:46.249857: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2020-05-25 11:08:46.249888: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2020-05-25 11:08:46.249901: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2020-05-25 11:08:46.249913: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2020-05-25 11:08:46.249925: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2020-05-25 11:08:46.249938: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2020-05-25 11:08:46.255653: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0, 1
2020-05-25 11:08:46.255709: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2020-05-25 11:08:46.259229: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-05-25 11:08:46.259243: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 1 
2020-05-25 11:08:46.259248: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N Y 
2020-05-25 11:08:46.259252: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 1:   Y N 
2020-05-25 11:08:46.265176: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 30583 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:1a:00.0, compute capability: 7.0)
2020-05-25 11:08:46.268464: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 30583 MB memory) -> physical GPU (device: 1, name: Tesla V100-SXM2-32GB, pci bus id: 0000:1b:00.0, compute capability: 7.0)
2020-05-25 11:08:46.270905: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0xdbd5460 executing computations on platform CUDA. Devices:
2020-05-25 11:08:46.270923: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2020-05-25 11:08:46.270928: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (1): Tesla V100-SXM2-32GB, Compute Capability 7.0
WARNING:tensorflow:From /home/stammes/development/envs/tf-deeplabv3/lib/python3.7/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to check for files with this prefix.
W0525 11:08:46.272718 140689338758976 deprecation.py:323] From /home/stammes/development/envs/tf-deeplabv3/lib/python3.7/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to check for files with this prefix.
INFO:tensorflow:Restoring parameters from train_deeplab_test_15/model.ckpt-0
I0525 11:08:46.273993 140689338758976 saver.py:1280] Restoring parameters from train_deeplab_test_15/model.ckpt-0
2020-05-25 11:08:48.614744: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
WARNING:tensorflow:From /home/stammes/development/envs/tf-deeplabv3/lib/python3.7/site-packages/tensorflow/python/training/saver.py:1066: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file utilities to get mtimes.
W0525 11:08:49.853774 140689338758976 deprecation.py:323] From /home/stammes/development/envs/tf-deeplabv3/lib/python3.7/site-packages/tensorflow/python/training/saver.py:1066: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file utilities to get mtimes.
INFO:tensorflow:Running local_init_op.
I0525 11:08:49.856222 140689338758976 session_manager.py:500] Running local_init_op.
INFO:tensorflow:Done running local_init_op.
I0525 11:08:50.772156 140689338758976 session_manager.py:502] Done running local_init_op.
INFO:tensorflow:Starting Session.
I0525 11:08:58.693684 140689338758976 learning.py:754] Starting Session.
INFO:tensorflow:Saving checkpoint to path train_deeplab_test_15/model.ckpt
I0525 11:08:59.046062 140684354885376 supervisor.py:1117] Saving checkpoint to path train_deeplab_test_15/model.ckpt
INFO:tensorflow:Starting Queues.
I0525 11:08:59.046199 140689338758976 learning.py:768] Starting Queues.
2020-05-25 11:09:08.968793: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
INFO:tensorflow:Recording summary at step 0.
I0525 11:09:13.616672 140683927086848 supervisor.py:1050] Recording summary at step 0.
INFO:tensorflow:global_step/sec: 0
I0525 11:09:16.224447 140683935479552 supervisor.py:1099] global_step/sec: 0
INFO:tensorflow:global step 10: loss = 2.7641 (1.359 sec/step)
I0525 11:09:32.953874 140689338758976 learning.py:507] global step 10: loss = 2.7641 (1.359 sec/step)
```

## 6. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- Mobile device name if the issue happens on a mobile device: n.a.
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 1.14
- Python version: 3.7.3
- Bazel version (if compiling from source): n.a.
- GCC/Compiler version (if compiling from source): n.a.
- CUDA/cuDNN version: CUDA 10.0/cuDNN 7
- GPU model and memory: 2x Tesla V100 32GB

<!-- 
Collect system information using our environment capture script.
https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can also obtain the TensorFlow version with:

1. TensorFlow 1.0
`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

2. TensorFlow 2.0
`python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`
-->
",ErikStammes,b'models:research type:bug',2020-05-25T09:13:21Z,2020-06-05T13:55:08Z,,,,,,,
8566,Cant export frozen inference graph ValueError: The passed save_path is not a valid checkpoint: training/model.ckpt-4347,"Whenever I try to export the frozen inference graph it produces an error ""ValueError: The passed save_path is not a valid checkpoint: training/model.ckpt-4347"" even though I am currently in object detection directory and there is a training folder which contains model.ckpt.4347

Logs

Traceback (most recent call last):
  File ""export_inference_graph.py"", line 162, in <module>
    tf.app.run()
  File ""C:\Users\Rahul\Anaconda3\envs\tf1.13.1\lib\site-packages\tensorflow\python\platform\app.py"", line 125, in run
    _sys.exit(main(argv))
  File ""export_inference_graph.py"", line 158, in main
    write_inference_graph=FLAGS.write_inference_graph)
  File ""D:\ExtraWork\models\research\object_detection\exporter.py"", line 489, in export_inference_graph
    write_inference_graph=write_inference_graph)
  File ""D:\ExtraWork\models\research\object_detection\exporter.py"", line 418, in _export_inference_graph
    trained_checkpoint_prefix=checkpoint_to_use)
  File ""D:\ExtraWork\models\research\object_detection\exporter.py"", line 327, in write_graph_and_checkpoint
    saver.restore(sess, trained_checkpoint_prefix)
  File ""C:\Users\Rahul\Anaconda3\envs\tf1.13.1\lib\site-packages\tensorflow\python\training\saver.py"", line 1268, in restore
    + compat.as_text(save_path))
ValueError: The passed save_path is not a valid checkpoint: training/model.ckpt-4347.


6. System information

- OS Platform :windows10
- TensorFlow version 1.13.1
- Python version 3.7
-Both my cuda and cudann are compatible with TensorFlow
- GPU model and memory: GTX 1050 4gb

![Screenshot (97)](https://user-images.githubusercontent.com/38246396/82751010-ea215480-9dd1-11ea-867e-ced490c6f5bf.png)

",bloodgreed99,b'models:research type:bug',2020-05-24T09:49:18Z,2020-05-24T09:52:18Z,,,,,,,
8565,Repeated tf.cast in official/image_classification,"# Description

See the change. The two tf.cast calls are repeated.

> :memo: Please include a summary of the change. 
>  
> * Please also include relevant motivation and context.  
> * List any dependencies that are required for this change.  

## Type of change

For a new feature or function, please create an issue first to discuss it
with us before submitting a pull request.

Note: Please delete options that are not relevant.

- [x] Bug fix (non-breaking change which fixes an issue)

## Tests

> :memo: Please describe the tests that you ran to verify your changes.
>  
> * Provide instructions so we can reproduce.  
> * Please also list any relevant details for your test configuration.  

**Test Configuration**:

## Checklist

- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).
- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).
- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).
- [x] I have made corresponding changes to the documentation.
- [x] My changes generate no new warnings.

",djdongjin,b'cla: yes ready to pull',2020-05-24T06:32:37Z,2020-06-06T00:22:06Z,,,,,,,
8564,"incompatible with both tensroflow v1 and v2, this project is absolutely unusable","I ran the code with tf 2 and it gave **tf.contrib** error. I searched the internet and found I should use version 1, and with version 1 it'll give **tf.python.tf2** error",aliamiri1380,b'models:research type:bug',2020-05-23T02:14:59Z,2020-05-28T05:03:13Z,,,,,,,
8562,"Move models/slim to tf_slim. Release MobileDet code and model, and require tf_slim installation for OD API.","# Description

Update models/slim to use tf_slim instead of contrib.slim, 

Release MobileDet code and model in Object Detection API.
tf_slim is now required to be installed for OD API.

## Type of change

For a new feature or function, please create an issue first to discuss it
with us before submitting a pull request.

Note: Please delete options that are not relevant.

- [ ] Bug fix (non-breaking change which fixes an issue)
- [ ] Documentation update
- [ ] TensorFlow 2 migration
- [ ] New feature (non-breaking change which adds functionality)
- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)
- [ ] A new research paper code implementation
- [ ] Other (Specify)

## Tests

> :memo: Please describe the tests that you ran to verify your changes.
>  
> * Provide instructions so we can reproduce.  
> * Please also list any relevant details for your test configuration.  

**Test Configuration**:

## Checklist

- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).
- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).
- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).
- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.
- [ ] I have commented my code, particularly in hard-to-understand areas.
- [ ] I have made corresponding changes to the documentation.
- [ ] My changes generate no new warnings.
- [ ] I have added tests that prove my fix is effective or that my feature works.
",pkulzc,b'cla: yes stat:awaiting review',2020-05-22T07:39:38Z,2020-06-11T16:52:55Z,,,,,,,
8561,"[Tensorboard] my training loss is stucked at step 1, but evaluation loss is updating","<!--
As per our GitHub Policy (https://github.com/tensorflow/models/blob/master/ISSUES.md), we only address code bugs, documentation issues, and feature requests on GitHub.

We will automatically close questions and help related issues.

Please go to Stack Overflow (http://stackoverflow.com/questions/tagged/tensorflow-model-garden) for questions and help.

-->

- What is the top-level directory of the model you are using: tensorflow1/models/research/object_detection

- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10

- TensorFlow installed from (source or binary): pip

- TensorFlow version (use command below): 1.14.0

- Bazel version (if compiling from source): NA

- CUDA/cuDNN version: NA

- GPU model and memory: NA

- Exact command to reproduce: python object_detection/model_main.py --pipeline_config_path=object_detection/datasets/experiments/training/faster_rcnn_datasets.config --model_dir=object_detection/datasets/experiments/training --num_train_steps=50000 --sample_1_of_n_eval_examples=1 --alsologtostderr

tensorboard --logdir ankylosing/experiments/training --host localhost --port 8088


I'm using model_main.py to train my model. It didn't give me an error and works quite well. However, when I checked tensorboard, my loss_1 and loss_2 graph seemed like not updating after step1.

![image](https://user-images.githubusercontent.com/62231006/82625864-39745300-9c21-11ea-9a44-80e204ade30d.png)

Can you tell me how to fix it?

![image](https://user-images.githubusercontent.com/62231006/82626540-0763f080-9c23-11ea-87a3-a7dd5a8da9cb.png)


My other loss graphs look like this. 
And below is the result I got from each step.



INFO:tensorflow:Calling model_fn.                                                          
I0522 11:32:46.233400  1256 estimator.py:1145] Calling model_fn.                           INFO:tensorflow:Scale of 0 disables regularizer.                                           
I0522 11:32:46.270332  1256 regularizers.py:98] Scale of 0 disables regularizer.    
INFO:tensorflow:Done calling model_fn.                                                     
I0522 11:09:04.982665  1256 estimator.py:1147] Done calling model_fn.                      INFO:tensorflow:Starting evaluation at 2020-05-22T11:09:04Z                                
I0522 11:09:04.999619  1256 evaluation.py:255] Starting evaluation at 2020-05-22T11:09:04Z INFO:tensorflow:Graph was finalized.                                                       
I0522 11:09:05.884253  1256 monitored_session.py:240] Graph was finalized.                 INFO:tensorflow:Restoring parameters from object_detection/ankylosing/experiments/training\model.ckpt-93                                                                              I0522 11:09:05.890208  1256 saver.py:1280] Restoring parameters from object_detection/ankylosing/experiments/training\model.ckpt-93                                                   INFO:tensorflow:Running local_init_op.     
I0522 11:09:07.192721  1256 session_manager.py:500] Running local_init_op.                 INFO:tensorflow:Done running local_init_op.                                                
I0522 11:09:07.348306  1256 session_manager.py:502] Done running local_init_op.            INFO:tensorflow:Performing evaluation on 221 images.                                       
I0522 11:32:15.174471 43460 coco_evaluation.py:236] Performing evaluation on 221 images.   creating index...                                                                          
index created!                                                                             
INFO:tensorflow:Loading and preparing annotation results...                                
I0522 11:32:15.213368 43460 coco_tools.py:115] Loading and preparing annotation results... INFO:tensorflow:DONE (t=0.14s)                                                             
I0522 11:32:15.356982 43460 coco_tools.py:137] DONE (t=0.14s)                              
creating index...                                                                          
index created!                                                                             
Running per image evaluation...                                                            
Evaluate annotation type *bbox*                                                            
DONE (t=7.06s).                                                                            
Accumulating evaluation results...                                                         
DONE (t=0.39s).                                                                             
Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.238             
Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.530             
Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.147             
Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000            
Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000            
Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.238             
Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.293             
Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.495             
Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.525             
Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000            
Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000            
Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.525            INFO:tensorflow:Finished evaluation at 2020-05-22-11:32:23                                 
I0522 11:32:23.277833  1256 evaluation.py:275] Finished evaluation at 2020-05-22-11:32:23  INFO:tensorflow:Saving dict for global step 93: DetectionBoxes_Precision/mAP = 0.23755923, DetectionBoxes_Precision/mAP (large) = 0.23755945, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.5303363, DetectionBoxes_Precision/mAP@.75IOU = 0.14674938, DetectionBoxes_Recall/AR@1 = 0.29293266, DetectionBoxes_Recall/AR@10 = 0.4948963, DetectionBoxes_Recall/AR@100 = 0.5246189, DetectionBoxes_Recall/AR@100 (large) = 0.5246189, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.24961615, Loss/BoxClassifierLoss/localization_loss = 0.4095158, Loss/RPNLoss/localization_loss = 0.15028447, Loss/RPNLoss/objectness_loss = 0.23827589, Loss/total_loss = 1.0476927, global_step = 93, learning_rate = 0.0003, loss = 1.0476927                           I0522 11:32:23.280791  1256 estimator.py:2039] Saving dict for global step 93: DetectionBoxes_Precision/mAP = 0.23755923, DetectionBoxes_Precision/mAP (large) = 0.23755945, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.5303363, DetectionBoxes_Precision/mAP@.75IOU = 0.14674938, DetectionBoxes_Recall/AR@1 = 0.29293266, DetectionBoxes_Recall/AR@10 = 0.4948963, DetectionBoxes_Recall/AR@100 = 0.5246189, DetectionBoxes_Recall/AR@100 (large) = 0.5246189, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.24961615, Loss/BoxClassifierLoss/localization_loss = 0.4095158, Loss/RPNLoss/localization_loss = 0.15028447, Loss/RPNLoss/objectness_loss = 0.23827589, Loss/total_loss = 1.0476927, global_step = 93, learning_rate = 0.0003, loss = 1.0476927                                                                                       INFO:tensorflow:Saving 'checkpoint_path' summary for global step 93: object_detection/ankylosing/experiments/training\model.ckpt-93                                                   I0522 11:32:23.324671  1256 estimator.py:2099] Saving 'checkpoint_path' summary for global step 93: object_detection/ankylosing/experiments/training\model.ckpt-93                    INFO:tensorflow:Saving checkpoints for 94 into object_detection/ankylosing/experiments/training\model.ckpt.                                                                           I0522 11:32:39.134387  1256 basic_session_run_hooks.py:606] Saving checkpoints for 94 into object_detection/ankylosing/experiments/training\model.ckpt.                               ",dain5832,b'models:research type:support',2020-05-22T02:52:55Z,2020-05-22T13:59:20Z,,,,,,,
8560,No OpKernel was registered to support Op 'NcclAllReduce' used by ,"# Prerequisites

Please answer the following questions for yourself before submitting an issue.

- [x] I am using the latest TensorFlow Model Garden release and TensorFlow 2.2.0
- [ ] I am reporting the issue to the correct repository. (Model Garden official or research directory)
- [ ] I checked to make sure that this issue has not been filed already.

## 1. The entire URL of the file you are using

https://github.com/tensorflow/models/tree/master/official/nlp/transformer

## 2. Describe the bug

tensorflow.python.framework.errors_impl.InvalidArgumentError: No OpKernel was registered to support Op 'NcclAllReduce' used by {{node div_no_nan/NcclAllReduce}} with these attrs: [T=DT_FLOAT, num_devices=4, reduction=""sum"", shared_name=""c2""]
Registered devices: [CPU, XLA_CPU]

## 3. Steps to reproduce

!python3 transformer_main.py --data_dir=data --model_dir=model \
    --vocab_file=data/vocab.ende.32768 --param_set=big \
    --train_steps=100000 --steps_between_evals=5000 \
    --batch_size=4096 --max_length=64 \
    --bleu_source=data/newstest2014.en \
    --bleu_ref=data/newstest2014.de \
    --num_gpus=4\
    --enable_time_history=false

## 4. Expected behavior

A clear and concise description of what you expected to happen.

## 5. Additional context

Include any logs that would be helpful to diagnose the problem.

## 6. System information

- OS Platform and Distribution (centos 7.5):
- Mobile device name if the issue happens on a mobile device:
- TensorFlow installed from (source):
- TensorFlow version (2.2.0):
- Python version:3.6
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:10.2.0
- GPU model and memory: v100 *4    11G/per

<!-- 
Collect system information using our environment capture script.
https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can also obtain the TensorFlow version with:

2. TensorFlow 2.2.0
`python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`
-->
",paulrich1234,b'models:official type:bug',2020-05-22T02:50:43Z,2020-05-27T02:53:45Z,,,,,,,
8559,AttributeError: change_coordinate_frame ,"## The entire URL of the file you are using

https://github.com/tensorflow/models/tree/master/research/model_main.py

## Describe the bug

When running `model_main.py` after pulling the latest from master, I'm getting the error: `AttributeError: change_coordinate_frame` from `https://github.com/tensorflow/models/tree/master/research/model_lib.py`:

```
WARNING: Logging before flag parsing goes to stderr.
W0522 01:48:09.645347 140098740733760 deprecation_wrapper.py:119] From /tf/models/research/object_detection/model_main.py:111: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.

W0522 01:48:09.647595 140098740733760 deprecation_wrapper.py:119] From /tf/models/research/object_detection/utils/config_util.py:137: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.

W0522 01:48:09.653165 140098740733760 deprecation_wrapper.py:119] From /tf/models/research/object_detection/model_lib.py:685: The name tf.logging.warning is deprecated. Please use tf.compat.v1.logging.warning instead.

W0522 01:48:09.653301 140098740733760 model_lib.py:686] Forced number of epochs for all eval validations to be 1.
W0522 01:48:09.653435 140098740733760 deprecation_wrapper.py:119] From /tf/models/research/object_detection/utils/config_util.py:523: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.

I0522 01:48:09.653532 140098740733760 config_util.py:523] Maybe overwriting train_steps: None
I0522 01:48:09.653616 140098740733760 config_util.py:523] Maybe overwriting use_bfloat16: False
I0522 01:48:09.653701 140098740733760 config_util.py:523] Maybe overwriting sample_1_of_n_eval_examples: 1
I0522 01:48:09.653797 140098740733760 config_util.py:523] Maybe overwriting eval_num_epochs: 1
I0522 01:48:09.653898 140098740733760 config_util.py:523] Maybe overwriting load_pretrained: True
I0522 01:48:09.653985 140098740733760 config_util.py:533] Ignoring config override key: load_pretrained
W0522 01:48:09.654740 140098740733760 model_lib.py:702] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.
I0522 01:48:09.654871 140098740733760 model_lib.py:737] create_estimator_and_inputs: use_tpu False, export_to_tpu False
I0522 01:48:09.655415 140098740733760 estimator.py:209] Using config: {'_model_dir': 'v2_fpn-dwise_BOX_AR1.0__AUG_0.15-1.0//train', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true
graph_options {
  rewrite_options {
    meta_optimizer_iterations: ONE
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f6b10801f60>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W0522 01:48:09.655672 140098740733760 model_fn.py:630] Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7f6b0de8d488>) includes params argument, but params are not passed to Estimator.
I0522 01:48:09.656445 140098740733760 estimator_training.py:186] Not using Distribute Coordinator.
I0522 01:48:09.656667 140098740733760 training.py:612] Running training and evaluation locally (non-distributed).
I0522 01:48:09.656970 140098740733760 training.py:700] Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.
W0522 01:48:09.668902 140098740733760 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
Traceback (most recent call last):
  File ""/tf/models/research/object_detection/model_main.py"", line 111, in <module>
    tf.app.run()
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 300, in run
    _run_main(main, args)
  File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 251, in _run_main
    sys.exit(main(argv))
  File ""/tf/models/research/object_detection/model_main.py"", line 107, in main
    tf.estimator.train_and_evaluate(estimator, train_spec, eval_specs[0])
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py"", line 473, in train_and_evaluate
    return executor.run()
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py"", line 613, in run
    return self.run_local()
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py"", line 714, in run_local
    saving_listeners=saving_listeners)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 367, in train
    loss = self._train_model(input_fn, hooks, saving_listeners)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1158, in _train_model
    return self._train_model_default(input_fn, hooks, saving_listeners)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1185, in _train_model_default
    input_fn, ModeKeys.TRAIN))
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1022, in _get_features_and_labels_from_input_fn
    self._call_input_fn(input_fn, mode))
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1113, in _call_input_fn
    return input_fn(**kwargs)
  File ""/tf/models/research/object_detection/inputs.py"", line 645, in _train_input_fn
    params=params)
  File ""/tf/models/research/object_detection/inputs.py"", line 720, in train_input
    model_config, is_training=True).preprocess
  File ""/tf/models/research/object_detection/builders/model_builder.py"", line 905, in build
    add_summaries)
  File ""/tf/models/research/object_detection/builders/model_builder.py"", line 340, in _build_ssd_model
    ssd_config.post_processing)
  File ""/tf/models/research/object_detection/builders/post_processing_builder.py"", line 59, in build
    post_processing_config.batch_non_max_suppression)
  File ""/tf/models/research/object_detection/builders/post_processing_builder.py"", line 105, in _build_non_max_suppressor
    change_coordinate_frame=nms_config.change_coordinate_frame)
AttributeError: change_coordinate_frame
```

## Steps to reproduce

`python models/tree/master/research/model_main.py`

## System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 1.14
- Python version: 3.6.8",alexdwu13,b'models:research type:bug',2020-05-22T02:06:08Z,2020-05-22T22:52:36Z,,,,,,,
8551,"when I run""python object_detection/model_main.py --pipeline_config_path=xxx/models-master/traindata/data/ssd_mobilenet_v2_pets_keras.config --model_dir=training --num_train_steps=60000 --num_eval_steps=20 --alsologtostderr"",ERROR:File ""/usr/local/lib/python3.5/dist-packages/object_detection-0.1-py3.5.egg/object_detection/utils/tf_version.py"", line 17, in <module>     from tensorflow.python import tf2  # pylint: disable=import-outside-toplevel ImportError: cannot import name 'tf2'","tf2?it is tf1.12,is 1.15 nessary?<!--
As per our GitHub Policy (https://github.com/tensorflow/models/blob/master/ISSUES.md), we only address code bugs, documentation issues, and feature requests on GitHub.

We will automatically close questions and help related issues.

Please go to Stack Overflow (http://stackoverflow.com/questions/tagged/tensorflow-model-garden) for questions and help.

-->
",HYG-777,b'type:support',2020-05-21T12:52:24Z,2020-06-14T08:55:58Z,,,,,,,
8544,Python Version,"The source code works only on Python v2.7 and is not compatible with Python v3.x versions.

# Description

> :memo: Please include a summary of the change. 
>  
> * Please also include relevant motivation and context.  
> * List any dependencies that are required for this change.  

## Type of change

For a new feature or function, please create an issue first to discuss it
with us before submitting a pull request.

Note: Please delete options that are not relevant.

- [ ] Bug fix (non-breaking change which fixes an issue)
- [x] Documentation update
- [ ] TensorFlow 2 migration
- [ ] New feature (non-breaking change which adds functionality)
- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)
- [ ] A new research paper code implementation
- [ ] Other (Specify)

## Tests

> :memo: Please describe the tests that you ran to verify your changes.
>  
> * Provide instructions so we can reproduce.  
> * Please also list any relevant details for your test configuration.  

**Test Configuration**:

## Checklist

- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).
- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).
- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).
- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.
- [ ] I have commented my code, particularly in hard-to-understand areas.
- [ ] I have made corresponding changes to the documentation.
- [ ] My changes generate no new warnings.
- [ ] I have added tests that prove my fix is effective or that my feature works.
",nightlessbaron,b'cla: yes',2020-05-20T11:59:27Z,2020-05-20T17:02:17Z,,,,,,,
8542,bugfix: unused and incorrect variable name,"# Description
there is a bug that assigns test data files to `train_files` variable. Also, currently, test data are downloaded only (unprocessed and unused), so there is no need for a variable to keep track of those files.

## Type of change

- [x] Bug fix (non-breaking change which fixes an issue)

## Checklist

- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).
- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).
- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).
- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.
- [x] I have commented my code, particularly in hard-to-understand areas.
- [x] I have made corresponding changes to the documentation.
- [x] My changes generate no new warnings.
- [x] I have added tests that prove my fix is effective or that my feature works.
",howl-anderson,b'cla: yes ready to pull',2020-05-20T07:53:15Z,2020-05-25T06:50:03Z,,,,,,,
8539,How can we relate the parameters that are defined in the VGGish network with nperseg  and NFFT.  ,"<!--
As per our GitHub Policy (https://github.com/tensorflow/models/blob/master/ISSUES.md), we only address code bugs, documentation issues, and feature requests on GitHub.

We will automatically close questions and help related issues.

Please go to Stack Overflow (http://stackoverflow.com/questions/tagged/tensorflow-model-garden) for questions and help.

--> I have been working to change the VGGISH model for my research. In order to get the spectrograms that are provided to me using the vggish_input file, I am using the scipy function called specgram which takes as inputs the wav file and parameters like nperseg and NFFT.  I got a really apt picture of my spectrogram for nperseg 128 and NFFT 512. How can I think of these two values in terms of the parameters defined in the vggish_param file? 
",tusharpoddar,b'models:research type:support',2020-05-19T21:35:17Z,2020-05-22T12:11:23Z,,,,,,,
8538,create_coco_tf_record.py generates multiple tfrecord files,"<!--
As per our GitHub Policy (https://github.com/tensorflow/models/blob/master/ISSUES.md), we only address code bugs, documentation issues, and feature requests on GitHub.

We will automatically close questions and help related issues.

Please go to Stack Overflow (http://stackoverflow.com/questions/tagged/tensorflow-model-garden) for questions and help.

-->
Please Help me !
I have an annotation file in coco json format(three seperate files for train, test, val) and whenever I try to make tf_record file from that I always get many file (around 200 named like: 'coco_train.record-00071-of-00100' , 'coco_val.record-00008-of-00010' , 'coco_testdev.record-00015-of-00100' like this for every image file) 

please help me to create just three tf_record files each one for train, test, and val or help me to choose which one do I consider for further training

I am attaching some screen shots for better understanding.
thanks in advance.

![file_explorer](https://user-images.githubusercontent.com/62234441/82369883-b0250c80-99e5-11ea-843e-af77df3361c7.png)
![file_explorer1](https://user-images.githubusercontent.com/62234441/82369897-b2876680-99e5-11ea-988b-413963ea279c.png)
![file_explorer2](https://user-images.githubusercontent.com/62234441/82369905-b3b89380-99e5-11ea-860f-7565d5d2275e.png)
![terminal1](https://user-images.githubusercontent.com/62234441/82369916-b7e4b100-99e5-11ea-8598-ced53556ee6a.png)
![terminal2](https://user-images.githubusercontent.com/62234441/82369929-badfa180-99e5-11ea-8d58-8d24f2f865fc.png)





",MousamSangwan,b'models:research type:support',2020-05-19T19:32:25Z,2020-05-27T18:19:42Z,,,,,,,
8537,Model failed to serialize as JSON. Ignoring... Layer MetricLayer has arguments in `__init__` and therefore must override `get_config`.,"# Prerequisites

Please answer the following questions for yourself before submitting an issue.

- [Y ] I am using the latest TensorFlow Model Garden release and TensorFlow 2.
- [Y ] I am reporting the issue to the correct repository. (Model Garden official or research directory)
- [ Y] I checked to make sure that this issue has not been filed already.

## 1. The entire URL of the file you are using

https://github.com/tensorflow/models/blob/master/official/recommendation/ncf_keras_main.py

## 2. Describe the bug

Running ncf_keras_main.py gives an output with warning:
summary_ops_v2.py:1139] Model failed to serialize as JSON. Ignoring... Layer MetricLayer has arguments in `__init__` and therefore must override `get_config`.

## 3. Steps to reproduce

python ncf_keras_main.py --model_dir=""..."" --data_dir=""...""

## 4. Expected behavior

No warning. What could I do in order to save model and test with tensorflow.js?

## 5. Additional context

Include any logs that would be helpful to diagnose the problem.

## 6. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): CentOS 7
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): v2.2.0-rc4-8-g2b96f3662b 2.2.0
- Python version: 3.6.8
",n0ego,b'models:official stalled stat:awaiting response type:bug',2020-05-19T18:04:36Z,2020-09-18T18:17:54Z,,,,,,,
8534,deeplab/local_test.sh: Use 'bash' instead of 'sh',"# Description

Use 'bash' instead of 'sh' in `deeplab/local_test.sh`:

- Make it consistent with '/bin/bash' shebang
- Fix ""Bad substitution"" error in BASH_SOURCE[0]

## Type of change

- [x] Bug fix (non-breaking change which fixes an issue)

## Tests

```
[research/deeplab]> bash local_test.sh
```

**Test Configuration**:

- Tensorflow 1.15.2
- Ubuntu 18.04.4 LTS
- CUDA 10.1

## Checklist

- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).
- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).
- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).
- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.
- [x] My changes generate no new warnings.
",ruslo,b'cla: yes',2020-05-19T05:15:27Z,2020-07-16T17:23:03Z,,,,,,,
8532,i think it is because the eval process the source language and it concat target language output errors .,"# Prerequisites

Please answer the following questions for yourself before submitting an issue.

- [1 ] I am using the latest TensorFlow Model Garden release and TensorFlow 2.2.0
- [ 2] I am reporting the issue to the correct repository. (Model Garden official or research directory)
- [ 3] I checked to make sure that this issue has not been filed already.

## 1. The entire URL of the file you are using

https://github.com/tensorflow/models/tree/master/official/nlp/transformer

## 2. Describe the bug
i use the follow command to run the translation ,
 it training is ok ,and during training it eval a newstest2014.en file and it cannot concat the eval translation results and errors as following 

 
!python3 transformer_main.py --data_dir=data_v2 \
    --model_dir=model\
    --vocab_file=data_v2/vocab.ende.32768 \
    --param_set=big \
    --train_steps=100000 \
    --steps_between_evals=5000\
    --batch_size=4096 --max_length=64 \
    --bleu_source=data_v2/newstest2014.en \
    --bleu_ref=data_v2/newstest2014.de \
    --num_gpus=4 \
    --enable_time_history=False



64/64 [==============================] - 432s 7s/step
Traceback (most recent call last):
  File ""transformer_main.py"", line 510, in <module>
    app.run(main)
  File ""/home/dell/anaconda3/envs/tf2.2/lib/python3.6/site-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/home/dell/anaconda3/envs/tf2.2/lib/python3.6/site-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""transformer_main.py"", line 498, in main
    task.train()
  File ""transformer_main.py"", line 371, in train
    uncased_score, cased_score = self.eval()
  File ""transformer_main.py"", line 404, in eval
    distribution_strategy)
  File ""transformer_main.py"", line 122, in evaluate_and_log_bleu
    model, params, subtokenizer, bleu_source, bleu_ref, distribution_strategy)
  File ""transformer_main.py"", line 89, in translate_and_compute_bleu
    distribution_strategy=distribution_strategy)
  File ""/home/dell/workspace/cps_seq/models-master_origin_20200427/official/nlp/transformer/translate.py"", line 174, in translate_file
    val_outputs, _ = model.predict(text,verbose=1)
  File ""/home/dell/anaconda3/envs/tf2.2/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py"", line 94, in _method_wrapper
    return method(self, *args, **kwargs)
  File ""/home/dell/anaconda3/envs/tf2.2/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py"", line 1396, in predict
    all_outputs = nest.map_structure_up_to(batch_outputs, concat, outputs)
  File ""/home/dell/anaconda3/envs/tf2.2/lib/python3.6/site-packages/tensorflow/python/util/nest.py"", line 1131, in map_structure_up_to
    **kwargs)
  File ""/home/dell/anaconda3/envs/tf2.2/lib/python3.6/site-packages/tensorflow/python/util/nest.py"", line 1227, in map_structure_with_tuple_paths_up_to
    *flat_value_lists)]
  File ""/home/dell/anaconda3/envs/tf2.2/lib/python3.6/site-packages/tensorflow/python/util/nest.py"", line 1226, in <listcomp>
    results = [func(*args, **kwargs) for args in zip(flat_path_list,
  File ""/home/dell/anaconda3/envs/tf2.2/lib/python3.6/site-packages/tensorflow/python/util/nest.py"", line 1129, in <lambda>
    lambda _, *values: func(*values),  # Discards the path arg.
  File ""/home/dell/anaconda3/envs/tf2.2/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py"", line 1884, in concat
    return array_ops.concat(tensors, axis=axis)
  File ""/home/dell/anaconda3/envs/tf2.2/lib/python3.6/site-packages/tensorflow/python/util/dispatch.py"", line 180, in wrapper
    return target(*args, **kwargs)
  File ""/home/dell/anaconda3/envs/tf2.2/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py"", line 1630, in concat
    return gen_array_ops.concat_v2(values=values, axis=axis, name=name)
  File ""/home/dell/anaconda3/envs/tf2.2/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py"", line 1198, in concat_v2
    _ops.raise_from_not_ok_status(e, name)
  File ""/home/dell/anaconda3/envs/tf2.2/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 6816, in raise_from_not_ok_status
    six.raise_from(core._status_to_exception(e.code, message), None)
  File ""<string>"", line 3, in raise_from
tensorflow.python.framework.errors_impl.InvalidArgumentError: ConcatOp : Dimensions of inputs should match: shape[0] = [32,178] vs. shape[1] = [32,175] [Op:ConcatV2] name: concat

## 3. Steps to reproduce

!python3 transformer_main.py --data_dir=data_v2 \
    --model_dir=model\
    --vocab_file=data_v2/vocab.ende.32768 \
    --param_set=big \
    --train_steps=100000 \
    --steps_between_evals=5000\
    --batch_size=4096 --max_length=64 \
    --bleu_source=data_v2/newstest2014.en \
    --bleu_ref=data_v2/newstest2014.de \
    --num_gpus=4 \
    --enable_time_history=False

## 4. Expected behavior

when training ,it eval the translation file ,but it's eval process outputs concats errors 

## 5. Additional context

i think it is because the eval process the source language and it concat target language batch results shape doesnt match errors
but i donot know how to fix it .

## 6. System information

- Linux Ubuntu 16.04):
- TensorFlow installed from source 
- TensorFlow version 2.2.0:
- Python version:3.6
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:10.2.1
- GPU model and memory: 2080TI  *4   

<!-- 
Collect system information using our environment capture script.
https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can also obtain the TensorFlow version with:

1. TensorFlow 1.0
`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

2. TensorFlow 2.0
`python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`
-->
",paulrich1234,b'models:official type:bug',2020-05-19T03:11:29Z,2020-05-22T07:43:28Z,,,,,,,
8530,Evaluation/Finetuning of Resnet 50 in TF 2.X,"# Prerequisites

Please answer the following questions for yourself before submitting an issue.

- [x] I am using the latest TensorFlow Model Garden release and TensorFlow 2.
- [x] I am reporting the issue to the correct repository. (Model Garden official or research directory)
- [x] I checked to make sure that this issue has not been filed already.

## 1. The entire URL of the file you are using

https://github.com/tensorflow/models/tree/master/official/vision/image_classification/resnet
For pretrained checkpoints, I used the ones linked in the README (https://github.com/tensorflow/models/tree/master/official/vision/image_classification/resnet#pretrained-models)

## 2. Describe the bug

1) I'm trying to evaluate and finetune the Resnet 50 model available at the URL(mentioned above). However I get near zero accuracy when I evaluate. I would like to know how to evaluate and finetune using the existing RN50 checkpoint. 

The command I use for evaluating the existing model 
`python3 resnet_ctl_imagenet_main.py --model_dir=checkpoints/ --num_gpus=1 --batch_size=32 --train_epochs=1 --train_steps=1 --use_synthetic_data=false --data_dir imagenet_tfr_data/ `

The `model_dir` is set to checkpoints directory which has the downloaded checkpoint (from the README link). The checkpoint manager picks up this checkpoint, however does not seem to load as I get many unresolved object issues where the layer names mismatch.

> W0518 15:35:57.377599 139869265008448 util.py:144] Unresolved object in checkpoint: (root).layer_with_weights-4.kernel
WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-5.axis


2) Currently I seem to get this resnet model running for Tensorflow 2.2. There were multiple errors for 2.0 and 2.1. One such error is `from tensorflow.python.keras.layers.preprocessing import image_preprocessing as image_ops. ImportError: cannot import name 'image_preprocessing'`
This may not be relevant to the actual issue but for me TF 2,0 and TF 2.1 seem to give import and not found attribute errors which drove me to try TF 2.2.

3) Evaluation works when I do the following

In the resnet_runnable.py, I use keras way of loading the checkpoint
`self.model.load_weights(flags_obj.pretrained_filepath)`

This probably loads the checkpoint according to network topology rather than names (used by tf.train.CheckpointManager. (Is this correct way of loading ? ) 
I disable training manually and run the `self._evaluate_once(current_step)` to get `76.476`. Just wanted to confirm if this is same accuracy that you obtained? 

The questions are

* Is there a plan to add standalone eval script to this repo ? 
* If the way of evaluation described in 3) is recommended, can it be added to the repo as well as update the documentation as well on eval/finetuning steps? 
I would be happy to make a PR if required :)

Thank you !!
",peri044,b'models:official type:docs',2020-05-18T22:44:19Z,2020-09-14T21:00:58Z,,,,,,,
8529,Evaluation/Fine-tuning of Resnet 50 in TF 2.X,"# Prerequisites

Please answer the following questions for yourself before submitting an issue.

- [x] I am using the latest TensorFlow Model Garden release and TensorFlow 2.
- [x] I am reporting the issue to the correct repository. (Model Garden official or research directory)
- [x] I checked to make sure that this issue has not been filed already.

## 1. The entire URL of the file you are using

https://github.com/tensorflow/models/tree/master/official/vision/image_classification/resnet
For pretrained checkpoints, I used the ones linked in the README (https://github.com/tensorflow/models/tree/master/official/vision/image_classification/resnet#pretrained-models)

## 2. Describe the bug

1) I'm trying to evaluate and finetune the Resnet 50 model available at the URL(mentioned above). However I get near zero accuracy when I evaluate. I would like to know how to evaluate and finetune using the existing RN50 checkpoint. 

The command I use for evaluating the existing model 
`python3 resnet_ctl_imagenet_main.py --model_dir=checkpoints/ --num_gpus=1 --batch_size=32 --train_epochs=1 --train_steps=1 --use_synthetic_data=false --data_dir imagenet_tfr_data/ `

The `model_dir` is set to checkpoints directory which has the downloaded checkpoint (from the README link). The checkpoint manager picks up this checkpoint, however does not seem to load as I get many unresolved object issues where the layer names mismatch.

> W0518 15:35:57.377599 139869265008448 util.py:144] Unresolved object in checkpoint: (root).layer_with_weights-4.kernel
WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-5.axis


2) Currently I seem to get this resnet model running for Tensorflow 2.2. There were multiple errors for 2.0 and 2.1. One such error is `from tensorflow.python.keras.layers.preprocessing import image_preprocessing as image_ops. ImportError: cannot import name 'image_preprocessing'`
This may not be relevant to the actual issue but for me TF 2,0 and TF 2.1 seem to give import and not found attribute errors which drove me to try TF 2.2.

3) Evaluation works when I do the following

In the resnet_runnable.py, I use keras way of loading the checkpoint
`self.model.load_weights(flags_obj.pretrained_filepath)`

This probably loads the checkpoint according to network topology rather than names (used by tf.train.CheckpointManager. (Is this correct way of loading ? ) 
I disable training manually and run the `self._evaluate_once(current_step)` to get `76.476`. Just wanted to confirm if this is same accuracy that you obtained? 

The questions are

* Is there a plan to add standalone eval script to this repo ? 
* If the way of evaluation described in 3) is recommended, can it be added to the repo as well as update the documentation as well on eval/finetuning steps? 
I would be happy to make some PR if required :)

Thank you !!
",peri044,b'models:official type:bug',2020-05-18T22:40:50Z,2020-05-18T22:45:24Z,,,,,,,
8522,"Fix error ""Missing value for flag -v""","# Description

- Fix error `Missing value for flag -v`

## Type of change

- [x] Bug fix (non-breaking change which fixes an issue)

## Tests

```
[research/deeplab]> bash local_test.sh
```

**Test Configuration**:

- Tensorflow 1.15.2
- Ubuntu 18.04.4 LTS
- CUDA 10.1

## Checklist

- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).
- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).
- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).
- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.
- [x] My changes generate no new warnings.
",ruslo,b'cla: yes',2020-05-18T10:59:51Z,2020-05-19T05:03:48Z,,,,,,,
8519,Added the font_size parameter to visualization_utils.visualize_boxes_and_labels_on_image_array,"# Description

I found many users including me had a problem with the default font size. And all the issues were closed by providing a change in font size in the  visualization_utils file. So I changed the  visualize_boxes_and_labels_on_image_array function in visualization_utils and added the font_size parameter. Also I added this parameter to draw_bounding_box_on_image which is responsible for drawing bounding box on the image. Now the user can dynamically change the font size.

## Type of change

- [x] Bug fix (non-breaking change which fixes an issue)
Now the user can change the font size

## Tests

I tested this on many different and the testing images provided in the repository. All tests are running good.

**Test Configuration**:

## Checklist

- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).
- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).
- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).
- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.
- [x] I have commented my code, particularly in hard-to-understand areas.
- [ ] I have made corresponding changes to the documentation.
- [x] My changes generate no new warnings.
- [x] I have added tests that prove my fix is effective or that my feature works.
",mittshah2,b'cla: yes',2020-05-17T15:32:19Z,2020-05-17T15:39:07Z,,,,,,,
8517,Update deeplab/local_test.sh,"# Description
model_test.py doesn't support -v (--verbose) parameter. Removed -v param while calling this script.
To fix the following error:
File ""/usr/local/lib/python3.6/dist-packages/absl/flags/_flagvalues.py"", line 698, in get_value raise _exceptions.Error('Missing value for flag ' + arg) # pylint: disable=undefined-loop-variable absl.flags._exceptions.Error: Missing value for flag -
## Type of change
- [x] Bug fix (non-breaking change which fixes an issue)

## Tests
From tensorflow/models/research/deeplab
sh local_test.sh

**Test Configuration**:

## Checklist

- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).
- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).
- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).
- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.
- [ ] I have commented my code, particularly in hard-to-understand areas.
- [ ] I have made corresponding changes to the documentation.
- [ ] My changes generate no new warnings.
- [ ] I have added tests that prove my fix is effective or that my feature works.
",xanjay,b'cla: yes',2020-05-16T16:03:48Z,2020-05-18T18:46:45Z,,,,,,,
8512,[Struct2depth] Bad Motion inference on custom data,"<!--
As per our GitHub Policy (https://github.com/tensorflow/models/blob/master/ISSUES.md), we only address code bugs, documentation issues, and feature requests on GitHub.

We will automatically close questions and help related issues.

Please go to Stack Overflow (http://stackoverflow.com/questions/tagged/tensorflow-model-garden) for questions and help.

-->
Nice work @aneliaangelova and @VincentCa and team !
I trained the struct2depth model for motion and depth estimation for 100 epochs.The training data comprises of 1600 left and 1600 right images comprising of vehicles on indian roads.The egomotion inference values show that the vehicle moves sideways and back and front continuously , as opposed to moving in one direction.
I am not sure why am I getting such results.
Any help is appreciated.
",anakita,b'models:research type:support',2020-05-15T08:55:02Z,2020-05-16T23:21:15Z,,,,,,,
8502,create playing_card_reader01_label_map.pbtxt,"# Description

> :memo: Please include a summary of the change. 
>  
> * Please also include relevant motivation and context.  
> * List any dependencies that are required for this change.  

## Type of change

For a new feature or function, please create an issue first to discuss it
with us before submitting a pull request.

Note: Please delete options that are not relevant.

- [ ] Bug fix (non-breaking change which fixes an issue)
- [ ] Documentation update
- [ ] TensorFlow 2 migration
- [ ] New feature (non-breaking change which adds functionality)
- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)
- [ ] A new research paper code implementation
- [ ] Other (Specify)

## Tests

> :memo: Please describe the tests that you ran to verify your changes.
>  
> * Provide instructions so we can reproduce.  
> * Please also list any relevant details for your test configuration.  

**Test Configuration**:

## Checklist

- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).
- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).
- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).
- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.
- [ ] I have commented my code, particularly in hard-to-understand areas.
- [ ] I have made corresponding changes to the documentation.
- [ ] My changes generate no new warnings.
- [ ] I have added tests that prove my fix is effective or that my feature works.
",pdharma01,b'cla: no',2020-05-13T06:38:47Z,2020-05-13T06:40:14Z,,,,,,,
8499,Merge pull request #1 from tensorflow/master,"更新

# Description

> :memo: Please include a summary of the change. 
>  
> * Please also include relevant motivation and context.  
> * List any dependencies that are required for this change.  

## Type of change

For a new feature or function, please create an issue first to discuss it
with us before submitting a pull request.

Note: Please delete options that are not relevant.

- [ ] Bug fix (non-breaking change which fixes an issue)
- [ ] Documentation update
- [ ] TensorFlow 2 migration
- [ ] New feature (non-breaking change which adds functionality)
- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)
- [ ] A new research paper code implementation
- [ ] Other (Specify)

## Tests

> :memo: Please describe the tests that you ran to verify your changes.
>  
> * Provide instructions so we can reproduce.  
> * Please also list any relevant details for your test configuration.  

**Test Configuration**:

## Checklist

- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).
- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).
- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).
- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.
- [ ] I have commented my code, particularly in hard-to-understand areas.
- [ ] I have made corresponding changes to the documentation.
- [ ] My changes generate no new warnings.
- [ ] I have added tests that prove my fix is effective or that my feature works.
",JiangKui007,b'cla: no',2020-05-13T03:19:01Z,2020-05-13T15:34:55Z,,,,,,,
8491,I am facing the same error while doing transfer learning on retinenet,"<!--
Please make sure that this is a bug. 

As per our GitHub Policy (https://github.com/tensorflow/models/blob/master/ISSUES.md), we only address code bugs, documentation issues, and feature requests on GitHub.

Please go to Stack Overflow (http://stackoverflow.com/questions/tagged/tensorflow-model-garden) for help and support.

The research models (https://github.com/tensorflow/models/tree/master/research) are a large collection of models implemented in TensorFlow by researchers. They are not officially supported. It is up to the individual researchers to maintain the models and/or provide support on issues and pull requests.
-->

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g., Pixel 4, Samsung Galaxy 10) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below):
- Python version:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

<!-- 
You can collect some of this information using our environment capture (https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 

1. TensorFlow 1.0
`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 

2. TensorFlow 2.0
`python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`
-->

**Please provide the entire URL of the model you are using?**
<!-- (e.g., https://github.com/tensorflow/models/tree/master/official/nlp/bert) -->

**Describe the current behavior**

**Describe the expected behavior**

**Code to reproduce the issue**
<!-- Provide a reproducible test case that is the bare minimum necessary to generate the problem. -->

**Other info / logs**
<!-- Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. -->
",bundelesneha05,b'models:research type:bug',2020-05-11T22:00:37Z,2020-06-05T07:21:04Z,,,,,,,
8489,Updating cifar download links,"# Description

> :memo: The cifar dataset links are changed to download python version of files. Downloading binary files will throw an error with the current code
```
tensorflow.python.framework.errors_impl.NotFoundError: $DATA_DIR/cifar10/data_batch_1; No such file or directory
```

## Type of change

For a new feature or function, please create an issue first to discuss it
with us before submitting a pull request.

Note: Please delete options that are not relevant.

- [x] Bug fix (non-breaking change which fixes an issue)
- [x] Documentation update

## Tests
Tested on python2.7 and tensorflow1.15

**Test Configuration**:

## Checklist

- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).
- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).
- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).
- [x] My changes generate no new warnings.

",shekkizh,b'cla: yes stat:awaiting review',2020-05-11T17:32:23Z,2020-05-24T18:57:08Z,,,,,,,
8488,tensorflow.python.framework.errors_impl.FailedPreconditionError: 2 root error(s) found.   (0) Failed precondition:  data/training; Is a directory,"running     on tensorflow-gpu=2.2.0  

!python3 transformer_main.py --data_dir=data \
    --model_dir=model\
    --vocab_file=data/vocab.ende.32768 \
    --param_set=big \
    --train_steps=100000 \
    --steps_between_evals=5000\
    --batch_size=4096 --max_length=64 \
    --bleu_source=data/newstest2014.en \
    --bleu_ref=data/newstest2014.de \
    --num_gpus=2 \
    --enable_time_history=false



the following error occors

INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')
I0511 16:00:08.782238 140326923654976 mirrored_strategy.py:341] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')
I0511 16:00:08.783418 140326923654976 transformer_main.py:186] Running transformer with num_gpus = 2
I0511 16:00:08.784826 140326923654976 transformer_main.py:190] For training, using distribution strategy: <tensorflow.python.distribute.mirrored_strategy.MirroredStrategy object at 0x7fa0207a48d0>
Model: ""model""

Total params: 210,804,736
Trainable params: 210,804,736
Non-trainable params: 0
__________________________________________________________________________________________________
I0511 16:00:16.170870 140326923654976 transformer_main.py:312] Start train iteration at global step:0
INFO:tensorflow:batch_all_reduce: 185 all-reduces with algorithm = nccl, num_packs = 1
I0511 16:00:23.557520 140326923654976 cross_device_ops.py:697] batch_all_reduce: 185 all-reduces with algorithm = nccl, num_packs = 1
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
I0511 16:00:26.764555 140326923654976 cross_device_ops.py:439] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
I0511 16:00:26.767467 140326923654976 cross_device_ops.py:439] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:batch_all_reduce: 185 all-reduces with algorithm = nccl, num_packs = 1
I0511 16:00:36.671541 140326923654976 cross_device_ops.py:697] batch_all_reduce: 185 all-reduces with algorithm = nccl, num_packs = 1
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
I0511 16:00:38.748556 140326923654976 cross_device_ops.py:439] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
I0511 16:00:38.750910 140326923654976 cross_device_ops.py:439] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
Traceback (most recent call last):
  File ""transformer_main.py"", line 509, in <module>
    app.run(main)
  File ""/home/dell/anaconda3/envs/tf2.2/lib/python3.6/site-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/home/dell/anaconda3/envs/tf2.2/lib/python3.6/site-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""transformer_main.py"", line 497, in main
    task.train()
  File ""transformer_main.py"", line 364, in train
    verbose=(2 if flags_obj.enable_time_history else 1))
  File ""/home/dell/anaconda3/envs/tf2.2/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py"", line 72, in _method_wrapper
    return method(self, *args, **kwargs)
  File ""/home/dell/anaconda3/envs/tf2.2/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py"", line 907, in fit
    tmp_logs = train_function(iterator)
  File ""/home/dell/anaconda3/envs/tf2.2/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py"", line 766, in __call__
    result = self._call(*args, **kwds)
  File ""/home/dell/anaconda3/envs/tf2.2/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py"", line 826, in _call
    return self._stateless_fn(*args, **kwds)
  File ""/home/dell/anaconda3/envs/tf2.2/lib/python3.6/site-packages/tensorflow/python/eager/function.py"", line 2812, in __call__
    return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access
  File ""/home/dell/anaconda3/envs/tf2.2/lib/python3.6/site-packages/tensorflow/python/eager/function.py"", line 1838, in _filtered_call
    cancellation_manager=cancellation_manager)
  File ""/home/dell/anaconda3/envs/tf2.2/lib/python3.6/site-packages/tensorflow/python/eager/function.py"", line 1915, in _call_flat
    ctx, args, cancellation_manager=cancellation_manager))
  File ""/home/dell/anaconda3/envs/tf2.2/lib/python3.6/site-packages/tensorflow/python/eager/function.py"", line 549, in call
    ctx=ctx)
  File ""/home/dell/anaconda3/envs/tf2.2/lib/python3.6/site-packages/tensorflow/python/eager/execute.py"", line 60, in quick_execute
    inputs, attrs, num_outputs)
tensorflow.python.framework.errors_impl.FailedPreconditionError: 2 root error(s) found.
  (0) Failed precondition:  data/training; Is a directory
	 [[{{node MultiDeviceIteratorGetNextFromShard}}]]
	 [[RemoteCall]]
	 [[IteratorGetNextAsOptional_1]]
  (1) Cancelled:  Function was cancelled before it was started
0 successful operations.
1 derived errors ignored. [Op:__inference_train_function_45467]

Function call stack:
train_function -> train_function",paulrich1234,b'models:official type:bug',2020-05-11T08:03:48Z,2020-05-11T08:28:36Z,,,,,,,
8485,ERROR:root:Internal Python error in the inspect module.,"<!--
As per our GitHub Policy (https://github.com/tensorflow/models/blob/master/ISSUES.md), we only address code bugs, documentation issues, and feature requests on GitHub.

We will automatically close questions and help related issues.

Please go to Stack Overflow (http://stackoverflow.com/questions/tagged/tensorflow-model-garden) for questions and help.

-->
ERROR:root:Internal Python error in the inspect module.
Below is the traceback from this internal error.

ERROR:root:Internal Python error in the inspect module.
Below is the traceback from this internal error.

Traceback (most recent call last):
  File ""C:\Users\nagar\anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\nagar\anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\nagar\anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\nagar\anaconda3\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\nagar\anaconda3\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: The specified module could not be found.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Users\nagar\anaconda3\lib\site-packages\IPython\core\interactiveshell.py"", line 3331, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File ""<ipython-input-2-ad3603cda5c0>"", line 1, in <module>
    import tensorflow as tf
  File ""C:\Users\nagar\anaconda3\lib\site-packages\tensorflow\__init__.py"", line 101, in <module>
    from tensorflow_core import *
  File ""C:\Users\nagar\anaconda3\lib\site-packages\tensorflow_core\__init__.py"", line 40, in <module>
    from tensorflow.python.tools import module_util as _module_util
  File ""C:\Users\nagar\anaconda3\lib\site-packages\tensorflow\__init__.py"", line 50, in __getattr__
    module = self._load()
  File ""C:\Users\nagar\anaconda3\lib\site-packages\tensorflow\__init__.py"", line 44, in _load
    module = _importlib.import_module(self.__name__)
  File ""C:\Users\nagar\anaconda3\lib\importlib\__init__.py"", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""C:\Users\nagar\anaconda3\lib\site-packages\tensorflow_core\python\__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""C:\Users\nagar\anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 74, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""C:\Users\nagar\anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\nagar\anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\nagar\anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\nagar\anaconda3\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\nagar\anaconda3\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: The specified module could not be found.


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/errors

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Users\nagar\anaconda3\lib\site-packages\IPython\core\interactiveshell.py"", line 2044, in showtraceback
    stb = value._render_traceback_()
AttributeError: 'ImportError' object has no attribute '_render_traceback_'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Users\nagar\anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\nagar\anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\nagar\anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\nagar\anaconda3\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\nagar\anaconda3\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: The specified module could not be found.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Users\nagar\anaconda3\lib\site-packages\IPython\core\ultratb.py"", line 1151, in get_records
    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)
  File ""C:\Users\nagar\anaconda3\lib\site-packages\IPython\core\ultratb.py"", line 319, in wrapped
    return f(*args, **kwargs)
  File ""C:\Users\nagar\anaconda3\lib\site-packages\IPython\core\ultratb.py"", line 353, in _fixed_getinnerframes
    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))
  File ""C:\Users\nagar\anaconda3\lib\inspect.py"", line 1502, in getinnerframes
    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)
  File ""C:\Users\nagar\anaconda3\lib\inspect.py"", line 1460, in getframeinfo
    filename = getsourcefile(frame) or getfile(frame)
  File ""C:\Users\nagar\anaconda3\lib\inspect.py"", line 696, in getsourcefile
    if getattr(getmodule(object, filename), '__loader__', None) is not None:
  File ""C:\Users\nagar\anaconda3\lib\inspect.py"", line 733, in getmodule
    if ismodule(module) and hasattr(module, '__file__'):
  File ""C:\Users\nagar\anaconda3\lib\site-packages\tensorflow\__init__.py"", line 50, in __getattr__
    module = self._load()
  File ""C:\Users\nagar\anaconda3\lib\site-packages\tensorflow\__init__.py"", line 44, in _load
    module = _importlib.import_module(self.__name__)
  File ""C:\Users\nagar\anaconda3\lib\importlib\__init__.py"", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""<frozen importlib._bootstrap>"", line 1006, in _gcd_import
  File ""<frozen importlib._bootstrap>"", line 983, in _find_and_load
  File ""<frozen importlib._bootstrap>"", line 953, in _find_and_load_unlocked
  File ""<frozen importlib._bootstrap>"", line 219, in _call_with_frames_removed
  File ""<frozen importlib._bootstrap>"", line 1006, in _gcd_import
  File ""<frozen importlib._bootstrap>"", line 983, in _find_and_load
  File ""<frozen importlib._bootstrap>"", line 967, in _find_and_load_unlocked
  File ""<frozen importlib._bootstrap>"", line 677, in _load_unlocked
  File ""<frozen importlib._bootstrap_external>"", line 728, in exec_module
  File ""<frozen importlib._bootstrap>"", line 219, in _call_with_frames_removed
  File ""C:\Users\nagar\anaconda3\lib\site-packages\tensorflow_core\__init__.py"", line 42, in <module>
    from . _api.v2 import audio
  File ""C:\Users\nagar\anaconda3\lib\site-packages\tensorflow_core\_api\v2\audio\__init__.py"", line 10, in <module>
    from tensorflow.python.ops.gen_audio_ops import decode_wav
  File ""C:\Users\nagar\anaconda3\lib\site-packages\tensorflow_core\python\ops\gen_audio_ops.py"", line 9, in <module>
    from tensorflow.python import pywrap_tensorflow as _pywrap_tensorflow
  File ""C:\Users\nagar\anaconda3\lib\site-packages\tensorflow\__init__.py"", line 50, in __getattr__
    module = self._load()
  File ""C:\Users\nagar\anaconda3\lib\site-packages\tensorflow\__init__.py"", line 44, in _load
    module = _importlib.import_module(self.__name__)
  File ""C:\Users\nagar\anaconda3\lib\importlib\__init__.py"", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""C:\Users\nagar\anaconda3\lib\site-packages\tensorflow_core\python\__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""C:\Users\nagar\anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 74, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""C:\Users\nagar\anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\nagar\anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\nagar\anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\nagar\anaconda3\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\nagar\anaconda3\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: The specified module could not be found.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Users\nagar\anaconda3\lib\site-packages\IPython\core\interactiveshell.py"", line 3331, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File ""<ipython-input-2-ad3603cda5c0>"", line 1, in <module>
    import tensorflow as tf
  File ""C:\Users\nagar\anaconda3\lib\site-packages\tensorflow\__init__.py"", line 101, in <module>
    from tensorflow_core import *
  File ""C:\Users\nagar\anaconda3\lib\site-packages\tensorflow_core\__init__.py"", line 40, in <module>
    from tensorflow.python.tools import module_util as _module_util
  File ""C:\Users\nagar\anaconda3\lib\site-packages\tensorflow\__init__.py"", line 50, in __getattr__
    module = self._load()
  File ""C:\Users\nagar\anaconda3\lib\site-packages\tensorflow\__init__.py"", line 44, in _load
    module = _importlib.import_module(self.__name__)
  File ""C:\Users\nagar\anaconda3\lib\importlib\__init__.py"", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""C:\Users\nagar\anaconda3\lib\site-packages\tensorflow_core\python\__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""C:\Users\nagar\anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 74, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""C:\Users\nagar\anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\nagar\anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\nagar\anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\nagar\anaconda3\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\nagar\anaconda3\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: The specified module could not be found.


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/errors

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Users\nagar\anaconda3\lib\site-packages\IPython\core\interactiveshell.py"", line 2044, in showtraceback
    stb = value._render_traceback_()
AttributeError: 'ImportError' object has no attribute '_render_traceback_'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Users\nagar\anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\nagar\anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\nagar\anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\nagar\anaconda3\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\nagar\anaconda3\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: The specified module could not be found.


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/errors

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.
Traceback (most recent call last):
  File ""C:\Users\nagar\anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\nagar\anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\nagar\anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\nagar\anaconda3\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\nagar\anaconda3\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: The specified module could not be found.

",Nagarjuna05,b'type:support',2020-05-09T12:30:10Z,2020-07-02T09:44:24Z,,,,,,,
8484,Open source MnasFPN,"310447280  by lzc:

    Internal change

310420845  by Zhichao Lu:

    Open source the internal Context RCNN code.

--
310362339  by Zhichao Lu:

    Internal change

310259448  by lzc:

    Update required TF version for OD API.

--
310252159  by Zhichao Lu:

    Port patch_ops_test to TF1/TF2 as TPUs.

--
310247180  by Zhichao Lu:

    Ignore keypoint heatmap loss in the regions/bounding boxes with target keypoint
    class but no valid keypoint annotations.

--
310178294  by Zhichao Lu:

    Opensource MnasFPN
    https://arxiv.org/abs/1912.01106

--
310094222  by lzc:

    Internal changes.

--
310085250  by lzc:

    Internal Change.

--
310016447  by huizhongc:

    Remove unrecognized classes from labeled_classes.

--
310009470  by rathodv:

    Mark batcher.py as TF1 only.

--
310001984  by rathodv:

    Update core/preprocessor.py to be compatible with TF1/TF2..

--
309455035  by Zhichao Lu:

    Makes the freezable_batch_norm_test run w/ v2 behavior.

    The main change is in v2 updates will happen right away when running batchnorm in training mode. So, we need to restore the weights between batchnorm calls to make sure the numerical checks all start from the same place.

--
309425881  by Zhichao Lu:

    Make TF1/TF2 optimizer builder tests explicit.

--
309408646  by Zhichao Lu:

    Make dataset builder tests TF1 and TF2 compatible.

--
309246305  by Zhichao Lu:

    Added the functionality of combining the person keypoints and object detection
    annotations in the binary that converts the COCO raw data to TfRecord.

--
309125076  by Zhichao Lu:

    Convert target_assigner_utils to TF1/TF2.

--
308966359  by huizhongc:

    Support SSD training with partially labeled groundtruth.

--
308937159  by rathodv:

    Update core/target_assigner.py to be compatible with TF1/TF2.

--
308774302  by Zhichao Lu:

    Internal

--
308732860  by rathodv:

    Make core/prefetcher.py  compatible with TF1 only.

--
308726984  by rathodv:

    Update core/multiclass_nms_test.py to be TF1/TF2 compatible.

--
308714718  by rathodv:

    Update core/region_similarity_calculator_test.py to be TF1/TF2 compatible.

--
308707960  by rathodv:

    Update core/minibatch_sampler_test.py to be TF1/TF2 compatible.

--
308700595  by rathodv:

    Update core/losses_test.py to be TF1/TF2 compatible and remove losses_test_v2.py

--
308361472  by rathodv:

    Update core/matcher_test.py to be TF1/TF2 compatible.

--
308335846  by Zhichao Lu:

    Updated the COCO evaluation logics and populated the groundturth area
    information through. This change matches the groundtruth format expected by the
    COCO keypoint evaluation.

--
308256924  by rathodv:

    Update core/keypoints_ops_test.py to be TF1/TF2 compatible.

--
308256826  by rathodv:

    Update class_agnostic_nms_test.py to be TF1/TF2 compatible.

--
308256112  by rathodv:

    Update box_list_ops_test.py to be TF1/TF2 compatible.

--
308159360  by Zhichao Lu:

    Internal change

308145008  by Zhichao Lu:

    Added 'image/class/confidence' field in the TFExample decoder.

--
307651875  by rathodv:

    Refactor core/box_list.py to support TF1/TF2.

--
307651798  by rathodv:

    Modify box_coder.py base class to work with with TF1/TF2

--
307651652  by rathodv:

    Refactor core/balanced_positive_negative_sampler.py to support TF1/TF2.

--
307651571  by rathodv:

    Modify BoxCoders tests to use test_case:execute method to allow testing with TF1.X and TF2.X

--
307651480  by rathodv:

    Modify Matcher tests to use test_case:execute method to allow testing with TF1.X and TF2.X

--
307651409  by rathodv:

    Modify AnchorGenerator tests to use test_case:execute method to allow testing with TF1.X and TF2.X

--
307651314  by rathodv:

    Refactor model_builder to support TF1 or TF2 models based on TensorFlow version.

--
307092053  by Zhichao Lu:

    Use manager to save checkpoint.

--
307071352  by ronnyvotel:

    Fixing keypoint visibilities. Now by default, the visibility is marked True if the keypoint is labeled (regardless of whether it is visible or not).
    Also, if visibilities are not present in the dataset, they will be created based on whether the keypoint coordinates are finite (vis = True) or NaN (vis = False).

--
307069557  by Zhichao Lu:

    Internal change to add few fields related to postprocessing parameters in
    center_net.proto and populate those parameters to the keypoint postprocessing
    functions.

--
307012091  by Zhichao Lu:

    Make Adam Optimizer's epsilon proto configurable.

    Potential issue: tf.compat.v1's AdamOptimizer has a default epsilon on 1e-08 ([doc-link](https://www.tensorflow.org/api_docs/python/tf/compat/v1/train/AdamOptimizer))  whereas tf.keras's AdamOptimizer has default epsilon 1e-07 ([doc-link](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam))

--
306858598  by Zhichao Lu:

    Internal changes to update the CenterNet model:
    1) Modified eval job loss computation to avoid averaging over batches with zero loss.
    2) Updated CenterNet keypoint heatmap target assigner to apply box size to heatmap Guassian standard deviation.
    3) Updated the CenterNet meta arch keypoint losses computation to apply weights outside of loss function.

--
306731223  by jonathanhuang:

    Internal change.

--
306549183  by rathodv:

    Internal Update.

--
306542930  by rathodv:

    Internal Update

--
306322697  by rathodv:

    Internal.

--
305345036  by Zhichao Lu:

    Adding COCO Camera Traps Json to tf.Example beam code

--
304104869  by lzc:

    Internal changes.

--
304068971  by jonathanhuang:

    Internal change.

--
304050469  by Zhichao Lu:

    Internal change.

--
303880642  by huizhongc:

    Support parsing partially labeled groundtruth.

--
303841743  by Zhichao Lu:

    Deprecate nms_on_host in SSDMetaArch.

--
303803204  by rathodv:

    Internal change.

--
303793895  by jonathanhuang:

    Internal change.

--
303467631  by rathodv:

    Py3 update for detection inference test.

--
303444542  by rathodv:

    Py3 update to metrics module

--
303421960  by rathodv:

    Update json_utils to python3.

--
302787583  by ronnyvotel:

    Coco results generator for submission to the coco test server.

--
302719091  by Zhichao Lu:

    Internal change to add the ResNet50 image feature extractor for CenterNet model.

--
302116230  by Zhichao Lu:

    Added the functions to overlay the heatmaps with images in visualization util
    library.

--
301888316  by Zhichao Lu:

    Fix checkpoint_filepath not defined error.

--
301840312  by ronnyvotel:

    Adding keypoint_scores to visualizations.

--
301683475  by ronnyvotel:

    Introducing the ability to preprocess `keypoint_visibilities`.

    Some data augmentation ops such as random crop can filter instances and keypoints. It's important to also filter keypoint visibilities, so that the groundtruth tensors are always in alignment.

--
301532344  by Zhichao Lu:

    Don't use tf.divide since ""Quantization not yet supported for op: DIV""

--
301480348  by ronnyvotel:

    Introducing keypoint evaluation into model lib v2.
    Also, making some fixes to coco keypoint evaluation.

--
301454018  by Zhichao Lu:

    Added the image summary to visualize the train/eval input images and eval's
    prediction/groundtruth side-by-side image.

--
301317527  by Zhichao Lu:

    Updated the random_absolute_pad_image function in the preprocessor library to
    support the keypoints argument.

--
301300324  by Zhichao Lu:

    Apply name change(experimental_run_v2 -> run) for all callers in Tensorflow.

--
301297115  by ronnyvotel:

    Utility function for setting keypoint visibilities based on keypoint coordinates.

--
301248885  by Zhichao Lu:

    Allow MultiworkerMirroredStrategy(MWMS) use by adding checkpoint handling with temporary directories in model_lib_v2. Added missing WeakKeyDictionary cfer_fn_cache field in CollectiveAllReduceStrategyExtended.

--
301224559  by Zhichao Lu:

    ...1) Fixes model_lib to also use keypoints while preparing model groundtruth.
    ...2) Tests model_lib with newly added keypoint metrics config.

--
300836556  by Zhichao Lu:

    Internal changes to add keypoint estimation parameters in CenterNet proto.

--
300795208  by Zhichao Lu:

    Updated the eval_util library to populate the keypoint groundtruth to
    eval_dict.

--
299474766  by Zhichao Lu:

    ...Modifies eval_util to create Keypoint Evaluator objects when configured in eval config.

--
299453920  by Zhichao Lu:

    Add swish activation as a hyperperams option.

--
299240093  by ronnyvotel:

    Keypoint postprocessing for CenterNetMetaArch.

--
299176395  by Zhichao Lu:

    Internal change.

--
299135608  by Zhichao Lu:

    Internal changes to refactor the CenterNet model in preparation for keypoint estimation tasks.

--
298915482  by Zhichao Lu:

    Make dataset_builder aware of input_context for distributed training.

--
298713595  by Zhichao Lu:

    Handling data with negative size boxes.

--
298695964  by Zhichao Lu:

    Expose change_coordinate_frame as a config parameter; fix multiclass_scores optional field.

--
298492150  by Zhichao Lu:

    Rename optimizer_builder_test_v2.py -> optimizer_builder_v2_test.py

--
298476471  by Zhichao Lu:

    Internal changes to support CenterNet keypoint estimation.

--
298365851  by ronnyvotel:

    Fixing a bug where groundtruth_keypoint_weights were being padded with a dynamic dimension.

--
297843700  by Zhichao Lu:

    Internal change.

--
297706988  by lzc:

    Internal change.

--
297705287  by ronnyvotel:

    Creating the ""snapping"" behavior in CenterNet, where regressed keypoints are refined with updated candidate keypoints from a heatmap.

--
297700447  by Zhichao Lu:

    Improve checkpoint checking logic with TF2 loop.

--
297686094  by Zhichao Lu:

    Convert ""import tensorflow as tf"" to ""import tensorflow.compat.v1"".

--
297670468  by lzc:

    Internal change.

--
297241327  by Zhichao Lu:

    Convert ""import tensorflow as tf"" to ""import tensorflow.compat.v1"".

--
297205959  by Zhichao Lu:

    Internal changes to support refactored the centernet object detection target assigner into a separate library.

--
297143806  by Zhichao Lu:

    Convert ""import tensorflow as tf"" to ""import tensorflow.compat.v1"".

--
297129625  by Zhichao Lu:

    Explicitly replace ""import tensorflow"" with ""tensorflow.compat.v1"" for TF2.x migration

--
297117070  by Zhichao Lu:

    Explicitly replace ""import tensorflow"" with ""tensorflow.compat.v1"" for TF2.x migration

--
297030190  by Zhichao Lu:

    Add configuration options for visualizing keypoint edges

--
296359649  by Zhichao Lu:

    Support DepthwiseConv2dNative (of separable conv) in weight equalization loss.

--
296290582  by Zhichao Lu:

    Internal change.

--
296093857  by Zhichao Lu:

    Internal changes to add general target assigner utilities.

--
295975116  by Zhichao Lu:

    Fix visualize_boxes_and_labels_on_image_array to show max_boxes_to_draw correctly.

--
295819711  by Zhichao Lu:

    Adds a flag to visualize_boxes_and_labels_on_image_array to skip the drawing of axis aligned bounding boxes.

--
295811929  by Zhichao Lu:

    Keypoint support in random_square_crop_by_scale.

--
295788458  by rathodv:

    Remove unused checkpoint to reduce repo size on github

--
295787184  by Zhichao Lu:

    Enable visualization of edges between keypoints

--
295763508  by Zhichao Lu:

    [Context RCNN] Add an option to enable / disable cropping feature in the post
    process step in the meta archtecture.

--
295605344  by Zhichao Lu:

    internal change.

--
294926050  by ronnyvotel:

    Adding per-keypoint groundtruth weights. These weights are intended to be used as multipliers in a keypoint loss function.

    Groundtruth keypoint weights are constructed as follows:
    - Initialize the weight for each keypoint type based on user-specified weights in the input_reader proto
    - Mask out (i.e. make zero) all keypoint weights that are not visible.

--
294829061  by lzc:

    Internal change.

--
294566503  by Zhichao Lu:

    Changed internal CenterNet Model configuration.

--
294346662  by ronnyvotel:

    Using NaN values in keypoint coordinates that are not visible.

--
294333339  by Zhichao Lu:

    Change experimetna_distribute_dataset -> experimental_distribute_dataset_from_function

--
293928752  by Zhichao Lu:

    Internal change

--
293909384  by Zhichao Lu:

    Add capabilities to train 1024x1024 CenterNet models.

--
293637554  by ronnyvotel:

    Adding keypoint visibilities to TfExampleDecoder.

--
293501558  by lzc:

    Internal change.

--
293252851  by Zhichao Lu:

    Change tf.gfile.GFile to tf.io.gfile.GFile.

--
292730217  by Zhichao Lu:

    Internal change.

--
292456563  by lzc:

    Internal changes.

--
292355612  by Zhichao Lu:

    Use tf.gather and tf.scatter_nd instead of matrix ops.

--
292245265  by rathodv:

    Internal

--
291989323  by richardmunoz:

    Refactor out building a DataDecoder from building a tf.data.Dataset.

--
291950147  by Zhichao Lu:

    Flip bounding boxes in arbitrary shaped tensors.

--
291401052  by huizhongc:

    Fix multiscale grid anchor generator to allow fully convolutional inference. When exporting model with identity_resizer as image_resizer, there is an incorrect box offset on the detection results. We add the anchor offset to address this problem.

--
291298871  by Zhichao Lu:

    Py3 compatibility changes.

--
290957957  by Zhichao Lu:

    Hourglass feature extractor for CenterNet.

--
290564372  by Zhichao Lu:

    Internal change.

--
290155278  by rathodv:

    Remove Dataset Explorer.

--
290155153  by Zhichao Lu:

    Internal change

--
290122054  by Zhichao Lu:

    Unify the format in the faster_rcnn.proto

--
290116084  by Zhichao Lu:

    Deprecate tensorflow.contrib.

--
290100672  by Zhichao Lu:

    Update MobilenetV3 SSD candidates

--
289926392  by Zhichao Lu:

    Internal change

--
289553440  by Zhichao Lu:

    [Object Detection API] Fix the comments about the dimension of the rpn_box_encodings from 4-D to 3-D.

--
288994128  by lzc:

    Internal changes.

--
288942194  by lzc:

    Internal change.

--
288746124  by Zhichao Lu:

    Configurable channel mean/std. dev in CenterNet feature extractors.

--
288552509  by rathodv:

    Internal.

--
288541285  by rathodv:

    Internal update.

--
288396396  by Zhichao Lu:

    Make object detection import contrib explicitly

--
288255791  by rathodv:

    Internal

--
288078600  by Zhichao Lu:

    Fix model_lib_v2 test

--
287952244  by rathodv:

    Internal

--
287921774  by Zhichao Lu:

    internal change

--
287906173  by Zhichao Lu:

    internal change

--
287889407  by jonathanhuang:

    PY3 compatibility

--
287889042  by rathodv:

    Internal

--
287876178  by Zhichao Lu:

    Internal change.

--
287770490  by Zhichao Lu:

    Add CenterNet proto and builder

--
287694213  by Zhichao Lu:

    Support for running multiple steps per tf.function call.

--
287377183  by jonathanhuang:

    PY3 compatibility

--
287371344  by rathodv:

    Support loading keypoint labels and ids.

--
287368213  by rathodv:

    Add protos supporting keypoint evaluation.

--
286673200  by rathodv:

    dataset_tools PY3 migration

--
286635106  by Zhichao Lu:

    Update code for upcoming tf.contrib removal

--
286479439  by Zhichao Lu:

    Internal change

--
286311711  by Zhichao Lu:

    Skeleton of context model within TFODAPI

--
286005546  by Zhichao Lu:

    Fix Faster-RCNN training when using keep_aspect_ratio_resizer with pad_to_max_dimension

--
285906400  by derekjchow:

    Internal change

--
285822795  by Zhichao Lu:

    Add CenterNet meta arch target assigners.

--
285447238  by Zhichao Lu:

    Internal changes.

--
285016927  by Zhichao Lu:

    Make _dummy_computation a tf.function. This fixes breakage caused by
    cl/284256438

--
284827274  by Zhichao Lu:

    Convert to python 3.

--
284645593  by rathodv:

    Internal change

--
284639893  by rathodv:

    Add missing documentation for keypoints in eval_util.py.

--
284323712  by Zhichao Lu:

    Internal changes.

--
284295290  by Zhichao Lu:

    Updating input config proto and dataset builder to include context fields

    Updating standard_fields and tf_example_decoder to include context features

--
284226821  by derekjchow:

    Update exporter.

--
284211030  by Zhichao Lu:

    API changes in CenterNet informed by the experiments with hourlgass network.

--
284190451  by Zhichao Lu:

    Add support for CenterNet losses in protos and builders.

--
284093961  by lzc:

    Internal changes.

--
284028174  by Zhichao Lu:

    Internal change

--
284014719  by derekjchow:

    Do not pad top_down feature maps unnecessarily.

--
284005765  by Zhichao Lu:

    Add new pad_to_multiple_resizer

--
283858233  by Zhichao Lu:

    Make target assigner work when under tf.function.

--
283836611  by Zhichao Lu:

    Make config getters more general.

--
283808990  by Zhichao Lu:

    Internal change

--
283754588  by Zhichao Lu:

    Internal changes.

--
282460301  by Zhichao Lu:

    Add ability to restore v2 style checkpoints.

--
281605842  by lzc:

    Add option to disable loss computation in OD API eval job.

--
280298212  by Zhichao Lu:

    Add backwards compatible change

--
280237857  by Zhichao Lu:

    internal change

--

PiperOrigin-RevId: 310447280

# Description

> :memo: Please include a summary of the change. 
>  
> * Please also include relevant motivation and context.  
> * List any dependencies that are required for this change.  

## Type of change

For a new feature or function, please create an issue first to discuss it
with us before submitting a pull request.

Note: Please delete options that are not relevant.

- [ ] Bug fix (non-breaking change which fixes an issue)
- [ ] Documentation update
- [ ] TensorFlow 2 migration
- [ ] New feature (non-breaking change which adds functionality)
- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)
- [ ] A new research paper code implementation
- [x] Other (Specify)

## Tests

> :memo: Please describe the tests that you ran to verify your changes.
>  
> * Provide instructions so we can reproduce.  
> * Please also list any relevant details for your test configuration.  

**Test Configuration**:

## Checklist

- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).
- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).
- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).
- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.
- [x] I have commented my code, particularly in hard-to-understand areas.
- [x] I have made corresponding changes to the documentation.
- [x] My changes generate no new warnings.
- [x] I have added tests that prove my fix is effective or that my feature works.
",pkulzc,b'cla: yes stat:awaiting review',2020-05-09T04:46:58Z,2020-05-12T18:41:08Z,,,,,,,
8483,Small update to DELF training README.,"# Description

> :memo: Please include a summary of the change. 
>  Small update to DELF training README.
> * Please also include relevant motivation and context.  
> * List any dependencies that are required for this change.  

## Type of change

For a new feature or function, please create an issue first to discuss it
with us before submitting a pull request.

Note: Please delete options that are not relevant.

- [ ] Bug fix (non-breaking change which fixes an issue)
- [ X] Documentation update
- [ ] TensorFlow 2 migration
- [ ] New feature (non-breaking change which adds functionality)
- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)
- [ ] A new research paper code implementation
- [ ] Other (Specify)

## Tests

> :memo: Please describe the tests that you ran to verify your changes.
>  
> * Provide instructions so we can reproduce.  
> * Please also list any relevant details for your test configuration.  

**Test Configuration**:

## Checklist

- [ ] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).
- [ ] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).
- [ ] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).
- [ ] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.
- [ ] I have commented my code, particularly in hard-to-understand areas.
- [ ] I have made corresponding changes to the documentation.
- [ ] My changes generate no new warnings.
- [ ] I have added tests that prove my fix is effective or that my feature works.
",andrefaraujo,b'cla: yes',2020-05-08T21:30:36Z,2020-05-08T21:39:51Z,,,,,,,
8482,Inference using attention ocr model,"<!--
Please make sure that this is a feature request. 

As per our GitHub Policy (https://github.com/tensorflow/models/blob/master/ISSUES.md), we only address code bugs, documentation issues, and feature requests on GitHub.

Please go to Stack Overflow (http://stackoverflow.com/questions/tagged/tensorflow-model-garden) for help and support.

The research models (https://github.com/tensorflow/models/tree/master/research) are a large collection of models implemented in TensorFlow by researchers. They are not officially supported. It is up to the individual researchers to maintain the models and/or provide support on issues and pull requests.
-->

**Please provide the entire URL of the model you are using?** 
<!-- (e.g., https://github.com/tensorflow/models/tree/master/official/nlp/bert) --> https://github.com/tensorflow/models/tree/master/research/attention_ocr

**Describe the feature you request and the current behavior/state.** how can one save the frozen model using the checkpoint files and make predictions using the frozen model...? Also, particularly for attention OCR, how can one find the names of input and output tensors?

**Are you willing to contribute it (Yes/No)?** Yes

**Any other info.**
",Guneetkaur03,b'models:research type:feature',2020-05-08T12:38:29Z,2020-07-06T19:39:42Z,,,,,,,
8480,Opensource MnasFPN in Object Detection API,"310362339  by Zhichao Lu:

    Internal change

310259448  by lzc:

    Update required TF version for OD API.

--
310252159  by Zhichao Lu:

    Port patch_ops_test to TF1/TF2 as TPUs.

--
310247180  by Zhichao Lu:

    Ignore keypoint heatmap loss in the regions/bounding boxes with target keypoint
    class but no valid keypoint annotations.

--
310178294  by Zhichao Lu:

    Opensource MnasFPN
    https://arxiv.org/abs/1912.01106

--
310094222  by lzc:

    Internal changes.

--
310085250  by lzc:

    Internal Change.

--
310016447  by huizhongc:

    Remove unrecognized classes from labeled_classes.

--
310009470  by rathodv:

    Mark batcher.py as TF1 only.

--
310001984  by rathodv:

    Update core/preprocessor.py to be compatible with TF1/TF2..

--
309455035  by Zhichao Lu:

    Makes the freezable_batch_norm_test run w/ v2 behavior.

    The main change is in v2 updates will happen right away when running batchnorm in training mode. So, we need to restore the weights between batchnorm calls to make sure the numerical checks all start from the same place.

--
309425881  by Zhichao Lu:

    Make TF1/TF2 optimizer builder tests explicit.

--
309408646  by Zhichao Lu:

    Make dataset builder tests TF1 and TF2 compatible.

--
309246305  by Zhichao Lu:

    Added the functionality of combining the person keypoints and object detection
    annotations in the binary that converts the COCO raw data to TfRecord.

--
309125076  by Zhichao Lu:

    Convert target_assigner_utils to TF1/TF2.

--
308966359  by huizhongc:

    Support SSD training with partially labeled groundtruth.

--
308937159  by rathodv:

    Update core/target_assigner.py to be compatible with TF1/TF2.

--
308774302  by Zhichao Lu:

    Internal

--
308732860  by rathodv:

    Make core/prefetcher.py  compatible with TF1 only.

--
308726984  by rathodv:

    Update core/multiclass_nms_test.py to be TF1/TF2 compatible.

--
308714718  by rathodv:

    Update core/region_similarity_calculator_test.py to be TF1/TF2 compatible.

--
308707960  by rathodv:

    Update core/minibatch_sampler_test.py to be TF1/TF2 compatible.

--
308700595  by rathodv:

    Update core/losses_test.py to be TF1/TF2 compatible and remove losses_test_v2.py

--
308361472  by rathodv:

    Update core/matcher_test.py to be TF1/TF2 compatible.

--
308335846  by Zhichao Lu:

    Updated the COCO evaluation logics and populated the groundturth area
    information through. This change matches the groundtruth format expected by the
    COCO keypoint evaluation.

--
308330634  by Zhichao Lu:

    Support float input/output in exporter.

--
308256924  by rathodv:

    Update core/keypoints_ops_test.py to be TF1/TF2 compatible.

--
308256826  by rathodv:

    Update class_agnostic_nms_test.py to be TF1/TF2 compatible.

--
308256112  by rathodv:

    Update box_list_ops_test.py to be TF1/TF2 compatible.

--
308159360  by Zhichao Lu:

    Internal change

308145008  by Zhichao Lu:

    Added 'image/class/confidence' field in the TFExample decoder.

--
307651875  by rathodv:

    Refactor core/box_list.py to support TF1/TF2.

--
307651798  by rathodv:

    Modify box_coder.py base class to work with with TF1/TF2

--
307651652  by rathodv:

    Refactor core/balanced_positive_negative_sampler.py to support TF1/TF2.

--
307651571  by rathodv:

    Modify BoxCoders tests to use test_case:execute method to allow testing with TF1.X and TF2.X

--
307651480  by rathodv:

    Modify Matcher tests to use test_case:execute method to allow testing with TF1.X and TF2.X

--
307651409  by rathodv:

    Modify AnchorGenerator tests to use test_case:execute method to allow testing with TF1.X and TF2.X

--
307651314  by rathodv:

    Refactor model_builder to support TF1 or TF2 models based on TensorFlow version.

--
307092053  by Zhichao Lu:

    Use manager to save checkpoint.

--
307071352  by ronnyvotel:

    Fixing keypoint visibilities. Now by default, the visibility is marked True if the keypoint is labeled (regardless of whether it is visible or not).
    Also, if visibilities are not present in the dataset, they will be created based on whether the keypoint coordinates are finite (vis = True) or NaN (vis = False).

--
307069557  by Zhichao Lu:

    Internal change to add few fields related to postprocessing parameters in
    center_net.proto and populate those parameters to the keypoint postprocessing
    functions.

--
307012091  by Zhichao Lu:

    Make Adam Optimizer's epsilon proto configurable.

    Potential issue: tf.compat.v1's AdamOptimizer has a default epsilon on 1e-08 ([doc-link](https://www.tensorflow.org/api_docs/python/tf/compat/v1/train/AdamOptimizer))  whereas tf.keras's AdamOptimizer has default epsilon 1e-07 ([doc-link](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam))

--
306947114  by Zhichao Lu:

    Updated the refine_keypoints in CenterNetMetaArch to support different
    criterias to select the refine the keypoint location.

--
306937457  by Zhichao Lu:

    Updated the CenterNetMetaArch's
    convert_strided_predictions_to_normalized_keypoints function such that the
    caller can choose to clip the out-of-frame keypoints to image boundary instead
    of pruning them.

--
306858598  by Zhichao Lu:

    Internal changes to update the CenterNet model:
    1) Modified eval job loss computation to avoid averaging over batches with zero loss.
    2) Updated CenterNet keypoint heatmap target assigner to apply box size to heatmap Guassian standard deviation.
    3) Updated the CenterNet meta arch keypoint losses computation to apply weights outside of loss function.

--
306731223  by jonathanhuang:

    Internal change.

--
306549183  by rathodv:

    Internal Update.

--
306542930  by rathodv:

    Internal Update

--
306446355  by rathodv:

    Internal Update

--
306322697  by rathodv:

    Internal.

--
305833518  by Zhichao Lu:

    Fixed bug in top_k_feature_map_locations function to select the top k scores
    from feature_map_peak as opposed to feature_map.

--
305345036  by Zhichao Lu:

    Adding COCO Camera Traps Json to tf.Example beam code

--
304439507  by Zhichao Lu:

    Fix exporter_lib_v2 test to use different input types.

--
304104869  by lzc:

    Internal changes.

--
304068971  by jonathanhuang:

    Internal change.

--
304050469  by Zhichao Lu:

    Internal change.

--
304012139  by ronnyvotel:

    Updating centernet keypoints to output 0.0 instead of NaN, which plays nicer with other tools.

--
303880642  by huizhongc:

    Support parsing partially labeled groundtruth.

--
303841743  by Zhichao Lu:

    Deprecate nms_on_host in SSDMetaArch.

--
303803204  by rathodv:

    Internal change.

--
303793895  by jonathanhuang:

    Internal change.

--
303774233  by Zhichao Lu:

    Internal changes to update the CenterNetMetaArch functions to handle the error when the keypoint postprocessing tries to call ""scatter_nd"" with empty indices and updates with zero dimensions.

    This came out when training the object detection and keypoint tasks on full COCO dataset with object detection/keypoint annotations where some images do not contain any ""person"" annotation and no ""keypoint"" to predict.

--
303561606  by ronnyvotel:

    Updating the exported model classes output datatype to float, to agree with V1 exporter

--
303467631  by rathodv:

    Py3 update for detection inference test.

--
303444542  by rathodv:

    Py3 update to metrics module

--
303421960  by rathodv:

    Update json_utils to python3.

--
303300597  by Zhichao Lu:

    Fixed bug/crash in center net model creation.

--
302787583  by ronnyvotel:

    Coco results generator for submission to the coco test server.

--
302719091  by Zhichao Lu:

    Internal change to add the ResNet50 image feature extractor for CenterNet model.

--
302116230  by Zhichao Lu:

    Added the functions to overlay the heatmaps with images in visualization util
    library.

--
301888316  by Zhichao Lu:

    Fix checkpoint_filepath not defined error.

--
301840312  by ronnyvotel:

    Adding keypoint_scores to visualizations.

--
301683475  by ronnyvotel:

    Introducing the ability to preprocess `keypoint_visibilities`.

    Some data augmentation ops such as random crop can filter instances and keypoints. It's important to also filter keypoint visibilities, so that the groundtruth tensors are always in alignment.

--
301532344  by Zhichao Lu:

    Don't use tf.divide since ""Quantization not yet supported for op: DIV""

--
301480348  by ronnyvotel:

    Introducing keypoint evaluation into model lib v2.
    Also, making some fixes to coco keypoint evaluation.

--
301454018  by Zhichao Lu:

    Added the image summary to visualize the train/eval input images and eval's
    prediction/groundtruth side-by-side image.

--
301317527  by Zhichao Lu:

    Updated the random_absolute_pad_image function in the preprocessor library to
    support the keypoints argument.

--
301300324  by Zhichao Lu:

    Apply name change(experimental_run_v2 -> run) for all callers in Tensorflow.

--
301297115  by ronnyvotel:

    Utility function for setting keypoint visibilities based on keypoint coordinates.

--
301248885  by Zhichao Lu:

    Allow MultiworkerMirroredStrategy(MWMS) use by adding checkpoint handling with temporary directories in model_lib_v2. Added missing WeakKeyDictionary cfer_fn_cache field in CollectiveAllReduceStrategyExtended.

--
301224559  by Zhichao Lu:

    ...1) Fixes model_lib to also use keypoints while preparing model groundtruth.
    ...2) Tests model_lib with newly added keypoint metrics config.

--
300836556  by Zhichao Lu:

    Internal changes to add keypoint estimation parameters in CenterNet proto.

--
300795208  by Zhichao Lu:

    Updated the eval_util library to populate the keypoint groundtruth to
    eval_dict.

--
300113487  by Zhichao Lu:

    Internal changes to allow CenterNet model to learn keypoint estimation tasks.

--
300086313  by ronnyvotel:

    Updating _get_shape() in center_net_meta_arch.py so that integers are returned for static shapes, rather than Tensors.

--
299474766  by Zhichao Lu:

    ...Modifies eval_util to create Keypoint Evaluator objects when configured in eval config.

--
299453920  by Zhichao Lu:

    Add swish activation as a hyperperams option.

--
299240093  by ronnyvotel:

    Keypoint postprocessing for CenterNetMetaArch.

--
299176395  by Zhichao Lu:

    Internal change.

--
299135608  by Zhichao Lu:

    Internal changes to refactor the CenterNet model in preparation for keypoint estimation tasks.

--
298915482  by Zhichao Lu:

    Make dataset_builder aware of input_context for distributed training.

--
298732566  by Zhichao Lu:

    Internal changes to add util functions to support multi-task CenterNet model training.

--
298713595  by Zhichao Lu:

    Handling data with negative size boxes.

--
298710411  by ronnyvotel:

    Adding two CenterNet utility functions. These functions help construct full keypoint coordinate/score tensors, from keypoint estimates on individual classes.

--
298697053  by ronnyvotel:

    Adding a CenterNet function to convert strided keypoint predictions to normalized (input space) coordinates.

--
298695964  by Zhichao Lu:

    Expose change_coordinate_frame as a config parameter; fix multiclass_scores optional field.

--
298650858  by Zhichao Lu:

    Internal changes to add util function and parameters for CenterNet keypoint estimation

--
298492150  by Zhichao Lu:

    Rename optimizer_builder_test_v2.py -> optimizer_builder_v2_test.py

--
298476471  by Zhichao Lu:

    Internal changes to support CenterNet keypoint estimation.

--
298365851  by ronnyvotel:

    Fixing a bug where groundtruth_keypoint_weights were being padded with a dynamic dimension.

--
297843700  by Zhichao Lu:

    Internal change.

--
297706988  by lzc:

    Internal change.

--
297705287  by ronnyvotel:

    Creating the ""snapping"" behavior in CenterNet, where regressed keypoints are refined with updated candidate keypoints from a heatmap.

--
297700447  by Zhichao Lu:

    Improve checkpoint checking logic with TF2 loop.

--
297686094  by Zhichao Lu:

    Convert ""import tensorflow as tf"" to ""import tensorflow.compat.v1"".

--
297670468  by lzc:

    Internal change.

--
297241327  by Zhichao Lu:

    Convert ""import tensorflow as tf"" to ""import tensorflow.compat.v1"".

--
297205959  by Zhichao Lu:

    Internal changes to support refactored the centernet object detection target assigner into a separate library.

--
297143806  by Zhichao Lu:

    Convert ""import tensorflow as tf"" to ""import tensorflow.compat.v1"".

--
297129625  by Zhichao Lu:

    Explicitly replace ""import tensorflow"" with ""tensorflow.compat.v1"" for TF2.x migration

--
297117070  by Zhichao Lu:

    Explicitly replace ""import tensorflow"" with ""tensorflow.compat.v1"" for TF2.x migration

--
297030190  by Zhichao Lu:

    Add configuration options for visualizing keypoint edges

--
296359649  by Zhichao Lu:

    Support DepthwiseConv2dNative (of separable conv) in weight equalization loss.

--
296290582  by Zhichao Lu:

    Internal change.

--
296278526  by ronnyvotel:

    Updating regressed_keypoints_at_object_centers() in center_net_meta_arch.py so that the regressed keypoints are returned in absolute coordinates (in output coordinate frame), not relative.

--
296093857  by Zhichao Lu:

    Internal changes to add general target assigner utilities.

--
296066476  by ronnyvotel:

    In center_net_meta_arch.py, allowing the ability to return the top k feature map values **per channel**. This will be used to retrieve an equal number of candidates per keypoint type. This avoids the possibility that a disproportionate number of candidates comes from a few keypoint types.

--
295975116  by Zhichao Lu:

    Fix visualize_boxes_and_labels_on_image_array to show max_boxes_to_draw correctly.

--
295819711  by Zhichao Lu:

    Adds a flag to visualize_boxes_and_labels_on_image_array to skip the drawing of axis aligned bounding boxes.

--
295811929  by Zhichao Lu:

    Keypoint support in random_square_crop_by_scale.

--
295788458  by rathodv:

    Remove unused checkpoint to reduce repo size on github

--
295787184  by Zhichao Lu:

    Enable visualization of edges between keypoints

--
295763508  by Zhichao Lu:

    [Context RCNN] Add an option to enable / disable cropping feature in the post
    process step in the meta archtecture.

--
295605344  by Zhichao Lu:

    internal change.

--
295252797  by ronnyvotel:

    Adding a function to gather regressed keypoints at specified locations.

--
295139603  by ronnyvotel:

    This CL updates two parts of the CenterNet meta architecture:
    - refactors the peak-finding functionality, since it is useful for both box centers and keypoints.
    - adding a post-processing utility function to get the locations and scores from the keypoint heatmap and offset feature maps.

--
294926050  by ronnyvotel:

    Adding per-keypoint groundtruth weights. These weights are intended to be used as multipliers in a keypoint loss function.

    Groundtruth keypoint weights are constructed as follows:
    - Initialize the weight for each keypoint type based on user-specified weights in the input_reader proto
    - Mask out (i.e. make zero) all keypoint weights that are not visible.

--
294829061  by lzc:

    Internal change.

--
294566503  by Zhichao Lu:

    Changed internal CenterNet Model configuration.

--
294346662  by ronnyvotel:

    Using NaN values in keypoint coordinates that are not visible.

--
294333339  by Zhichao Lu:

    Change experimetna_distribute_dataset -> experimental_distribute_dataset_from_function

--
293928752  by Zhichao Lu:

    Internal change

--
293909384  by Zhichao Lu:

    Add capabilities to train 1024x1024 CenterNet models.

--
293889713  by jonathanhuang:

    Internal changes.

--
293637554  by ronnyvotel:

    Adding keypoint visibilities to TfExampleDecoder.

--
293501558  by lzc:

    Internal change.

--
293252851  by Zhichao Lu:

    Change tf.gfile.GFile to tf.io.gfile.GFile.

--
292730217  by Zhichao Lu:

    Internal change.

--
292456563  by lzc:

    Internal changes.

--
292355612  by Zhichao Lu:

    Use tf.gather and tf.scatter_nd instead of matrix ops.

--
292245265  by rathodv:

    Internal

--
291989323  by richardmunoz:

    Refactor out building a DataDecoder from building a tf.data.Dataset.

--
291950147  by Zhichao Lu:

    Flip bounding boxes in arbitrary shaped tensors.

--
291401052  by huizhongc:

    Fix multiscale grid anchor generator to allow fully convolutional inference. When exporting model with identity_resizer as image_resizer, there is an incorrect box offset on the detection results. We add the anchor offset to address this problem.

--
291298871  by Zhichao Lu:

    Py3 compatibility changes.

--
290957957  by Zhichao Lu:

    Hourglass feature extractor for CenterNet.

--
290564372  by Zhichao Lu:

    Internal change.

--
290155278  by rathodv:

    Remove Dataset Explorer.

--
290155153  by Zhichao Lu:

    Internal change

--
290122054  by Zhichao Lu:

    Unify the format in the faster_rcnn.proto

--
290116084  by Zhichao Lu:

    Deprecate tensorflow.contrib.

--
290100672  by Zhichao Lu:

    Update MobilenetV3 SSD candidates

--
289926392  by Zhichao Lu:

    Internal change

--
289553440  by Zhichao Lu:

    [Object Detection API] Fix the comments about the dimension of the rpn_box_encodings from 4-D to 3-D.

--
288994128  by lzc:

    Internal changes.

--
288942194  by lzc:

    Internal change.

--
288746124  by Zhichao Lu:

    Configurable channel mean/std. dev in CenterNet feature extractors.

--
288552509  by rathodv:

    Internal.

--
288541285  by rathodv:

    Internal update.

--
288396396  by Zhichao Lu:

    Make object detection import contrib explicitly

--
288255791  by rathodv:

    Internal

--
288078600  by Zhichao Lu:

    Fix model_lib_v2 test

--
287952244  by rathodv:

    Internal

--
287921774  by Zhichao Lu:

    internal change

--
287906173  by Zhichao Lu:

    internal change

--
287889407  by jonathanhuang:

    PY3 compatibility

--
287889042  by rathodv:

    Internal

--
287876178  by Zhichao Lu:

    Internal change.

--
287770490  by Zhichao Lu:

    Add CenterNet proto and builder

--
287694213  by Zhichao Lu:

    Support for running multiple steps per tf.function call.

--
287377183  by jonathanhuang:

    PY3 compatibility

--
287371344  by rathodv:

    Support loading keypoint labels and ids.

--
287368213  by rathodv:

    Add protos supporting keypoint evaluation.

--
287225346  by Zhichao Lu:

    Add CenterNet postprocess methods.

--
286673200  by rathodv:

    dataset_tools PY3 migration

--
286635106  by Zhichao Lu:

    Update code for upcoming tf.contrib removal

--
286513155  by Zhichao Lu:

    Add Center Net meta arch losses.

--
286479439  by Zhichao Lu:

    Internal change

--
286311711  by Zhichao Lu:

    Skeleton of context model within TFODAPI

--
286009924  by Zhichao Lu:

    Add CenterNet meta-architecture predict functions.

--
286005546  by Zhichao Lu:

    Fix Faster-RCNN training when using keep_aspect_ratio_resizer with pad_to_max_dimension

--
285906400  by derekjchow:

    Internal change

--
285822795  by Zhichao Lu:

    Add CenterNet meta arch target assigners.

--
285447238  by Zhichao Lu:

    Internal changes.

--
285016927  by Zhichao Lu:

    Make _dummy_computation a tf.function. This fixes breakage caused by
    cl/284256438

--
284827274  by Zhichao Lu:

    Convert to python 3.

--
284645593  by rathodv:

    Internal change

--
284639893  by rathodv:

    Add missing documentation for keypoints in eval_util.py.

--
284323712  by Zhichao Lu:

    Internal changes.

--
284295290  by Zhichao Lu:

    Updating input config proto and dataset builder to include context fields

    Updating standard_fields and tf_example_decoder to include context features

--
284226821  by derekjchow:

    Update exporter.

--
284211030  by Zhichao Lu:

    API changes in CenterNet informed by the experiments with hourlgass network.

--
284190451  by Zhichao Lu:

    Add support for CenterNet losses in protos and builders.

--
284093961  by lzc:

    Internal changes.

--
284028174  by Zhichao Lu:

    Internal change

--
284014719  by derekjchow:

    Do not pad top_down feature maps unnecessarily.

--
284005765  by Zhichao Lu:

    Add new pad_to_multiple_resizer

--
283858233  by Zhichao Lu:

    Make target assigner work when under tf.function.

--
283836611  by Zhichao Lu:

    Make config getters more general.

--
283808990  by Zhichao Lu:

    Internal change

--
283754588  by Zhichao Lu:

    Internal changes.

--
282460301  by Zhichao Lu:

    Add ability to restore v2 style checkpoints.

--
281605842  by lzc:

    Add option to disable loss computation in OD API eval job.

--
280298212  by Zhichao Lu:

    Add backwards compatible change

--
280237857  by Zhichao Lu:

    internal change

--

PiperOrigin-RevId: 310362339",pkulzc,b'cla: yes',2020-05-07T18:17:32Z,2020-05-08T01:02:24Z,,,,,,,
8475,Using YAMNet  in android,"<!--
Please make sure that this is a bug. 

As per our GitHub Policy (https://github.com/tensorflow/models/blob/master/ISSUES.md), we only address code bugs, documentation issues, and feature requests on GitHub.

Please go to Stack Overflow (http://stackoverflow.com/questions/tagged/tensorflow-model-garden) for help and support.

The research models (https://github.com/tensorflow/models/tree/master/research) are a large collection of models implemented in TensorFlow by researchers. They are not officially supported. It is up to the individual researchers to maintain the models and/or provide support on issues and pull requests.
-->

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
N/A
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
N/A
- Mobile device (e.g., Pixel 4, Samsung Galaxy 10) if the issue happens on mobile device:
Android 9
- TensorFlow installed from (source or binary):
source 
- TensorFlow version (use command below):
1.13.1
- Python version:
3.6
- Bazel version (if compiling from source):
0.19.1
- GCC/Compiler version (if compiling from source):
N/A
- CUDA/cuDNN version:
N/A
- GPU model and memory:
N/A
- NDK:
r18b

<!-- 
You can collect some of this information using our environment capture (https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 

1. TensorFlow 1.0
`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 

2. TensorFlow 2.0
`python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`
-->

**Please provide the entire URL of the model you are using?**
<!-- (e.g., https://github.com/tensorflow/models/tree/master/official/nlp/bert) -->
https://github.com/tensorflow/models/tree/master/research/audioset/yamnet
**Describe the current behavior**
I'm using YAMNet in android, I compiled Tensorflow 1.13 from source in Ubuntu 16.04 for android platform, so I can use native c++ to do inference in android. But now I get no output of YAMNet. 
This is the logcat in android studio, seems the 'RFFT' op is not supported?
```
D/Mudra: Graph /data/user/0/com.example.sd/cache/yamnet.pb read successfully! 
I/Mudra: Create TensorFlow Session: Invalid argument: No OpKernel was registered to support Op 'RFFT' used by {{node log_mel_features/stft/rfft}}with these attrs: []
    Registered devices: [CPU]
    Registered kernels:
      <no registered kernels>
    
    	 [[{{node log_mel_features/stft/rfft}}]]
```
**Describe the expected behavior**
I test the pb model in windows, tensorflow 1.14, it works fine.
**Code to reproduce the issue**
<!-- Provide a reproducible test case that is the bare minimum necessary to generate the problem. -->
N/A
**Other info / logs**
<!-- Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. -->
N/A",paleomoon,b'models:research type:bug',2020-05-07T07:39:13Z,2020-05-07T10:45:21Z,,,,,,,
8474,model_main.py: Windows fatal exception: (No any Valid information),"<!--
Please make sure that this is a bug. 

As per our GitHub Policy (https://github.com/tensorflow/models/blob/master/ISSUES.md), we only address code bugs, documentation issues, and feature requests on GitHub.

Please go to Stack Overflow (http://stackoverflow.com/questions/tagged/tensorflow-model-garden) for help and support.
-->

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Windows 10 1941.207
- Mobile device (e.g., Pixel 4, Samsung Galaxy 10) if the issue happens on mobile device:
no
- TensorFlow installed from (source or binary):
pip
- TensorFlow version (use command below):
-gpu(1.13.1,1.14,1.15)
- Python version:
3.7.7
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
CUDA:10.0 cuDNN:7.6.5.32
- GPU model and memory:
RTX 2080
<!-- 
You can collect some of this information using our environment capture (https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 

1. TensorFlow 1.0
`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 

2. TensorFlow 2.0
`python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`
-->

**Please provide the entire URL of the model you are using?**
<!-- (e.g., https://github.com/tensorflow/models/tree/master/official/nlp/bert) -->

**Describe the current behavior**
Training model
**Describe the expected behavior**
Training sucessful
**Code to reproduce the issue**
<!-- Provide a reproducible test case that is the bare minimum necessary to generate the problem. -->

**Other info / logs**
<!-- Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. -->

tensorflow: I try 1.13-1.15 all is don't work.



Command: python model_main.py --alsologtostderr --model_dir=training/ --pipeline_config_path=training/ssd_inception_v2_coco.config

complite running log:


`WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:From C:\Users\16668\source\repos\Arknights-Auto\TensorFlowObjectDetectionAPI\TensorFlow\models\research\slim\nets\inception_resnet_v2.py:373: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.

WARNING:tensorflow:From C:\Users\16668\source\repos\Arknights-Auto\TensorFlowObjectDetectionAPI\TensorFlow\models\research\slim\nets\mobilenet\mobilenet.py:389: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.

WARNING:tensorflow:From model_main.py:109: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.

WARNING:tensorflow:From C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python37_64\lib\site-packages\object_detection\utils\config_util.py:94: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.

W0507 00:49:51.139271  8860 module_wrapper.py:139] From C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python37_64\lib\site-packages\object_detection\utils\config_util.py:94: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.

WARNING:tensorflow:From C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python37_64\lib\site-packages\object_detection\model_lib.py:573: The name tf.logging.warning is deprecated. Please use tf.compat.v1.logging.warning instead.

W0507 00:49:51.143266  8860 module_wrapper.py:139] From C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python37_64\lib\site-packages\object_detection\model_lib.py:573: The name tf.logging.warning is deprecated. Please use tf.compat.v1.logging.warning instead.

WARNING:tensorflow:Forced number of epochs for all eval validations to be 1.
W0507 00:49:51.144263  8860 model_lib.py:574] Forced number of epochs for all eval validations to be 1.
WARNING:tensorflow:From C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python37_64\lib\site-packages\object_detection\utils\config_util.py:480: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.

W0507 00:49:51.144263  8860 module_wrapper.py:139] From C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python37_64\lib\site-packages\object_detection\utils\config_util.py:480: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.

INFO:tensorflow:Maybe overwriting train_steps: None
I0507 00:49:51.145691  8860 config_util.py:480] Maybe overwriting train_steps: None
INFO:tensorflow:Maybe overwriting sample_1_of_n_eval_examples: 1
I0507 00:49:51.145691  8860 config_util.py:480] Maybe overwriting sample_1_of_n_eval_examples: 1
INFO:tensorflow:Maybe overwriting eval_num_epochs: 1
I0507 00:49:51.146691  8860 config_util.py:480] Maybe overwriting eval_num_epochs: 1
INFO:tensorflow:Maybe overwriting load_pretrained: True
I0507 00:49:51.146691  8860 config_util.py:480] Maybe overwriting load_pretrained: True
INFO:tensorflow:Ignoring config override key: load_pretrained
I0507 00:49:51.146691  8860 config_util.py:490] Ignoring config override key: load_pretrained
WARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.
W0507 00:49:51.147687  8860 model_lib.py:590] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.
INFO:tensorflow:create_estimator_and_inputs: use_tpu False, export_to_tpu False
I0507 00:49:51.147687  8860 model_lib.py:623] create_estimator_and_inputs: use_tpu False, export_to_tpu False
INFO:tensorflow:Using config: {'_model_dir': 'training/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true
graph_options {
  rewrite_options {
    meta_optimizer_iterations: ONE
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000002115590BE08>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0507 00:49:51.148684  8860 estimator.py:212] Using config: {'_model_dir': 'training/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true
graph_options {
  rewrite_options {
    meta_optimizer_iterations: ONE
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000002115590BE08>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
WARNING:tensorflow:Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x000002115590D708>) includes params argument, but params are not passed to Estimator.
W0507 00:49:51.150257  8860 model_fn.py:630] Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x000002115590D708>) includes params argument, but params are not passed to Estimator.
INFO:tensorflow:Not using Distribute Coordinator.
I0507 00:49:51.151252  8860 estimator_training.py:186] Not using Distribute Coordinator.
INFO:tensorflow:Running training and evaluation locally (non-distributed).
I0507 00:49:51.151252  8860 training.py:612] Running training and evaluation locally (non-distributed).
INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.
I0507 00:49:51.151252  8860 training.py:700] Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.
WARNING:tensorflow:From C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python37_64\lib\site-packages\tensorflow_core\python\training\training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0507 00:49:51.157238  8860 deprecation.py:323] From C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python37_64\lib\site-packages\tensorflow_core\python\training\training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
Windows fatal exception: access violation

Current thread 0x0000229c (most recent call first):
  File ""C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python37_64\lib\site-packages\tensorflow_core\python\lib\io\file_io.py"", line 84 in _preread_check
  File ""C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python37_64\lib\site-packages\tensorflow_core\python\lib\io\file_io.py"", line 122 in read
  File ""C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python37_64\lib\site-packages\object_detection\utils\label_map_util.py"", line 133 in load_labelmap
  File ""C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python37_64\lib\site-packages\object_detection\utils\label_map_util.py"", line 164 in get_label_map_dict
  File ""C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python37_64\lib\site-packages\object_detection\data_decoders\tf_example_decoder.py"", line 59 in __init__
  File ""C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python37_64\lib\site-packages\object_detection\data_decoders\tf_example_decoder.py"", line 297 in __init__
  File ""C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python37_64\lib\site-packages\object_detection\builders\dataset_builder.py"", line 123 in build
  File ""C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python37_64\lib\site-packages\object_detection\inputs.py"", line 488 in _train_input_fn
  File ""C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python37_64\lib\site-packages\tensorflow_estimator\python\estimator\estimator.py"", line 1116 in _call_input_fn
  File ""C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python37_64\lib\site-packages\tensorflow_estimator\python\estimator\estimator.py"", line 1025 in _get_features_and_labels_from_input_fn
  File ""C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python37_64\lib\site-packages\tensorflow_estimator\python\estimator\estimator.py"", line 1188 in _train_model_default
  File ""C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python37_64\lib\site-packages\tensorflow_estimator\python\estimator\estimator.py"", line 1161 in _train_model
  File ""C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python37_64\lib\site-packages\tensorflow_estimator\python\estimator\estimator.py"", line 370 in train
  File ""C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python37_64\lib\site-packages\tensorflow_estimator\python\estimator\training.py"", line 714 in run_local
  File ""C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python37_64\lib\site-packages\tensorflow_estimator\python\estimator\training.py"", line 613 in run
  File ""C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python37_64\lib\site-packages\tensorflow_estimator\python\estimator\training.py"", line 473 in train_and_evaluate
  File ""model_main.py"", line 105 in main
  File ""C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python37_64\lib\site-packages\absl\app.py"", line 250 in _run_main
  File ""C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python37_64\lib\site-packages\absl\app.py"", line 299 in run
  File ""C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python37_64\lib\site-packages\tensorflow_core\python\platform\app.py"", line 40 in run
  File ""model_main.py"", line 109 in <module>`

",JiXiaoYao,b'models:research type:bug',2020-05-07T04:56:20Z,2020-08-18T08:40:26Z,,,,,,,
8464,[deeplab] Slow inference speed,"<!--
Please make sure that this is a bug. 

As per our GitHub Policy (https://github.com/tensorflow/models/blob/master/ISSUES.md), we only address code bugs, documentation issues, and feature requests on GitHub.

Please go to Stack Overflow (http://stackoverflow.com/questions/tagged/tensorflow-model-garden) for help and support.

The research models (https://github.com/tensorflow/models/tree/master/research) are a large collection of models implemented in TensorFlow by researchers. They are not officially supported. It is up to the individual researchers to maintain the models and/or provide support on issues and pull requests.
-->

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): **yes**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): **18.04 (Docker image 1.14-py3-gpu)**
- Mobile device (e.g., Pixel 4, Samsung Galaxy 10) if the issue happens on mobile device: **N/A**
- TensorFlow installed from (source or binary): **bundled in Docker image 1.14-py3-gpu**
- TensorFlow version (use command below): **v1.14.0-rc1-22-gaf24dc91b5 1.14.0**
- Python version: **3.6.8**
- Bazel version (if compiling from source): **N/A**
- GCC/Compiler version (if compiling from source): **N/A**
- CUDA/cuDNN version: **7.4.1.5-1**
- GPU model and memory: **NVIDIA GTX 1080 (8GB)**

<!-- 
You can collect some of this information using our environment capture (https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 

1. TensorFlow 1.0
`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 

2. TensorFlow 2.0
`python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`
-->

**Please provide the entire URL of the model you are using?**
 [https://github.com/tensorflow/models/blob/master/research/deeplab](url)

<!-- (e.g., https://github.com/tensorflow/models/tree/master/official/nlp/bert) -->

**Describe the current behavior**

- A quite slow inference speed. In my i7-7800X + GTX 1080 (8GB RAM) machine, using self-trained DeepLabV3+ (Xception) model, needs around 2.5+ seconds to inference a image. 

- The inference speed does not change no matter I changed the input image size from 512x512 to 256x256. 

- And I also tested with the default PASCAL VOC trained model (http://download.tensorflow.org/models/deeplabv3_pascal_train_aug_2018_01_04.tar.gz), the inference time is nearly the same (3 seconds per image).

- Does my machine (especially the graphics card) is too slow to run DeepLabV3+ (Xception) ? 

**Describe the expected behavior**
I am expecting a sub-second (around 500ms or lower) inference time. 

**Code to reproduce the issue**

<!-- Provide a reproducible test case that is the bare minimum necessary to generate the problem. -->

**Other info / logs**
<!-- Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. -->
",cclo-astri,b'models:research type:performance',2020-05-04T11:02:02Z,2020-08-13T00:58:42Z,,,,,,,
8459,how to use train.py with a cloud TPU?,"<!--
As per our GitHub Policy (https://github.com/tensorflow/models/blob/master/ISSUES.md), we only address code bugs, documentation issues, and feature requests on GitHub.

We will automatically close questions and help related issues.

Please go to Stack Overflow (http://stackoverflow.com/questions/tagged/tensorflow-model-garden) for questions and help.

-->

just wanted to know if it is possible to use train.py(deprecated) in object detection with a Google cloud TPU??
",satyamedh,b'models:research type:support',2020-05-03T08:48:26Z,2020-05-14T10:07:36Z,,,,,,,
8458,[deeplab] cityscapes  error:data split name val not recognized,"when i try eval
python deeplab/eval.py \
    --logtostderr \
    --eval_split=""val"" \
    --model_variant=""xception_65"" \
    --atrous_rates=6 \
    --atrous_rates=12 \
    --atrous_rates=18 \
    --output_stride=16 \
    --decoder_output_stride=4 \
    --eval_crop_size=1025 \
	--eval_crop_size=2049 \
    --dataset=""cityscapes"" \
    --checkpoint_dir=""/data/mll/models/research/deeplab/datasets/cityscapes/exp/train_on_train_set/train"" \
    --eval_logdir=""/data/mll/models/research/deeplab/datasets/cityscapes/exp/train_on_train_set/val"" \
    --dataset_dir=""/data/mll/models/research/deeplab/datasets/cityscapes/tfrecord"" \


error:
Traceback (most recent call last):
  File ""deeplab/eval.py"", line 227, in <module>
    tf.app.run()
  File ""/home/mll/anaconda3/envs/tensor/lib/python3.7/site-packages/tensorflow_core/python/platform/app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""/home/mll/anaconda3/envs/tensor/lib/python3.7/site-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/home/mll/anaconda3/envs/tensor/lib/python3.7/site-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""deeplab/eval.py"", line 106, in main
    should_repeat=False)
  File ""/data/mll/models/research/deeplab/datasets/data_generator.py"", line 171, in __init__
    raise ValueError('data split name %s not recognized' % split_name)
ValueError: data split name val not recognized





<!--
As per our GitHub Policy (https://github.com/tensorflow/models/blob/master/ISSUES.md), we only address code bugs, documentation issues, and feature requests on GitHub.

We will automatically close questions and help related issues.

Please go to Stack Overflow (http://stackoverflow.com/questions/tagged/tensorflow-model-garden) for questions and help.

-->
",sorrowyn,b'models:research type:support',2020-05-02T15:18:26Z,2020-05-08T16:49:01Z,,,,,,,
8457,TPU distribution strategy fail: NodeDef expected inputs 'string' do not match 0 inputs specified,"I'm trying to initialize a TPU distribution strategy and I have the following error:

```
tensorflow.python.framework.errors_impl.InvalidArgumentError: NodeDef expected inputs 'string' do not match 0 inputs specified; Op<name=_Send; signature=tensor:T -> ; attr=T:type; attr=tensor_name:string; 
attr=send_device:string; attr=send_device_incarnation:int; attr=recv_device:string; attr=client_terminated:bool,default=false; is_stateful=true>; NodeDef: {{node _Send}}
```

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): `Yes`
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): `Debian 10`
- TensorFlow installed from (source or binary): `binary (pip3)`
- TensorFlow version (use command below): `2.2.0-dev20200501`
- Python version: `Python 3.7.3`
- CUDA/cuDNN version: `none (GCP TPU)`
- GPU model and memory: `none (GCP TPU)`

**Code to reproduce the issue**

`tpu_strategy.py`

```python
# -*- coding: utf-8 -*-
import os

from official.utils.misc import distribution_utils

tpu_name=os.getenv('TPU_NAME')

strategy = distribution_utils.get_distribution_strategy(
    distribution_strategy=""tpu"",
    tpu_address=tpu_name)

strategy_scope = distribution_utils.get_strategy_scope(strategy)
```

**How to run this code**

Follow the guide to run a TPU vm: https://cloud.google.com/tpu/docs/quickstart)

Then when you have a shell session on it, execute the following commands instead of running the MNIST example:
 
```bash
$ pip3 install tf-models-nightly
$ TPU_NAME=tpu-quickstart python3 tpu_strategy.py
```

**Other info / logs**

<details><summary>Complete log + stacktrace</summary>

```
2020-05-02 06:30:09.091314: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: N
o such file or directory
2020-05-02 06:30:09.091362: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
Get strategy tpu
on TPU ichimia
2020-05-02 06:30:10.718866: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such fil
e or directory
2020-05-02 06:30:10.718920: E tensorflow/stream_executor/cuda/cuda_driver.cc:313] failed call to cuInit: UNKNOWN ERROR (303)
2020-05-02 06:30:10.718950: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ichimia): /proc/driver/nvidia/version does not exist
2020-05-02 06:30:10.886804: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance-critical oper
ations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-05-02 06:30:10.894306: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 2300000000 Hz
2020-05-02 06:30:10.894601: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5a05920 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-05-02 06:30:10.894631: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-05-02 06:30:10.903492: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job worker -> {0 -> 10.240.1.2:8470}
2020-05-02 06:30:10.903537: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job localhost -> {0 -> localhost:40985}
2020-05-02 06:30:10.919176: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job worker -> {0 -> 10.240.1.2:8470}
2020-05-02 06:30:10.919227: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job localhost -> {0 -> localhost:40985}
2020-05-02 06:30:10.919829: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:390] Started server with target: grpc://localhost:40985
Traceback (most recent call last):
  File ""src/tpu.py"", line 15, in <module>
    tpu_address=tpu_name)
  File ""/home/amaret93/.local/lib/python3.7/site-packages/official/utils/misc/distribution_utils.py"", line 129, in get_distribution_strategy
    cluster_resolver = tpu_lib.tpu_initialize(tpu_address)
  File ""/home/amaret93/.local/lib/python3.7/site-packages/official/utils/misc/tpu_lib.py"", line 33, in tpu_initialize
    tf.tpu.experimental.initialize_tpu_system(cluster_resolver)
  File ""/home/amaret93/.local/lib/python3.7/site-packages/tensorflow/python/tpu/tpu_strategy_util.py"", line 103, in initialize_tpu_system
    serialized_topology = output.numpy()
  File ""/home/amaret93/.local/lib/python3.7/site-packages/tensorflow/python/framework/ops.py"", line 1110, in numpy
    maybe_arr = self._numpy()  # pylint: disable=protected-access
  File ""/home/amaret93/.local/lib/python3.7/site-packages/tensorflow/python/framework/ops.py"", line 1078, in _numpy
    six.raise_from(core._status_to_exception(e.code, e.message), None)
  File ""<string>"", line 3, in raise_from
tensorflow.python.framework.errors_impl.InvalidArgumentError: NodeDef expected inputs 'string' do not match 0 inputs specified; Op<name=_Send; signature=tensor:T -> ; attr=T:type; attr=tensor_name:string; 
attr=send_device:string; attr=send_device_incarnation:int; attr=recv_device:string; attr=client_terminated:bool,default=false; is_stateful=true>; NodeDef: {{node _Send}}
2020-05-02 06:30:21.913994: W tensorflow/core/distributed_runtime/eager/remote_tensor_handle_data.cc:76] Unable to destroy remote tensor handles. If you are running a tf.function, it usually indicates some
 op in the graph gets an error: NodeDef expected inputs 'string' do not match 0 inputs specified; Op<name=_Send; signature=tensor:T -> ; attr=T:type; attr=tensor_name:string; attr=send_device:string; attr=
send_device_incarnation:int; attr=recv_device:string; attr=client_terminated:bool,default=false; is_stateful=true>; NodeDef: {{node _Send}}
```

</details>",Aschen,b'models:official type:bug',2020-05-02T06:44:14Z,2020-07-31T03:40:13Z,,,,,,,
8456,export_tflite_ssd_graph crash in TF 2,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Windows 10
- Mobile device (e.g., Pixel 4, Samsung Galaxy 10) if the issue happens on mobile device:
N/A
- TensorFlow installed from (source or binary):
Binary (pip)
- TensorFlow version (use command below):
v2.1.0-rc2-17-ge5bf8de410 2.1.0
- Python version:
3.6.3
- Bazel version (if compiling from source):
N/A
- GCC/Compiler version (if compiling from source):
N/A
- CUDA/cuDNN version:
N/A
- GPU model and memory:
N/A

**Describe the current behavior**
Running `export_tflite_ssd_graph.py` crashes due to `ModuleNotFoundError: No module named 'tensorflow.tools.graph_transforms'`.

Full stacktrace:
```
Traceback (most recent call last):
  File ""C:\MyProjects\tensorflow-models\research\object_detection\export_tflite_ssd_graph.py"", line 96, in <module>
    from object_detection import export_tflite_ssd_graph_lib
  File ""C:\MyProjects\tensorflow-models\research\object_detection\export_tflite_ssd_graph_lib.py"", line 26, in <module>
    from tensorflow.tools.graph_transforms import TransformGraph
ModuleNotFoundError: No module named 'tensorflow.tools.graph_transforms'
```

As per [this](https://github.com/tensorflow/tensorflow/issues/33352#issuecomment-556245567), graph_transforms no longer exposed intentionally in TF 2.0

Anytime I need to convert I use some VM with TF 1.14.0 is there any fix/workaround for this issue on TF2?
Thx.",ValYouW,b'models:research type:bug',2020-04-30T23:52:30Z,2020-05-29T05:54:22Z,,,,,,,
8455,[struct2depth]Resource exhausted with batch size=1,"<!--
As per our GitHub Policy (https://github.com/tensorflow/models/blob/master/ISSUES.md), we only address code bugs, documentation issues, and feature requests on GitHub.

We will automatically close questions and help related issues.

Please go to Stack Overflow (http://stackoverflow.com/questions/tagged/tensorflow-model-garden) for questions and help.

-->


Great work @aneliaangelova and @VincentCa  and team. I am getting the following error whenever I use masks also for training along with the rgb images:

Resource exhausted: OOM when allocating tensor with shape[1,4,53248]
I have a 10gb gpu .The model trains perfectly without masks ,i.e without handle motion.
I got this error for a batchsize of 1.
Can anyone please help me out.
This is the mask stack which I give as input:
![0000000001-fseg](https://user-images.githubusercontent.com/64612239/80753490-f99edc00-8b4a-11ea-9d03-81482437f9a9.jpg)
I also tried eliminating small masks but end up with the same error.
Thank you

",anakita,b'models:research type:support',2020-04-30T20:00:32Z,2020-05-15T08:44:46Z,,,,,,,
8452,impl.OpError: file is too short to be an sstable - TensorFlow,"<!--
As per our GitHub Policy (https://github.com/tensorflow/models/blob/master/ISSUES.md), we only address code bugs, documentation issues, and feature requests on GitHub.

We will automatically close questions and help related issues.

Please go to Stack Overflow (http://stackoverflow.com/questions/tagged/tensorflow-model-garden) for questions and help.

-->
Hi guys! i am trying to run this TensorFlow job on Kubernetes cluster using kubeflow. But i keep getting these indeterministic errors, which are really hard to follow. I have to run the same job again and again using different tfconfigs ... and every time, there's a chance that the job might fail because of the following issue. The job uses TensorFlow2.0, and kubeflow1.0. The fact that the job fails with a chance is really weird which makes it very hard to isolate. If I simply delete and restart the job, sometimes it runs fine(but there's a chance it might give the same error again - slight chance!). Could someone please point out the root cause that might be causing such behavior!
```
2020-04-16 03:32:10.840927: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory
2020-04-16 03:32:10.841009: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory
2020-04-16 03:32:10.841016: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
I0416 03:32:11.778649 140150905272128 dataset_builder.py:199] Overwrite dataset info from restored data version.
I0416 03:32:11.781358 140150905272128 dataset_builder.py:285] Reusing dataset cifar10 (./dataDir/cifar10/3.0.0)
I0416 03:32:11.781544 140150905272128 dataset_builder.py:458] Constructing tf.data.Dataset for split train, from ./dataDir/cifar10/3.0.0
2020-04-16 03:32:11.785308: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2020-04-16 03:32:11.785339: E tensorflow/stream_executor/cuda/cuda_driver.cc:351] failed call to cuInit: UNKNOWN ERROR (303)
2020-04-16 03:32:11.785361: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (tftestaccuracy7-testjob-temp-1-7-3-3-0-master-0): /proc/driver/nvidia/version does not exist
2020-04-16 03:32:11.785606: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2020-04-16 03:32:11.794453: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2194825000 Hz
2020-04-16 03:32:11.796551: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4895200 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-04-16 03:32:11.796574: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
INFO:1587007938.6536536:tensorflow:TF_CONFIG environment variable: {'cluster': {'master': ['tftestaccuracy7-testjob-temp-1-7-3-3-0-master-0.ali.svc:2222'], 'ps': ['tftestaccuracy7-testjob-temp-1-7-3-3-0-ps-0.ali.svc:2222', 'tftestaccuracy7-testjob-temp-1-7-3-3-0-ps-1.ali.svc:2222', 'tftestaccuracy7-testjob-temp-1-7-3-3-0-ps-2.ali.svc:2222', 'tftestaccuracy7-testjob-temp-1-7-3-3-0-ps-3.ali.svc:2222', 'tftestaccuracy7-testjob-temp-1-7-3-3-0-ps-4.ali.svc:2222', 'tftestaccuracy7-testjob-temp-1-7-3-3-0-ps-5.ali.svc:2222', 'tftestaccuracy7-testjob-temp-1-7-3-3-0-ps-6.ali.svc:2222'], 'worker': ['tftestaccuracy7-testjob-temp-1-7-3-3-0-worker-0.ali.svc:2222', 'tftestaccuracy7-testjob-temp-1-7-3-3-0-worker-1.ali.svc:2222', 'tftestaccuracy7-testjob-temp-1-7-3-3-0-worker-2.ali.svc:2222']}, 'task': {'type': 'master', 'index': 0}, 'environment': 'cloud'}
I0416 03:32:18.653653 140150905272128 run_config.py:535] TF_CONFIG environment variable: {'cluster': {'master': ['tftestaccuracy7-testjob-temp-1-7-3-3-0-master-0.ali.svc:2222'], 'ps': ['tftestaccuracy7-testjob-temp-1-7-3-3-0-ps-0.ali.svc:2222', 'tftestaccuracy7-testjob-temp-1-7-3-3-0-ps-1.ali.svc:2222', 'tftestaccuracy7-testjob-temp-1-7-3-3-0-ps-2.ali.svc:2222', 'tftestaccuracy7-testjob-temp-1-7-3-3-0-ps-3.ali.svc:2222', 'tftestaccuracy7-testjob-temp-1-7-3-3-0-ps-4.ali.svc:2222', 'tftestaccuracy7-testjob-temp-1-7-3-3-0-ps-5.ali.svc:2222', 'tftestaccuracy7-testjob-temp-1-7-3-3-0-ps-6.ali.svc:2222'], 'worker': ['tftestaccuracy7-testjob-temp-1-7-3-3-0-worker-0.ali.svc:2222', 'tftestaccuracy7-testjob-temp-1-7-3-3-0-worker-1.ali.svc:2222', 'tftestaccuracy7-testjob-temp-1-7-3-3-0-worker-2.ali.svc:2222']}, 'task': {'type': 'master', 'index': 0}, 'environment': 'cloud'}
INFO:1587007938.6553543:tensorflow:Using the Keras model provided.
I0416 03:32:18.655354 140150905272128 keras.py:540] Using the Keras model provided.
WARNING:1587007938.7225273:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1635: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
Instructions for updating:
If using Keras pass *_constraint arguments to layers.
W0416 03:32:18.722527 140150905272128 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1635: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
Instructions for updating:
If using Keras pass *_constraint arguments to layers.
INFO:1587007950.8246615:tensorflow:Using config: {'_model_dir': './out/tftestaccuracy7-testjob-temp-1-7-3-3-0', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 20000, '_save_checkpoints_secs': None, '_session_config': device_filters: ""/job:ps""
device_filters: ""/job:master""
allow_soft_placement: true
graph_options {
  rewrite_options {
    meta_optimizer_iterations: ONE
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({'master': ['tftestaccuracy7-testjob-temp-1-7-3-3-0-master-0.ali.svc:2222'], 'ps': ['tftestaccuracy7-testjob-temp-1-7-3-3-0-ps-0.ali.svc:2222', 'tftestaccuracy7-testjob-temp-1-7-3-3-0-ps-1.ali.svc:2222', 'tftestaccuracy7-testjob-temp-1-7-3-3-0-ps-2.ali.svc:2222', 'tftestaccuracy7-testjob-temp-1-7-3-3-0-ps-3.ali.svc:2222', 'tftestaccuracy7-testjob-temp-1-7-3-3-0-ps-4.ali.svc:2222', 'tftestaccuracy7-testjob-temp-1-7-3-3-0-ps-5.ali.svc:2222', 'tftestaccuracy7-testjob-temp-1-7-3-3-0-ps-6.ali.svc:2222'], 'worker': ['tftestaccuracy7-testjob-temp-1-7-3-3-0-worker-0.ali.svc:2222', 'tftestaccuracy7-testjob-temp-1-7-3-3-0-worker-1.ali.svc:2222', 'tftestaccuracy7-testjob-temp-1-7-3-3-0-worker-2.ali.svc:2222']}), '_task_type': 'master', '_task_id': 0, '_global_id_in_cluster': 0, '_master': 'grpc://tftestaccuracy7-testjob-temp-1-7-3-3-0-master-0.ali.svc:2222', '_evaluation_master': '', '_num_ps_replicas': 7, '_num_worker_replicas': 4, '_is_chief': True}
I0416 03:32:30.824661 140150905272128 estimator.py:216] Using config: {'_model_dir': './out/tftestaccuracy7-testjob-temp-1-7-3-3-0', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 20000, '_save_checkpoints_secs': None, '_session_config': device_filters: ""/job:ps""
device_filters: ""/job:master""
allow_soft_placement: true
graph_options {
  rewrite_options {
    meta_optimizer_iterations: ONE
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({'master': ['tftestaccuracy7-testjob-temp-1-7-3-3-0-master-0.ali.svc:2222'], 'ps': ['tftestaccuracy7-testjob-temp-1-7-3-3-0-ps-0.ali.svc:2222', 'tftestaccuracy7-testjob-temp-1-7-3-3-0-ps-1.ali.svc:2222', 'tftestaccuracy7-testjob-temp-1-7-3-3-0-ps-2.ali.svc:2222', 'tftestaccuracy7-testjob-temp-1-7-3-3-0-ps-3.ali.svc:2222', 'tftestaccuracy7-testjob-temp-1-7-3-3-0-ps-4.ali.svc:2222', 'tftestaccuracy7-testjob-temp-1-7-3-3-0-ps-5.ali.svc:2222', 'tftestaccuracy7-testjob-temp-1-7-3-3-0-ps-6.ali.svc:2222'], 'worker': ['tftestaccuracy7-testjob-temp-1-7-3-3-0-worker-0.ali.svc:2222', 'tftestaccuracy7-testjob-temp-1-7-3-3-0-worker-1.ali.svc:2222', 'tftestaccuracy7-testjob-temp-1-7-3-3-0-worker-2.ali.svc:2222']}), '_task_type': 'master', '_task_id': 0, '_global_id_in_cluster': 0, '_master': 'grpc://tftestaccuracy7-testjob-temp-1-7-3-3-0-master-0.ali.svc:2222', '_evaluation_master': '', '_num_ps_replicas': 7, '_num_worker_replicas': 4, '_is_chief': True}
INFO:1587007950.825566:tensorflow:Not using Distribute Coordinator.
I0416 03:32:30.825566 140150905272128 estimator_training.py:186] Not using Distribute Coordinator.
INFO:1587007950.8260767:tensorflow:Start Tensorflow server.
I0416 03:32:30.826076 140150905272128 training.py:744] Start Tensorflow server.
2020-04-16 03:32:30.835044: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:300] Initialize GrpcChannelCache for job master -> {0 -> localhost:2222}
2020-04-16 03:32:30.835109: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:300] Initialize GrpcChannelCache for job ps -> {0 -> tftestaccuracy7-testjob-temp-1-7-3-3-0-ps-0.ali.svc:2222, 1 -> tftestaccuracy7-testjob-temp-1-7-3-3-0-ps-1.ali.svc:2222, 2 -> tftestaccuracy7-testjob-temp-1-7-3-3-0-ps-2.ali.svc:2222, 3 -> tftestaccuracy7-testjob-temp-1-7-3-3-0-ps-3.ali.svc:2222, 4 -> tftestaccuracy7-testjob-temp-1-7-3-3-0-ps-4.ali.svc:2222, 5 -> tftestaccuracy7-testjob-temp-1-7-3-3-0-ps-5.ali.svc:2222, 6 -> tftestaccuracy7-testjob-temp-1-7-3-3-0-ps-6.ali.svc:2222}
2020-04-16 03:32:30.835125: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:300] Initialize GrpcChannelCache for job worker -> {0 -> tftestaccuracy7-testjob-temp-1-7-3-3-0-worker-0.ali.svc:2222, 1 -> tftestaccuracy7-testjob-temp-1-7-3-3-0-worker-1.ali.svc:2222, 2 -> tftestaccuracy7-testjob-temp-1-7-3-3-0-worker-2.ali.svc:2222}
2020-04-16 03:32:30.838051: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:390] Started server with target: grpc://localhost:2222
WARNING:1587007950.8507316:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0416 03:32:30.850731 140150905272128 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0416 03:32:30.867805 140150905272128 dataset_builder.py:199] Overwrite dataset info from restored data version.
I0416 03:32:30.875023 140150905272128 dataset_builder.py:285] Reusing dataset cifar10 (./dataDir/cifar10/3.0.0)
I0416 03:32:30.875263 140150905272128 dataset_builder.py:458] Constructing tf.data.Dataset for split train, from ./dataDir/cifar10/3.0.0
INFO:1587007951.0019863:tensorflow:Calling model_fn.
I0416 03:32:31.001986 140150905272128 estimator.py:1151] Calling model_fn.
INFO:1587007957.5129364:tensorflow:Done calling model_fn.
I0416 03:32:37.512936 140150905272128 estimator.py:1153] Done calling model_fn.
INFO:1587007957.5134861:tensorflow:Warm-starting with WarmStartSettings: WarmStartSettings(ckpt_to_initialize_from='./out/tftestaccuracy7-testjob-temp-1-7-3-3-0/keras/keras_model.ckpt', vars_to_warm_start='.*', var_name_to_vocab_info={}, var_name_to_prev_var_name={})
I0416 03:32:37.513486 140150905272128 estimator.py:1372] Warm-starting with WarmStartSettings: WarmStartSettings(ckpt_to_initialize_from='./out/tftestaccuracy7-testjob-temp-1-7-3-3-0/keras/keras_model.ckpt', vars_to_warm_start='.*', var_name_to_vocab_info={}, var_name_to_prev_var_name={})
INFO:1587007957.513585:tensorflow:Warm-starting from: ./out/tftestaccuracy7-testjob-temp-1-7-3-3-0/keras/keras_model.ckpt
I0416 03:32:37.513585 140150905272128 warm_starting_util.py:464] Warm-starting from: ./out/tftestaccuracy7-testjob-temp-1-7-3-3-0/keras/keras_model.ckpt
INFO:1587007957.513649:tensorflow:Warm-starting variables only in TRAINABLE_VARIABLES.
I0416 03:32:37.513648 140150905272128 warm_starting_util.py:343] Warm-starting variables only in TRAINABLE_VARIABLES.
tfds.core.DatasetInfo(
    name='cifar10',
    version=3.0.0,
    description='The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images.',
    homepage='https://www.cs.toronto.edu/~kriz/cifar.html',
    features=FeaturesDict({
        'image': Image(shape=(32, 32, 3), dtype=tf.uint8),
        'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=10),
    }),
    total_num_examples=60000,
    splits={
        'test': 10000,
        'train': 50000,
    },
    supervised_keys=('image', 'label'),
    citation=""""""@TECHREPORT{Krizhevsky09learningmultiple,
        author = {Alex Krizhevsky},
        title = {Learning multiple layers of features from tiny images},
        institution = {},
        year = {2009}
    }"""""",
    redistribution_info=,
)

Input data (batch size 64): <DatasetV1Adapter shapes: ((None, 128, 128, 3), (None,)), types: (tf.float32, tf.int64)>
+++++ Building Keras model +++++
Output of feature extraction (original model): (64, 4, 4, 2048)
Output of 0th classification layer (<tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D object at 0x7f766056aa58>): (64, 2048)
Output of 1th classification layer (<tensorflow.python.keras.layers.core.Dense object at 0x7f766056aba8>): (64, 10)
Model: ""sequential_1""
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
resnet50 (Model)             (None, 4, 4, 2048)        23587712  
_________________________________________________________________
sequential (Sequential)      (None, 10)                20490     
=================================================================
Total params: 23,608,202
Trainable params: 23,555,082
Non-trainable params: 53,120
_________________________________________________________________
Model: ""sequential""
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
global_average_pooling2d (Gl (None, 2048)              0         
_________________________________________________________________
dense (Dense)                (None, 10)                20490     
=================================================================
Total params: 20,490
Trainable params: 20,490
Non-trainable params: 0
_________________________________________________________________
+++++ Train and evaluate the Estimator model +++++
tfds.core.DatasetInfo(
    name='cifar10',
    version=3.0.0,
    description='The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images.',
    homepage='https://www.cs.toronto.edu/~kriz/cifar.html',
    features=FeaturesDict({
        'image': Image(shape=(32, 32, 3), dtype=tf.uint8),
        'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=10),
    }),
    total_num_examples=60000,
    splits={
        'test': 10000,
        'train': 50000,
    },
    supervised_keys=('image', 'label'),
    citation=""""""@TECHREPORT{Krizhevsky09learningmultiple,
        author = {Alex Krizhevsky},
        title = {Learning multiple layers of features from tiny images},
        institution = {},
        year = {2009}
    }"""""",
    redistribution_info=,
)

Input data (batch size 64): <DatasetV1Adapter shapes: ((None, 128, 128, 3), (None,)), types: (tf.float32, tf.int64)>
Traceback (most recent call last):
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/py_checkpoint_reader.py"", line 95, in NewCheckpointReader
    return CheckpointReader(compat.as_bytes(filepattern))
RuntimeError: file is too short to be an sstable

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/app/keras_to_est.py"", line 242, in <module>
    app.run(main)
  File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""/app/keras_to_est.py"", line 227, in main
    tf.estimator.train_and_evaluate(model_est, train_spec, eval_spec)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py"", line 473, in train_and_evaluate
    return executor.run()
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py"", line 640, in run
    getattr(self, task_to_run)()
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py"", line 677, in run_master
    self._start_distributed_training(saving_listeners=saving_listeners)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py"", line 796, in _start_distributed_training
    saving_listeners=saving_listeners)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 374, in train
    loss = self._train_model(input_fn, hooks, saving_listeners)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1164, in _train_model
    return self._train_model_default(input_fn, hooks, saving_listeners)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1198, in _train_model_default
    saving_listeners)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1373, in _train_with_estimator_spec
    warm_starting_util.warm_start(*self._warm_start_settings)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/warm_starting_util.py"", line 476, in warm_start
    ckpt_to_initialize_from, grouped_variables.keys())
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/warm_starting_util.py"", line 397, in _get_object_checkpoint_renames
    names_to_keys = saver_lib.object_graph_key_mapping(fname)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py"", line 1617, in object_graph_key_mapping
    reader = py_checkpoint_reader.NewCheckpointReader(checkpoint_path)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/py_checkpoint_reader.py"", line 99, in NewCheckpointReader
    error_translator(e)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/py_checkpoint_reader.py"", line 48, in error_translator
    raise errors_impl.OpError(None, None, error_message, errors_impl.UNKNOWN)
tensorflow.python.framework.errors_impl.OpError: file is too short to be an sstable
```",ali-raza-tariq,b'models:official type:support',2020-04-28T17:14:34Z,2020-04-29T18:10:05Z,,,,,,,
8451,Checksum does not match: stored vs. calculated - tensorflow,"<!--
As per our GitHub Policy (https://github.com/tensorflow/models/blob/master/ISSUES.md), we only address code bugs, documentation issues, and feature requests on GitHub.

We will automatically close questions and help related issues.

Please go to Stack Overflow (http://stackoverflow.com/questions/tagged/tensorflow-model-garden) for questions and help.

-->
Hi guys! i am trying to run this TensorFlow job on Kubernetes cluster using kubeflow. But i keep getting these indeterministic errors, which are really hard to follow. I have to run the same job again and again using different tfconfigs ... and every time, there's a chance that the job might fail because of the following issue. The job uses TensorFlow2.0, and kubeflow1.0. The fact that the job fails with a chance is really weird which makes it very hard to isolate. Could someone please point out the root cause that might be causing such behavior!

```
2020-04-17 11:10:04.594547: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory
2020-04-17 11:10:04.594650: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory
2020-04-17 11:10:04.594665: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
I0417 11:10:05.664701 140220500707136 dataset_builder.py:199] Overwrite dataset info from restored data version.
I0417 11:10:05.667569 140220500707136 dataset_builder.py:285] Reusing dataset cifar10 (./dataDir/cifar10/3.0.0)
I0417 11:10:05.667821 140220500707136 dataset_builder.py:458] Constructing tf.data.Dataset for split train, from ./dataDir/cifar10/3.0.0
2020-04-17 11:10:05.672440: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2020-04-17 11:10:05.672469: E tensorflow/stream_executor/cuda/cuda_driver.cc:351] failed call to cuInit: UNKNOWN ERROR (303)
2020-04-17 11:10:05.672494: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (tftestaccuracy6-testjob-temp-1-6-11-11-0-master-0): /proc/driver/nvidia/version does not exist
2020-04-17 11:10:05.672896: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2020-04-17 11:10:05.685860: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2194855000 Hz
2020-04-17 11:10:05.688580: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4db8fe0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-04-17 11:10:05.688621: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
INFO:1587121814.71867:tensorflow:TF_CONFIG environment variable: {'cluster': {'master': ['tftestaccuracy6-testjob-temp-1-6-11-11-0-master-0.ali.svc:2222'], 'ps': ['tftestaccuracy6-testjob-temp-1-6-11-11-0-ps-0.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-ps-1.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-ps-2.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-ps-3.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-ps-4.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-ps-5.ali.svc:2222'], 'worker': ['tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-0.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-1.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-2.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-3.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-4.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-5.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-6.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-7.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-8.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-9.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-10.ali.svc:2222']}, 'task': {'type': 'master', 'index': 0}, 'environment': 'cloud'}
I0417 11:10:14.718669 140220500707136 run_config.py:535] TF_CONFIG environment variable: {'cluster': {'master': ['tftestaccuracy6-testjob-temp-1-6-11-11-0-master-0.ali.svc:2222'], 'ps': ['tftestaccuracy6-testjob-temp-1-6-11-11-0-ps-0.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-ps-1.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-ps-2.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-ps-3.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-ps-4.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-ps-5.ali.svc:2222'], 'worker': ['tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-0.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-1.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-2.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-3.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-4.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-5.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-6.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-7.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-8.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-9.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-10.ali.svc:2222']}, 'task': {'type': 'master', 'index': 0}, 'environment': 'cloud'}
INFO:1587121814.7204363:tensorflow:Using the Keras model provided.
I0417 11:10:14.720436 140220500707136 keras.py:540] Using the Keras model provided.
INFO:1587121814.7229145:tensorflow:Using config: {'_model_dir': './out/tftestaccuracy6-testjob-temp-1-6-11-11-0', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 20000, '_save_checkpoints_secs': None, '_session_config': device_filters: ""/job:ps""
device_filters: ""/job:master""
allow_soft_placement: true
graph_options {
  rewrite_options {
    meta_optimizer_iterations: ONE
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({'master': ['tftestaccuracy6-testjob-temp-1-6-11-11-0-master-0.ali.svc:2222'], 'ps': ['tftestaccuracy6-testjob-temp-1-6-11-11-0-ps-0.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-ps-1.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-ps-2.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-ps-3.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-ps-4.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-ps-5.ali.svc:2222'], 'worker': ['tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-0.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-1.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-2.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-3.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-4.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-5.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-6.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-7.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-8.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-9.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-10.ali.svc:2222']}), '_task_type': 'master', '_task_id': 0, '_global_id_in_cluster': 0, '_master': 'grpc://tftestaccuracy6-testjob-temp-1-6-11-11-0-master-0.ali.svc:2222', '_evaluation_master': '', '_num_ps_replicas': 6, '_num_worker_replicas': 12, '_is_chief': True}
I0417 11:10:14.722914 140220500707136 estimator.py:216] Using config: {'_model_dir': './out/tftestaccuracy6-testjob-temp-1-6-11-11-0', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 20000, '_save_checkpoints_secs': None, '_session_config': device_filters: ""/job:ps""
device_filters: ""/job:master""
allow_soft_placement: true
graph_options {
  rewrite_options {
    meta_optimizer_iterations: ONE
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({'master': ['tftestaccuracy6-testjob-temp-1-6-11-11-0-master-0.ali.svc:2222'], 'ps': ['tftestaccuracy6-testjob-temp-1-6-11-11-0-ps-0.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-ps-1.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-ps-2.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-ps-3.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-ps-4.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-ps-5.ali.svc:2222'], 'worker': ['tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-0.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-1.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-2.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-3.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-4.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-5.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-6.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-7.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-8.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-9.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-10.ali.svc:2222']}), '_task_type': 'master', '_task_id': 0, '_global_id_in_cluster': 0, '_master': 'grpc://tftestaccuracy6-testjob-temp-1-6-11-11-0-master-0.ali.svc:2222', '_evaluation_master': '', '_num_ps_replicas': 6, '_num_worker_replicas': 12, '_is_chief': True}
INFO:1587121814.7236319:tensorflow:Not using Distribute Coordinator.
I0417 11:10:14.723631 140220500707136 estimator_training.py:186] Not using Distribute Coordinator.
INFO:1587121814.7240767:tensorflow:Start Tensorflow server.
I0417 11:10:14.724076 140220500707136 training.py:744] Start Tensorflow server.
2020-04-17 11:10:14.731863: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:300] Initialize GrpcChannelCache for job master -> {0 -> localhost:2222}
2020-04-17 11:10:14.731898: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:300] Initialize GrpcChannelCache for job ps -> {0 -> tftestaccuracy6-testjob-temp-1-6-11-11-0-ps-0.ali.svc:2222, 1 -> tftestaccuracy6-testjob-temp-1-6-11-11-0-ps-1.ali.svc:2222, 2 -> tftestaccuracy6-testjob-temp-1-6-11-11-0-ps-2.ali.svc:2222, 3 -> tftestaccuracy6-testjob-temp-1-6-11-11-0-ps-3.ali.svc:2222, 4 -> tftestaccuracy6-testjob-temp-1-6-11-11-0-ps-4.ali.svc:2222, 5 -> tftestaccuracy6-testjob-temp-1-6-11-11-0-ps-5.ali.svc:2222}
2020-04-17 11:10:14.731910: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:300] Initialize GrpcChannelCache for job worker -> {0 -> tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-0.ali.svc:2222, 1 -> tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-1.ali.svc:2222, 2 -> tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-2.ali.svc:2222, 3 -> tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-3.ali.svc:2222, 4 -> tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-4.ali.svc:2222, 5 -> tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-5.ali.svc:2222, 6 -> tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-6.ali.svc:2222, 7 -> tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-7.ali.svc:2222, 8 -> tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-8.ali.svc:2222, 9 -> tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-9.ali.svc:2222, 10 -> tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-10.ali.svc:2222}
2020-04-17 11:10:14.733813: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:390] Started server with target: grpc://localhost:2222
WARNING:1587121814.7500741:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1635: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
Instructions for updating:
If using Keras pass *_constraint arguments to layers.
W0417 11:10:14.750074 140220500707136 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1635: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
Instructions for updating:
If using Keras pass *_constraint arguments to layers.
WARNING:1587121814.7521474:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0417 11:10:14.752147 140220500707136 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0417 11:10:14.775437 140220500707136 dataset_builder.py:199] Overwrite dataset info from restored data version.
I0417 11:10:14.781437 140220500707136 dataset_builder.py:285] Reusing dataset cifar10 (./dataDir/cifar10/3.0.0)
I0417 11:10:14.781795 140220500707136 dataset_builder.py:458] Constructing tf.data.Dataset for split train, from ./dataDir/cifar10/3.0.0
INFO:1587121814.9113212:tensorflow:Calling model_fn.
I0417 11:10:14.911321 140220500707136 estimator.py:1151] Calling model_fn.
INFO:1587121822.074707:tensorflow:Done calling model_fn.
I0417 11:10:22.074707 140220500707136 estimator.py:1153] Done calling model_fn.
INFO:1587121822.0750966:tensorflow:Warm-starting with WarmStartSettings: WarmStartSettings(ckpt_to_initialize_from='./out/tftestaccuracy6-testjob-temp-1-6-11-11-0/keras/keras_model.ckpt', vars_to_warm_start='.*', var_name_to_vocab_info={}, var_name_to_prev_var_name={})
I0417 11:10:22.075096 140220500707136 estimator.py:1372] Warm-starting with WarmStartSettings: WarmStartSettings(ckpt_to_initialize_from='./out/tftestaccuracy6-testjob-temp-1-6-11-11-0/keras/keras_model.ckpt', vars_to_warm_start='.*', var_name_to_vocab_info={}, var_name_to_prev_var_name={})
INFO:1587121822.075177:tensorflow:Warm-starting from: ./out/tftestaccuracy6-testjob-temp-1-6-11-11-0/keras/keras_model.ckpt
I0417 11:10:22.075176 140220500707136 warm_starting_util.py:464] Warm-starting from: ./out/tftestaccuracy6-testjob-temp-1-6-11-11-0/keras/keras_model.ckpt
INFO:1587121822.0752382:tensorflow:Warm-starting variables only in TRAINABLE_VARIABLES.
I0417 11:10:22.075238 140220500707136 warm_starting_util.py:343] Warm-starting variables only in TRAINABLE_VARIABLES.
INFO:1587121823.262496:tensorflow:Warm-started 214 variables.
I0417 11:10:23.262495 140220500707136 warm_starting_util.py:538] Warm-started 214 variables.
INFO:1587121823.2661114:tensorflow:Create CheckpointSaverHook.
I0417 11:10:23.266111 140220500707136 basic_session_run_hooks.py:546] Create CheckpointSaverHook.
INFO:1587121825.0649378:tensorflow:Graph was finalized.
I0417 11:10:25.064937 140220500707136 monitored_session.py:246] Graph was finalized.
tfds.core.DatasetInfo(
    name='cifar10',
    version=3.0.0,
    description='The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images.',
    homepage='https://www.cs.toronto.edu/~kriz/cifar.html',
    features=FeaturesDict({
        'image': Image(shape=(32, 32, 3), dtype=tf.uint8),
        'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=10),
    }),
    total_num_examples=60000,
    splits={
        'test': 10000,
        'train': 50000,
    },
    supervised_keys=('image', 'label'),
    citation=""""""@TECHREPORT{Krizhevsky09learningmultiple,
        author = {Alex Krizhevsky},
        title = {Learning multiple layers of features from tiny images},
        institution = {},
        year = {2009}
    }"""""",
    redistribution_info=,
)

Input data (batch size 64): <DatasetV1Adapter shapes: ((None, 128, 128, 3), (None,)), types: (tf.float32, tf.int64)>
+++++ Building Keras model +++++
Output of feature extraction (original model): (64, 4, 4, 2048)
Output of 0th classification layer (<tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D object at 0x7f86ec14b9e8>): (64, 2048)
Output of 1th classification layer (<tensorflow.python.keras.layers.core.Dense object at 0x7f86ec14bb38>): (64, 10)
Model: ""sequential_1""
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
resnet50 (Model)             (None, 4, 4, 2048)        23587712  
_________________________________________________________________
sequential (Sequential)      (None, 10)                20490     
=================================================================
Total params: 23,608,202
Trainable params: 23,555,082
Non-trainable params: 53,120
_________________________________________________________________
Model: ""sequential""
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
global_average_pooling2d (Gl (None, 2048)              0         
_________________________________________________________________
dense (Dense)                (None, 10)                20490     
=================================================================
Total params: 20,490
Trainable params: 20,490
Non-trainable params: 0
_________________________________________________________________
+++++ Train and evaluate the Estimator model +++++
tfds.core.DatasetInfo(
    name='cifar10',
    version=3.0.0,
    description='The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images.',
    homepage='https://www.cs.toronto.edu/~kriz/cifar.html',
    features=FeaturesDict({
        'image': Image(shape=(32, 32, 3), dtype=tf.uint8),
        'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=10),
    }),
    total_num_examples=60000,
    splits={
        'test': 10000,
        'train': 50000,
    },
    supervised_keys=('image', 'label'),
    citation=""""""@TECHREPORT{Krizhevsky09learningmultiple,
        author = {Alex Krizhevsky},
        title = {Learning multiple layers of features from tiny images},
        institution = {},
        year = {2009}
    }"""""",
    redistribution_info=,
)

Input data (batch size 64): <DatasetV1Adapter shapes: ((None, 128, 128, 3), (None,)), types: (tf.float32, tf.int64)>
Traceback (most recent call last):
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1367, in _do_call
    return fn(*args)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1352, in _run_fn
    target_list, run_metadata)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1445, in _call_tf_sessionrun
    run_metadata)
tensorflow.python.framework.errors_impl.DataLossError: From /job:ps/replica:0/task:3:
Checksum does not match: stored 3880206044 vs. calculated on the restored bytes 1782481297
	 [[{{node checkpoint_initializer_53}}]]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/app/keras_to_est.py"", line 242, in <module>
    app.run(main)
  File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""/app/keras_to_est.py"", line 227, in main
    tf.estimator.train_and_evaluate(model_est, train_spec, eval_spec)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py"", line 473, in train_and_evaluate
    return executor.run()
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py"", line 640, in run
    getattr(self, task_to_run)()
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py"", line 677, in run_master
    self._start_distributed_training(saving_listeners=saving_listeners)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py"", line 796, in _start_distributed_training
    saving_listeners=saving_listeners)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 374, in train
    loss = self._train_model(input_fn, hooks, saving_listeners)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1164, in _train_model
    return self._train_model_default(input_fn, hooks, saving_listeners)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1198, in _train_model_default
    saving_listeners)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1493, in _train_with_estimator_spec
    log_step_count_steps=log_step_count_steps) as mon_sess:
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 604, in MonitoredTrainingSession
    stop_grace_period_secs=stop_grace_period_secs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1038, in __init__
    stop_grace_period_secs=stop_grace_period_secs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 749, in __init__
    self._sess = _RecoverableSession(self._coordinated_creator)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1231, in __init__
    _WrappedSession.__init__(self, self._create_session())
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1236, in _create_session
    return self._sess_creator.create_session()
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 902, in create_session
    self.tf_sess = self._session_creator.create_session()
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 669, in create_session
    init_fn=self._scaffold.init_fn)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/session_manager.py"", line 300, in prepare_session
    sess.run(init_op, feed_dict=init_feed_dict)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 960, in run
    run_metadata_ptr)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1183, in _run
    feed_dict_tensor, options, run_metadata)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1361, in _do_run
    run_metadata)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1386, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.DataLossError: From /job:ps/replica:0/task:3:
Checksum does not match: stored 3880206044 vs. calculated on the restored bytes 1782481297
	 [[node checkpoint_initializer_53 (defined at usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py:1373) ]]

Original stack trace for 'checkpoint_initializer_53':
  File ""app/keras_to_est.py"", line 242, in <module>
    app.run(main)
  File ""usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""app/keras_to_est.py"", line 227, in main
    tf.estimator.train_and_evaluate(model_est, train_spec, eval_spec)
  File ""usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py"", line 473, in train_and_evaluate
    return executor.run()
  File ""usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py"", line 640, in run
    getattr(self, task_to_run)()
  File ""usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py"", line 677, in run_master
    self._start_distributed_training(saving_listeners=saving_listeners)
  File ""usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py"", line 796, in _start_distributed_training
    saving_listeners=saving_listeners)
  File ""usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 374, in train
    loss = self._train_model(input_fn, hooks, saving_listeners)
  File ""usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1164, in _train_model
    return self._train_model_default(input_fn, hooks, saving_listeners)
  File ""usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1198, in _train_model_default
    saving_listeners)
  File ""usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1373, in _train_with_estimator_spec
    warm_starting_util.warm_start(*self._warm_start_settings)
  File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/warm_starting_util.py"", line 533, in warm_start
    checkpoint_utils.init_from_checkpoint(ckpt_to_initialize_from, vocabless_vars)
  File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/checkpoint_utils.py"", line 291, in init_from_checkpoint
    init_from_checkpoint_fn)
  File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/distribute/distribute_lib.py"", line 1949, in merge_call
    return self._merge_call(merge_fn, args, kwargs)
  File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/distribute/distribute_lib.py"", line 1956, in _merge_call
    return merge_fn(self._strategy, *args, **kwargs)
  File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/checkpoint_utils.py"", line 286, in <lambda>
    ckpt_dir_or_file, assignment_map)
  File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/checkpoint_utils.py"", line 334, in _init_from_checkpoint
    _set_variable_or_list_initializer(var, ckpt_file, tensor_name_in_ckpt)
  File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/checkpoint_utils.py"", line 458, in _set_variable_or_list_initializer
    _set_checkpoint_initializer(variable_or_list, ckpt_file, tensor_name, """")
  File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/checkpoint_utils.py"", line 412, in _set_checkpoint_initializer
    ckpt_file, [tensor_name], [slice_spec], [base_type], name=name)[0]
  File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/gen_io_ops.py"", line 1506, in restore_v2
    name=name)
  File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/op_def_library.py"", line 742, in _apply_op_helper
    attrs=attr_protos, op_def=op_def)
  File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py"", line 3322, in _create_op_internal
    op_def=op_def)
  File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py"", line 1756, in __init__
    self._traceback = tf_stack.extract_stack()
```",ali-raza-tariq,b'models:official type:support',2020-04-28T17:08:59Z,2020-04-29T18:07:11Z,,,,,,,
8450,Error: cannot import name 'export_saved_model,"<!--


**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g., Pixel 4, Samsung Galaxy 10) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below):
- Python version:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

<!-- 
You can collect some of this information using our environment capture (https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 

1. TensorFlow 1.0
`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 

2. TensorFlow 2.0
`python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`
-->

**Please provide the entire URL of the model you are using?**
<!-- (e.g., https://github.com/tensorflow/models/tree/master/official/nlp/bert) -->

**Describe the current behavior**
Getting Error  while import from tensorflow.python.keras.saving.save import export_saved_model
Error 👍 cannot import name 'export_saved_model
 Tensorflow 2.2 version

**Describe the expected behavior**

**Code to reproduce the issue**
<!-- Provide a reproducible test case that is the bare minimum necessary to generate the problem. -->from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

from tensorflow.python.keras.saving.hdf5_format import load_attributes_from_hdf5_group
from tensorflow.python.keras.saving.hdf5_format import load_model_from_hdf5
from tensorflow.python.keras.saving.hdf5_format import load_weights_from_hdf5_group
from tensorflow.python.keras.saving.hdf5_format import load_weights_from_hdf5_group_by_name
from tensorflow.python.keras.saving.hdf5_format import preprocess_weights_for_loading
from tensorflow.python.keras.saving.hdf5_format import save_attributes_to_hdf5_group
from tensorflow.python.keras.saving.hdf5_format import save_model_to_hdf5
from tensorflow.python.keras.saving.hdf5_format import save_weights_to_hdf5_group
from tensorflow.python.keras.saving.model_config import model_from_config
from tensorflow.python.keras.saving.model_config import model_from_json
from tensorflow.python.keras.saving.model_config import model_from_yaml
from tensorflow.python.keras.saving.save import load_model
from tensorflow.python.keras.saving.save import save_model
from tensorflow.python.keras.saving.save import export_saved_model
from tensorflow.python.keras.saving.saved_model import load_from_saved_model
from tensorflow.python.keras.saving.saving_utils import trace_model_call

**Other info / logs**
<!-- Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. -->
",abhishekray2010,b'models:official type:bug',2020-04-28T14:25:26Z,2020-09-19T22:13:49Z,,,,,,,
8449,Inference hangs on GPU only when Eager is enabled,"<!--
Please make sure that this is a bug. 

As per our GitHub Policy (https://github.com/tensorflow/models/blob/master/ISSUES.md), we only address code bugs, documentation issues, and feature requests on GitHub.

Please go to Stack Overflow (http://stackoverflow.com/questions/tagged/tensorflow-model-garden) for help and support.

The research models (https://github.com/tensorflow/models/tree/master/research) are a large collection of models implemented in TensorFlow by researchers. They are not officially supported. It is up to the individual researchers to maintain the models and/or provide support on issues and pull requests.
-->

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
I made small changes (use of opencv to capture images) to the object_detection_tutorial file.
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- TensorFlow installed from (source or binary): python -m pip install tensorflow
- TensorFlow version (use command below): v2.1.0-rc2-17-ge5bf8de410 2.1.0
- Python version: 3.7
- CUDA/cuDNN version: 10.1 / 7.6.5.32
- GPU model and memory: GTX 960M 2GB or RTX2070 Super 8 GB

<!-- 
You can collect some of this information using our environment capture (https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 

1. TensorFlow 1.0
`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 

2. TensorFlow 2.0
`python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`
-->

**Describe the current behavior**
With GPU and Eager mode enabled, running inference hangs indefinitely after processing a few frames (<15).  
If I then disable Eager mode, it runs fine.

**Describe the expected behavior**
Being able to run inference without hangs with Eager mode enabled. 

**Code to reproduce the issue**

```
import os
import pathlib
import cv2
import numpy as np
import tensorflow as tf

from object_detection.utils import ops as utils_ops

def load_model(model_name):
    base_url = 'http://download.tensorflow.org/models/object_detection/'
    model_file = model_name + '.tar.gz'
    model_dir = tf.keras.utils.get_file(
        fname=model_name,
        origin=base_url + model_file,
        untar=True)
    model_dir = pathlib.Path(model_dir)/""saved_model""
    model = tf.saved_model.load(str(model_dir))
    model = model.signatures['serving_default']
    return model

def run_inference_for_single_image(model, image):
    image = np.asarray(image)
    input_tensor = tf.convert_to_tensor(image)
    input_tensor = input_tensor[tf.newaxis, ...]
    # Run inference
    print(""Inference start"")
    model(input_tensor)
    print(""Inference end"")

if ""models"" in pathlib.Path.cwd().parts:
    while ""models"" in pathlib.Path.cwd().parts:
        os.chdir('..')

#disable eager mode
#tf.compat.v1.disable_eager_execution()

MODELNAME = 'ssd_mobilenet_v1_coco_2017_11_17'
DETECTION_MODEL = load_model(MODELNAME)

utils_ops.tf = tf.compat.v1
tf.gfile = tf.io.gfile

IMGPATH = PATH_TO_IMAGE
IMAGE = cv2.cv2.imread(IMGPATH)

while True:
    run_inference_for_single_image(DETECTION_MODEL, IMAGE)
```
I ran this from the research\object_detection folder

**Other info / logs**
I am not sure how to support the claim of it being a bug. I tried it on different machines and the code is based on an example. I thought it was because there are no error or warning messages before hanging, it works fine when just using the CPU (with or without Eager mode), it works on GPU without Eager mode and it hangs in a library function.

I never did anything like this before. If i did something wrong or more information is required, please let me know. 
",McSlay,b'models:research type:bug',2020-04-28T13:39:44Z,2020-05-11T07:24:38Z,,,,,,,
8448,the pretrained model in multiprocessing,"hi,dear,
I have the problem in multiprocessing ,codes 
```
from multiprocessing.pool import ThreadPool
modelV3=tf.keras.applications.InceptionV3(include_top=False, pooling='avg')

def process(inputs):
    x_pred=modelV3.predict(inputs)
    return x_pred

x=np.random.randn(1,299,299,3)
y=np.random.randn(1,299,299,3)
z=np.random.randn(1,299,299,3)

pool=ThreadPool(2)
pool.map(process,[x,y,z])
```

**Error**:
```
Traceback (most recent call last):
  File ""D:\python36\new\xception_load_.py"", line 26, in <module>
    pool.map(process,[x,y,z])
  File ""D:\python36\lib\multiprocessing\pool.py"", line 266, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File ""D:\python36\lib\multiprocessing\pool.py"", line 644, in get
    raise self._value
  File ""D:\python36\lib\multiprocessing\pool.py"", line 119, in worker
    result = (True, func(*args, **kwds))
  File ""D:\python36\lib\multiprocessing\pool.py"", line 44, in mapstar
    return list(map(*args))
  File ""D:\python36\new\xception_load_.py"", line 18, in process
    x_pred=modelV3.predict(inputs)
  File ""D:\python36\lib\site-packages\tensorflow_core\python\keras\engine\training.py"", line 908, in predict
    use_multiprocessing=use_multiprocessing)
  File ""D:\python36\lib\site-packages\tensorflow_core\python\keras\engine\training_arrays.py"", line 723, in predict
    callbacks=callbacks)
  File ""D:\python36\lib\site-packages\tensorflow_core\python\keras\engine\training_arrays.py"", line 189, in model_iteration
    f = _make_execution_function(model, mode)
  File ""D:\python36\lib\site-packages\tensorflow_core\python\keras\engine\training_arrays.py"", line 566, in _make_execution_function
    return model._make_execution_function(mode)
  File ""D:\python36\lib\site-packages\tensorflow_core\python\keras\engine\training.py"", line 2189, in _make_execution_function
    self._make_predict_function()
  File ""D:\python36\lib\site-packages\tensorflow_core\python\keras\engine\training.py"", line 2179, in _make_predict_function
    **kwargs)
  File ""D:\python36\lib\site-packages\tensorflow_core\python\keras\backend.py"", line 3678, in function
    return GraphExecutionFunction(inputs, outputs, updates=updates, **kwargs)
  File ""D:\python36\lib\site-packages\tensorflow_core\python\keras\backend.py"", line 3330, in __init__
    with ops.control_dependencies([self.outputs[0]]):
  File ""D:\python36\lib\site-packages\tensorflow_core\python\framework\ops.py"", line 5254, in control_dependencies
    return get_default_graph().control_dependencies(control_inputs)
  File ""D:\python36\lib\site-packages\tensorflow_core\python\framework\ops.py"", line 4688, in control_dependencies
    c = self.as_graph_element(c)
  File ""D:\python36\lib\site-packages\tensorflow_core\python\framework\ops.py"", line 3607, in as_graph_element
    return self._as_graph_element_locked(obj, allow_tensor, allow_operation)
  File ""D:\python36\lib\site-packages\tensorflow_core\python\framework\ops.py"", line 3686, in _as_graph_element_locked
    raise ValueError(""Tensor %s is not an element of this graph."" % obj)
ValueError: Tensor Tensor(""global_average_pooling2d_1/Mean:0"", shape=(?, 2048), dtype=float32) is not an element of this graph.
```

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):win10 64
- TensorFlow installed from (source or binary):pip
- TensorFlow version (use command below):1.14
- Python version: 3.6.8
- CUDA/cuDNN version: NO
- GPU model and memory: No GPU


Could you pls help me ?
thx",ucas010,b'models:research type:bug',2020-04-28T04:12:07Z,2020-05-12T01:49:02Z,,,,,,,
8447,Added skimage troubleshooting,"Following exactly the installation instructions and running features matching, we encounter at features_matching.py from the skimage import. This is a known bug as indicated in the troubleshooting steps.

`Traceback (most recent call last):
  File ""match_images.py"", line 34, in <module>
    from skimage import feature
  File ""/nfs/core/python/3.6/lib/python3.6/site-packages/skimage/__init__.py"", line 158, in <module>
    from .util.dtype import *
  File ""/nfs/core/python/3.6/lib/python3.6/site-packages/skimage/util/__init__.py"", line 7, in <module>
    from .arraycrop import crop
  File ""/nfs/core/python/3.6/lib/python3.6/site-packages/skimage/util/arraycrop.py"", line 8, in <module>
    from numpy.lib.arraypad import _validate_lengths
ImportError: cannot import name '_validate_lengths'
`",Noezor,b'cla: yes',2020-04-27T17:31:53Z,2020-04-27T17:43:52Z,,,,,,,
8442,[Struct2depth]Cuda error out of memory for batch_size=1,"<!--
As per our GitHub Policy (https://github.com/tensorflow/models/blob/master/ISSUES.md), we only address code bugs, documentation issues, and feature requests on GitHub.

We will automatically close questions and help related issues.

Please go to Stack Overflow (http://stackoverflow.com/questions/tagged/tensorflow-model-garden) for questions and help.

-->@aneliaangelova  I have a rtx 2080ti with 10gb of gpu ram,but when I try to run the following command,i get a cuda out of memory error:

> python3 train.py   --logtostderr --checkpoint_dir /weights/   --data_dir /kitti_raw_eigen/    --architecture resnet --pretrained_ckpt /model-199160 --imagenet_norm true  --joint_encoder=False --handle_motion=True --batch_size=1

But when I changed the data_dir to some other part of the same dataset with more number of examples,I do not have any problem.
Any suggestion greatly appreciated.
Thankyou
 
",poornimajd,b'models:research type:support',2020-04-26T17:08:06Z,2020-04-26T19:45:15Z,,,,,,,
8441,KeyError: 'leonberger' in create_pet_tf_record.py with pets dataset,"Hello everybody.
i want to train the mask-rcnn on the oxford pets dataset.
i downloaded the pets dataset from this official link :[https://www.robots.ox.ac.uk/~vgg/data/pets/](url)
now it is required to convert raw dataset to tfrecord files with  **create_pet_tf_record.py** script.
but when i run this script , i face an issue like this :

> File ""/home/eagle-soft/anaconda3/lib/python3.7/site-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""new_create_pet_tf_record.py"", line 308, in main
    mask_type=FLAGS.mask_type)
  File ""new_create_pet_tf_record.py"", line 263, in create_tf_record
    mask_type=mask_type)
  File ""new_create_pet_tf_record.py"", line 169, in dict_to_tf_example
    classes.append(label_map_dict[class_name])
KeyError: 'leonberger'

it seems that the label_map_util.get_label_map_dict method returns an empty dictionary.
but i don't know how to solve this issue.
does anybody can help me ?
thank you ",naserpiltan,b'models:research type:bug',2020-04-26T10:00:55Z,2020-05-11T18:05:43Z,,,,,,,
8440,Train efficient-hrl on Point Maze environment,"<!--
Please make sure that this is a feature request. 

As per our GitHub Policy (https://github.com/tensorflow/models/blob/master/ISSUES.md), we only address code bugs, documentation issues, and feature requests on GitHub.

Please go to Stack Overflow (http://stackoverflow.com/questions/tagged/tensorflow-model-garden) for help and support.

The research models (https://github.com/tensorflow/models/tree/master/research) are a large collection of models implemented in TensorFlow by researchers. They are not officially supported. It is up to the individual researchers to maintain the models and/or provide support on issues and pull requests.
-->

**Please provide the entire URL of the model you are using?**
<!-- (e.g., https://github.com/tensorflow/models/tree/master/official/nlp/bert) -->
https://github.com/tensorflow/models/tree/master/research/efficient-hrl

**Describe the feature you request and the current behavior/state.**
Is it convenient to start a training job on Point Maze environment with the configuration file https://github.com/tensorflow/models/blob/master/research/efficient-hrl/context/configs/point_maze.gin ? I noticed that `point.xml` is missing from the assets directory (https://github.com/tensorflow/models/tree/master/research/efficient-hrl/environments/assets), so currently running `python scripts/local_train.py test1 hiro_orig point_maze base_uvf suite` would lead to `FileNotFoundError: [Errno 2] No such file or directory: 'environments/assets/point.xml'
  In call to configurable 'create_maze_env'`.

**Are you willing to contribute it (Yes/No)?**
No.

**Any other info.**
None.
",IrisLi17,b'models:research type:feature',2020-04-26T08:45:01Z,2020-04-26T15:23:53Z,,,,,,,
8435,tf.compat.v1.name_scope to tf.name_scope,"<!--
Please make sure that this is a feature request.

As per our GitHub Policy (https://github.com/tensorflow/models/blob/master/ISSUES.md), we only address code bugs, documentation issues, and feature requests on GitHub.

Please go to Stack Overflow (http://stackoverflow.com/questions/tagged/tensorflow-model-garden) for help and support.
-->

**Please provide the entire URL of the model you are using?**
<!-- (e.g., https://github.com/tensorflow/models/tree/master/official/nlp/bert) -->
https://github.com/tensorflow/models/blob/master/official/vision/image_classification/resnet/common.py

**Describe the feature you request and the current behavior/state.**
Since tf.name_scope is now avaliable in tf2.x, i propose to update it.
**Are you willing to contribute it (Yes/No)?**
Yes
**Any other info.**
",ayushmankumar7,b'models:official type:feature',2020-04-25T03:54:02Z,2020-04-26T14:05:22Z,,,,,,,
8433,BERT training using MirroredStrategy,"<!--
As per our GitHub Policy (https://github.com/tensorflow/models/blob/master/ISSUES.md), we only address code bugs, documentation issues, and feature requests on GitHub.

We will automatically close questions and help related issues.

Please go to Stack Overflow (http://stackoverflow.com/questions/tagged/tensorflow-model-garden) for questions and help.

-->

While going through the `run_customized_training_loop` function in BERT which is used for model training using multi-GPU I can't find the usage of `tf.distribute.Strategy.reduce`. How is the loss across multiple replicas are aggregated? @jharmsen @lehougoogle @chenGitHuber @saberkun 

https://www.tensorflow.org/guide/distributed_training#using_tfdistributestrategy_with_custom_training_loops",kamalkraj,b'type:support',2020-04-24T17:27:43Z,2020-04-25T07:09:58Z,,,,,,,
8432,Question about YAMNet input ,"
I am a first learner of YAMNet and VGGish.

When I use YAMNet/inference.py to predict different audios, I find out that all duration of audios(larger than 975ms) can be computed into features and input into the model. If there is long audio with multiple events, the inference can only give me top5 labels which describe the whole audio(which single event it belongs to).

I wanna ask why the duration can have this range(>=0.975)? What is the duration of the training input data? Is the inference result of the audio whose duration is different from the training reasonable? 

Thanks for your concern. @dpwe 
<!--
As per our GitHub Policy (https://github.com/tensorflow/models/blob/master/ISSUES.md), we only address code bugs, documentation issues, and feature requests on GitHub.

We will automatically close questions and help related issues.

Please go to Stack Overflow (http://stackoverflow.com/questions/tagged/tensorflow-model-garden) for questions and help.

-->
",NiborZ,b'models:research type:support',2020-04-24T09:36:57Z,2020-04-26T15:16:58Z,,,,,,,
8430,[Research][Struct2depth]Do rectangular masks for object motion work?,"<!--
As per our GitHub Policy (https://github.com/tensorflow/models/blob/master/ISSUES.md), we only address code bugs, documentation issues, and feature requests on GitHub.

We will automatically close questions and help related issues.

Please go to Stack Overflow (http://stackoverflow.com/questions/tagged/tensorflow-model-garden) for questions and help.

-->
Hi great work! @aneliaangelova  and team.
I am trying to generate masks for training the model to even learn object motion.
I have bounding boxes for my dataset,but to generate masks from it ,is it necessary for  it to be Run length encoding (RLE) format (used by Mask-RCNN) ?
I was wondering if it is fine to just generate masks from bounding box by 
[xmin,ymin:xmax,ymax]=[255,255,255] , and another instance [254,254,254] and so on ,so basically I will lose the shape of the object and all masks will be rectangular in shape.Since the model does not learn the shape but just the motion , so is this method correct or does it require the RLE masks itself?
Any suggestion is greatly appreciated.
Thank you
",poornimajd,b'type:support',2020-04-24T06:41:25Z,2020-04-24T21:46:01Z,,,,,,,
8429,FIFOQueue '_1_prefetch_queue/fifo_queue' is closed and has insufficient elements,"I run slim/train_image_classifier.py and used mobilenet_v2 fine-turning
I set up the relevant configuration according to the documentation， when i run .py, I got the bug:

`INFO:tensorflow:Caught OutOfRangeError. Stopping Training. FIFOQueue '_1_prefetch_queue/fifo_queue' is closed and has insufficient elements (requested 1, current size 0)
	 [[node fifo_queue_Dequeue (defined at E:/sence-classification/models/research/slim/train_image_classifier.py:488) ]]`

`tensorflow.python.framework.errors_impl.DataLossError: corrupted record at 0
	 [[{{node parallel_read/ReaderReadV2_1}}]]`

How can i solve it？

Thanks！",Ijustakid,b'models:research type:bug',2020-04-24T06:29:01Z,2020-04-24T06:57:39Z,,,,,,,
8423,Exploding loss after few iterations of training  of Faster RCNN ResNet50 ,"**System information**
**What is the top-level directory of the model you are using:**
object_detection

**Have I written custom code (as opposed to using a stock example script provided in TensorFlow):**
use train.py script on my own dataset

**OS Platform and Distribution (e.g., Linux Ubuntu 16.04):**
Using google collab

**TensorFlow installed from (source or binary):**
changed to %tensorflow_version 1.x  (in collab)

**TensorFlow version (use command below):**
1.15.2

**CUDA/cuDNN version:**
Using google collab

**GPU model and memory:**
12GB NVIDIA Tesla K80 GP(I guess as its google collab)


I am using **faster_rcnn_resnet50_coco** and facing  problem of exploding loss after few iteration of training

- I relabelled my dataset from scratch too to avoid any annotation error .

- I rechecked labelmap.pbtxt many times .

- I rechecked classes and also I tried to change different learning rates and gradient clipping .

- My tfrecord is good too

- I recheck csv files which created .

I am training on only one class but gradient is exploding after few iterations exponentially please help. I am using dataset **Penn-Fudan Database for Pedestrian Detection**

Following is my config file

model {
faster_rcnn {
num_classes: 1
image_resizer {
keep_aspect_ratio_resizer {
min_dimension: 400
max_dimension: 600
}
}
feature_extractor {
type: 'faster_rcnn_resnet50'
first_stage_features_stride: 16
}
first_stage_anchor_generator {
grid_anchor_generator {
scales: [0.25, 0.5, 1.0, 2.0]
aspect_ratios: [0.5, 1.0, 2.0]
height_stride: 16
width_stride: 16
}
}
first_stage_box_predictor_conv_hyperparams {
op: CONV
regularizer {
l2_regularizer {
weight: 0.0
}
}
initializer {
truncated_normal_initializer {
stddev: 0.01
}
}
}
first_stage_nms_score_threshold: 0.0
first_stage_nms_iou_threshold: 0.7
first_stage_max_proposals: 300
first_stage_localization_loss_weight: 2.0
first_stage_objectness_loss_weight: 1.0
initial_crop_size: 14
maxpool_kernel_size: 2
maxpool_stride: 2
second_stage_box_predictor {
mask_rcnn_box_predictor {
use_dropout: false
dropout_keep_probability: 1.0
fc_hyperparams {
op: FC
regularizer {
l2_regularizer {
weight: 0.0
}
}
initializer {
variance_scaling_initializer {
factor: 1.0
uniform: true
mode: FAN_AVG
}
}
}
}
}
second_stage_post_processing {
batch_non_max_suppression {
score_threshold: 0.0
iou_threshold: 0.6
max_detections_per_class: 100
max_total_detections: 300
}
score_converter: SIGMOID
}
second_stage_localization_loss_weight: 2.0
second_stage_classification_loss_weight: 1.0
}
}

train_config: {
batch_size: 1
optimizer {
momentum_optimizer: {
learning_rate: {
manual_step_learning_rate {
initial_learning_rate: 0.0001
schedule {
step: 900000
learning_rate: .000001
}
schedule {
step: 1200000
learning_rate: .000001
}
}
}
momentum_optimizer_value: 0.9
}
use_moving_average: false
}
gradient_clipping_by_norm: 5.0
fine_tune_checkpoint: ""/content/drive/My Drive/Tensorflow/models/faster_rcnn_resnet50_coco_2018_01_28/model.ckpt""
from_detection_checkpoint: true

num_steps: 200000
data_augmentation_options {
random_horizontal_flip {
}
}
}

train_input_reader: {
tf_record_input_reader {
input_path: ""/content/drive/My Drive/Tensorflow/models/train.record""
}
label_map_path: ""/content/drive/My Drive/Tensorflow/models/training/labelmap.pbtxt""
}

eval_config: {
num_examples: 36

max_evals: 10
}

eval_input_reader: {
tf_record_input_reader {
input_path: ""/content/drive/My Drive/Tensorflow/models/test.record""
}
label_map_path: ""/content/drive/My Drive/Tensorflow/models/training/labelmap.pbtxt""
shuffle: false
num_readers: 1
}



**My training log**

I0422 07:09:55.320835 140486560917376 learning.py:507] global step 374: loss = 0.2636 (0.294 sec/step)
INFO:tensorflow:global step 375: loss = 0.6618 (0.306 sec/step)
I0422 07:09:55.628338 140486560917376 learning.py:507] global step 375: loss = 0.6618 (0.306 sec/step)
INFO:tensorflow:global step 376: loss = 0.3663 (0.289 sec/step)
I0422 07:09:55.919772 140486560917376 learning.py:507] global step 376: loss = 0.3663 (0.289 sec/step)
INFO:tensorflow:global step 377: loss = 0.2678 (0.292 sec/step)
I0422 07:09:56.213927 140486560917376 learning.py:507] global step 377: loss = 0.2678 (0.292 sec/step)
INFO:tensorflow:global step 378: loss = 0.3992 (0.293 sec/step)
I0422 07:09:56.509216 140486560917376 learning.py:507] global step 378: loss = 0.3992 (0.293 sec/step)
INFO:tensorflow:global step 379: loss = 0.4918 (0.264 sec/step)
I0422 07:09:56.775810 140486560917376 learning.py:507] global step 379: loss = 0.4918 (0.264 sec/step)
INFO:tensorflow:global step 380: loss = 0.2143 (0.269 sec/step)
I0422 07:09:57.046996 140486560917376 learning.py:507] global step 380: loss = 0.2143 (0.269 sec/step)
INFO:tensorflow:global step 381: loss = 1.0149 (0.273 sec/step)
I0422 07:09:57.321473 140486560917376 learning.py:507] global step 381: loss = 1.0149 (0.273 sec/step)
INFO:tensorflow:global step 382: loss = 0.2884 (0.262 sec/step)
I0422 07:09:57.585358 140486560917376 learning.py:507] global step 382: loss = 0.2884 (0.262 sec/step)
INFO:tensorflow:global step 383: loss = 0.3797 (0.289 sec/step)
I0422 07:09:57.876454 140486560917376 learning.py:507] global step 383: loss = 0.3797 (0.289 sec/step)
INFO:tensorflow:global step 384: loss = 0.6466 (0.306 sec/step)
I0422 07:09:58.183916 140486560917376 learning.py:507] global step 384: loss = 0.6466 (0.306 sec/step)
INFO:tensorflow:global step 385: loss = 0.0887 (0.271 sec/step)
I0422 07:09:58.457142 140486560917376 learning.py:507] global step 385: loss = 0.0887 (0.271 sec/step)
INFO:tensorflow:global step 386: loss = 0.7238 (0.297 sec/step)
I0422 07:09:58.756018 140486560917376 learning.py:507] global step 386: loss = 0.7238 (0.297 sec/step)
INFO:tensorflow:global step 387: loss = 0.8665 (0.314 sec/step)
I0422 07:09:59.072811 140486560917376 learning.py:507] global step 387: loss = 0.8665 (0.314 sec/step)
INFO:tensorflow:global step 388: loss = 1.0504 (0.292 sec/step)
I0422 07:09:59.366814 140486560917376 learning.py:507] global step 388: loss = 1.0504 (0.292 sec/step)
INFO:tensorflow:global step 389: loss = 1.0150 (0.290 sec/step)
I0422 07:09:59.661545 140486560917376 learning.py:507] global step 389: loss = 1.0150 (0.290 sec/step)
INFO:tensorflow:global step 390: loss = 0.6820 (0.284 sec/step)
I0422 07:09:59.947800 140486560917376 learning.py:507] global step 390: loss = 0.6820 (0.284 sec/step)
INFO:tensorflow:global step 391: loss = 1.7842 (0.266 sec/step)
I0422 07:10:00.215992 140486560917376 learning.py:507] global step 391: loss = 1.7842 (0.266 sec/step)
INFO:tensorflow:global step 392: loss = 5.3590 (0.257 sec/step)
I0422 07:10:00.474348 140486560917376 learning.py:507] global step 392: loss = 5.3590 (0.257 sec/step)
INFO:tensorflow:global step 393: loss = 5.0548 (0.304 sec/step)
I0422 07:10:00.780560 140486560917376 learning.py:507] global step 393: loss = 5.0548 (0.304 sec/step)
INFO:tensorflow:global step 394: loss = 7.1372 (0.302 sec/step)
I0422 07:10:01.084518 140486560917376 learning.py:507] global step 394: loss = 7.1372 (0.302 sec/step)
INFO:tensorflow:global step 395: loss = 0.3071 (0.259 sec/step)
I0422 07:10:01.345200 140486560917376 learning.py:507] global step 395: loss = 0.3071 (0.259 sec/step)
INFO:tensorflow:global step 396: loss = 33.3896 (0.267 sec/step)
I0422 07:10:01.613836 140486560917376 learning.py:507] global step 396: loss = 33.3896 (0.267 sec/step)
INFO:tensorflow:global step 397: loss = 0.1341 (0.285 sec/step)
I0422 07:10:01.900630 140486560917376 learning.py:507] global step 397: loss = 0.1341 (0.285 sec/step)
INFO:tensorflow:global step 398: loss = 20.5861 (0.252 sec/step)
I0422 07:10:02.154454 140486560917376 learning.py:507] global step 398: loss = 20.5861 (0.252 sec/step)
INFO:tensorflow:global step 399: loss = 0.2996 (0.260 sec/step)
I0422 07:10:02.416572 140486560917376 learning.py:507] global step 399: loss = 0.2996 (0.260 sec/step)
INFO:tensorflow:global step 400: loss = 53.6560 (0.276 sec/step)
I0422 07:10:02.693947 140486560917376 learning.py:507] global step 400: loss = 53.6560 (0.276 sec/step)
INFO:tensorflow:global step 401: loss = 354.2955 (0.303 sec/step)
I0422 07:10:02.998691 140486560917376 learning.py:507] global step 401: loss = 354.2955 (0.303 sec/step)
INFO:tensorflow:global step 402: loss = 138.3654 (0.270 sec/step)
I0422 07:10:03.271044 140486560917376 learning.py:507] global step 402: loss = 138.3654 (0.270 sec/step)
INFO:tensorflow:global step 403: loss = 81.3835 (0.292 sec/step)
I0422 07:10:03.565308 140486560917376 learning.py:507] global step 403: loss = 81.3835 (0.292 sec/step)
INFO:tensorflow:global step 404: loss = 2043.4795 (0.282 sec/step)
I0422 07:10:03.848872 140486560917376 learning.py:507] global step 404: loss = 2043.4795 (0.282 sec/step)
INFO:tensorflow:global step 405: loss = 0.0435 (0.297 sec/step)
I0422 07:10:04.148034 140486560917376 learning.py:507] global step 405: loss = 0.0435 (0.297 sec/step)
INFO:tensorflow:global step 406: loss = 7290.5103 (0.267 sec/step)
I0422 07:10:04.417101 140486560917376 learning.py:507] global step 406: loss = 7290.5103 (0.267 sec/step)
INFO:tensorflow:global step 407: loss = 7957.7422 (0.261 sec/step)
I0422 07:10:04.680258 140486560917376 learning.py:507] global step 407: loss = 7957.7422 (0.261 sec/step)
INFO:tensorflow:global step 408: loss = 0.1442 (0.302 sec/step)
I0422 07:10:04.984018 140486560917376 learning.py:507] global step 408: loss = 0.1442 (0.302 sec/step)
INFO:tensorflow:global step 409: loss = 25237.8984 (0.273 sec/step)
I0422 07:10:05.258542 140486560917376 learning.py:507] global step 409: loss = 25237.8984 (0.273 sec/step)
INFO:tensorflow:global step 410: loss = 75835.2812 (0.319 sec/step)
I0422 07:10:05.579621 140486560917376 learning.py:507] global step 410: loss = 75835.2812 (0.319 sec/step)
INFO:tensorflow:global step 411: loss = 28575.1914 (0.250 sec/step)
I0422 07:10:05.832293 140486560917376 learning.py:507] global step 411: loss = 28575.1914 (0.250 sec/step)
INFO:tensorflow:global step 412: loss = 134869.8906 (0.293 sec/step)
I0422 07:10:06.129227 140486560917376 learning.py:507] global step 412: loss = 134869.8906 (0.293 sec/step)
INFO:tensorflow:global step 413: loss = 437442.4062 (0.296 sec/step)
I0422 07:10:06.427104 140486560917376 learning.py:507] global step 413: loss = 437442.4062 (0.296 sec/step)
INFO:tensorflow:global step 414: loss = 212268.4531 (0.255 sec/step)
I0422 07:10:06.684252 140486560917376 learning.py:507] global step 414: loss = 212268.4531 (0.255 sec/step)
INFO:tensorflow:global step 415: loss = 1216893.1250 (0.276 sec/step)
I0422 07:10:06.961721 140486560917376 learning.py:507] global step 415: loss = 1216893.1250 (0.276 sec/step)
INFO:tensorflow:global step 416: loss = 0.1749 (0.262 sec/step)
I0422 07:10:07.225651 140486560917376 learning.py:507] global step 416: loss = 0.1749 (0.262 sec/step)
INFO:tensorflow:global step 417: loss = 2736256.2500 (0.312 sec/step)
I0422 07:10:07.539854 140486560917376 learning.py:507] global step 417: loss = 2736256.2500 (0.312 sec/step)
INFO:tensorflow:global step 418: loss = 4241052.0000 (0.263 sec/step)
I0422 07:10:07.805094 140486560917376 learning.py:507] global step 418: loss = 4241052.0000 (0.263 sec/step)
INFO:tensorflow:global step 419: loss = 4462876.0000 (0.266 sec/step)
I0422 07:10:08.073152 140486560917376 learning.py:507] global step 419: loss = 4462876.0000 (0.266 sec/step)
INFO:tensorflow:global step 420: loss = 18808836.0000 (0.295 sec/step)
I0422 07:10:08.370062 140486560917376 learning.py:507] global step 420: loss = 18808836.0000 (0.295 sec/step)
INFO:tensorflow:global step 421: loss = 96460304.0000 (0.288 sec/step)
I0422 07:10:08.660426 140486560917376 learning.py:507] global step 421: loss = 96460304.0000 (0.288 sec/step)
INFO:tensorflow:global step 422: loss = 85134320.0000 (0.320 sec/step)
I0422 07:10:08.982865 140486560917376 learning.py:507] global step 422: loss = 85134320.0000 (0.320 sec/step)
INFO:tensorflow:global step 423: loss = 364593632.0000 (0.257 sec/step)
I0422 07:10:09.241693 140486560917376 learning.py:507] global step 423: loss = 364593632.0000 (0.257 sec/step)
INFO:tensorflow:global step 424: loss = 159115248.0000 (0.267 sec/step)
I0422 07:10:09.510233 140486560917376 learning.py:507] global step 424: loss = 159115248.0000 (0.267 sec/step)
INFO:tensorflow:global step 425: loss = 854715264.0000 (0.312 sec/step)
I0422 07:10:09.823988 140486560917376 learning.py:507] global step 425: loss = 854715264.0000 (0.312 sec/step)
INFO:tensorflow:global step 426: loss = 3067453952.0000 (0.296 sec/step)
I0422 07:10:10.121925 140486560917376 learning.py:507] global step 426: loss = 3067453952.0000 (0.296 sec/step)
INFO:tensorflow:global step 427: loss = 3518234624.0000 (0.291 sec/step)
I0422 07:10:10.414811 140486560917376 learning.py:507] global step 427: loss = 3518234624.0000 (0.291 sec/step)
INFO:tensorflow:global step 428: loss = 17210691584.0000 (0.327 sec/step)
I0422 07:10:10.743706 140486560917376 learning.py:507] global step 428: loss = 17210691584.0000 (0.327 sec/step)
INFO:tensorflow:global step 429: loss = 22827235328.0000 (0.298 sec/step)
I0422 07:10:11.043578 140486560917376 learning.py:507] global step 429: loss = 22827235328.0000 (0.298 sec/step)
INFO:tensorflow:global step 430: loss = 99799859200.0000 (0.263 sec/step)
I0422 07:10:11.308007 140486560917376 learning.py:507] global step 430: loss = 99799859200.0000 (0.263 sec/step)
INFO:tensorflow:global step 431: loss = 0.7569 (0.287 sec/step)
I0422 07:10:11.596587 140486560917376 learning.py:507] global step 431: loss = 0.7569 (0.287 sec/step)
INFO:tensorflow:global step 432: loss = 164616962048.0000 (0.323 sec/step)
I0422 07:10:11.922135 140486560917376 learning.py:507] global step 432: loss = 164616962048.0000 (0.323 sec/step)
INFO:tensorflow:global step 433: loss = 598838804480.0000 (0.267 sec/step)
I0422 07:10:12.191077 140486560917376 learning.py:507] global step 433: loss = 598838804480.0000 (0.267 sec/step)
INFO:tensorflow:global step 434: loss = 171039686656.0000 (0.285 sec/step)
I0422 07:10:12.478295 140486560917376 learning.py:507] global step 434: loss = 171039686656.0000 (0.285 sec/step)
INFO:tensorflow:global step 435: loss = 0.1586 (0.294 sec/step)
I0422 07:10:12.774455 140486560917376 learning.py:507] global step 435: loss = 0.1586 (0.294 sec/step)
INFO:tensorflow:global step 436: loss = 11961404227584.0000 (0.264 sec/step)
I0422 07:10:13.040502 140486560917376 learning.py:507] global step 436: loss = 11961404227584.0000 (0.264 sec/step)
INFO:tensorflow:global step 437: loss = 10615577903104.0000 (0.297 sec/step)
I0422 07:10:13.339689 140486560917376 learning.py:507] global step 437: loss = 10615577903104.0000 (0.297 sec/step)
INFO:tensorflow:global step 438: loss = 6634327769088.0000 (0.262 sec/step)
I0422 07:10:13.603152 140486560917376 learning.py:507] global step 438: loss = 6634327769088.0000 (0.262 sec/step)
INFO:tensorflow:global step 439: loss = 0.0360 (0.265 sec/step)
I0422 07:10:13.870558 140486560917376 learning.py:507] global step 439: loss = 0.0360 (0.265 sec/step)
INFO:tensorflow:global step 440: loss = 15168851410944.0000 (0.312 sec/step)
I0422 07:10:14.184696 140486560917376 learning.py:507] global step 440: loss = 15168851410944.0000 (0.312 sec/step)
INFO:tensorflow:global step 441: loss = 0.3786 (0.265 sec/step)
I0422 07:10:14.451148 140486560917376 learning.py:507] global step 441: loss = 0.3786 (0.265 sec/step)
INFO:tensorflow:global step 442: loss = 204700758573056.0000 (0.258 sec/step)
I0422 07:10:14.711573 140486560917376 learning.py:507] global step 442: loss = 204700758573056.0000 (0.258 sec/step)
INFO:tensorflow:global step 443: loss = 0.0319 (0.262 sec/step)
I0422 07:10:14.974974 140486560917376 learning.py:507] global step 443: loss = 0.0319 (0.262 sec/step)
INFO:tensorflow:global step 444: loss = 1549614536720384.0000 (0.273 sec/step)
I0422 07:10:15.250102 140486560917376 learning.py:507] global step 444: loss = 1549614536720384.0000 (0.273 sec/step)
INFO:tensorflow:global step 445: loss = 706502994165760.0000 (0.280 sec/step)
I0422 07:10:15.532128 140486560917376 learning.py:507] global step 445: loss = 706502994165760.0000 (0.280 sec/step)
INFO:tensorflow:global step 446: loss = 1583030992896000.0000 (0.292 sec/step)
I0422 07:10:15.825623 140486560917376 learning.py:507] global step 446: loss = 1583030992896000.0000 (0.292 sec/step)
INFO:tensorflow:global step 447: loss = 11534830458109952.0000 (0.286 sec/step)
I0422 07:10:16.113319 140486560917376 learning.py:507] global step 447: loss = 11534830458109952.0000 (0.286 sec/step)
INFO:tensorflow:global step 448: loss = 28171772826222592.0000 (0.310 sec/step)
I0422 07:10:16.424631 140486560917376 learning.py:507] global step 448: loss = 28171772826222592.0000 (0.310 sec/step)
INFO:tensorflow:global step 449: loss = 33334265533956096.0000 (0.271 sec/step)
I0422 07:10:16.697575 140486560917376 learning.py:507] global step 449: loss = 33334265533956096.0000 (0.271 sec/step)
INFO:tensorflow:global step 450: loss = 0.0328 (0.276 sec/step)
I0422 07:10:16.975500 140486560917376 learning.py:507] global step 450: loss = 0.0328 (0.276 sec/step)
INFO:tensorflow:global step 451: loss = 0.0162 (0.274 sec/step)
I0422 07:10:17.251272 140486560917376 learning.py:507] global step 451: loss = 0.0162 (0.274 sec/step)
INFO:tensorflow:global step 452: loss = 67449892993236992.0000 (0.313 sec/step)
I0422 07:10:17.565719 140486560917376 learning.py:507] global step 452: loss = 67449892993236992.0000 (0.313 sec/step)
INFO:tensorflow:global step 453: loss = 95736882612142080.0000 (0.263 sec/step)
I0422 07:10:17.831138 140486560917376 learning.py:507] global step 453: loss = 95736882612142080.0000 (0.263 sec/step)
INFO:tensorflow:global step 454: loss = 266017148894183424.0000 (0.280 sec/step)
I0422 07:10:18.112651 140486560917376 learning.py:507] global step 454: loss = 266017148894183424.0000 (0.280 sec/step)
INFO:tensorflow:global step 455: loss = 903144486052298752.0000 (0.298 sec/step)
I0422 07:10:18.412338 140486560917376 learning.py:507] global step 455: loss = 903144486052298752.0000 (0.298 sec/step)
INFO:tensorflow:global step 456: loss = 2083570548905869312.0000 (0.286 sec/step)
I0422 07:10:18.700075 140486560917376 learning.py:507] global step 456: loss = 2083570548905869312.0000 (0.286 sec/step)
INFO:tensorflow:global step 457: loss = 845515095910907904.0000 (0.269 sec/step)
I0422 07:10:18.971438 140486560917376 learning.py:507] global step 457: loss = 845515095910907904.0000 (0.269 sec/step)
INFO:tensorflow:global step 458: loss = 1061061568713719808.0000 (0.272 sec/step)
I0422 07:10:19.245239 140486560917376 learning.py:507] global step 458: loss = 1061061568713719808.0000 (0.272 sec/step)

**I am using google collab having following libraries**
absl-py==0.9.0
alabaster==0.7.12
albumentations==0.1.12
altair==4.1.0
asgiref==3.2.7
astor==0.8.1
astropy==4.0.1.post1
astunparse==1.6.3
atari-py==0.2.6
atomicwrites==1.3.0
attrs==19.3.0
audioread==2.1.8
autograd==1.3
Babel==2.8.0
backcall==0.1.0
backports.tempfile==1.0
backports.weakref==1.0.post1
beautifulsoup4==4.6.3
bleach==3.1.4
blis==0.4.1
bokeh==1.4.0
boto==2.49.0
boto3==1.12.40
botocore==1.15.40
Bottleneck==1.3.2
branca==0.4.0
bs4==0.0.1
bz2file==0.98
CacheControl==0.12.6
cachetools==3.1.1
catalogue==1.0.0
certifi==2020.4.5.1
cffi==1.14.0
chainer==6.5.0
chardet==3.0.4
click==7.1.1
cloudpickle==1.3.0
cmake==3.12.0
cmdstanpy==0.4.0
colorlover==0.3.0
community==1.0.0b1
contextlib2==0.5.5
convertdate==2.2.0
coverage==3.7.1
coveralls==0.5
crcmod==1.7
cufflinks==0.17.3
cupy-cuda101==6.5.0
cvxopt==1.2.5
cvxpy==1.0.31
cycler==0.10.0
cymem==2.0.3
Cython==0.29.16
daft==0.0.4
dask==2.12.0
dataclasses==0.7
datascience==0.10.6
decorator==4.4.2
defusedxml==0.6.0
descartes==1.1.0
dill==0.3.1.1
distributed==1.25.3
Django==3.0.5
dlib==19.18.0
dm-sonnet==1.35
docopt==0.6.2
docutils==0.15.2
dopamine-rl==1.0.5
earthengine-api==0.1.218
easydict==1.9
ecos==2.0.7.post1
editdistance==0.5.3
en-core-web-sm==2.2.5
entrypoints==0.3
ephem==3.7.7.1
et-xmlfile==1.0.1
fa2==0.3.5
fancyimpute==0.4.3
fastai==1.0.60
fastdtw==0.3.4
fastprogress==0.2.3
fastrlock==0.4
fbprophet==0.6
feather-format==0.4.0
featuretools==0.4.1
filelock==3.0.12
firebase-admin==4.0.1
fix-yahoo-finance==0.0.22
Flask==1.1.2
folium==0.8.3
fsspec==0.7.2
future==0.16.0
gast==0.3.3
GDAL==2.2.2
gdown==3.6.4
gensim==3.6.0
geographiclib==1.50
geopy==1.17.0
gevent==1.4.0
gin-config==0.3.0
glob2==0.7
google==2.0.3
google-api-core==1.16.0
google-api-python-client==1.7.12
google-auth==1.7.2
google-auth-httplib2==0.0.3
google-auth-oauthlib==0.4.1
google-cloud-bigquery==1.21.0
google-cloud-core==1.0.3
google-cloud-datastore==1.8.0
google-cloud-firestore==1.6.2
google-cloud-language==1.2.0
google-cloud-storage==1.18.1
google-cloud-translate==1.5.0
google-colab==1.0.0
google-pasta==0.2.0
google-resumable-media==0.4.1
googleapis-common-protos==1.51.0
googledrivedownloader==0.4
graph-nets==1.0.5
graphviz==0.10.1
greenlet==0.4.15
grpcio==1.28.1
gspread==3.0.1
gspread-dataframe==3.0.5
gunicorn==20.0.4
gym==0.17.1
h5py==2.10.0
HeapDict==1.0.1
holidays==0.9.12
html5lib==1.0.1
httpimport==0.5.18
httplib2==0.17.2
httplib2shim==0.0.3
humanize==0.5.1
hyperopt==0.1.2
ideep4py==2.0.0.post3
idna==2.8
image==1.5.30
imageio==2.4.1
imagesize==1.2.0
imbalanced-learn==0.4.3
imblearn==0.0
imgaug==0.2.9
importlib-metadata==1.6.0
imutils==0.5.3
inflect==2.1.0
intel-openmp==2020.0.133
intervaltree==2.1.0
ipykernel==4.10.1
ipython==5.5.0
ipython-genutils==0.2.0
ipython-sql==0.3.9
ipywidgets==7.5.1
itsdangerous==1.1.0
jax==0.1.62
jaxlib==0.1.42
jdcal==1.4.1
jedi==0.17.0
jieba==0.42.1
Jinja2==2.11.2
jmespath==0.9.5
joblib==0.14.1
jpeg4py==0.1.4
jsonschema==2.6.0
jupyter==1.0.0
jupyter-client==5.3.4
jupyter-console==5.2.0
jupyter-core==4.6.3
kaggle==1.5.6
kapre==0.1.3.1
Keras==2.3.1
Keras-Applications==1.0.8
Keras-Preprocessing==1.1.0
keras-vis==0.4.1
kfac==0.2.0
kiwisolver==1.2.0
knnimpute==0.1.0
librosa==0.6.3
lightgbm==2.2.3
llvmlite==0.31.0
lmdb==0.98
lucid==0.3.8
LunarCalendar==0.0.9
lxml==4.2.6
magenta==0.3.19
Markdown==3.2.1
MarkupSafe==1.1.1
matplotlib==3.2.1
matplotlib-venn==0.11.5
mesh-tensorflow==0.1.12
mido==1.2.6
mir-eval==0.5
missingno==0.4.2
mistune==0.8.4
mizani==0.6.0
mkl==2019.0
mlxtend==0.14.0
more-itertools==8.2.0
moviepy==0.2.3.5
mpi4py==3.0.3
mpmath==1.1.0
msgpack==1.0.0
multiprocess==0.70.9
multitasking==0.0.9
murmurhash==1.0.2
music21==5.5.0
natsort==5.5.0
nbconvert==5.6.1
nbformat==5.0.5
networkx==2.4
nibabel==3.0.2
nltk==3.2.5
notebook==5.2.2
np-utils==0.5.12.1
numba==0.48.0
numexpr==2.7.1
numpy==1.18.2
nvidia-ml-py3==7.352.0
oauth2client==4.1.3
oauthlib==3.1.0
object-detection==0.1
okgrade==0.4.3
opencv-contrib-python==4.1.2.30
opencv-python==4.1.2.30
openpyxl==2.5.9
opt-einsum==3.2.1
osqp==0.6.1
packaging==20.3
palettable==3.3.0
pandas==1.0.3
pandas-datareader==0.8.1
pandas-gbq==0.11.0
pandas-profiling==1.4.1
pandocfilters==1.4.2
parso==0.7.0
pathlib==1.0.1
patsy==0.5.1
pexpect==4.8.0
pickleshare==0.7.5
Pillow==7.0.0
pip-tools==4.5.1
plac==1.1.3
plotly==4.4.1
plotnine==0.6.0
pluggy==0.7.1
portpicker==1.3.1
prefetch-generator==1.0.1
preshed==3.0.2
pretty-midi==0.2.8
prettytable==0.7.2
progressbar2==3.38.0
prometheus-client==0.7.1
promise==2.3
prompt-toolkit==1.0.18
protobuf==3.10.0
psutil==5.4.8
psycopg2==2.7.6.1
ptvsd==5.0.0a12
ptyprocess==0.6.0
py==1.8.1
pyarrow==0.14.1
pyasn1==0.4.8
pyasn1-modules==0.2.8
pycocotools==2.0.0
pycparser==2.20
pydata-google-auth==0.3.0
pydot==1.3.0
pydot-ng==2.0.0
pydotplus==2.0.2
PyDrive==1.3.1
pyemd==0.5.1
pyglet==1.5.0
Pygments==2.1.3
pygobject==3.26.1
pymc3==3.7
PyMeeus==0.3.7
pymongo==3.10.1
pymystem3==0.2.0
PyOpenGL==3.1.5
pyparsing==2.4.7
pypng==0.0.20
pyrsistent==0.16.0
pysndfile==1.3.8
PySocks==1.7.1
pystan==2.19.1.1
pytest==3.6.4
python-apt==1.6.5+ubuntu0.2
python-chess==0.23.11
python-dateutil==2.8.1
python-louvain==0.14
python-rtmidi==1.4.0
python-slugify==4.0.0
python-utils==2.4.0
pytz==2018.9
PyWavelets==1.1.1
PyYAML==3.13
pyzmq==19.0.0
qtconsole==4.7.3
QtPy==1.9.0
regex==2019.12.20
requests==2.21.0
requests-oauthlib==1.3.0
resampy==0.2.2
retrying==1.3.3
rpy2==3.2.7
rsa==4.0
s3fs==0.4.2
s3transfer==0.3.3
scikit-image==0.16.2
scikit-learn==0.22.2.post1
scipy==1.4.1
screen-resolution-extra==0.0.0
scs==2.1.2
seaborn==0.10.0
semantic-version==2.8.4
Send2Trash==1.5.0
setuptools-git==1.2
Shapely==1.7.0
simplegeneric==0.8.1
six==1.12.0
sklearn==0.0
sklearn-pandas==1.8.0
smart-open==1.11.1
snowballstemmer==2.0.0
sortedcontainers==2.1.0
spacy==2.2.4
Sphinx==1.8.5
sphinxcontrib-websupport==1.2.1
SQLAlchemy==1.3.16
sqlparse==0.3.1
srsly==1.0.2
stable-baselines==2.2.1
statsmodels==0.10.2
sympy==1.1.1
tables==3.4.4
tabulate==0.8.7
tbb==2020.0.133
tblib==1.6.0
tensor2tensor==1.14.1
tensorboard==1.15.0
tensorboard-plugin-wit==1.6.0.post3
tensorboardcolab==0.0.22
tensorflow==1.15.2
tensorflow-addons==0.8.3
tensorflow-datasets==2.1.0
tensorflow-estimator==1.15.1
tensorflow-gan==2.0.0
tensorflow-gcs-config==2.1.8
tensorflow-hub==0.8.0
tensorflow-metadata==0.21.2
tensorflow-privacy==0.2.2
tensorflow-probability==0.7.0
termcolor==1.1.0
terminado==0.8.3
testpath==0.4.4
text-unidecode==1.3
textblob==0.15.3
textgenrnn==1.4.1
tflearn==0.3.2
Theano==1.0.4
thinc==7.4.0
toolz==0.10.0
torch==1.4.0
torchsummary==1.5.1
torchtext==0.3.1
torchvision==0.5.0
tornado==4.5.3
tqdm==4.38.0
traitlets==4.3.3
tweepy==3.6.0
typeguard==2.7.1
typing==3.6.6
typing-extensions==3.6.6
tzlocal==1.5.1
umap-learn==0.4.1
uritemplate==3.0.1
urllib3==1.24.3
vega-datasets==0.8.0
wasabi==0.6.0
wcwidth==0.1.9
webencodings==0.5.1
Werkzeug==1.0.1
widgetsnbextension==3.5.1
wordcloud==1.5.0
wrapt==1.12.1
xarray==0.15.1
xgboost==0.90
xkit==0.0.0
xlrd==1.1.0
xlwt==1.3.0
yellowbrick==0.9.1
zict==2.0.0
zipp==3.1.0
zmq==0.0.0


<!--
As per our GitHub Policy (https://github.com/tensorflow/models/blob/master/ISSUES.md), we only address code bugs, documentation issues, and feature requests on GitHub.

We will automatically close questions and help related issues.

Please go to Stack Overflow (http://stackoverflow.com/questions/tagged/tensorflow-model-garden) for questions and help.

-->
",Boltuzamaki,b'models:research type:support',2020-04-22T08:25:31Z,2020-04-29T07:09:41Z,,,,,,,
8407,If I have 5 classes what changes have to do in config file?,"<!--
As per our GitHub Policy (https://github.com/tensorflow/models/blob/master/ISSUES.md), we only address code bugs, documentation issues, and feature requests on GitHub.

We will automatically close questions and help related issues.

Please go to Stack Overflow (http://stackoverflow.com/questions/tagged/tensorflow-model-garden) for questions and help.

-->
",yashmukaty,b'type:support',2020-04-18T16:32:02Z,2020-04-22T11:31:52Z,,,,,,,
8404,Object detection API: Training stuck at step=0 for ssd mobilenetv2,"**System information**
- Didn't change the code but used my own data:
- Windows 10 + conda
- TensorFlow installed from binary
- TensorFlow version: v1.15.0-rc3-22-g590d6eef7e 1.15.0
- Python version: 3.7.6
- CUDA/cuDNN version: 10.0
- GPU model and memory: GeForce GTX 1080 Ti

<!-- 
You can collect some of this information using our environment capture (https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 

1. TensorFlow 1.0
`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 

2. TensorFlow 2.0
`python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`
-->

**Please provide the entire URL of the model you are using?**
http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v2_oid_v4_2018_12_12.tar.gz

**Describe the current behavior**
The training stops at step = 0.

I wanted to do transfer learning using a ssd + mobilenetv2 model with my own images. I have only one class. The images were downloaded from OpenImageDataSet. I verified that the TFRecord was correctly created as I can use the same data to train faster_rcnn with object detetion APIs. I created my own config file using the one in the repos: ssd_mobilenet_v2_oid_v4.config. 

I also tried to start with ssd_mobilenet_v2_coco_2018_03_29.tar.gz using corresponding config file. The behavior is the same -- it also stuck at the same place.

**Describe the expected behavior**
I would expect I can train the ssd + mobilenetv2 with the my data as what I did for faster_rcnn. 

**Code to reproduce the issue**
Images of one class and train with a config file like below. 
Thank you!

**Other info / logs**

####################
ssd_mobilenet_v2_oid_v4.config. 

model {
  ssd {
    num_classes: 1
    box_coder {
      faster_rcnn_box_coder {
        y_scale: 10.0
        x_scale: 10.0
        height_scale: 5.0
        width_scale: 5.0
      }
    }
    matcher {
      argmax_matcher {
        matched_threshold: 0.5
        unmatched_threshold: 0.5
        ignore_thresholds: false
        negatives_lower_than_unmatched: true
        force_match_for_each_row: true
      }
    }
    similarity_calculator {
      iou_similarity {
      }
    }
    anchor_generator {
      ssd_anchor_generator {
        num_layers: 6
        min_scale: 0.2
        max_scale: 0.95
        aspect_ratios: 1.0
        aspect_ratios: 2.0
        aspect_ratios: 0.5
        aspect_ratios: 3.0
        aspect_ratios: 0.3333
      }
    }
    image_resizer {
      fixed_shape_resizer {
        height: 300
        width: 300
      }
    }
    box_predictor {
      convolutional_box_predictor {
        min_depth: 0
        max_depth: 0
        num_layers_before_predictor: 0
        use_dropout: false
        dropout_keep_probability: 0.8
        kernel_size: 1
        box_code_size: 4
        apply_sigmoid_to_scores: false
        conv_hyperparams {
          activation: RELU_6,
          regularizer {
            l2_regularizer {
              weight: 0.00004
            }
          }
          initializer {
            truncated_normal_initializer {
              stddev: 0.03
              mean: 0.0
            }
          }
          batch_norm {
            train: true,
            scale: true,
            center: true,
            decay: 0.9997,
            epsilon: 0.001,
          }
        }
      }
    }
    feature_extractor {
      type: 'ssd_mobilenet_v2'
      min_depth: 16
      depth_multiplier: 1.0
      conv_hyperparams {
        activation: RELU_6,
        regularizer {
          l2_regularizer {
            weight: 0.00004
          }
        }
        initializer {
          truncated_normal_initializer {
            stddev: 0.03
            mean: 0.0
          }
        }
        batch_norm {
          train: true,
          scale: true,
          center: true,
          decay: 0.9997,
          epsilon: 0.001,
        }
      }
    }
    loss {
      classification_loss {
        weighted_sigmoid {
        }
      }
      localization_loss {
        weighted_smooth_l1 {
        }
      }
      hard_example_miner {
        num_hard_examples: 3000
        iou_threshold: 0.99
        loss_type: CLASSIFICATION
        max_negatives_per_positive: 3
        min_negatives_per_image: 3
      }
      classification_weight: 1.0
      localization_weight: 1.0
    }
    normalize_loss_by_num_matches: true
    post_processing {
      batch_non_max_suppression {
        score_threshold: 1e-8
        iou_threshold: 0.6
        max_detections_per_class: 100
        max_total_detections: 100
      }
      score_converter: SIGMOID
    }
  }
}

train_config: {
  batch_size: 24
  optimizer {
    rms_prop_optimizer: {
      learning_rate: {
        exponential_decay_learning_rate {
          initial_learning_rate: 0.0008
          decay_steps: 800720
          decay_factor: 0.95
        }
      }
      momentum_optimizer_value: 0.9
      decay: 0.9
      epsilon: 1.0
    }
  }

  gradient_clipping_by_norm: 10.0
  keep_checkpoint_every_n_hours: 24
  fine_tune_checkpoint: ""D:/work/cv/others/my-tf2-od-transfer-ssd-mobilenet-v2/ssd_mobilenet_v2_oid_v4_2018_12_12/model.ckpt""




  num_steps: 100
  data_augmentation_options {
    random_horizontal_flip {
    }
  }
  data_augmentation_options {
    ssd_random_crop {
    }
  }
}

train_input_reader: {
  tf_record_input_reader {

    input_path: ""D:/work/cv/others/my-tf2-od-transfer-ssd-mobilenet-v2/data/oid_glasses_train.tfrecord""
  }

  label_map_path: ""D:/work/cv/others/my-tf2-od-transfer-ssd-mobilenet-v2/labelmap.pbtxt""
}

eval_config: {





  metrics_set: ""open_images_V2_detection_metrics""
}

eval_input_reader: {
  sample_1_of_n_examples: 10
  tf_record_input_reader {

    input_path: ""D:/work/cv/others/my-tf2-od-transfer-ssd-mobilenet-v2/data/oid_glasses_validation.tfrecord""
  }

  label_map_path: ""D:/work/cv/others/my-tf2-od-transfer-ssd-mobilenet-v2/labelmap.pbtxt""
  shuffle: false
  num_readers: 1
}





####################
CONSOLE LOG:
Instructions for updating:
Use standard file utilities to get mtimes.
INFO:tensorflow:Running local_init_op.
I0416 16:30:39.198738 19792 session_manager.py:500] Running local_init_op.
INFO:tensorflow:Done running local_init_op.
I0416 16:30:39.632495 19792 session_manager.py:502] Done running local_init_op.
INFO:tensorflow:Saving checkpoints for 0 into D:\work\cv\others\my-tf2-od-transfer-ssd-mobilenet-v2\model.ckpt.
I0416 16:30:48.724722 19792 basic_session_run_hooks.py:606] Saving checkpoints for 0 into D:\work\cv\others\my-tf2-od-transfer-ssd-mobilenet-v2\model.ckpt.
2020-04-16 16:30:59.919297: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll
2020-04-16 16:31:00.964680: W tensorflow/stream_executor/cuda/redzone_allocator.cc:312] Internal: Invoking ptxas not supported on Windows
Relying on driver to perform ptx compilation. This message will be only logged once.
2020-04-16 16:31:00.986098: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_100.dll
INFO:tensorflow:loss = 12.512502, step = 0
I0416 16:31:02.740392 19792 basic_session_run_hooks.py:262] loss = 12.512502, step = 0  [STUCK HERE]
",jackyvr,b'models:research type:bug',2020-04-17T00:20:02Z,2020-04-24T04:07:45Z,,,,,,,
8402,Object detection mAP@.5:.95 evaluation on own dataset,"<!--
As per our GitHub Policy (https://github.com/tensorflow/models/blob/master/ISSUES.md), we only address code bugs, documentation issues, and feature requests on GitHub.

We will automatically close questions and help related issues.

Please go to Stack Overflow (http://stackoverflow.com/questions/tagged/tensorflow-model-garden) for questions and help.

-->
How can I perform Coco's mAP@.5:.95 evaluation on my own dataset with eval.py?
",emmbertelen,b'type:support',2020-04-16T11:00:37Z,2020-04-26T14:41:21Z,,,,,,,
8400,fine_tune,"<!--
As per our GitHub Policy (https://github.com/tensorflow/models/blob/master/ISSUES.md), we only address code bugs, documentation issues, and feature requests on GitHub.

We will automatically close questions and help related issues.

Please go to Stack Overflow (http://stackoverflow.com/questions/tagged/tensorflow-model-garden) for questions and help.

-->
",linhongbao,b'type:support',2020-04-15T08:01:03Z,2020-04-15T18:33:20Z,,,,,,,
8399,Some Python objects were not bound to checkpointed values,"<!--
Please make sure that this is a bug. 

As per our GitHub Policy (https://github.com/tensorflow/models/blob/master/ISSUES.md), we only address code bugs, documentation issues, and feature requests on GitHub.

Please go to Stack Overflow (http://stackoverflow.com/questions/tagged/tensorflow-model-garden) for help and support.
-->

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04
- Mobile device (e.g., Pixel 4, Samsung Galaxy 10) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): v1.12.1-29517-g242129341e 2.2.0-dev20200414
- Python version: 3.7.4
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: CUDA Version 10.1.243
- GPU model and memory: GeForce GTX 970

<!-- 
You can collect some of this information using our environment capture (https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 

1. TensorFlow 1.0
`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 

2. TensorFlow 2.0
`python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`
-->

**Please provide the entire URL of the model you are using?**
<!-- (e.g., https://github.com/tensorflow/models/tree/master/official/nlp/bert) -->

https://github.com/tensorflow/models/tree/master/official/nlp/bert

**Describe the current behavior**

I am fine-tuning a bert-based model and saving checkpoints. At prediction time, restoring the checkpoints fails with the errors similar to:
```
Traceback (most recent call last):
  File ""/home/david/github/bert-checkpoints-bug/predict.py"", line 12, in <module>
    checkpoint.restore(tf.train.latest_checkpoint('checkpoints')).assert_existing_objects_matched()
  File ""/home/david/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/tracking/util.py"", line 783, in assert_existing_objects_matched
    (list(unused_python_objects),))
AssertionError: Some Python objects were not bound to checkpointed values, likely due to changes in the Python program: [<tf.Variable 'save_counter:0' shape=() dtype=int64, numpy=0>, <tf.Variable 'transformer/layer_2/self_attention_output/kernel:0' shape=(12, 64, 768) dtype=float32, numpy=
...
```
**Describe the expected behavior**
Should work without errors

**Code to reproduce the issue**
<!-- Provide a reproducible test case that is the bare minimum necessary to generate the problem. -->

reproduce.py:
```
import os

import tensorflow as tf
from official.nlp.bert.bert_models import get_transformer_encoder
from official.nlp.bert.configs import BertConfig
from tensorflow.keras.layers import Dense
from tensorflow.keras.models import Model


def build_model(bert_dir):
    max_seq_len = 384

    bert_config = BertConfig.from_json_file(os.path.join(bert_dir, 'bert_config.json'))
    bert_encoder = get_transformer_encoder(bert_config, max_seq_len)

    input_ids = tf.keras.layers.Input(shape=(max_seq_len,), dtype=tf.int32, name='input_ids')
    input_mask = tf.keras.layers.Input(shape=(max_seq_len,), dtype=tf.int32, name='input_mask')
    segment_ids = tf.keras.layers.Input(shape=(max_seq_len,), dtype=tf.int32, name='segment_ids')

    bert_inputs = [input_ids, input_mask, segment_ids]
    bert_sequence_output, bert_pooled_output = bert_encoder(bert_inputs)

    out = Dense(1, activation='sigmoid', name='out')(bert_pooled_output)
    return Model(inputs=bert_inputs, outputs=[out])


dir_path = os.path.dirname(os.path.realpath(__file__))
bert_dir = os.path.join(dir_path, 'uncased_L-12_H-768_A-12')

# TRAIN

model = build_model(bert_dir)
checkpoint = tf.train.Checkpoint(model=model)
checkpoint.restore(os.path.join(bert_dir, 'bert_model.ckpt')).expect_partial()

optimizer = tf.optimizers.Adam()
model.compile(optimizer=optimizer, loss=[tf.losses.BinaryCrossentropy()])

input_ids = tf.zeros((1, 384))
input_mask = tf.zeros((1, 384))
segment_ids = tf.zeros((1, 384))

y = tf.zeros((1, 1))

checkpoint_path = ""checkpoints/model.ckpt""
checkpoint_dir = os.path.dirname(checkpoint_path)
cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,
                                                 save_weights_only=True,
                                                 verbose=1)
model.fit(x=[input_ids, input_mask, segment_ids], y=y, epochs=3, callbacks=[cp_callback])

# PREDICT

model = build_model(bert_dir)
checkpoint = tf.train.Checkpoint(model=model)
checkpoint.restore(tf.train.latest_checkpoint('checkpoints')).assert_existing_objects_matched()  # <-- ERROR

input_ids = tf.zeros((1, 384))
input_mask = tf.zeros((1, 384))
segment_ids = tf.zeros((1, 384))

model.predict([input_ids, input_mask, segment_ids])
```

To reproduce, first download and extract the pre-trained model https://storage.googleapis.com/cloud-tpu-checkpoints/bert/keras_bert/uncased_L-12_H-768_A-12.tar.gz

Then run
```
python reproduce.py
```

I also have a repo with the same code as above: https://github.com/david-wb/bert-checkpoints-bug
**Other info / logs**
<!-- Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. -->
",david-wb,b'models:official type:bug',2020-04-14T23:18:09Z,2020-08-24T14:02:29Z,,,,,,,
8394,Matrix of confusion in tensor flow 1.4,"hello, I am using the script ( https://www.shiftedup.com/2018/10/10/confusion-matrix-in-object-detection-api-with-tensorflow ), I generated the confuction matrix, only I have two classes and the matrix has a size of 3x3, which is wrong. someone could explain me. Thank you

![matriz](https://user-images.githubusercontent.com/62752094/79141415-1fc52d80-7d90-11ea-9504-6a663b34f85d.PNG)


matriz

Matriz de confusión:
[[1. 1. 7.]
[0. 3. 3.]
[2. 1. 0.]]

categoría ... recordar_@0.5IOU
0 Gafas ... 0.111111
1 Bolígrafo ... 0.500000

[2 filas x 3 columnas]
",jhonjam,b'models:official type:bug',2020-04-13T17:08:01Z,2020-08-07T18:22:56Z,,,,,,,
8392,RuntimeError when using TransformerXLModel layers ,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Windows 10 (10.0, Build 18362)
- Mobile device (e.g., Pixel 4, Samsung Galaxy 10) if the issue happens on mobile device:None
- TensorFlow installed from (source or binary):binary
- TensorFlow version (use command below):2.1.0
- Python version:3.7.6
Describe the problem
I want to use transformer xl in my keras model and  I use xlnet_modeling.py provided in official models to test, when testing models I met a RuntimeError.
Source code / logs
the code here is mainly from xlnet_modeling.py in official models and I rewrite some part of input.
[code.txt](https://github.com/tensorflow/models/files/4470425/code.txt)
and here's the wrong information:
Traceback (most recent call last):

  File ""<ipython-input-3-049aa757e999>"", line 1, in <module>
    model_use = model_test1(True)

  File ""D:\bug_fixing.py"", line 800, in model_test1
    a,b = user_hist_item_transformerxl([input1, input3, input4, None, None, None, None])

  File ""C:\Users\win\Anaconda3\lib\site-packages\tensorflow_core\python\keras\engine\base_layer.py"", line 822, in __call__
    outputs = self.call(cast_inputs, *args, **kwargs)

  File ""D:\bug_fixing.py"", line 637, in call
    non_tgt_mask = -tf.eye(qlen, dtype=self.tf_float)

  File ""C:\Users\win\Anaconda3\lib\site-packages\tensorflow_core\python\ops\linalg_ops.py"", line 169, in eye
    name=name)

  File ""C:\Users\win\Anaconda3\lib\site-packages\tensorflow_core\python\ops\linalg_ops_impl.py"", line 65, in eye
    diag_shape = array_ops.concat((batch_shape, [diag_size]), axis=0)

  File ""C:\Users\win\Anaconda3\lib\site-packages\tensorflow_core\python\util\dispatch.py"", line 180, in wrapper
    return target(*args, **kwargs)

  File ""C:\Users\win\Anaconda3\lib\site-packages\tensorflow_core\python\ops\array_ops.py"", line 1517, in concat
    return gen_array_ops.concat_v2(values=values, axis=axis, name=name)

  File ""C:\Users\win\Anaconda3\lib\site-packages\tensorflow_core\python\ops\gen_array_ops.py"", line 1334, in concat_v2
    ""ConcatV2"", values=values, axis=axis, name=name)

  File ""C:\Users\win\Anaconda3\lib\site-packages\tensorflow_core\python\framework\op_def_library.py"", line 412, in _apply_op_helper
    as_ref=input_arg.is_ref)

  File ""C:\Users\win\Anaconda3\lib\site-packages\tensorflow_core\python\framework\ops.py"", line 1382, in internal_convert_n_to_tensor
    ctx=ctx))

  File ""C:\Users\win\Anaconda3\lib\site-packages\tensorflow_core\python\framework\ops.py"", line 1280, in convert_to_tensor
    raise RuntimeError(""Attempting to capture an EagerTensor without ""

RuntimeError: Attempting to capture an EagerTensor without building a function.

As for me, I think it may because tf.eye EagerTensor part is not attached to the graph,but I haven't come up with any idea to solve the problem above",shidaide2019,b'models:official stalled stat:awaiting response type:bug',2020-04-13T16:21:07Z,2020-09-18T19:17:29Z,,,,,,,
8388,ValueError: Eval batch size 256 is not divisible by 1000,"<!--
Please make sure that this is a bug. 

As per our GitHub Policy (https://github.com/tensorflow/models/blob/master/ISSUES.md), we only address code bugs, documentation issues, and feature requests on GitHub.

Please go to Stack Overflow (http://stackoverflow.com/questions/tagged/tensorflow-model-garden) for help and support.
-->

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS Catalina Version 10.15.4 (19E287)d
- Mobile device (e.g., Pixel 4, Samsung Galaxy 10) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below): 2.2.0-dev20200411
- Python version: 3.6
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

<!-- 
You can collect some of this information using our environment capture (https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 

1. TensorFlow 1.0
`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 

2. TensorFlow 2.0
`python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`
-->

**Please provide the entire URL of the model you are using?** 
https://github.com/tensorflow/models/blob/master/official/recommendation/ncf_keras_main.py
<!-- (e.g., https://github.com/tensorflow/models/tree/master/official/nlp/bert) -->

**Describe the current behavior**
Got the following error message when running command `python official/recommendation/ncf_keras_main.py --model_dir ../XXXX/model --data_dir ../XXXX/data`:
```
ValueError: Eval batch size 256 is not divisible by 1000
```
Full log is like below:
```sh
$ python official/recommendation/ncf_keras_main.py --model_dir ../ncf_tensorflow_sample/model --data_dir ../ncf_tensorflow_sample/data
2020-04-11 11:03:52.325168: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-04-11 11:03:52.343370: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f8d359bcbd0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-04-11 11:03:52.343389: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
WARNING:tensorflow:Some requested devices in `tf.distribute.Strategy` are not visible to TensorFlow: /job:localhost/replica:0/task:0/device:GPU:0
W0411 11:03:52.343887 4374371776 cross_device_ops.py:1172] Some requested devices in `tf.distribute.Strategy` are not visible to TensorFlow: /job:localhost/replica:0/task:0/device:GPU:0
INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)
I0411 11:03:52.345362 4374371776 mirrored_strategy.py:341] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)
I0411 11:03:52.345715 4374371776 movielens.py:108] Dataset ml-1m has already been downloaded
I0411 11:03:52.345789 4374371776 data_preprocessing.py:201] Beginning data preprocessing.
I0411 11:03:53.482697 4374371776 data_preprocessing.py:117] Generating user_map and item_map...
I0411 11:03:54.415248 4374371776 data_preprocessing.py:139] Sorting by user, timestamp...
I0411 11:03:57.333374 4374371776 data_preprocessing.py:172] Writing raw data cache.
Traceback (most recent call last):
  File ""official/recommendation/ncf_keras_main.py"", line 562, in <module>
    app.run(main)
  File ""/Users/xyin/anaconda3/envs/py36/lib/python3.6/site-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/Users/xyin/anaconda3/envs/py36/lib/python3.6/site-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""official/recommendation/ncf_keras_main.py"", line 557, in main
    run_ncf(FLAGS)
  File ""official/recommendation/ncf_keras_main.py"", line 246, in run_ncf
    num_users, num_items, _, _, producer = ncf_common.get_inputs(params)
  File ""/Users/xyin/Documents/self/models/official/recommendation/ncf_common.py"", line 61, in get_inputs
    deterministic=FLAGS.seed is not None)
  File ""/Users/xyin/Documents/self/models/official/recommendation/data_preprocessing.py"", line 236, in instantiate_pipeline
    create_data_offline=generate_data_offline)
  File ""/Users/xyin/Documents/self/models/official/recommendation/data_pipeline.py"", line 852, in __init__
    super(BisectionDataConstructor, self).__init__(*args, **kwargs)
  File ""/Users/xyin/Documents/self/models/official/recommendation/data_pipeline.py"", line 414, in __init__
    eval_batch_size, 1 + rconst.NUM_EVAL_NEGATIVES))
ValueError: Eval batch size 256 is not divisible by 1000
```


**Describe the expected behavior**

**Code to reproduce the issue**
https://github.com/tensorflow/models/blob/master/official/recommendation/ncf_keras_main.py
<!-- Provide a reproducible test case that is the bare minimum necessary to generate the problem. -->

**Other info / logs**
<!-- Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. -->
",xiangshiyin,b'models:official type:bug',2020-04-11T19:51:23Z,2020-04-16T04:30:08Z,,,,,,,
8386,Can I use the tf record generated in the way of faster rcnn to train mask rcnn model?,"<!--
As per our GitHub Policy (https://github.com/tensorflow/models/blob/master/ISSUES.md), we only address code bugs, documentation issues, and feature requests on GitHub.

We will automatically close questions and help related issues.

Please go to Stack Overflow (http://stackoverflow.com/questions/tagged/tensorflow-model-garden) for questions and help.

-->
",JJLim99,b'type:support',2020-04-11T11:51:05Z,2020-04-26T14:54:00Z,,,,,,,
8384,Errors with pip install dependencies if numpy is not pre-installed,"<!--
Please make sure that this is a documentation issue. 

As per our GitHub Policy (https://github.com/tensorflow/models/blob/master/ISSUES.md), we only address code bugs, documentation issues, and feature requests on GitHub.

Please go to Stack Overflow (http://stackoverflow.com/questions/tagged/tensorflow-model-garden) for help and support.
-->

**Documentation URL(s) with the issue:** https://github.com/tensorflow/models/tree/master/official#method-2-clone-the-source
<!-- Please provide a link to the documentation entry, for example: https://github.com/tensorflow/models/tree/master/official/README.md -->

**Description of the issue (what needs to be changed):** 
* numpy needs to first installed in order to install the dependencies listed in `requirements.txt`. Otherwise, following error will pop up:
```
Obtaining pycocotools from git+https://github.com/cocodataset/cocoapi#egg=pycocotools&subdirectory=PythonAPI (from -r official/requirements.txt (line 25))
  Cloning https://github.com/cocodataset/cocoapi to ./src/pycocotools
  Running command git clone -q https://github.com/cocodataset/cocoapi /Users/xyin/Documents/self/models/src/pycocotools
    ERROR: Command errored out with exit status 1:
     command: /Users/xyin/anaconda3/envs/py36/bin/python -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/Users/xyin/Documents/self/models/src/pycocotools/PythonAPI/setup.py'""'""'; __file__='""'""'/Users/xyin/Documents/self/models/src/pycocotools/PythonAPI/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' egg_info
         cwd: /Users/xyin/Documents/self/models/src/pycocotools/PythonAPI
    Complete output (5 lines):
    Traceback (most recent call last):
      File ""<string>"", line 1, in <module>
      File ""/Users/xyin/Documents/self/models/src/pycocotools/PythonAPI/setup.py"", line 2, in <module>
        import numpy as np
    ModuleNotFoundError: No module named 'numpy'
    ----------------------------------------
ERROR: Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.
```
",xiangshiyin,b'models:official type:docs',2020-04-10T22:12:46Z,2020-04-11T02:23:13Z,,,,,,,
8380,ValueError: Unknown ssd feature_extractor: ssd_mobilenet_v3_large,"Ubuntu 18.04 
TensorFlow 1.15.0 (Because of workaround: [link](https://stackoverflow.com/questions/59825444/modulenotfounderror-no-module-named-tensorflow-tools-graph-transforms-when-us))
Python = 3.6
I want to place ssd_mobilenet_v3_large into android code, to do so Im following [link](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/running_on_mobile_tensorflowlite.md)

and when I run command: 

`python object_detection/export_tflite_ssd_graph.py \
--pipeline_config_path=/home/n/Downloads/ssd_mobilenet_v3_large_coco_2019_08_14/pipeline.config \
--trained_checkpoint_prefix=/home/n/Downloads/ssd_mobilenet_v3_large_coco_2019_08_14/model.ckpt.data-00000-of-00001 \
--output_directory=/tmp/tflite \
--add_postprocessing_op=true`

I got:
`Traceback (most recent call last):
  File ""object_detection/export_tflite_ssd_graph.py"", line 143, in <module>
    tf.app.run(main)
  File ""/home/n/.conda/envs/car_detection/lib/python3.6/site-packages/tensorflow_core/python/platform/app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""/home/n/.conda/envs/car_detection/lib/python3.6/site-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/home/n/.conda/envs/car_detection/lib/python3.6/site-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""object_detection/export_tflite_ssd_graph.py"", line 139, in main
    FLAGS.max_classes_per_detection, use_regular_nms=FLAGS.use_regular_nms)
  File ""/home/n/.conda/envs/car_detection/lib/python3.6/site-packages/object_detection/export_tflite_ssd_graph_lib.py"", line 234, in export_tflite_graph
    pipeline_config.model, is_training=False)
  File ""/home/n/.conda/envs/car_detection/lib/python3.6/site-packages/object_detection/builders/model_builder.py"", line 121, in build
    return _build_ssd_model(model_config.ssd, is_training, add_summaries)
  File ""/home/n/.conda/envs/car_detection/lib/python3.6/site-packages/object_detection/builders/model_builder.py"", line 244, in _build_ssd_model
    is_training=is_training)
  File ""/home/n/.conda/envs/car_detection/lib/python3.6/site-packages/object_detection/builders/model_builder.py"", line 168, in _build_ssd_feature_extractor
    raise ValueError('Unknown ssd feature_extractor: {}'.format(feature_type))
ValueError: Unknown ssd feature_extractor: ssd_mobilenet_v3_large
`


However that's weird, because in file  /home/n/.conda/envs/car_detection/lib/python3.6/site-packages/object_detection/builders/model_builder.py

there is what they looking for: 
`    'ssd_mobilenet_v3_large': SSDMobileNetV3LargeFeatureExtractor,
`
in SSD_FEATURE_EXTRACTOR_CLASS_MAP

What is going on ?
",Adblu,b'models:research type:bug',2020-04-10T09:53:12Z,2020-08-06T07:14:23Z,,,,,,,
8377,Error while running deep_speech.py,"<!--
Please make sure that this is a bug. 

As per our GitHub Policy (https://github.com/tensorflow/models/blob/master/ISSUES.md), we only address code bugs, documentation issues, and feature requests on GitHub.

Please go to Stack Overflow (http://stackoverflow.com/questions/tagged/tensorflow-model-garden) for help and support.
-->

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- Mobile device (e.g., Pixel 4, Samsung Galaxy 10) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below): 1.15
- Python version: 3.6.9
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

<!-- 
You can collect some of this information using our environment capture (https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 

1. TensorFlow 1.0
`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 

2. TensorFlow 2.0
`python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`
-->

**Please provide the entire URL of the model you are using?**
<!-- (e.g., https://github.com/tensorflow/models/tree/master/official/nlp/bert) -->

**Describe the current behavior**
per_replica_batch_size is missing in distribution_utils of official.utils.misc
**Describe the expected behavior**
per_replica_batch_size is called in deep_speech.py. So, it should be in distribution_utils. The function definition exists in official/r1/transformer/transformer_main.py

**Code to reproduce the issue**
<!-- Provide a reproducible test case that is the bare minimum necessary to generate the problem. -->

**Other info / logs**
<!-- Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. -->
",Rafi99769,b'models:official type:bug',2020-04-09T12:00:06Z,2020-04-21T16:58:58Z,,,,,,,
8368,Seq2Species failes tests in run_training_test.py,"<!--
Please make sure that this is a bug. 

As per our GitHub Policy (https://github.com/tensorflow/models/blob/master/ISSUES.md), we only address code bugs, documentation issues, and feature requests on GitHub.

Please go to Stack Overflow (http://stackoverflow.com/questions/tagged/tensorflow-model-garden) for help and support.

The research models (https://github.com/tensorflow/models/tree/master/research) are a large collection of models implemented in TensorFlow by researchers. They are not officially supported. It is up to the individual researchers to maintain the models and/or provide support on issues and pull requests.
-->

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Latest Debian and Ubuntu
- TensorFlow installed from (source or binary): Binary (pip)
- TensorFlow version (use command below):  ('v1.15.0-rc3-22-g590d6ee', '1.15.0')
- Python version: 2.7.16

**Please provide the entire URL of the model you are using?**
https://github.com/tensorflow/models/tree/master/research/seq2species/

**Describe the current behavior**
2 tests fail
**Describe the expected behavior**
No tests fail
**Code to reproduce the issue**
First copy seq2species dir and cd into it
```
virtualenv -p /usr/bin/python2 venv
source venv/bin/activate
pip2 install tensorflow==1.15
python2 -B run_training_test.py
```
**Other info / logs**
See attached [log file](https://github.com/tensorflow/models/files/4443664/output.log)
The real training script seems to work fine using the provided preprocessed data (for the 60 seconds I let it run), so there might be something wrong with the test code. @apbusia and @depristo tagging maintainers.
",Bartvelp,b'models:archived models:research type:bug',2020-04-07T10:49:24Z,2020-04-28T16:46:09Z,,,,,,,
8363,Transformer: training failed at 3k steps on TPU,"I followed the official Transformer-2.x tutorial to train a Transformer Translation model on WMT, but training failed after 3k steps.
Tutorial: https://cloud.google.com/tpu/docs/tutorials/transformer-2.x

I checked that the instructions are up-to-date with transformer README here, and the code provided by the tutorial is the same as the 2.1.0 release of this repository: https://github.com/tensorflow/models/archive/v2.1.0.tar.gz


**System information**

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Google Cloud TPU v3-8
- TensorFlow version (use command below): 2.1
- Python version: 3.7.3

I followed exact instructions from Transformer-2.x tutorial to create my VM/TPU:  https://cloud.google.com/tpu/docs/tutorials/transformer-2.x

**Please provide the entire URL of the model you are using?**
official/transformer models in: 
https://github.com/tensorflow/models/archive/v2.1.0.tar.gz

OR

/usr/share/models/official/transformer on Cloud TPU

**Describe the current behavior**
Training failed after 3k steps during evaluation. 

It seems that different runs will fail at different # of steps. Previously, it failed at 6k steps.

**Describe the expected behavior**
The model is able to train 200k steps with full convergence.

**Code to reproduce the issue**
The codebase in the tutorial is the same as https://github.com/tensorflow/models/archive/v2.1.0.tar.gz

I followed the steps here: https://cloud.google.com/tpu/docs/tutorials/transformer-2.x

Training command is: python3 transformer_main.py --tpu=$TPU_NAME --model_dir=$MODEL_DIR --data_dir=$GCS_DATA_DIR --vocab_file=$GCS_DATA_DIR/vocab.ende.32768 --bleu_source=$GCS_DATA_DIR/newstest2014.en --bleu_ref=$GCS_DATA_DIR/newstest2014.de --batch_size=6144 --train_steps=200000 --static_batch=true --use_ctl=true --param_set=big --max_length=64 --decode_batch_size=32 --decode_max_length=97 --padded_decode=true --distribution_strategy=tpu

**Other info / logs**



  File ""transformer_main.py"", line 383, in eval
    distribution_strategy)
  File ""transformer_main.py"", line 118, in evaluate_and_log_bleu
    model, params, subtokenizer, bleu_source, bleu_ref, distribution_strategy)
  File ""transformer_main.py"", line 88, in translate_and_compute_bleu
    uncased_score = compute_bleu.bleu_wrapper(bleu_ref, tmp_filename, False)
  File ""/usr/share/models/official/transformer/compute_bleu.py"", line 96, in bleu_wrapper
    raise ValueError(""Reference and translation files have different number of ""
ValueError: Reference and translation files have different number of lines. If training only a few steps (100-200), the translation may be empty.

2020-04-05 20:40:41.852968: W ./tensorflow/core/distributed_runtime/eager/destroy_tensor_handle_node.h:79] Ignoring an error encountered when deleting remote tensors handles: Invalid argument: Unable to find a context_id matching the specified one (16973409415646534521). Perhaps the worker was restarted, or the context was GC'd?
Additional GRPC error information:
{""created"":""@1586119241.852831589"",""description"":""Error received from peer"",""file"":""external/grpc/src/core/lib/surface/call.cc"",""file_line"":1039,""grpc_message"":""Unable to find a context_id matching the specified one (16973409415646534521). Perhaps the worker was restarted, or the context was GC'd?"",""grpc_status"":3}
",dguo98,b'models:official stat:awaiting response type:bug',2020-04-05T22:10:22Z,2020-04-28T02:57:00Z,,,,,,,
8362,Tensorflow graph nodes are exchange  ,"I have trained a model with fine-tuning pre-trained model ` ssd_mobilenet_v2_coco_2018`. Here, i have used the exactly same `pipeline.config` file for training which is available inside `ssd_mobilenet_v2_coco_2018` pre-trained folder. 
I have only removed the `batch_norm_trainable: true` flag and changed the number of classes (4).
After training the model with my custom datasets with 4 classes, i found concat and concat_1 nodes gets exchange with each others. 
Pre-trained model has
| concat       | 1x1917x1x4  |
after-training it becomes
| concat       | 1x1917x5   |             
I have attached both tensorboard graph visualisation images. First image is pre-trained graph `ssd_mobilenet_v2_coco_2018`.
![pre-trained](https://user-images.githubusercontent.com/25616511/78499856-db72d580-7770-11ea-86ee-aacf49e29112.png)
![aftertraining](https://user-images.githubusercontent.com/25616511/78499862-e594d400-7770-11ea-9ba9-334b8780a08f.png)
          
The node exchanges can be seen on the right most corner of image. As in pre-trained graph, `Postprocess layer` connect with `concat_1` and `Squeeeze` connect with `concat`. But after the training, the graph shows completely reverse. Like `Prosprocess layer` connect with `concat` and `Squeeeze` connect with `concat_1`.
Further, i also found in pre-trained model graph that the `Preprocessor` takes input `ToFloat` while after training the  graph shows `Cast` as an input to `Preprocessor`.
I have fed the input to the model as `tfrecords`.

OS: Ubuntu 18.04
Framework: Tensorflow 1.14.0",sainisanjay,b'models:research type:bug',2020-04-05T13:41:08Z,2020-05-09T23:56:13Z,,,,,,,
8349,Transfer Learning with Inceptionv3 - flag directory error,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Ubuntu 16.04 running via VMware on Macbook Pro - External HDD
- TensorFlow installed from (source or binary): Source
- TensorFlow version (use command below): 1.14.0
- Python version: 3
- Bazel version (if compiling from source): 2.2.0
- GCC/Compiler version (if compiling from source):5.4.0

**Describe the current behavior**

Using a custom dataset of grocery store items to retrain InceptionV3. The dataset is hosted on an external hard drive and is accessible by cd'ing into it. The `noexec` option is not tagged.
I can edit and modify the external hard drive data via terminal.


Running an unmodified retrain.py fails with the following error: `AttributeError: 'NoneType' object has no attribute 'keys`

Tracing back, I can see the dir_path is prepended incorrectly: `E0401 14:27:30.038295 140710347978496 retrain.py:141] Image directory '/home/XXX/media/XXX/book/dataset/train_img' not found.`

The pertinent output is:
`E0401 14:27:30.038295 140710347978496 retrain.py:141] Image directory '/home/XXX/media/XXX/book/dataset/train_img' not found.
Traceback (most recent call last):
  File ""retrain.py"", line 1285, in <module>
    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)
  File ""/home/XXX/MIDI/lib/python3.6/site-packages/tensorflow/python/platform/app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""/home/XXX/MIDI/lib/python3.6/site-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/home/XXX/MIDI/lib/python3.6/site-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""retrain.py"", line 943, in main
    class_count = len(image_lists.keys())
AttributeError: 'NoneType' object has no attribute 'keys'
`

**Describe the expected behavior**
I expected the dir_path, in this case the image_dir, to be as I flagged it: `--image_dir ~/media/XXX/book/dataset/train_img`

and not what is seen in the output, above: `'/home/XXX/media/XXX/book/dataset/train_img' not found.`

**Code to reproduce the issue**

`python3 retrain.py --model_dir ./media/XXX/book/tmp/checkpoints --image_dir ~/media/XXX/book/dataset/train_img --output_graph ./media/XXX/book/tmp --how_many_training_steps 1000`


I ask if anyone knows why the dir_path is prepended with `home` directory, then the user `XXX`, and then follows the flagged directive?
I cannot find where in [retrain.py](https://github.com/tensorflow/hub/blob/master/examples/image_retraining/retrain.py) the germane changes should be made.
Line 141 assigns the `dir_name = os.path.basename()` and not a `os.path.dirname(path)`.

So I am trying to ascertain why the dir_path is prepended with the local `home` directory and then the user `/home/XXX/`.

If anyone can assist it would be a great help.
",CapitalZe,b'models:research type:bug',2020-04-01T14:28:48Z,2020-04-08T15:54:57Z,,,,,,,
8348,Dependency addition in BUILD file for /research/tcn,"I kept running into _ImportError_ when running _videos_to_tfrecords_ with _bazel_.
'_util_' should be added to the dependency for _videos_to_tfrecords_

**Correction**
py_binary(
    name = ""videos_to_tfrecords"",
    srcs = [
        ""dataset/videos_to_tfrecords.py"",
    ],
    main = ""dataset/videos_to_tfrecords.py"",
    deps = [
        "":preprocessing"",
        "":util"",
    ],
)
",Vignesh-Nswamy,b'models:archived models:research type:bug',2020-04-01T00:35:46Z,2020-04-26T20:12:00Z,,,,,,,
8343,"[object detection] when train ssd add random_image_scale and some other Photometric Distortions augment, cost a lot gpu memory?","
**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (linux):
- TensorFlow installed from (source or binary): pip install tensorflow 1.14
- TensorFlow version (use command below):
- Python version: python 3.7
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 10
- GPU model and memory: 24G

i use object detection package to train ssd detector (use coco predefine config), i add follow augment to data process pipeline (random_horizontal_flip **random_vertical_flip random_rotation90 random_adjust_brightness random_adjust_contrast random_adjust_saturation random_image_scale** ssd_random_crop), expect model will be more balance to Photometric change and scale change. 
but when i trained the model, the batch size on 4 gpu can only 128 as if not add augment the batch size can be 512, and the 4 gpu is not all used all the time , but some time some gpu use rate is 0 but next time is 100%, why these happen, as augment only processed before model!",mlinxiang,b'models:research type:bug',2020-03-31T12:11:51Z,2020-05-12T17:33:05Z,,,,,,,
8332,model_main.py tries to import unavailable libraries in tensorflow v2,"I'm trying to run models/research/objection_detection/model_main.py. It calls eval_utils.py which contains this line:

slim = tf.contrib.slim

Currently **tensorflow v2 does not have the tf.contrib library** anymore. This is the error I get:

`Traceback (most recent call last):
  File ""model_main.py"", line 26, in <module>
    from object_detection import model_lib
  File ""C:\Users\Me\Documents\Project 2018\07_imagerec\Tensorflow\models\research\object_detection\model_lib.py"", line 27, in <module>
    from object_detection import eval_util
  File ""C:\Users\Me\Documents\Project 2018\07_imagerec\Tensorflow\models\research\object_detection\eval_util.py"", line 35, in <module>
    slim = tf.contrib.slim
AttributeError: module 'tensorflow' has no attribute `'contrib'`

I did however find someone with a similar issue and the solution proposed is to use ""tf_slim"" package. This solve the particular error above but further in hits another error which is also due to calling from tensorflow.contrib

`2020-03-26 22:47:22.437429: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_100.dll
Traceback (most recent call last):
  File ""model_main.py"", line 26, in <module>
    from object_detection import model_lib
  File ""C:\Users\Me\Documents\Project 2018\07_imagerec\Tensorflow\models\research\object_detection\model_lib.py"", line 27, in <module>
    from object_detection import eval_util
  File ""C:\Users\Me\Documents\Project 2018\07_imagerec\Tensorflow\models\research\object_detection\eval_util.py"", line 34, in <module>
    import tf_slim as slim
  File ""C:\Users\Me\AppData\Local\Programs\Python\Python36\lib\site-packages\tf_slim\__init__.py"", line 23, in <module>
    from tf_slim import evaluation
  File ""C:\Users\Me\AppData\Local\Programs\Python\Python36\lib\site-packages\tf_slim\evaluation.py"", line 131, in <module>
    from tensorflow.contrib.training.python.training import evaluation
  File ""C:\Users\Me\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\contrib\training\__init__.py"", line 58, in <module>
    from tensorflow.contrib.training.python.training.hparam import *
  File ""C:\Users\Me\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\contrib\training\python\training\hparam.py"", line 26, in <module>
    from tensorflow.contrib.training.python.training import hparam_pb2
ImportError: cannot import name 'hparam_pb2'`

Is there a workaround or does the model_main.py need to be updated?",john-khgoh,b'models:research type:bug',2020-03-26T14:53:07Z,2020-05-28T04:47:58Z,,,,,,,
8320,"""ncf_test.py"" failed.","<!--
Please make sure that this is a bug. 

As per our GitHub Policy (https://github.com/tensorflow/models/blob/master/ISSUES.md), we only address code bugs, documentation issues, and feature requests on GitHub.

Please go to Stack Overflow (http://stackoverflow.com/questions/tagged/tensorflow-model-garden) for help and support.
-->

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g., Pixel 4, Samsung Galaxy 10) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):pip3
- TensorFlow version (use command below): Tensorflow 2.2.0rc
- Python version: 3.6
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

<!-- 
You can collect some of this information using our environment capture (https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 

1. TensorFlow 1.0
`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 

2. TensorFlow 2.0
`python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`
-->

**Please provide the entire URL of the model you are using?**
<!-- (e.g., https://github.com/tensorflow/models/tree/master/official/nlp/bert) -->
https://github.com/tensorflow/models/blob/master/official/recommendation/ncf_test.py
**Describe the current behavior**
![Screenshot from 2020-03-20 19-19-03](https://user-images.githubusercontent.com/41910134/77169598-c09d3180-6adf-11ea-9661-593b19760e2d.png)

**Describe the expected behavior**
![Screenshot from 2020-03-20 19-17-20](https://user-images.githubusercontent.com/41910134/77169601-c3982200-6adf-11ea-880a-de6ecc5ae72c.png)

**Code to reproduce the issue**
<!-- Provide a reproducible test case that is the bare minimum necessary to generate the problem. -->
python3 official/recommendation/ncf_test.py
**Other info / logs**
<!-- Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. -->
",ayushmankumar7,b'models:official type:bug',2020-03-20T13:50:14Z,2020-04-27T04:43:14Z,,,,,,,
8319,ValueError: Eval batch size 256 is not divisible by 1000,"<!--
Please make sure that this is a bug. 

As per our GitHub Policy (https://github.com/tensorflow/models/blob/master/ISSUES.md), we only address code bugs, documentation issues, and feature requests on GitHub.

Please go to Stack Overflow (http://stackoverflow.com/questions/tagged/tensorflow-model-garden) for help and support.
-->

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04 LTS
- Mobile device (e.g., Pixel 4, Samsung Galaxy 10) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): pip3
- TensorFlow version (use command below): 2.2.0rc
- Python version: 3.6
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

<!-- 
You can collect some of this information using our environment capture (https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 

1. TensorFlow 1.0
`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 

2. TensorFlow 2.0
`python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`
-->

**Please provide the entire URL of the model you are using?**
<!-- (e.g., https://github.com/tensorflow/models/tree/master/official/nlp/bert) -->
https://github.com/tensorflow/models/blob/master/official/recommendation/ncf_keras_main.py
**Describe the current behavior**


**Describe the expected behavior**

**Code to reproduce the issue**
<!-- Provide a reproducible test case that is the bare minimum necessary to generate the problem. -->
python3 official/recommendation/ncf_keras_main.py 

**Other info / logs**
<!-- Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. -->

Traceback (most recent call last):
  File ""official/recommendation/ncf_keras_main.py"", line 562, in <module>
    app.run(main)
  File ""/home/ayushman/.local/lib/python3.6/site-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/home/ayushman/.local/lib/python3.6/site-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""official/recommendation/ncf_keras_main.py"", line 557, in main
    run_ncf(FLAGS)
  File ""official/recommendation/ncf_keras_main.py"", line 246, in run_ncf
    num_users, num_items, _, _, producer = ncf_common.get_inputs(params)
  File ""/home/ayushman/Documents/github/models/official/recommendation/ncf_common.py"", line 61, in get_inputs
    deterministic=FLAGS.seed is not None)
  File ""/home/ayushman/Documents/github/models/official/recommendation/data_preprocessing.py"", line 236, in instantiate_pipeline
    create_data_offline=generate_data_offline)
  File ""/home/ayushman/Documents/github/models/official/recommendation/data_pipeline.py"", line 852, in __init__
    super(BisectionDataConstructor, self).__init__(*args, **kwargs)
  File ""/home/ayushman/Documents/github/models/official/recommendation/data_pipeline.py"", line 414, in __init__
    eval_batch_size, 1 + rconst.NUM_EVAL_NEGATIVES))
ValueError: Eval batch size 256 is not divisible by 1000

",ayushmankumar7,b'models:official type:bug',2020-03-20T13:28:32Z,2020-05-07T07:14:19Z,,,,,,,
8315," TypeError: expected bytes, Descriptor found while importing Keras modules","Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No custome code. just importing the modules from keras
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10
- **TensorFlow installed from (source or binary)**: installed using pip
- **TensorFlow version (use command below)**: 
tensorflow                1.6.0                    
tensorflow-base           1.10.0

keras                     2.3.1                    
keras-applications        1.0.8            
keras-preprocessing       1.1.0
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**: getting the error while importing the modules.
from keras.models import Sequential
from keras.layers import Conv2D
from keras.layers import MaxPooling2D
from keras.layers import Flatten
from keras.layers import Dense
You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

when i am firing the following imports am getting the typeerror. 
from keras.models import Sequential
from keras.layers import Conv2D
from keras.layers import MaxPooling2D
from keras.layers import Flatten
from keras.layers import Dense



### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
Using TensorFlow backend.
---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
<ipython-input-1-34e168d9265f> in <module>()
----> 1 from keras.models import Sequential
      2 from keras.layers import Conv2D
      3 from keras.layers import MaxPooling2D
      4 from keras.layers import Flatten
      5 from keras.layers import Dense

D:\ANA\envs\tf16\lib\site-packages\keras\__init__.py in <module>()
      1 from __future__ import absolute_import
      2 
----> 3 from . import utils
      4 from . import activations
      5 from . import applications

D:\ANA\envs\tf16\lib\site-packages\keras\utils\__init__.py in <module>()
      4 from . import data_utils
      5 from . import io_utils
----> 6 from . import conv_utils
      7 from . import losses_utils
      8 from . import metrics_utils

D:\ANA\envs\tf16\lib\site-packages\keras\utils\conv_utils.py in <module>()
      7 from six.moves import range
      8 import numpy as np
----> 9 from .. import backend as K
     10 
     11 

D:\ANA\envs\tf16\lib\site-packages\keras\backend\__init__.py in <module>()
----> 1 from .load_backend import epsilon
      2 from .load_backend import set_epsilon
      3 from .load_backend import floatx
      4 from .load_backend import set_floatx
      5 from .load_backend import cast_to_floatx

D:\ANA\envs\tf16\lib\site-packages\keras\backend\load_backend.py in <module>()
     88 elif _BACKEND == 'tensorflow':
     89     sys.stderr.write('Using TensorFlow backend.\n')
---> 90     from .tensorflow_backend import *
     91 else:
     92     # Try and load external backend.

D:\ANA\envs\tf16\lib\site-packages\keras\backend\tensorflow_backend.py in <module>()
      3 from __future__ import print_function
      4 
----> 5 import tensorflow as tf
      6 from tensorflow.python.eager import context
      7 from tensorflow.python.framework import device as tfdev

D:\ANA\envs\tf16\lib\site-packages\tensorflow\__init__.py in <module>()
     26 
     27 # pylint: disable=g-bad-import-order
---> 28 from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import
     29 
     30 try:

D:\ANA\envs\tf16\lib\site-packages\tensorflow\python\__init__.py in <module>()
     50 
     51 # Protocol buffers
---> 52 from tensorflow.core.framework.graph_pb2 import *
     53 from tensorflow.core.framework.node_def_pb2 import *
     54 from tensorflow.core.framework.summary_pb2 import *

D:\ANA\envs\tf16\lib\site-packages\tensorflow\core\framework\graph_pb2.py in <module>()
     13 
     14 
---> 15 from tensorflow.core.framework import node_def_pb2 as tensorflow_dot_core_dot_framework_dot_node__def__pb2
     16 from tensorflow.core.framework import function_pb2 as tensorflow_dot_core_dot_framework_dot_function__pb2
     17 from tensorflow.core.framework import versions_pb2 as tensorflow_dot_core_dot_framework_dot_versions__pb2

D:\ANA\envs\tf16\lib\site-packages\tensorflow\core\framework\node_def_pb2.py in <module>()
     13 
     14 
---> 15 from tensorflow.core.framework import attr_value_pb2 as tensorflow_dot_core_dot_framework_dot_attr__value__pb2
     16 
     17 

D:\ANA\envs\tf16\lib\site-packages\tensorflow\core\framework\attr_value_pb2.py in <module>()
     13 
     14 
---> 15 from tensorflow.core.framework import tensor_pb2 as tensorflow_dot_core_dot_framework_dot_tensor__pb2
     16 from tensorflow.core.framework import tensor_shape_pb2 as tensorflow_dot_core_dot_framework_dot_tensor__shape__pb2
     17 from tensorflow.core.framework import types_pb2 as tensorflow_dot_core_dot_framework_dot_types__pb2

D:\ANA\envs\tf16\lib\site-packages\tensorflow\core\framework\tensor_pb2.py in <module>()
     13 
     14 
---> 15 from tensorflow.core.framework import resource_handle_pb2 as tensorflow_dot_core_dot_framework_dot_resource__handle__pb2
     16 from tensorflow.core.framework import tensor_shape_pb2 as tensorflow_dot_core_dot_framework_dot_tensor__shape__pb2
     17 from tensorflow.core.framework import types_pb2 as tensorflow_dot_core_dot_framework_dot_types__pb2

D:\ANA\envs\tf16\lib\site-packages\tensorflow\core\framework\resource_handle_pb2.py in <module>()
     89 ResourceHandleProto = _reflection.GeneratedProtocolMessageType('ResourceHandleProto', (_message.Message,), dict(
     90   DESCRIPTOR = _RESOURCEHANDLEPROTO,
---> 91   __module__ = 'tensorflow.core.framework.resource_handle_pb2'
     92   # @@protoc_insertion_point(class_scope:tensorflow.ResourceHandleProto)
     93   ))

TypeError: expected bytes, Descriptor found",sidbhat1979,None,2020-03-20T10:55:15Z,2020-03-24T03:41:46Z,,,,,,,
8310,Attention OCR does not converge.,"<!--
Please make sure that this is a bug. 

As per our GitHub Policy (https://github.com/tensorflow/models/blob/master/ISSUES.md), we only address code bugs, documentation issues, and feature requests on GitHub.

Please go to Stack Overflow (http://stackoverflow.com/questions/tagged/tensorflow-model-garden) for help and support.

The research models (https://github.com/tensorflow/models/tree/master/research) are a large collection of models implemented in TensorFlow by researchers. They are not officially supported. It is up to the individual researchers to maintain the models and/or provide support on issues and pull requests.
-->

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 19.04
- Mobile device (e.g., Pixel 4, Samsung Galaxy 10) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below):
- Python version: python 3.7
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

<!-- 
You can collect some of this information using our environment capture (https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 

1. TensorFlow 1.0
`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 

2. TensorFlow 2.0
`python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`
-->

**Please provide the entire URL of the model you are using?**
<!-- (e.g., https://github.com/tensorflow/models/tree/master/official/nlp/bert) -->

**Describe the current behavior**

**Describe the expected behavior**

**Code to reproduce the issue**
<!-- Provide a reproducible test case that is the bare minimum necessary to generate the problem. -->

**Other info / logs**
<!-- Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. -->


When I train attention OCR on fsns data, my loss is not going below 30. How does one use fine-tuning and hyperparameter optimization to reduce training loss?

Also, when the same model is trained on my custom num plate images, nearly 8k images, my loss increases and fails to converge. Any inputs on how to overcome this challenge.
",Guneetkaur03,b'models:research type:bug',2020-03-19T12:30:05Z,2020-05-13T23:53:11Z,,,,,,,
8305,tf.contrib related issue with main TF API. Object detection trainining and inference export from checkpoint not working.,"Since yesterday morning 9 AM CEST I was not able to proceed training from checkpoint or even export current checkpoint via export_inference_graph.py. Tested on both TF 1.15 and 2.1.0 and it worked flawlessly up until yesterday. Is there any workaround currently?


**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes.
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux (Colab)
- Mobile device (e.g., Pixel 4, Samsung Galaxy 10) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): 
- TensorFlow version (use command below): 1.15 and 2.1.0
- Python version: 3.6.9
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 
- GPU model and memory:  depends on which one Colab assigns to me

<!-- 
You can collect some of this information using our environment capture (https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 

1. TensorFlow 1.0
`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 

2. TensorFlow 2.0
`python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`
-->

**Please provide the entire URL of the model you are using?**
https://github.com/tensorflow/models/blob/master/research/object_detection/samples/configs/faster_rcnn_inception_v2_pets.config

**Describe the current behavior**
Using /usr/local/lib/python3.6/dist-packages
Finished processing dependencies for object-detection==0.1
env: PYTHONPATH=/content/models/research:/content/models/research/slim
Traceback (most recent call last):
  File ""object_detection/builders/model_builder_test.py"", line 23, in <module>
    from object_detection.builders import model_builder
  File ""/content/models/research/object_detection/builders/model_builder.py"", line 22, in <module>
    from object_detection.builders import box_predictor_builder
  File ""/content/models/research/object_detection/builders/box_predictor_builder.py"", line 20, in <module>
    from object_detection.predictors import convolutional_box_predictor
  File ""/content/models/research/object_detection/predictors/convolutional_box_predictor.py"", line 23, in <module>
    slim = tf.contrib.slim
AttributeError: module 'tensorflow' has no attribute 'contrib'

same with train.py:

Traceback (most recent call last):
  File ""object_detection/legacy/train.py"", line 48, in <module>
    from tensorflow.contrib import framework as contrib_framework
ModuleNotFoundError: No module named 'tensorflow.contrib'

and model_main.py:
Traceback (most recent call last):
  File ""object_detection/model_main.py"", line 26, in <module>
    from object_detection import model_lib
  File ""/content/models/research/object_detection/model_lib.py"", line 27, in <module>
    from object_detection import eval_util
  File ""/content/models/research/object_detection/eval_util.py"", line 40, in <module>
    slim = tf.contrib.slim
AttributeError: module 'tensorflow' has no attribute 'contrib'

and even export_inference_graph.py:

Traceback (most recent call last):
  File ""object_detection/export_inference_graph.py"", line 108, in <module>
    from object_detection import exporter
  File ""/content/models/research/object_detection/exporter.py"", line 20, in <module>
    from tensorflow.contrib.quantize.python import graph_matcher
ModuleNotFoundError: No module named 'tensorflow.contrib'


**Describe the expected behavior**

test the model builder:

object_detection/builders/model_builder_test.py    outputs 17 in TF1(10 in TF2) successful tests


**Code to reproduce the issue**

!python object_detection/builders/model_builder_test.py

**Other info / logs**

",synergy178,b'models:research type:bug',2020-03-18T15:07:31Z,2020-04-14T15:20:41Z,,,,,,,
8300,"When trying to train attention_ocr, I am facing the following issue","In train.py at app.run(), I get the following issue:
/content/python/datasets/data/fsns/train; No such file or directory

![image](https://user-images.githubusercontent.com/43083412/76865558-e7155f80-6888-11ea-9f42-f9ad908d300d.png)
",rajphani,b'models:official type:bug',2020-03-17T14:23:22Z,2020-04-24T18:41:37Z,,,,,,,
8297,is there any complete documentation about tensorflow object detection api model traininfwith code explanation,"<!--
As per our GitHub Policy (https://github.com/tensorflow/models/blob/master/ISSUES.md), we only address code bugs, documentation issues, and feature requests on GitHub.

We will automatically close questions and help related issues.

Please go to Stack Overflow (http://stackoverflow.com/questions/tagged/tensorflow-model-garden) for questions and help.

-->
",sreenupadidapu,b'models:research type:support',2020-03-16T10:44:07Z,2020-05-12T17:31:29Z,,,,,,,
8296,Model not training well on data for multiple objects in same image,"<!--
As per our GitHub Policy (https://github.com/tensorflow/models/blob/master/ISSUES.md), we only address code bugs, documentation issues, and feature requests on GitHub.

We will automatically close questions and help related issues.

Please go to Stack Overflow (http://stackoverflow.com/questions/tagged/tensorflow-model-garden) for questions and help.

-->


I am using tensorflow object detection to retrain for face detection using WFLW dataset. Many images contain multiple faces in a single image. And I believe that training does not perform well on these dataset, becasue I have also trained for other object in which all the images contain only 1 object per image. So what should I do ?",Rutvik21,b'models:research type:support',2020-03-16T05:47:48Z,2020-05-12T18:21:24Z,,,,,,,
8295,How to get evaluation throughput in NCF implementation from ncf_keras_main.py,"<!--
As per our GitHub Policy (https://github.com/tensorflow/models/blob/master/ISSUES.md), we only address code bugs, documentation issues, and feature requests on GitHub.

We will automatically close questions and help related issues.

Please go to Stack Overflow (http://stackoverflow.com/questions/tagged/tensorflow-model-garden) for questions and help.

-->
Hi everyone, I'm playing around with the ncf codebase for r2.1.0 and I can understand the training part but I'm unable to add callbacks to get evaluation throughput directly. Any ideas?",mankeyboy,b'models:official type:support',2020-03-16T03:57:58Z,2020-06-27T05:12:50Z,,,,,,,
8293,tf.compat.v1.train.AdamOptimizer() to tf.keras.optimizers.Adam,"<!--
Please make sure that this is a feature request.

As per our GitHub Policy (https://github.com/tensorflow/models/blob/master/ISSUES.md), we only address code bugs, documentation issues, and feature requests on GitHub.

Please go to Stack Overflow (http://stackoverflow.com/questions/tagged/tensorflow-model-garden) for help and support.
-->

**Please provide the entire URL of the model you are using?**
<!-- (e.g., https://github.com/tensorflow/models/tree/master/official/nlp/bert) -->

**Describe the feature you request and the current behavior/state.**

Few models use the old train.AdamOptimizer(). I propose to update it with the Keras API, tf.keras.optimizers.Adam().

**Are you willing to contribute it (Yes/No)?**

# YES
**Any other info.**
",ayushmankumar7,b'models:official type:feature',2020-03-14T19:38:02Z,2020-03-17T19:18:36Z,,,,,,,
8291,ModuleNotFoundError: No module named 'official',"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 (64 bit)
- Mobile device (e.g., Pixel 4, Samsung Galaxy 10) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below): 2.1.0
- Python version: 3.7
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 10.1
- GPU model and memory: GTX 1050ti and 4 GB

I am running below script mentioned [here](https://github.com/tensorflow/models/tree/master/official/vision/image_classification) and it gives me  ModuleNotFoundError: No module named 'official'. 

> python mnist_main.py \
  --model_dir=$MODEL_DIR \
  --data_dir=$DATA_DIR \
  --train_epochs=10 \
  --distribution_strategy=one_device \
  --num_gpus=$NUM_GPUS \
  --download",Eshan-Agarwal,b'models:official type:bug',2020-03-13T15:24:05Z,2020-08-23T12:57:01Z,,,,,,,
8289,tf.compat.v1.logging should be implemented with tf.get_logger(),"<!--
Please make sure that this is a feature request.

As per our GitHub Policy (https://github.com/tensorflow/models/blob/master/ISSUES.md), we only address code bugs, documentation issues, and feature requests on GitHub.

Please go to Stack Overflow (http://stackoverflow.com/questions/tagged/tensorflow-model-garden) for help and support.
-->

**Please provide the entire URL of the model you are using?**
<!-- (e.g., https://github.com/tensorflow/models/tree/master/official/nlp/bert) -->

**Describe the feature you request and the current behavior/state.**
Currently, logging is performed using tf.compat.v1.logging. 
My proposal is to implement logging using tf.get_logger()

**Are you willing to contribute it (Yes/No)?**
# YES

**Any other info.**
",ayushmankumar7,b'models:official type:feature',2020-03-13T14:22:55Z,2020-05-08T22:12:32Z,,,,,,,
8287,translate.py in nlp/transformer needs upgradation with the latest API.,"<!--
Please make sure that this is a feature request.

As per our GitHub Policy (https://github.com/tensorflow/models/blob/master/ISSUES.md), we only address code bugs, documentation issues, and feature requests on GitHub.

Please go to Stack Overflow (http://stackoverflow.com/questions/tagged/tensorflow-model-garden) for help and support.
-->

**Please provide the entire URL of the model you are using?**
<!-- (e.g., https://github.com/tensorflow/models/tree/master/official/nlp/bert) -->
https://github.com/tensorflow/models/blob/master/official/nlp/transformer/translate.py

**Describe the feature you request and the current behavior/state.**
tf.compat.v1.logging.info needs to be changed using tf.get_logger()

**Are you willing to contribute it (Yes/No)?**
# YES
**Any other info.**
",ayushmankumar7,b'models:official type:feature',2020-03-13T13:47:14Z,2020-06-13T05:22:22Z,,,,,,,
8285,resnet_run_loop.py needs to be upgraded to latest tensorflow's API.,"<!--
Please make sure that this is a feature request.

As per our GitHub Policy (https://github.com/tensorflow/models/blob/master/ISSUES.md), we only address code bugs, documentation issues, and feature requests on GitHub.

Please go to Stack Overflow (http://stackoverflow.com/questions/tagged/tensorflow-model-garden) for help and support.
-->

**Please provide the entire URL of the model you are using?**
<!-- (e.g., https://github.com/tensorflow/models/tree/master/official/nlp/bert) -->
https://github.com/tensorflow/models/blob/master/official/r1/resnet/resnet_run_loop.py

**Describe the feature you request and the current behavior/state.**
Current :Uses compat.v1 on updated APIs also

Request: Use the alternative latest APIS
**Are you willing to contribute it (Yes/No)?**
# YES

**Any other info.**
",ayushmankumar7,b'models:official type:feature',2020-03-13T13:28:13Z,2020-06-13T05:18:32Z,,,,,,,
8283,transpose does not suppport  quant,"<!--
Please make sure that this is a bug. 

As per our GitHub Policy (https://github.com/tensorflow/models/blob/master/ISSUES.md), we only address code bugs, documentation issues, and feature requests on GitHub.

Please go to Stack Overflow (http://stackoverflow.com/questions/tagged/tensorflow-model-garden) for help and support.

The research models (https://github.com/tensorflow/models/tree/master/research) are a large collection of models implemented in TensorFlow by researchers. They are not officially supported. It is up to the individual researchers to maintain the models and/or provide support on issues and pull requests.
-->

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):16.04
- Mobile device (e.g., Pixel 4, Samsung Galaxy 10) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below):1.14.0
- Python version:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

<!-- 
You can collect some of this information using our environment capture (https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 

1. TensorFlow 1.0
`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 

2. TensorFlow 2.0
`python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`
-->

**Please provide the entire URL of the model you are using?**
<!-- (e.g., https://github.com/tensorflow/models/tree/master/official/nlp/bert) -->

**Describe the current behavior**
toco run failed,axis is much big or negative number
**Describe the expected behavior**
the axis should be (0,3)
**Code to reproduce the issue**
<!-- Provide a reproducible test case that is the bare minimum necessary to generate the problem. -->
tf.squeeze()+tf.transpose() will occur the bug.
if I use tf.squeeze()+tf.reshape() it pass


**Other info / logs**
<!-- Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. -->
2020-03-13 11:19:52.146016: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 2359 operators, 3524 arrays (0 quantized)
2020-03-13 11:19:52.372475: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 2359 operators, 3524 arrays (0 quantized)
2020-03-13 11:19:52.982458: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 342 operators, 672 arrays (1 quantized)
2020-03-13 11:19:52.984716: F tensorflow/lite/toco/graph_transformations/propagate_fixed_sizes.cc:1813] Check failed: axis < input_shape.dimensions_count() (1696750784 vs. 4)
Fatal Python error: Aborted

",sunzhe09,b'models:research type:bug',2020-03-13T11:22:38Z,2020-07-02T09:40:23Z,,,,,,,
8280,tf.Graph() can be used instead of tf.compat.v1.get_default_graph(),"<!--
Please make sure that this is a feature request.

As per our GitHub Policy (https://github.com/tensorflow/models/blob/master/ISSUES.md), we only address code bugs, documentation issues, and feature requests on GitHub.

Please go to Stack Overflow (http://stackoverflow.com/questions/tagged/tensorflow-model-garden) for help and support.
-->

**Please provide the entire URL of the model you are using?**
<!-- (e.g., https://github.com/tensorflow/models/tree/master/official/nlp/bert) -->
https://github.com/tensorflow/models/official/vision/image_classification.common.py
**Describe the feature you request and the current behavior/state.**
Since the required task can be done with the lastest API under tf.Graph() then why use tf.compat.v1. 
In this feature request, i propose to convert tf.compat.v1.get_default_graph() to the lastest API.


**Are you willing to contribute it (Yes/No)?**
# YES
**Any other info.**
",ayushmankumar7,b'models:official type:feature',2020-03-13T10:10:35Z,2020-05-13T23:48:09Z,,,,,,,
8273,Evaluation results not matching the Struct2depth paper ,"<!--
As per our GitHub Policy (https://github.com/tensorflow/models/blob/master/ISSUES.md), we only address code bugs, documentation issues, and feature requests on GitHub.

We will automatically close questions and help related issues.

Please go to Stack Overflow (http://stackoverflow.com/questions/tagged/tensorflow-model-garden) for questions and help.

-->
 I ran eval_depth.py from SfMLearner repo. I also tried combining all the npy files into a single npy file but the results are very bad :
abs_rel, sq_rel, rms, log_rms, d1_all, a1, a2, a3
0.3783, 5.4348, 10.2664, 0.4428, 0.0000, 0.4598, 0.7445, 0.8751

Can anyone let me know as to how to combine the files into a single npy file?It would be of great help.
this is the code I used to combine
import numpy as np
import os
import tensorflow as tf
all_arrays = []
gfile = tf.gfile
output_raw1='./output.npy'
path='~/struct2depth/out/' ###here all the predictions for the images are stored in npy format (after running inference.py)
for npfile in os.listdir(path):
all_arrays.append(np.load(os.path.join(path, npfile)))
all_arrays = np.array(all_arrays)
with gfile.Open(output_raw1, 'wb') as f:

np.save(f,  @all_arrays)
@VincentCa Can you please help me with this?",poornimajd,b'models:research type:support',2020-03-12T10:59:13Z,2020-05-13T23:16:35Z,,,,,,,
8268,modulenotfounderror: no module named tensorflow.contrib ,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",96abhijitp,None,2020-03-11T17:41:21Z,2020-03-12T03:44:25Z,,,,,,,
8260,All segmentation images are completely black,"I am executing the pascal example.
I can execute all steps, but in visual step, all segmentation images are completely black.

I am processing with GPU, Python 3.5 and Tensorflow-gpu 1.14.0.

I executed:

- ./download_and_convert_voc2012.sh
- ./local_test_mobilenetv2.sh

The image result example:

![000008_image](https://user-images.githubusercontent.com/18166522/76171979-e0436a00-616f-11ea-8f57-20e025cb0625.png)
![000008_prediction](https://user-images.githubusercontent.com/18166522/76171981-e20d2d80-616f-11ea-9d49-5ea935312661.png)

What is the problem?

Thanks
",rafaelmarconiramos,b'models:research stat:awaiting response type:bug',2020-03-08T22:06:38Z,2020-07-02T09:46:23Z,,,,,,,
8256,Tokenizer update,"By this PR I propose several improvements to the tokenizer found in transformer model:

1. Unhardcode alphanumeric charset (it is still the default). This help me to use tokenizer in tasks which require a different charsets
2. Safety check before inserting EOL. The check detects the situation where users don't include default `RESERVE_TOKENS` list into their custom `reserved_tokens` argument.
3. ~~(updated)  Debug-print the status of long-runnning token counting~~",grwlf,b'cla: yes ready to pull',2020-03-07T15:56:01Z,2020-03-20T03:13:47Z,,,,,,,
8249,alexnet in tutorials not updated to TF2.x,"<!--
As per our GitHub Policy (https://github.com/tensorflow/models/blob/master/ISSUES.md), we only address code bugs, documentation issues, and feature requests on GitHub.

We will automatically close questions and help related issues.

Please go to Stack Overflow (http://stackoverflow.com/questions/tagged/tensorflow-model-garden) for questions and help.

-->
Link to issue: 
https://github.com/tensorflow/models/blob/master/tutorials/image/alexnet/alexnet_benchmark.py

![Screenshot from 2020-03-05 22-02-40](https://user-images.githubusercontent.com/41910134/76003195-b4d13d00-5f2d-11ea-92de-62e25f9a9fb5.png)
",ayushmankumar7,b'type:support',2020-03-05T16:37:37Z,2020-03-22T16:26:55Z,,,,,,,
8246,ImportError: cannot import name 'profiler_v2',"<!--
Please make sure that this is a bug. 

As per our GitHub Policy (https://github.com/tensorflow/models/blob/master/ISSUES.md), we only address code bugs, documentation issues, and feature requests on GitHub.

Please go to Stack Overflow (http://stackoverflow.com/questions/tagged/tensorflow-model-garden) for help and support.
-->

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g., Pixel 4, Samsung Galaxy 10) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): pip3
- TensorFlow version (use command below): 2.1.0
- Python version: 3.6
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

<!-- 
You can collect some of this information using our environment capture (https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 

1. TensorFlow 1.0
`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 

2. TensorFlow 2.0
`python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`
-->

**Please provide the entire URL of the model you are using?**
<!-- (e.g., https://github.com/tensorflow/models/tree/master/official/nlp/bert) -->

**Describe the current behavior**
![Screenshot from 2020-03-05 18-05-22](https://user-images.githubusercontent.com/41910134/75982396-9444bb00-5f0c-11ea-9f7d-6ba878e63723.png)

**Describe the expected behavior**
![Screenshot from 2020-03-05 18-07-15](https://user-images.githubusercontent.com/41910134/75982424-a45c9a80-5f0c-11ea-8315-ead552c513de.png)


**Code to reproduce the issue**
<!-- Provide a reproducible test case that is the bare minimum necessary to generate the problem. -->

**Other info / logs**
<!-- Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. -->
",ayushmankumar7,b'models:official type:bug',2020-03-05T12:41:10Z,2020-05-14T06:13:35Z,,,,,,,
8244,tf.contrib not available in Tensorflow 2.0,"<!--
Please make sure that this is a bug. 

As per our GitHub Policy (https://github.com/tensorflow/models/blob/master/ISSUES.md), we only address code bugs, documentation issues, and feature requests on GitHub.

Please go to Stack Overflow (http://stackoverflow.com/questions/tagged/tensorflow-model-garden) for help and support.

The research models (https://github.com/tensorflow/models/tree/master/research) are a large collection of models implemented in TensorFlow by researchers. They are not officially supported. It is up to the individual researchers to maintain the models and/or provide support on issues and pull requests.
-->

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04
- Mobile device (e.g., Pixel 4, Samsung Galaxy 10) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): Binary
- TensorFlow version (use command below): 2.0 / 2.1.0
- Python version: 3.7.6
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory: No GPU

<!-- 
You can collect some of this information using our environment capture (https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 

1. TensorFlow 1.0
`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 

2. TensorFlow 2.0
`python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`
-->

**Please provide the entire URL of the model you are using?**
<!-- (e.g., https://github.com/tensorflow/models/tree/master/official/nlp/bert) -->
https://github.com/tensorflow/models/blob/master/research/object_detection/predictors/convolutional_box_predictor.py

**Describe the current behavior**
Training SSD Mobilenet with Tensorflow 2.0 breaks due to missing `tf.contrib` API

**Describe the expected behavior**

**Code to reproduce the issue**
<!-- Provide a reproducible test case that is the bare minimum necessary to generate the problem. -->

**Other info / logs**
<!-- Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. -->
",bornhardt,b'models:research type:bug',2020-03-05T08:23:44Z,2020-03-17T20:00:54Z,,,,,,,
8243,ImportError: cannot import name 'profiler_v2' from 'tensorflow.python.profiler' ,"When I Using official/recommendation/ncf_keras_main.py, I got:

Traceback (most recent call last):
  File ""ncf_keras_main.py"", line 37, in <module>
    from official.recommendation import ncf_common
  File ""/home/ruyin/Projects/models/official/recommendation/ncf_common.py"", line 38, in <module>
    from official.utils.misc import keras_utils
  File ""/home/ruyin/Projects/models/official/utils/misc/keras_utils.py"", line 28, in <module>
    from tensorflow.python.profiler import profiler_v2 as profiler
ImportError: cannot import name 'profiler_v2' from 'tensorflow.python.profiler' (/home/ruyin/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/profiler/__init__.py)

what's the reason?

**System information**
Linux Ubuntu 18.04
TensorFlow version: 2.1, installed from binary
Python version: 3.7
CUDA: 10.1
GPU model: 1080Ti
",ruipingyin,b'models:official type:bug',2020-03-05T07:53:22Z,2020-03-06T07:16:15Z,,,,,,,
8237,SSD mobilenet v3 converted to tflite with postprocessing does not work correctly on the device,"The problem is that: I export the [ssd_mobilenet_v3_large_coco](http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v3_large_coco_2019_08_14.tar.gz) model to a graph along with postprocessing.

```
python object_detection/export_tflite_ssd_graph.py \
--pipeline_config_path ssd_mobilenet_v3_large_coco_2019_08_14/pipeline.config \
--trained_checkpoint_prefix ssd_mobilenet_v3_large_coco_2019_08_14/model.ckpt \
--output_directory ssd_mobilenet_v3_large_coco_2019_08_14/tflite \
--add_postprocessing_op=true
```

Next, I get a graph such as a .pb file with post-processing

Then I convert the previously obtained graph into a float tflite model using the following script: 
```
tflite_convert \
--graph_def_file=tflite/tflite_graph.pb \
--output_file=tflite/frozen_inference_graph_test.tflite \
--output_format=TFLITE \
--input_arrays=normalized_input_image_tensor \
--input_shapes=1,320,320,3 \
--output_arrays=""TFLite_Detection_PostProcess,TFLite_Detection_PostProcess:1,TFLite_Detection_PostProcess:2,TFLite_Detection_PostProcess:3"" \
--allow_custom_ops
```
I use the converted model in my Android application, but I don’t get the correct results, always at the output I get strange results:

```
D/DEBUGMODELANSWEAR:  
     SCORES: 0.116135836 CLASS: 14.0
     SCORES: 0.046395004 CLASS: 0.0
     SCORES: 0.045846403 CLASS: 0.0
     SCORES: 0.045446068 CLASS: 0.0
     SCORES: 0.04536411 CLASS: 0.0
     SCORES: 0.04513964 CLASS: 0.0
     SCORES: 0.045139074 CLASS: 0.0
     SCORES: 0.04456976 CLASS: 14.0
     SCORES: 0.044314265 CLASS: 0.0
     SCORES: 0.044303298 CLASS: 0.0
```

Interestingly, I do the same actions with [ssd_mobilenet_v3_small_coco](http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v3_small_coco_2019_08_14.tar.gz), but this model works fine. Can someone tell me what I'm doing wrong and how can I fix this situation


**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Mac
- Mobile device (e.g., Pixel 4, Samsung Galaxy 10) if the issue happens on mobile device: Xiaomi mi 9
- TensorFlow installed from (source or binary):  pip
- TensorFlow version (use command below): v1.14.0-rc1-22-gaf24dc91b5 1.14.0
- Tflite mobile: 'org.tensorflow:tensorflow-lite:0.0.0-nightly'
- Python version: 3
- Bazel version (if compiling from source):  not applicable
- GCC/Compiler version (if compiling from source): not applicable
- CUDA/cuDNN version: not applicable
- GPU model and memory: not applicable

1. TensorFlow 1.0
v1.14.0-rc1-22-gaf24dc91b5 1.14.0
",AndrzejKRK,b'models:research type:bug',2020-03-04T10:35:55Z,2020-03-04T11:03:27Z,,,,,,,
8231,samples/cookbook/regression/custom_regression not compatible with TF2.x,"<!--
As per our GitHub Policy (https://github.com/tensorflow/models/blob/master/ISSUES.md), we only address code bugs, documentation issues, and feature requests on GitHub.

We will automatically close questions and help related issues.

Please go to Stack Overflow (http://stackoverflow.com/questions/tagged/tensorflow-model-garden) for questions and help.

-->
## Link to the File
https://github.com/tensorflow/models/blob/master/samples/cookbook/regression/custom_regression.py


Traceback (most recent call last):
  File ""custom_regression.py"", line 162, in <module>
    tf.logging.set_verbosity(tf.logging.INFO)
AttributeError: module 'tensorflow' has no attribute 'logging'",ayushmankumar7,b'stat:awaiting response type:support',2020-03-03T16:20:28Z,2020-05-14T16:25:35Z,,,,,,,
8230,ImportError: No module named absl,"<!--
Please make sure that this is a bug. 

As per our GitHub Policy (https://github.com/tensorflow/models/blob/master/ISSUES.md), we only address code bugs, documentation issues, and feature requests on GitHub.

Please go to Stack Overflow (http://stackoverflow.com/questions/tagged/tensorflow-model-garden) for help and support.
-->

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g., Pixel 4, Samsung Galaxy 10) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below):
- Python version:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

<!-- 
You can collect some of this information using our environment capture (https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 

1. TensorFlow 1.0
`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 

2. TensorFlow 2.0
`python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`
-->

**Please provide the entire URL of the model you are using?**
<!-- (e.g., https://github.com/tensorflow/models/tree/master/official/nlp/bert) -->
https://github.com/tensorflow/models/blob/master/official/recommendation/run.sh

**Describe the current behavior**
![Screenshot from 2020-03-03 20-20-24](https://user-images.githubusercontent.com/41910134/75787376-a4359100-5d8c-11ea-8779-f70d9d5d11e5.png)



**Describe the expected behavior**

**Code to reproduce the issue**
<!-- Provide a reproducible test case that is the bare minimum necessary to generate the problem. -->

**Other info / logs**
<!-- Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. -->
",ayushmankumar7,b'models:official type:bug',2020-03-03T14:52:09Z,2020-03-08T08:39:13Z,,,,,,,
8222,ModuleNotFoundError: No module named 'tensorflow.python.training.checkpointable',"<!--
Please make sure that this is a documentation issue. 

As per our GitHub Policy (https://github.com/tensorflow/models/blob/master/ISSUES.md), we only address code bugs, documentation issues, and feature requests on GitHub.

Please go to Stack Overflow (http://stackoverflow.com/questions/tagged/tensorflow-model-garden) for help and support.

The research models (https://github.com/tensorflow/models/tree/master/research) are a large collection of models implemented in TensorFlow by researchers. They are not officially supported. It is up to the individual researchers to maintain the models and/or provide support on issues and pull requests.
-->

**Documentation URL(s) with the issue:**
<!-- Please provide a link to the documentation entry, for example: https://github.com/tensorflow/models/blob/master/research/README.md -->
when i start training using this command 

**python train.py --logtostderr --train_dir=training/ --pipeline_config_path=training/faster_rcnn_resnet101_voc07.config**

and get respond something like this

**2020-03-01 23:00:07.833275: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll
Traceback (most recent call last):
  File ""train.py"", line 48, in <module>
    from tensorflow.contrib import framework as contrib_framework
  File ""C:\Users\Lab Visual I\Anaconda3\envs\tensorflow_gpu\lib\site-packages\tensorflow\contrib\__init__.py"", line 27, in <module>
    from tensorflow.contrib import checkpoint
  File ""C:\Users\Lab Visual I\Anaconda3\envs\tensorflow_gpu\lib\site-packages\tensorflow\contrib\checkpoint\__init__.py"", line 37, in <module>
    from tensorflow.contrib.checkpoint.python.containers import UniqueNameTracker
  File ""C:\Users\Lab Visual I\Anaconda3\envs\tensorflow_gpu\lib\site-packages\tensorflow\contrib\checkpoint\python\containers.py"", line 20, in <module>
    from tensorflow.python.training.checkpointable import base as checkpointable_lib
ModuleNotFoundError: No module named 'tensorflow.python.training.checkpointable'**


**Description of the issue (what needs to be changed):**
i really dont know how to fix it, i had searched on github and got nothing.
",inskaf,b'models:research type:docs',2020-03-01T16:08:22Z,2020-07-02T09:50:39Z,,,,,,,
8201,ModuleNotFoundError: No module named 'official',"<!--
Please make sure that this is a bug. 

As per our GitHub Policy (https://github.com/tensorflow/models/blob/master/ISSUES.md), we only address code bugs, documentation issues, and feature requests on GitHub.

Please go to Stack Overflow (http://stackoverflow.com/questions/tagged/tensorflow) for help and support.
-->

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g., Pixel 4, Samsung Galaxy 10) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): pip3
- TensorFlow version (use command below): 2.1.0
- Python version: 3.6
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

<!-- 
You can collect some of this information using our environment capture (https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 

1. TensorFlow 1.0
`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 

2. TensorFlow 2.0
`python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`
-->

**Please provide the entire URL of the model you are using?**
<!-- (e.g., https://github.com/tensorflow/models/tree/master/official/nlp/bert) -->

**Describe the current behavior**
![Screenshot from 2020-02-24 22-25-56](https://user-images.githubusercontent.com/41910134/75345417-b4e49380-58c2-11ea-8ade-c8be6ecbe8f5.png)


**Describe the expected behavior**

**Code to reproduce the issue**
<!-- Provide a reproducible test case that is the bare minimum necessary to generate the problem. -->

**Other info / logs**
<!-- Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. -->
",ayushmankumar7,b'models:official type:bug',2020-02-26T12:36:42Z,2020-02-27T11:30:44Z,,,,,,,
8200,GPU Support for official models detection ,"<!--
Please make sure that this is a feature request.

As per our GitHub Policy (https://github.com/tensorflow/models/blob/master/ISSUES.md), we only address code bugs, documentation issues, and feature requests on GitHub.

Please go to Stack Overflow (http://stackoverflow.com/questions/tagged/tensorflow) for help and support.
-->

**Please provide the entire URL of the model you are using?**
https://github.com/tensorflow/models/tree/master/official/vision/detection

**Describe the feature you request and the current behavior/state.**
I want train the retinanet in GPU,Please tell me how long it will be supported.
**Are you willing to contribute it (Yes/No)?**
Yes
**Any other info.**
",weichen456,b'models:official type:feature',2020-02-26T10:56:33Z,2020-02-27T18:46:34Z,,,,,,,
8196,official/benchmark/models/resnet_cifar_main.py name 'absl_app' is not defined,"It caused by this commit https://github.com/tensorflow/models/commit/02af9bb524030d1a133d7380207fbe6776865289 

`from absl import app as absl_app` has been removed, so the test can't run.",chuanqi129,b'models:official type:bug',2020-02-26T07:25:23Z,2020-02-26T16:53:56Z,,,,,,,
8190,Change the Documentation totally for Python3,"<!--
Please make sure that this is a documentation issue. 

As per our GitHub Policy (https://github.com/tensorflow/models/blob/master/ISSUES.md), we only address code bugs, documentation issues, and feature requests on GitHub.

Please go to Stack Overflow (http://stackoverflow.com/questions/tagged/tensorflow) for help and support.
-->

**Documentation URL(s) with the issue:**
<!-- https://github.com/tensorflow/models/blob/master/official/README.md -->

**Description of the issue (what needs to be changed):**

SInce, PSF has stopped its support for Python2 so the code samples for Python2 may not be needed now. 

We can convert the pip to pip3 and remove the codes dedicated for python2. This will help developes to just copy and paste the files only.
",ayushmankumar7,b'models:official type:docs',2020-02-25T04:15:43Z,2020-05-20T04:44:26Z,,,,,,,
8188,Graph After Training is Different Than Pretrained Model's Graph (MobileNetV2),"I have trained an image classification model (MobileNetV2) using train_image_classifier.py and the resulting model's graph is different than the pretrained model given at:

https://github.com/tensorflow/models/tree/master/research/slim/nets/mobilenet

My model has extra nodes such as `Logits/Dropout/dropout_1/Cast`. I have asked this as a question at stackoverflow. See below for graph outputs from tensorboard and list of extra nodes :

Pretrained MobileNetV2's graph:
https://i.stack.imgur.com/CozaP.jpg

My model's graph after training:
https://i.stack.imgur.com/ilJbp.jpg

https://stackoverflow.com/questions/60378750/tf-slim-image-classification-model-nodes-are-different-from-given-pretrained-net

But this seems more like a bug or version mismatch to me. How can I make sure, after training I have the same graph structure as the pretrained model (MobileNetV2)?",menessahin,b'models:research type:bug',2020-02-24T18:33:46Z,2020-05-28T04:56:00Z,,,,,,,
8186,ModuleNotFoundError: No module named 'mock',"<!--
Please make sure that this is a bug. 

As per our GitHub Policy (https://github.com/tensorflow/models/blob/master/ISSUES.md), we only address code bugs, documentation issues, and feature requests on GitHub.

Please go to Stack Overflow (http://stackoverflow.com/questions/tagged/tensorflow) for help and support.
-->

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04 LTS
- Mobile device (e.g., Pixel 4, Samsung Galaxy 10) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): pip3
- TensorFlow version (use command below): 2.1.0
- Python version: 3.6
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 
- GPU model and memory:

<!-- 
You can collect some of this information using our environment capture (https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 

1. TensorFlow 1.0
`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 

2. TensorFlow 2.0
`python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`
-->

**Please provide the entire URL of the model you are using?**
<!-- (https://github.com/tensorflow/models/blob/master/official/recommendation/ncf_test.py) -->

**Describe the current behavior**
![Screenshot from 2020-02-24 22-25-56](https://user-images.githubusercontent.com/41910134/75173550-10910e80-5755-11ea-9239-9e7f41efb333.png)

**Describe the expected behavior**
mock should be included in requirements.txt
**Code to reproduce the issue**
<!-- Provide a reproducible test case that is the bare minimum necessary to generate the problem. -->

**Other info / logs**
<!-- Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. -->
",ayushmankumar7,b'models:official type:bug',2020-02-24T16:59:44Z,2020-02-24T20:09:57Z,,,,,,,
8173,As I now this model build for multi classification. What I have to change to use this model for binary classification?,"<!--
Please make sure that this is a feature request. 

As per our GitHub Policy (https://github.com/tensorflow/models/blob/master/ISSUES.md), we only address code bugs, documentation issues, and feature requests on GitHub.

Please go to Stack Overflow (http://stackoverflow.com/questions/tagged/tensorflow) for help and support.

The research models (https://github.com/tensorflow/models/tree/master/research) are a large collection of models implemented in TensorFlow by researchers. They are not officially supported. It is up to the individual researchers to maintain the models and/or provide support on issues and pull requests.
-->

**Please provide the entire URL of the model you are using?**
<!-- (e.g., https://github.com/tensorflow/models/tree/master/official/nlp/bert) -->

**Describe the feature you request and the current behavior/state.**

**Are you willing to contribute it (Yes/No)?**

**Any other info.**
",SabinaUS,b'models:research type:feature',2020-02-21T02:41:09Z,2020-02-21T20:14:53Z,,,,,,,
8166, Can I train my own dataset in ResNet,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",SabinaUS,b'models:official type:support',2020-02-20T13:39:25Z,2020-05-08T22:16:01Z,,,,,,,
8164,How I can use my own dataset for training ResNet model,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",SabinaUS,b'models:official type:support',2020-02-20T12:15:21Z,2020-02-21T21:46:15Z,,,,,,,
8155,loss_1=loss_2 in tensorboard when I did training using model_main.py,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",leedo-hub,b'stat:awaiting response',2020-02-19T07:54:32Z,2020-06-15T12:12:52Z,,,,,,,
8154,the vis.py don`t work,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:  ~/cxj/models/research
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**:pip install tensorflow-gpu
- **TensorFlow version (use command below)**:1.14.0
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:CUDA 10.0 cuDNN 7.6.5
- **GPU model and memory**:Getforce 1060 16G
- **Exact command to reproduce**:
`
#the train command
python deeplab/train.py \
    --logtostderr \
    --training_number_of_steps=200 \
    --train_split=""train"" \
    --model_variant=""xception_65"" \
    --atrous_rates=6 \
    --atrous_rates=12 \
    --atrous_rates=18 \
    --output_stride=16 \
    --decoder_output_stride=4 \
    --train_crop_size=321,321 \
    --train_batch_size=2 \
    --dataset=""mydata"" \
    --tf_initial_checkpoint='/home/aiyunji/cxj/models/research/deeplab/backbone/deeplabv3_cityscapes_train/model.ckpt' \
    --train_logdir='/home/aiyunji/cxj/models/research/deeplab/exp/train_on_train_set/train' \
    --dataset_dir='/home/aiyunji/cxj/models/research/deeplab/datasets/lv/tfrecord'

#the eval command
python deeplab/eval.py \
  --logtostderr \
  --eval_split=""val"" \
  --model_variant=""xception_65"" \
  --atrous_rates=6 \
  --atrous_rates=12 \
  --atrous_rates=18 \
  --output_stride=16 \
  --decoder_output_stride=4 \
  --eval_crop_size=321,321 \
  --min_resize_value=321 \
  --max_resize_value=321 \
  --dataset=""mydata"" \
  --checkpoint_dir=""/home/aiyunji/cxj/models/research/deeplab/exp/train_on_train_set/train"" \
  --eval_logdir=""/home/aiyunji/cxj/models/research/deeplab/exp/train_on_train_set/eval"" \
  --dataset_dir=""/home/aiyunji/cxj/models/research/deeplab/datasets/lv/tfrecord"" \
  --max_number_of_evaluations=1

#the vis command
#command1
python deeplab/vis.py \
    --logtostderr \
    --vis_split=""val"" \
    --model_variant=""xception_65"" \
    --atrous_rates=6 \
    --atrous_rates=12 \
    --atrous_rates=18 \
    --output_stride=16 \
    --decoder_output_stride=4 \
    --vis_crop_size=531,531 \
    --dataset=""mydata"" \
    --colormap_type=""pascal"" \
    --checkpoint_dir='/home/aiyunji/cxj/models/research/deeplab/exp/train_on_train_set/train' \
    --vis_logdir='/home/aiyunji/cxj/models/research/deeplab/exp/train_on_train_set/vis' \
    --dataset_dir='/home/aiyunji/cxj/models/research/deeplab/datasets/lv/tfrecord'

#command2
python deeplab/vis.py \
  --logtostderr \
  --vis_split=""val"" \
  --model_variant=""xception_65"" \
  --atrous_rates=6 \
  --atrous_rates=12 \
  --atrous_rates=18 \
  --output_stride=16 \
  --decoder_output_stride=4 \
  --vis_crop_size=321,321 \
  **--min_resize_value=321 \
  --max_resize_value=321 \**
  --dataset=""mydata"" \
  --checkpoint_dir='/home/aiyunji/cxj/models/research/deeplab/exp/train_on_train_set/train' \
  --vis_logdir=""/home/aiyunji/cxj/models/research/deeplab/exp/train_on_train_set/vis"" \
  --dataset_dir=""/home/aiyunji/cxj/models/research/deeplab/datasets/lv/tfrecord"" \
  --max_number_of_iterations=1

`

### Describe the problem
I passed the model_test.py. And train.py also work.
But when i wanted to eval and vis.It went wrong.

when I use the eval command without the --min_resize_value=321 \--max_resize_value=321
--max_number_of_evaluations=1, the wrong occurred.The log was bellow.

`2020-02-19 15:11:00.387115: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2020-02-19 15:11:01.176250: W tensorflow/core/framework/op_kernel.cc:1502] OP_REQUIRES failed at spacetobatch_op.cc:219 : Invalid argument: padded_shape[1]=29 is not divisible by block_shape[1]=2
Traceback (most recent call last):
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py"", line 1356, in _do_call
    return fn(*args)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py"", line 1341, in _run_fn
    options, feed_dict, fetch_list, target_list, run_metadata)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py"", line 1429, in _call_tf_sessionrun
    run_metadata)
tensorflow.python.framework.errors_impl.InvalidArgumentError: 2 root error(s) found.
  (0) Invalid argument: padded_shape[1]=29 is not divisible by block_shape[1]=2
	 [[{{node xception_65/exit_flow/block2/unit_1/xception_module/separable_conv1_depthwise/depthwise/SpaceToBatchND}}]]
	 [[mean_iou/AssignAdd/_4527]]
  (1) Invalid argument: padded_shape[1]=29 is not divisible by block_shape[1]=2
	 [[{{node xception_65/exit_flow/block2/unit_1/xception_module/separable_conv1_depthwise/depthwise/SpaceToBatchND}}]]
0 successful operations.
0 derived errors ignored.
`

But after add the command --min_resize_value=321 \--max_resize_value=321
--max_number_of_evaluations=1 suggerted by the issue in here,the eval command work like below.

`
2020-02-19 15:15:39.522904: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
eval/miou_1.0_class_4[0]
eval/miou_1.0_class_3[0.00103092787]
eval/miou_1.0_class_1[nan]
eval/miou_1.0_class_0[0.486860573]
eval/miou_1.0_class_5[nan]
eval/miou_1.0_class_2[0.135669887]
eval/miou_1.0_overall[0.124712273]
`

And then I try this way in vis command.But it occurd another problem as below.

`
Traceback (most recent call last):
  File ""deeplab/vis.py"", line 327, in <module>
    tf.app.run()
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/platform/app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""/home/aiyunji/.local/lib/python3.5/site-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/home/aiyunji/.local/lib/python3.5/site-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""deeplab/vis.py"", line 274, in main
    align_corners=True), 3)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/image_ops_impl.py"", line 1182, in resize_images
    skip_resize_if_same=True)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/image_ops_impl.py"", line 1048, in _resize_images_common
    new_height_const = size_const_as_shape.dims[0].value
TypeError: 'NoneType' object is not subscriptable

`

If I didn`t add the command command --min_resize_value=321 \--max_resize_value=321 in vis command.The log liked below.

`
INFO:tensorflow:Visualizing batch 2
I0219 15:23:10.167136 140088710698752 vis.py:303] Visualizing batch 2
INFO:tensorflow:Visualizing batch 3
I0219 15:23:10.292280 140088710698752 vis.py:303] Visualizing batch 3
2020-02-19 15:23:10.658753: W tensorflow/core/framework/op_kernel.cc:1502] OP_REQUIRES failed at spacetobatch_op.cc:219 : Invalid argument: padded_shape[0]=74 is not divisible by block_shape[0]=18
2020-02-19 15:23:10.658821: W tensorflow/core/framework/op_kernel.cc:1502] OP_REQUIRES failed at spacetobatch_op.cc:219 : Invalid argument: padded_shape[0]=62 is not divisible by block_shape[0]=12
2020-02-19 15:23:10.658838: W tensorflow/core/framework/op_kernel.cc:1502] OP_REQUIRES failed at spacetobatch_op.cc:219 : Invalid argument: padded_shape[0]=50 is not divisible by block_shape[0]=6
Traceback (most recent call last):
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py"", line 1356, in _do_call
    return fn(*args)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py"", line 1341, in _run_fn
    options, feed_dict, fetch_list, target_list, run_metadata)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py"", line 1429, in _call_tf_sessionrun
    run_metadata)
tensorflow.python.framework.errors_impl.InvalidArgumentError: 2 root error(s) found.
  (0) Invalid argument: padded_shape[0]=74 is not divisible by block_shape[0]=18
	 [[{{node aspp3_depthwise/depthwise/SpaceToBatchND}}]]
	 [[ArgMax/_4403]]
  (1) Invalid argument: padded_shape[0]=74 is not divisible by block_shape[0]=18
	 [[{{node aspp3_depthwise/depthwise/SpaceToBatchND}}]]
0 successful operations.
0 derived errors ignored.
`
I thought it was the same when I used eval command without the command min_resize_value=321 \--max_resize_value=321.

I really want to know how to solve this problem.
Look forward to your soonest reply.



I made several changes in the code.

**In train.py:**

`
flags.DEFINE_boolean('initialize_last_layer', False,
                     'Initialize the last layer.')

flags.DEFINE_boolean('last_layers_contain_logits_only', True,
                     'Only consider logits as last layers or not.')

`
**In train_util.py**

`
# Variables that will not be restored.
exclude_list = ['global_step','logits']
if not initialize_last_layer:
exclude_list.extend(last_layers)
`

**and add my data in segmentation_dataset.py**
`
_MYDATA_INFORMATION = DatasetDescriptor(
    splits_to_sizes={
        'train': 40,  # num of samples in images/training
        'val': 4,  # num of samples in images/validation
    },
    num_classes=6,
    ignore_label=255,
)

_DATASETS_INFORMATION = {
    'cityscapes': _CITYSCAPES_INFORMATION,
    'pascal_voc_seg': _PASCAL_VOC_SEG_INFORMATION,
    'ade20k': _ADE20K_INFORMATION,
    'mydata': _MYDATA_INFORMATION
}
`
Thank you very much！





 

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",xixixijie,None,2020-02-19T07:32:59Z,2020-09-21T11:07:39Z,,,,,,,
8125,Can you share the email of the contributor with me?,"I am very interested in the ""faster_rcnn_inception_resnet_v2_atrous_oid_2018_01_28"". And I have some questions about it. So could you share the email of the contributor with me?


Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**: N/A
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: N/A
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: N/A
- **TensorFlow installed from (source or binary)**: N/A
- **TensorFlow version (use command below)**: N/A
- **Bazel version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**: N/A

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",username123062,b'models:research',2020-02-10T12:33:26Z,2020-04-15T19:51:47Z,,,,,,,
8115,rewriter,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",KangGrandesty,None,2020-02-07T10:33:53Z,2020-02-07T10:35:10Z,,,,,,,
8111,Error in installation instructions for DELF,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
models/research/delf/INSTALL_INSTRUCTIONS.md
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**: 1.14.0
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:  import delf

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

### Describe the problem
This is a documentation problem. A problem with the install instructions: `/models/research/delf/INSTALL_INSTRUCTIONS.md`. The instructions have you install the `nets` module inside `models/research/slim/`. To let python know where to find the `nets` package, it then instructs you to append `models/research/` to the PYTHONPATH, whereas it should be asking you to append `models/research/slim/` to the PYTHONPATH, because the `nets` package is at location `models/research/slim/nets`. Thus, when you finish the installation as instructed, when you run `install delf`, python runs another line `from nets import resnet_v1`, but it can't find `nets` because the PYTHONPATH was not set correctly.
Adding `models/research/slim` to the PYTHONPATH fixes the problem.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.

>>> import delf
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/data/delf/delf/__init__.py"", line 28, in <module>
    from delf.python import delf_v1
  File ""/data/delf/delf/python/delf_v1.py"", line 30, in <module>
    from nets import resnet_v1
ModuleNotFoundError: No module named 'nets'
",tjennz12,b'models:research type:docs',2020-02-04T21:25:18Z,2020-05-04T21:34:08Z,,,,,,,
8107,quantization-aware training of ResNet50 model,"Hello,
While I'm working on transfer learning of ResNet50 model, I'm going to do quantization aware training of the final model.
I have a run-time issue in tf.contrib.quantize.create_training_graph method when I do quantization aware training of Resnet50.
Traceback (most recent call last):
File ""C:\Program Files\JetBrains\PyCharm Community Edition 2019.1\helpers\pydev\pydevd.py"", line 1741, in
main()
File ""C:\Program Files\JetBrains\PyCharm Community Edition 2019.1\helpers\pydev\pydevd.py"", line 1735, in main
globals = debugger.run(setup['file'], None, None, is_module)
File ""C:\Program Files\JetBrains\PyCharm Community Edition 2019.1\helpers\pydev\pydevd.py"", line 1135, in run
pydev_imports.execfile(file, globals, locals) # execute the script
File ""C:\Program Files\JetBrains\PyCharm Community Edition 2019.1\helpers\pydev_pydev_imps_pydev_execfile.py"", line 18, in execfile
exec(compile(contents+""\n"", file, 'exec'), glob, loc)
File ""D:/Jin/Internet_Task/Jobs/2019/2019.11.20-fr_fl_rasppi-sridhar/work/fr_jin/fr_jin/test_quant_aware_training.py"", line 42, in
tf.contrib.quantize.create_training_graph(sess.graph)
File ""C:\Users\admin\Anaconda3\envs\py37_tf1.x\lib\site-packages\tensorflow_core\contrib\quantize\python\quantize_graph.py"", line 122, in create_training_graph
freeze_bn_delay=freeze_bn_delay)
File ""C:\Users\admin\Anaconda3\envs\py37_tf1.x\lib\site-packages\tensorflow_core\contrib\quantize\python\quantize_graph.py"", line 73, in _create_graph
is_training=is_training)
File ""C:\Users\admin\Anaconda3\envs\py37_tf1.x\lib\site-packages\tensorflow_core\contrib\quantize\python\fold_batch_norms.py"", line 53, in FoldBatchNorms
graph, is_training, freeze_batch_norm_delay=freeze_batch_norm_delay)
File ""C:\Users\admin\Anaconda3\envs\py37_tf1.x\lib\site-packages\tensorflow_core\contrib\quantize\python\fold_batch_norms.py"", line 98, in _FoldFusedBatchNorms
freeze_batch_norm_delay=freeze_batch_norm_delay))
File ""C:\Users\admin\Anaconda3\envs\py37_tf1.x\lib\site-packages\tensorflow_core\contrib\quantize\python\fold_batch_norms.py"", line 384, in _ComputeBatchNormCorrections
match.moving_variance_tensor + match.batch_epsilon)
TypeError: unsupported operand type(s) for +: 'NoneType' and 'float'

I think that the problem is the batch normalization of ResNet50.
I'm using Python 3.7 and tensorflow 1.14/1.15.
Could anybody help me for this issue?
Thanks",rose-jinyang,b'models:official type:support',2020-02-03T11:28:56Z,2020-05-13T21:56:24Z,,,,,,,
8091," Import Statements in Nasnet.py: from tensorflow.contrib import framework as contrib_framework, from tensorflow.contrib import layers as contrib_layers, from tensorflow.contrib import training as contrib_training","Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",RACHANAMOVVA09,None,2020-01-27T19:54:07Z,2020-01-28T17:59:29Z,,,,,,,
8078,[BUGS] The recent update(1 hr ago) on reserch/slim/net has some problems,"there are some files with 
`from tensorflow.contrib import slim as contrib_slim`
which suggest the tensorflow version used must be < 2.0 since tf2.0 doesnt have the contrib attribute.

and then in the same file compat.v1 is present.
eg:
```
with tf.compat.v1.variable_scope(scope, 'Block17', [net], reuse=reuse):
    with tf.compat.v1.variable_scope('Branch_0'):
```

and there is no compat.v1 for tf versions < 2.0

i came across this in reserch/slim/nets/inception_resnet_v2.py",richardjoy530,b'models:research type:bug',2020-01-22T03:18:28Z,2020-05-15T10:48:56Z,,,,,,,
8063,Fix bug of class DenseEinsum,This pr fixs bug of class DenseEinsum.,ZhuBaohe,b'cla: yes',2020-01-19T02:27:33Z,2020-01-22T08:08:36Z,,,,,,,
8061,Ideal value of Global Scale Var : Struct2Depth,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**: Struct2Depth
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes in pytorch
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: Not needed
- **TensorFlow version (use command below)**: Not needed
- **Bazel version (if compiling from source)**: Not needed
- **CUDA/cuDNN version**: 10
- **GPU model and memory**: GeForce 11GB
- **Exact command to reproduce**: None

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

### Describe the problem
Hi @aneliaangelova !

Could you please let me know what should be the ideal value of global scale var, when its trained?

I am trying to implement ""object constraint loss"" in pytorch but facing difficulties. The scale var I defined slowly decreases to zero. I posted a similar question on stackoverflow : https://stackoverflow.com/questions/59800247/pytorch-equivalent-of-tf-variable

Thankyou!

",ezorfa,b'models:research type:support',2020-01-18T12:03:22Z,2020-06-09T18:29:24Z,,,,,,,
8041,AssertionError: Some objects had attributes which were not restored,"### System information
- **What is the top-level directory of the model you are using**: `models/official/nlp/bert/` in https://github.com/tensorflow/models/releases/tag/v2.0
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Mac Catalina
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 2.0 (Released version https://github.com/tensorflow/models/releases/tag/v2.0)
- **Bazel version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**: 

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

Current repository doesn't provide Bert Multilingual pretrained model for download. So obtained the model from [BERT-Base, Multilingual Cased (New, recommended)](https://github.com/google-research/bert/blob/master/multilingual.md).
Converted to TF2 compatible version using the script `tf1_to_keras_checkpoint_converter.py` available in the released version. 
Trying to run the `run_classifier` with the converted checkpoint fails with the `AssertionError: Some objects had attributes which were not restored` similar to the issue https://github.com/tensorflow/models/issues/7412

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.

```
Instructions for updating:
Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future.
W0113 16:05:10.320911 4773436864 deprecation.py:323] From /opt/anaconda3/envs/ner-bert-tf-2.0/lib/python3.7/site-packages/tensorflow_core/python/training/tracking/util.py:1249: NameBasedSaverStatus.__init__ (from tensorflow.python.training.tracking.util) is deprecated and will be removed in a future version.
Instructions for updating:
Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future.
Traceback (most recent call last):
  File ""/Users/poornima/python_projects/ner-bert-tf-2.0/models-2.0/official/nlp/bert/run_classifier.py"", line 321, in <module>
    app.run(main)
  File ""/opt/anaconda3/envs/ner-bert-tf-2.0/lib/python3.7/site-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/opt/anaconda3/envs/ner-bert-tf-2.0/lib/python3.7/site-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""/Users/poornima/python_projects/ner-bert-tf-2.0/models-2.0/official/nlp/bert/run_classifier.py"", line 314, in main
    run_bert(strategy, input_meta_data)
  File ""/Users/poornima/python_projects/ner-bert-tf-2.0/models-2.0/official/nlp/bert/run_classifier.py"", line 287, in run_bert
    run_eagerly=FLAGS.run_eagerly)
  File ""/Users/poornima/python_projects/ner-bert-tf-2.0/models-2.0/official/nlp/bert/run_classifier.py"", line 164, in run_bert_classifier
    custom_callbacks=None)
  File ""/Users/poornima/python_projects/ner-bert-tf-2.0/models-2.0/official/nlp/bert/run_classifier.py"", line 208, in run_keras_compile_fit
    checkpoint.restore(init_checkpoint).assert_existing_objects_matched()
  File ""/opt/anaconda3/envs/ner-bert-tf-2.0/lib/python3.7/site-packages/tensorflow_core/python/training/tracking/util.py"", line 958, in assert_existing_objects_matched
    return self.assert_consumed()
  File ""/opt/anaconda3/envs/ner-bert-tf-2.0/lib/python3.7/site-packages/tensorflow_core/python/training/tracking/util.py"", line 943, in assert_consumed
    """".join(unused_attribute_strings)))
AssertionError: Some objects had attributes which were not restored:
    MirroredVariable:{
  0 /job:localhost/replica:0/task:0/device:CPU:0: <tf.Variable 'save_counter:0' shape=() dtype=int64, numpy=0>
}: ['save_counter']
```

@saberkun Please advise.",pcraman,b'models:official type:support',2020-01-14T00:15:26Z,2020-04-21T03:25:58Z,,,,,,,
8038,"Update VGGish README for new path, soundfile",Attempting to rerun the README instructions revealed longstanding bugs.,dpwe,b'cla: yes',2020-01-13T19:24:00Z,2020-02-08T04:34:44Z,,,,,,,
8033,AttributeError:module 'tensorflow.tools.api.generator.api.image' has no attribute 'resize',"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",frw511,b'stat:awaiting response type:support',2020-01-13T09:38:48Z,2020-07-14T09:19:46Z,,,,,,,
8025,AttributeError:module 'tensorflow.image' has no attribute 'resize' ,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",frw511,b'stat:awaiting response type:support',2020-01-10T10:19:21Z,2020-07-14T09:21:29Z,,,,,,,
8020,tf.contrib.slim is not worked in tensorflow 2.0 what is the alternative for that?,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",sreenupadidapu,b'models:research type:support',2020-01-09T10:01:42Z,2020-07-14T09:23:20Z,,,,,,,
8000,Fix multi-scale prediction bug in model.py,The prediction returned in `predict_labels_multi_scale()` is `outputs_to_predictions` instead of `predictions`.,JasonLiTW,b'cla: yes',2020-01-01T21:23:20Z,2020-01-02T17:51:30Z,,,,,,,
7991,TypeError: in converted code:,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",xxwang1,b'type:support',2019-12-29T02:48:31Z,2020-06-02T10:55:05Z,,,,,,,
7975,Possible mismatch between the provided ResNet V1 50 pre-trained ckpt and pb,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: no
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: win10
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.15
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

### Describe the problem

I found that maybe there's a mismatch between the provided ResNet V1 50 pre-trained model ckpt and generated resnet_v1_50.pb.

There's how to reproduce:

```
python .\models\research\slim\export_inference_graph.py --model_name=resnet_v1_50 --output_file=./resnet_v1_50_var.pb
# download ckpt from http://download.tensorflow.org/models/resnet_v1_50_2016_08_28.tar.gz and extract to the working directory
python ~\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow_core\python\tools\freeze_graph.py --input_graph=.\resnet_v1_50_var.pb --input_checkpoint=.\resnet_v1_50.ckpt --input_binary=true --output_graph=.\resnet_v1_50.pb --output_node_names=resnet_v1_50/predictions/Reshape_1
```

### Source code / logs
```
WARNING:tensorflow:From C:\\Users\\v-xiat\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\tools\\freeze_graph.py:127: checkpoint_exists (from 
tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to check for files with this prefix.
W1221 17:41:38.434148 19332 deprecation.py:323] From C:\\Users\\v-xiat\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\tools\\freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to check for files with this prefix.
2019-12-21 17:41:39.003578: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations:  AVX AVX2
To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags.
2019-12-21 17:41:39.022982: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 12. Tune using inter_op_parallelism_threads for best performance.
INFO:tensorflow:Restoring parameters from .\resnet_v1_50.ckpt
I1221 17:41:39.283333 19332 saver.py:1284] Restoring parameters from .\resnet_v1_50.ckpt
Traceback (most recent call last):
  File ""C:\Users\v-xiat\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow_core\python\client\session.py"", line 1365, in _do_call
    return fn(*args)
  File ""C:\Users\v-xiat\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow_core\python\client\session.py"", line 1350, in _run_fn
    target_list, run_metadata)
  File ""C:\Users\v-xiat\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow_core\python\client\session.py"", line 1443, in _call_tf_sessionrun
    run_metadata)
tensorflow.python.framework.errors_impl.InvalidArgumentError: Assign requires shapes of both tensors to match. lhs shape= [1001] rhs shape= [1000]
         [[{{node save/Assign_265}}]]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Users\v-xiat\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow_core\python\training\saver.py"", line 1290, in restore
    {self.saver_def.filename_tensor_name: save_path})
  File ""C:\Users\v-xiat\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow_core\python\client\session.py"", line 956, in run
    run_metadata_ptr)
  File ""C:\Users\v-xiat\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow_core\python\client\session.py"", line 1180, in _run
    feed_dict_tensor, options, run_metadata)
  File ""C:\Users\v-xiat\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow_core\python\client\session.py"", line 1359, in _do_run
    run_metadata)
  File ""C:\Users\v-xiat\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow_core\python\client\session.py"", line 1384, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.InvalidArgumentError: Assign requires shapes of both tensors to match. lhs shape= [1001] rhs shape= [1000]
         [[node save/Assign_265 (defined at Users\v-xiat\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow_core\python\framework\ops.py:1748) ]]

Original stack trace for 'save/Assign_265':
  File ""\Users\\v-xiat\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\tools\\freeze_graph.py"", line 491, in <module>
    run_main()
  File ""\Users\\v-xiat\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\tools\\freeze_graph.py"", line 487, in run_main
    app.run(main=my_main, argv=[sys.argv[0]] + unparsed)
  File ""Users\v-xiat\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow_core\python\platform\app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""Users\v-xiat\AppData\Local\Continuum\anaconda3\lib\site-packages\absl\app.py"", line 299, in run
    _run_main(main, args)
  File ""Users\v-xiat\AppData\Local\Continuum\anaconda3\lib\site-packages\absl\app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""\Users\\v-xiat\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\tools\\freeze_graph.py"", line 486, in <lambda>
    my_main = lambda unused_args: main(unused_args, flags)
  File ""\Users\\v-xiat\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\tools\\freeze_graph.py"", line 378, in main
    flags.saved_model_tags, checkpoint_version)
  File ""\Users\\v-xiat\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\tools\\freeze_graph.py"", line 361, in freeze_graph
    checkpoint_version=checkpoint_version)
  File ""\Users\\v-xiat\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\tools\\freeze_graph.py"", line 190, in freeze_graph_with_def_protos     
    var_list=var_list, write_version=checkpoint_version)
  File ""Users\v-xiat\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow_core\python\training\saver.py"", line 828, in __init__
    self.build()
  File ""Users\v-xiat\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow_core\python\training\saver.py"", line 840, in build
    self._build(self._filename, build_save=True, build_restore=True)
  File ""Users\v-xiat\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow_core\python\training\saver.py"", line 878, in _build
    build_restore=build_restore)
  File ""Users\v-xiat\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow_core\python\training\saver.py"", line 508, in _build_internal
    restore_sequentially, reshape)
  File ""Users\v-xiat\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow_core\python\training\saver.py"", line 350, in _AddRestoreOps
    assign_ops.append(saveable.restore(saveable_tensors, shapes))
  File ""Users\v-xiat\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow_core\python\training\saving\saveable_object_util.py"", line 73, in restore
    self.op.get_shape().is_fully_defined())
  File ""Users\v-xiat\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow_core\python\ops\state_ops.py"", line 227, in assign
    validate_shape=validate_shape)
  File ""Users\v-xiat\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow_core\python\ops\gen_state_ops.py"", line 65, in assign
    use_locking=use_locking, name=name)
  File ""Users\v-xiat\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow_core\python\framework\op_def_library.py"", line 794, in _apply_op_helper
    op_def=op_def)
  File ""Users\v-xiat\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow_core\python\util\deprecation.py"", line 507, in new_func
    return func(*args, **kwargs)
  File ""Users\v-xiat\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow_core\python\framework\ops.py"", line 3357, in create_op
    attrs, op_def, compute_device)
  File ""Users\v-xiat\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow_core\python\framework\ops.py"", line 3426, in _create_op_internal
    op_def=op_def)
  File ""Users\v-xiat\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow_core\python\framework\ops.py"", line 1748, in __init__
    self._traceback = tf_stack.extract_stack()


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\\Users\\v-xiat\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\tools\\freeze_graph.py"", line 491, in <module>
    run_main()
  File ""C:\\Users\\v-xiat\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\tools\\freeze_graph.py"", line 487, in run_main
    app.run(main=my_main, argv=[sys.argv[0]] + unparsed)
  File ""C:\Users\v-xiat\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow_core\python\platform\app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""C:\Users\v-xiat\AppData\Local\Continuum\anaconda3\lib\site-packages\absl\app.py"", line 299, in run
    _run_main(main, args)
  File ""C:\Users\v-xiat\AppData\Local\Continuum\anaconda3\lib\site-packages\absl\app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""C:\\Users\\v-xiat\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\tools\\freeze_graph.py"", line 486, in <lambda>
    my_main = lambda unused_args: main(unused_args, flags)
  File ""C:\\Users\\v-xiat\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\tools\\freeze_graph.py"", line 378, in main
    flags.saved_model_tags, checkpoint_version)
  File ""C:\\Users\\v-xiat\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\tools\\freeze_graph.py"", line 361, in freeze_graph
    checkpoint_version=checkpoint_version)
  File ""C:\\Users\\v-xiat\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\tools\\freeze_graph.py"", line 209, in freeze_graph_with_def_protos  
    saver.restore(sess, input_checkpoint)
  File ""C:\Users\v-xiat\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow_core\python\training\saver.py"", line 1326, in restore
    err, ""a mismatch between the current graph and the graph"")
tensorflow.python.framework.errors_impl.InvalidArgumentError: Restoring from checkpoint failed. This is most likely due to a mismatch between the current graph and the graph from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:

Assign requires shapes of both tensors to match. lhs shape= [1001] rhs shape= [1000]
         [[node save/Assign_265 (defined at Users\v-xiat\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow_core\python\framework\ops.py:1748) ]]

Original stack trace for 'save/Assign_265':
  File ""\Users\\v-xiat\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\tools\\freeze_graph.py"", line 491, in <module>
    run_main()
  File ""\Users\\v-xiat\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\tools\\freeze_graph.py"", line 487, in run_main
    app.run(main=my_main, argv=[sys.argv[0]] + unparsed)
  File ""Users\v-xiat\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow_core\python\platform\app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""Users\v-xiat\AppData\Local\Continuum\anaconda3\lib\site-packages\absl\app.py"", line 299, in run
    _run_main(main, args)
  File ""Users\v-xiat\AppData\Local\Continuum\anaconda3\lib\site-packages\absl\app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""\Users\\v-xiat\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\tools\\freeze_graph.py"", line 486, in <lambda>
    my_main = lambda unused_args: main(unused_args, flags)
  File ""\Users\\v-xiat\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\tools\\freeze_graph.py"", line 378, in main
    flags.saved_model_tags, checkpoint_version)
  File ""\Users\\v-xiat\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\tools\\freeze_graph.py"", line 361, in freeze_graph
    checkpoint_version=checkpoint_version)
  File ""\Users\\v-xiat\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\tools\\freeze_graph.py"", line 190, in freeze_graph_with_def_protos     
    var_list=var_list, write_version=checkpoint_version)
  File ""Users\v-xiat\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow_core\python\training\saver.py"", line 828, in __init__
    self.build()
  File ""Users\v-xiat\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow_core\python\training\saver.py"", line 840, in build
    self._build(self._filename, build_save=True, build_restore=True)
  File ""Users\v-xiat\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow_core\python\training\saver.py"", line 878, in _build
    build_restore=build_restore)
  File ""Users\v-xiat\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow_core\python\training\saver.py"", line 508, in _build_internal
    restore_sequentially, reshape)
  File ""Users\v-xiat\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow_core\python\training\saver.py"", line 350, in _AddRestoreOps
    assign_ops.append(saveable.restore(saveable_tensors, shapes))
  File ""Users\v-xiat\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow_core\python\training\saving\saveable_object_util.py"", line 73, in restore
    self.op.get_shape().is_fully_defined())
  File ""Users\v-xiat\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow_core\python\ops\state_ops.py"", line 227, in assign
    validate_shape=validate_shape)
  File ""Users\v-xiat\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow_core\python\ops\gen_state_ops.py"", line 65, in assign
    use_locking=use_locking, name=name)
  File ""Users\v-xiat\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow_core\python\framework\op_def_library.py"", line 794, in _apply_op_helper
    op_def=op_def)
  File ""Users\v-xiat\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow_core\python\util\deprecation.py"", line 507, in new_func
    return func(*args, **kwargs)
  File ""Users\v-xiat\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow_core\python\framework\ops.py"", line 3357, in create_op
    attrs, op_def, compute_device)
  File ""Users\v-xiat\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow_core\python\framework\ops.py"", line 3426, in _create_op_internal
    op_def=op_def)
  File ""Users\v-xiat\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow_core\python\framework\ops.py"", line 1748, in __init__
    self._traceback = tf_stack.extract_stack()
```
",tigert1998,b'models:research type:bug',2019-12-21T09:44:17Z,2020-06-04T16:59:14Z,,,,,,,
7956,_tf module not found,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",shubzzz98,b'stat:awaiting response type:support',2019-12-18T17:21:04Z,2020-07-13T13:19:19Z,,,,,,,
7955,Get class name labels on ssd_mobilenetv2_oidv4,"How are the classes name sorted in the oidv4 model?

I've downloaded the class names csv file and converted it into a plain txt containing only the names.

Whe I make a test on [this](https://ibb.co/d2y9ycB) image it gives me this predictions, with the labels shown on the image.

Is it problem with sorting the names or with the predictions itself?

Here is my txt file with the 600 classes:

Tortoise
Container
Magpie
Sea turtle
Football
Ambulance
Ladder
Toothbrush
Syringe
Sink
Toy
Organ (Musical Instrument)
Cassette deck
Apple
Human eye
Cosmetics
Paddle
Snowman
Beer
Chopsticks
Human beard
Bird
Parking meter
Traffic light
Croissant
Cucumber
Radish
Towel
Doll
Skull
Washing machine
Glove
Tick
Belt
Sunglasses
Banjo
Cart
Ball
Backpack
Bicycle
Home appliance
Centipede
Boat
Surfboard
Boot
Headphones
Hot dog
Shorts
Fast food
Bus
Boy
Screwdriver
Bicycle wheel
Barge
Laptop
Miniskirt
Drill (Tool)
Dress
Bear
Waffle
Pancake
Brown bear
Woodpecker
Blue jay
Pretzel
Bagel
Tower
Teapot
Person
Bow and arrow
Swimwear
Beehive
Brassiere
Bee
Bat (Animal)
Starfish
Popcorn
Burrito
Chainsaw
Balloon
Wrench
Tent
Vehicle registration plate
Lantern
Toaster
Flashlight
Billboard
Tiara
Limousine
Necklace
Carnivore
Scissors
Stairs
Computer keyboard
Printer
Traffic sign
Chair
Shirt
Poster
Cheese
Sock
Fire hydrant
Land vehicle
Earrings
Tie
Watercraft
Cabinetry
Suitcase
Muffin
Bidet
Snack
Snowmobile
Clock
Medical equipment
Cattle
Cello
Jet ski
Camel
Coat
Suit
Desk
Cat
Bronze sculpture
Juice
Gondola
Beetle
Cannon
Computer mouse
Cookie
Office building
Fountain
Coin
Calculator
Cocktail
Computer monitor
Box
Stapler
Christmas tree
Cowboy hat
Hiking equipment
Studio couch
Drum
Dessert
Wine rack
Drink
Zucchini
Ladle
Human mouth
Dairy Product
Dice
Oven
Dinosaur
Ratchet (Device)
Couch
Cricket ball
Winter melon
Spatula
Whiteboard
Pencil sharpener
Door
Hat
Shower
Eraser
Fedora
Guacamole
Dagger
Scarf
Dolphin
Sombrero
Tin can
Mug
Tap
Harbor seal
Stretcher
Can opener
Goggles
Human body
Roller skates
Coffee cup
Cutting board
Blender
Plumbing fixture
Stop sign
Office supplies
Volleyball (Ball)
Vase
Slow cooker
Wardrobe
Coffee
Whisk
Paper towel
Personal care
Food
Sun hat
Tree house
Flying disc
Skirt
Gas stove
Salt and pepper shakers
Mechanical fan
Face powder
Fax
Fruit
French fries
Nightstand
Barrel
Kite
Tart
Treadmill
Fox
Flag
French horn
Window blind
Human foot
Golf cart
Jacket
Egg (Food)
Street light
Guitar
Pillow
Human leg
Isopod
Grape
Human ear
Power plugs and sockets
Panda
Giraffe
Woman
Door handle
Rhinoceros
Bathtub
Goldfish
Houseplant
Goat
Baseball bat
Baseball glove
Mixing bowl
Marine invertebrates
Kitchen utensil
Light switch
House
Horse
Stationary bicycle
Hammer
Ceiling fan
Sofa bed
Adhesive tape
Harp
Sandal
Bicycle helmet
Saucer
Harpsichord
Human hair
Heater
Harmonica
Hamster
Curtain
Bed
Kettle
Fireplace
Scale
Drinking straw
Insect
Hair dryer
Kitchenware
Indoor rower
Invertebrate
Food processor
Bookcase
Refrigerator
Wood-burning stove
Punching bag
Common fig
Cocktail shaker
Jaguar (Animal)
Golf ball
Fashion accessory
Alarm clock
Filing cabinet
Artichoke
Table
Tableware
Kangaroo
Koala
Knife
Bottle
Bottle opener
Lynx
Lavender (Plant)
Lighthouse
Dumbbell
Human head
Bowl
Humidifier
Porch
Lizard
Billiard table
Mammal
Mouse
Motorcycle
Musical instrument
Swim cap
Frying pan
Snowplow
Bathroom cabinet
Missile
Bust
Man
Waffle iron
Milk
Ring binder
Plate
Mobile phone
Baked goods
Mushroom
Crutch
Pitcher (Container)
Mirror
Personal flotation device
Table tennis racket
Pencil case
Musical keyboard
Scoreboard
Briefcase
Kitchen knife
Nail (Construction)
Tennis ball
Plastic bag
Oboe
Chest of drawers
Ostrich
Piano
Girl
Plant
Potato
Hair spray
Sports equipment
Pasta
Penguin
Pumpkin
Pear
Infant bed
Polar bear
Mixer
Cupboard
Jacuzzi
Pizza
Digital clock
Pig
Reptile
Rifle
Lipstick
Skateboard
Raven
High heels
Red panda
Rose
Rabbit
Sculpture
Saxophone
Shotgun
Seafood
Submarine sandwich
Snowboard
Sword
Picture frame
Sushi
Loveseat
Ski
Squirrel
Tripod
Stethoscope
Submarine
Scorpion
Segway
Training bench
Snake
Coffee table
Skyscraper
Sheep
Television
Trombone
Tea
Tank
Taco
Telephone
Torch
Tiger
Strawberry
Trumpet
Tree
Tomato
Train
Tool
Picnic basket
Cooking spray
Trousers
Bowling equipment
Football helmet
Truck
Measuring cup
Coffeemaker
Violin
Vehicle
Handbag
Paper cutter
Wine
Weapon
Wheel
Worm
Wok
Whale
Zebra
Auto part
Jug
Pizza cutter
Cream
Monkey
Lion
Bread
Platter
Chicken
Eagle
Helicopter
Owl
Duck
Turtle
Hippopotamus
Crocodile
Toilet
Toilet paper
Squid
Clothing
Footwear
Lemon
Spider
Deer
Frog
Banana
Rocket
Wine glass
Countertop
Tablet computer
Waste container
Swimming pool
Dog
Book
Elephant
Shark
Candle
Leopard
Axe
Hand dryer
Soap dispenser
Porcupine
Flower
Canary
Cheetah
Palm tree
Hamburger
Maple
Building
Fish
Lobster
Garden Asparagus
Furniture
Hedgehog
Airplane
Spoon
Otter
Bull
Oyster
Horizontal bar
Convenience store
Bomb
Bench
Ice cream
Caterpillar
Butterfly
Parachute
Orange
Antelope
Beaker
Moths and butterflies
Window
Closet
Castle
Jellyfish
Goose
Mule
Swan
Peach
Coconut
Seat belt
Raccoon
Chisel
Fork
Lamp
Camera
Squash (Plant)
Racket
Human face
Human arm
Vegetable
Diaper
Unicycle
Falcon
Chime
Snail
Shellfish
Cabbage
Carrot
Mango
Jeans
Flowerpot
Pineapple
Drawer
Stool
Envelope
Cake
Dragonfly
Common sunflower
Microwave oven
Honeycomb
Marine mammal
Sea lion
Ladybug
Shelf
Watch
Candy
Salad
Parrot
Handgun
Sparrow
Van
Grinder
Spice rack
Light bulb
Corded phone
Sports uniform
Tennis racket
Wall clock
Serving tray
Kitchen & dining room table
Dog bed
Cake stand
Cat furniture
Bathroom accessory
Facial tissue holder
Pressure cooker
Kitchen appliance
Tire
Ruler
Luggage and bags
Microphone
Broccoli
Umbrella
Pastry
Grapefruit
Band-aid
Animal
Bell pepper
Turkey
Lily
Pomegranate
Doughnut
Glasses
Human nose
Pen
Ant
Car
Aircraft
Human hand
Skunk
Teddy bear
Watermelon
Cantaloupe
Dishwasher
Flute
Balance beam
Sandwich
Shrimp
Sewing machine
Binoculars
Rays and skates
Ipod
Accordion
Willow
Crab
Crown
Seahorse
Perfume
Alpaca
Taxi
Canoe
Remote control
Wheelchair
Rugby ball
Armadillo
Maracas
Helmet


",yieniggu,b'models:research stalled stat:awaiting response type:support',2019-12-18T15:15:06Z,2020-09-18T18:17:49Z,,,,,,,
7931,For what this file used for can anyone tell me visualization_utils_test.py?,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:16.04
- **TensorFlow installed from (source or binary)**:sudo
- **TensorFlow version (use command below)**:1.13.0
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:1.10.0
- **GPU model and memory**:1080 TI
- **Exact command to reproduce**:python3 visualization_utils_test.py

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",Naveennavik,b'stat:awaiting response type:support',2019-12-09T12:19:01Z,2020-07-14T09:27:55Z,,,,,,,
7926," File ""<ipython-input-1-a41006cfe50f>"", line 4, in <module>     with detection_graph.as_default():  NameError: name 'detection_graph' is not defined","Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",SamiUllahTaunsvi786,b'type:support',2019-12-08T23:08:22Z,2020-06-17T10:22:25Z,,,,,,,
7925, Key conv1/biases/ExponentialMovingAverage not found in checkpoint[[node save/RestoreV2 (defined at cifar10_eval.py:136)]],"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**: models
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 18.04
- **TensorFlow installed from (source or binary)**: pip install
- **TensorFlow version (use command below)**: v1.14.0-rc1-22-gaf24dc91b5 1.14.0
- **Bazel version (if compiling from source)**: No
- **CUDA/cuDNN version**: NaN
- **GPU model and memory**: only CPU 
- **Exact command to reproduce**: `python cifar10_eval.py` 

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

### Describe the problem
I'm trying to run `cifar10_eval.py` from `models/tutorials/image/cifar10`, i get the error below.  

### Source code / logs
```
/home/ubuntu/geo-distNet/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([(""qint8"", np.int8, 1)])
/home/ubuntu/geo-distNet/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([(""quint8"", np.uint8, 1)])
/home/ubuntu/geo-distNet/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([(""qint16"", np.int16, 1)])
/home/ubuntu/geo-distNet/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([(""quint16"", np.uint16, 1)])
/home/ubuntu/geo-distNet/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([(""qint32"", np.int32, 1)])
/home/ubuntu/geo-distNet/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([(""resource"", np.ubyte, 1)])
/home/ubuntu/geo-distNet/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([(""qint8"", np.int8, 1)])
/home/ubuntu/geo-distNet/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([(""quint8"", np.uint8, 1)])
/home/ubuntu/geo-distNet/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([(""qint16"", np.int16, 1)])
/home/ubuntu/geo-distNet/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([(""quint16"", np.uint16, 1)])
/home/ubuntu/geo-distNet/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([(""qint32"", np.int32, 1)])
/home/ubuntu/geo-distNet/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([(""resource"", np.ubyte, 1)])
WARNING:tensorflow:From cifar10_eval.py:161: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.

WARNING:tensorflow:From cifar10_eval.py:154: The name tf.gfile.Exists is deprecated. Please use tf.io.gfile.exists instead.

W1208 21:46:42.478865 140593835398976 deprecation_wrapper.py:119] From cifar10_eval.py:154: The name tf.gfile.Exists is deprecated. Please use tf.io.gfile.exists instead.

WARNING:tensorflow:From cifar10_eval.py:155: The name tf.gfile.DeleteRecursively is deprecated. Please use tf.io.gfile.rmtree instead.

W1208 21:46:42.479185 140593835398976 deprecation_wrapper.py:119] From cifar10_eval.py:155: The name tf.gfile.DeleteRecursively is deprecated. Please use tf.io.gfile.rmtree instead.

WARNING:tensorflow:From cifar10_eval.py:156: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.

W1208 21:46:42.479549 140593835398976 deprecation_wrapper.py:119] From cifar10_eval.py:156: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.

WARNING:tensorflow:From /home/ubuntu/aws_share/DistNet-master/cifar10_input.py:545: string_input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.
Instructions for updating:
Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(string_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.
W1208 21:46:42.493719 140593835398976 deprecation.py:323] From /home/ubuntu/aws_share/DistNet-master/cifar10_input.py:545: string_input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.
Instructions for updating:
Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(string_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.
WARNING:tensorflow:From /home/ubuntu/geo-distNet/lib/python3.6/site-packages/tensorflow/python/training/input.py:278: input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.
Instructions for updating:
Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(input_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.
W1208 21:46:42.502568 140593835398976 deprecation.py:323] From /home/ubuntu/geo-distNet/lib/python3.6/site-packages/tensorflow/python/training/input.py:278: input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.
Instructions for updating:
Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(input_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.
WARNING:tensorflow:From /home/ubuntu/geo-distNet/lib/python3.6/site-packages/tensorflow/python/training/input.py:190: limit_epochs (from tensorflow.python.training.input) is deprecated and will be removed in a future version.
Instructions for updating:
Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensors(tensor).repeat(num_epochs)`.
W1208 21:46:42.503705 140593835398976 deprecation.py:323] From /home/ubuntu/geo-distNet/lib/python3.6/site-packages/tensorflow/python/training/input.py:190: limit_epochs (from tensorflow.python.training.input) is deprecated and will be removed in a future version.
Instructions for updating:
Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensors(tensor).repeat(num_epochs)`.
WARNING:tensorflow:From /home/ubuntu/geo-distNet/lib/python3.6/site-packages/tensorflow/python/training/input.py:199: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.
Instructions for updating:
To construct input pipelines, use the `tf.data` module.
W1208 21:46:42.505728 140593835398976 deprecation.py:323] From /home/ubuntu/geo-distNet/lib/python3.6/site-packages/tensorflow/python/training/input.py:199: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.
Instructions for updating:
To construct input pipelines, use the `tf.data` module.
WARNING:tensorflow:From /home/ubuntu/geo-distNet/lib/python3.6/site-packages/tensorflow/python/training/input.py:199: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.
Instructions for updating:
To construct input pipelines, use the `tf.data` module.
W1208 21:46:42.507081 140593835398976 deprecation.py:323] From /home/ubuntu/geo-distNet/lib/python3.6/site-packages/tensorflow/python/training/input.py:199: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.
Instructions for updating:
To construct input pipelines, use the `tf.data` module.
WARNING:tensorflow:From /home/ubuntu/aws_share/DistNet-master/cifar10_input.py:79: FixedLengthRecordReader.__init__ (from tensorflow.python.ops.io_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.FixedLengthRecordDataset`.
W1208 21:46:42.511251 140593835398976 deprecation.py:323] From /home/ubuntu/aws_share/DistNet-master/cifar10_input.py:79: FixedLengthRecordReader.__init__ (from tensorflow.python.ops.io_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.FixedLengthRecordDataset`.
WARNING:tensorflow:From /home/ubuntu/aws_share/DistNet-master/cifar10_input.py:556: The name tf.image.resize_image_with_crop_or_pad is deprecated. Please use tf.image.resize_with_crop_or_pad instead.

W1208 21:46:42.526786 140593835398976 deprecation_wrapper.py:119] From /home/ubuntu/aws_share/DistNet-master/cifar10_input.py:556: The name tf.image.resize_image_with_crop_or_pad is deprecated. Please use tf.image.resize_with_crop_or_pad instead.

WARNING:tensorflow:From /home/ubuntu/geo-distNet/lib/python3.6/site-packages/tensorflow/python/ops/image_ops_impl.py:1514: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Deprecated in favor of operator or tf.math.divide.
W1208 21:46:42.553675 140593835398976 deprecation.py:323] From /home/ubuntu/geo-distNet/lib/python3.6/site-packages/tensorflow/python/ops/image_ops_impl.py:1514: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Deprecated in favor of operator or tf.math.divide.
WARNING:tensorflow:From /home/ubuntu/aws_share/DistNet-master/cifar10_input.py:132: batch (from tensorflow.python.training.input) is deprecated and will be removed in a future version.
Instructions for updating:
Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.batch(batch_size)` (or `padded_batch(...)` if `dynamic_pad=True`).
W1208 21:46:42.554902 140593835398976 deprecation.py:323] From /home/ubuntu/aws_share/DistNet-master/cifar10_input.py:132: batch (from tensorflow.python.training.input) is deprecated and will be removed in a future version.
Instructions for updating:
Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.batch(batch_size)` (or `padded_batch(...)` if `dynamic_pad=True`).
WARNING:tensorflow:From /home/ubuntu/aws_share/DistNet-master/cifar10_input.py:135: The name tf.summary.image is deprecated. Please use tf.compat.v1.summary.image instead.

W1208 21:46:42.563536 140593835398976 deprecation_wrapper.py:119] From /home/ubuntu/aws_share/DistNet-master/cifar10_input.py:135: The name tf.summary.image is deprecated. Please use tf.compat.v1.summary.image instead.

WARNING:tensorflow:From /home/ubuntu/aws_share/DistNet-master/cifar10.py:421: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

W1208 21:46:42.566410 140593835398976 deprecation_wrapper.py:119] From /home/ubuntu/aws_share/DistNet-master/cifar10.py:421: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

WARNING:tensorflow:From /home/ubuntu/aws_share/DistNet-master/cifar10.py:135: calling TruncatedNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W1208 21:46:42.567062 140593835398976 deprecation.py:506] From /home/ubuntu/aws_share/DistNet-master/cifar10.py:135: calling TruncatedNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
WARNING:tensorflow:From /home/ubuntu/aws_share/DistNet-master/cifar10.py:111: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

W1208 21:46:42.567486 140593835398976 deprecation_wrapper.py:119] From /home/ubuntu/aws_share/DistNet-master/cifar10.py:111: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

WARNING:tensorflow:From /home/ubuntu/aws_share/DistNet-master/cifar10.py:138: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.

W1208 21:46:42.576922 140593835398976 deprecation_wrapper.py:119] From /home/ubuntu/aws_share/DistNet-master/cifar10.py:138: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.

WARNING:tensorflow:From /home/ubuntu/aws_share/DistNet-master/cifar10.py:433: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.

W1208 21:46:42.584422 140593835398976 deprecation_wrapper.py:119] From /home/ubuntu/aws_share/DistNet-master/cifar10.py:433: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.

WARNING:tensorflow:From cifar10_eval.py:138: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

W1208 21:46:42.695417 140593835398976 deprecation_wrapper.py:119] From cifar10_eval.py:138: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

WARNING:tensorflow:From cifar10_eval.py:141: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.

W1208 21:46:42.714674 140593835398976 deprecation_wrapper.py:119] From cifar10_eval.py:141: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.

WARNING:tensorflow:From cifar10_eval.py:143: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.

W1208 21:46:42.715788 140593835398976 deprecation_wrapper.py:119] From cifar10_eval.py:143: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.

WARNING:tensorflow:From cifar10_eval.py:71: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

W1208 21:46:42.741833 140593835398976 deprecation_wrapper.py:119] From cifar10_eval.py:71: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-12-08 21:46:42.742588: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-12-08 21:46:42.746921: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2400100000 Hz
2019-12-08 21:46:42.747076: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x36cba40 executing computations on platform Host. Devices:
2019-12-08 21:46:42.747101: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
WARNING:tensorflow:From /home/ubuntu/geo-distNet/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to check for files with this prefix.
W1208 21:46:42.748043 140593835398976 deprecation.py:323] From /home/ubuntu/geo-distNet/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to check for files with this prefix.
INFO:tensorflow:Restoring parameters from /home/ubuntu/tmp/cifar10_train/model.ckpt-0
I1208 21:46:42.749160 140593835398976 saver.py:1280] Restoring parameters from /home/ubuntu/tmp/cifar10_train/model.ckpt-0
2019-12-08 21:46:42.768650: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-12-08 21:46:42.771015: W tensorflow/core/framework/op_kernel.cc:1502] OP_REQUIRES failed at save_restore_v2_ops.cc:184 : Not found: Key conv1/biases/ExponentialMovingAverage not found in checkpoint
Traceback (most recent call last):
  File ""/home/ubuntu/geo-distNet/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1356, in _do_call
    return fn(*args)
  File ""/home/ubuntu/geo-distNet/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1341, in _run_fn
    options, feed_dict, fetch_list, target_list, run_metadata)
  File ""/home/ubuntu/geo-distNet/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1429, in _call_tf_sessionrun
    run_metadata)
tensorflow.python.framework.errors_impl.NotFoundError: Key conv1/biases/ExponentialMovingAverage not found in checkpoint
	 [[{{node save/RestoreV2}}]]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/home/ubuntu/geo-distNet/lib/python3.6/site-packages/tensorflow/python/training/saver.py"", line 1286, in restore
    {self.saver_def.filename_tensor_name: save_path})
  File ""/home/ubuntu/geo-distNet/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 950, in run
    run_metadata_ptr)
  File ""/home/ubuntu/geo-distNet/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1173, in _run
    feed_dict_tensor, options, run_metadata)
  File ""/home/ubuntu/geo-distNet/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1350, in _do_run
    run_metadata)
  File ""/home/ubuntu/geo-distNet/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1370, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.NotFoundError: Key conv1/biases/ExponentialMovingAverage not found in checkpoint
	 [[node save/RestoreV2 (defined at cifar10_eval.py:138) ]]

Original stack trace for 'save/RestoreV2':
  File ""cifar10_eval.py"", line 161, in <module>
    tf.app.run()
  File ""/home/ubuntu/geo-distNet/lib/python3.6/site-packages/tensorflow/python/platform/app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""/home/ubuntu/geo-distNet/lib/python3.6/site-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/home/ubuntu/geo-distNet/lib/python3.6/site-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""cifar10_eval.py"", line 157, in main
    evaluate()
  File ""cifar10_eval.py"", line 138, in evaluate
    saver = tf.train.Saver(variables_to_restore)
  File ""/home/ubuntu/geo-distNet/lib/python3.6/site-packages/tensorflow/python/training/saver.py"", line 825, in __init__
    self.build()
  File ""/home/ubuntu/geo-distNet/lib/python3.6/site-packages/tensorflow/python/training/saver.py"", line 837, in build
    self._build(self._filename, build_save=True, build_restore=True)
  File ""/home/ubuntu/geo-distNet/lib/python3.6/site-packages/tensorflow/python/training/saver.py"", line 875, in _build
    build_restore=build_restore)
  File ""/home/ubuntu/geo-distNet/lib/python3.6/site-packages/tensorflow/python/training/saver.py"", line 508, in _build_internal
    restore_sequentially, reshape)
  File ""/home/ubuntu/geo-distNet/lib/python3.6/site-packages/tensorflow/python/training/saver.py"", line 328, in _AddRestoreOps
    restore_sequentially)
  File ""/home/ubuntu/geo-distNet/lib/python3.6/site-packages/tensorflow/python/training/saver.py"", line 575, in bulk_restore
    return io_ops.restore_v2(filename_tensor, names, slices, dtypes)
  File ""/home/ubuntu/geo-distNet/lib/python3.6/site-packages/tensorflow/python/ops/gen_io_ops.py"", line 1696, in restore_v2
    name=name)
  File ""/home/ubuntu/geo-distNet/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py"", line 788, in _apply_op_helper
    op_def=op_def)
  File ""/home/ubuntu/geo-distNet/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py"", line 507, in new_func
    return func(*args, **kwargs)
  File ""/home/ubuntu/geo-distNet/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 3616, in create_op
    op_def=op_def)
  File ""/home/ubuntu/geo-distNet/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 2005, in __init__
    self._traceback = tf_stack.extract_stack()


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/home/ubuntu/geo-distNet/lib/python3.6/site-packages/tensorflow/python/training/saver.py"", line 1296, in restore
    names_to_keys = object_graph_key_mapping(save_path)
  File ""/home/ubuntu/geo-distNet/lib/python3.6/site-packages/tensorflow/python/training/saver.py"", line 1614, in object_graph_key_mapping
    object_graph_string = reader.get_tensor(trackable.OBJECT_GRAPH_PROTO_KEY)
  File ""/home/ubuntu/geo-distNet/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 678, in get_tensor
    return CheckpointReader_GetTensor(self, compat.as_bytes(tensor_str))
tensorflow.python.framework.errors_impl.NotFoundError: Key _CHECKPOINTABLE_OBJECT_GRAPH not found in checkpoint

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""cifar10_eval.py"", line 161, in <module>
    tf.app.run()
  File ""/home/ubuntu/geo-distNet/lib/python3.6/site-packages/tensorflow/python/platform/app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""/home/ubuntu/geo-distNet/lib/python3.6/site-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/home/ubuntu/geo-distNet/lib/python3.6/site-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""cifar10_eval.py"", line 157, in main
    evaluate()
  File ""cifar10_eval.py"", line 146, in evaluate
    eval_once(saver, summary_writer, top_k_op, summary_op)
  File ""cifar10_eval.py"", line 77, in eval_once
    saver.restore(sess, ckpt.model_checkpoint_path)
  File ""/home/ubuntu/geo-distNet/lib/python3.6/site-packages/tensorflow/python/training/saver.py"", line 1302, in restore
    err, ""a Variable name or other graph key that is missing"")
tensorflow.python.framework.errors_impl.NotFoundError: Restoring from checkpoint failed. This is most likely due to a Variable name or other graph key that is missing from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:

Key conv1/biases/ExponentialMovingAverage not found in checkpoint
	 [[node save/RestoreV2 (defined at cifar10_eval.py:138) ]]

Original stack trace for 'save/RestoreV2':
  File ""cifar10_eval.py"", line 161, in <module>
    tf.app.run()
  File ""/home/ubuntu/geo-distNet/lib/python3.6/site-packages/tensorflow/python/platform/app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""/home/ubuntu/geo-distNet/lib/python3.6/site-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/home/ubuntu/geo-distNet/lib/python3.6/site-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""cifar10_eval.py"", line 157, in main
    evaluate()
  File ""cifar10_eval.py"", line 138, in evaluate
    saver = tf.train.Saver(variables_to_restore)
  File ""/home/ubuntu/geo-distNet/lib/python3.6/site-packages/tensorflow/python/training/saver.py"", line 825, in __init__
    self.build()
  File ""/home/ubuntu/geo-distNet/lib/python3.6/site-packages/tensorflow/python/training/saver.py"", line 837, in build
    self._build(self._filename, build_save=True, build_restore=True)
  File ""/home/ubuntu/geo-distNet/lib/python3.6/site-packages/tensorflow/python/training/saver.py"", line 875, in _build
    build_restore=build_restore)
  File ""/home/ubuntu/geo-distNet/lib/python3.6/site-packages/tensorflow/python/training/saver.py"", line 508, in _build_internal
    restore_sequentially, reshape)
  File ""/home/ubuntu/geo-distNet/lib/python3.6/site-packages/tensorflow/python/training/saver.py"", line 328, in _AddRestoreOps
    restore_sequentially)
  File ""/home/ubuntu/geo-distNet/lib/python3.6/site-packages/tensorflow/python/training/saver.py"", line 575, in bulk_restore
    return io_ops.restore_v2(filename_tensor, names, slices, dtypes)
  File ""/home/ubuntu/geo-distNet/lib/python3.6/site-packages/tensorflow/python/ops/gen_io_ops.py"", line 1696, in restore_v2
    name=name)
  File ""/home/ubuntu/geo-distNet/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py"", line 788, in _apply_op_helper
    op_def=op_def)
  File ""/home/ubuntu/geo-distNet/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py"", line 507, in new_func
    return func(*args, **kwargs)
  File ""/home/ubuntu/geo-distNet/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 3616, in create_op
    op_def=op_def)
  File ""/home/ubuntu/geo-distNet/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 2005, in __init__
    self._traceback = tf_stack.extract_stack()
```
",snat1505027,b'stat:awaiting response type:support',2019-12-08T22:06:38Z,2020-07-14T09:29:18Z,,,,,,,
7920,TF Object Detection API incompatible with TF 2.1.X,"### System information
- **What is the top-level directory of the model you are using**: object_detection
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: no
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: MacOS 10.15.1
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: tf-nightly==2.1.0.dev20191203
- **Bazel version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**:

`from object_detection import model_lib_v2`

### Describe the problem
Model training fails in versions of TensorFlow greater than 2.0 due to the removal of the contrib library. The evaluation utils still depend on this module which has officially been deprecated in 2.1.X.

### Source code / logs
```
from object_detection import model_lib_v2
```
```
---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
<ipython-input-2-fe4a9e95a33f> in <module>
----> 1 from object_detection import model_lib_v2

~/.pyenv/versions/3.7.5/envs/fritzml-tf2/lib/python3.7/site-packages/object_detection/model_lib_v2.py in <module>
     24 import tensorflow as tf
     25 
---> 26 from object_detection import eval_util
     27 from object_detection import inputs
     28 from object_detection import model_lib

~/.pyenv/versions/3.7.5/envs/fritzml-tf2/lib/python3.7/site-packages/object_detection/eval_util.py in <module>
     38 from object_detection.utils import visualization_utils as vis_utils
     39 
---> 40 slim = tf.contrib.slim
     41 
     42 # A dictionary of metric names to classes that implement the metric. The classes

AttributeError: module 'tensorflow' has no attribute 'contrib'
```",jamesonthecrow,b'models:research type:bug',2019-12-06T16:22:09Z,2020-07-10T18:15:19Z,,,,,,,
7917,RuntimeError when trying to use the functional API.,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 18.04
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 2.0.0
- **Exact command to reproduce**:

### Describe the problem
I implemented transformer xl using tf.keras.layers with the subclassing api and it works. I also checked the trainable variables and their names are the same as in original implementation. If i want to use my model with the Functional api, i get a RuntimeError. 

### Source code / logs
My code for the Functional api follows the same structure as the code in bert [here](https://github.com/tensorflow/models/blob/master/official/nlp/modeling/networks/transformer_encoder.py). In my transformer xl code i have custom layers and a final big keras layer which connects all the other layers in the call function.

My code for the functional api is shown below:
```
class TransformerXLModel(network.Network):
    def __init__(self, n_token, init_method, init_std, init_range, n_layer, d_model, n_head, d_head, d_inner,
                 ff_activation, untie_r, dropout, dropout_att, mem_len, reuse_len, bi_data, clamp_len,
                 same_length, tf_float, residual, **kwargs):
        initializer = _get_initializer(init_method, init_std, init_range)
        attn_type = 'bi'
        self._self_setattr_tracking = False
        self._config_dict = {
            'n_token': n_token,
            'init_method': init_method,
            'init_std': init_std,
            'init_range': init_range,
            'n_layer': n_layer,
            'd_model': d_model,
            'n_head': n_head,
            'd_head': d_head,
            'd_inner': d_inner,
            'ff_activation': ff_activation,
            'untie_r': untie_r,
            'dropout': dropout,
            'dropout_att': dropout_att,
            'mem_len': mem_len,
            'reuse_len': reuse_len,
            'bi_data': bi_data,
            'clamp_len': clamp_len,
            'same_length': same_length,
            'tf_float': tf_float,
            'residual': residual
        }

        input_word_ids = tf.keras.layers.Input(
            shape=(FLAGS.seq_length,), dtype=tf.int32, name='input_ids')
        segment_ids = tf.keras.layers.Input(
            shape=(FLAGS.seq_length,), dtype=tf.int32, name='segment_ids')
        input_mask = tf.keras.layers.Input(
            shape=(FLAGS.seq_length,), dtype=tf.float32, name='input_mask')
        mems = None
        perm_mask = None
        inps = pack_inputs([input_word_ids, segment_ids, input_mask, mems, perm_mask])

        self.transformerxl_model = TransformerXlLayer(n_layer, d_model, n_head, d_head, d_inner, ff_activation, untie_r,
                                                      n_token, dropout, dropout_att, attn_type, mem_len, reuse_len,
                                                      bi_data, clamp_len, same_length, initializer, tf_float,
                                                      residual, name='transformer')
        output, new_mems, lookup_table = self.transformerxl_model(inps)

        super(TransformerXLModel, self).__init__(
            inputs=[input_word_ids, segment_ids, input_mask, mems, perm_mask],
            outputs=[output],
            **kwargs)

    def get_config(self):
        return self._config_dict

    @classmethod
    def from_config(cls, config, custom_objects=None):
        return cls(**config)
```


```
Traceback (most recent call last):
  File ""checkpoint_converter/checkpoint_conv_tool.py"", line 179, in <module>
    app.run(main=main)
  File ""/home/chris/miniconda3/envs/tensorflow_cpu/lib/python3.7/site-packages/tensorflow_core/python/platform/app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""/home/chris/miniconda3/envs/tensorflow_cpu/lib/python3.7/site-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/home/chris/miniconda3/envs/tensorflow_cpu/lib/python3.7/site-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""checkpoint_converter/checkpoint_conv_tool.py"", line 173, in main
    FLAGS.target_checkpoint,
  File ""checkpoint_converter/checkpoint_conv_tool.py"", line 159, in convert_checkpoint
    model = get_XLnet()
  File ""checkpoint_converter/checkpoint_conv_tool.py"", line 146, in get_XLnet
    FLAGS.same_length, tf_float, FLAGS.residual)
  File ""checkpoint_converter/checkpoint_conv_tool.py"", line 90, in __init__
    output, new_mems, lookup_table = self.transformerxl_model(inps)
  File ""/home/chris/miniconda3/envs/tensorflow_cpu/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py"", line 891, in __call__
    outputs = self.call(cast_inputs, *args, **kwargs)
  File ""/home/chris/PycharmProjects/My_xlnet/modeling.py"", line 664, in call
    non_tgt_mask = -tf.eye(qlen, dtype=self.tf_float)
  File ""/home/chris/miniconda3/envs/tensorflow_cpu/lib/python3.7/site-packages/tensorflow_core/python/ops/linalg_ops.py"", line 169, in eye
    name=name)
  File ""/home/chris/miniconda3/envs/tensorflow_cpu/lib/python3.7/site-packages/tensorflow_core/python/ops/linalg_ops_impl.py"", line 65, in eye
    diag_shape = array_ops.concat((batch_shape, [diag_size]), axis=0)
  File ""/home/chris/miniconda3/envs/tensorflow_cpu/lib/python3.7/site-packages/tensorflow_core/python/util/dispatch.py"", line 180, in wrapper
    return target(*args, **kwargs)
  File ""/home/chris/miniconda3/envs/tensorflow_cpu/lib/python3.7/site-packages/tensorflow_core/python/ops/array_ops.py"", line 1431, in concat
    return gen_array_ops.concat_v2(values=values, axis=axis, name=name)
  File ""/home/chris/miniconda3/envs/tensorflow_cpu/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_array_ops.py"", line 1257, in concat_v2
    ""ConcatV2"", values=values, axis=axis, name=name)
  File ""/home/chris/miniconda3/envs/tensorflow_cpu/lib/python3.7/site-packages/tensorflow_core/python/framework/op_def_library.py"", line 471, in _apply_op_helper
    as_ref=input_arg.is_ref)
  File ""/home/chris/miniconda3/envs/tensorflow_cpu/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py"", line 1365, in internal_convert_n_to_tensor
    ctx=ctx))
  File ""/home/chris/miniconda3/envs/tensorflow_cpu/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py"", line 1264, in internal_convert_to_tensor
    raise RuntimeError(""Attempting to capture an EagerTensor without ""
RuntimeError: Attempting to capture an EagerTensor without building a function.
```
Please help!!! i cant find a solution. It seems that functional api requires graph and not eager tensors. I used the @tf.function decorator without success. I also tried using functional api with the tf.keras.model.Model and the result is exactly the same.

**EDIT**
By watching a tensor when executing both functional and subclassing api i found that the names differ.
Subclassing API: Tensor(""model/transformer/Cast:0"", shape=(1, 128, 1, 1), dtype=float32)
Functional API: Tensor(""Cast:0"", shape=(1, 128, 1, 1), dtype=float32)",christk1,b'models:official type:bug',2019-12-06T13:17:25Z,2020-06-13T04:46:22Z,,,,,,,
7916,AttributeError: module 'nets.mobilenet.conv_blocks' has no attribute 'squeeze_excite',"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",jundongAI,b'models:research stat:awaiting response type:support',2019-12-06T11:50:57Z,2020-07-14T09:30:41Z,,,,,,,
7907,ObjectDecetion custom trained model recognizes objects with many wrong results,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**: object_decetion/legacy/train.py
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:  no 
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:  Ubuntu 16.04
- **TensorFlow installed from (source or binary)**:  source
- **TensorFlow version (use command below)**:   tensorflow-gpu  1.15.0
- **Bazel version (if compiling from source)**:   0.26.1
- **CUDA/cuDNN version**:  10.1
- **GPU model and memory**: GTX 1660   6G
- **Exact command to reproduce**:  n/a


### Describe the problem
i use ssd_mobilenet_v1_coco  train my own data( Hammer  ， screwdriver ，Pipe wrenches )
use 2 gpu，  batch_size：30，  train steps  150w，then  save as model ,    This model can identify these three tools, but which other objects are also recognized as tools and the score is still high. What is wrong with this? Thank you.


### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
my ssd_mobilenet_v1_coco.config
` 

model {
  ssd {
    num_classes: 3
    box_coder {
      faster_rcnn_box_coder {
        y_scale: 10.0
        x_scale: 10.0
        height_scale: 5.0
        width_scale: 5.0
      }
    }
    matcher {
      argmax_matcher {
        matched_threshold: 0.5
        unmatched_threshold: 0.5
        ignore_thresholds: false
        negatives_lower_than_unmatched: true
        force_match_for_each_row: true
      }
    }
    similarity_calculator {
      iou_similarity {
      }
    }
    anchor_generator {
      ssd_anchor_generator {
        num_layers: 6
        min_scale: 0.2
        max_scale: 0.95
        aspect_ratios: 1.0
        aspect_ratios: 2.0
        aspect_ratios: 0.5
        aspect_ratios: 3.0
        aspect_ratios: 0.3333
      }
    }
    image_resizer {
      fixed_shape_resizer {
        height: 300
        width: 300
      }
    }
    box_predictor {
      convolutional_box_predictor {
        min_depth: 0
        max_depth: 0
        num_layers_before_predictor: 0
        use_dropout: false
        dropout_keep_probability: 0.8
        kernel_size: 1
        box_code_size: 4
        apply_sigmoid_to_scores: false
        conv_hyperparams {
          activation: RELU_6,
          regularizer {
            l2_regularizer {
              weight: 0.00004
            }
          }
          initializer {
            truncated_normal_initializer {
              stddev: 0.03
              mean: 0.0
            }
          }
          batch_norm {
            train: true,
            scale: true,
            center: true,
            decay: 0.9997,
            epsilon: 0.001,
          }
        }
      }
    }
    feature_extractor {
      type: 'ssd_mobilenet_v1'
      min_depth: 16
      depth_multiplier: 1.0
      conv_hyperparams {
        activation: RELU_6,
        regularizer {
          l2_regularizer {
            weight: 0.00004
          }
        }
        initializer {
          truncated_normal_initializer {
            stddev: 0.03
            mean: 0.0
          }
        }
        batch_norm {
          train: true,
          scale: true,
          center: true,
          decay: 0.9997,
          epsilon: 0.001,
        }
      }
    }
    loss {
      classification_loss {
        weighted_sigmoid {
        }
      }
      localization_loss {
        weighted_smooth_l1 {
        }
      }
      hard_example_miner {
        num_hard_examples: 3000
        iou_threshold: 0.99
        loss_type: CLASSIFICATION
        max_negatives_per_positive: 3
        min_negatives_per_image: 0
      }
      classification_weight: 1.0
      localization_weight: 1.0
    }
    normalize_loss_by_num_matches: true
    post_processing {
      batch_non_max_suppression {
        score_threshold: 1e-8
        iou_threshold: 0.6
        max_detections_per_class: 100
        max_total_detections: 100
      }
      score_converter: SIGMOID
    }
  }
}

train_config: {
  batch_size: 30
  optimizer {
    rms_prop_optimizer: {
      learning_rate: {
        exponential_decay_learning_rate {
          initial_learning_rate: 0.004
          schedule {
            step: 800000
            learning_rate: 0.004
          }
          schedule {
            step: 1000000
            learning_rate: 0.002
          }
          decay_steps: 800720
          decay_factor: 0.95
        }
      }
      momentum_optimizer_value: 0.9
      decay: 0.9
      epsilon: 1.0
    }
  }
  fine_tune_checkpoint: ""/home/a/yxf/ssd_mobile_train/ssd_mobilenet_v1_coco/model.ckpt""
  from_detection_checkpoint: true

  num_steps: 1000000
  data_augmentation_options {
    random_horizontal_flip {
    }
  }
  data_augmentation_options {
    ssd_random_crop {
    }
  }
}

train_input_reader: {
  tf_record_input_reader {
    input_path: ""path/data/record/train.record""
  }
  label_map_path: ""path/object_label_map.pbtxt""
}

eval_config: {
  num_examples:   8000
  max_evals: 10
}

eval_input_reader: {
  tf_record_input_reader {
    input_path: ""path/data/record/test.record""
  }
  label_map_path: ""path/object_label_map.pbtxt""
  shuffle: false
  num_readers: 1
}

`

### this is the right result !
![ok1](https://user-images.githubusercontent.com/32695021/70208040-7d54c800-1767-11ea-92fc-3e2a3df0abfd.jpg)
![ok2](https://user-images.githubusercontent.com/32695021/70208042-7ded5e80-1767-11ea-9c3f-f1be75028258.jpg)
### but  this is err  result !
![err](https://user-images.githubusercontent.com/32695021/70208039-7d54c800-1767-11ea-84ec-34f26d3a9a5d.jpg)
![err2](https://user-images.githubusercontent.com/32695021/70208307-28fe1800-1768-11ea-9432-cd3cad6ab087.jpg)

",alanjuster,b'models:research type:support',2019-12-05T06:07:37Z,2020-01-07T15:10:34Z,,,,,,,
7899,model save,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",cillayue,None,2019-12-03T03:08:09Z,2019-12-04T06:32:40Z,,,,,,,
7884,Fixed tf.compat.v1 bug,"Before that, it called __tensorflow.compat.v1.compat.v1.io.tf_record_iterator__ function, which does not exist, instead of __tensorflow.compat.v1.io.tf_record_iterator__.",miraliahmadli,b'cla: yes ready to pull',2019-11-29T13:22:47Z,2019-11-30T06:11:37Z,,,,,,,
7870,Can the ‘ssd_resnet_50_fpn_coco‘ be converted to a tflite model and deploy in android?,"
### System information
- **What is the top-level directory of the model you are using**: object_detection
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: no
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: convert model in Ubuntu 16.04,deploy model in Windows10
- **TensorFlow installed from (source or binary)**: binary, installed from pip: pip install tensorflow-gpu
- **TensorFlow version (use command below)**: 1.14
- **Bazel version (if compiling from source)**: None
- **CUDA/cuDNN version**: CUDA10
- **GPU model and memory**: TITAN XP 12G
- **Phone**: HUAWEI Mate 30 Pro ,Android10 , 8G RAM, HUAWEI Kirin 990
- **Exact command to reproduce**:


### Describe the problem
I use the instruction of https://github.com/tensorflow/models/issues/6709#issuecomment-543432460 to convert ```ssd_resnet_50_fpn_coco``` to ```*.tflite```file. I finally got the file successfully. Here is my [tflite file](https://drive.google.com/open?id=12bp6mxasB9EGo3VPu3L5ljZlGm_rhaeF). But When I deploy the ```.tflite``` file in Android Studio ,the app crashed.

```ssd_resnet_50_fpn_coco``` is download from [Tensorflow detection model zoo](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md).

Android app code is download from [TensorFlow Lite Object Detection Android Demo](https://github.com/tensorflow/examples/tree/master/lite/examples/object_detection/android).It can install and run in my phone.

Then ready to deploy ```ssd_resnet_50_fpn_coco```tflite model in android. 
- First: I just rename my```.tflite```file to ```detect1.tflite``` and copy to ```app\src\main\assets``` and not change the ```labelmap.txt``` file. Then I modified the ```TF_OD_API_INPUT_SIZE``` parameter from 300 to 640 in ```\app\src\main\java\org\tensorflow\lite\examples\detection\DetectorActivity.java``` .

However, the app crashed. Here is the log from Android Studio.
```
2019-11-27 20:38:02.873 14663-14707/org.tensorflow.lite.examples.detection E/AndroidRuntime: FATAL EXCEPTION: inference
    Process: org.tensorflow.lite.examples.detection, PID: 14663
    java.lang.IllegalArgumentException: Cannot convert between a TensorFlowLite buffer with 4915200 bytes and a Java Buffer with 1228800 bytes.
        at org.tensorflow.lite.Tensor.throwIfShapeIsIncompatible(Tensor.java:332)
        at org.tensorflow.lite.Tensor.throwIfDataIsIncompatible(Tensor.java:305)
        at org.tensorflow.lite.Tensor.setTo(Tensor.java:123)
        at org.tensorflow.lite.NativeInterpreterWrapper.run(NativeInterpreterWrapper.java:148)
        at org.tensorflow.lite.Interpreter.runForMultipleInputsOutputs(Interpreter.java:296)
        at org.tensorflow.lite.examples.detection.tflite.TFLiteObjectDetectionAPIModel.recognizeImage(TFLiteObjectDetectionAPIModel.java:197)
        at org.tensorflow.lite.examples.detection.DetectorActivity$2.run(DetectorActivity.java:181)
        at android.os.Handler.handleCallback(Handler.java:888)
        at android.os.Handler.dispatchMessage(Handler.java:100)
        at android.os.Looper.loop(Looper.java:213)
        at android.os.HandlerThread.run(HandlerThread.java:67)
```
- Second: Observing the log above, I found that the problem may be because I modified the value to 640, so I changed a to 1280. The app still crashes, but a new error log appears. 
```
2019-11-27 20:58:10.236 17448-17553/org.tensorflow.lite.examples.detection E/AndroidRuntime: FATAL EXCEPTION: inference
    Process: org.tensorflow.lite.examples.detection, PID: 17448
    java.lang.ArrayIndexOutOfBoundsException: length=160; index=-6
        at java.util.Vector.elementData(Vector.java:734)
        at java.util.Vector.get(Vector.java:750)
        at org.tensorflow.lite.examples.detection.tflite.TFLiteObjectDetectionAPIModel.recognizeImage(TFLiteObjectDetectionAPIModel.java:218)
        at org.tensorflow.lite.examples.detection.DetectorActivity$2.run(DetectorActivity.java:181)
        at android.os.Handler.handleCallback(Handler.java:888)
        at android.os.Handler.dispatchMessage(Handler.java:100)
        at android.os.Looper.loop(Looper.java:213)
        at android.os.HandlerThread.run(HandlerThread.java:67)
2019-11-27 20:58:10.243 17448-17448/org.tensorflow.lite.examples.detection E/ResMng NATIVE_MSG_FILTER: endActivityTransaction: margin state not match

```
The code in ```TFLiteObjectDetectionAPIModel.java:218``` is:
```
recognitions.add(
          new Recognition(
              """" + i,
              labels.get((int) outputClasses[0][i] + labelOffset),
              outputScores[0][i],
              detection));
```
Then I debug the App, I found the value of ```outputClasses[0][i]``` is negative, So maybe it is the reason . But I dont konw how to fix it. 
- Third: In this step, I modified the ```TF_OD_API_INPUT_SIZE``` parameter from 1280 to 640, and modified ```TF_OD_API_IS_QUANTIZED``` from ```true``` to ```false```. ```TF_OD_API_IS_QUANTIZED``` parameter is defined below ```TF_OD_API_INPUT_SIZE```. 
Unfortunately, the App still crashes with errors similar to those in Second.
```
2019-11-27 21:02:03.342 17894-18086/org.tensorflow.lite.examples.detection E/AndroidRuntime: FATAL EXCEPTION: inference
    Process: org.tensorflow.lite.examples.detection, PID: 17894
    java.lang.ArrayIndexOutOfBoundsException: length=160; index=-5
        at java.util.Vector.elementData(Vector.java:734)
        at java.util.Vector.get(Vector.java:750)
        at org.tensorflow.lite.examples.detection.tflite.TFLiteObjectDetectionAPIModel.recognizeImage(TFLiteObjectDetectionAPIModel.java:218)
        at org.tensorflow.lite.examples.detection.DetectorActivity$2.run(DetectorActivity.java:181)
        at android.os.Handler.handleCallback(Handler.java:888)
        at android.os.Handler.dispatchMessage(Handler.java:100)
        at android.os.Looper.loop(Looper.java:213)
        at android.os.HandlerThread.run(HandlerThread.java:67)
2019-11-27 21:02:03.356 17894-17894/org.tensorflow.lite.examples.detection E/ResMng NATIVE_MSG_FILTER: endActivityTransaction: margin state not match
```
After the above three steps, I think it may be a problem with the android program, but I don't know how to modify the official demo to a code suitable for ```ssd_resnet_50_fpn_coco```.

",yzmean,b'models:research type:support',2019-11-27T13:10:43Z,2019-12-12T20:53:58Z,,,,,,,
7854,Tensorflow serving datatype issue i am using tensorboard as client,"I am getting this error how to change data type:
raise _Rendezvous(state, None, None, deadline)
grpc._channel._Rendezvous: <_Rendezvous of RPC that terminated with:
status = StatusCode.INVALID_ARGUMENT
details = ""Expects arg[0] to be float but string is provided""
debug_error_string = ""{""created"":""@1574400948.336107855"",""description"":""Error received from peer ipv6:[::1]:8500"",""file"":""src/core/lib/surface/call.cc"",""file_line"":1055,""grpc_message"":""Expects arg[0] to be float but string is provided"",""grpc_status"":3}",spraveen420,b'stat:awaiting response type:support',2019-11-22T06:00:55Z,2020-07-14T09:35:25Z,,,,,,,
7826, tf.image.resize,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",Evoluange,b'type:support',2019-11-18T12:23:49Z,2020-06-19T09:24:10Z,,,,,,,
7823,Error polling for event status: failed to query event: CUDA_ERROR_ILLEGAL_ADDRESS: an illegal memory access was encountered,"trying to run trasformer in v2 with TF-2.0 stable and branch in models : tf_2_0_rc1(https://github.com/tensorflow/models/tree/tf_2_0_rc1) as per ticket
#7644
with below command:
python transformer_main.py --data_dir=$DATA_DIR --model_dir=$MODEL_DIR --vocab_file=$VOCAB_FILE --param_set=big --bleu_source=$DATA_DIR/newstest2014.en --bleu_ref=$DATA_DIR/newstest2014.de

Got error with below Stack trace:

W1118 07:34:57.648332 140172354287360 util.py:144] Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.decoder_stack.layers.5.2.layer.filter_dense_layer.bias
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.decoder_stack.layers.5.2.layer.output_dense_layer.kernel
W1118 07:34:57.648442 140172354287360 util.py:144] Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.decoder_stack.layers.5.2.layer.output_dense_layer.kernel
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.decoder_stack.layers.5.2.layer.output_dense_layer.bias
W1118 07:34:57.648550 140172354287360 util.py:144] Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.decoder_stack.layers.5.2.layer.output_dense_layer.bias
WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/alpha/guide/checkpoints#loading_mechanics for details.
W1118 07:34:57.648662 140172354287360 util.py:152] A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/alpha/guide/checkpoints#loading_mechanics for details.
2019-11-18 07:34:57.650464: E tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:750] failed to record completion event; therefore, failed to create inter-stream dependency
2019-11-18 07:34:57.650537: I tensorflow/stream_executor/stream.cc:4816] [stream=0x5401120,impl=0x53ffe90] did not memcpy host-to-device; source: 0x7f7b6c055f00
2019-11-18 07:34:57.650560: E tensorflow/stream_executor/stream.cc:332] Error recording event in stream: error recording CUDA event on stream 0x5400b10: CUDA_ERROR_ILLEGAL_ADDRESS: an illegal memory access was encountered; not marking stream as bad, as the Event object may be at fault. Monitor for further errors.
2019-11-18 07:34:57.650586: E tensorflow/stream_executor/cuda/cuda_event.cc:29] Error polling for event status: failed to query event: CUDA_ERROR_ILLEGAL_ADDRESS: an illegal memory access was encountered
2019-11-18 07:34:57.650613: F tensorflow/core/common_runtime/gpu/gpu_event_mgr.cc:273] Unexpected Event status: 1
Fatal Python error: Aborted

Thread 0x00007f7c6b627700 (most recent call first):
  File ""/home/ubuntu/tf2py/lib/python3.5/site-packages/tensorflow_core/python/ops/gen_dataset_ops.py"", line 1141 in delete_iterator
  File ""/home/ubuntu/tf2py/lib/python3.5/site-packages/tensorflow_core/python/data/ops/iterator_ops.py"", line 537 in __del__
Aborted




",tkngoutham,b'models:official stat:awaiting response type:bug',2019-11-18T07:55:06Z,2020-05-10T06:24:34Z,,,,,,,
7822,TypeError: unsupported operand type(s) for *: 'NoneType' and 'int' in keras_utils.py,"trying to run trasformer in v2 with  TF-2.0 stable and branch in models : tf_2_0_rc1(https://github.com/tensorflow/models/tree/tf_2_0_rc1)  as per ticket 
 https://github.com/tensorflow/models/issues/7644 
with below command:
python transformer_main.py --data_dir=$DATA_DIR --model_dir=$MODEL_DIR     --vocab_file=$VOCAB_FILE --param_set=base     --bleu_source=$DATA_DIR/newstest2014.en --bleu_ref=$DATA_DIR/newstest2014.de


Got error with below Stack trace:

Total params: 61,362,176
Trainable params: 61,362,176
Non-trainable params: 0
__________________________________________________________________________________________________
I1118 07:25:13.213394 139963829905152 transformer_main.py:298] Start train iteration at global step:0
Train for 1000 steps
/home/ubuntu/tf2py/lib/python3.5/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  ""Converting sparse IndexedSlices to a dense Tensor of unknown shape. ""
/home/ubuntu/tf2py/lib/python3.5/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  ""Converting sparse IndexedSlices to a dense Tensor of unknown shape. ""
2019-11-18 07:25:42.524686: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
INFO:tensorflow:BenchmarkMetric: {'epoch':0, 'time_taken': 91.634508}
I1118 07:26:44.871305 139963829905152 keras_utils.py:93] BenchmarkMetric: {'epoch':0, 'time_taken': 91.634508}
Traceback (most recent call last):
  File ""official/transformer/v2/transformer_main.py"", line 474, in <module>
    app.run(main)
  File ""/usr/local/lib/python3.5/dist-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/usr/local/lib/python3.5/dist-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""official/transformer/v2/transformer_main.py"", line 463, in main
    _run_task(task)
  File ""official/transformer/v2/transformer_main.py"", line 454, in _run_task
    task.train()
  File ""official/transformer/v2/transformer_main.py"", line 329, in train
    verbose=(2 if flags_obj.enable_time_history else 1))
  File ""/home/ubuntu/tf2py/lib/python3.5/site-packages/tensorflow_core/python/keras/engine/training.py"", line 728, in fit
    use_multiprocessing=use_multiprocessing)
  File ""/home/ubuntu/tf2py/lib/python3.5/site-packages/tensorflow_core/python/keras/engine/training_v2.py"", line 324, in fit
    total_epochs=epochs)
  File ""/home/ubuntu/tf2py/lib/python3.5/site-packages/tensorflow_core/python/keras/engine/training_v2.py"", line 174, in run_one_epoch
    step += 1
  File ""/usr/lib/python3.5/contextlib.py"", line 66, in __exit__
    next(self.gen)
  File ""/home/ubuntu/tf2py/lib/python3.5/site-packages/tensorflow_core/python/keras/engine/training_v2.py"", line 700, in on_batch
    mode, 'end', step, batch_logs)
  File ""/home/ubuntu/tf2py/lib/python3.5/site-packages/tensorflow_core/python/keras/callbacks.py"", line 235, in _call_batch_hook
    batch_hook(batch, logs)
  File ""/home/ubuntu/tf2py/lib/python3.5/site-packages/tensorflow_core/python/keras/callbacks.py"", line 518, in on_train_batch_end
    self.on_batch_end(batch, logs=logs)
  File ""/mnt/data/models/official/utils/misc/keras_utils.py"", line 80, in on_batch_end
    examples_per_second = (self.batch_size * self.log_steps) / elapsed_time
TypeError: unsupported operand type(s) for *: 'NoneType' and 'int'



Note:PARAM_SET is base

",tkngoutham,b'models:official type:bug',2019-11-18T07:49:41Z,2020-05-15T17:33:28Z,,,,,,,
7821,Tensorflow GPU trained .PB file,"Hi Team,

I trained Faster RCNN deep learning model on GCP with GPU and generated the .pb file. Am trying to use trained .pb file in CPU. I am getting errors while reading the .pb file in CPU without gpu. Pls. find the attached error.

![image](https://user-images.githubusercontent.com/9213878/69027700-d3024400-09f5-11ea-8bbf-4979e989c318.png)

Regards
Mohan
",mohanrajmit,b'models:research stalled stat:awaiting response type:bug',2019-11-18T05:53:32Z,2020-09-18T17:17:40Z,,,,,,,
7809,Printing the time while detection is happening,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",HemanthKumar-Thope,b'stat:awaiting response type:support',2019-11-14T17:03:53Z,2020-07-14T09:41:01Z,,,,,,,
7800,Merged commit includes the following changes:,"280142968  by Zhichao Lu:

    Opensource MobilenetEdgeTPU + ssdlite into third-party object detection APIs on EdgeTPU.

--
280134001  by Zhichao Lu:

    Adds MobilenetEdgeTpu + ssdlite into internal object detection APIs on EdgeTPU.

--
278941778  by Zhichao Lu:

    Add support for fixed input shapes for 'encoded_image_string_tensor' and 'tf_example' inputs.

--
278933274  by Zhichao Lu:

      Adding fool proof check to avoid using 1x1 depthwise conv op.

--
278762192  by Zhichao Lu:

    Ensure correct number of iterations after training resumes.

--
278746440  by Zhichao Lu:

    Internal change.

--
278006953  by Zhichao Lu:

    Internal changes to tf.contrib symbols

--
278006330  by Zhichao Lu:

    Internal changes to tf.contrib symbols

--
277593959  by Zhichao Lu:

      Make the ssd_feature_extractor_test.py PY3 compatible. The ""six.zip"" will use ""itertools.izip"" in Python 2 and ""zip"" in Python 3.

--
277344551  by Zhichao Lu:

    Internal change.

--
277154953  by Zhichao Lu:

    Conditionally use keras based optimizers so that check-pointing works correctly.
    This change also enables summaries on TPU which were previously not enabled
    due to a bug.

--
277087572  by Zhichao Lu:

    Fix resizing boxes when using keep_aspect_ratio_rezier with padding.

--
275898543  by Zhichao Lu:

    Support label_map_proto as input in label_map_util.

--
275891248  by Zhichao Lu:

    Fix top-k computation logic for boxes to consider all classes per location.

--
275347137  by Zhichao Lu:

    Add force_no_resize flag in eval.proto which replaces
    the resize config with identity resizer. This is useful
    when we want to test at the original image resolution.

--

PiperOrigin-RevId: 280142968",marksandler2,b'cla: yes',2019-11-13T09:58:56Z,2019-11-13T18:36:48Z,,,,,,,
7799,deeplab code bug,"`https://github.com/tensorflow/models/blob/master/research/deeplab/train.py#L345`
`dataset.num_classes` shold be `dataset.num_of_classes`",FishermanZzhang,b'stat:awaiting response',2019-11-13T08:18:29Z,2019-11-18T01:50:24Z,,,,,,,
7792,there are some problems when i use tf.loadGraphModel,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- object_detection
- tensorflow:1.14.0
- linux ubuntu
- tensorflowjs: 1.2.3

I use object_detection/g3doc/exporting_models.md to export a ssd model, and i use tfjs to converter the .pb file, and obtain the model.json, then i try to load the model, but there is always an error.

code:
const WEIGHTS_URL='web_model/model.json';
tf.loadGraphModel(WEIGHTS_URL).then(  
            res => {
                model = res;
                modelReady = true;
            }
        );    //error shows here

error:
Uncaught (in promise) TypeError: lt(...).registerTensor is not a function
    at new t (tfjs@1.2.3:2)
    at Function.t.make (tfjs@1.2.3:2)
    at tn (tfjs@1.2.3:2)
    at Qe (tfjs@1.2.3:2)
    at i (tfjs@1.2.3:2)
    at Object.Jl [as decodeWeights] (tfjs@1.2.3:2)
    at t.<anonymous> (tfjs@1.2.3:2)
    at tfjs@1.2.3:2
    at Object.next (tfjs@1.2.3:2)
    at o (tfjs@1.2.3:2)
t @ tfjs@1.2.3:2
t.make @ tfjs@1.2.3:2
tn @ tfjs@1.2.3:2
Qe @ tfjs@1.2.3:2
i @ tfjs@1.2.3:2
Jl @ tfjs@1.2.3:2
(anonymous) @ tfjs@1.2.3:2
(anonymous) @ tfjs@1.2.3:2
(anonymous) @ tfjs@1.2.3:2
o @ tfjs@1.2.3:2
Promise.then (async)
(anonymous) @ index.html:327


the reason i did not use the latest version is that the latest version have some problem.",xusongpei,None,2019-11-12T06:32:54Z,2019-11-12T07:20:39Z,,,,,,,
7781,About tf2.0 pretrained models,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

### Describe the problem
how can I get the pretrained models ( tensorflow 2.0), for example resnet50

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",xiaohu2015,None,2019-11-11T06:27:12Z,2019-11-14T04:39:58Z,,,,,,,
7769,[deeplab] The eval.py and vis.py not working ,"### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: : Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: : binary
- **TensorFlow version (use command below)**: : 1.15.0
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**: : 10.0 / 7.6.4
- **GPU model and memory**:  V100, 32GB
- **Exact command to reproduce**:

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

I use script in research/deeplab to train deeplab for my own dataset. 
My image has size as 1920x1080.

I use the following command to train. it worked smoothly

```bash
python deeplab/train.py \
    --logtostderr \
    --train_split=""trainval"" \
    --model_variant=""mobilenet_v2"" \
    --train_crop_size=""769,769"" \
    --train_batch_size=16 \
    --fine_tune_batch_norm=false \
    --tf_initial_checkpoint='/home/user/workspace/2019_ICT/deeplab_model_zoo/deeplabv3_mnv2_pascal_train_aug/model.ckpt-30000' \
    --initialize_last_layer=False \
    --last_layers_contain_logits_only=True \
    --train_logdir='/home/user/workspace/2019_ICT/icboard_dataset/segmentation/part1/train_log' \
    --dataset_dir='/home/user/workspace/2019_ICT/icboard_dataset/segmentation/part1/tfrecord/' \
    --dataset=""icboard_seg"" \
    --training_number_of_steps=1000 \
    --base_learning_rate=0.0001 
```

The training log: [train.log](https://github.com/tensorflow/models/files/3818482/train.log) . There aren't any error messages.

But when I try the eval.py, the mIoU is not output in the console. There isn't any error message in the log, so I guess there are some options that I have to turn on.

The eval log : [eval.log](https://github.com/tensorflow/models/files/3818485/eval.log). There isn't any error message too.

```bash
python deeplab/eval.py \
  --logtostderr \
  --eval_split=""val"" \
  --model_variant=""mobilenet_v2"" \
  --eval_crop_size=""513,513"" \
  --min_resize_value=288 \
  --max_resize_value=512 \
  --checkpoint_dir='/home/user/workspace/2019_ICT/icboard_dataset/segmentation/part1/train_log' \
  --eval_logdir='/home/user/workspace/2019_ICT/icboard_dataset/segmentation/part1/train_eval' \
  --dataset_dir='/home/user/workspace/2019_ICT/icboard_dataset/segmentation/part1/tfrecord/' \
  --max_number_of_evaluations=1 \
  --eval_interval_secs=0 \
  --dataset=""icboard_seg"" 
```

I used the following command to run vis.py.

```bash
python deeplab/eval.py \
  --logtostderr \
  --eval_split=""val"" \
  --model_variant=""mobilenet_v2"" \
  --eval_crop_size=""513,513"" \
  --min_resize_value=288 \
  --max_resize_value=512 \
  --checkpoint_dir='/home/user/workspace/2019_ICT/icboard_dataset/segmentation/part1/train_log' \
  --eval_logdir='/home/user/workspace/2019_ICT/icboard_dataset/segmentation/part1/train_eval' \
  --dataset_dir='/home/user/workspace/2019_ICT/icboard_dataset/segmentation/part1/tfrecord/' \
  --max_number_of_evaluations=1 \
  --eval_interval_secs=0 \
  --dataset=""icboard_seg"" 
```

The vis log : [vis.log](https://github.com/tensorflow/models/files/3818490/vis.log). As you can see the error is as follow.

```bash
tf.image.resize_bilinear is deprecated. Please use tf.compat.v1.image.resize_bilinear instead.

Traceback (most recent call last):
  File ""deeplab/vis.py"", line 320, in <module>
    tf.app.run()
  File ""/home/user/opt/miniconda2/envs/py2.7/lib/python2.7/site-packages/tensorflow_core/python/platform/app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""/home/user/opt/miniconda2/envs/py2.7/lib/python2.7/site-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/home/user/opt/miniconda2/envs/py2.7/lib/python2.7/site-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""deeplab/vis.py"", line 267, in main
    align_corners=True), 3)
  File ""/home/user/opt/miniconda2/envs/py2.7/lib/python2.7/site-packages/tensorflow_core/python/ops/image_ops_impl.py"", line 1187, in resize_images
    skip_resize_if_same=True)
  File ""/home/user/opt/miniconda2/envs/py2.7/lib/python2.7/site-packages/tensorflow_core/python/ops/image_ops_impl.py"", line 1053, in _resize_images_common
    new_height_const = size_const_as_shape.dims[0].value
TypeError: 'NoneType' object has no attribute '__getitem__'

```

Is there anybody who know why this happened and how can I overcome this?


",gachiemchiep,None,2019-11-07T08:14:55Z,2019-11-11T06:35:01Z,,,,,,,
7742,which version of tensorflow use in this model,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",sheikh67,None,2019-11-01T14:04:14Z,2019-11-05T18:12:06Z,,,,,,,
7720,  (0) Not found: Key FeatureExtractor/MobilenetV3/Conv/conv_quant/max not found in checkpoint     ,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
v1.14.0-rc1-22-gaf24dc91b5

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.
  
when train the quantization uint8  mobilenet v3 ,I get the error as list above , any help? thanks
### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",shenmayufei,b'stat:awaiting response type:support',2019-10-25T15:47:22Z,2020-07-17T09:48:50Z,,,,,,,
7716,ImportError: cannot import name string_int_label_map_pb2,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",coopot,b'type:support',2019-10-25T06:51:26Z,2020-07-17T09:49:53Z,,,,,,,
7714,Convolution not supported for input with rank,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",dapeng2017,None,2019-10-25T01:27:34Z,2019-10-25T01:29:20Z,,,,,,,
7711,"Hello, I found that the target detection returns the 10 most probable targets for each picture. The target I want to detect is about 25 in the clothes picture. I don't know where to modify it to achieve my goal. Thank you very much. Any help you provide","Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",siyangbing,b'type:support',2019-10-24T08:24:13Z,2020-07-17T09:51:03Z,,,,,,,
7705,[Object detection] WARNING:root:Variable [...] is not available in checkpoint,"Hello,

I'm trying to train a model to detect trunks.
I've already prepared my inputs.
So, I'm executing the training script in the following way:

```
#!/bin/bash

# Exit script on error.
set -e
# Echo each command, easier for debugging.
set -x

export PYTHONPATH=`pwd`:`pwd`/slim:$PYTHONPATH

num_training_steps=500
num_eval_steps=100

MODEL_DIR=""/home/andre-criis/Source/coral/detect/models/research/models/mobilenet_v2""
TRAIN_DIR=train_dir
mkdir ""${TRAIN_DIR}""

python3 object_detection/model_main.py \
  --pipeline_config_path=${MODEL_DIR}/pipeline.config \
  --model_dir=${TRAIN_DIR} \
  --num_train_steps=""${num_training_steps}"" \
  --num_eval_steps=""${num_eval_steps}"" \
  --sample_1_of_n_eval_examples=1 \
  --alsologtostderr
```

However, I'm stuck in this error:
```
WARNING:root:Variable [BoxPredictor_0/BoxEncodingPredictor/biases] is not available in checkpoint
...
WARNING:root:Variable [FeatureExtractor/MobilenetV2/expanded_conv/project/BatchNorm/gamma] is not available in checkpoint
...
WARNING:root:Variable [FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/BatchNorm/gamma] is not available in checkpoint
```

It's weird because I'm creating an empty directory for the train (as can be seen above) and the parameter `from_detection_checkpoint` is set to `true` in my `pipeline.config`.

Can anybody help me?
Thanks in advance.",aaguiar96,b'models:research type:support',2019-10-22T12:21:52Z,2020-06-19T16:36:30Z,,,,,,,
7689,Minor Download bug in tensorflow_datasets,"Tensorflow 2.0.0
Latest tensorflow_datasets from pip install tensorflow_datasets

Windows Anaconda environment.

Code is from Tensorflow tutorials.


import tensorflow as tf
from __future__ import absolute_import, division, print_function, unicode_literals
from tensorflow_examples.models.pix2pix import pix2pix

import tensorflow_datasets as tfds
tfds.disable_progress_bar()

from IPython.display import clear_output
import matplotlib.pyplot as plt
dataset, info = tfds.load('oxford_iiit_pet:3.0.0', with_info=True)

Results in:

DownloadError: Failed to get url http://www.robots.ox.ac.uk/~vgg/data/pets/data\images.tar.gz. HTTP code: 404.


404 is due to the data\images.tar.gz instead of /images.tar.gz

downloader could be modified to always replace ""\"" with ""/"" when over http protocol.",Nodice,None,2019-10-18T23:47:35Z,2019-10-19T00:30:50Z,,,,,,,
7681,BERT training on TPU with keras_compile_fit results in error when starting validation step,"I'm using BERT model in colab with TPU runtime selected. I installed the last nightly version of tensorflow 2.0 as the current stable one had some functionalities missing. The checkpoint model and the training and validation datasets are stored in a google storage bucket as recommended. The ouput directory is as well a folder on gs.
The training for the first epoch works well but it doesn't seem to get past this step. I tried both training methods implemented keras or that custom tensorflow training (_model_training_utils.run_customized_training_loop_). The following output is displayed on run:

```
I1017 07:57:10.538644 140106235082624 remote.py:156] Entering into master device scope: /job:worker/replica:0/task:0
2019-10-17 07:57:10.542454: E tensorflow/stream_executor/cuda/cuda_driver.cc:334] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
INFO:tensorflow:Initializing the TPU system: 10.112.92.218:8470
I1017 07:57:10.572217 140106235082624 tpu_strategy_util.py:71] Initializing the TPU system: 10.112.92.218:8470
INFO:tensorflow:Clearing out eager caches
I1017 07:57:10.663481 140106235082624 tpu_strategy_util.py:95] Clearing out eager caches
INFO:tensorflow:Finished initializing TPU system.
I1017 07:57:18.129874 140106235082624 tpu_strategy_util.py:115] Finished initializing TPU system.
INFO:tensorflow:Found TPU system:
I1017 07:57:18.135898 140106235082624 tpu_system_metadata.py:148] Found TPU system:
INFO:tensorflow:*** Num TPU Cores: 8
I1017 07:57:18.136226 140106235082624 tpu_system_metadata.py:149] *** Num TPU Cores: 8
INFO:tensorflow:*** Num TPU Workers: 1
I1017 07:57:18.136900 140106235082624 tpu_system_metadata.py:150] *** Num TPU Workers: 1
INFO:tensorflow:*** Num TPU Cores Per Worker: 8
I1017 07:57:18.136965 140106235082624 tpu_system_metadata.py:152] *** Num TPU Cores Per Worker: 8
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)
I1017 07:57:18.137022 140106235082624 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)
I1017 07:57:18.137387 140106235082624 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)
I1017 07:57:18.137451 140106235082624 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)
I1017 07:57:18.137512 140106235082624 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)
I1017 07:57:18.137567 140106235082624 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)
I1017 07:57:18.137620 140106235082624 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)
I1017 07:57:18.137671 140106235082624 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)
I1017 07:57:18.137726 140106235082624 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)
I1017 07:57:18.137780 140106235082624 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)
I1017 07:57:18.137832 140106235082624 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)
I1017 07:57:18.137883 140106235082624 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)
I1017 07:57:18.137935 140106235082624 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)
I1017 07:57:18.137987 140106235082624 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)
strategy
I1017 07:57:18.306019 140106235082624 train.py:211] Training using TF 2.0 Keras compile/fit API with distrubuted strategy.
Train for 258 steps, validate for 65 steps
Epoch 1/3
  1/258 [..............................] - ETA: 6:56:39 - loss: 0.7556 - test_accuracy: 0.4688WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (1.674855). Check your callbacks.
W1017 08:00:08.274050 140106235082624 callbacks.py:246] Method (on_train_batch_end) is slow compared to the batch update (1.674855). Check your callbacks.
257/258 [============================>.] - ETA: 0s - loss: 7.2636 - test_accuracy: 0.42132019-10-17 08:01:11.056463: E tensorflow/core/distributed_runtime/eager/remote_tensor_handle_data.cc:71] Unable to destroy remote tensor handles: Failed copying input tensor from /job:worker/replica:0/task:0/device:TPU:0 to /job:worker/replica:0/task:0/device:CPU:0 in order to run Identity: Driver not open.
	Encountered when executing an operation using EagerExecutor. This error cancels all future operations and poisons their output tensors.
Traceback (most recent call last):
  File ""/usr/lib/python3.6/runpy.py"", line 193, in _run_module_as_main
2019-10-17 08:01:11.056718: E tensorflow/core/distributed_runtime/eager/remote_tensor_handle_data.cc:71] Unable to destroy remote tensor handles: Failed copying input tensor from /job:worker/replica:0/task:0/device:TPU:0 to /job:worker/replica:0/task:0/device:CPU:0 in order to run Identity: Driver not open.
	Encountered when executing an operation using EagerExecutor. This error cancels all future operations and poisons their output tensors.
2019-10-17 08:01:11.056881: E tensorflow/core/distributed_runtime/eager/remote_tensor_handle_data.cc:71] Unable to destroy remote tensor handles: Failed copying input tensor from /job:worker/replica:0/task:0/device:TPU:0 to /job:worker/replica:0/task:0/device:CPU:0 in order to run Identity: Driver not open.
	Encountered when executing an operation using EagerExecutor. This error cancels all future operations and poisons their output tensors.
2019-10-17 08:01:11.057070: E tensorflow/core/distributed_runtime/eager/remote_tensor_handle_data.cc:71] Unable to destroy remote tensor handles: Failed copying input tensor from /job:worker/replica:0/task:0/device:TPU:0 to /job:worker/replica:0/task:0/device:CPU:0 in order to run Identity: Driver not open.
	Encountered when executing an operation using EagerExecutor. This error cancels all future operations and poisons their output tensors.
2019-10-17 08:01:11.057218: E tensorflow/core/distributed_runtime/eager/remote_tensor_handle_data.cc:71] Unable to destroy remote tensor handles: Failed copying input tensor from /job:worker/replica:0/task:0/device:TPU:0 to /job:worker/replica:0/task:0/device:CPU:0 in order to run Identity: Driver not open.
	Encountered when executing an operation using EagerExecutor. This error cancels all future operations and poisons their output tensors.
2019-10-17 08:01:11.057321: E tensorflow/core/distributed_runtime/eager/remote_tensor_handle_data.cc:71] Unable to destroy remote tensor handles: Failed copying input tensor from /job:worker/replica:0/task:0/device:TPU:0 to /job:worker/replica:0/task:0/device:CPU:0 in order to run Identity: Driver not open.
	Encountered when executing an operation using EagerExecutor. This error cancels all future operations and poisons their output tensors.
2019-10-17 08:01:11.057427: E tensorflow/core/distributed_runtime/eager/remote_tensor_handle_data.cc:71] Unable to destroy remote tensor handles: Failed copying input tensor from /job:worker/replica:0/task:0/device:TPU:0 to /job:worker/replica:0/task:0/device:CPU:0 in order to run Identity: Driver not open.
	Encountered when executing an operation using EagerExecutor. This error cancels all future operations and poisons their output tensors.
2019-10-17 08:01:11.057527: E tensorflow/core/distributed_runtime/eager/remote_tensor_handle_data.cc:71] Unable to destroy remote tensor handles: Failed copying input tensor from /job:worker/replica:0/task:0/device:TPU:0 to /job:worker/replica:0/task:0/device:CPU:0 in order to run Identity: Driver not open.
```

The error is truncated as the last error message is repeated.

I would very much appreciate some help regarding why this might happen. For now I don't know if I'm doing something wrong or it's a bug and I shouldn't continue with debugging. ",georgealexandruvlad,None,2019-10-17T08:57:00Z,2019-10-17T19:25:35Z,,,,,,,
7680,Not getting Mentioned Accuracy(93%) for training MobilenetV2 with cifar10 dataset on CPU,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- tensorflow/models/research/slim
- Have I written custom code : NO
- OS Platform and Distribution : Ubuntu 18.04
- TensorFlow installed from source
- TensorFlow version 1.14
-Bazel version  : N/A
-CUDA/cuDNN version : N/A
- **GPU model and memory**: Working on CPU : intel i5 8th gen
- **Exact command to reproduce**:DATASET_DIR=/tmp/cifar10
                                                        TRAIN_DIR=/tmp/train_logs
                                                         python train_image_classifier.py \
                                                         --train_dir=${TRAIN_DIR} \
                                                         --dataset_name=cifar10 \
                                                         --dataset_split_name=train \
                                                         --dataset_dir=${DATASET_DIR} \
                                                         --model_name=mobilenet_v2 \
                                                          --clone_cpu=True

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

### Describe the problem
I was trying train mobilenetv2 with cifar10 dataset from Scratch as given directions in slim model on CPU but ended getting only 70% accuracy

### Source code / logs
DATASET_DIR=/tmp/cifar10
                                                        TRAIN_DIR=/tmp/train_logs
                                                         python train_image_classifier.py \
                                                         --train_dir=${TRAIN_DIR} \
                                                         --dataset_name=cifar10 \
                                                         --dataset_split_name=train \
                                                         --dataset_dir=${DATASET_DIR} \
                                                         --model_name=mobilenet_v2 \
                                                          --clone_cpu=True
",AkashB23,b'stat:awaiting response',2019-10-17T05:49:10Z,2019-12-10T13:11:57Z,,,,,,,
7657,"Traceback (most recent call last):   File ""generate_tfrecord.py"", line 129, in <module>     tf.app.run() AttributeError: module 'tensorflow' has no attribute 'app'","Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",hemanth358,b'stat:awaiting response type:support',2019-10-13T10:09:01Z,2020-07-17T10:14:01Z,,,,,,,
7643,[TF2]'Tensor' object has no attribute '_keras_history'   ,"### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:Linux Ubuntu 16.04)
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**:2.0-GPU
- **CUDA/cuDNN version**:9.6
- **GPU model and memory**:
- **Exact command to reproduce**:





### Problem
in TF2.0 use Keras to save model.h5 ,then load model.h5.

I have saved **model.h5** from **official.nlp.bert_models.py** by use model.save(""model.h5"") .
everything is ok , but when I load the **model.h5** there have some problems.
```python

model =tf.keras.models.load_model('./my_model1.h5', custom_objects={'BertModel':bert_modeling.BertModel})
```

emmmmm, how to solve this problem???? 


### Traceback 
Traceback (most recent call last):
  File ""/Users/lollipop/Documents/tf2g/false_news/test.py"", line 30, in <module>
    model =tf.keras.models.load_model('./my_model1.h5', custom_objects={'BertModel':bert_modeling.BertModel})
  File ""/Users/lollipop/.conda/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/save.py"", line 146, in load_model
    return hdf5_format.load_model_from_hdf5(filepath, custom_objects, compile)
  File ""/Users/lollipop/.conda/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py"", line 168, in load_model_from_hdf5
    custom_objects=custom_objects)
  File ""/Users/lollipop/.conda/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/model_config.py"", line 55, in model_from_config
    return deserialize(config, custom_objects=custom_objects)
  File ""/Users/lollipop/.conda/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/keras/layers/serialization.py"", line 102, in deserialize
    printable_module_name='layer')
  File ""/Users/lollipop/.conda/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/keras/utils/generic_utils.py"", line 191, in deserialize_keras_object
    list(custom_objects.items())))
  File ""/Users/lollipop/.conda/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py"", line 906, in from_config
    config, custom_objects)
  File ""/Users/lollipop/.conda/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py"", line 1852, in reconstruct_from_config
    process_node(layer, node_data)
  File ""/Users/lollipop/.conda/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py"", line 1802, in process_node
    output_index = nest.flatten(output_tensors)[0]._keras_history.node_index
AttributeError: 'Tensor' object has no attribute '_keras_history'

Process finished with exit code 1

",SmileTM,b'models:official type:bug',2019-10-10T10:25:42Z,2020-06-21T18:26:07Z,,,,,,,
7626,"TypeError: Expected binary or unicode string, got None","Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",hmaresearch2,None,2019-10-04T04:44:19Z,2019-10-04T04:45:45Z,,,,,,,
7625,[Deeplabv3] Loss increase after restoring from checkpoint.,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**: research/deeplab
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: 
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 18.04.2 LTS
- **TensorFlow installed from (source or binary)**:Binary
- **TensorFlow version (use command below)**:1.13.1
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:10.1
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

### Describe the problem
When I train a model on training dataset for let's say 100,000 iterations, the loss goes down nice from 3.5 to 0.2
However, when I try to run just the eval.py using the same checkpoint on the training dataset, the restored model state is no longer the same. Loss is usually high. I haven't made any changes with saving and restoring model code.
Any leads?

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",rajanieprabha,b'models:research',2019-10-03T16:16:30Z,2019-11-29T01:01:26Z,,,,,,,
7602,Port BERT Tutorial Notebook to TF2.0?,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------
### Describe the problem
The predicting movie reviews notebook in TF1.4 was useful for getting up and running with BERT:
https://github.com/google-research/bert/blob/master/predicting_movie_reviews_with_bert_on_tf_hub.ipynb

Would you be open to a pull request which rewrites this notebook in TF2.0? 

See also [matching issue on BERT](https://github.com/google-research/bert/issues/584#issue-434185367).

",bwindsor22,b'models:official type:feature',2019-09-24T16:58:30Z,2020-06-23T04:19:18Z,,,,,,,
7587,Fix bug in ptb_word_lm.py,"If ptb_word_lm.py is executed with --num_gpus=0, initial_state and final_state are not imported. As a result, feed_dict is always empty.",gyojir,b'cla: yes',2019-09-20T15:04:53Z,2020-04-24T07:08:15Z,,,,,,,
7570,owSSD MobilenetV1 on COCO - pre-trained protobuf and checkpoint mAP don't match ,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",zhangqianYY,None,2019-09-17T11:56:00Z,2019-09-17T11:57:24Z,,,,,,,
7562,"File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/tensor_shape.py"", line 615, in assert_has_rank     raise ValueError(""Shape %s must have rank %d"" % (self, rank)) ValueError: Shape (10, 10, 10, 256) must have rank 2","Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",sreenupadidapu,b'stat:awaiting response type:support',2019-09-16T07:15:31Z,2020-07-22T07:36:05Z,,,,,,,
7556,Undefined name: missing imports in ./official/nlp/xlnet,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**: ./official/nlp/xlnet
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Any
- **TensorFlow installed from (source or binary)**: pip install tensorflow
- **TensorFlow version (use command below)**: current master
- **Bazel version (if compiling from source)**: n/a
- **CUDA/cuDNN version**: n/a
- **GPU model and memory**: n/a
- **Exact command to reproduce**: flake8 . --select=E9,F63,F7,F82 --show-source

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.
Missing imports in ./official/nlp/xlnet have the possibility to raise NameError at runtime.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.

[flake8](http://flake8.pycqa.org) testing of https://github.com/tensorflow/models on Python 3.7.1

$ __flake8 . --count --select=E9,F63,F7,F82 --show-source --statistics__
```
./official/nlp/xlnet/run_squad.py:231:24: F821 undefined name 'tpu_lib'
    cluster_resolver = tpu_lib.tpu_initialize(FLAGS.tpu)
                       ^
./official/nlp/xlnet/run_classifier.py:139:24: F821 undefined name 'tpu_lib'
    cluster_resolver = tpu_lib.tpu_initialize(FLAGS.tpu)
                       ^
./official/nlp/xlnet/run_pretrain.py:70:24: F821 undefined name 'tpu_lib'
    cluster_resolver = tpu_lib.tpu_initialize(FLAGS.tpu)
                       ^
./official/nlp/xlnet/preprocess_pretrain_data.py:997:3: F821 undefined name 'absl_app'
  absl_app.run(create_data)
  ^
```",cclauss,None,2019-09-13T07:38:02Z,2019-09-13T20:36:58Z,,,,,,,
7483,tensorboard,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",NowJzy,None,2019-08-21T15:16:07Z,2019-09-10T16:27:00Z,,,,,,,
7470,Merged commit includes the following changes:,"263863588  by yongzhe:

    Fix a bug that the SetExternalContext for EdgeTPU wasn't called when initializing LSTD client.

--
263370193  by yongzhe:

    Internal change.

--

PiperOrigin-RevId: 263863588",yongzhe2160,b'cla: yes',2019-08-19T18:10:20Z,2019-08-19T21:55:39Z,,,,,,,
7435,Remove 8xGPU XLA tests.  They are not supported yet.,"Remove 8xGPU XLA tests.  They fail, are not supported, and the team is not planning to debug.  They can be added back later when supported.",tfboyd,b'cla: yes',2019-08-13T20:25:41Z,2019-08-13T20:28:24Z,,,,,,,
7429,    Add a public method to extract shareable layers with decoder.,"Merged commit includes the following changes:
262962783  by hongkuny<hongkuny@google.com>:

    Internal change

262460803  by hongkuny<hongkuny@google.com>:
    
    Add a public method to extract shareable layers with decoder.
    
--
262315011  by A. Unique TensorFlower<gardener@tensorflow.org>:
    
    Refactor tpu initialization logic to common module.
    
--
262299019  by akuegel<akuegel@google.com>:

    Internal change

262178259  by hongkuny<hongkuny@google.com>:
    
    We should call training=True in CTL train step.
    
--
262081759  by akuegel<akuegel@google.com>:

    Internal change

262021128  by isaprykin<isaprykin@google.com>:

    Internal change

262004398  by taylorrobie<taylorrobie@google.com>:

    Internal change

261786323  by yanhuasun<yanhuasun@google.com>:
    
    Replace set, dict with ObjectIdentityDict/Set to prepare for eq implementation
    
--
261393597  by hongkuny<hongkuny@google.com>:
    
    add an encoder mode for BertModel which returns all layers.
    
--
261218818  by A. Unique TensorFlower<gardener@tensorflow.org>:

    Internal change

261202754  by hongkuny<hongkuny@google.com>:
    
    Use enable_xla flag for classifier and squad, so xla option is exposed to users.
    
--
261171038  by gjn<gjn@google.com>:
    
    Remove weight_decay_rate 0 early exit check
    
    Removing this code path should be fine since this was actually not doing
    what it meant to do. Since weight_decay_rate is actually a tensor, the
    equality check was only looking at the id of the object and comparing to
    0. This should never be true. Evaluating a tensor is also not what we
    want to do at this point of the code. Thus it should be fine to simply
    remove this code.
    
--
261169862  by haoyuzhang<haoyuzhang@google.com>:

    Internal change

261153520  by haoyuzhang<haoyuzhang@google.com>:

    Internal change

261140302  by hongkuny<hongkuny@google.com>:
    
    Clean up
    
--
260862396  by A. Unique TensorFlower<gardener@tensorflow.org>:
    
    Fix BERT pretraining input pipeline to shuffle and shard dataset properly for multi-worker training.
    
--
260601376  by hongkuny<hongkuny@google.com>:
    
    reorder Q,K to make TPU faster.
    
--
260580119  by hongkuny<hongkuny@google.com>:
    
    Adds expect_partial()
    
--
260228553  by priyag<priyag@google.com>:
    
    Enable transformer and NCF official model tests. Also fix some minor issues so that all tests pass with TF 1 + enable_v2_behavior. 
    
--
260060237  by zongweiz<zongweiz@google.com>:
    
    [BERT SQuAD] Enable mixed precision training
    
    Add mixed precision training support for BERT SQuAD model. Using the experimental Keras mixed precision API. For numeric stability, use fp32 for layer normalization, dense layers with GELU activation, etc.
    
--
260052674  by hongkuny<hongkuny@google.com>:
    
    Add expect_partial()
    
--
259889221  by hongkuny<hongkuny@google.com>:
    
    Add no ds / xla / eager perfzero tests
    
--
259790197  by hongkuny<hongkuny@google.com>:
    
    Update pretraining model to match tf1 var names.
    
--
259656389  by hongkuny<hongkuny@google.com>:

    Internal change

259649972  by hongkuny<hongkuny@google.com>:
    
    Update docs.
    
--
259470074  by hongkuny<hongkuny@google.com>:
    
    Adds a dedup phase for trainable variables.
    
--
259442882  by hongkuny<hongkuny@google.com>:
    
    Internal
    
--
259341546  by mrry<mrry@google.com>:
    
    Remove DEBUG-level logging from the BERT benchmark.
    
    This triggers graph serialization and other verbose logging in the TensorFlow runtime, which inflates the execution time.
    
--
259253185  by hongkuny<hongkuny@google.com>:
    
    Writes a separated checkpoint for the core model in pretraining.
    Clean up export utils to just take a model as argument.
    
--
258893811  by hongkuny<hongkuny@google.com>:
    
    Adds summaries for metrics, allowing metrics inside keras.model.
    
--
258881002  by hongkuny<hongkuny@google.com>:
    
    Fix lint.
    
--
258871624  by hongkuny<hongkuny@google.com>:

    Internal change

258597234  by rxsang<rxsang@google.com>:
    
    Update all the TPUStrategy examples to use the new v2 APIs, i.e.
    make_dataset_iterator -> experimental_distribute_dataset,
    make_input_fn_iterator -> experimental_distribute_datasets_from_function,
    unwrap -> experimental_local_results,
    experimental_run -> experimental_run_v2
    
--
258581998  by taylorrobie<taylorrobie@google.com>:
    
    
    Update keras v2 optimizers to reuse coefficients which are shared across all updates, which reduces the total number of ops created by between 5% (for simple optimizers such as SGD and Adagrad) and 25% (for complicated optimizers such as Adam and NAdam). Separate copies are made for each device and dtype.
    
    The effect of this change on run time is fairly minimal since Grappler is expected to consolidate most of these ops; however it does improve graph construction time.
    
    
--
258208153  by hongkuny<hongkuny@google.com>:
    
    Adds run_eagerly option for bert.
    
--
257883986  by hongkuny<hongkuny@google.com>:
    
    Adds tf.summary for bert training
    
--
257285772  by haoyuzhang<haoyuzhang@google.com>:

    Internal change

256242827  by yuefengz<yuefengz@google.com>:

    Internal change

256204636  by hongkuny<hongkuny@google.com>:
    
    Internal
    
--
256079834  by hongkuny<hongkuny@google.com>:
    
    Clean up: move common flags together for further refactoring
    Enable steps_per_loop option for all applications.
    
--
255493073  by hongkuny<hongkuny@google.com>:
    
    BERT initial OSS readme update.
    
--
255470372  by dmchen<dmchen@google.com>:
    
    Slightly expand expected range for F1 score in BERT SQuAD accuracy test
    
--
255109240  by hongkuny<hongkuny@google.com>:
    
    Update eval/predict batch sizes.
    
--
255010016  by hongkuny<hongkuny@google.com>:
    
    Internal
    
--
254874613  by hongkuny<hongkuny@google.com>:
    
    Update glue tasks enum to match directory name
    
--
254866171  by taylorrobie<taylorrobie@google.com>:

    Internal change

254785517  by zongweiz<zongweiz@google.com>:
    
    Use train_single_step for BERT GPU models to temporarily work around some performance bugs in GPU runs
    
--
254497647  by hongkuny<hongkuny@google.com>:
    
    Fix device placement for TPU export model.
    
--
254293763  by haoyuzhang<haoyuzhang@google.com>:

    Internal change

254134531  by yuefengz<yuefengz@google.com>:
    
    Fix a typo in bert_benchmark.py
    
--
254069984  by hongkuny<hongkuny@google.com>:
    Automated rollback of changelist 254060732.

254061429  by hongkuny<hongkuny@google.com>:
    
    Use host while loop for training steps.
    
--
254060732  by yifeif<yifeif@google.com>:
    Automated rollback of changelist 254027750.

254027750  by hongkuny<hongkuny@google.com>:

    Internal change

253850824  by hongkuny<hongkuny@google.com>:
    
    Improve bert training utils.
    
--
253818191  by hongkuny<hongkuny@google.com>:
    
    Update savedmodel export to use new model.save() api.
    
--
253636854  by dmchen<dmchen@google.com>:
    
    Run only training in BERT SQuAD performance test
    
--
253118910  by hongkuny<hongkuny@google.com>:

    Internal change

253113801  by zongweiz<zongweiz@google.com>:

    Internal change

252697519  by dmchen<dmchen@google.com>:
    
    BERT SQuAD accuracy test
    
--
252663512  by A. Unique TensorFlower<gardener@tensorflow.org>:
    
    Internal change
    
--
252647871  by A. Unique TensorFlower<gardener@tensorflow.org>:
    
    Enable multi worker TPU training for BERT pretraining.
    
--
252550871  by hongkuny<hongkuny@google.com>:

    Internal change

252522861  by hongkuny<hongkuny@google.com>:
    
    Remove export using trained model due to implementation error
    
--
252156812  by yuefengz<yuefengz@google.com>:
    
    Fix the callback method name in BERT: replaced on_batch_start with on_batch_begin. Without the fix, it won't work with Keras callbacks.
    
--
251782065  by dmchen<dmchen@google.com>:

    Internal change

251681245  by hongkuny<hongkuny@google.com>:
    
    Update bert to use the new tf.distribute APIs 
    
--
251575972  by A. Unique TensorFlower<gardener@tensorflow.org>:
    
    Remove `steps_per_run` when instantiating TPUStrategy.
    
--
251325964  by hongkuny<hongkuny@google.com>:
    
    Improve flags
    
--
251303452  by haoyuzhang<haoyuzhang@google.com>:

    Internal change

250942274  by tobyboyd<tobyboyd@google.com>:

    Internal change

250779087  by A. Unique TensorFlower<gardener@tensorflow.org>:
    
    Reduce BERT Perfzero benchmark test training steps.
    
--
250713045  by hongkuny<hongkuny@google.com>:
    
    TPU util
    
--
250606180  by A. Unique TensorFlower<gardener@tensorflow.org>:
    
    Fix BERT benchamrk test errors.
    
--
250589623  by A. Unique TensorFlower<gardener@tensorflow.org>:
    
    Change BERT benchmark test pretrained checkpoint url.
    
--
250587892  by A. Unique TensorFlower<gardener@tensorflow.org>:
    
    Fix error in BERT custom training loop checkpoint restoration.
    
--
250577163  by A. Unique TensorFlower<gardener@tensorflow.org>:
    
    Add logic to inject callback that measures performance in BERT custom training
    loop.
    
--
250529526  by hongkuny<hongkuny@google.com>:
    
    Internal clean up
    
--
250428976  by hongkuny<hongkuny@google.com>:

    Internal change

250415383  by A. Unique TensorFlower<gardener@tensorflow.org>:
    
    Add min/max value to BERT classifier benchmark test.
    
--
250376246  by A. Unique TensorFlower<gardener@tensorflow.org>:
    
    Add benchmark performance test to run BERT on multiple numbers of GPUs. 
    
--
250347237  by A. Unique TensorFlower<gardener@tensorflow.org>:
    
    Fix linting errors in BERT benchmark test.
    
--
250326131  by A. Unique TensorFlower<gardener@tensorflow.org>:

    Internal change

250315593  by A. Unique TensorFlower<gardener@tensorflow.org>:

    Internal change

250303528  by haoyuzhang<haoyuzhang@google.com>:
    
    Add method docstring to fix lint error.
    
--
250009207  by A. Unique TensorFlower<gardener@tensorflow.org>:
    
    Add feature in BERT to write training metrics to a summary file.
    
--
249896208  by hongkuny<hongkuny@google.com>:
    
    Adds __init__.py
    
--
249883771  by hongkuny<hongkuny@google.com>:
    
    Creates a benchmark dir
    
--
249580533  by A. Unique TensorFlower<gardener@tensorflow.org>:

    Internal change

249566870  by A. Unique TensorFlower<gardener@tensorflow.org>:
    
    Set up BERT benchmark test.
    
--
249500988  by hongkuny<hongkuny@google.com>:
    
    Lints
    
--
249377254  by hongkuny<hongkuny@google.com>:

    Internal change

249373328  by hongkuny<hongkuny@google.com>:
    
    Clean up tf import
    
--
249333938  by hongkuny<hongkuny@google.com>:
    
    Fix tf1 import
    
--
249325089  by hongkuny<hongkuny@google.com>:
    
    BERT 2.0
    
--
249195008  by tianlin<tianlin@google.com>:

    Internal change

249173564  by hongkuny<hongkuny@google.com>:

    Internal change

246677582  by haoyuzhang<haoyuzhang@google.com>:

    Internal change

245821839  by shiningsun<shiningsun@google.com>:

    Internal change

245353681  by gjn<gjn@google.com>:

    Internal change

245340898  by haoyuzhang<haoyuzhang@google.com>:

    Internal change

245155641  by haoyuzhang<haoyuzhang@google.com>:

    Internal change

244019160  by haoyuzhang<haoyuzhang@google.com>:

    Internal change

242930998  by shiningsun<shiningsun@google.com>:

    Internal change

242049350  by haoyuzhang<haoyuzhang@google.com>:

    Internal change

241663771  by haoyuzhang<haoyuzhang@google.com>:

    Internal change

241054800  by haoyuzhang<haoyuzhang@google.com>:

    Internal change

241028555  by yuefengz<yuefengz@google.com>:

    Internal change

239316550  by haoyuzhang<haoyuzhang@google.com>:

    Internal change

238251867  by haoyuzhang<haoyuzhang@google.com>:

    Internal change

237876559  by taylorrobie<taylorrobie@google.com>:

    Internal change

236346619  by haoyuzhang<haoyuzhang@google.com>:

    Internal change

236182665  by tayo<tayo@google.com>:

    Internal change

234652747  by wangtz<wangtz@google.com>:

    Internal change

233837502  by shiningsun<shiningsun@google.com>:

    Internal change

232033015  by shiningsun<shiningsun@google.com>:

    Internal change

228564809  by taylorrobie<taylorrobie@google.com>:

    Internal change

227052580  by shiningsun<shiningsun@google.com>:

    Internal change

225436264  by shiningsun<shiningsun@google.com>:

    Internal change

222283824  by taylorrobie<taylorrobie@google.com>:

    Internal change

219241224  by taylorrobie<taylorrobie@google.com>:

    Internal change

218774474  by A. Unique TensorFlower<gardener@tensorflow.org>:

    Internal change

218610966  by taylorrobie<taylorrobie@google.com>:

    Internal change

218576353  by taylorrobie<taylorrobie@google.com>:

    Internal change

217776707  by A. Unique TensorFlower<gardener@tensorflow.org>:

    Internal change

217749789  by A. Unique TensorFlower<gardener@tensorflow.org>:

    Internal change

214516790  by A. Unique TensorFlower<gardener@tensorflow.org>:

    Internal change

212339556  by A. Unique TensorFlower<gardener@tensorflow.org>:

    Internal change

210658133  by A. Unique TensorFlower<gardener@tensorflow.org>:

    Internal change

206866123  by taylorrobie<taylorrobie@google.com>:

    Internal change

205252141  by A. Unique TensorFlower<gardener@tensorflow.org>:

    Internal change

202519641  by scottzhu<scottzhu@google.com>:

    Internal change

201299684  by kathywu<kathywu@google.com>:

    Internal change

199655516  by karmel<karmel@google.com>:

    Internal change

199209802  by karmel<karmel@google.com>:

    Internal change

198089630  by karmel<karmel@google.com>:

    Internal change

198060863  by karmel<karmel@google.com>:
    Automated rollback of changelist 197920496.

197920496  by kathywu<kathywu@google.com>:

    Internal change

197841416  by A. Unique TensorFlower<gardener@tensorflow.org>:

    Internal change

195867348  by A. Unique TensorFlower<gardener@tensorflow.org>:

    Internal change

195725348  by taylorrobie<taylorrobie@google.com>:

    Internal change

195283704  by A. Unique TensorFlower<gardener@tensorflow.org>:

    Internal change

194662698  by A. Unique TensorFlower<gardener@tensorflow.org>:

    Internal change

194103064  by A. Unique TensorFlower<gardener@tensorflow.org>:

    Internal change

193581866  by A. Unique TensorFlower<gardener@tensorflow.org>:

    Internal change

192783651  by scottzhu<scottzhu@google.com>:
    Automated rollback of changelist 192714881.

192714881  by scottzhu<scottzhu@google.com>:
    Automated rollback of changelist 192710755.

192710755  by A. Unique TensorFlower<gardener@tensorflow.org>:

    Internal change

192374551  by A. Unique TensorFlower<gardener@tensorflow.org>:

    Internal change

192346754  by A. Unique TensorFlower<gardener@tensorflow.org>:

    Internal change

192298443  by karmel<karmel@google.com>:

    Internal change

192220576  by A. Unique TensorFlower<gardener@tensorflow.org>:

    Internal change

191514106  by scottzhu<scottzhu@google.com>:

    Internal change

191327699  by A. Unique TensorFlower<gardener@tensorflow.org>:

    Internal change

190938103  by karmel<karmel@google.com>:

    Internal change

190804388  by A. Unique TensorFlower<gardener@tensorflow.org>:

    Internal change

190479716  by karmel<karmel@google.com>:

    Internal change

189844661  by scottzhu<scottzhu@google.com>:
    Automated rollback of changelist 189816818.

189816818  by A. Unique TensorFlower<gardener@tensorflow.org>:

    Internal change

189639056  by A. Unique TensorFlower<gardener@tensorflow.org>:

    Internal change

189628781  by karmel<karmel@google.com>:

    Internal change

189267175  by karmel<karmel@google.com>:

    Internal change

189096159  by karmel<karmel@google.com>:

    Internal change

189085341  by karmel<karmel@google.com>:

    Internal change

188949700  by karmel<karmel@google.com>:",saberkun,b'cla: yes',2019-08-12T18:19:25Z,2019-08-12T18:24:39Z,,,,,,,
7422,"    from tensorflow.python.pywrap_tensorflow_internal import *   File ""C:\Users\AlDorado Pc2\Anaconda3\envs\car-behavioral-cloning\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 21, in <module>     _pywrap_tensorflow_internal = swig_import_helper()   File ""C:\Users\AlDorado Pc2\Anaconda3\envs\car-behavioral-cloning\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 20, in swig_import_helper     return importlib.import_module('_pywrap_tensorflow_internal')   File ""C:\Users\AlDorado Pc2\Anaconda3\envs\car-behavioral-cloning\lib\importlib\__init__.py"", line 126, in import_module     return _bootstrap._gcd_import(name[level:], package, level) ImportError: No module named '_pywrap_tensorflow_internal'   Failed to load the native TensorFlow runtime.","Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",AladdinDorado,b'stat:awaiting response type:support',2019-08-09T09:36:38Z,2020-07-22T07:59:32Z,,,,,,,
7421,hi....i need to automate image labelling in labelme,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",shivangi97dubey,b'stat:awaiting response type:support',2019-08-09T09:22:35Z,2020-07-22T08:01:08Z,,,,,,,
7417,Freezing the Pre-Trained DELF model leading to issues. ,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

### Describe the problem
@andrefaraujo I am trying to freeze the below model and use it for Delf extraction.  

I downloaded the model from here -- 
`http://storage.googleapis.com/delf/delf_gld_20190411.tar.gz`

and wrote the below code to freeze the model. However, when freezing it complains that the node `extractor_delf/boxes is not in graph`. That's incorrect because after loading the graph, I printed the names of all nodes and `extractor_delf/boxes` was part of it.

I checked the [freeze_graph.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/tools/freeze_graph.py) but the same requires a checkpoint file which is not what we get from the above tar. 

### Source code / logs

`input_node_names = ['extractor_delf/input_image', 'extractor_delf/input_abs_thres', 
                    'extractor_delf/input_scales', 'extractor_delf/input_max_feature_num']
output_node_names = ['extractor_delf/boxes', 'extractor_delf/features', 
                     'extractor_delf/scales', 'extractor_delf/scores']

import tensorflow as tf
from tensorflow.python.tools import optimize_for_inference_lib
def freeze_graph(output_node_names, model_dir = './delf/delf_gld_20190411/model'):
    
    with tf.Session() as sess:
        sess.run(tf.global_variables_initializer())
        
        # We import the meta graph in the current default Graph
        tf.saved_model.loader.load(
        sess, [tf.saved_model.tag_constants.SERVING],
        './delf/delf_gld_20190411/model',
        import_scope='extractor_delf')

        # We use a built-in TF helper to export variables to constants
        input_graph_def = tf.graph_util.convert_variables_to_constants(
            sess, 
            sess.graph.as_graph_def(), 
            output_node_names
        )

        # We generate the inference graph_def
        output_graph_def = optimize_for_inference_lib.optimize_for_inference(
                                                 tf.graph_util.remove_training_nodes(input_graph_def),
                                                 input_node_names, 
                                                 output_node_names,
                                                 tf.float32.as_datatype_enum)

    print(output_graph_def)
    # Finally we serialize and dump the output graph_def to the filesystem
    with tf.gfile.GFile('frozen.pb', ""wb"") as f:
            f.write(output_graph_def.SerializeToString())
freeze_graph(output_node_names)`



",rapidcoder7,b'models:research',2019-08-09T02:42:02Z,2020-05-04T21:51:37Z,,,,,,,
7409,"when I run lstm_object_detection code, it appeared ValueError: Unknown ssd feature_extractor: lstm_mobilenet_v1","Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",gtfaiwxm,b'models:research stat:awaiting response type:support',2019-08-08T02:17:35Z,2020-07-22T08:02:25Z,,,,,,,
7406,Change PCA dimensions being spit out by DELF TF-Hub module. ,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: MacOS
- **TensorFlow installed from (source or binary)**: Binary
- **TensorFlow version (use command below)**: 1.14.0
- **Bazel version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**: N/A

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

### Describe the problem
@andrefaraujo 

I am trying to re-use the code for DTR using python. I have used the model-ssd model for extracting regions from a given image. After this, I crop the image into various regions and for each region I use the DELF TF-Hub module for extracting features. 

The TF-HUB module spits out a descriptor of 40 dimensions. Is there a way to make it spit out 128 dimension descriptor? I want to do this because the codebooks have been developed to expect 128 dimension vectors.  

I am aware I can use the DELF extracting code available in the repo; but using the code is slower than using the module. Thus, I chose the above route. 


### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.",rapidcoder7,None,2019-08-07T21:23:44Z,2019-08-08T18:45:45Z,,,,,,,
7395,Separable convolution is slow to train,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>
**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 1.13
- Python version: 3.6
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 10.0
- GPU model and memory: Tesla V100-SXM2 16GB

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**

In our experiments, we replaced standard convolutions (tf.contrib.layers.conv2d) with the separable convolutions (tf.nn.separable_conv2d), and it turned out although with less FLOPs the model with separable convolutions ( .06M images/hour) is worse than twice as slow to train as with the standard ones ( .15M images/hour). Notice that except the type of convolutions, we didn't modify any other stuffs like the size of input and the output. So the only cause should come from the API of the separable convolution.

You may also argue that it is because of the increased memory access from the intermediate tensors of separable convolutions. Thus we also tried the same replacement using Pytorch (same CUDA version as TensorFlow) on the same machine, it turned out that the two models have a close speed on Pytorch, which helps us rule out that possibility.

**Describe the expected behavior**

The separable convolution (tf.nn.separable_conv2d) has the same or close speed with the standard convolution (tf.contrib.layers.conv2d).

**Code to reproduce the issue**
https://github.com/lauriebyrum/slowtraining/blob/master/src/example.py

**Other info / logs**
Output from model that is fast to train: https://github.com/lauriebyrum/slowtraining/blob/master/fast.txt
Output from model that is slow to train: https://github.com/lauriebyrum/slowtraining/blob/master/slow.txt
",lauriebyrum,None,2019-08-07T00:22:34Z,2020-04-01T03:22:19Z,,,,,,,
7388,Object detection API not detecting objects in images of different size than training set,"### System information
- **What is the top-level directory of the model you are using**: N/A
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes. The exact details are explained below.
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: OSX 10.14.5
- **TensorFlow installed from (source or binary)**: Binary
- **TensorFlow version (use command below)**: 1.13.1
- **Bazel version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**: See below


### Describe the problem
I have trained my model on several [test images](https://github.com/marcoistasy/imagineOCR/tree/develop/imagineOCR/example_data/images) and have trained a `rfcn_resnet101_coco` model to detect the letter *o* in these images.

I thought the model was working fine as it was detecting *o* (with decent accuracy) in the images I was passing to it. Please see [here](https://github.com/marcoistasy/imagineOCR/blob/develop/imagineOCR/example_data/test/results/image2_result.png) and [here](https://github.com/marcoistasy/imagineOCR/blob/develop/imagineOCR/example_data/test/results/image3_result.png) for examples.

However, when I passed in two more images whose size varied greatly from the first two, the model was unable to detect anything! For example, when I passed in a [full page](https://github.com/marcoistasy/imagineOCR/blob/develop/imagineOCR/example_data/test/results/image1_result.png) or a [single world](https://github.com/marcoistasy/imagineOCR/blob/develop/imagineOCR/example_data/test/results/image4_result.png) to the model, the output was the same as the input.

I believe this is because the last two images I passed in where much larger or smaller than the [original training set](https://github.com/marcoistasy/imagineOCR/tree/develop/imagineOCR/example_data/images) that I used to train the model, whereas the first two or roughly the same size. 

I am wondering if there is anyway to train my model such that it can detect the letter *o* in images of varying sizes and not just those similar to the training input. I thought of tweaking my `pipeline.config` (found [here](https://github.com/marcoistasy/imagineOCR/blob/develop/imagineOCR/example_data/model/pipeline.config)) but am not sure where to start. Alternatively, this might be a bug in the `object_detection` source code. 

### Source code / logs
Here is a link to the Github repo where the [source code](https://github.com/marcoistasy/imagineOCR/tree/develop/imagineOCR/example_data) is held.
",marcoistasy,b'models:research type:support',2019-08-06T13:15:40Z,2020-06-30T22:13:57Z,,,,,,,
7386,"Scope naming in keras models: additional ""_1"" suffix fails exporting graph","###System information:###
**What is the top-level directory of the model you are using:** N/A
**Have I written custom code (as opposed to using a stock example script provided in TensorFlow):** Yes.
**OS Platform and Distribution (e.g., Linux Ubuntu 16.04):** Linux Ubuntu 18.04
**TensorFlow installed from (source or binary):** binary (via pip)
**TensorFlow version (use command below):** tensorflow-gpu==1.13.1
**Bazel version (if compiling from source):** N/A
**CUDA/cuDNN version:** 10.0.130
**GPU model and memory:** GeForce GTX 1080 8116MiB
**Exact command to reproduce:** N/A

Dear all. I try to implement (or even simpler, just run native) keras ssd feature extractor.
The problem is, that in the constructor of SSDMetaArch class there are following piece of code:
```
# Needed for fine-tuning from classification checkpoints whose
# variables do not have the feature extractor scope.
if self._feature_extractor.is_keras_model:
    # Keras feature extractors will have a name they implicitly use to scope.
    # So, all contained variables are prefixed by this name.
    # To load from classification checkpoints, need to filter out this name.
    self._extract_features_scope = feature_extractor.name
else:
    # Slim feature extractors get an explicit naming scope
    self._extract_features_scope = 'FeatureExtractor'
```

For some reason (I don't know is it a bug o feature) the feature extractor instance creates twice in training cycle. Since that, the _extract_features_scope of second instance (which is trained) contains suffix ""_1"". As well as corresponding operation names in checkpoint. But when I try to export frozen graph, I obtain obvious error: ""Key ..._feature_extractor/... not found in checkpoint"". Of course not found, because in checkpoint it is called ""..._feature_extractor **_1** /..."".

Please, provide an explanation how to fix that. I guess, that KerasFeatureExtractor should be instantiated only once.",pryadchenko,b'stat:awaiting response type:support',2019-08-06T08:05:32Z,2020-06-25T09:45:11Z,,,,,,,
7364,[Deeplabv3+] Bug with output image in segementation folder for 16bit png,"
### System information
- **What is the top-level directory of the model you are using**:Deeplab
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:  Just a bit to print out info so I can see how the data format is,
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04
- **TensorFlow installed from (source or binary)**:source
- **TensorFlow version (use command below)**:1.13.1
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:10.1 CUDA
- **GPU model and memory**:12GB
- **Exact command to reproduce**:
``
#!/bin/bash
python3 vis.py --also_save_raw_predictions=""True""  --vis_split=""train"" --model_variant=""xception_65"" --atrous_rates=6 --atrous_rates=12 --atrous_rates=18 --output_stride=16 --decoder_output_stride=4 --vis_crop_size=320,320 --dataset=""hedges"" --colormap_type=""pascal"" --checkpoint_dir=""/Data/logs"" --vis_logdir ""Data/"" --dataset_dir=""Data/output_data""
``

### Describe the problem


I have converted my PNG image files into TFRecords using the build_voc20120_data.py. When I use the vis.py script (calling with the above .sh file) I recieve images which have lost all pixel value information. 
The images I am using to train are remote sensing images with pixel values that should be ranging up to around 100 - 800, but when I print out the values of the 'label' in the save_annotations function 

```
def save_annotation(label,
                    save_dir,
                    filename,
                    add_colormap=True,
                    normalize_to_unit_values=False,
                    scale_values=False,
                    orig = False,
                    colormap_type=get_dataset_colormap.get_pascal_name()):
  """"""Saves the given label to image on disk.

  Args:
    label: The numpy array to be saved. The data will be converted
      to uint8 and saved as png image.
    save_dir: String, the directory to which the results will be saved.
    filename: String, the image filename.
    add_colormap: Boolean, add color map to the label or not.
    normalize_to_unit_values: Boolean, normalize the input values to [0, 1].
    scale_values: Boolean, scale the input values to [0, 255] for visualization.
    colormap_type: String, colormap type for visualization.
  """"""

    print(label[:20])
    if add_colormap:
        colored_label = get_dataset_colormap.label_to_color_image(
            label, colormap_type)
```

The results are values ranging from 0-3. Since save_annotations gets the 'label' variable from the samples generated by data_generator.Dataset I am worried that the data which the network is training on is also in this same format where all spectral information has been lost. 

So is something going wrong with my images being read as TFRecords? 

Here is an example of the image (named 00000_image. It is NOT the 00000_prediction image) which I get as output from the vis.py

![image](https://user-images.githubusercontent.com/52926709/62377204-a4de1e80-b542-11e9-8fa5-a914634e223d.png)


But my original data looks as such 

![image](https://user-images.githubusercontent.com/52926709/62377245-b45d6780-b542-11e9-927f-1cbe2821e0e1.png)



### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",SevenFoldDeep,None,2019-08-02T14:31:12Z,2019-08-06T08:15:14Z,,,,,,,
7360,Accuracy super low while using Coco2014 Minival set ,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**: Mobilenet SSD
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 14.04
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.11
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

I am getting good accuracy while using 40K COCO2014 dataset. By the score is score low(3.1) when I am using Minival set. I think it could be due to the instance_val2014.json(annotation file) I am using which contains all 40k results. Could that be a reason for such low accuracy? 

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",dibya001,None,2019-08-02T04:36:59Z,2019-08-13T08:53:57Z,,,,,,,
7352,Failed to find dynamic library: libwarpctc.so ( dlopen: cannot load any more object with static TLS ),"My local environment:
CentOS: release 6.9
NCCL: v2.4.7
cuda: 9.0.176
cudnn: 7.3.1
Paddle: 1.5.1
Python: 3.7.3
___________________________________________________________________
When i start training ocr_recognition model with crnn_ctc model, paddle occured error as follow:

(paddle) [ocr_recognition]# env CUDA_VISIBLE_DEVICES=0 python train.py --train_images dataset/public_data_english/train_images --train_list dataset/public_data_english/train.list --test_images dataset/public_data_english/test_images --test_list dataset/public_data_english/test.list
-----------  Configuration Arguments -----------
average_window: 0.15
batch_size: 32
eval_period: 15000
init_model: None
log_period: 1000
max_average_window: 12500
min_average_window: 10000
model: crnn_ctc
parallel: False
profile: False
save_model_dir: ./models
save_model_period: 15000
skip_batch_num: 0
skip_test: False
test_images: dataset/public_data_english/test_images
test_list: dataset/public_data_english/test.list
total_step: 720000
train_images: dataset/public_data_english/train_images
train_list: dataset/public_data_english/train.list
use_gpu: True
------------------------------------------------
/home/work/software/anaconda2/envs/paddle/lib/python3.7/site-packages/paddle/fluid/evaluator.py:71: Warning: The EditDistance is deprecated, because maintain a modified program inside evaluator cause bug easily, please use fluid.metrics.EditDistance instead.
  % (self.__class__.__name__, self.__class__.__name__), Warning)
finish batch shuffle
W0801 21:22:58.187352 37850 device_context.cc:259] Please NOTE: device: 0, CUDA Capability: 61, Driver API Version: 9.2, Runtime API Version: 9.0
W0801 21:22:58.192481 37850 device_context.cc:267] device: 0, cuDNN Version: 7.3.
W0801 21:22:59.779482 37850 dynamic_loader.cc:140] Failed to find dynamic library: /paddle/build/third_party/install/warpctc/lib/libwarpctc.so (dlopen: cannot load any more object with static TLS)
W0801 21:22:59.779705 37850 dynamic_loader.cc:109] Can not find library: libwarpctc.so. The process maybe hang. Please try to add the lib path to LD_LIBRARY_PATH.
Traceback (most recent call last):
  File ""train.py"", line 222, in <module>
    main()
  File ""train.py"", line 218, in main
    train(args)
  File ""train.py"", line 151, in train
    results = train_one_batch(data)
  File ""train.py"", line 112, in train_one_batch
    fetch_list=fetch_vars)
  File ""/home/work/software/anaconda2/envs/paddle/lib/python3.7/site-packages/paddle/fluid/executor.py"", line 651, in run
    use_program_cache=use_program_cache)
  File ""/home/work/software/anaconda2/envs/paddle/lib/python3.7/site-packages/paddle/fluid/executor.py"", line 749, in _run
    exe.run(program.desc, scope, 0, True, True, fetch_var_name)
paddle.fluid.core_avx.EnforceNotMet: Invoke operator warpctc error.
Python Callstacks:
  File ""/home/work/software/anaconda2/envs/paddle/lib/python3.7/site-packages/paddle/fluid/framework.py"", line 1771, in append_op
    attrs=kwargs.get(""attrs"", None))
  File ""/home/work/software/anaconda2/envs/paddle/lib/python3.7/site-packages/paddle/fluid/layer_helper.py"", line 43, in append_op
    return self.main_program.current_block().append_op(*args, **kwargs)
  File ""/home/work/software/anaconda2/envs/paddle/lib/python3.7/site-packages/paddle/fluid/layers/nn.py"", line 5573, in warpctc
    'use_cudnn': use_cudnn
  File ""/home/zhaoyanmei/models/PaddleCV/ocr_recognition/crnn_ctc_model.py"", line 189, in ctc_train_net
    input=fc_out, label=label, blank=num_classes, norm_by_times=True)
  File ""train.py"", line 61, in train
    args, data_shape, num_classes)
  File ""train.py"", line 218, in main
    train(args)
  File ""train.py"", line 222, in <module>
    main()
C++ Callstacks:
Failed to find dynamic library: libwarpctc.so ( dlopen: cannot load any more object with static TLS )
 Please specify its path correctly using following ways:
 Method. set environment variable LD_LIBRARY_PATH on Linux or DYLD_LIBRARY_PATH on Mac OS.
 For instance, issue command: export LD_LIBRARY_PATH=...
 Note: After Mac OS 10.11, using the DYLD_LIBRARY_PATH is impossible unless System Integrity Protection (SIP) is disabled. at [/paddle/paddle/fluid/platform/dynload/dynamic_loader.cc:166]
PaddlePaddle Call Stacks:
0       0x7fe93ff05830p void paddle::platform::EnforceNotMet::Init<char const*>(char const*, char const*, int) + 352
1       0x7fe93ff05ba9p paddle::platform::EnforceNotMet::EnforceNotMet(std::__exception_ptr::exception_ptr, char const*, int) + 137
2       0x7fe941f09f9bp paddle::platform::dynload::GetWarpCTCDsoHandle() + 1835
3       0x7fe940177be9p void std::__once_call_impl<std::_Bind_simple<paddle::platform::dynload::DynLoad__get_warpctc_version::operator()<>()::{lambda()#1} ()> >() + 9
4       0x7fe9b196fbe0p pthread_once + 80
5       0x7fe9401809b8p paddle::operators::WarpCTCFunctor<paddle::platform::CUDADeviceContext>::operator()(paddle::framework::ExecutionContext const&, float const*, float*, int const*, int const*, int const*, unsigned long, unsigned long, unsigned long, float*) + 136
6       0x7fe940183206p paddle::operators::WarpCTCKernel<paddle::platform::CUDADeviceContext, float>::Compute(paddle::framework::ExecutionContext const&) const + 2390
7       0x7fe940184ab3p std::_Function_handler<void (paddle::framework::ExecutionContext const&), paddle::framework::OpKernelRegistrarFunctor<paddle::platform::CUDAPlace, false, 0ul, paddle::operators::WarpCTCKernel<paddle::platform::CUDADeviceContext, float> >::operator()(char const*, char const*, int) const::{lambda(paddle::framework::ExecutionContext const&)#1}>::_M_invoke(std::_Any_data const&, paddle::framework::ExecutionContext const&) + 35
8       0x7fe941e6bf07p paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&, paddle::framework::RuntimeContext*) const + 375
9       0x7fe941e6c2e1p paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&) const + 529
10      0x7fe941e698dcp paddle::framework::OperatorBase::Run(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&) + 332
11      0x7fe94009061ep paddle::framework::Executor::RunPreparedContext(paddle::framework::ExecutorPrepareContext*, paddle::framework::Scope*, bool, bool, bool) + 382
12      0x7fe9400936bfp paddle::framework::Executor::Run(paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool, std::vector<std::string, std::allocator<std::string> > const&, bool) + 143
13      0x7fe93fef6ebdp
14      0x7fe93ff38166p
15      0x7fe9b1f1b6e4p _PyMethodDef_RawFastCallKeywords + 612
16      0x7fe9b1f1b801p _PyCFunction_FastCallKeywords + 33
17      0x7fe9b1f777aep _PyEval_EvalFrameDefault + 21374
18      0x7fe9b1eb84f9p _PyEval_EvalCodeWithName + 761
19      0x7fe9b1f1aa27p _PyFunction_FastCallKeywords + 903
20      0x7fe9b1f738fep _PyEval_EvalFrameDefault + 5326
21      0x7fe9b1eb84f9p _PyEval_EvalCodeWithName + 761
22      0x7fe9b1f1aa27p _PyFunction_FastCallKeywords + 903
23      0x7fe9b1f738fep _PyEval_EvalFrameDefault + 5326
24      0x7fe9b1eb8db9p _PyEval_EvalCodeWithName + 3001
25      0x7fe9b1f1aa27p _PyFunction_FastCallKeywords + 903
26      0x7fe9b1f72846p _PyEval_EvalFrameDefault + 1046
27      0x7fe9b1eb8db9p _PyEval_EvalCodeWithName + 3001
28      0x7fe9b1f1aa27p _PyFunction_FastCallKeywords + 903
29      0x7fe9b1f72846p _PyEval_EvalFrameDefault + 1046
30      0x7fe9b1f1a79bp _PyFunction_FastCallKeywords + 251
31      0x7fe9b1f72846p _PyEval_EvalFrameDefault + 1046
32      0x7fe9b1eb84f9p _PyEval_EvalCodeWithName + 761
33      0x7fe9b1eb93c4p PyEval_EvalCodeEx + 68
34      0x7fe9b1eb93ecp PyEval_EvalCode + 28
35      0x7fe9b1fd1874p
36      0x7fe9b1fdbb81p PyRun_FileExFlags + 161
37      0x7fe9b1fdbd73p PyRun_SimpleFileExFlags + 451
38      0x7fe9b1fdce5fp
39      0x7fe9b1fdcf7cp _Py_UnixMain + 60
40      0x7fe9b15c3b45p __libc_start_main + 245
41      0x7fe9b1f82122p

(paddle) [ocr_recognition]#
 

___________________________________________________________________________
Can anyone help me? Thank you in advance！",yanmeizhao,None,2019-08-01T13:39:35Z,2019-08-02T03:31:21Z,,,,,,,
7342,struct2depth model.py does not apply imagenet normalization during inference,"The original version does not apply normalization to the `input_image` even if `self.imagenet_norm` is `True`.
In the original version when line 772 is reached and `self.imagenet_norm == True` the variable `input_image` holds the tensor `depth_prediction/truediv:0`, i.e. the output of the normalization operation. When a value is fed in [line 840](https://github.com/tensorflow/models/blob/master/research/struct2depth/model.py#L840) the normalization operation is not run on this tensor.
With the change `self.input_image` is the tensor `depth_prediction/raw_input:0` which I think is the intended behavior.

I have opened an issue with more information: https://github.com/tensorflow/models/issues/7343 .

I hope that this is a valid bug and apologize if I made a mistake.
Bests
-Lukas",lkskstlr,b'cla: yes',2019-07-31T15:24:49Z,2020-04-24T06:55:22Z,,,,,,,
7341,Train FasterRCNN Model Without Transfer Learning (No Fine_Tune_Checkpoint),"### System information
- **What is the top-level directory of the model you are using**:
`models/research/object_detection/models/`
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
`Mac OS 10.14.5`
- **TensorFlow installed from (source or binary)**:
Binary
- **TensorFlow version (use command below)**:
`1.13.1`
- **Exact command to reproduce**:
Non-reproducable

### Describe the problem
I'm not sure if this is a feature request or a bug. I am trying to train a faster rcnn model from scratch (end-to-end and not using transfer-learning). I am wondering whether I am able to train a faster rcnn model without specifiying a `fine_tune_checkpoint` in the `pipeline.config` file?",marcoistasy,None,2019-07-31T14:01:01Z,2019-08-01T12:38:55Z,,,,,,,
7326,"eval.py eval coco dataset , mAP values are all nan","
### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:Ubuntu 18.04
- **TensorFlow installed from (source or binary)**:source
- **TensorFlow version (use command below)**:1.13.1
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:10.1
- **GPU model and memory**:2080ti 10988Mib
- **Exact command to reproduce**:



### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

I use models/research/object_detection/dataset_tools/download_and_preprocess_mscoco.sh to download coco dataset. Download ssd_mobilenet_v1_coco COCO-trained models. 
Modify the pipeline.config like below.

eval_input_reader {
  label_map_path: ""/home/ubuntupc/tensorflow/models/research/object_detection/data/mscoco_complete_label_map.pbtxt""
  shuffle: false
  num_readers: 1
  tf_record_input_reader {
    input_path: ""/home/ubuntupc/tensorflow/models/research/object_detection/coco_dataset/coco_testdev.record-?????-of-00100""
  }
}


ues eval.py
python legacy/eval.py --logtostderr --eval_dir=training/ssd_mobilenet_v1_coco_2018_01_28/eval --pipeline_config_path=training/ssd_mobilenet_v1_coco_2018_01_28/pipeline.config --checkpoint_dir=training/ssd_mobilenet_v1_coco_2018_01_28/

python -m tensorboard.main --logdir=training/ssd_mobilenet_v1_coco_2018_01_28/eval

In tensorboard ,The picture can successfully select the car and the person, but the mAP values are all nan.



### Source code / logs
INFO:tensorflow:# skipped: 0
INFO:tensorflow:# skipped: 0
WARNING:root:The following classes have no ground truth examples: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24
 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48
 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72
 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90]
/home/ubuntupc/tensorflow/models/research/object_detection/utils/metrics.py:142: RuntimeWarning: invalid value encountered in true_divide
  num_images_correctly_detected_per_class / num_gt_imgs_per_class)
/home/ubuntupc/tensorflow/models/research/object_detection/utils/object_detection_evaluation.py:1056: RuntimeWarning: Mean of empty slice
  mean_ap = np.nanmean(self.average_precision_per_class)
/home/ubuntupc/tensorflow/models/research/object_detection/utils/object_detection_evaluation.py:1057: RuntimeWarning: Mean of empty slice
  mean_corloc = np.nanmean(self.corloc_per_class)
INFO:tensorflow:Writing metrics to tf summary.
INFO:tensorflow:Writing metrics to tf summary.
INFO:tensorflow:Losses/Loss/classification_loss: 0.000000
INFO:tensorflow:Losses/Loss/classification_loss: 0.000000
INFO:tensorflow:Losses/Loss/localization_loss: 0.000000
INFO:tensorflow:Losses/Loss/localization_loss: 0.000000
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/12: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/12: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/26: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/26: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/29: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/29: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/30: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/30: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/45: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/45: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/66: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/66: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/68: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/68: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/69: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/69: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/71: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/71: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/83: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/83: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/airplane: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/airplane: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/apple: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/apple: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/backpack: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/backpack: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/banana: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/banana: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/baseball bat: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/baseball bat: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/baseball glove: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/baseball glove: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/bear: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/bear: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/bed: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/bed: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/bench: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/bench: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/bicycle: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/bicycle: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/bird: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/bird: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/boat: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/boat: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/book: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/book: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/bottle: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/bottle: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/bowl: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/bowl: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/broccoli: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/broccoli: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/bus: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/bus: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/cake: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/cake: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/car: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/car: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/carrot: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/carrot: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/cat: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/cat: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/cell phone: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/cell phone: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/chair: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/chair: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/clock: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/clock: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/couch: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/couch: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/cow: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/cow: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/cup: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/cup: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/dining table: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/dining table: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/dog: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/dog: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/donut: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/donut: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/elephant: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/elephant: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/fire hydrant: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/fire hydrant: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/fork: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/fork: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/frisbee: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/frisbee: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/giraffe: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/giraffe: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/hair drier: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/hair drier: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/handbag: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/handbag: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/horse: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/horse: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/hot dog: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/hot dog: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/keyboard: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/keyboard: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/kite: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/kite: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/knife: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/knife: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/laptop: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/laptop: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/microwave: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/microwave: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/motorcycle: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/motorcycle: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/mouse: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/mouse: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/orange: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/orange: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/oven: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/oven: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/parking meter: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/parking meter: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/person: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/person: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/pizza: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/pizza: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/potted plant: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/potted plant: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/refrigerator: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/refrigerator: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/remote: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/remote: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/sandwich: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/sandwich: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/scissors: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/scissors: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/sheep: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/sheep: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/sink: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/sink: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/skateboard: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/skateboard: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/skis: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/skis: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/snowboard: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/snowboard: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/spoon: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/spoon: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/sports ball: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/sports ball: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/stop sign: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/stop sign: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/suitcase: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/suitcase: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/surfboard: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/surfboard: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/teddy bear: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/teddy bear: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/tennis racket: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/tennis racket: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/tie: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/tie: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/toaster: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/toaster: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/toilet: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/toilet: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/toothbrush: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/toothbrush: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/traffic light: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/traffic light: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/train: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/train: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/truck: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/truck: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/tv: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/tv: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/umbrella: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/umbrella: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/vase: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/vase: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/wine glass: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/wine glass: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/zebra: nan
INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/zebra: nan
INFO:tensorflow:PascalBoxes_Precision/mAP@0.5IOU: nan
INFO:tensorflow:PascalBoxes_Precision/mAP@0.5IOU: nan

",webrtcccccc,b'models:research',2019-07-30T06:26:56Z,2020-06-30T22:16:38Z,,,,,,,
7308,Merged commit includes the following changes:,"Merged commit includes the following changes:
260060237  by zongweiz<zongweiz@google.com>:
    
    [BERT SQuAD] Enable mixed precision training
    
    Add mixed precision training support for BERT SQuAD model. Using the experimental Keras mixed precision API. For numeric stability, use fp32 for layer normalization, dense layers with GELU activation, etc.
    
--
260052674  by hongkuny<hongkuny@google.com>:
    
    Add expect_partial()
    
--
259889221  by hongkuny<hongkuny@google.com>:
    
    Add no ds / xla / eager perfzero tests
    
--
259790197  by hongkuny<hongkuny@google.com>:
    
    Update pretraining model to match tf1 var names.
    
--
259649972  by hongkuny<hongkuny@google.com>:
    
    Update docs.
    
--
259470074  by hongkuny<hongkuny@google.com>:
    
    Adds a dedup phase for trainable variables.
    
--
259442882  by hongkuny<hongkuny@google.com>:
    
    Internal
    
--
259341546  by mrry<mrry@google.com>:
    
    Remove DEBUG-level logging from the BERT benchmark.
    
    This triggers graph serialization and other verbose logging in the TensorFlow runtime, which inflates the execution time.
    
--
259253185  by hongkuny<hongkuny@google.com>:
    
    Writes a separated checkpoint for the core model in pretraining.
    Clean up export utils to just take a model as argument.
    
--
258893811  by hongkuny<hongkuny@google.com>:
    
    Adds summaries for metrics, allowing metrics inside keras.model.
    
--
258881002  by hongkuny<hongkuny@google.com>:
    
    Fix lint.
    
--
258597234  by rxsang<rxsang@google.com>:
    
    Update all the TPUStrategy examples to use the new v2 APIs, i.e.
    make_dataset_iterator -> experimental_distribute_dataset,
    make_input_fn_iterator -> experimental_distribute_datasets_from_function,
    unwrap -> experimental_local_results,
    experimental_run -> experimental_run_v2
    
--
258581998  by taylorrobie<taylorrobie@google.com>:
    
    
    Update keras v2 optimizers to reuse coefficients which are shared across all updates, which reduces the total number of ops created by between 5% (for simple optimizers such as SGD and Adagrad) and 25% (for complicated optimizers such as Adam and NAdam). Separate copies are made for each device and dtype.
    
    The effect of this change on run time is fairly minimal since Grappler is expected to consolidate most of these ops; however it does improve graph construction time.
    
    
--
258208153  by hongkuny<hongkuny@google.com>:
    
    Adds run_eagerly option for bert.
    
--
257883986  by hongkuny<hongkuny@google.com>:
    
    Adds tf.summary for bert training
    
--
256204636  by hongkuny<hongkuny@google.com>:
    
    Internal
    
--
256079834  by hongkuny<hongkuny@google.com>:
    
    Clean up: move common flags together for further refactoring
    Enable steps_per_loop option for all applications.
    
--
255493073  by hongkuny<hongkuny@google.com>:
    
    BERT initial OSS readme update.
    
--
255470372  by dmchen<dmchen@google.com>:
    
    Slightly expand expected range for F1 score in BERT SQuAD accuracy test
    
--
255109240  by hongkuny<hongkuny@google.com>:
    
    Update eval/predict batch sizes.
    
--
255010016  by hongkuny<hongkuny@google.com>:
    
    Internal
    
--
254874613  by hongkuny<hongkuny@google.com>:
    
    Update glue tasks enum to match directory name
    
--
254866171  by taylorrobie<taylorrobie@google.com>:

    Internal change

254785517  by zongweiz<zongweiz@google.com>:
    
    Use train_single_step for BERT GPU models to temporarily work around some performance bugs in GPU runs
    
--
254497647  by hongkuny<hongkuny@google.com>:
    
    Fix device placement for TPU export model.
    
--
254134531  by yuefengz<yuefengz@google.com>:
    
    Fix a typo in bert_benchmark.py
    
--
254069984  by hongkuny<hongkuny@google.com>:
    Automated rollback of changelist 254060732.

254061429  by hongkuny<hongkuny@google.com>:
    
    Use host while loop for training steps.
    
--
254060732  by yifeif<yifeif@google.com>:
    Automated rollback of changelist 254027750.

254027750  by hongkuny<hongkuny@google.com>:

    Internal change

253850824  by hongkuny<hongkuny@google.com>:
    
    Improve bert training utils.
    
--
253818191  by hongkuny<hongkuny@google.com>:
    
    Update savedmodel export to use new model.save() api.
    
--
253636854  by dmchen<dmchen@google.com>:
    
    Run only training in BERT SQuAD performance test
    
--
253118910  by hongkuny<hongkuny@google.com>:

    Internal change

253113801  by zongweiz<zongweiz@google.com>:

    Internal change

252697519  by dmchen<dmchen@google.com>:
    
    BERT SQuAD accuracy test
    
--
252663512  by A. Unique TensorFlower<gardener@tensorflow.org>:
    
    Internal change
    
--
252647871  by A. Unique TensorFlower<gardener@tensorflow.org>:
    
    Enable multi worker TPU training for BERT pretraining.
    
--
252522861  by hongkuny<hongkuny@google.com>:
    
    Remove export using trained model due to implementation error
    
--
252156812  by yuefengz<yuefengz@google.com>:
    
    Fix the callback method name in BERT: replaced on_batch_start with on_batch_begin. Without the fix, it won't work with Keras callbacks.
    
--
251782065  by dmchen<dmchen@google.com>:

    Internal change

251681245  by hongkuny<hongkuny@google.com>:
    
    Update bert to use the new tf.distribute APIs 
    
--
251575972  by A. Unique TensorFlower<gardener@tensorflow.org>:
    
    Remove `steps_per_run` when instantiating TPUStrategy.
    
--
251325964  by hongkuny<hongkuny@google.com>:
    
    Improve flags
    
--
250942274  by tobyboyd<tobyboyd@google.com>:

    Internal change

250779087  by A. Unique TensorFlower<gardener@tensorflow.org>:
    
    Reduce BERT Perfzero benchmark test training steps.
    
--
250713045  by hongkuny<hongkuny@google.com>:
    
    TPU util
    
--
250606180  by A. Unique TensorFlower<gardener@tensorflow.org>:
    
    Fix BERT benchamrk test errors.
    
--
250589623  by A. Unique TensorFlower<gardener@tensorflow.org>:
    
    Change BERT benchmark test pretrained checkpoint url.
    
--
250587892  by A. Unique TensorFlower<gardener@tensorflow.org>:
    
    Fix error in BERT custom training loop checkpoint restoration.
    
--
250577163  by A. Unique TensorFlower<gardener@tensorflow.org>:
    
    Add logic to inject callback that measures performance in BERT custom training
    loop.
    
--
250529526  by hongkuny<hongkuny@google.com>:
    
    Internal clean up
    
--
250428976  by hongkuny<hongkuny@google.com>:

    Internal change

250415383  by A. Unique TensorFlower<gardener@tensorflow.org>:
    
    Add min/max value to BERT classifier benchmark test.
    
--
250376246  by A. Unique TensorFlower<gardener@tensorflow.org>:
    
    Add benchmark performance test to run BERT on multiple numbers of GPUs. 
    
--
250347237  by A. Unique TensorFlower<gardener@tensorflow.org>:
    
    Fix linting errors in BERT benchmark test.
    
--
250326131  by A. Unique TensorFlower<gardener@tensorflow.org>:

    Internal change

250315593  by A. Unique TensorFlower<gardener@tensorflow.org>:

    Internal change

250303528  by haoyuzhang<haoyuzhang@google.com>:
    
    Add method docstring to fix lint error.
    
--
250009207  by A. Unique TensorFlower<gardener@tensorflow.org>:
    
    Add feature in BERT to write training metrics to a summary file.
    
--
249896208  by hongkuny<hongkuny@google.com>:
    
    Adds __init__.py
    
--
249883771  by hongkuny<hongkuny@google.com>:
    
    Creates a benchmark dir
    
--
249580533  by A. Unique TensorFlower<gardener@tensorflow.org>:

    Internal change

249566870  by A. Unique TensorFlower<gardener@tensorflow.org>:
    
    Set up BERT benchmark test.
    
--
249500988  by hongkuny<hongkuny@google.com>:
    
    Lints
    
--
249377254  by hongkuny<hongkuny@google.com>:

    Internal change

249373328  by hongkuny<hongkuny@google.com>:
    
    Clean up tf import
    
--
249333938  by hongkuny<hongkuny@google.com>:
    
    Fix tf1 import
    
--
249325089  by hongkuny<hongkuny@google.com>:
    
    BERT 2.0
    
--
249173564  by hongkuny<hongkuny@google.com>:",saberkun,b'cla: yes',2019-07-26T05:49:04Z,2019-07-26T05:50:05Z,,,,,,,
7300,While train the model always getting “Saving checkpoint to path training/model.ckpt”,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",lintujizoarakal777,b'stat:awaiting response type:support',2019-07-25T05:04:46Z,2020-07-29T07:22:56Z,,,,,,,
7277,Merged commit includes the following changes:,"Merged commit includes the following changes:
259442882  by hongkuny<hongkuny@google.com>:
    
    Internal
    
--
259341546  by mrry<mrry@google.com>:
    
    Remove DEBUG-level logging from the BERT benchmark.
    
    This triggers graph serialization and other verbose logging in the TensorFlow runtime, which inflates the execution time.
    
--
259253185  by hongkuny<hongkuny@google.com>:
    
    Writes a separated checkpoint for the core model in pretraining.
    Clean up export utils to just take a model as argument.
    ",saberkun,b'cla: yes kokoro:run',2019-07-23T01:00:01Z,2019-07-23T01:42:50Z,,,,,,,
7271,ImportError: cannot import name 'evalutor',"enviroment:
Window7 64bit
intel i5-6300HQ
tensorflow cpu ver
anaconda/pycharm

main.py

import os
import subprocess
from utils.utils import download_model, remove_model_tar_file, model_input, model_dict, remake_config, check_time, set_log
import argparse
import shutil
import time

def user_input():
    config = argparse.ArgumentParser()
    config.add_argument('-l', '--label_file', help='Label file Location', default='./label_map.pbtxt', type=str,required=False)
    config.add_argument('-log_level', '--log_level', help='Logger Level [DEBUG, INFO(Default), WARNING, ERROR, CRITICAL]', default='INFO', type=str, required=False)
    config.add_argument('-r', '--reset', help='Training Resset configration [ Default = False ]', default=False, type=str,required=False)
    config.add_argument('-e', '--evaluate', help='Perform an evaluate every evaluate_number times.  [ Default = True ]', default=True, type=str, required=False)
    config.add_argument('-n', '--evaluate_number', help='Perform an evaluate every evaluate_number times.  [ Default = 2000 ]', default='2000', type=str, required=False)
    args = config.parse_args()
    arguments = vars(args)

    return arguments


# re-training func
def transfer_learning(logger, model,args):
    start_time = time.time()
    logger.info('Transfer learning start')

    if args['reset']:
        shutil.rmtree('./train_dir/' + model_dict[model][0])
        os.mkdir('./train_dir/' + model_dict[model][0])
        args['reset'] = False

    train_dir = './train_dir/' + model_dict[model][0]
    config_file = './model_conf/' + model_dict[model][1]
    try:
        subprocess.check_output(['python', 'object_detection/train.py', ' --logtostderr', '--train_dir', train_dir,
                     '--pipeline_config_path', config_file])
    except:
        logger.error('Transfer leaarning Error')
        exit()
    end_time = time.time()
    h,m,s = check_time(int(end_time-start_time))
    logger.info('Transfer learning Success [ Total learning time : '+h+"" Hour ""+m+"" Minute ""+s+"" Second ]"")

# export func
def export_model(logger, model, exam_num):
    logger.info('Export model start')
    if os.path.isdir('./export_dir/' + model_dict[model][0]):
        shutil.rmtree('./export_dir/' + model_dict[model][0])
    export_dir = './export_dir/' + model_dict[model][0]
    config_file = './model_conf/' + model_dict[model][1]
    trained_checkpoint = './train_dir/' + model_dict[model][0] + '/model.ckpt-' + str(exam_num)
    try:
        subprocess.check_output(['python', 'object_detection/export_inference_graph.py',
                     '--input_type', 'image_tensor',
                     '--pipeline_config_path', config_file,
                     '--trained_checkpoint_prefix', trained_checkpoint,
                     '--output_directory', export_dir])
    except:
        logger.error('Export Model Error')
        exit()
    logger.info('Export model Success')

# evaluate func
def evaluate_model(logger, model, num_steps):
    logger.info('Evaluate model start [ Step number : ' + str(num_steps) + "" ]"")
    config_file = './model_conf/' + model_dict[model][1]
    try:
        subprocess.check_output(['python', 'object_detection/eval.py',
                     '--logtostderr',
                     '--pipeline_config_path', config_file,
                     '--checkpoint_dir', './train_dir/' + model_dict[model][0],
                     '--eval_dir',  './eval_dir/' + model_dict[model][0] ,
                     '--run_once','True'])
    except:
        logger.error('Evaluate Model Error')
        exit()
    logger.info('Evaluate model Success')

def main():

    args = user_input()

    # logger setting
    logger = set_log(args['log_level'])

    model = model_input()

    print("""")
    num_steps = int(input('Input number steps : '))
    print("""")

    total_start_time = time.time()
    logger.info('Program start [ model : ' + model_dict[model][0] + ', num steps : ' + str(num_steps) + ' ]')

    # Download model zoo file into the device
    download_model(logger,model)
    remove_model_tar_file(model)

    if args['reset']:
        if os.path.isdir('./eval_dir/' + model_dict[model][0]):
            shutil.rmtree('./eval_dir/' + model_dict[model][0])

    if args['evaluate']:
        tmp_num = int(args['evaluate_number'])
        while tmp_num < num_steps:
            remake_config(model, tmp_num, args)
            transfer_learning(logger, model, args)
            evaluate_model(logger, model, tmp_num)
            tmp_num += int(args['evaluate_number'])
        remake_config(model, num_steps, args)
        transfer_learning(logger, model, args)
        evaluate_model(logger, model, num_steps)
    else:
        remake_config(model, num_steps, args)
        transfer_learning(logger, model, args)

    export_model(logger, model, num_steps)
    total_end_time = time.time()
    h, m, s = check_time(int(total_end_time - total_start_time))
    logger.info('Program end [ Total time : '+h+"" Hour ""+m+"" Minute ""+s+"" Second ]"")
    logger.info('')

main()

#TO-DO visualization func add
#TO-DO Active learning check
#TO-D0 model download and test

I'm studying object detection, 
and i make my custom dataset.
learning finished, error in eval.py

# Copyright 2017 The TensorFlow Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ==============================================================================

r""""""Evaluation executable for detection models.

This executable is used to evaluate DetectionModels. There are two ways of
configuring the eval job.

1) A single pipeline_pb2.TrainEvalPipelineConfig file maybe specified instead.
In this mode, the --eval_training_data flag may be given to force the pipeline
to evaluate on training data instead.

Example usage:
    ./eval \
        --logtostderr \
        --checkpoint_dir=path/to/checkpoint_dir \
        --eval_dir=path/to/eval_dir \
        --pipeline_config_path=pipeline_config.pbtxt

2) Three configuration files may be provided: a model_pb2.DetectionModel
configuration file to define what type of DetectionModel is being evaluated, an
input_reader_pb2.InputReader file to specify what data the model is evaluating
and an eval_pb2.EvalConfig file to configure evaluation parameters.

Example usage:
    ./eval \
        --logtostderr \
        --checkpoint_dir=path/to/checkpoint_dir \
        --eval_dir=path/to/eval_dir \
        --eval_config_path=eval_config.pbtxt \
        --model_config_path=model_config.pbtxt \
        --input_config_path=eval_input_config.pbtxt
""""""
import functools
import os
import tensorflow as tf

from object_detection import evaluator
from object_detection.builders import dataset_builder
from object_detection.builders import model_builder
from object_detection.utils import config_util
from object_detection.utils import dataset_util
from object_detection.utils import label_map_util


tf.logging.set_verbosity(tf.logging.INFO)

flags = tf.app.flags
flags.DEFINE_boolean('eval_training_data', False,
                     'If training data should be evaluated for this job.')
flags.DEFINE_string('checkpoint_dir', '',
                    'Directory containing checkpoints to evaluate, typically '
                    'set to `train_dir` used in the training job.')
flags.DEFINE_string('eval_dir', '',
                    'Directory to write eval summaries to.')
flags.DEFINE_string('pipeline_config_path', '',
                    'Path to a pipeline_pb2.TrainEvalPipelineConfig config '
                    'file. If provided, other configs are ignored')
flags.DEFINE_string('eval_config_path', '',
                    'Path to an eval_pb2.EvalConfig config file.')
flags.DEFINE_string('input_config_path', '',
                    'Path to an input_reader_pb2.InputReader config file.')
flags.DEFINE_string('model_config_path', '',
                    'Path to a model_pb2.DetectionModel config file.')
flags.DEFINE_boolean('run_once', False, 'Option to only run a single pass of '
                     'evaluation. Overrides the `max_evals` parameter in the '
                     'provided config.')
FLAGS = flags.FLAGS


def main(unused_argv):
  assert FLAGS.checkpoint_dir, '`checkpoint_dir` is missing.'
  assert FLAGS.eval_dir, '`eval_dir` is missing.'
  tf.gfile.MakeDirs(FLAGS.eval_dir)
  if FLAGS.pipeline_config_path:
    configs = config_util.get_configs_from_pipeline_file(
        FLAGS.pipeline_config_path)
    tf.gfile.Copy(FLAGS.pipeline_config_path,
                  os.path.join(FLAGS.eval_dir, 'pipeline.config'),
                  overwrite=True)
  else:
    configs = config_util.get_configs_from_multiple_files(
        model_config_path=FLAGS.model_config_path,
        eval_config_path=FLAGS.eval_config_path,
        eval_input_config_path=FLAGS.input_config_path)
    for name, config in [('model.config', FLAGS.model_config_path),
                         ('eval.config', FLAGS.eval_config_path),
                         ('input.config', FLAGS.input_config_path)]:
      tf.gfile.Copy(config,
                    os.path.join(FLAGS.eval_dir, name),
                    overwrite=True)

  model_config = configs['model']
  eval_config = configs['eval_config']
  input_config = configs['eval_input_config']
  if FLAGS.eval_training_data:
    input_config = configs['train_input_config']

  model_fn = functools.partial(
      model_builder.build,
      model_config=model_config,
      is_training=False)

  def get_next(config):
    return dataset_util.make_initializable_iterator(
        dataset_builder.build(config)).get_next()

  create_input_dict_fn = functools.partial(get_next, input_config)

  label_map = label_map_util.load_labelmap(input_config.label_map_path)
  max_num_classes = max([item.id for item in label_map.item])
  categories = label_map_util.convert_label_map_to_categories(
      label_map, max_num_classes)

  if FLAGS.run_once:
    eval_config.max_evals = 1

  evaluator.evaluate(create_input_dict_fn, model_fn, eval_config, categories,
                     FLAGS.checkpoint_dir, FLAGS.eval_dir)


if __name__ == '__main__':
  tf.app.run()



ImportError: cannot import name 'evalutor'

What should i do?


",Ddongdun,b'models:research stalled stat:awaiting response',2019-07-22T02:47:11Z,2020-09-18T16:17:33Z,,,,,,,
7268,Add a simple signal-based Python callstack sampler for debugging,,zongweiz,b'cla: yes',2019-07-20T01:51:57Z,2020-03-17T03:59:36Z,,,,,,,
7267,Do we have DELF feature extraction code in Golang?,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------
@andrefaraujo 
### System information
- **What is the top-level directory of the model you are using**:
I am using the DELF module in TensorFlow-hub
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
Not written custom code.
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
MacOS Mojave
- **TensorFlow installed from (source or binary)**:
Binary using pip3
- **TensorFlow version (use command below)**:
1.15.0-dev20190719
- **Bazel version (if compiling from source)**:
N/A
- **CUDA/cuDNN version**:
N/A
- **GPU model and memory**:
N/A
- **Exact command to reproduce**:
N/A
You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

### Describe the problem
Do we have a way to use the DELF feature extraction in GoLang?

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.",rapidcoder7,None,2019-07-20T01:23:09Z,2019-08-07T21:17:02Z,,,,,,,
7261,Low confidence predictions for Faster R-CNN,"### System information
- **What is the top-level directory of the model you are using**: research/object-detection
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Red Hat Enterprise Linux Server 7.5 (Maipo) **TensorFlow installed from (source or binary)**: binary (conda)
- **TensorFlow version (use command below)**: 1.12.0
- **Bazel version (if compiling from source)**: -
- **CUDA/cuDNN version**: 9
- **GPU model and memory**: -
- **Exact command to reproduce**: Following this tutorial for inference https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/oid_inference_and_evaluation.md just using http://download.tensorflow.org/models/object_detection/faster_rcnn_resnet101_coco_2018_01_28.tar.gz (with the standard config in the samples folder)

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

### Describe the problem
Even though the non-max suppression threshold is set to 0.0, the box with the lowest confidence is about 0.001. I have been looking in all the documentation and debugging through the code but could not find anything where the low confidence boxes are filtered out.  I haven't tried out if this is a general problem or just applies to the Faster RCNN models.

This is a bug or documentation flaw since the user would expect a different behavior given the pipeline configuration. Of course, setting the threshold very low, on the other hand, might lead to unexpected behavior as well.

This use case might seem a little odd, but for my problem, I am tuning for very high recall. The false positives are not that big of a concern. I would be glad if someone could pinpoint me where to look. If desired by the maintainers I am happy to submitta merge request fixing this.

### Source code / logs
Here the pipeline config:
```
# Faster R-CNN with Resnet-101 (v1), configuration for MSCOCO Dataset.
# Users should configure the fine_tune_checkpoint field in the train config as
# well as the label_map_path and input_path fields in the train_input_reader and
# eval_input_reader. Search for ""PATH_TO_BE_CONFIGURED"" to find the fields that
# should be configured.

model {
  faster_rcnn {
    num_classes: 90
    image_resizer {
      keep_aspect_ratio_resizer {
        min_dimension: 600
        max_dimension: 1024
      }
    }
    feature_extractor {
      type: 'faster_rcnn_resnet101'
      first_stage_features_stride: 16
    }
    first_stage_anchor_generator {
      grid_anchor_generator {
        scales: [0.25, 0.5, 1.0, 2.0]
        aspect_ratios: [0.5, 1.0, 2.0]
        height_stride: 16
        width_stride: 16
      }
    }
    first_stage_box_predictor_conv_hyperparams {
      op: CONV
      regularizer {
        l2_regularizer {
          weight: 0.0
        }
      }
      initializer {
        truncated_normal_initializer {
          stddev: 0.01
        }
      }
    }
    first_stage_nms_score_threshold: 0.0
    first_stage_nms_iou_threshold: 0.7
    first_stage_max_proposals: 300
    first_stage_localization_loss_weight: 2.0
    first_stage_objectness_loss_weight: 1.0
    initial_crop_size: 14
    maxpool_kernel_size: 2
    maxpool_stride: 2
    second_stage_box_predictor {
      mask_rcnn_box_predictor {
        use_dropout: false
        dropout_keep_probability: 1.0
        fc_hyperparams {
          op: FC
          regularizer {
            l2_regularizer {
              weight: 0.0
            }
          }
          initializer {
            variance_scaling_initializer {
              factor: 1.0
              uniform: true
              mode: FAN_AVG
            }
          }
        }
      }
    }
    second_stage_post_processing {
      batch_non_max_suppression {
        score_threshold: 0.0
        iou_threshold: 0.6
        max_detections_per_class: 100
        max_total_detections: 300
      }
      score_converter: SOFTMAX
    }
    second_stage_localization_loss_weight: 2.0
    second_stage_classification_loss_weight: 1.0
  }
}

train_config: {
  batch_size: 1
  optimizer {
    momentum_optimizer: {
      learning_rate: {
        manual_step_learning_rate {
          initial_learning_rate: 0.0003
          schedule {
            step: 900000
            learning_rate: .00003
          }
          schedule {
            step: 1200000
            learning_rate: .000003
          }
        }
      }
      momentum_optimizer_value: 0.9
    }
    use_moving_average: false
  }
  gradient_clipping_by_norm: 10.0
  fine_tune_checkpoint: ""PATH_TO_BE_CONFIGURED/model.ckpt""
  from_detection_checkpoint: true
  data_augmentation_options {
    random_horizontal_flip {
    }
  }
}

train_input_reader: {
  tf_record_input_reader {
    input_path: ""PATH_TO_BE_CONFIGURED/mscoco_train.record-?????-of-00100""
  }
  label_map_path: ""PATH_TO_BE_CONFIGURED/mscoco_label_map.pbtxt""
}

eval_config: {
  num_examples: 8000
  # Note: The below line limits the evaluation process to 10 evaluations.
  # Remove the below line to evaluate indefinitely.
  max_evals: 10
}

eval_input_reader: {
  tf_record_input_reader {
    input_path: ""PATH_TO_BE_CONFIGURED/mscoco_val.record-?????-of-00010""
  }
  label_map_path: ""PATH_TO_BE_CONFIGURED/mscoco_label_map.pbtxt""
  shuffle: false
  num_readers: 1
}
```",sigeisler,None,2019-07-19T17:53:22Z,2019-07-30T01:15:30Z,,,,,,,
7250, Merged commit includes the following changes:,"258709909  by yongzhe:

    1. Fix a bug that input wasn't copied.
    2. Change the tensor indexing to support graph with postprocessing.
    3. Fix a bug that the quantized lstm states weren't initialized.

--
258398095  by yongzhe:

    Internal change.

--",yongzhe2160,b'cla: no',2019-07-18T18:04:50Z,2019-07-18T18:08:30Z,,,,,,,
7249, Merged commit includes the following changes: ,"258709909  by yongzhe:

    1. Fix a bug that input wasn't copied.
    2. Change the tensor indexing to support graph with postprocessing.
    3. Fix a bug that the quantized lstm states weren't initialized.

--
258398095  by yongzhe:

    Internal change.

",yongzhe2160,None,2019-07-18T17:59:58Z,2019-07-18T18:02:07Z,,,,,,,
7245,deeplab requirements,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",javierjsa,b'models:research stat:awaiting response',2019-07-18T12:33:29Z,2019-07-19T19:34:33Z,,,,,,,
7243,TensorRT error when running SavedModel,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.14.1
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**: 10.0
- **GPU model and memory**: Nvidia T4
- **Exact command to reproduce**:

```
python -m research.tensorrt.tensorrt --savedmodel_dir=/home/gogasca/resnet_v2_fp32_savedmodel_NCHW_jpg/1538687370/ --image_file=image.jpg --native --fp32 --fp16 --int8 --output_dir=/home/gogasca/
```

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
('v1.14.0-rc1-22-gaf24dc91b5', '1.14.0')

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

Unable to run TensorRT with TF 1.14 for Resnet model.
```
wget http://download.tensorflow.org/models/official/20181001_resnet/savedmodels/resnet_v2_fp32_savedmodel_NCHW_jpg.tar.gz
```

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.

```
 python -m research.tensorrt.tensorrt --savedmodel_dir=/home/gogasca/resnet_v2_fp32_savedmodel_NCHW_jpg/1538687370/ --image_file=image.jpg --native --fp32 --fp16 --int8 --output_dir=/home/gogasca/
WARNING: Logging before flag parsing goes to stderr.
W0717 23:46:32.237600 140638531470784 deprecation_wrapper.py:119] From /home/gogasca/models/research/tensorrt/tensorrt.py:628: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.

W0717 23:46:32.237802 140638531470784 deprecation_wrapper.py:119] From /home/gogasca/models/research/tensorrt/tensorrt.py:628: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.

W0717 23:46:32.239108 140638531470784 deprecation_wrapper.py:119] From /home/gogasca/models/research/tensorrt/tensorrt.py:69: The name tf.read_file is deprecated. Please use tf.io.read_file instead.

W0717 23:46:32.269068 140638531470784 deprecation_wrapper.py:119] From /home/gogasca/models/research/tensorrt/tensorrt.py:78: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

W0717 23:46:32.269264 140638531470784 deprecation_wrapper.py:119] From /home/gogasca/models/research/tensorrt/tensorrt.py:273: The name tf.GPUOptions is deprecated. Please use tf.compat.v1.GPUOptions instead.

W0717 23:46:32.269359 140638531470784 deprecation_wrapper.py:119] From /home/gogasca/models/research/tensorrt/tensorrt.py:274: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

2019-07-17 23:46:32.269567: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-17 23:46:32.277257: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz
2019-07-17 23:46:32.277475: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55f19aa84540 executing computations on platform Host. Devices:
2019-07-17 23:46:32.277566: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-07-17 23:46:32.297776: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
W0717 23:46:32.351721 140638531470784 deprecation_wrapper.py:119] From /home/gogasca/models/research/tensorrt/tensorrt.py:144: The name tf.saved_model.tag_constants.SERVING is deprecated. Please use tf.saved_model.SERVING instead.

W0717 23:46:32.364584 140638531470784 deprecation_wrapper.py:119] From /home/gogasca/models/research/tensorrt/tensorrt.py:187: The name tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY is deprecated. Please use tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY instead.

W0717 23:46:32.365458 140638531470784 deprecation.py:323] From /home/gogasca/models/research/tensorrt/tensorrt.py:195: load (from tensorflow.python.saved_model.loader_impl) is deprecated and will be removed in a future version.
Instructions for updating:
This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.loader.load or tf.compat.v1.saved_model.load. There will be a new function for importing SavedModels in Tensorflow 2.0.
W0717 23:46:32.782711 140638531470784 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to check for files with this prefix.
I0717 23:46:32.783581 140638531470784 saver.py:1280] Restoring parameters from /home/gogasca/resnet_v2_fp32_savedmodel_NCHW_jpg/1538687370/variables/variables
W0717 23:46:33.202677 140638531470784 deprecation.py:323] From /home/gogasca/models/research/tensorrt/tensorrt.py:197: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.graph_util.convert_variables_to_constants`
W0717 23:46:33.202893 140638531470784 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/graph_util_impl.py:270: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.graph_util.extract_sub_graph`
I0717 23:46:33.409485 140638531470784 graph_util_impl.py:311] Froze 251 variables.
I0717 23:46:33.560045 140638531470784 graph_util_impl.py:364] Converted 251 variables to const ops.
W0717 23:46:33.587506 140638531470784 deprecation_wrapper.py:119] From /home/gogasca/models/research/tensorrt/tensorrt.py:160: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.

Running native graph
W0717 23:46:34.440793 140638531470784 deprecation_wrapper.py:119] From /home/gogasca/models/research/tensorrt/tensorrt.py:304: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.

I0717 23:46:34.441003 140638531470784 tensorrt.py:304] Starting execution
W0717 23:46:34.441147 140638531470784 deprecation_wrapper.py:119] From /home/gogasca/models/research/tensorrt/tensorrt.py:306: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.

W0717 23:46:34.706238 140638531470784 deprecation.py:323] From /home/gogasca/models/research/tensorrt/tensorrt.py:280: make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.
Traceback (most recent call last):
  File ""/usr/lib/python2.7/runpy.py"", line 174, in _run_module_as_main
    ""__main__"", fname, loader, pkg_name)
  File ""/usr/lib/python2.7/runpy.py"", line 72, in _run_code
    exec code in run_globals
  File ""/home/gogasca/models/research/tensorrt/tensorrt.py"", line 629, in <module>
    main(argv=sys.argv)
  File ""/home/gogasca/models/research/tensorrt/tensorrt.py"", line 476, in main
    g_name, frozen_graph_def, data, log_buffer, flags)
  File ""/home/gogasca/models/research/tensorrt/tensorrt.py"", line 376, in time_and_log_graph
    graph_def, data, flags.input_node, flags.output_node, flags.num_loops)
  File ""/home/gogasca/models/research/tensorrt/tensorrt.py"", line 314, in time_graph
    return_elements=[output_node]
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/util/deprecation.py"", line 507, in new_func
    return func(*args, **kwargs)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/importer.py"", line 431, in import_graph_def
    raise ValueError(str(e))
ValueError: Input 0 of node import/map/Shape was passed float from IteratorGetNext:0 incompatible with expected string.
```",gogasca,None,2019-07-17T23:50:22Z,2019-07-31T23:40:40Z,,,,,,,
7236,"tf lite with ""use_regular_nms"" flag","Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",HelliH,None,2019-07-17T12:42:51Z,2019-07-17T14:02:48Z,,,,,,,
7235,"tf lite with ""use_regular_nms"" flag","Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",HelliH,None,2019-07-17T12:42:51Z,2019-07-17T14:03:35Z,,,,,,,
7234,"tf lite with ""use_regular_nms"" flag","Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",HelliH,None,2019-07-17T12:42:51Z,2019-07-17T14:03:15Z,,,,,,,
7216,CIFAR-10 tutorial for multi-GPU fails because full shape isn't passed to prefetch_queue,"### System information
- **What is the top-level directory of the model you are using**:
   - tutorials/image/cifar10/cifar10_multi_gpu_train.py 
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
 no
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux jupyter-mattmann-40usc-2eedu 4.15.15-1.el7.x86_64 #1 SMP Thu Oct 4 07:42:41 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux
- **TensorFlow installed from (source or binary)**: used PIP (binary)
- **TensorFlow version (use command below)**: 1.13.1, tensorflow-datasets 1.0.2
- **Bazel version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: 4 GPUs
- **Exact command to reproduce**:
python3 cifar_eval.py

```
== env ==========================================================
LD_LIBRARY_PATH /usr/local/nvidia/lib:/usr/local/nvidia/lib64
DYLD_LIBRARY_PATH is unset

== nvidia-smi ===================================================
Tue Jul 16 15:59:26 2019       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 430.14       Driver Version: 430.14       CUDA Version: 10.2     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  GeForce RTX 208...  Off  | 00000000:1B:00.0 Off |                  N/A |
| 31%   32C    P0    85W / 250W |      0MiB / 11019MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   1  GeForce RTX 208...  Off  | 00000000:1E:00.0 Off |                  N/A |
|  0%   30C    P8    22W / 250W |      0MiB / 11019MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   2  GeForce RTX 208...  Off  | 00000000:61:00.0 Off |                  N/A |
|  0%   30C    P0    65W / 250W |      0MiB / 11019MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   3  GeForce RTX 208...  Off  | 00000000:63:00.0 Off |                  N/A |
| 29%   29C    P0    62W / 250W |      0MiB / 11019MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID   Type   Process name                             Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+

== cuda libs  ===================================================
/usr/local/cuda-10.0/targets/x86_64-linux/lib/libcudart_static.a
/usr/local/cuda-10.0/targets/x86_64-linux/lib/libcudart.so.10.0.130

== tensorflow installed from info ==================

== python version  ==============================================
(major, minor, micro, releaselevel, serial)
(3, 7, 3, 'final', 0)

== bazel version  ===============================================
jovyan@jupyter-mattmann-40usc-2eedu:~/models/tutorials/image/cifar10$ 
```

### Describe the problem

The [CIFAR-10 Multi-GPU Tutorial](https://github.com/tensorflow/models/blob/master/tutorials/image/cifar10/cifar10_multi_gpu_train.py) has a bug in it when run from the command line. I am using Tensorflow `1.13.1` and Tensorflow-Datasets `1.0.2`. You simply need to put an explicit call to tf.reshape before passing it into the prefetch_queue to add the outer num_samples shape. I've got a quick PR that fixes this.

### Source code / logs
Will send a PR.",chrismattmann,None,2019-07-15T19:33:46Z,2019-07-28T21:13:26Z,,,,,,,
7208,Release Open Image 2019 metrics,"257914648  by lzc:

    Internal changes

--
257525973  by Zhichao Lu:

    Fixes bug that silently prevents checkpoints from loading when training w/ eager + functions. Also sets up scripts to run training.

--
257296614  by Zhichao Lu:

    Adding detection_features to model outputs

--
257234565  by Zhichao Lu:

    Fix wrong order of `classes_with_max_scores` in class-agnostic NMS caused by
    sorting in partitioned-NMS.

--
257232002  by ronnyvotel:

    Supporting `filter_nonoverlapping` option in np_box_list_ops.clip_to_window().

--
257198282  by Zhichao Lu:

    Adding the focal loss and l1 loss from the Objects as Points paper.

--
257089535  by Zhichao Lu:

    Create Keras based ssd + resnetv1 + fpn.

--
257087407  by Zhichao Lu:

    Make object_detection/data_decoders Python3-compatible.

--
257004582  by Zhichao Lu:

    Updates _decode_raw_data_into_masks_and_boxes to the latest binary masks-to-string encoding format.

--
257002124  by Zhichao Lu:

    Make object_detection/utils Python3-compatible, except json_utils.

    The patching trick used in json_utils is not going to work in Python 3.

--
256795056  by lzc:

    Add a detection_anchor_indices field to detection outputs.

--
256477542  by Zhichao Lu:

    Make object_detection/core Python3-compatible.

--
256387593  by Zhichao Lu:

    Edit class_id_function_approximations builder to skip class ids not present in label map.

--
256259039  by Zhichao Lu:

    Move NMS to TPU for FasterRCNN.

--
256071360  by rathodv:

    When multiclass_scores is empty, add one-hot encoding of groundtruth_classes as multiclass scores so that data_augmentation ops that expect the presence of multiclass_scores don't have to individually handle this case.

    Also copy input tensor_dict to out_tensor_dict first to avoid inplace modification.

--
256023645  by Zhichao Lu:

    Adds the first WIP iterations of TensorFlow v2 eager + functions style custom training & evaluation loops.

--
255980623  by Zhichao Lu:

    Adds a new data augmentation operation ""remap_labels"" which remaps a set of labels to a new label.

--
255753259  by Zhichao Lu:

    Announcement of the released evaluation tutorial for Open Images Challenge
    2019.

--
255698776  by lzc:

    Fix rewrite_nn_resize_op function which was broken by tf forward compatibility movement.

--
255623150  by Zhichao Lu:

    Add Keras-based ResnetV1 models.

--
255504992  by Zhichao Lu:

    Fixing the typo in specifying label expansion for ground truth segmentation
    file.

--
255470768  by Zhichao Lu:

    1. Fixing Python bug with parsed arguments.
    2. Adding capability to parse relevant columns from CSV header.
    3. Fixing bug with duplicated labels expansion.

--
255462432  by Zhichao Lu:

    Adds a new data augmentation operation ""drop_label_probabilistically"" which drops a given label with the given probability. This supports experiments on training in the presence of label noise.

--
255441632  by rathodv:

    Fallback on groundtruth classes when multiclass_scores tensor is empty.

--
255434899  by Zhichao Lu:

    Ensuring evaluation binary can run even with big files by synchronizing
    processing of ground truth and predictions: in this way, ground truth is not stored but immediatly
    used for evaluation. In case gt of object masks, this allows to run
    evaluations on relatively large sets.

--
255337855  by lzc:

    Internal change.

--
255308908  by Zhichao Lu:

    Add comment to clarify usage of calibration parameters proto.

--
255266371  by Zhichao Lu:

    Ensuring correct processing of the case, when no groundtruth masks are provided
    for an image.

--
255236648  by Zhichao Lu:

    Refactor model_builder in faster_rcnn.py to a util_map, so that it's possible to be overwritten.

--
255093285  by Zhichao Lu:

    Updating capability to subsample data during evaluation

--
255081222  by rathodv:

    Convert groundtruth masks to be of type float32 before its used in the loss function.

    When using mixed precision training, masks are represented using bfloat16 tensors in the input pipeline for performance reasons. We need to convert them to float32 before using it in the loss function.

--
254788436  by Zhichao Lu:

    Add forward_compatible to non_max_suppression_with_scores to make it is
    compatible with older tensorflow version.

--
254442362  by Zhichao Lu:

    Add num_layer field to ssd feature extractor proto.

--
253911582  by jonathanhuang:

    Plumbs Soft-NMS options (using the new tf.image.non_max_suppression_with_scores op) into the TF Object Detection API.  It adds a `soft_nms_sigma` field to the postprocessing proto file and plumbs this through to both the multiclass and class_agnostic versions of NMS. Note that there is no effect on behavior of NMS when soft_nms_sigma=0 (which it is set to by default).

    See also ""Soft-NMS -- Improving Object Detection With One Line of Code"" by Bodla et al (https://arxiv.org/abs/1704.04503)

--
253703949  by Zhichao Lu:

    Internal test fixes.

--
253151266  by Zhichao Lu:

    Fix the op type check for FusedBatchNorm, given that we introduced
    FusedBatchNormV3 in a previous change.

--
252718956  by Zhichao Lu:

    Customize activation function to enable relu6 instead of relu for saliency
    prediction model seastarization

--
252158593  by Zhichao Lu:

    Make object_detection/core Python3-compatible.

--
252150717  by Zhichao Lu:

    Make object_detection/core Python3-compatible.

--
251967048  by Zhichao Lu:

    Make GraphRewriter proto extensible.

--
251950039  by Zhichao Lu:

    Remove experimental_export_device_assignment from TPUEstimator.export_savedmodel(), so as to remove rewrite_for_inference().

    As a replacement, export_savedmodel() V2 API supports device_assignment where user call tpu.rewrite in model_fn and pass in device_assigment there.

--
251890697  by rathodv:

    Updated docstring to include new output nodes.

--
251662894  by Zhichao Lu:

    Add autoaugment augmentation option to objection detection api codebase. This
    is an available option in preprocessor.py.

    The intended usage of autoaugment is to be done along with random flipping and
    cropping for best results.

--
251532908  by Zhichao Lu:

    Add TrainingDataType enum to track whether class-specific or agnostic data was used to fit the calibration function.

    This is useful, since classes with few observations may require a calibration function fit on all classes.

--
251511339  by Zhichao Lu:

    Add multiclass isotonic regression to the calibration builder.

--
251317769  by pengchong:

    Internal Change.

--
250729989  by Zhichao Lu:

    Fixing bug in gt statistics count in case of mask and box annotations.

--
250729627  by Zhichao Lu:

    Label expansion for segmentation.

--
250724905  by Zhichao Lu:

    Fix use_depthwise in fpn and test it with fpnlite on ssd + mobilenet v2.

--
250670379  by Zhichao Lu:

    Internal change

250630364  by lzc:

    Fix detection_model_zoo footnotes

--
250560654  by Zhichao Lu:

    Fix static shape issue in matmul_crop_and_resize.

--
250534857  by Zhichao Lu:

    Edit class agnostic calibration function docstring to more accurately describe the function's outputs.

--
250533277  by Zhichao Lu:

    Edit the multiclass messages to use class ids instead of labels.

--

PiperOrigin-RevId: 257914648",pkulzc,b'cla: yes',2019-07-13T04:11:01Z,2019-09-03T06:29:03Z,,,,,,,
7198,how to valid the youtube dataset （In youtube dataset the valid data‘s annotation dir images number is not equal with JPEGimage dir images）,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",Linjiehua,b'stat:awaiting response type:support',2019-07-12T02:39:46Z,2020-07-29T07:26:53Z,,,,,,,
7197,Release OpenImage 2019 metrics,"257525973  by Zhichao Lu:

    Fixes bug that silently prevents checkpoints from loading when training w/ eager + functions. Also sets up scripts to run training.

--
257296614  by Zhichao Lu:

    Adding detection_features to model outputs

--
257234565  by Zhichao Lu:

    Fix wrong order of `classes_with_max_scores` in class-agnostic NMS caused by
    sorting in partitioned-NMS.

--
257232002  by ronnyvotel:

    Supporting `filter_nonoverlapping` option in np_box_list_ops.clip_to_window().

--
257198282  by Zhichao Lu:

    Adding the focal loss and l1 loss from the Objects as Points paper.

--
257089535  by Zhichao Lu:

    Create Keras based ssd + resnetv1 + fpn.

--
257087407  by Zhichao Lu:

    Make object_detection/data_decoders Python3-compatible.

--
257004582  by Zhichao Lu:

    Updates _decode_raw_data_into_masks_and_boxes to the latest binary masks-to-string encoding format.

--
257002124  by Zhichao Lu:

    Make object_detection/utils Python3-compatible, except json_utils.

    The patching trick used in json_utils is not going to work in Python 3.

--
256795056  by lzc:

    Add a detection_anchor_indices field to detection outputs.

--
256477542  by Zhichao Lu:

    Make object_detection/core Python3-compatible.

--
256387593  by Zhichao Lu:

    Edit class_id_function_approximations builder to skip class ids not present in label map.

--
256259039  by Zhichao Lu:

    Move NMS to TPU for FasterRCNN.

--
256071360  by rathodv:

    When multiclass_scores is empty, add one-hot encoding of groundtruth_classes as multiclass scores so that data_augmentation ops that expect the presence of multiclass_scores don't have to individually handle this case.

    Also copy input tensor_dict to out_tensor_dict first to avoid inplace modification.

--
256023645  by Zhichao Lu:

    Adds the first WIP iterations of TensorFlow v2 eager + functions style custom training & evaluation loops.

--
255980623  by Zhichao Lu:

    Adds a new data augmentation operation ""remap_labels"" which remaps a set of labels to a new label.

--
255753259  by Zhichao Lu:

    Announcement of the released evaluation tutorial for Open Images Challenge
    2019.

--
255698776  by lzc:

    Fix rewrite_nn_resize_op function which was broken by tf forward compatibility movement.

--
255623150  by Zhichao Lu:

    Add Keras-based ResnetV1 models.

--
255504992  by Zhichao Lu:

    Fixing the typo in specifying label expansion for ground truth segmentation
    file.

--
255470768  by Zhichao Lu:

    1. Fixing Python bug with parsed arguments.
    2. Adding capability to parse relevant columns from CSV header.
    3. Fixing bug with duplicated labels expansion.

--
255462432  by Zhichao Lu:

    Adds a new data augmentation operation ""drop_label_probabilistically"" which drops a given label with the given probability. This supports experiments on training in the presence of label noise.

--
255441632  by rathodv:

    Fallback on groundtruth classes when multiclass_scores tensor is empty.

--
255434899  by Zhichao Lu:

    Ensuring evaluation binary can run even with big files by synchronizing
    processing of ground truth and predictions: in this way, ground truth is not stored but immediatly
    used for evaluation. In case gt of object masks, this allows to run
    evaluations on relatively large sets.

--
255337855  by lzc:

    Internal change.

--
255308908  by Zhichao Lu:

    Add comment to clarify usage of calibration parameters proto.

--
255266371  by Zhichao Lu:

    Ensuring correct processing of the case, when no groundtruth masks are provided
    for an image.

--
255236648  by Zhichao Lu:

    Refactor model_builder in faster_rcnn.py to a util_map, so that it's possible to be overwritten.

--
255093285  by Zhichao Lu:

    Updating capability to subsample data during evaluation

--
255081222  by rathodv:

    Convert groundtruth masks to be of type float32 before its used in the loss function.

    When using mixed precision training, masks are represented using bfloat16 tensors in the input pipeline for performance reasons. We need to convert them to float32 before using it in the loss function.

--
254788436  by Zhichao Lu:

    Add forward_compatible to non_max_suppression_with_scores to make it is
    compatible with older tensorflow version.

--
254442362  by Zhichao Lu:

    Add num_layer field to ssd feature extractor proto.

--
253911582  by jonathanhuang:

    Plumbs Soft-NMS options (using the new tf.image.non_max_suppression_with_scores op) into the TF Object Detection API.  It adds a `soft_nms_sigma` field to the postprocessing proto file and plumbs this through to both the multiclass and class_agnostic versions of NMS. Note that there is no effect on behavior of NMS when soft_nms_sigma=0 (which it is set to by default).

    See also ""Soft-NMS -- Improving Object Detection With One Line of Code"" by Bodla et al (https://arxiv.org/abs/1704.04503)

--
253703949  by Zhichao Lu:

    Internal test fixes.

--
253151266  by Zhichao Lu:

    Fix the op type check for FusedBatchNorm, given that we introduced
    FusedBatchNormV3 in a previous change.

--
252718956  by Zhichao Lu:

    Customize activation function to enable relu6 instead of relu for saliency
    prediction model seastarization

--
252158593  by Zhichao Lu:

    Make object_detection/core Python3-compatible.

--
252150717  by Zhichao Lu:

    Make object_detection/core Python3-compatible.

--
251967048  by Zhichao Lu:

    Make GraphRewriter proto extensible.

--
251950039  by Zhichao Lu:

    Remove experimental_export_device_assignment from TPUEstimator.export_savedmodel(), so as to remove rewrite_for_inference().

    As a replacement, export_savedmodel() V2 API supports device_assignment where user call tpu.rewrite in model_fn and pass in device_assigment there.

--
251890697  by rathodv:

    Updated docstring to include new output nodes.

--
251662894  by Zhichao Lu:

    Add autoaugment augmentation option to objection detection api codebase. This
    is an available option in preprocessor.py.

    The intended usage of autoaugment is to be done along with random flipping and
    cropping for best results.

--
251532908  by Zhichao Lu:

    Add TrainingDataType enum to track whether class-specific or agnostic data was used to fit the calibration function.

    This is useful, since classes with few observations may require a calibration function fit on all classes.

--
251511339  by Zhichao Lu:

    Add multiclass isotonic regression to the calibration builder.

--
251317769  by pengchong:

    Internal Change.

--
250729989  by Zhichao Lu:

    Fixing bug in gt statistics count in case of mask and box annotations.

--
250729627  by Zhichao Lu:

    Label expansion for segmentation.

--
250724905  by Zhichao Lu:

    Fix use_depthwise in fpn and test it with fpnlite on ssd + mobilenet v2.

--
250670379  by Zhichao Lu:

    Internal change

250630364  by lzc:

    Fix detection_model_zoo footnotes

--
250560654  by Zhichao Lu:

    Fix static shape issue in matmul_crop_and_resize.

--
250534857  by Zhichao Lu:

    Edit class agnostic calibration function docstring to more accurately describe the function's outputs.

--
250533277  by Zhichao Lu:

    Edit the multiclass messages to use class ids instead of labels.

--

PiperOrigin-RevId: 257525973",pkulzc,b'cla: yes',2019-07-11T21:02:03Z,2019-07-13T03:48:11Z,,,,,,,
7184,Transformer training error with evaluation/test dataset newstest2014.de ,"Please make sure that this is a bug. As per our GitHub Policy, we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template

System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes (only changed batch/filter size on modelparams.py)
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: n/a
TensorFlow installed from (source or binary): https://hub.docker.com/r/tensorflow/tensorflow nightly-gpu-py3
TensorFlow version (use command below): 1.15
Python version: 3.6
Bazel version (if compiling from source): n/a
GCC/Compiler version (if compiling from source): n/a
CUDA/cuDNN version: 10.1
GPU model and memory: NVIDIA RTX 8000 x2 (wNVLINK)
You can collect some of this information using our environment capture
script
You can also obtain the TensorFlow version with: 1. TF 1.0: python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)"" 2. TF 2.0: python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""

Describe the current behavior
When following the transformer walkthrough There seems to be an issue with the newstest2014.de 'Download and preprocess datasets' step the newstest2014.de doesn't appear to be in valid text format. When its unpacked it cannot be opened as a text file (looks like another archive file) as the newstest2014.en can and was in previous versions.


For example: when I run the following command (after completing the rest of the requisite steps):

**Exact command to reproduce**
 python3 transformer_main.py --data_dir=$DATA_DIR --model_dir=$MODEL_DIR --vocab_file=$VOCAB_FILE --param_set=$PARAM_SET --bleu_source=$DATA_DIR/newstest2014.en --bleu_ref=$DATA_DIR/newstest2014.de --train_steps=250000 --steps_between_evals=10000 **--export_dir=$EXPORT_DIR

**What is the top-level directory of the model you are using**
models/official/transformer/

I get the error ( see attached/below for traceback) UnicodeDecodeError: 'utf8' codec can't decode byte 0x8b in position 1: invalid start byte

Describe the expected behavior
compute_bleu.py should work, but does not (only when i replace newstest2014.de with an older version (text format)

Code to reproduce the issue
Provide a reproducible test case that is the bare minimum necessary to generate the problem.
Follow the example walkthrough, you'll get invalid newstest2014.de (as of 7/8/19)

Other info / logs see attached for traceback as well
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

As it currently stands, training only worked when i replaced the invalid newstest2014.de file with the older version, therefore i think thats the error.

I0708 18:55:13.764734 140267571169088 translate.py:133] Writing to file /tmp/tmpie7053oh
Traceback (most recent call last):
File ""transformer_main.py"", line 670, in 
absl_app.run(main)
File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 300, in run
_run_main(main, args)
File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 251, in _run_main
sys.exit(main(argv))
File ""transformer_main.py"", line 664, in main
run_transformer(flags.FLAGS)
File ""transformer_main.py"", line 644, in run_transformer
vocab_file=flags_obj.vocab_file)
File ""transformer_main.py"", line 361, in run_loop
estimator, bleu_source, bleu_ref, vocab_file)
File ""transformer_main.py"", line 238, in evaluate_and_log_bleu
estimator, subtokenizer, bleu_source, bleu_ref)
File ""transformer_main.py"", line 222, in translate_and_compute_bleu
uncased_score = compute_bleu.bleu_wrapper(bleu_ref, tmp_filename, False)
File ""/datasets/datasets/models/official/transformer/compute_bleu.py"", line 91, in bleu_wrapper
tf.io.gfile.GFile(ref_filename).read()).strip().splitlines()
File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/lib/io/file_io.py"", line 128, in read
pywrap_tensorflow.ReadFromStream(self._read_buf, length))
File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/lib/io/file_io.py"", line 98, in _prepare_value
return compat.as_str_any(val)
File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/compat.py"", line 117, in as_str_any
return as_str(value)
File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/compat.py"",
[traceback1.txt](https://github.com/tensorflow/models/files/3375753/traceback1.txt)
 line 87, in as_text
return bytes_or_text.decode(encoding)
UnicodeDecodeError: 'utf-8' codec can't decode byte 0x8b in position 1: invalid start byte",Montantes,b'models:official',2019-07-10T04:40:26Z,2020-05-10T06:04:48Z,,,,,,,
7177,"Update adversarial_crypto to tf 1.14 syntax, fix bug #7125 ","Needed additional expand for conv2d. 

Suppress compat warnings by moving to compat.v1 versions of some functions.

Note that this code is not 2.0 compatible yet - that will be a future set of changes.",dave-andersen,b'cla: yes',2019-07-09T15:48:21Z,2019-07-09T19:26:40Z,,,,,,,
7155,s3dg issue,"### System information
- **What is the top-level directory of the model you are using**: slim
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: 16.04
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.13.1
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:10.0
- **GPU model and memory**: GTX 1080
- **Exact command to reproduce**: see code below. Ran this in a python script with tensorflow_io installed.


### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.
I am feeding images with 5-D shape and dtype of uint8, as specified by the documentation s3dg However, bug arises saying that I am feeding a float
## Error:
```
Traceback (most recent call last):
  File ""test.py"", line 29, in <module>
    features,info = s3dg.s3dg(nxt)
  File ""/home/hollowgalaxy/Github/models/research/slim/nets/s3dg.py"", line 570, in s3dg
    scope=scope)
  File ""/home/hollowgalaxy/Github/models/research/slim/nets/s3dg.py"", line 228, in s3dg_base
    scope=end_point)
  File ""/home/hollowgalaxy/anaconda3/envs/py36/lib/python3.7/site-packages/tensorflow/contrib/framework/python/ops/arg_scope.py"", line 182, in func_with_args
    return func(*args, **current_args)
  File ""/home/hollowgalaxy/Github/models/research/slim/nets/i3d_utils.py"", line 170, in conv3d_spatiotemporal
    scope=scope)
  File ""/home/hollowgalaxy/anaconda3/envs/py36/lib/python3.7/site-packages/tensorflow/contrib/framework/python/ops/arg_scope.py"", line 182, in func_with_args
    return func(*args, **current_args)
  File ""/home/hollowgalaxy/anaconda3/envs/py36/lib/python3.7/site-packages/tensorflow/contrib/layers/python/layers/layers.py"", line 1198, in convolution3d
    conv_dims=3)
  File ""/home/hollowgalaxy/anaconda3/envs/py36/lib/python3.7/site-packages/tensorflow/contrib/framework/python/ops/arg_scope.py"", line 182, in func_with_args
    return func(*args, **current_args)
  File ""/home/hollowgalaxy/anaconda3/envs/py36/lib/python3.7/site-packages/tensorflow/contrib/layers/python/layers/layers.py"", line 1058, in convolution
    outputs = layer.apply(inputs)
  File ""/home/hollowgalaxy/anaconda3/envs/py36/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py"", line 1227, in apply
    return self.__call__(inputs, *args, **kwargs)
  File ""/home/hollowgalaxy/anaconda3/envs/py36/lib/python3.7/site-packages/tensorflow/python/layers/base.py"", line 530, in __call__
    outputs = super(Layer, self).__call__(inputs, *args, **kwargs)
  File ""/home/hollowgalaxy/anaconda3/envs/py36/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py"", line 538, in __call__
    self._maybe_build(inputs)
  File ""/home/hollowgalaxy/anaconda3/envs/py36/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py"", line 1603, in _maybe_build
    self.build(input_shapes)
  File ""/home/hollowgalaxy/anaconda3/envs/py36/lib/python3.7/site-packages/tensorflow/python/keras/layers/convolutional.py"", line 165, in build
    dtype=self.dtype)
  File ""/home/hollowgalaxy/anaconda3/envs/py36/lib/python3.7/site-packages/tensorflow/python/layers/base.py"", line 435, in add_weight
    getter=vs.get_variable)
  File ""/home/hollowgalaxy/anaconda3/envs/py36/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py"", line 349, in add_weight
    aggregation=aggregation)
  File ""/home/hollowgalaxy/anaconda3/envs/py36/lib/python3.7/site-packages/tensorflow/python/training/checkpointable/base.py"", line 607, in _add_variable_with_custom_getter
    **kwargs_for_getter)
  File ""/home/hollowgalaxy/anaconda3/envs/py36/lib/python3.7/site-packages/tensorflow/python/ops/variable_scope.py"", line 1479, in get_variable
    aggregation=aggregation)
  File ""/home/hollowgalaxy/anaconda3/envs/py36/lib/python3.7/site-packages/tensorflow/python/ops/variable_scope.py"", line 1220, in get_variable
    aggregation=aggregation)
  File ""/home/hollowgalaxy/anaconda3/envs/py36/lib/python3.7/site-packages/tensorflow/python/ops/variable_scope.py"", line 530, in get_variable
    return custom_getter(**custom_getter_kwargs)
  File ""/home/hollowgalaxy/anaconda3/envs/py36/lib/python3.7/site-packages/tensorflow/contrib/layers/python/layers/layers.py"", line 1750, in layer_variable_getter
    return _model_variable_getter(getter, *args, **kwargs)
  File ""/home/hollowgalaxy/anaconda3/envs/py36/lib/python3.7/site-packages/tensorflow/contrib/layers/python/layers/layers.py"", line 1741, in _model_variable_getter
    aggregation=aggregation)
  File ""/home/hollowgalaxy/anaconda3/envs/py36/lib/python3.7/site-packages/tensorflow/contrib/framework/python/ops/arg_scope.py"", line 182, in func_with_args
    return func(*args, **current_args)
  File ""/home/hollowgalaxy/anaconda3/envs/py36/lib/python3.7/site-packages/tensorflow/contrib/framework/python/ops/variables.py"", line 350, in model_variable
    aggregation=aggregation)
  File ""/home/hollowgalaxy/anaconda3/envs/py36/lib/python3.7/site-packages/tensorflow/contrib/framework/python/ops/arg_scope.py"", line 182, in func_with_args
    return func(*args, **current_args)
  File ""/home/hollowgalaxy/anaconda3/envs/py36/lib/python3.7/site-packages/tensorflow/contrib/framework/python/ops/variables.py"", line 277, in variable
    aggregation=aggregation)
  File ""/home/hollowgalaxy/anaconda3/envs/py36/lib/python3.7/site-packages/tensorflow/python/ops/variable_scope.py"", line 499, in _true_getter
    aggregation=aggregation)
  File ""/home/hollowgalaxy/anaconda3/envs/py36/lib/python3.7/site-packages/tensorflow/python/ops/variable_scope.py"", line 911, in _get_single_variable
    aggregation=aggregation)
  File ""/home/hollowgalaxy/anaconda3/envs/py36/lib/python3.7/site-packages/tensorflow/python/ops/variables.py"", line 213, in __call__
    return cls._variable_v1_call(*args, **kwargs)
  File ""/home/hollowgalaxy/anaconda3/envs/py36/lib/python3.7/site-packages/tensorflow/python/ops/variables.py"", line 176, in _variable_v1_call
    aggregation=aggregation)
  File ""/home/hollowgalaxy/anaconda3/envs/py36/lib/python3.7/site-packages/tensorflow/python/ops/variables.py"", line 155, in <lambda>
    previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)
  File ""/home/hollowgalaxy/anaconda3/envs/py36/lib/python3.7/site-packages/tensorflow/python/ops/variable_scope.py"", line 2495, in default_variable_creator
    expected_shape=expected_shape, import_scope=import_scope)
  File ""/home/hollowgalaxy/anaconda3/envs/py36/lib/python3.7/site-packages/tensorflow/python/ops/variables.py"", line 217, in __call__
    return super(VariableMetaclass, cls).__call__(*args, **kwargs)
  File ""/home/hollowgalaxy/anaconda3/envs/py36/lib/python3.7/site-packages/tensorflow/python/ops/variables.py"", line 1395, in __init__
    constraint=constraint)
  File ""/home/hollowgalaxy/anaconda3/envs/py36/lib/python3.7/site-packages/tensorflow/python/ops/variables.py"", line 1503, in _init_from_args
    initial_value(), name=""initial_value"", dtype=dtype)
  File ""/home/hollowgalaxy/anaconda3/envs/py36/lib/python3.7/site-packages/tensorflow/python/ops/variable_scope.py"", line 883, in <lambda>
    shape.as_list(), dtype=dtype, partition_info=partition_info)
  File ""/home/hollowgalaxy/anaconda3/envs/py36/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py"", line 345, in __call__
    shape, self.mean, self.stddev, dtype, seed=self.seed)
  File ""/home/hollowgalaxy/anaconda3/envs/py36/lib/python3.7/site-packages/tensorflow/python/ops/random_ops.py"", line 174, in truncated_normal
    mean_tensor = ops.convert_to_tensor(mean, dtype=dtype, name=""mean"")
  File ""/home/hollowgalaxy/anaconda3/envs/py36/lib/python3.7/site-packages/tensorflow/python/framework/ops.py"", line 1039, in convert_to_tensor
    return convert_to_tensor_v2(value, dtype, preferred_dtype, name)
  File ""/home/hollowgalaxy/anaconda3/envs/py36/lib/python3.7/site-packages/tensorflow/python/framework/ops.py"", line 1097, in convert_to_tensor_v2
    as_ref=False)
  File ""/home/hollowgalaxy/anaconda3/envs/py36/lib/python3.7/site-packages/tensorflow/python/framework/ops.py"", line 1175, in internal_convert_to_tensor
    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
  File ""/home/hollowgalaxy/anaconda3/envs/py36/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py"", line 304, in _constant_tensor_conversion_function
    return constant(v, dtype=dtype, name=name)
  File ""/home/hollowgalaxy/anaconda3/envs/py36/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py"", line 245, in constant
    allow_broadcast=True)
  File ""/home/hollowgalaxy/anaconda3/envs/py36/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py"", line 283, in _constant_impl
    allow_broadcast=allow_broadcast))
  File ""/home/hollowgalaxy/anaconda3/envs/py36/lib/python3.7/site-packages/tensorflow/python/framework/tensor_util.py"", line 466, in make_tensor_proto
    _AssertCompatible(values, dtype)
  File ""/home/hollowgalaxy/anaconda3/envs/py36/lib/python3.7/site-packages/tensorflow/python/framework/tensor_util.py"", line 371, in _AssertCompatible
    (dtype.name, repr(mismatch), type(mismatch).__name__))
TypeError: Expected uint8, got 0.0 of type 'float' instead.
```

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.

```
from pathlib import Path

import tensorflow as tf
import nets.s3dg as s3dg
from tensorflow_io.video import VideoDataset

video_path = Path.home()/'Desktop/1_minute.mp4'  # any video would suffice


video_path_ph = tf.placeholder(tf.string)

video = VideoDataset(video_path_ph)

video = video.batch(32).batch(1)

itr = video.make_initializable_iterator()
nxt = itr.get_next()
# nxt = Tensor(""IteratorGetNext:0"", shape=(?, ?, ?, ?, 3), dtype=uint8)
features,info = s3dg.s3dg(nxt)
```
Mentioning @pkulzc as you were made the last change on this model.",hollowgalaxy,None,2019-07-05T01:59:39Z,2019-07-05T15:46:55Z,,,,,,,
7143,Trained only the RPN in Faster R-CNN and when I am trying to run eval.py or the export_inference_graph.py I get this error . OP_REQUIRES failed at save_restore_v2_ops.cc:184 : Not found: Key SecondStageBoxPredictor/BoxEncodingPredictor/biases not found in checkpoint.,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",PallawiSinghal,None,2019-07-03T10:10:40Z,2019-07-03T10:36:02Z,,,,,,,
7140,how can I using i3d net to train? cansomeone help,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",YAwei666,b'models:research type:support',2019-07-02T13:41:12Z,2020-07-29T07:30:04Z,,,,,,,
7136,`pip install object-detection` does not work,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

### Describe the problem
Since I notice we can use `pip install object-detection`[Here](https://pypi.org/project/object-detection/) to install `Object Detection API`， it will be easy to install API.Howerver,It does not include `pycocotools`.How can I fix it？

### Source code / logs
from object_detection import model_lib
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/usr/local/lib/python3.5/dist-packages/object_detection/model_lib.py"", line 27, in <module>
    from object_detection import eval_util
  File ""/usr/local/lib/python3.5/dist-packages/object_detection/eval_util.py"", line 27, in <module>
    from object_detection.metrics import coco_evaluation
  File ""/usr/local/lib/python3.5/dist-packages/object_detection/metrics/coco_evaluation.py"", line 20, in <module>
    from object_detection.metrics import coco_tools
  File ""/usr/local/lib/python3.5/dist-packages/object_detection/metrics/coco_tools.py"", line 47, in <module>
    from pycocotools import coco
ImportError: No module named 'pycocotools'

",DeepTecher,None,2019-07-02T01:20:57Z,2019-07-03T07:04:50Z,,,,,,,
7131,how extract batch_size image delf features? extract delf features too slow.,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",swpucl,None,2019-07-01T08:48:33Z,2019-07-02T09:00:10Z,,,,,,,
7129,no module name tensorflow,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",TamEmbedded,None,2019-07-01T07:35:19Z,2019-07-02T22:21:11Z,,,,,,,
7110,"Hi please been trying to run my tensorflow model but i keep getting this errors Traceback (most recent call last):   File ""C:\Tensorflow\models\research\object_detection\object_detection.py"", line 40, in <module>     from utils import label_map_util   File ""C:\Tensorflow\models\research\object_detection\utils\label_map_util.py"", line 21, in <module>     from object_detection.protos import string_int_label_map_pb2   File ""C:\Tensorflow\models\research\object_detection\object_detection.py"", line 42, in <module>     from utils import visualization_utils as vis_util   File ""C:\Tensorflow\models\research\object_detection\utils\visualization_utils.py"", line 35, in <module>     from object_detection.core import standard_fields as fields ModuleNotFoundError: No module named 'object_detection.core'; 'object_detection' is not a package","Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",Folawixo,b'models:research',2019-06-27T01:45:02Z,2020-03-25T23:01:33Z,,,,,,,
7099,The evaluation total loss is missing,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**: models/research/object_detection/legacy
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: 
NO
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: Anaconda
- **TensorFlow version (use command below)**: 13.1
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**: 9.0
- **GPU model and memory**: TITAN Xp
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

### Describe the problem
When I tried to plot the training loss and evaluation loss by using tensorboard at the same time, I found the evaluation total loss and clone loss are missing, I only can see training total loss and clone loss. Other types of losses are right.
![Screenshot from 2019-06-25 19-03-21](https://user-images.githubusercontent.com/30953107/60096759-5fc90e80-9784-11e9-9ebc-98b42d544411.png)

Is this anybody know how to resolve this problem?


### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",frankdeepl,None,2019-06-25T12:00:14Z,2019-06-26T07:00:05Z,,,,,,,
7093,Merged commit includes the following changes:,"Merged commit includes the following changes:
254785517  by A. Unique TensorFlower<gardener@tensorflow.org>:
    
    Use train_single_step for BERT GPU models to temporarily work around some performance bugs in GPU runs
    ",saberkun,b'cla: yes',2019-06-24T18:13:54Z,2019-06-24T18:25:49Z,,,,,,,
7091,How to train auto Deeplab,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using:model/
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: data path relevant
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: Conda
- **TensorFlow version (use command below)**: 1.9.0
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**: CUDA10 Cudnn7
- **GPU model and memory**: 12GBx4
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:
ValueError: Dimension 1 in both shapes must be equal, but are 33 and 65. Shapes are [?,33,33] and [?,65,65]. for 'concat' (op: 'ConcatV2') with input shapes: [?,33,33,256], [?,65,65,256], [] and with computed input tensors: input[2] = <3>.


How to run Auto Deeplab code?
I found that the code is integrated in train.py in model/research/deeplab/.  I modified the data path and model_variant parameters. but got error above. 
I want to know How to train Auto Deeplab and what parameters I should tune?",xingjici,b'models:research',2019-06-24T12:27:46Z,2020-03-25T23:01:31Z,,,,,,,
7090,research/syntaxnet: Buggy handling of unicode when char is signed,"### System information
- **What is the top-level directory of the model you are using**: research/syntaxnet
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: n/a
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: n/a
- **TensorFlow installed from (source or binary)**: n/a
- **TensorFlow version (use command below)**: n/a
- **Bazel version (if compiling from source)**: n/a
- **CUDA/cuDNN version**: n/a
- **GPU model and memory**: n/a
- **Exact command to reproduce** n/a:

### Describe the problem

`research/syntaxnet/util/utf8/unicodetext.cc` has several code locations which only work when the `char` data type is unsigned.

Class `const_iterator` declares the member variable `it_` of type `const char*` (see [code](https://github.com/tensorflow/models/blob/master/research/syntaxnet/util/utf8/unicodetext.h#L243)). If `char` is signed (the most common case), its value will be in the range -128...127, so a comparison `it_[0] < 0x80` won't work as expected but always return true ([see example of bad code](https://github.com/tensorflow/models/blob/master/research/syntaxnet/util/utf8/unicodetext.cc#L461), more wrong code in the same file).

Buggy functions:

- UnicodeText::const_iterator::operator*
- UnicodeText::const_iterator::get_utf8
- UnicodeText::const_iterator::utf8_length

That problem was found while debugging test code for Tesseract OCR.

### Source code / logs
n/a",stweil,b'models:research',2019-06-24T10:13:26Z,2019-07-20T15:22:06Z,,,,,,,
7077,Transformer Keras: Use add_loss instead of loss layer,"model.add_loss is (1) simpler (2) works in both 1.x and 2.0 with distribution strategy.
Using the loss layer has a bug with 1.x + distribution strategy that we do not have an easy way to fix. ",guptapriya,b'cla: yes',2019-06-21T06:12:44Z,2020-03-17T03:59:31Z,,,,,,,
7062,matport text graph,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",buaacarzp,b'type:support',2019-06-20T03:33:04Z,2020-03-25T23:01:29Z,,,,,,,
7043,Dataset.map(tf.keras.applications.vgg16.preprocess_input) -> AttributeError: 'Tensor' object has no attribute '_datatype_enum',"### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes. Small error-reproducing script provided below
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 18.04
- **TensorFlow installed from (source or binary)**: Binary (Python 3.6)
- **TensorFlow version (use command below)**: 2.0, nightly installed 6/18/19
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**: CPU only
- **GPU model and memory**:
- **Exact command to reproduce**: python map_bug.py, script provided below

### Describe the problem

Just installed nightly to make sure this hadn't been caught yet--I am trying to do some map() operations on a dataset, nothing fancy. If I build only one dataset in a  script, it works fine. If I do it twice, however--for instance, make a train and hold-out set using the same operations--I get this mysterious error message. Pretty sure this cannot be intended behavior.

### Source code / logs

Originally this was done in a large project. But I did a bit of work and whittled it down to the following script, which just uses MNIST to reproduce the error:

```
import tensorflow as tf
from tensorflow.keras import datasets
import numpy as np
BATCH_SIZE = 128


def size_image_for_vgg(image):
    return tf.image.resize(image, [224, 224])


if __name__ == '__main__':
    # punch up mnist
    (train_images, train_labels), (test_images, test_labels) = datasets.mnist.load_data()
    train_images = train_images.reshape((60000, 28, 28, 1)).astype(np.float32) / 255.0
    test_images = test_images.reshape((10000, 28, 28, 1)).astype(np.float32) / 255.0

    # Now create a dataset
    im_ds = tf.data.Dataset.from_tensor_slices(train_images)
    label_ds = tf.data.Dataset.from_tensor_slices(train_labels)
    im_ds_t = tf.data.Dataset.from_tensor_slices(test_images)
    label_ds_t = tf.data.Dataset.from_tensor_slices(test_labels)

    # If this block is commented out, the block below it will NOT throw any error
    # do some normal Dataset operations on test and train data like we're getting ready to fit a model
    im_ds = im_ds.map(size_image_for_vgg, num_parallel_calls=tf.data.experimental.AUTOTUNE)
    im_ds = im_ds.map(tf.keras.applications.vgg16.preprocess_input, num_parallel_calls=tf.data.experimental.AUTOTUNE)
    train_ds = tf.data.Dataset.zip((im_ds, label_ds))
    train_ds = train_ds.apply(tf.data.experimental.shuffle_and_repeat(buffer_size=1000))
    train_ds = train_ds.batch(batch_size=BATCH_SIZE)

    im_ds_t = im_ds_t.map(size_image_for_vgg, num_parallel_calls=tf.data.experimental.AUTOTUNE)
    # TODO throws error if you do it a second time?
    im_ds_t = im_ds_t.map(tf.keras.applications.vgg16.preprocess_input, num_parallel_calls=tf.data.experimental.AUTOTUNE)
    test_ds = tf.data.Dataset.zip((im_ds_t, label_ds_t))
    test_ds = test_ds.batch(batch_size=BATCH_SIZE)
```

### Stack trace
Traceback (most recent call last):
  File ""map_bug.py"", line 33, in <module>
    im_ds_t = im_ds_t.map(tf.keras.applications.vgg16.preprocess_input, num_parallel_calls=tf.data.experimental.AUTOTUNE)
  File ""/home/menarcj/OtherSoftware/miniconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/data/ops/dataset_ops.py"", line 1141, in map
    self, map_func, num_parallel_calls, preserve_cardinality=True)
  File ""/home/menarcj/OtherSoftware/miniconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/data/ops/dataset_ops.py"", line 3320, in __init__
    **flat_structure(self))
  File ""/home/menarcj/OtherSoftware/miniconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/ops/gen_dataset_ops.py"", line 4141, in parallel_map_dataset
    preserve_cardinality=preserve_cardinality, name=name, ctx=_ctx)
  File ""/home/menarcj/OtherSoftware/miniconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/ops/gen_dataset_ops.py"", line 4224, in parallel_map_dataset_eager_fallback
    _attr_Targuments, other_arguments = _execute.convert_to_mixed_eager_tensors(other_arguments, _ctx)
  File ""/home/menarcj/OtherSoftware/miniconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/eager/execute.py"", line 210, in convert_to_mixed_eager_tensors
    types = [t._datatype_enum() for t in v]  # pylint: disable=protected-access
  File ""/home/menarcj/OtherSoftware/miniconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/eager/execute.py"", line 210, in <listcomp>
    types = [t._datatype_enum() for t in v]  # pylint: disable=protected-access
AttributeError: 'Tensor' object has no attribute '_datatype_enum'



",CJMenart,None,2019-06-18T13:35:44Z,2019-06-18T20:34:13Z,,,,,,,
7037,AssertionError: `train_dir` is missing.,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- I am implementing the procedure from this blog post. Which is similar - 
https://www.freecodecamp.org/news/how-to-play-quidditch-using-the-tensorflow-object-detection-api-b0742b99065d/

- No I didn't
- Windows 10
- Tensorflow installed in pycharm
- Tensorflow 1.8
- **Bazel version (if compiling from source)**:
- 
- NVIDIA 1050ti
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

### Describe the problem
When I am trying to run
python object_detection/train.py \--logtostderr \--pipeline_config_path=pipeline.config \--train_dir=train
this command for object detection using Tensorflow I'm getting this error -
AssertionError: `train_dir` is missing.

I have tried to find for a solution but couldn't find one. Not sure where is the problem. 

### Source code / logs
Traceback (most recent call last):
  File ""object_detection/train.py"", line 163, in <module>
    tf.app.run()
  File ""C:\Users\User\Anaconda3\envs\Quidditch\lib\site-packages\tensorflow\python\pla
tform\app.py"", line 126, in run
    _sys.exit(main(argv))
  File ""object_detection/train.py"", line 87, in main
    assert FLAGS.train_dir, '`train_dir` is missing.'
AssertionError: `train_dir` is missing.
",Iqbal0007,b'models:research',2019-06-17T16:14:18Z,2020-05-12T13:37:26Z,,,,,,,
7036,AttributeError: module 'tensorflow' has no attribute 'contrib',"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Colab
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 2.0.0b1
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

!pip install -q tensorflow==2.0.0-beta1
from google.colab import auth
auth.authenticate_user()

### Describe the problem

Exception when authenticating in CoLab.

### Source code / logs

---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
<ipython-input-4-e9280defa4ea> in <module>()
     25 
     26 from google.colab import auth
---> 27 auth.authenticate_user()
     28 
     29 prepared_record_paths = tf.io.gfile.glob(training_data)

/usr/local/lib/python3.6/dist-packages/google/colab/auth.py in authenticate_user(clear_output)
    154       with tf.compat.v1.Session('grpc://{}'.format(colab_tpu_addr)) as sess:
    155         with open(_get_adc_path()) as auth_info:
--> 156           tf.contrib.cloud.configure_gcs(
    157               sess, credentials=_json.load(auth_info))
    158   if _check_adc():

AttributeError: module 'tensorflow' has no attribute 'contrib'",ssable,None,2019-06-17T16:03:24Z,2020-04-05T18:31:30Z,,,,,,,
7035,object_detection.py is not python3 ready,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**: /models/research/object_detection/
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: i am trying to run /models/research/object_detection/object_detection_tutorial.ipynb
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: docker image tensorflow/tensorflow:1.13.1-py3
- **TensorFlow installed from (source or binary)**: bundled with docker image 
- **TensorFlow version (use command below)**: 1.13.1
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**: no gpu acceleration used
- **GPU model and memory**: no gpu acceleration used
- **Exact command to reproduce**: python3 /models/research/object_detection/legacy/eval.py \
     --logtostderr \
     --pipeline_config_path=/ssd_model/ssdlite_mobilenetv2/pipeline.config \
     --checkpoint_dir=/ssd_model/train_logs \
     --eval_dir=/ssd_model/eval_logs

### Describe the problem
object_detection.py uses python2 exclusive unicode calls:
https://stackoverflow.com/questions/19877306/nameerror-global-name-unicode-is-not-defined-in-python-3


### Source code / logs
```
WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
If you depend on functionality not listed there, please file an issue.

Traceback (most recent call last):
  File ""/models/research/object_detection/legacy/eval.py"", line 142, in <module>
    tf.app.run()
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/platform/app.py"", line 125, in run
    _sys.exit(main(argv))
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/util/deprecation.py"", line 324, in new_func
    return func(*args, **kwargs)
  File ""/models/research/object_detection/legacy/eval.py"", line 138, in main
    graph_hook_fn=graph_rewriter_fn)
  File ""/models/research/object_detection/legacy/evaluator.py"", line 277, in evaluate
    evaluator_list = get_evaluators(eval_config, categories)
  File ""/models/research/object_detection/legacy/evaluator.py"", line 169, in get_evaluators
    EVAL_METRICS_CLASS_DICT[eval_metric_fn_key](categories=categories))
  File ""/models/research/object_detection/utils/object_detection_evaluation.py"", line 505, in __init__
    use_weighted_mean_ap=False)
  File ""/models/research/object_detection/utils/object_detection_evaluation.py"", line 222, in __init__
    self._build_metric_names()
  File ""/models/research/object_detection/utils/object_detection_evaluation.py"", line 248, in _build_metric_names
    category_name = unicode(category_name, 'utf-8')
NameError: name 'unicode' is not defined

```
",cguentherTUChemnitz,b'models:research',2019-06-17T15:04:47Z,2019-07-03T12:41:42Z,,,,,,,
7031,TypeError: resize_images() got an unexpected keyword argument 'preserve_aspect_r atio',"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",xiongcaihua,None,2019-06-17T11:43:47Z,2019-06-19T20:35:20Z,,,,,,,
7024,Object detection training is not starting as given for coral edge tpu,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",avinash00721,b'comp:lite models:research stat:awaiting model gardener type:bug',2019-06-15T17:38:07Z,2020-03-25T23:02:48Z,,,,,,,
7010,my output keras model is channel first? ,"Can anyone show me how to solve this?

Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",hackeritchy,None,2019-06-13T10:12:13Z,2019-06-13T11:03:42Z,,,,,,,
7008,Fine tuning generates incorrect variable values for quantized ssd mobilenet,"### System information

**What is the top-level directory of the model you are using:** object_detection
**Have I written custom code (as opposed to using a stock example script provided in TensorFlow):** No
**OS Platform and Distribution (e.g., Linux Ubuntu 16.04):** Linux Ubuntu 18.04
**TensorFlow installed from (source or binary)**: source
**TensorFlow version (use command below)**: 1.13.1
**Bazel version (if compiling from source)**: 0.24.1
**CUDA/cuDNN version**: N/A
**GPU model and memory**: N/A

### Repro instructions

**Issue 1: Fine-tuning from checkpoint causes fp32 inference to fail**

1. Download ssd_mobilenet_v1_quantized_coco from https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md and the 2017 coco data set from http://cocodataset.org/#download
2. Train from checkpoint (downloaded above) with 10 additional steps using command:
python object_detection/model_main.py --pipeline_config_path=object_detection/samples/configs/ssd_mobilenet_v1_quantized_300x300_coco14_sync.config --model_dir=data/ --alsologtostderr --quantize
3. Freeze values for fp32 graph using command:
python export_inference_graph.py --input_type image_tensor --pipeline_config_path=samples/configs/ssd_mobilenet_v1_quantized_300x300_coco14_sync.config --trained_checkpoint_prefix=../data/model.ckpt --output_directory=../data
4. Run inference on fp32 graph. Accuracy is now 0%.

**Issue 2: Pre-trained checkpoint gives incorrect min/max values for FakeQuantization resulting in poor int8 inference**

1. Download ssd_mobilenet_v1_quantized_coco from https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md
2. Freeze values for fp32 graph using command:
python export_inference_graph.py --input_type image_tensor --pipeline_config_path=samples/configs/ssd_mobilenet_v1_quantized_300x300_coco14_sync.config --trained_checkpoint_prefix=../data/model.ckpt --output_directory=../data
3. Quantize graph to generate int8 graph
4. Inference on fp32 graph gives expected accuracy but on int8 gives very poor accuracy. For inference I'm using a prebuild record file because using the downloaded coco dataset to generate a new record file results in errors during inference (all images skipped during inference).

**Setup:**

- This experiment is being run on CPU without tflite.

- Using steps described here: https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/running_locally.md

**Debugging notes**
The issue is almost certainly the fact that FakeQuantization min/max values in this checkpoint are incorrect. In particular, after fine-tuning (as in issue 1), we get min/max values of (0,6) as expected because the input comes from Relu6. On the other hand, min/max values without training (i.e. using the downloaded checkpoint) for the same node are (-25,32), which are certainly incorrect.

So, there are two problems here:
1. The pre-trained model checkpoint has incorrect min/max values
2. Fine tuning the checkpoint results in incorrect weights

Please let me know if there is any additional information that is required.
",sdamani-intel,b'comp:lite stat:awaiting model gardener',2019-06-12T17:57:14Z,2020-03-25T23:02:48Z,,,,,,,
7000,ll hopeful_ardinghelli,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",tactycHQ,None,2019-06-11T23:38:22Z,2019-06-11T23:38:41Z,,,,,,,
6995,can anyone tell me the reason why the object detection model takes 1 min for processing and produce the result,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",sreenupadidapu,None,2019-06-11T06:35:34Z,2019-06-15T18:34:32Z,,,,,,,
6994,How to create tfrecords to train lstm based object detection?,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",ghost,b'stat:awaiting response type:support',2019-06-11T03:34:48Z,2020-06-25T06:53:24Z,,,,,,,
6986,AttributeError: module 'tensorflow' has no attribute 'batch_gather',"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",fudemin1,None,2019-06-10T01:02:42Z,2019-06-26T21:32:05Z,,,,,,,
6983,What does max_detections_per_class and max_total_detections mean?,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",Prilyf,None,2019-06-09T10:25:06Z,2020-03-25T23:02:47Z,,,,,,,
6981,how do I deploy YOLO v2 model after trained locally ?,"### System information
- **What is the top-level directory of the model you are using**: YOLOv2
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: MSI 
- **TensorFlow installed from (source or binary)**: pip installed
- **TensorFlow version (use command below)**: tensorflow-gpu: 1.9
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**: geforce nvidia
- **GPU model and memory**:
- **Exact command to reproduce**: 


### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

1. I could not find any resources on deploying yolo v2 trained model for serving/production (real time prediction end point).

2. Also not able to get variables folder just like how can get in object detection API


",shivaram93,None,2019-06-07T07:30:03Z,2020-03-25T23:02:47Z,,,,,,,
6974,"(bytes_or_text,)) TypeError: Expected binary or unicode string, got None","Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",chiragbajaj25,b'stat:awaiting response type:support',2019-06-06T15:21:11Z,2020-06-25T06:57:09Z,,,,,,,
6970,transformer/v2,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**: https://github.com/tensorflow/models/tree/master/official/transformer/v2
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 18.04
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**: TF2.0 alpha
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**: CUDA 10.0
- **GPU model and memory**: Quadro GV100
- **Exact command to reproduce**:
export DATA_DIR=/home/maggie/Desktop/tensorflowModels/models/official/transformer/data
export MODEL_DIR=/home/maggie/Desktop/tensorflowModels/models/official/transformer/model_$PARAM_SET
export VOCAB_FILE=$DATA_DIR/vocab.ende.32768
python3 transformer_main.py --data_dir=$DATA_DIR --model_dir=$MODEL_DIR     --vocab_file=$VOCAB_FILE --param_set=$PARAM_SET

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.
Here is the output I got when I ran command ""python3 transformer_main.py --data_dir=$DATA_DIR --model_dir=$MODEL_DIR     --vocab_file=$VOCAB_FILE --param_set=$PARAM_SET""
2019-06-06 00:45:12.116713: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-06-06 00:45:12.143552: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: Quadro GV100 major: 7 minor: 0 memoryClockRate(GHz): 1.627
pciBusID: 0000:09:00.0
2019-06-06 00:45:12.143586: I tensorflow/stream_executor/platform/default/dlopen_checker.cc:62] Not built with GPU enabled. Skip GPU library dlopen check.
2019-06-06 00:45:12.146261: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-06-06 00:45:12.146505: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-06-06 00:45:12.247573: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x39cc710 executing computations on platform CUDA. Devices:
2019-06-06 00:45:12.247602: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Quadro GV100, Compute Capability 7.0
2019-06-06 00:45:12.269426: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3598280000 Hz
2019-06-06 00:45:12.270334: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x3911d60 executing computations on platform Host. Devices:
2019-06-06 00:45:12.270384: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-06-06 00:45:12.274456: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: Quadro GV100 major: 7 minor: 0 memoryClockRate(GHz): 1.627
pciBusID: 0000:09:00.0
2019-06-06 00:45:12.274482: I tensorflow/stream_executor/platform/default/dlopen_checker.cc:62] Not built with GPU enabled. Skip GPU library dlopen check.
2019-06-06 00:45:12.283583: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-06-06 00:45:12.290146: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-06-06 00:45:12.292086: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-06-06 00:45:12.292102: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-06-06 00:45:12.292108: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-06-06 00:45:12.295154: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 30582 MB memory) -> physical GPU (device: 0, name: Quadro GV100, pci bus id: 0000:09:00.0, compute capability: 7.0)
W0606 00:45:18.731456 139869725849408 training_utils.py:1101] Output logits missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to logits.
Model: ""model""
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
inputs (InputLayer)             [(None, None)]       0                                            
__________________________________________________________________________________________________
targets (InputLayer)            [(None, None)]       0                                            
__________________________________________________________________________________________________
transformer_v2 (Transformer)    (None, None, 33708)  210804736   inputs[0][0]                     
                                                                 targets[0][0]                    
__________________________________________________________________________________________________
metric_layer (MetricLayer)      (None, None, 33708)  0           transformer_v2[0][0]             
                                                                 targets[0][0]                    
__________________________________________________________________________________________________
loss_layer (LossLayer)          (None, None, 33708)  0           metric_layer[0][0]               
                                                                 targets[0][0]                    
__________________________________________________________________________________________________
logits (Lambda)                 (None, None, 33708)  0           loss_layer[0][0]                 
==================================================================================================
Total params: 210,804,736
Trainable params: 210,804,736
Non-trainable params: 0
__________________________________________________________________________________________________
2019-06-06 00:45:18.796342: W tensorflow/core/common_runtime/eager/context.cc:371] Added two functions with the same name: __inference_Dataset_flat_map_read_one_file_8184
Traceback (most recent call last):
  File ""transformer_main.py"", line 260, in <module>
    absl_app.run(main)
  File ""/home/maggie/.local/lib/python3.6/site-packages/absl/app.py"", line 300, in run
    _run_main(main, args)
  File ""/home/maggie/.local/lib/python3.6/site-packages/absl/app.py"", line 251, in _run_main
    sys.exit(main(argv))
  File ""transformer_main.py"", line 248, in main
    task.train()
  File ""transformer_main.py"", line 140, in train
    if flags_obj.train_steps < flags_obj.steps_between_evals:

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",maggiezha,b'models:official',2019-06-06T02:28:19Z,2019-06-18T21:04:07Z,,,,,,,
6951,Do not use XLA in warmup tests,"Because we run warmup tests in all real data benchmarks, XLA bugs will cause non-XLA tests to fail as well.",haoyuz,b'cla: yes',2019-06-03T17:32:39Z,2019-06-03T17:37:48Z,,,,,,,
6941,Can anyone tell me how to predict the captions with pre-trained model of show and tell image caption generator,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",Sparsh-Bansal,None,2019-06-02T18:20:57Z,2019-06-07T06:57:19Z,,,,,,,
6932,"Object detection: update postprocessing to allow class agnostic NMS, and other fixes/refactors","250447559  by Zhichao Lu:

    Update expected files format for Instance Segmentation challenge:
    - add fields ImageWidth, ImageHeight and store the values per prediction
    - as mask, store only encoded image and assume its size is ImageWidth x ImageHeight

--
250402780  by rathodv:

    Fix failing Mask R-CNN TPU convergence test.

    Cast second stage prediction tensors from bfloat16 to float32 to prevent errors in third target assignment (Mask Prediction) - Concat with different types bfloat16 and bfloat32 isn't allowed.

--
250300240  by Zhichao Lu:

    Addion Open Images Challenge 2019 object detection and instance segmentation
    support into Estimator framework.

--
249944839  by rathodv:

    Modify exporter.py to add multiclass score nodes in exported inference graphs.

--
249935201  by rathodv:

    Modify postprocess methods to preserve multiclass scores after non max suppression.

--
249878079  by Zhichao Lu:

    This CL slightly refactors some Object Detection helper functions for data creation, evaluation, and groundtruth providing.

    This will allow the eager+function custom loops to share code with the existing estimator training loops.

    Concretely we make the following changes:
    1. In input creation we separate dataset-creation into top-level helpers, and allow it to optionally accept a pre-constructed model directly instead of always creating a model from the config just for feature preprocessing.

    2. In coco evaluation we split the update_op creation into its own function, which the custom loops will call directly.

    3. In model_lib we move groundtruth providing/ datastructure munging into a helper function

    4. For now we put an escape hatch in `_summarize_target_assignment` when executing in tf v2.0 behavior because the summary apis used only work w/ tf 1.x

--
249673507  by rathodv:

    Use explicit casts instead of tf.to_float and tf.to_int32 to avoid warnings.

--
249656006  by Zhichao Lu:

    Add named ""raw_keypoint_locations"" node that corresponds with the ""raw_box_locations"" node.

--
249651674  by rathodv:

    Keep proposal boxes in float format. MatMulCropAndResize can handle the type even when feature themselves are bfloat16s.

--
249568633  by rathodv:

    Support q > 1 in class agnostic NMS.
    Break post_processing_test.py into 3 separate files to avoid linter errors.

--
249535530  by rathodv:

    Update some deprecated arguments to tf ops.

--
249368223  by rathodv:

    Modify MatMulCropAndResize to use MultiLevelRoIAlign method and move the tests to spatial_transform_ops.py module.

    This cl establishes that CropAndResize and RoIAlign are equivalent and only differ in the sampling point grid within the boxes. CropAndResize uses a uniform size x size point grid such that the corner points exactly overlap box corners, while RoiAlign divides boxes into size x size cells and uses their centers as sampling points. In this cl, we switch MatMulCropAndResize to use the MultiLevelRoIAlign implementation with `align_corner` option as MultiLevelRoIAlign implementation is more memory efficient on TPU when compared to the original MatMulCropAndResize.

--
249337338  by chowdhery:

    Add class-agnostic non-max-suppression in post_processing

--
249139196  by Zhichao Lu:

    Fix positional argument bug in export_tflite_ssd_graph

--
249120219  by Zhichao Lu:

    Add evaluator for computing precision limited to a given recall range.

--
249030593  by Zhichao Lu:

    Evaluation util to run segmentation and detection challenge evaluation.

--
248554358  by Zhichao Lu:

    This change contains the auxiliary changes required for TF 2.0 style training with eager+functions+dist strat loops, but not the loops themselves.

    It includes:
    - Updates to shape usage to support both tensorshape v1 and tensorshape v2
    - A fix to FreezableBatchNorm to not override the `training` arg in call when `None` was passed to the constructor (Not an issue in the estimator loops but it was in the custom loops)
    - Puts some constants in init_scope so they work in eager + functions
    - Makes learning rate schedules return a callable in eager mode (required so they update when the global_step changes)
    - Makes DetectionModel a tf.module so it tracks variables (e.g. ones nested in layers)
    - Removes some references to `op.name` for some losses and replaces it w/ explicit names
    - A small part of the change to allow the coco evaluation metrics to work in eager mode

--
248271226  by rathodv:

    Add MultiLevel RoIAlign op.

--
248229103  by rathodv:

    Add functions to 1. pad features maps 2. ravel 5-D indices

--
248206769  by rathodv:

    Add utilities needed to introduce RoI Align op.

--
248177733  by pengchong:

    Internal changes

--
247742582  by Zhichao Lu:

    Open Images Challenge 2019 instance segmentation metric: part 2

--
247525401  by Zhichao Lu:

    Update comments on max_class_per_detection.

--
247520753  by rathodv:

    Add multilevel crop and resize operation that builds on top of matmul_crop_and_resize.

--
247391600  by Zhichao Lu:

    Open Images Challenge 2019 instance segmentation metric

--
247325813  by chowdhery:

    Quantized MobileNet v2 SSD FPNLite config with depth multiplier 0.75

--

PiperOrigin-RevId: 250447559",pkulzc,b'cla: yes',2019-05-31T00:49:40Z,2019-05-31T05:27:45Z,,,,,,,
6928,Bug fix of cifar10_eval.py,"line 120: changed from eval_data = FLAGS.eval_data == 'test'
to: eval_data = FLAGS.eval_data
comment: the original code assigns 'true' to eval_data, when the script is being used to evaluate networks on the evaluation set, it DOES NOT load the evaluation set as intended, but actually loads the trainning set (line 105 of cifar10_input.py).",youngleox,b'cla: yes',2019-05-30T20:10:36Z,2019-07-08T20:28:45Z,,,,,,,
6871, Fix bug in dataset reader.,"The "".mat"" files loaded in the dataset are byte files. Python 3.7 requires them to be loaded using ""rb"".

@andrefaraujo ",MarvinTeichmann,b'cla: yes',2019-05-23T21:13:43Z,2019-05-28T18:46:20Z,,,,,,,
6869,Please help  for that error object detection not found,"[Please](url) go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow
![Annotation 2019-05-24 001410](https://user-images.githubusercontent.com/43698096/58278097-0cf8d300-7d50-11e9-99cb-6f1b27f08988.png)


Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",leone952140914,None,2019-05-23T18:44:46Z,2020-03-25T23:03:12Z,,,,,,,
6819,Getting an optimized model with TOCO failed,"### System information
- **What is the top-level directory of the model you are using**: tensorflow
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: 1.12.0 (CPU only)
- **Bazel version (if compiling from source)**: 0.19.0
- **CUDA/cuDNN version**: 9.0/7.4
- **GPU model and memory**: GeForce 660M/8 GB RAM
- **Exact command to reproduce**: 

```
bazel run -c opt tensorflow/contrib/lite/toco:toco -- --input_file=D:\tensor\output\tflite_graph.pb --output_file=D:\tensor\output\flutter_model.tflite --inference_type=QUANTIZED_UINT8 --input_format=TENSORFLOW_GRAPHDEF --output_format=TFLITE --input_shapes=1,300,300,3 --input_arrays=normalized_input_image_tensor --output_arrays='TFLite_Detection_PostProcess','TFLite_Detection_PostProcess:1','TFLite_Detection_PostProcess:2','TFLite_Detection_PostProcess:3' --mean_values=128 --std_values=128 --change_concat_input_ranges=false --allow_custom_ops
```

### Describe the problem
My goal is to run a Mobilenet pretrained model on a mobile. I went step by step through the following tutorial, starting from building TF from source:
https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/running_on_mobile_tensorflowlite.md

Everything went quite smoothly or I managed to find some already solved issues. Yet, I have a problem with the last step that is getting the optimized model with TOCO.

### Source code / logs

When I ran the command:

```
bazel run -c opt tensorflow/contrib/lite/toco:toco -- --input_file=D:\tensor\output\tflite_graph.pb --output_file=D:\tensor\output\flutter_model.tflite --inference_type=QUANTIZED_UINT8 --input_format=TENSORFLOW_GRAPHDEF --output_format=TFLITE --input_shapes=1,300,300,3 --input_arrays=normalized_input_image_tensor --output_arrays='TFLite_Detection_PostProcess','TFLite_Detection_PostProcess:1','TFLite_Detection_PostProcess:2','TFLite_Detection_PostProcess:3' --mean_values=128 --std_values=128 --change_concat_input_ranges=false --allow_custom_ops
```

I got the following error:
```
2019-05-18 13:50:34.792006: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1080] Converting unsupported operation: TFLite_Detection_PostProcess
2019-05-18 13:50:34.870333: F tensorflow/contrib/lite/toco/tooling_util.cc:854] Check failed: model.HasArray(output_array) Output array not found: 'TFLite_Detection_PostProcess'
```",abiela,b'comp:lite models:research stat:awaiting response type:bug',2019-05-20T06:02:56Z,2019-07-08T17:44:59Z,,,,,,,
6818,MaskGAN code contains several bugs and is incomplete,"The maskgan implementation does not meet the code quality usually found in the tensorflow codebase. It contains several bugs and many shortcomings.

## bugs
- In  models/research/maskgan/data/ptb_loader.py 
`` return f.read().decode(""utf-8"").replace(""\n"", ""<eos>"").split()``
attaches the `<eos>` to random symbols.

- In models/research/maskgan/generate_samples.py 
`tf.Supervisor()`
does not exist in the recommended TF version 1.5. It was probably always under tf.train

## shortcomings

- Corpus filenames i.e. `ptb.train.txt` are hardcoded.

- It is very unclear how the code in `generate_samples.py` can generate *unconditional* samples. It iterates across the dataset and the output -- even masking all tokens -- impacts the generated output (as tested by providing a dummy corpus).

- Essential documentation, for example for pretraining the LM, is marked as WIP for over a year.
- Many features, for example generator pre-training, raise NotImplemented exceptions. 


### System information
- **What is the top-level directory of the model you are using**:
models/research/maskgan/
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
no
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
ubuntu 18.04
- **TensorFlow installed from (source or binary)**:
binary
- **TensorFlow version (use command below)**:
1.5.1 as is recommended but the code can be found in the current master
- **Bazel version (if compiling from source)**:
n/a
- **CUDA/cuDNN version**:
n/a
- **GPU model and memory**:
n/a
- **Exact command to reproduce**:
",schmiflo,b'models:research',2019-05-18T18:33:22Z,2020-03-25T23:03:09Z,,,,,,,
6814,Is there checkpoints for trained classification model in Audioset?,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",shamanez,None,2019-05-18T10:42:06Z,2019-06-21T21:19:53Z,,,,,,,
6798,Latest merge is not training properly on Cloud ML engine (No GPU utilization),"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
/models/research
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
Yes. But I still face the issue after removing it. 
Here is the code for calculating per category metrics in cocoeval.py in pycocotools 

```
    def summarize_per_category(self):
        '''
        Compute and display summary metrics for evaluation results *per category*.
        Note this functin can *only* be applied on the default parameter setting
        '''
        def _summarize_single_category(ap=1, iouThr=None, categoryId=None, areaRng='all', maxDets=100):
            p = self.params
            iStr = ' {:<18} {} @[ CategoryId={:>3d} | IoU={:<9} | area={:>6s} | maxDets={:>3d} ] = {:0.3f}'
            titleStr = 'Average Precision' if ap == 1 else 'Average Recall'
            typeStr = '(AP)' if ap==1 else '(AR)'
            iouStr = '{:0.2f}:{:0.2f}'.format(p.iouThrs[0], p.iouThrs[-1]) \
                if iouThr is None else '{:0.2f}'.format(iouThr)

            aind = [i for i, aRng in enumerate(p.areaRngLbl) if aRng == areaRng]
            mind = [i for i, mDet in enumerate(p.maxDets) if mDet == maxDets]

            if ap == 1:
                # dimension of precision: [TxRxKxAxM]
                s = self.eval['precision']
                # IoU
                if iouThr is not None:
                    t = np.where(iouThr == p.iouThrs)[0]
                    s = s[t]
                if categoryId is not None:
                    category_index = [i for i, i_catId in enumerate(p.catIds) if i_catId == categoryId]
                    s = s[:,:,category_index,aind,mind]
                else:
                    s = s[:,:,:, aind, mind]
            else:
                # dimension of recall: [TxKxAxM]
                s = self.eval['recall']
                if iouThr is not None:
                    t = np.where(iouThr == p.iouThrs)[0]
                    s = s[t]
                if categoryId is not None:
                    category_index = [i for i, i_catId in enumerate(p.catIds) if i_catId == categoryId]
                    s = s[:,category_index,aind,mind]
                else:
                    s = s[:,:, aind, mind]
            if len(s[s>-1])==0:
                mean_s = -1
            else:
                mean_s = np.mean(s[s>-1])
            #print(iStr.format(titleStr, typeStr, catId, iouStr, areaRng, maxDets, mean_s))
            return mean_s
    def _summarizeDets_per_category():
            category_stats = np.zeros((12,len(self.params.catIds)))
            for category_index, category_id in enumerate(self.params.catIds):
                category_stats[0][category_index] = _summarize_single_category(1,
                                                                               categoryId=category_id)
                category_stats[1][category_index] = _summarize_single_category(1,
                                                                               iouThr=.5,
                                                                               maxDets=self.params.maxDets[2],
                                                                               categoryId=category_id)
                category_stats[2][category_index] = _summarize_single_category(1,
                                                                               iouThr=.75,
                                                                               maxDets=self.params.maxDets[2],
                                                                               categoryId=category_id)
                category_stats[3][category_index] = _summarize_single_category(1,
                                                                               areaRng='small',
                                                                               maxDets=self.params.maxDets[2],
                                                                               categoryId=category_id)
                category_stats[4][category_index] = _summarize_single_category(1,
                                                                               areaRng='medium',
                                                                               maxDets=self.params.maxDets[2],
                                                                               categoryId=category_id)
                category_stats[5][category_index] = _summarize_single_category(1,
                                                                               areaRng='large',
                                                                               maxDets=self.params.maxDets[2],
                                                                               categoryId=category_id)
                category_stats[6][category_index] = _summarize_single_category(0,
                                                                               maxDets=self.params.maxDets[0],
                                                                               categoryId=category_id)
                category_stats[7][category_index] = _summarize_single_category(0,
                                                                               maxDets=self.params.maxDets[1],
                                                                               categoryId=category_id)
                category_stats[8][category_index] = _summarize_single_category(0,
                                                                               maxDets=self.params.maxDets[2],
                                                                               categoryId=category_id)
                category_stats[9][category_index] = _summarize_single_category(0,
                                                                               areaRng='small',
                                                                               maxDets=self.params.maxDets[2],
                                                                               categoryId=category_id)
                category_stats[10][category_index] = _summarize_single_category(0,
                                                                                areaRng='medium',
                                                                                maxDets=self.params.maxDets[2],
                                                                                categoryId=category_id)
                category_stats[11][category_index] = _summarize_single_category(0,
                                                                                areaRng='large',
                                                                                maxDets=self.params.maxDets[2],
                                                                                categoryId=category_id)
            return category_stats

     def _summarizeKps_per_category():
            category_stats = np.zeros((10,len(self.params.catIds)))
            for category_index, category_id in self.params.catIds:
                category_stats[0][category_index] = _summarize_single_category(1,
                                                                               maxDets=20,
                                                                               categoryId=category_id)
                category_stats[1][category_index] = _summarize_single_category(1,
                                                                               maxDets=20,
                                                                               iouThr=.5,
                                                                               categoryId=category_id)
                category_stats[2][category_index] = _summarize_single_category(1,
                                                                               maxDets=20,
                                                                               iouThr=.75,
                                                                               categoryId=category_id)
                category_stats[3][category_index] = _summarize_single_category(1,
                                                                               maxDets=20,
                                                                               areaRng='medium',
                                                                               categoryId=category_id)
                category_stats[4][category_index] = _summarize_single_category(1,
                                                                               maxDets=20,
                                                                               areaRng='large',
                                                                               categoryId=category_id)
                category_stats[5][category_index] = _summarize_single_category(0,
                                                                               maxDets=20,
                                                                               categoryId=category_id)
                category_stats[6][category_index] = _summarize_single_category(0,
                                                                               maxDets=20,
                                                                               iouThr=.5,
                                                                               categoryId= category_id)
                category_stats[7][category_index] = _summarize_single_category(0,
                                                                               maxDets=20,
                                                                               iouThr=.75,
                                                                               categoryId=category_id)
                category_stats[8][category_index] = _summarize_single_category(0,
                                                                               maxDets=20,
                                                                               areaRng='medium',
                                                                               categoryId=category_id)
                category_stats[9][category_index] = _summarize_single_category(0,
                                                                               maxDets=20,
                                                                               areaRng='large',
                                                                               categoryId=category_id)
            return category_stats

    if not self.eval:
            raise Exception('Please run accumulate() first')
        iouType = self.params.iouType
        if iouType == 'segm' or iouType == 'bbox':
            summarize_per_category = _summarizeDets_per_category
        elif iouType == 'keypoints':
            summarize_per_category = _summarizeKps_per_category
        self.category_stats = summarize_per_category()

    def __str__(self):
        self.summarize_per_category()
```
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:  Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.13
- **Bazel version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: 10
- **GPU model and memory**: Nvidia Tesla V100
- **Exact command to reproduce**:
gcloud ml-engine jobs submit training frcnn_inception_oid_with_icons_summarize_eval_`date +%m_%d_%Y_%H_%M_%S`     --runtime-version 1.13     --job-dir=$MODEL_DIR     --packages dist/object_detection-0.1.tar.gz,slim/dist/slim-0.1.tar.gz,/tmp/pycocotools/pycocotools-2.0.tar.gz     --module-name object_detection.model_main     --region us-central1     --config=config.yaml     --     --model_dir=$MODEL_DIR     --pipeline_config_path=$PIPELINE_CONFIG_PATH

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.
After I pulled the latest merge, I have not been able to train any model configuration on Cloud ML engine. I have spoken to the google cloud Product Team and according to them the problem lies within this repo. The reasoning they gave is that GPU utilization is 0 and hence because of this the model is training very very slowly. 
I feel this is a fair reasoning -- the model that used to take 9-12 hours to train for 200,000 steps previously is now been training for more than 7 days and is only at step 179k.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.

```
**2019-05-16 04:47:37.544 PDT**
master-replica-0
Saving 'checkpoint_path' summary for global step 179065:

**2019-05-16 05:05:16.926 PDT**
master-replica-0
Saving 'checkpoint_path' summary for global step 179066:

**2019-05-16 05:23:20.108 PDT**
master-replica-0
Saving 'checkpoint_path' summary for global step 179067:

**2019-05-16 06:51:23.196 PDT**
master-replica-0
Saving 'checkpoint_path' summary for global step 179068

**2019-05-16 08:24:38.903 PDT**
master-replica-0
Saving 'checkpoint_path' summary for global step 179069:

**2019-05-16 09:58:34.556 PDT**
master-replica-0
Saving 'checkpoint_path' summary for global step 179070:

```
As evident from above training logs, the speed is ridiculously slow. Please help.  
",kulkarnivishal,None,2019-05-16T17:44:27Z,2020-03-25T23:03:35Z,,,,,,,
6790,multi-gpus of feelvos,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",crazyblacker,None,2019-05-16T05:10:34Z,2019-05-18T00:06:50Z,,,,,,,
6785,Output Total Loss / Save model with lowest total loss in extra folder,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**: /models/research/object_detection
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux 16.04
- **TensorFlow installed from (source or binary)**: Bazel
- **TensorFlow version (use command below)**: 1.12.0-rc2
- **Bazel version (if compiling from source)**: NA
- **CUDA/cuDNN version**: 10.0
- **GPU model and memory**: GeForce GTX 980 Titan
- **Exact command to reproduce**: NA


-------------------------

Is there are way to output the total loss ? In Tensorboard I see the loss, but I want to check the loss each iteration. 

I want to additionally keep the model with the lowest total loss aside from the output I get each iteration step. So, I want to have, for example, a model in an extra folder with the lowest total loss. If a model with a lower total loss is output, the last model should be overwritten. 

Or an other idea: To keep all models? In Tensorboard I can check in which iteration the total loss is the lowest and I can take this model. However, this would only be the plan B, because it is very memory consuming. 

Does a feature exist as described? 


Thanks a lot in advance 
",paviddavid,None,2019-05-15T10:50:04Z,2020-03-25T23:03:33Z,,,,,,,
6766,"Hello! I have a dataset with 14 classes, and I run MobilenetV2 and ResNet101, but I found MobileNetV2's accuracy higher than ResNet-101 about 1%, is correct?","Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",fengwuxuan,None,2019-05-11T15:56:31Z,2019-05-12T05:25:49Z,,,,,,,
6753,Op type not registered 'TFLite_Detection_PostProcess' in binary for TF 1.13.1,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
na
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
no
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**:
binary
- **TensorFlow version (use command below)**:
b'v1.13.0-rc2-5-g6612da8' 1.13.1
- **Bazel version (if compiling from source)**:
na
- **CUDA/cuDNN version**:
na
- **GPU model and memory**:
na
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

### Describe the problem
I tried to use object detection notebook example provided in the examples section. I tried to download ssd_mobilenet_v2_quantized_coco. However, when I try to import and run `run_inference_for_single_image` function, the whole things fail with the following error:

`tensorflow.python.framework.errors_impl.NotFoundError: Op type not registered 'TFLite_Detection_PostProcess' in binary running on`

I know there were problems like this one. However, in previous issues it helped people to update their TF to 1.12. My version is 1.13, so the problem should not be there. What are potential reasons for this problem in 1.13? 

### Source code / logs
na
",drsealks,None,2019-05-10T13:34:49Z,2019-08-22T05:07:56Z,,,,,,,
6749,How to modify the proportion of loss to make the localization and the objectness more important in faster rcnn,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",tdf1995,None,2019-05-10T08:47:09Z,2020-03-25T23:03:31Z,,,,,,,
6747,xmin.append(float(obj['bndbox']['xmin']) / width)  :why let the xmin/width instead of use xmin directly?,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",YuanYunjing,None,2019-05-10T07:10:01Z,2020-03-25T23:03:30Z,,,,,,,
6741,"when training voc2012 with mobilenetv1-ssd on win10, cuda out of memory?","the log is like that:
2019-05-09 21:09:32.262836: E T:\src\github\tensorflow\tensorflow\stream_executor\cuda\cuda_driver.cc:936] failed to allocate 6.25G (6712326144 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
2019-05-09 21:09:32.673686: E T:\src\github\tensorflow\tensorflow\stream_executor\cuda\cuda_driver.cc:936] failed to allocate 5.63G (6041093120 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
2019-05-09 21:09:33.080204: E T:\src\github\tensorflow\tensorflow\stream_executor\cuda\cuda_driver.cc:936] failed to allocate 5.06G (5436983808 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",SyGoing,None,2019-05-09T13:13:07Z,2020-03-19T00:52:36Z,,,,,,,
6738,"I'm working on a traffic sign recognition bachelor project and I have to run it on an android device. I just finished training using tensorflow object detection api and Faster RCNN , however I can't figure out what to do after I'm done with training the model. I read about freezing the model but I can't find detailed tutorials for beginners so if anyone knows any good resources or can help I would be very grateful. Thanks in advance.","Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",RanaEzzat,None,2019-05-09T01:51:18Z,2020-03-25T23:03:30Z,,,,,,,
6737,Merged commit includes the following changes:,"247226201  by ronnyvotel:

    Updating the visualization tools to accept unique_ids for color coding.

--
247067830  by Zhichao Lu:

    Add box_encodings_clip_range options for the convolutional box predictor (for TPU compatibility).

--
246888475  by Zhichao Lu:

    Remove unused _update_eval_steps function.

--
246163259  by lzc:

    Add a gather op that can handle ignore indices (which are ""-1""s in this case).

--
246084944  by Zhichao Lu:

    Keras based implementation for SSD + MobilenetV2 + FPN.

--
245544227  by rathodv:

    Add batch_get_targets method to target assigner module to gather any groundtruth tensors based on the results of target assigner.

--
245540854  by rathodv:

    Update target assigner to return match tensor instead of a match object.

--
245434441  by Zhichao Lu:

    Add README for tpu_exporters package.

--
245381834  by lzc:

    Internal change.

--
245298983  by Zhichao Lu:

    Add conditional_shape_resizer to config_util

--
245134666  by Zhichao Lu:

    Adds ConditionalShapeResizer to the ImageResizer proto which enables resizing only if input image height or width is is greater or smaller than a certain size. Also enables specification of resize method in resize_to_{max, min}_dimension methods.

--
245093975  by Zhichao Lu:

    Exporting SavedModel for Object Detection TPU inference. (faster-rcnn)

--
245072421  by Zhichao Lu:

    Adds a new image resizing method ""resize_to_max_dimension"" which resizes images only if a dimension is greater than the maximum desired value while maintaining aspect ratio.

--
244946998  by lzc:

    Internal Changes.

--
244943693  by Zhichao Lu:

    Add a custom config to mobilenet v2 that makes it more detection friendly.

--
244754158  by derekjchow:

    Internal change.

--
244699875  by Zhichao Lu:

    Add check_range=False to box_list_ops.to_normalized_coordinates when training
    for instance segmentation.  This is consistent with other calls when training
    for object detection.  There could be wrongly annotated boxes in the dataset.

--
244507425  by rathodv:

    Support bfloat16 for ssd models.

--
244399982  by Zhichao Lu:

    Exporting SavedModel for Object Detection TPU inference. (ssd)

--
244209387  by Zhichao Lu:

    Internal change.

--
243922296  by rathodv:

    Change `raw_detection_scores` to contain softmax/sigmoid scores (not logits) for `raw_ detection_boxes`.

--
243883978  by Zhichao Lu:

    Add a sample fully conv config.

--
243369455  by Zhichao Lu:

    Fix regularization loss gap in Keras and Slim.

--
243292002  by lzc:

    Internal changes.

--
243097958  by Zhichao Lu:

    Exporting SavedModel for Object Detection TPU inference. (ssd model)

--
243007177  by Zhichao Lu:

    Exporting SavedModel for Object Detection TPU inference. (ssd model)

--
242776550  by Zhichao Lu:

    Make object detection pre-processing run on GPU.  tf.map_fn() uses
    TensorArrayV3 ops, which have no int32 GPU implementation.  Cast to int64,
    then cast back to int32.

--
242723128  by Zhichao Lu:

    Using sorted dictionaries for additional heads in non_max_suppression to ensure tensor order

--
242495311  by Zhichao Lu:

    Update documentation to reflect new TFLite examples repo location

--
242230527  by Zhichao Lu:

    Fix Dropout bugs for WeightSharedConvolutionalBoxPred.

--
242226573  by Zhichao Lu:

    Create Keras-based WeightSharedConvolutionalBoxPredictor.

--
241806074  by Zhichao Lu:

    Add inference in unit tests of TFX OD template.

--
241641498  by lzc:

    Internal change.

--
241637481  by Zhichao Lu:

    matmul_crop_and_resize(): Switch to dynamic shaping, so that not all dimensions are required to be known.

--
241429980  by Zhichao Lu:

    Internal change

--
241167237  by Zhichao Lu:

    Adds a faster_rcnn_inception_resnet_v2 Keras feature extractor, and updates the model builder to construct it.

--
241088616  by Zhichao Lu:

    Make it compatible with different dtype, e.g. float32, bfloat16, etc.

--
240897364  by lzc:

    Use image_np_expanded in object_detection_tutorial notebook.

--
240890393  by Zhichao Lu:

    Disable multicore inference for OD template as its not yet compatible.

--
240352168  by Zhichao Lu:

    Make SSDResnetV1FpnFeatureExtractor not protected to allow inheritance.

--
240351470  by lzc:

    Internal change.

--
239878928  by Zhichao Lu:

    Defines Keras box predictors for Faster RCNN and RFCN

--
239872103  by Zhichao Lu:

    Delete duplicated inputs in test.

--
239714273  by Zhichao Lu:

    Adding scope variable to all class heads

--
239698643  by Zhichao Lu:

    Create FPN feature extractor for object detection.

--
239696657  by Zhichao Lu:

    Internal Change.

--
239299404  by Zhichao Lu:

    Allows the faster rcnn meta-architecture to support Keras subcomponents

--
238502595  by Zhichao Lu:

    Lay the groundwork for symmetric quantization.

--
238496885  by Zhichao Lu:

    Add flexible_grid_anchor_generator

--
238138727  by lzc:

    Remove dead code.

    _USE_C_SHAPES has been forced True in TensorFlow releases since
    TensorFlow 1.9
    (https://github.com/tensorflow/tensorflow/commit/1d74a69443f741e69f9f52cb6bc2940b4d4ae3b7)

--
238123936  by rathodv:

    Add num_matched_groundtruth summary to target assigner in SSD.

--
238103345  by ronnyvotel:

    Raising error if input file pattern does not match any files.
    Also printing the number of evaluation images for coco metrics.

--
238044081  by Zhichao Lu:

    Fix docstring to state the correct dimensionality of `class_predictions_with_background`.

--
237920279  by Zhichao Lu:

    [XLA] Rework debug flags for dumping HLO.

    The following flags (usually passed via the XLA_FLAGS envvar) are removed:

      xla_dump_computations_to
      xla_dump_executions_to
      xla_dump_ir_to
      xla_dump_optimized_hlo_proto_to
      xla_dump_per_pass_hlo_proto_to
      xla_dump_unoptimized_hlo_proto_to
      xla_generate_hlo_graph
      xla_generate_hlo_text_to
      xla_hlo_dump_as_html
      xla_hlo_graph_path
      xla_log_hlo_text

    The following new flags are added:

      xla_dump_to
      xla_dump_hlo_module_re
      xla_dump_hlo_pass_re
      xla_dump_hlo_as_text
      xla_dump_hlo_as_proto
      xla_dump_hlo_as_dot
      xla_dump_hlo_as_url
      xla_dump_hlo_as_html
      xla_dump_ir
      xla_dump_hlo_snapshots

    The default is not to dump anything at all, but as soon as some dumping flag is
    specified, we enable the following defaults (most of which can be overridden).

     * dump to stdout (overridden by --xla_dump_to)
     * dump HLO modules at the very beginning and end of the optimization pipeline
     * don't dump between any HLO passes (overridden by --xla_dump_hlo_pass_re)
     * dump all HLO modules (overridden by --xla_dump_hlo_module_re)
     * dump in textual format (overridden by
       --xla_dump_hlo_as_{text,proto,dot,url,html}).

    For example, to dump optimized and unoptimized HLO text and protos to /tmp/foo,
    pass

      --xla_dump_to=/tmp/foo --xla_dump_hlo_as_text --xla_dump_hlo_as_proto

    For details on these flags' meanings, see xla.proto.

    The intent of this change is to make dumping both simpler to use and more
    powerful.

    For example:

     * Previously there was no way to dump the HLO module during the pass pipeline
       in HLO text format; the only option was --dump_per_pass_hlo_proto_to, which
       dumped in proto format.

       Now this is --xla_dump_pass_re=.* --xla_dump_hlo_as_text.  (In fact, the
       second flag is not necessary in this case, as dumping as text is the
       default.)

     * Previously there was no way to dump HLO as a graph before and after
       compilation; the only option was --xla_generate_hlo_graph, which would dump
       before/after every pass.

       Now this is --xla_dump_hlo_as_{dot,url,html} (depending on what format you
       want the graph in).

     * Previously, there was no coordination between the filenames written by the
       various flags, so info about one module might be dumped with various
       filename prefixes.  Now the filenames are consistent and all dumps from a
       particular module are next to each other.

    If you only specify some of these flags, we try to figure out what you wanted.
    For example:

     * --xla_dump_to implies --xla_dump_hlo_as_text unless you specify some
       other --xla_dump_as_* flag.

     * --xla_dump_hlo_as_text or --xla_dump_ir implies dumping to stdout unless you
       specify a different --xla_dump_to directory.  You can explicitly dump to
       stdout with --xla_dump_to=-.

    As part of this change, I simplified the debugging code in the HLO passes for
    dumping HLO modules.  Previously, many tests explicitly VLOG'ed the HLO module
    before, after, and sometimes during the pass.  I removed these VLOGs.  If you
    want dumps before/during/after an HLO pass, use --xla_dump_pass_re=<pass_name>.

--
237510043  by lzc:

    Internal Change.

--
237469515  by Zhichao Lu:

    Parameterize model_builder.build in inputs.py.

--
237293511  by rathodv:

    Remove multiclass_scores from tensor_dict in transform_data_fn always.

--
237260333  by ronnyvotel:

    Updating faster_rcnn_meta_arch to define prediction dictionary fields that are batched.

--

PiperOrigin-RevId: 247226201",lzr-google,b'cla: yes',2019-05-08T23:08:56Z,2019-05-22T17:29:22Z,,,,,,,
6723,Run vis.py file with error：InvalidArgumentError (see above for traceback): padded_shape[0]=64 is not divisible by block_shape[0]=6,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",swjtxw,None,2019-05-07T07:38:20Z,2020-03-25T23:03:57Z,,,,,,,
6719,"ValueError: Tensor conversion requested dtype string for Tensor with dtype float32: 'Tensor(""arg0:0"", shape=(), dtype=float32)'","Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:  object_detection
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: N/A
- **TensorFlow version (use command below)**: 1.7.0
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**: 7.0.4
- **GPU model and memory**: N/A
- **Exact command to reproduce**: python train.py --logtostderr --train_dir=training/ --pipeline_config_path=training/faster_rcnn_inception_v2_pets.config


### Describe the problem
when i try to train a model using my own tfrecords, i get the following error: 
ValueError: Tensor conversion requested dtype string for Tensor with dtype float32: 'Tensor(""arg0:0"", shape=(), dtype=float32)'

i read that it is a problem with the path to the tfrecords in the config file.
i use the faster_rcnn_inception_v2_pets.config file and the paths look like this:



### Source code / logs
train_input_reader: {
  tf_record_input_reader {
    input_path:""/home/robotix/models/research/object_detection/train.record-?????-of-00086""
  }
  label_map_path:""/home/robotix/models/research/object_detection/training/labelmap.pbtxt""
}

eval_config: {
  metrics_set: ""coco_detection_metrics""
  num_examples:41                                      
}

eval_input_reader: {
  tf_record_input_reader {
    input_path:""/home/robotix/models/research/object_detection/test.record-?????-of-00041""
  }
  label_map_path:""/home/robotix/models/research/object_detection/training/labelmap.pbtxt""
  shuffle: false
  num_readers: 1
}



i do not understand why i am getting that error, because it seems that the paths are correct.
can anyone please advise? thank you ",Eladsimba,b'models:research',2019-05-05T09:13:49Z,2019-05-06T20:13:28Z,,,,,,,
6717,unable to generate inference graph from model checkpoint,"```
I'm using ssd_mobilenet_v2_coco for my custom data training. I completed the training process after 10000 iterations and I got model checkpoint-10000. after that, I tried to generate an interference graph using /tensorflow/models/research/object_detection/export_inference_graph.py using this command python export_inference_graph.py --input_type image_tensor --pipeline_config_path training/ssd_inception_v2_coco.config --trained_checkpoint_prefix training/model.ckpt-10000 --output_directory trained-inference-graphs/output_inference_graph_v1.pb
 but I got following error

(zero) pi@pi-HP-280-G1-MT:~/tf/training_demo$ python export_inference_graph.py --input_type image_tensor --pipeline_config_path training/pipeline_cocco.config --trained_checkpoint_prefix training/model.ckpt --output_directory trained-inference-graphs/output_inference_graph_v1.pb
Traceback (most recent call last):
  File ""export_inference_graph.py"", line 156, in <module>
    tf.app.run()
  File ""/home/pi/.virtualenvs/zero/lib/python3.5/site-packages/tensorflow/python/platform/app.py"", line 125, in run
    _sys.exit(main(argv))
  File ""export_inference_graph.py"", line 140, in main
    text_format.Merge(f.read(), pipeline_config)
  File ""/home/pi/.virtualenvs/zero/lib/python3.5/site-packages/google/protobuf/text_format.py"", line 574, in Merge
    descriptor_pool=descriptor_pool)
  File ""/home/pi/.virtualenvs/zero/lib/python3.5/site-packages/google/protobuf/text_format.py"", line 631, in MergeLines
    return parser.MergeLines(lines, message)
  File ""/home/pi/.virtualenvs/zero/lib/python3.5/site-packages/google/protobuf/text_format.py"", line 654, in MergeLines
    self._ParseOrMerge(lines, message)
  File ""/home/pi/.virtualenvs/zero/lib/python3.5/site-packages/google/protobuf/text_format.py"", line 676, in _ParseOrMerge
    self._MergeField(tokenizer, message)
  File ""/home/pi/.virtualenvs/zero/lib/python3.5/site-packages/google/protobuf/text_format.py"", line 801, in _MergeField
    merger(tokenizer, message, field)
  File [""/home/pi/.virtualenvs/zero/lib/python3.5/site-packages/google/protobuf/text_format.py"",](url) line 875, in _MergeMessageField
    self._MergeField(tokenizer, sub_message)
  File ""/home/pi/.virtualenvs/zero/lib/python3.5/site-packages/google/protobuf/text_format.py"", line 801, in _MergeField
    merger(tokenizer, message, field)
  File ""/home/pi/.virtualenvs/zero/lib/python3.5/site-packages/google/protobuf/text_format.py"", line 875, in _MergeMessageField
    self._MergeField(tokenizer, sub_message)
  File ""/home/pi/.virtualenvs/zero/lib/python3.5/site-packages/google/protobuf/text_format.py"", line 801, in _MergeField
    merger(tokenizer, message, field)
  File ""/home/pi/.virtualenvs/zero/lib/python3.5/site-packages/google/protobuf/text_format.py"", line 875, in _MergeMessageField
    self._MergeField(tokenizer, sub_message)
  File ""/home/pi/.virtualenvs/zero/lib/python3.5/site-packages/google/protobuf/text_format.py"", line 768, in _MergeField
    (message_descriptor.full_name, name))
google.protobuf.text_format.ParseError: 35:7 : Message type ""object_detection.protos.SsdFeatureExtractor"" has no field named ""batch_norm_trainable"".

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:ubuntu 16.04
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:1.10.0
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:9.0
- **GPU model and memory**:GT 730
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.

```",Hashirroshan,None,2019-05-05T07:17:07Z,2020-03-25T23:03:56Z,,,,,,,
6715,The mobilenet is missing in deeplab code,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",sjytker,None,2019-05-04T02:30:49Z,2019-05-04T02:32:09Z,,,,,,,
6711,"Using the latest version of DeepLabv3+ (checked out today), how to get eval results","Hi,

The eval script does not seem to print out the results anymore to the terminal. I am not sure where to look for the output. Can you please help?

Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",ahanagemini,None,2019-05-02T05:34:21Z,2020-03-25T23:28:37Z,,,,,,,
6706,ls,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",devvikas,None,2019-05-01T11:58:23Z,2019-05-02T18:43:34Z,,,,,,,
6700,struct2depth Memory not released,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",fengkai11,None,2019-04-30T05:17:20Z,2020-03-25T23:03:55Z,,,,,,,
6695,bug fix,,seemuch,b'cla: yes',2019-04-29T20:37:16Z,2019-04-29T20:53:13Z,,,,,,,
6656,deeplab unable to make frozen_inference_graph.pb,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**: deeplab
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: copy existing script to use my own dataset
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 18.04
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.13
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**: 10.0
- **GPU model and memory**: Geforce GTX 1080 Ti
- **Exact command to reproduce**:

CKPT_PATH=""${TRAIN_LOGDIR}/model.ckpt-1576438""
EXPORT_PATH=""${EXPORT_DIR}/frozen_inference_graph.pb""
python3 ""${WORK_DIR}""/export_model.py \
  --logtostderr \
  --checkpoint_path=""${CKPT_PATH}"" \
  --export_path=""${EXPORT_PATH}"" \
  --model_variant=""xception_65"" \
  --atrous_rates=6 \
  --atrous_rates=12 \
  --atrous_rates=18 \
  --output_stride=16 \
  --decoder_output_stride=4 \
  --num_classes=6 \
  --crop_size=513 \
  --crop_size=513 \
  --inference_scales=1.0

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

### Describe the problem
I have trained on my own dataset which is made of six classes. 
The result is great but I have a problem when trying to make frozen_inference_graph.pb
I have the following error lhs shape= [1,1,256,6] rhs shape= [1,1,256,21]
I don't why it is stucked with 21 classes (_PASCAL_VOC_SEG_INFORMATION) I have set the following option  --num_classes=6.

Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
INFO:tensorflow:Prepare to export model to: /media/nv/Unix/deeplab/research/deeplab/datasets/PQR/exp/train_on_trainval_set/export/frozen_inference_graph.pb
INFO:tensorflow:Exported model performs single-scale inference.
WARNING:tensorflow:From /media/nv/Unix/deeplab/research/deeplab/core/feature_extractor.py:196: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
WARNING:tensorflow:From /home/nv/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
WARNING:tensorflow:From /home/nv/.local/lib/python3.6/site-packages/tensorflow/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to check for files with this prefix.
2019-04-24 12:05:22.349775: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-04-24 12:05:22.350676: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x3e13670 executing computations on platform CUDA. Devices:
2019-04-24 12:05:22.350721: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): GeForce GTX 1080 Ti, Compute Capability 6.1
2019-04-24 12:05:22.370865: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3410935000 Hz
2019-04-24 12:05:22.371495: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x2d3e090 executing computations on platform Host. Devices:
2019-04-24 12:05:22.371524: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
2019-04-24 12:05:22.372379: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: 
name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.645
pciBusID: 0000:01:00.0
totalMemory: 10.91GiB freeMemory: 10.48GiB
2019-04-24 12:05:22.372409: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0
2019-04-24 12:05:22.373841: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-04-24 12:05:22.373865: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 
2019-04-24 12:05:22.373877: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N 
2019-04-24 12:05:22.374712: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10192 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
INFO:tensorflow:Restoring parameters from /media/nv/Unix/deeplab/research/deeplab/datasets/PQR/exp/train_on_trainval_set/train/model.ckpt-1576438
Traceback (most recent call last):
  File ""/home/nv/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1334, in _do_call
    return fn(*args)
  File ""/home/nv/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1319, in _run_fn
    options, feed_dict, fetch_list, target_list, run_metadata)
  File ""/home/nv/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1407, in _call_tf_sessionrun
    run_metadata)
tensorflow.python.framework.errors_impl.InvalidArgumentError: Assign requires shapes of both tensors to match. lhs shape= [1,1,256,6] rhs shape= [1,1,256,21]
	 [[{{node save/Assign_71}}]]
	 [[{{node save/RestoreV2}}]]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/home/nv/.local/lib/python3.6/site-packages/tensorflow/python/training/saver.py"", line 1276, in restore
    {self.saver_def.filename_tensor_name: save_path})
  File ""/home/nv/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 929, in run
    run_metadata_ptr)
  File ""/home/nv/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1152, in _run
    feed_dict_tensor, options, run_metadata)
  File ""/home/nv/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1328, in _do_run
    run_metadata)
  File ""/home/nv/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1348, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.InvalidArgumentError: Assign requires shapes of both tensors to match. lhs shape= [1,1,256,6] rhs shape= [1,1,256,21]
	 [[node save/Assign_71 (defined at /media/nv/Unix/deeplab/research/deeplab/export_model.py:153) ]]
	 [[node save/RestoreV2 (defined at /media/nv/Unix/deeplab/research/deeplab/export_model.py:153) ]]

Caused by op 'save/Assign_71', defined at:
  File ""/media/nv/Unix/deeplab/research/deeplab/export_model.py"", line 176, in <module>
    tf.app.run()
  File ""/home/nv/.local/lib/python3.6/site-packages/tensorflow/python/platform/app.py"", line 125, in run
    _sys.exit(main(argv))
  File ""/media/nv/Unix/deeplab/research/deeplab/export_model.py"", line 153, in main
    saver = tf.train.Saver(tf.model_variables())
  File ""/home/nv/.local/lib/python3.6/site-packages/tensorflow/python/training/saver.py"", line 832, in __init__
    self.build()
  File ""/home/nv/.local/lib/python3.6/site-packages/tensorflow/python/training/saver.py"", line 844, in build
    self._build(self._filename, build_save=True, build_restore=True)
  File ""/home/nv/.local/lib/python3.6/site-packages/tensorflow/python/training/saver.py"", line 881, in _build
    build_save=build_save, build_restore=build_restore)
  File ""/home/nv/.local/lib/python3.6/site-packages/tensorflow/python/training/saver.py"", line 513, in _build_internal
    restore_sequentially, reshape)
  File ""/home/nv/.local/lib/python3.6/site-packages/tensorflow/python/training/saver.py"", line 354, in _AddRestoreOps
    assign_ops.append(saveable.restore(saveable_tensors, shapes))
  File ""/home/nv/.local/lib/python3.6/site-packages/tensorflow/python/training/saving/saveable_object_util.py"", line 73, in restore
    self.op.get_shape().is_fully_defined())
  File ""/home/nv/.local/lib/python3.6/site-packages/tensorflow/python/ops/state_ops.py"", line 223, in assign
    validate_shape=validate_shape)
  File ""/home/nv/.local/lib/python3.6/site-packages/tensorflow/python/ops/gen_state_ops.py"", line 64, in assign
    use_locking=use_locking, name=name)
  File ""/home/nv/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py"", line 788, in _apply_op_helper
    op_def=op_def)
  File ""/home/nv/.local/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py"", line 507, in new_func
    return func(*args, **kwargs)
  File ""/home/nv/.local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 3300, in create_op
    op_def=op_def)
  File ""/home/nv/.local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 1801, in __init__
    self._traceback = tf_stack.extract_stack()

InvalidArgumentError (see above for traceback): Assign requires shapes of both tensors to match. lhs shape= [1,1,256,6] rhs shape= [1,1,256,21]
	 [[node save/Assign_71 (defined at /media/nv/Unix/deeplab/research/deeplab/export_model.py:153) ]]
	 [[node save/RestoreV2 (defined at /media/nv/Unix/deeplab/research/deeplab/export_model.py:153) ]]


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/media/nv/Unix/deeplab/research/deeplab/export_model.py"", line 176, in <module>
    tf.app.run()
  File ""/home/nv/.local/lib/python3.6/site-packages/tensorflow/python/platform/app.py"", line 125, in run
    _sys.exit(main(argv))
  File ""/media/nv/Unix/deeplab/research/deeplab/export_model.py"", line 167, in main
    initializer_nodes=None)
  File ""/home/nv/.local/lib/python3.6/site-packages/tensorflow/python/tools/freeze_graph.py"", line 151, in freeze_graph_with_def_protos
    saver.restore(sess, input_checkpoint)
  File ""/home/nv/.local/lib/python3.6/site-packages/tensorflow/python/training/saver.py"", line 1312, in restore
    err, ""a mismatch between the current graph and the graph"")
tensorflow.python.framework.errors_impl.InvalidArgumentError: Restoring from checkpoint failed. This is most likely due to a mismatch between the current graph and the graph from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:

Assign requires shapes of both tensors to match. lhs shape= [1,1,256,6] rhs shape= [1,1,256,21]
	 [[node save/Assign_71 (defined at /media/nv/Unix/deeplab/research/deeplab/export_model.py:153) ]]
	 [[node save/RestoreV2 (defined at /media/nv/Unix/deeplab/research/deeplab/export_model.py:153) ]]

Caused by op 'save/Assign_71', defined at:
  File ""/media/nv/Unix/deeplab/research/deeplab/export_model.py"", line 176, in <module>
    tf.app.run()
  File ""/home/nv/.local/lib/python3.6/site-packages/tensorflow/python/platform/app.py"", line 125, in run
    _sys.exit(main(argv))
  File ""/media/nv/Unix/deeplab/research/deeplab/export_model.py"", line 153, in main
    saver = tf.train.Saver(tf.model_variables())
  File ""/home/nv/.local/lib/python3.6/site-packages/tensorflow/python/training/saver.py"", line 832, in __init__
    self.build()
  File ""/home/nv/.local/lib/python3.6/site-packages/tensorflow/python/training/saver.py"", line 844, in build
    self._build(self._filename, build_save=True, build_restore=True)
  File ""/home/nv/.local/lib/python3.6/site-packages/tensorflow/python/training/saver.py"", line 881, in _build
    build_save=build_save, build_restore=build_restore)
  File ""/home/nv/.local/lib/python3.6/site-packages/tensorflow/python/training/saver.py"", line 513, in _build_internal
    restore_sequentially, reshape)
  File ""/home/nv/.local/lib/python3.6/site-packages/tensorflow/python/training/saver.py"", line 354, in _AddRestoreOps
    assign_ops.append(saveable.restore(saveable_tensors, shapes))
  File ""/home/nv/.local/lib/python3.6/site-packages/tensorflow/python/training/saving/saveable_object_util.py"", line 73, in restore
    self.op.get_shape().is_fully_defined())
  File ""/home/nv/.local/lib/python3.6/site-packages/tensorflow/python/ops/state_ops.py"", line 223, in assign
    validate_shape=validate_shape)
  File ""/home/nv/.local/lib/python3.6/site-packages/tensorflow/python/ops/gen_state_ops.py"", line 64, in assign
    use_locking=use_locking, name=name)
  File ""/home/nv/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py"", line 788, in _apply_op_helper
    op_def=op_def)
  File ""/home/nv/.local/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py"", line 507, in new_func
    return func(*args, **kwargs)
  File ""/home/nv/.local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 3300, in create_op
    op_def=op_def)
  File ""/home/nv/.local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 1801, in __init__
    self._traceback = tf_stack.extract_stack()

InvalidArgumentError (see above for traceback): Restoring from checkpoint failed. This is most likely due to a mismatch between the current graph and the graph from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:

Assign requires shapes of both tensors to match. lhs shape= [1,1,256,6] rhs shape= [1,1,256,21]
	 [[node save/Assign_71 (defined at /media/nv/Unix/deeplab/research/deeplab/export_model.py:153) ]]
	 [[node save/RestoreV2 (defined at /media/nv/Unix/deeplab/research/deeplab/export_model.py:153) ]]
",nosleduc,None,2019-04-24T10:30:59Z,2019-04-30T14:01:15Z,,,,,,,
6649,'module' object has no attribute 'GraphDef',"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",haydariashik,None,2019-04-23T19:23:59Z,2019-04-30T21:25:24Z,,,,,,,
6646,image_id to image_file_name mapping for object detection custom evaluator,"**System Information:**

OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS Mojave 10.14.2
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy): NA
TensorFlow installed from (source or binary): binary
TensorFlow version: 1.12.0
Python version: 3.6
Installed using virtualenv? pip? conda?: Conda
Bazel version (if compiling from source): NA
GCC/Compiler version (if compiling from source): NA
CUDA/cuDNN version: NA
GPU model and memory: NA

**Problem Description:**

I'm using a custom evaluator by extending object_detection_evaluation.DetectionEvaluator to have better control on evaluation protocol and training progress. I would like to map image_id to the actual image file for debugging which isn't available at evaluator. It would be good to pass the same.

If this request looks reasonable, I would be happy to provide a PR.

",kmadhugit,b'stat:awaiting response',2019-04-23T16:13:02Z,2020-03-25T23:03:53Z,,,,,,,
6644,"Got 2 frames, but animated gifs can only be decoded by tf.image.decode_gif or tf.image.decode_image 	 [[{{node DecodeJpeg_1}}]]","Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",cxrus,None,2019-04-23T14:24:46Z,2020-03-25T23:03:52Z,,,,,,,
6605,How to train model using TFSlim library?,"I'm reading Object Detection API source code and I wonder how to use TFSlim to train model?

More specifically, when we use Tensorflow to train the model, we use something like this:

    parameters = model(X_train, Y_train, X_test, Y_test)
    # Returns: parameters -- parameters learnt by the model. 
    # They can then be used to predict.

And to predict the result, we use something like:

    y_image_prediction = predict(my_image, parameters)

But in file trainer.py, we don't have something like above, we only get:

    slim.learning.train(
        train_tensor,
        logdir=train_dir,
        master=master,
        is_chief=is_chief,
        session_config=session_config,
        startup_delay_steps=train_config.startup_delay_steps,
        init_fn=init_fn,
        summary_op=summary_op,
        number_of_steps=(
            train_config.num_steps if train_config.num_steps else None),
        save_summaries_secs=120,
        sync_optimizer=sync_optimizer,
        saver=saver)

And there are no return about this `slim.learning.train` function. So I wonder what is the using of `slim.learning.train` function, and how do we get the parameters -- that can be used to predict the result? 

[HERE][1] is source code of trainer.py.


  [1]: https://github.com/tensorflow/models/blob/master/research/object_detection/legacy/trainer.py

------------------------

### System information
- **What is the top-level directory of the model you are using**:
NA
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**:source
- **TensorFlow version (use command below)**:1.12
- **Bazel version (if compiling from source)**:NA
- **CUDA/cuDNN version**:NA
- **GPU model and memory**:Titan V
- **Exact command to reproduce**:NA

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",AI-LastWish,None,2019-04-18T07:44:31Z,2019-04-19T07:25:53Z,,,,,,,
6603,During creating embedding file,"
/home/quantiphi/anaconda3/bin/python /snap/pycharm-community/123/helpers/pydev/pydevd.py --multiproc --qt-support=auto --client 127.0.0.1 --port 33961 --file /home/quantiphi/PycharmProjects/training_skipThoughts/vocabulary_expansion.py
pydev debugger: process 6624 is connecting

Connected to pydev debugger (build 191.6605.12)
paramiko missing, opening SSH/SCP/SFTP paths will be disabled.  `pip install paramiko` to suppress
/home/quantiphi/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
INFO:tensorflow:Loading skip-thoughts embedding matrix from /home/quantiphi/PycharmProjects/training_skipThoughts/train_file/model.ckpt-13
INFO:tensorflow:Loaded skip-thoughts embedding matrix of shape (20000, 620)
INFO:tensorflow:Reading vocabulary from /home/quantiphi/PycharmProjects/training_skipThoughts/data/out2txt/vocab.txt
Backend Qt5Agg is interactive backend. Turning interactive mode on.
INFO:tensorflow:Read vocabulary of size 20000
INFO:tensorflow:Finding shared words
INFO:tensorflow:Selecting embeddings for 10892 shared words
INFO:tensorflow:Training linear regression model
INFO:tensorflow:Creating embeddings for expanded vocabuary
size >>>>>>>>>>>> 6404648
INFO:tensorflow:Created expanded vocabulary of 85452 words
size >>>>>>>>>>>> 88
INFO:tensorflow:Wrote vocabulary file to vocabFile/vocab.txt
Traceback (most recent call last):
  File ""/snap/pycharm-community/123/helpers/pydev/pydevd.py"", line 1741, in <module>
    main()
  File ""/snap/pycharm-community/123/helpers/pydev/pydevd.py"", line 1735, in main
    globals = debugger.run(setup['file'], None, None, is_module)
  File ""/snap/pycharm-community/123/helpers/pydev/pydevd.py"", line 1135, in run
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File ""/snap/pycharm-community/123/helpers/pydev/_pydev_imps/_pydev_execfile.py"", line 18, in execfile
    exec(compile(contents+""\n"", file, 'exec'), glob, loc)
  File ""/home/quantiphi/PycharmProjects/training_skipThoughts/vocabulary_expansion.py"", line 205, in <module>
    tf.app.run()
  File ""/home/quantiphi/.local/lib/python3.6/site-packages/tensorflow/python/platform/app.py"", line 126, in run
    _sys.exit(main(argv))
  File ""/home/quantiphi/PycharmProjects/training_skipThoughts/vocabulary_expansion.py"", line 200, in main
    np.save(embeddings_file, embeddings)
  File ""/home/quantiphi/.local/lib/python3.6/site-packages/numpy/lib/npyio.py"", line 529, in save
    pickle_kwargs=pickle_kwargs)
  File ""/home/quantiphi/.local/lib/python3.6/site-packages/numpy/lib/format.py"", line 629, in write_array
    pickle.dump(array, fp, protocol=2, **pickle_kwargs)
TypeError: can't pickle odict_values objects


PLease help me to fix this issue",karthika-devi,None,2019-04-18T06:01:11Z,2020-03-25T23:04:19Z,,,,,,,
6600,how to use tf.feature_column with tf.keras.Model,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",wendongqu,b'stat:awaiting response type:support',2019-04-17T23:59:11Z,2020-08-08T02:15:36Z,,,,,,,
6599,"Recent DELF updates, including initial Detect-to-Retrieve code","- Small bug fixes
- DELF extraction function refactoring
- Initial D2R code with box extraction proto/library/scripts",andrefaraujo,b'cla: yes',2019-04-17T23:41:48Z,2019-04-18T18:04:54Z,,,,,,,
6586,fix bug in research/deep_speech model when is_bidirectional == False,"When is_bidirectional == False, the original version passes the output tuple (output tensor and state tensor) of unidirectional RNN to the rnn_outputs. However, it should pass the exact output tensor instead of the tuple to the rnn_outputs.",xysmlx,b'cla: yes',2019-04-16T12:50:04Z,2020-04-24T06:22:09Z,,,,,,,
6580,Tensorflow object detection training hangs on INFO:tensorflow:Done running local_init_op.,"-----------------------

### System information
- **What is the top-level directory of the model you are using**:

/object_detection

- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Windows 10   1803 - Build  17134.137

- **TensorFlow installed from (source or binary)**:

Binary

Bazel version
n/a


- **TensorFlow version (use command below)**:

Tensorflow gpu 1.12.0

- **CUDA/cuDNN version**:

CUDA 10, cudnn 7.4.1.5.

- **GPU model and memory**:

1070 , 8GB

- **Exact command to reproduce**:

python model_main.py pipeline_config_path=train\pipeline.config --num_training_steps=50000 --alsologtostderr --sample_1_of_n_eval_examples=1 --num_eval_steps=50



Tensorflow-gpu 1.12.0

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

model training hangs after 
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.

Building a faster rcnn model using


### Source code / logs
INFO:tensorflow:loss = 0.21724904, step = 1900 (23.515 sec)
INFO:tensorflow:global_step/sec: 4.29146
INFO:tensorflow:loss = 0.12039319, step = 2000 (23.302 sec)
INFO:tensorflow:global_step/sec: 4.29928
INFO:tensorflow:loss = 0.09950572, step = 2100 (23.260 sec)
INFO:tensorflow:global_step/sec: 4.33873
INFO:tensorflow:loss = 0.19138448, step = 2200 (23.048 sec)
INFO:tensorflow:global_step/sec: 4.31786
INFO:tensorflow:loss = 0.16577782, step = 2300 (23.178 sec)
INFO:tensorflow:global_step/sec: 4.29797
INFO:tensorflow:loss = 0.20454644, step = 2400 (23.250 sec)
INFO:tensorflow:global_step/sec: 4.34147
INFO:tensorflow:loss = 0.13730098, step = 2500 (23.035 sec)
INFO:tensorflow:Saving checkpoints for 2565 into C:\Users\AI\AppData\Local\Temp\tmp5tf_l_nn\model.ckpt.
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:Scale of 0 disables regularizer.
INFO:tensorflow:Scale of 0 disables regularizer.
INFO:tensorflow:Scale of 0 disables regularizer.
INFO:tensorflow:depth of additional conv before box predictor: 0
INFO:tensorflow:Scale of 0 disables regularizer.
INFO:tensorflow:Scale of 0 disables regularizer.
INFO:tensorflow:Scale of 0 disables regularizer.
INFO:tensorflow:Scale of 0 disables regularizer.
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Starting evaluation at 2019-04-16-02:06:58
INFO:tensorflow:Graph was finalized.
2019-04-16 12:06:59.249796: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-04-16 12:06:59.255662: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-04-16 12:06:59.260656: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0
2019-04-16 12:06:59.265927: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N
2019-04-16 12:06:59.270140: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6397 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1070, pci bus id: 0000:65:00.0, compute capability: 6.1)
INFO:tensorflow:Restoring parameters from C:\Users\AI\AppData\Local\Temp\tmp5tf_l_nn\model.ckpt-2565
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.


",bzburr,b'stat:awaiting response',2019-04-16T02:17:44Z,2020-05-21T05:25:16Z,,,,,,,
6577,"hi , I want to store my loss value in an array for my personal metrics. But I am not able to find the function from where i can get loss value.  Can you please help me out of this i used tensorflow object detection API with ssd mobilenet. Also i am using my own dataset. Thank you in advance.","Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",jalpa91,None,2019-04-15T19:38:44Z,2020-03-18T21:17:17Z,,,,,,,
6565,Deeplab does not produce correct segmentation mask.,"------------------------

### System information
- **What is the top-level directory of the model you are using**: models->research ->Deeplab
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**:1.13
- **Bazel version (if compiling from source)**: bazel-0.24.0-installer-darwin-x86_64


### Describe the problem

I am training my own model to segment squares in images using Deeplab. For that I have annotated the training data, Heres an example of training image(on left) and segmentation mask  image(on right).

<img width=""1042"" alt=""Screenshot 2019-04-12 at 12 29 17 PM"" src=""https://user-images.githubusercontent.com/17012391/56018029-9911e680-5d1e-11e9-9d51-74b839f58b7a.png"">

I am converting this training data to record file using: Deeplab-> build_voc2012_data.py

I have further made following changes to the scripts described as below, These changes are such that I can train my own dataset.

**deeplab -> datasets -> datagenerator.py**

> TESTSET_INFORMATION = DatasetDescriptor(
>     splits_to_sizes={
>         'train': 800,  # num of samples in images/training
>         'val': 200,  # num of samples in images/validation
>     },
>     num_classes=2,
>     ignore_label=255,    # When setting ignore_label = 0 predictions come back as a red or green image; and when setting ignore_label = 255 predictions come back as a black image
> )
> _DATASETS_INFORMATION = {
>     'cityscapes': _CITYSCAPES_INFORMATION,
>     'pascal_voc_seg': _PASCAL_VOC_SEG_INFORMATION,
>     'ade20k': _ADE20K_INFORMATION,
>     'testset': _TESTSET_INFORMATION,
> }
> 

**utils > train_utils.py**

> exclude_list = ['global_step', 'logits'] 


> not_ignore_mask = tf.to_float(tf.equal(scaled_labels, 0)) * 1 + tf.to_float(tf    .equal(scaled_labels, 1)) * 2 + tf.to_float(tf.equal(scaled_labels, ignore_label    )) * 0

Please note batch size=12. And training number of steps = 1000. I get following predictions

<img width=""1088"" alt=""Screenshot 2019-04-12 at 12 37 56 PM"" src=""https://user-images.githubusercontent.com/17012391/56018457-cf039a80-5d1f-11e9-96bf-5cf6171619b1.png"">

I am not sure what is it I am doing wrong ?
To further debug the problem I observed that during training the loss dosen't change it keeps on oscillating.

example loss is:

> Total loss is :[0.0697127208]
> INFO:tensorflow:global_step/sec: 0.715997
> Total loss is :[0.0697126836]
> INFO:tensorflow:global_step/sec: 0.835336
> Total loss is :[0.0697126538]
> INFO:tensorflow:global_step/sec: 0.83706
> Total loss is :[0.0697126389]
> INFO:tensorflow:global_step/sec: 0.833028
> Total loss is :[0.069712624]
> INFO:tensorflow:global_step/sec: 0.836747
> Total loss is :[0.069712624]
> INFO:tensorflow:global_step/sec: 0.831312
> Total loss is :[0.069712624]
> INFO:tensorflow:global_step/sec: 0.832811
> Total loss is :[0.069712624]
> INFO:tensorflow:global_step/sec: 0.83014
> Total loss is :[0.069712624]
> INFO:tensorflow:global_step/sec: 0.830697
> 
> 

**What should I do so that the loss is reduced and the model gives a proper square as a segmentation output ?**

@bleedingfight @aquariusjay  @Citygity could you shed some light and help me bring one step closer to the solution ?",ajinkya933,None,2019-04-12T07:18:48Z,2019-06-14T12:55:09Z,,,,,,,
6550,Object detection exported SavedModel input has no shape,"### System information
- **What is the top-level directory of the model you are using**: object_detection
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.12.0
- **Bazel version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: 9.0
- **GPU model and memory**: V100, 16GB
- **Exact command to reproduce**:  `saved_model_cli show --dir <saved_model_path> --all`

### Describe the problem
The object detection API automatically exported a SavedModel with `variables` directory and `saved_model.pb` upon my training completion. When I run `saved_model_cli` on this directory, the SavedModel SignatureDef input has no shape:

```
signature_def['serving_default']:
  The given SavedModel SignatureDef contains the following input(s):
    inputs['serialized_example'] tensor_info:
        dtype: DT_STRING
        shape: ()
        name: tf_example:0
```
Is this a bug or the intended result? The training size in my model .config file was set to `width: 640`, `height: 480`. Are there kwargs for `model_main.py` related to this?",austinmw,None,2019-04-09T21:12:48Z,2020-03-25T23:04:16Z,,,,,,,
6542,train,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",2018daofeng,None,2019-04-08T03:07:32Z,2019-04-12T23:28:54Z,,,,,,,
6541,train,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",2018daofeng,None,2019-04-08T03:07:21Z,2019-04-12T23:29:19Z,,,,,,,
6523,Tensorrt INT8 calibration for caffe-yolov3 failed ,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",tilaba,None,2019-04-04T08:20:54Z,2020-08-03T04:00:15Z,,,,,,,
6521,Tensorflow r1.13 Bazel Build Failure,"OS: Linux version 3.18.6-2.el7.centos.x86_64
Bazel : Build label: 0.20.0
gcc (GCC) 7.2.1 20170829 (Red Hat 7.2.1-1)
Python 2.7.16 :: Anaconda, Inc.

ERROR: /root/.cache/bazel/_bazel_root/9fd418c66caf2752d640a3e143a42ab2/external/org_tensorflow/tensorflow/core/kernels/BUILD:3206:1: C++ compilation of rule '@org_tensorflow//tensorflow/core/kernels:reduction_ops' failed (Exit 1)
In file included from external/eigen_archive/unsupported/Eigen/CXX11/Tensor:124:0,
                 from external/org_tensorflow/third_party/eigen3/unsupported/Eigen/CXX11/Tensor:1,
                 from external/org_tensorflow/tensorflow/core/kernels/reduction_ops_common.h:27,
                 from external/org_tensorflow/tensorflow/core/kernels/reduction_ops_sum.cc:16:
external/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorReduction.h: In static member function 'static void std::_Function_handler<void(_ArgTypes ...), _Functor>::_M_invoke(const std::_Any_data&, _ArgTypes&& ...) [with _Functor = Eigen::internal::TensorExecutor<Expression, Eigen::ThreadPoolDevice, Vectorizable, Tileable>::run(const Expression&, const Eigen::ThreadPoolDevice&) [with Expression = const Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<std::complex<float>, 0, 1, long int>, 16, Eigen::MakePointer>, const Eigen::TensorReductionOp<Eigen::internal::SumReducer<std::complex<float> >, const Eigen::IndexList<Eigen::type2index<0> >, const Eigen::TensorMap<Eigen::Tensor<const std::complex<float>, 1, 1, long int>, 16, Eigen::MakePointer>, Eigen::MakePointer> >; bool Vectorizable = true; bool Tileable = false]::<lambda(Eigen::internal::TensorExecutor<const Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<std::complex<float>, 0, 1, long int>, 16, Eigen::MakePointer>, const Eigen::TensorReductionOp<Eigen::internal::SumReducer<std::complex<float> >, const Eigen::IndexList<Eigen::type2index<0> >, const Eigen::TensorMap<Eigen::Tensor<const std::complex<float>, 1, 1, long int>, 16, Eigen::MakePointer>, Eigen::MakePointer> >, Eigen::ThreadPoolDevice, true, false>::StorageIndex, Eigen::internal::TensorExecutor<const Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<std::complex<float>, 0, 1, long int>, 16, Eigen::MakePointer>, const Eigen::TensorReductionOp<Eigen::internal::SumReducer<std::complex<float> >, const Eigen::IndexList<Eigen::type2index<0> >, const Eigen::TensorMap<Eigen::Tensor<const std::complex<float>, 1, 1, long int>, 16, Eigen::MakePointer>, Eigen::MakePointer> >, Eigen::ThreadPoolDevice, true, false>::StorageIndex)>; _ArgTypes = {long int, long int}]':
external/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorReduction.h:801:9: internal compiler error: in emit_move_insn, at expr.c:3698
         values[i] = internal::InnerMostDimReducer<Self, Op>::reduce(*this, firstIndex + i * num_values_to_reduce,
         ^~~~~~
Please submit a full bug report,
with preprocessed source if appropriate.
See <http://bugzilla.redhat.com/bugzilla> for instructions.
Preprocessed source stored into /tmp/cc383lvq.out file, please attach this to your bugreport.
INFO: Elapsed time: 548.113s, Critical Path: 209.08s
INFO: 4386 processes: 4386 local.
FAILED: Build did NOT complete successfully",FrankYu0502,b'stat:awaiting response',2019-04-04T03:21:32Z,2019-05-14T20:45:58Z,,,,,,,
6516,INT8 calibartion for tensorrt-yolov3 failed,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",tilaba,None,2019-04-03T15:25:14Z,2020-03-25T23:04:41Z,,,,,,,
6512,GCP Pet training failed,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",tonychen257,None,2019-04-03T08:17:58Z,2020-03-25T23:04:40Z,,,,,,,
6510,Fix Resnet XLA with multi-GPUs,Don't pass `batch_size` to keras.layers.Input in DS multi-replica case. There is currently a bug in Keras side which will cause a batch size incompatible error.,rxsang,b'cla: yes',2019-04-03T00:01:59Z,2020-02-17T20:07:55Z,,,,,,,
6509,steps_per_epoch not honored in tf.keras.fit ,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

## Please refer to this issue: https://github.com/tensorflow/tensorflow/issues/24075


### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",ToddMorrill,None,2019-04-02T22:11:33Z,2020-03-18T21:14:27Z,,,,,,,
6501,Resnet model creates new nccl communicator for each allreduce,"### System information
- **What is the top-level directory of the model you are using**:
models/official/resnet/
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: no
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: ubuntu 16.04
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: 2.0 alpha
- **Bazel version (if compiling from source)**: n/a
- **CUDA/cuDNN version**: 10.0/
- **GPU model and memory**: V100 16GB
- **Exact command to reproduce**: NCCL_DEBUG=info NCCL_DEBUG_SUBSYS=coll python imagenet_main.py --num_gpus=2 --use_synthetic_data --train_epochs=1 --max_train_steps=1000 --use_train_and_evaluate=True  --distribution_strategy=multi_worker_mirrored --all_reduce_alg=nccl --worker_hosts=""SOME_HOSTS"" --task_index=SOME_INDEX

### Describe the problem
It looks like that resnet model (or TensorFlow itself?) creates new nccl communicator for each collective operation which is too expensive for distributed computations. Is it a bug in TensorFlow?

### Source code / logs
I0401 05:03:06.554658 140477256177408 session_manager.py:500] Running local_init_op.
I0401 05:03:06.692303 140477256177408 session_manager.py:502] Done running local_init_op.
I0401 05:03:11.522593 140477256177408 basic_session_run_hooks.py:594] Saving checkpoints for 0 into /tmp/model.ckpt.
[0] NCCL INFO NET/Socket : Using [0]ib0:21.21.21.61<0> [1]ib2:22.22.22.61<0> [2]ib4:23.23.23.61<0> [3]ib6:24.24.24.61<0>
[0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so).
[0] NCCL INFO NET/IB : Using [0]mlx5_6:1/IB [1]mlx5_4:1/IB [2]mlx5_2:1/IB [3]mlx5_0:1/IB ; OOB ib0:21.21.21.61<0>
[0] NCCL INFO Using network IB
NCCL version 2.4.3+cuda10.0
[0] NCCL INFO Setting affinity for GPU 0 to 3ffff0,0003ffff
[0] NCCL INFO comm 0x7fb840002a10 rank 0 nranks 2 cudaDev 0 nvmlDev 0
[0] NCCL INFO CUDA Dev 0[0], IB NIC distance :  SOC SOC SOC PIX
[0] NCCL INFO Channel 00 :    0   1
[0] NCCL INFO Channel 01 :    0   1
[0] NCCL INFO Ring 00 : 1 -> 0 [receive] via NET/IB/3
[0] NCCL INFO Ring 00 : 0 -> 1 [send] via NET/IB/3
[0] NCCL INFO Ring 01 : 1 -> 0 [receive] via NET/IB/3
[0] NCCL INFO Ring 01 : 0 -> 1 [send] via NET/IB/3
[0] NCCL INFO Using 256 threads, Min Comp Cap 7, Trees disabled
[0] NCCL INFO comm 0x7fb840002a10 rank 0 nranks 2 cudaDev 0 nvmlDev 0 - Init COMPLETE
**[0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fba1e1f6300 recvbuff 0x7fba2b49f200 count 64 datatype 7 op 0 root 0 comm 0x7fb840002a10 [nranks=2] stream 0x7fb4400014a0**
[0] NCCL INFO Launch mode Parallel
[0] NCCL INFO Setting affinity for GPU 0 to 3ffff0,0003ffff
[0] NCCL INFO comm 0x7fb84002da90 rank 0 nranks 2 cudaDev 0 nvmlDev 0
[0] NCCL INFO Channel 00 :    0   1
[0] NCCL INFO Channel 01 :    0   1
[0] NCCL INFO Ring 00 : 1 -> 0 [receive] via NET/IB/3
[0] NCCL INFO Ring 00 : 0 -> 1 [send] via NET/IB/3
[0] NCCL INFO Ring 01 : 1 -> 0 [receive] via NET/IB/3
[0] NCCL INFO Ring 01 : 0 -> 1 [send] via NET/IB/3
[0] NCCL INFO Using 256 threads, Min Comp Cap 7, Trees disabled
[0] NCCL INFO comm 0x7fb84002da90 rank 0 nranks 2 cudaDev 0 nvmlDev 0 - Init COMPLETE
**[0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fba1e1f6400 recvbuff 0x7fba2b49f300 count 64 datatype 7 op 0 root 0 comm 0x7fb84002da90 [nranks=2] stream 0x7fb4400014a0**",Sergei-Lebedev,None,2019-04-01T12:04:24Z,2020-03-19T06:12:41Z,,,,,,,
6482,No model saved for object_detection API using,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.


****
**Hello, I use the example of ssd_mobilenet_v1_focal_loss_pets.config. I use on detection my own object, e.g., hands, I set the num_steps as 1000000 which is very big. Some guys told me that the check-points can be saved every ten minutes, however, I have not found the saved check-point currently on my training directory.  
How can I resolve the issue?
Thanks & Regards!**

****",momo1986,None,2019-03-30T01:48:02Z,2019-05-08T21:25:07Z,,,,,,,
6476, dataset_name [cifar-10-python] was not recognized.,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",zzm699520,b'stat:awaiting response type:support',2019-03-29T02:52:22Z,2019-04-03T23:18:54Z,,,,,,,
6474,[DeepLab]: No input node after training,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**: deeplab
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 18.04
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**:1.13.1
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**: Using cpu for this purpose
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
I'm using Deeplab to train on my custom data, `train.sh` looks like this:
```
NUM_ITERATIONS=5 ##just for this illustration
python ""${WORK_DIR}""/train.py \
  --logtostderr \
  --train_split=""train"" \
  --model_variant=""xception_65"" \
  --atrous_rates=6 \
  --atrous_rates=12 \
  --atrous_rates=18 \
  --output_stride=16 \
  --decoder_output_stride=4 \
  --train_crop_size=513 \
  --train_crop_size=513 \
  --train_batch_size=4 \
  --training_number_of_steps=""${NUM_ITERATIONS}"" \
  --fine_tune_batch_norm=true \
  --tf_initial_checkpoint=""${INIT_FOLDER}/model.ckpt"" \
  --train_logdir=""${TRAIN_LOGDIR}"" \
  --dataset_dir=""${DATASET}""
```
If I run summarize graph on downloaded weights, I'm getting input and output node (see the attahced file: pre_traning.txt)
`./tensorflow$ bazel-bin/tensorflow/tools/graph_transforms/summarize_graph --in_graph=/path-to/frozen_inference_graph.pb`
```
Found 1 possible inputs: (name=ImageTensor, type=uint8(4), shape=[1,?,?,3]) 
No variables spotted.
Found 1 possible outputs: (name=SemanticPredictions, op=Slice) 
Found 41259000 (41.26M) const parameters, 0 (0) variable parameters, and 4 control_edges

```
But, if I run the same command on the trained model (graph.pbtxt), I'm not finding input node
```
No inputs spotted.
Found 1173 variables: (..)
Found 1428 possible outputs: (..)
```
Am I doing something wrong (see the attahced file: after_traning.txt)? 

[after_traning.txt](https://github.com/tensorflow/models/files/3020546/after_traning.txt)
[pre_traning.txt](https://github.com/tensorflow/models/files/3020547/pre_traning.txt)

However, I'm able to run validation and visualization steps without any issues. I ran into this issue when I tried to freeze grpah files to create `.pb` file, there I need to provide the name of Input and Output tensors. 

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",ramesh8v,None,2019-03-28T23:55:33Z,2019-04-04T20:09:23Z,,,,,,,
6469,Multi-GPU Error with Deeplabv3 updated version,"### System information
- **What is the top-level directory of the model you are using**: deeplab
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 18.04
- **TensorFlow installed from (source or binary)**:docker-tensorflow-gpu
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:10.0
- **GPU model and memory**: GTX1080 * 2, memory 11G each
- **Exact command to reproduce**: 
research_home_dir='/app/'
export PYTHONPATH=$PYTHONPATH:${research_home_dir}:${research_home_dir}slim

python /app/deeplab/ori_train_e.py \
    --logtostderr \
    --initialize_last_layer=False \
    --last_layers_contain_logits_only=False \
    --num_clones=2 \
    --training_number_of_steps=150000 \
    --train_split=""train"" \
    --model_variant=""xception_65"" \
    --atrous_rates=6 \
    --atrous_rates=12 \
    --atrous_rates=18 \
    --output_stride=16 \
    --decoder_output_stride=4 \
    --train_crop_size=513 \
    --train_crop_size=513 \
    --train_batch_size=4 \
    --fine_tune_batch_norm=False \
    --min_resize_value=513 \
    --max_resize_value=513 \
    --resize_factor=16 \
    --dataset=""ade20k17"" \
    --tf_initial_checkpoint=""/app/tf_initial_checkpoint/model.ckpt"" \
    --train_logdir=""/app/trainlog"" \
    --dataset_dir=""/app/tfrecord"" \
    --checkpoint_dir=""/app/checkpoint_dir"" \
    --eval_logdir=""/app/evallog"" \
    --log_steps=10 \
    --save_summaries_images=True \
    --save_interval_secs=1200 \
    --save_summaries_secs=600 \
    --learning_rate_decay_step=4000
~                                     
You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.
**Every time, I set the gpu(num_clones) greater or equals to 2, the program will just freeze and become a zombie that I could not kill.

My question is, does anyone have the same issue with me that the code is not compatible with multi-gpus?**

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.


The program just stuck there and there is no information come out. 

Any help is welcome!
Thanks!",Eavis,None,2019-03-28T18:46:23Z,2020-03-25T23:04:37Z,,,,,,,
6457,ncf_keras_main doesn't run ,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**: models/official/recommendation
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: no
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: linux ubuntu 18.04
- **TensorFlow installed from (source or binary)**: pip install
- **TensorFlow version (use command below)**: b'v1.13.1-0-g6612da8951' 1.13.1
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**: 10.0 , 7.5
- **GPU model and memory**: 
- **Exact command to reproduce**:./run_keras.sh

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

I'm trying to run_keras.sh and it outputs an error `ValueError: When using iterators as input to a model, you should specify the `steps_per_epoch` argument.` 

so I tried adding `steps_per_epoch=producer.train_batches_per_epoch` 
but it gives me warning message

`W0327 23:25:59.123543 140526636000832 training_arrays.py:273] Your dataset iterator ran out of data; interrupting training. Make sure that your dataset can g
enerate at least `steps_per_epoch * epochs` batches (in this case, 311 batches)`

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",littlehome-eugene,b'models:official',2019-03-27T14:54:02Z,2020-03-25T23:04:58Z,,,,,,,
6455,bounding box ,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",baronpalacios,None,2019-03-27T12:28:06Z,2019-03-29T21:51:46Z,,,,,,,
6454,Xmax,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",baronpalacios,None,2019-03-27T12:24:57Z,2019-03-29T21:50:37Z,,,,,,,
6441,ncf bisection negative sampling doesn't look right,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**: recommendation
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: no
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: linux ubuntu 18.04
- **TensorFlow installed from (source or binary)**: pip install
- **TensorFlow version (use command below)**: b'v1.13.1-0-g6612da8951' 1.13.1
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**: 10.0, 7.5
- **GPU model and memory**: geforce 2060, 6gig
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.


I'm trying to use ncf_keras from recommendation model.

in `lookup_negative_items` , 
there's a comment that says: 

`# Expected state after bisection pass:                                                                                                                       #   The right index is the smallest index whose tally is greater than the                                                                                    #   negative item choice index.
`

I couldn't make sense of it, so I tried with a small sample , and printed out variables.  

I think the above comment means, 
`right_index` 's value should be smallest index of `self._total_negatives` which is greather than `neg_item_choice`

Then  I think `self._total_negatives[right_index] - neg_item_choice:  [-1 -2  0  3  0 -2]`  shouldn't have negative values.

Besides 
```
negative_users:  [1 0 2 2 2 1]
negative_items:  [4 3 6 0 6 5]  

```
says user 2 has not rated 6, 0 but user 2 did rate 6 given 
```
_train_pos_users: [0, 0, 1, 1, 1, 2, 2, 2, 2]
_sorted_train_pos_items: [0 1 0 1 3 3 4 5 6]

```

Am I misinterpretating the comments or the code is buggy because data size is too small?


```
     output[not_use_shortcut] = (
         self._sorted_train_pos_items[right_index] -
         (self._total_negatives[right_index] - neg_item_choice)
     )
```
The above code, is interpreted:
`self._sorted_train_pos_items[right_index]` get the item at right_index (which is smallest index whose tally is bigger than neg_item_choice)
`self._total_negatives[right_index]` total negative tally at right_index
`neg_item_choice` a random choice 
,

so in a sense,  it picks an item at right_index and substracts a random amount, I don't see how it could be guaranteed to pick a negative(unrated) item..  



I forcefully bypassed `use_shortcut` 

```
user_map: {0: 0, 1: 1, 3: 2}
item_map: {33: 2, 2: 5, 3: 3, 22: 1, 7: 6, 8: 4, 9: 7, 11: 0}
batch_ind_mod:  [3 1 8 6 5 3]
users:  [1 0 2 2 2 1]
negative_indices:  [ True  True  True  True  True  True]                                                                                                     negative_users:  [1 0 2 2 2 1]
index_bounds: [0 2 5 9]
num_positives:  [3 2 4 4 4 3]
num_negatives:  [5 6 4 4 4 5]
neg_item_choice: [2 2 3 0 3 3]
left_index: [2 0 5 5 5 2]
right_index: [4 1 8 8 8 4]                                                                                                                                   num_positives:  [3 2 4 4 4 3]                                                                                                                                num_negatives:  [5 6 4 4 4 5]                                                                                                                                neg_item_choice: [2 2 3 0 3 3]                                                                                                                               total_negatives:  [0 0 0 0 1 3 3 3 3]                                                                                                                        use_shortcut:  [False False False False False False]                                                                                                                                                                                                                                        mid_index:  [3 0 7 5 7 3]
right_criteria:  [False False False  True False False]                                                                                                       right_index:  [4 1 8 5 8 4]
left_index:  [3 0 7 5 7 3]
_sorted_train_pos_items: [0 1 0 1 3 3 4 5 6]
_total_negatives:  [0 0 0 0 1 3 3 3 3]
self._sorted_train_pos_items[right_index]:  [3 1 6 3 6 3]
self._total_negatives[right_index]:  [1 0 3 3 3 1]
self._total_negatives[right_index] - neg_item_choice:  [-1 -2  0  3  0 -2]
negative_items:  [4 3 6 0 6 5] 
```


I tested this with following data
```
user_id,item_id,rating,timestamp
0,11,1,2
0,22,1,2
0,33,1,2                                                                                                                                                     1,3,1,2
1,22,1,2
1,11,1,2                                                                                                                                                     1,8,1,2
3,2,1,2
3,3,1,2
3,7,1,2
3,8,1,2
3,9,1,2

```
### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",littlehome-eugene,b'stat:awaiting response type:support',2019-03-26T13:00:26Z,2020-08-08T02:18:31Z,,,,,,,
6431,mask can can not be drawed after training due to mask shape error,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
object detection
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Ubuntu 16.04
- **TensorFlow installed from (source or binary)**:
binary
- **TensorFlow version (use command below)**:
1.12
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
9.0/7.4
- **GPU model and memory**:
24GB
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.

It is fine when i am training with Mask R-CNN via mask_rcnn_resnet101_atrous_coco.config, the visualization of mask is clearly showed in evalution tensorboard. When I exported the checkpoint to the freeze graph and doing the inference, the mask shape is wrong:
image shape is (1, 636, 1024, 3)
mask shape is (7, 1, 636)
Traceback (most recent call last):
File ""run_inference.py"", line 225, in 
min_score_thresh=0.2)
File ""/home/models/research/object_detection/utils/visualization_utils.py"", line 726, in visualize_boxes_and_labels_on_image_array
color=color
File ""/home/models/research/object_detection/utils/visualization_utils.py"", line 609, in draw_mask_on_image_array
'dimensions %s' % (image.shape[:2], mask.shape))
ValueError: The image has spatial dimensions (636, 1024) but the mask has dimensions (1, 636)",roger1993,None,2019-03-25T06:29:07Z,2019-03-25T06:50:05Z,,,,,,,
6430,mask shape of mask rcnn is wrong ,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
     object detection
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:

- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.


It is fine when i am training with Mask R-CNN, the visualization of mask is clearly showed in evalution tensorboard. When I exported the checkpoint to the freeze graph and doing the inference, the mask shape is wrong:
image shape is (1, 636, 1024, 3) 
box shape is <unknown> 
mask shape is (7, 1, 636)
Traceback (most recent call last):
  File ""run_inference.py"", line 225, in <module>
    min_score_thresh=0.2)
  File ""/home/rgou/models/research/object_detection/utils/visualization_utils.py"", line 726, in visualize_boxes_and_labels_on_image_array
    color=color
  File ""/home/rgou/models/research/object_detection/utils/visualization_utils.py"", line 609, in draw_mask_on_image_array
    'dimensions %s' % (image.shape[:2], mask.shape))
ValueError: The image has spatial dimensions (636, 1024) but the mask has dimensions (1, 636)

",roger1993,None,2019-03-25T06:04:20Z,2019-03-25T06:05:33Z,,,,,,,
6429,mask rcnn,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",roger1993,None,2019-03-25T05:40:43Z,2019-03-25T05:41:01Z,,,,,,,
6428,[Deeplab] is there a bug in refine_by_decoder,"### System information
- **What is the top-level directory of the model you are using**: 
   [Deeplab](https://github.com/tensorflow/models/tree/master/research/deeplab)
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
    No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
    Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**:
    Binary
- **TensorFlow version (use command below)**:
    1.13.1
- **CUDA/cuDNN version**:
    CUDA 9.0, cuDNN 7.4.2
- **GPU model and memory**:
    3*NVIDIA 1080Ti

### Describe the problem

I also have a question on `refine_by_decoder`. Would really appreciate it if @aquariusjay could take a look too.

https://github.com/tensorflow/models/blob/aad56e4c428ce9ff5fbb1e9e1b0ef96f1e1fdfd2/research/deeplab/model.py#L547-L588

I read through code below, and I believe different low level features are convolved different times. For example, in `Xception-65`'s case, 
1. first low level feature, say `entry_flow/block2/unit_1/xception_module/`, will go through 1*1 Conv -> Resize -> Concated with other features in `decoder_features_list` (which is now encoder features) -> being named as 
-> `decoder_conv0` -> `decoder_conv1`
2. second low level feature, say `separable_conv2_pointwise`, will go through the same procedure. 1*1 Conv -> Resize . And then, it's concated with other features in `decoder_features_list`, which is now the output in `1`, including convolved first low-level feature and encoder features. This makes different low-level features ""being convolved"" different times. 

 Not sure it's intention or is it a bug? Could it be the way following?
```
def resize_and_set_shape(features):
    features = tf.image.resize_bilinear(features, [decoder_height, decoder_width], align_corners=True)
    features.set_shape(
        [None, decoder_height, decoder_width, None])
    return features

# resize encoder features to (decoder_height, decoder_width)
encoder_features= resize_and_set_shape(features)
decoder_features_list = [encoder_features]

# resize low-level features to (decoder_height, decoder_width)
for i, name in enumerate(feature_list):
    feature_name = '{}/{}'.format(
        feature_extractor.name_scope[model_variant], name)
    decoder_feature =  slim.conv2d(
            end_points[feature_name],
            48,
            1,
            scope='feature_projection' + str(i))
    decoder_feature_list.append( resize_and_set_shape(decoder_feature) )

# after resize is done, concat all features and perform conv
decoder_depth = 256
if decoder_use_separable_conv:
    decoder_features = _split_separable_conv2d(
            tf.concat(decoder_features_list, 3),
            filters=decoder_depth,
            rate=1,
            weight_decay=weight_decay,
            scope='decoder_conv0')
    decoder_features = _split_separable_conv2d(
            decoder_features,
            filters=decoder_depth,
            rate=1,
            weight_decay=weight_decay,
            scope='decoder_conv1')
else:
    num_convs = 2
    decoder_features = slim.repeat(
            tf.concat(decoder_features_list, 3),
            num_convs,
            slim.conv2d,
            decoder_depth,
            3,
            scope='decoder_conv' + str(i))
return decoder_features
```",yoyolin,None,2019-03-24T01:22:02Z,2019-03-24T06:24:55Z,,,,,,,
6421,coco object detection accuracy bugs,"i'm trying to repeat the pretrained object detection model accuracy on coco, and we could not repeat this mAP numbers after some suffering hacks. here is my result:
![image](https://user-images.githubusercontent.com/17486215/54798058-c294a080-4c91-11e9-9253-d9620d210c7b.png)

model | coco image   count | image resize | mAP
-- | -- | -- | --
ssd_resnet_50_fpn_coco | standard: 40504 | None | 37.97
ssd_resnet_50_fpn_coco | standard: 40504 | 640 | 36.97
ssd_resnet_50_fpn_coco | subset: 8059 | 640 | 31.67

Am i missing something?
This is the first time that the model zoo accuracy could not be repeated, and i thought tensorflow, as a leading framework, should not have this kind of navie bugs.

Please comment.
",xhzhao,None,2019-03-22T03:08:09Z,2020-03-25T23:04:57Z,,,,,,,
6412,Running model_main to train faster-rcnn-resnet-101 exits with error 1,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:

Used default `model_main.py` in `tensorflow/models/research/object_detection` 

- **OS Platform and Distribution (Linux Ubuntu 16.04)**: Linux Ubuntu 16.04, Python 3.5.2
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**: NA
- **CUDA/cuDNN version**: NA
- **GPU model and memory**: NA
- **Exact command to reproduce**: NA

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

Training Faster-rcnn-resnet-101 (run using model_main.py) with custom dataset on ML Engine Standard CPU exits with the following error:
```
TypeError: resize_images() got an unexpected keyword argument 'preserve_aspect_ratio'
```

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.

```
Traceback (most recent call last):
  [...]
  File ""/root/.local/lib/python3.5/site-packages/object_detection/inputs.py"", line 515, in transform_and_pad_input_data_fn
    tensor_dict=transform_data_fn(tensor_dict),
  File ""/root/.local/lib/python3.5/site-packages/object_detection/inputs.py"", line 129, in transform_input_data
    tf.expand_dims(tf.to_float(image), axis=0))
  File ""/root/.local/lib/python3.5/site-packages/object_detection/meta_architectures/faster_rcnn_meta_arch.py"", line 543, in preprocess
    parallel_iterations=self._parallel_iterations)
  File ""/root/.local/lib/python3.5/site-packages/object_detection/utils/shape_utils.py"", line 237, in static_or_dynamic_map_fn
    outputs = [fn(arg) for arg in tf.unstack(elems)]
  File ""/root/.local/lib/python3.5/site-packages/object_detection/utils/shape_utils.py"", line 237, in <listcomp>
    outputs = [fn(arg) for arg in tf.unstack(elems)]
  File ""/root/.local/lib/python3.5/site-packages/object_detection/core/preprocessor.py"", line 2264, in resize_to_range
    lambda: _resize_portrait_image(image))
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/util/deprecation.py"", line 432, in new_func
    return func(*args, **kwargs)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/control_flow_ops.py"", line 2040, in cond
    orig_res_t, res_t = context_t.BuildCondBranch(true_fn)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/control_flow_ops.py"", line 1890, in BuildCondBranch
    original_result = fn()
  File ""/root/.local/lib/python3.5/site-packages/object_detection/core/preprocessor.py"", line 2263, in <lambda>
    lambda: _resize_landscape_image(image),
  File ""/root/.local/lib/python3.5/site-packages/object_detection/core/preprocessor.py"", line 2245, in _resize_landscape_image
    align_corners=align_corners, preserve_aspect_ratio=True)
TypeError: resize_images() got an unexpected keyword argument 'preserve_aspect_ratio'
```",Sri-vatsa,b'models:research stat:awaiting model gardener',2019-03-20T09:30:52Z,2019-05-19T00:10:59Z,,,,,,,
6411,error while converting to tflite model,"Please go to Stack Overflow for help and support:

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.13.1
- **Bazel version (if compiling from source)**: 18.0
- **CUDA/cuDNN version** :none
- **GPU model and memory**: none 
- **Exact command to reproduce**:
bazel run --config=opt tensorflow/contrib/lite/toco:toco -- --input_file=temp/box.pb --output_file=temp/detect.tflite -input_shapes=1,300,300,3--input_arrays=normalized_input_image_tensor --output_arrays='TFLite_Detection_PostProcess','TFLite_Detection_PostProcess:1','TFLite_Detection_PostProcess:2','TFLite_Detection_PostProcess:3' --inference_type=QUANTIZED_UINT8 --mean_values=128 --std_values=128 --change_concat_input_ranges=false --allow_custom_ops

### Describe the problem
We trained the custom object detection model for the box(inventory box) detection using tensorflow object detection API. We used weights of pretrained  ssd_mobilenet_v1_coco models for training. 
Then we convert frozen graph for the model from checkpoints using export_tflite_ssd_graph.py file.
Now I wanted to convert an optimized model by using TOCO so I can run our model on android devices. 
We followed all the mentioned steps, also we tried with various version of bazel (0.22.0, 0.20.0, 0.19.1) but not able to transform the model successfully.
While running above command with bazel 0.18.0 I got the following error. Please help me with the same.
Also, is there any update to convert a frozen inference graph of Faster RCNN model to Tflite, as iI read from Tensorflow API documentation, currently SSD mobilenet model only support for the tflite conversion.


### Source code / logs
ERROR: D:/tensorflow/tensorflow/contrib/lite/BUILD:34:1: C++ compilation of rule '//tensorflow/contrib/lite:arena_planner' failed (Exit 2): cl.exe failed: error executing command
  cd C:/users/pritamm1/_bazel_pritamm1/26orbg4z/execroot/org_tensorflow
  SET INCLUDE=C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE;C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\ATLMFC\INCLUDE;C:\Program Files (x86)\Windows Kits\10\include\10.0.17763.0\ucrt;C:\Program Files (x86)\Windows Kits\10\include\10.0.17763.0\shared;C:\Program Files (x86)\Windows Kits\10\include\10.0.17763.0\um;C:\Program Files (x86)\Windows Kits\10\include\10.0.17763.0\winrt;
    SET PATH=C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\BIN\amd64;C:\windows\Microsoft.NET\Framework64\v4.0.30319;C:\Program Files (x86)\Microsoft Visual Studio 14.0\Common7\IDE;C:\Program Files (x86)\Microsoft Visual Studio 14.0\Common7\Tools;C:\Program Files (x86)\Windows Kits\10\bin\x64;C:\Program Files (x86)\Windows Kits\10\bin\x86;;C:\windows\system32
    SET PWD=/proc/self/cwd
    SET PYTHON_BIN_PATH=C:/Users/pritamm1/AppData/Local/conda/conda/envs/tensorflow111/python.exe
    SET PYTHON_LIB_PATH=C:/Users/pritamm1/AppData/Local/conda/conda/envs/tensorflow111/lib/site-packages
    SET TEMP=C:\Users\pritamm1\AppData\Local\Temp
    SET TF_DOWNLOAD_CLANG=0
    SET TF_NEED_CUDA=0
    SET TF_NEED_OPENCL_SYCL=0
    SET TMP=C:\Users\pritamm1\AppData\Local\Temp
  C:/Program Files (x86)/Microsoft Visual Studio 14.0/VC/bin/amd64/cl.exe /nologo /DCOMPILER_MSVC /DNOMINMAX /D_WIN32_WINNT=0x0600 /D_CRT_SECURE_NO_DEPRECATE /D_CRT_SECURE_NO_WARNINGS /bigobj /Zm500 /EHsc /wd4351 /wd4291 /wd4250 /wd4996 /I. /Ibazel-out/x64_windows-opt/genfiles /Ibazel-out/x64_windows-opt/bin /Iexternal/bazel_tools /Ibazel-out/x64_windows-opt/genfiles/external/bazel_tools /Ibazel-out/x64_windows-opt/bin/external/bazel_tools /showIncludes /MD /O2 /Oy- /DNDEBUG /wd4117 -D__DATE__=""redacted"" -D__TIMESTAMP__=""redacted"" -D__TIME__=""redacted"" /Gy /Gw -w /arch:AVX /Fobazel-out/x64_windows-opt/bin/tensorflow/contrib/lite/_objs/arena_planner/arena_planner.obj /c tensorflow/contrib/lite/arena_planner.cc
.\tensorflow/contrib/lite/context.h(183): error C2144: syntax error: 'float' should be preceded by ';'
.\tensorflow/contrib/lite/context.h(183): error C4430: missing type specifier - int assumed. Note: C++ does not support default-int
Target //tensorflow/contrib/lite/toco:toco failed to build
INFO: Elapsed time: 33.305s, Critical Path: 1.15s
INFO: 0 processes.
FAILED: Build did NOT complete successfully
FAILED: Build did NOT complete successfully
",pritammahadik94,b'comp:lite',2019-03-20T08:05:45Z,2020-03-25T23:04:56Z,,,,,,,
6398, how to use multi gpu for inferencing ,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

What is the top-level directory of the model you are using: research/object_detection
Have I written custom code (as opposed to using a stock example script provided in TensorFlow): no
OS Platform and Distribution (e.g., Linux cent os 7.5): Linux Cent OS 7.5
TensorFlow installed from (source or binary): binary
TensorFlow version (use command below): v1.12.0
Bazel version (if compiling from source): NA
CUDA/cuDNN version: 10.0
GPU model and memory: 2x Tesla P100 16Gb
Exact command to reproduce: NA

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
how to using multi gpu card for inferencing？

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",lighTQ,None,2019-03-19T03:24:37Z,2020-03-25T23:04:55Z,,,,,,,
6393,[deeplab] Improper HNASNet architecture,"### System information
- **What is the top-level directory of the model you are using**: deeplab
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: no
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 18.04
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.13.1
- **Bazel version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: 9.0/7.5
- **GPU model and memory**: GeForce RTX 2080 Ti
- **Exact command to reproduce**:
`python train.py --logtostderr --training_number_of_steps=30000 --train_split=""train"" --model_variant=""nas_hnasnet"" --atrous_rates=12 --atrous_rates=24 --atrous_rates=36 --output_stride=8 --decoder_output_stride=4 --train_crop_size=513 --train_crop_size=513 --train_batch_size=4 --dataset=""pascal_voc_seg"" --train_logdir=""datasets/pascal_voc_seg/train/"" --dataset_dir=""datasets/pascal_voc_seg/tfrecord/""`

### Source code / logs

> File ""train.py"", line 461, in main
>     dataset.ignore_label)
>   File ""train.py"", line 377, in _train_deeplab_model
>     reuse_variable=(i != 0))
>   File ""train.py"", line 274, in _tower_loss
>     _build_deeplab(iterator, {common.OUTPUT_TYPE: num_of_classes}, ignore_label)
>   File ""train.py"", line 234, in _build_deeplab
>     'total_training_steps': FLAGS.training_number_of_steps,
>   File ""/home/adrian/repos/tfmodels/research/deeplab/model.py"", line 313, in multi_scale_logits
>     nas_training_hyper_parameters=nas_training_hyper_parameters)
>   File ""/home/adrian/repos/tfmodels/research/deeplab/model.py"", line 553, in _get_logits
>     nas_training_hyper_parameters=nas_training_hyper_parameters)
>   File ""/home/adrian/repos/tfmodels/research/deeplab/model.py"", line 458, in extract_features
>     model_options.image_pooling_stride, padding='VALID')
>   File ""/home/adrian/repos/cap-subsidy-validator/venv/lib/python3.6/site-packages/tensorflow/contrib/framework/python/ops/arg_scope.py"", line 182, in func_with_args
>     return func(*args, **current_args)
>   File ""/home/adrian/repos/cap-subsidy-validator/venv/lib/python3.6/site-packages/tensorflow/contrib/layers/python/layers/layers.py"", line 122, in avg_pool2d
>     outputs = layer.apply(inputs)
>   File ""/home/adrian/repos/cap-subsidy-validator/venv/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py"", line 1227, in apply
>     return self.__call__(inputs, *args, **kwargs)
>   File ""/home/adrian/repos/cap-subsidy-validator/venv/lib/python3.6/site-packages/tensorflow/python/layers/base.py"", line 530, in __call__
>     outputs = super(Layer, self).__call__(inputs, *args, **kwargs)
>   File ""/home/adrian/repos/cap-subsidy-validator/venv/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py"", line 554, in __call__
>     outputs = self.call(inputs, *args, **kwargs)
>   File ""/home/adrian/repos/cap-subsidy-validator/venv/lib/python3.6/site-packages/tensorflow/python/keras/layers/pooling.py"", line 256, in call
>     data_format=conv_utils.convert_data_format(self.data_format, 4))
>   File ""/home/adrian/repos/cap-subsidy-validator/venv/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py"", line 2718, in avg_pool
>     name=name)
>   File ""/home/adrian/repos/cap-subsidy-validator/venv/lib/python3.6/site-packages/tensorflow/python/ops/gen_nn_ops.py"", line 93, in avg_pool
>     data_format=data_format, name=name)
>   File ""/home/adrian/repos/cap-subsidy-validator/venv/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py"", line 788, in _apply_op_helper
>     op_def=op_def)
>   File ""/home/adrian/repos/cap-subsidy-validator/venv/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py"", line 507, in new_func
>     return func(*args, **kwargs)
>   File ""/home/adrian/repos/cap-subsidy-validator/venv/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 3300, in create_op
>     op_def=op_def)
>   File ""/home/adrian/repos/cap-subsidy-validator/venv/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 1823, in __init__
>     control_input_ops)
>   File ""/home/adrian/repos/cap-subsidy-validator/venv/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 1662, in _create_c_op
>     raise ValueError(str(e))
> ValueError: Negative dimension size caused by subtracting 65 from 17 for 'clone_0/AvgPool2D/AvgPool' (op: 'AvgPool') with input shapes: [?,17,17,200].


### Describe the problem
It looks like HNASNet architecture is not properly built. When debugging: in _build_nas_base in nas_network.py, cell_outputs are following:

> [
> <tf.Tensor 'clone_0/hnasnet/conv1_bn/FusedBatchNorm:0' shape=(?, 257, 257, 64) dtype=float32>, 
> <tf.Tensor 'clone_0/hnasnet/conv2_bn/FusedBatchNorm:0' shape=(?, 129, 129, 128) dtype=float32>, 
> <tf.Tensor 'clone_0/hnasnet/cell_0/cell_output/concat:0' shape=(?, 129, 129, 100) dtype=float32>, 
> <tf.Tensor 'clone_0/hnasnet/cell_1/cell_output/concat:0' shape=(?, 129, 129, 100) dtype=float32>, 
> <tf.Tensor 'clone_0/hnasnet/cell_2/cell_output/concat:0' shape=(?, 129, 129, 100) dtype=float32>, 
> <tf.Tensor 'clone_0/hnasnet/cell_3/cell_output/concat:0' shape=(?, 65, 65, 200) dtype=float32>, 
> <tf.Tensor 'clone_0/hnasnet/cell_4/cell_output/concat:0' shape=(?, 33, 33, 400) dtype=float32>,
> <tf.Tensor 'clone_0/hnasnet/cell_5/cell_output/concat:0' shape=(?, 65, 65, 200) dtype=float32>, 
> <tf.Tensor 'clone_0/hnasnet/cell_6/cell_output/concat:0' shape=(?, 33, 33, 400) dtype=float32>, 
> <tf.Tensor 'clone_0/hnasnet/cell_7/cell_output/concat:0' shape=(?, 33, 33, 400) dtype=float32>, 
> <tf.Tensor 'clone_0/hnasnet/cell_8/cell_output/concat:0' shape=(?, 17, 17, 800) dtype=float32>, 
> <tf.Tensor 'clone_0/hnasnet/cell_9/cell_output/concat:0' shape=(?, 17, 17, 800) dtype=float32>, 
> <tf.Tensor 'clone_0/hnasnet/cell_10/cell_output/concat:0' shape=(?, 17, 17, 400) dtype=float32>, 
> <tf.Tensor 'clone_0/hnasnet/cell_11/cell_output/concat:0' shape=(?, 17, 17, 200) dtype=float32>
> ]

According to paper, last two cells should have 33x33 and 65x65 respectively.

Looks like problem with resizing previous layers.
@aquariusjay @YknZhu ",adrianboguszewski,None,2019-03-18T16:22:13Z,2019-03-21T16:46:07Z,,,,,,,
6390,ValueError: No variable to save / on tensorflow object detection API with ssd_resnet50_v1_fpn,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",19KouameYoel96,b'stat:awaiting response',2019-03-18T12:19:19Z,2019-03-29T21:55:53Z,,,,,,,
6385,Running tflite,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**: deeplab
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Mac
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: 1.13.1
- **Bazel version (if compiling from source)**: 0.21
- **CUDA/cuDNN version**: 
- **GPU model and memory**:
- **Exact command to reproduce**:

### Describe the problem

I tried to build running gpu model for image segmentation inference exactly.

```
tflite_convert \
 --output_file=$TF_FILE \
 --graph_def_file=$PB_FILE \
 --output_format=TFLITE \
 --input_arrays=sub_7 \
 --output_arrays=ResizeBilinear_2 \
 --input_shapes=1,${DIMENSION},${DIMENSION},3 \
 --inference_input_type=FLOAT \
 --inference_type=FLOAT \
```
",ilous12,None,2019-03-18T08:27:15Z,2019-03-25T01:35:57Z,,,,,,,
6379,I had a problem training my data setvalueerror: metric not found: open_images_metrics,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",R1193685072,None,2019-03-16T19:11:21Z,2019-03-29T21:56:22Z,,,,,,,
6371,Object detection oid_v4_label_map.pbtxt doesn't match oidv4 model(faster_rcnn_inception_resnet_v2_atrous_oidv4 and ssd_mobilenetv2_oidv4),"I've tested oidv4 model(faster_rcnn_inception_resnet_v2_atrous_oidv4 and ssd_mobilenetv2_oidv4) with oid_v4_label_map.pbtxt and there are some mismatch between bounding box and labels.

The specific result can be seen at here: https://github.com/AI-LastWish/Deep-Learning-CV/blob/master/Bug_Report/faster_rcnn_inception_resnet_v2_atrous_oidv4.ipynb
and here 
https://github.com/AI-LastWish/Deep-Learning-CV/blob/master/Bug_Report/ssd_mobilenetv2_oidv4.ipynb

You can see in the first picture of faster_rcnn_inception_resnet_v2_atrous_oidv4.ipynb file, there is a ""Computer monitor 43%"", which is very very weird and a lot of ""screwdriver"" while I think must be a ""person"". In the second picture of the same file, the model predicts ""sofa bed"", while indeed it is a face, another unacceptable mismatch. The same for the second file.

One more question: 
From 
https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md
Researchers tested by using COCO 14 minival set(about 8000 images). So they used approximately 8000 over 40000 images in  COCO 14 Test Dataset, but how could they evaluate? Did they upload only 8000/40000 images to Codalab and got corrected result? So to calculate mAP of test set, we don't need to test over all 40000 images, just a subset and upload to Codalab also OK, right? We don't have ground truth annotation of Test set?",AI-LastWish,None,2019-03-15T06:03:41Z,2020-03-25T23:05:25Z,,,,,,,
6364,Convert Problem Deeplab on android GPU,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:deeplab
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:no
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:16.04
- **TensorFlow installed from (source or binary)**:binary
- **TensorFlow version (use command below)**:1.12
- **Bazel version (if compiling from source)**:0.22
- **CUDA/cuDNN version**: 9.x
- **GPU model and memory**:12
- **Exact command to reproduce**: 

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

('v1.12.0-rc2-3-ga6d8ffae09', '1.12.0')

### Describe the problem

I saw google's ""deeplabv3_257_mv_gpu.tflite"", It worked good on android gpu.
After checking the run reference, I trained ""research/deeplab/local_test_mobilenetv2.sh"" and I got frozen_inference_graph.pb.

Unfortunately, it was not converted like deeplabv3_257_mv_gpu.tflite.
It had belows, I don't know why.

> SpaceToBatchND, Mul, BatchToSpaceND, Add Ops,

And It work not same input/ouput shape.

anyone tell me. thanks. @aquariusjay 


### Source code / logs
",ilous12,None,2019-03-14T12:50:02Z,2019-12-18T22:44:32Z,,,,,,,
6356,deeplab,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",heiheiya,None,2019-03-13T09:15:47Z,2019-03-13T09:16:55Z,,,,,,,
6347,it is not giveing right result https://prnt.sc/mwuz3r,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",ghost,None,2019-03-12T14:45:39Z,2019-03-13T21:04:21Z,,,,,,,
6342,file missing,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",Darshan-98,None,2019-03-12T02:49:14Z,2019-03-13T20:44:26Z,,,,,,,
6341,Are the object detection evaluation scripts still working for coco dataset?,"Are the evaluation scripts still working for coco dataset, say on model ssd_inception_v2?
https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/oid_inference_and_evaluation.md

I tried the flow above with tfrecord generated by create_coco_tf_record. But it looks like it's quite bumpy, that I have to fix several typo-looking issues in the source code to make it through.

```
object_detection/inference/detection_inference.py:65
-  with tf.gfile.Open(inference_graph_path, 'r') as graph_def_file:
+  with tf.gfile.Open(inference_graph_path, 'rb') as graph_def_file:

object_detection/metrics/offline_eval_map_corloc.py:159
-  input_config = configs['eval_input_config']
+  input_config = configs['eval_input_configs'][0]
```

Finally all image got skipped when computing evaluation measures from tfrecord, because some 'groundtruth_classes' can't be found in annotations.

So how can I evaluate ssd_inception_v2 in model zoo on coco dataset exactly? Do I need to try on Python2? Do I need to try object_detection/legacy/eval.py?",lbingbing,b'models:research type:bug',2019-03-11T13:18:57Z,2020-03-25T23:05:24Z,,,,,,,
6339,Increasing speed of detection in android,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**: tensorflow/examples/android
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: NO
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.07
- **Bazel version (if compiling from source)**: 
- **CUDA/cuDNN version**: 9.0, 7.1
- **GPU model and memory**: Nvidia Gti 1080 Ti, 12 Gb
- **Exact command to reproduce**: running android project in studio TF Detect

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
I am running mobilelet ssd object detector and while its performance is fine, its speed is on the lower side. What can I do to increase the detection speed in android?


",Amanpradhan,b'models:research stat:awaiting response',2019-03-11T06:27:51Z,2019-11-29T08:50:13Z,,,,,,,
6336,Failed to run wide and deep models,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**: official/wide_deep
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: no
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Centos 7.5
- **TensorFlow installed from (source or binary)**: Binary
- **TensorFlow version (use command below)**: tf_nightly-1.14.1.dev20190310-cp27-cp27mu-manylinux1_x86_64.whl
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**: python official/wide_deep/census_main.py

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.
Failed to trin the model
### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
```

I0310 01:43:08.053369 139844466702144 basic_session_run_hooks.py:594] Saving checkpoints for 0 into /t                                  mp/census_model/model.ckpt.
Traceback (most recent call last):
  File ""official/wide_deep/census_main.py"", line 116, in <module>
    absl_app.run(main)
  File ""/home/leslie/venv/lib/python2.7/site-packages/absl/app.py"", line 300, in run
    _run_main(main, args)
  File ""/home/leslie/venv/lib/python2.7/site-packages/absl/app.py"", line 251, in _run_main
    sys.exit(main(argv))
  File ""official/wide_deep/census_main.py"", line 110, in main
    run_census(flags.FLAGS)
  File ""official/wide_deep/census_main.py"", line 105, in run_census
    early_stop=True)
  File ""/home/leslie/models/official/wide_deep/wide_deep_run_loop.py"", line 109, in run_loop
    model.train(input_fn=train_input_fn, hooks=train_hooks)
  File ""/home/leslie/venv/lib/python2.7/site-packages/tensorflow_estimator/python/estimator/estimator.                                  py"", line 359, in train
    loss = self._train_model(input_fn, hooks, saving_listeners)
  File ""/home/leslie/venv/lib/python2.7/site-packages/tensorflow_estimator/python/estimator/estimator.                                  py"", line 1139, in _train_model
    return self._train_model_default(input_fn, hooks, saving_listeners)
  File ""/home/leslie/venv/lib/python2.7/site-packages/tensorflow_estimator/python/estimator/estimator.                                  py"", line 1173, in _train_model_default
    saving_listeners)
  File ""/home/leslie/venv/lib/python2.7/site-packages/tensorflow_estimator/python/estimator/estimator.                                  py"", line 1451, in _train_with_estimator_spec
    _, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])
  File ""/home/leslie/venv/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py""                                  , line 746, in run
    run_metadata=run_metadata)
  File ""/home/leslie/venv/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py""                                  , line 1240, in run
    run_metadata=run_metadata)
  File ""/home/leslie/venv/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py""                                  , line 1341, in run
    raise six.reraise(*original_exc_info)
  File ""/home/leslie/venv/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py""                                  , line 1326, in run
    return self._sess.run(*args, **kwargs)
  File ""/home/leslie/venv/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py""                                  , line 1399, in run
    run_metadata=run_metadata)
  File ""/home/leslie/venv/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py""                                  , line 1157, in run
    return self._sess.run(*args, **kwargs)
  File ""/home/leslie/venv/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 930,                                   in run
    run_metadata_ptr)
  File ""/home/leslie/venv/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 1153,                                   in _run
    feed_dict_tensor, options, run_metadata)
  File ""/home/leslie/venv/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 1329,                                   in _do_run
    run_metadata)
  File ""/home/leslie/venv/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 1349,                                   in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.InvalidArgumentError: Expect 15 fields but have 2 in record 0
         [[{{node DecodeCSV}}]]
         [[IteratorGetNext]]
```
",Leslie-Fang,None,2019-03-10T09:46:40Z,2020-04-10T08:50:01Z,,,,,,,
6332,Tensorflow lite Model doesn't detect objects and crashes the example app when debugged,"
### System information
- **What is the top-level directory of the model you are using**: models/research/object_detection
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution **:Linux Ubuntu 18.04 and Windows 10
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.9.0 CPU
- **Bazel version (if compiling from source)**: 0.11.1
- **CUDA/cuDNN version**: None
- **GPU model and memory**: None used

Hello, I followed the following [steps](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/running_locally.md) for training my tensorflow model ssd_mobilenet_v1_coco (the tf records and env preparations were done using this [tutorial](https://github.com/EdjeElectronics/TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10) )

All this was done on windows 10, the model works fine, even on the Tensorflow Android App
then for exporting to TF lite format i i sent the .pb file to a Ubuntu dist and the FLOAT command[used](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/running_on_mobile_tensorflowlite.md)

My issue arise when I try to run the model on the tensorflow lite android app, I followed the instructions that are [here](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/running_on_mobile_tensorflowlite.md) to add a custom model, but my model doesn't detect anything. When I try to press the volume down button to ""debug"" the inferences the app crashes. This is my relevante android stack:

`03-09 19:22:19.311 u0_a4 30807 30807 E AndroidRuntime: FATAL EXCEPTION: main
03-09 19:22:19.311 u0_a4 30807 30807 E AndroidRuntime: Process: org.tensorflow.lite.demo, PID: 30807
03-09 19:22:19.311 u0_a4 30807 30807 E AndroidRuntime: java.lang.NullPointerException: Attempt to invoke interface method 'void org.tensorflow.demo.Classifier.enableStatLogging(boolean)' on a null object reference
03-09 19:22:19.311 u0_a4 30807 30807 E AndroidRuntime: 	at org.tensorflow.demo.DetectorActivity.onSetDebug(DetectorActivity.java:294)
03-09 19:22:19.311 u0_a4 30807 30807 E AndroidRuntime: 	at org.tensorflow.demo.CameraActivity.onKeyDown(CameraActivity.java:420)
03-09 19:22:19.311 u0_a4 30807 30807 E AndroidRuntime: 	at android.view.KeyEvent.dispatch(KeyEvent.java:2712)
03-09 19:22:19.311 u0_a4 30807 30807 E AndroidRuntime: 	at android.app.Activity.dispatchKeyEvent(Activity.java:3291)
03-09 19:22:19.311 u0_a4 30807 30807 E AndroidRuntime: 	at com.android.internal.policy.DecorView.dispatchKeyEvent(DecorView.java:383)
03-09 19:22:19.311 u0_a4 30807 30807 E AndroidRuntime: 	at android.view.ViewRootImpl$ViewPostImeInputStage.processKeyEvent(ViewRootImpl.java:4767)
03-09 19:22:19.311 u0_a4 30807 30807 E AndroidRuntime: 	at android.view.ViewRootImpl$ViewPostImeInputStage.onProcess(ViewRootImpl.java:4639)
03-09 19:22:19.311 u0_a4 30807 30807 E AndroidRuntime: 	at android.view.ViewRootImpl$InputStage.deliver(ViewRootImpl.java:4181)
03-09 19:22:19.311 u0_a4 30807 30807 E AndroidRuntime: 	at android.view.ViewRootImpl$InputStage.onDeliverToNext(ViewRootImpl.java:4234)
03-09 19:22:19.311 u0_a4 30807 30807 E AndroidRuntime: 	at android.view.ViewRootImpl$InputStage.forward(ViewRootImpl.java:4200)
03-09 19:22:19.311 u0_a4 30807 30807 E AndroidRuntime: 	at android.view.ViewRootImpl$AsyncInputStage.forward(ViewRootImpl.java:4327)
03-09 19:22:19.311 u0_a4 30807 30807 E AndroidRuntime: 	at android.view.ViewRootImpl$InputStage.apply(ViewRootImpl.java:4208)
03-09 19:22:19.311 u0_a4 30807 30807 E AndroidRuntime: 	at android.view.ViewRootImpl$AsyncInputStage.apply(ViewRootImpl.java:4384)
03-09 19:22:19.311 u0_a4 30807 30807 E AndroidRuntime: 	at android.view.ViewRootImpl$InputStage.deliver(ViewRootImpl.java:4181)
03-09 19:22:19.311 u0_a4 30807 30807 E AndroidRuntime: 	at android.view.ViewRootImpl$InputStage.onDeliverToNext(ViewRootImpl.java:4234)
03-09 19:22:19.311 u0_a4 30807 30807 E AndroidRuntime: 	at android.view.ViewRootImpl$InputStage.forward(ViewRootImpl.java:4200)
03-09 19:22:19.311 u0_a4 30807 30807 E AndroidRuntime: 	at android.view.ViewRootImpl$InputStage.apply(ViewRootImpl.java:4208)
03-09 19:22:19.311 u0_a4 30807 30807 E AndroidRuntime: 	at android.view.ViewRootImpl$InputStage.deliver(ViewRootImpl.java:4181)
03-09 19:22:19.311 u0_a4 30807 30807 E AndroidRuntime: 	at android.view.ViewRootImpl$InputStage.onDeliverToNext(ViewRootImpl.java:4234)
03-09 19:22:19.311 u0_a4 30807 30807 E AndroidRuntime: 	at android.view.ViewRootImpl$InputStage.forward(ViewRootImpl.java:4200)
03-09 19:22:19.311 u0_a4 30807 30807 E AndroidRuntime: 	at android.view.ViewRootImpl$AsyncInputStage.forward(ViewRootImpl.java:4360)
03-09 19:22:19.311 u0_a4 30807 30807 E AndroidRuntime: 	at android.view.ViewRootImpl$ImeInputStage.onFinishedInputEvent(ViewRootImpl.java:4521)
03-09 19:22:19.311 u0_a4 30807 30807 E AndroidRuntime: 	at android.view.inputmethod.InputMethodManager$PendingEvent.run(InputMethodManager.java:2435)
03-09 19:22:19.311 u0_a4 30807 30807 E AndroidRuntime: 	at android.view.inputmethod.InputMethodManager.invokeFinishedInputEventCallback(InputMethodManager.java:1998)
03-09 19:22:19.311 u0_a4 30807 30807 E AndroidRuntime: 	at android.view.inputmethod.InputMethodManager.finishedInputEvent(InputMethodManager.java:1989)
03-09 19:22:19.311 u0_a4 30807 30807 E AndroidRuntime: 	at android.view.inputmethod.InputMethodManager$ImeInputEventSender.onInputEventFinished(InputMethodManager.java:2412)
03-09 19:22:19.311 u0_a4 30807 30807 E AndroidRuntime: 	at android.view.InputEventSender.dispatchInputEventFinished(InputEventSender.java:141)
03-09 19:22:19.311 u0_a4 30807 30807 E AndroidRuntime: 	at android.os.MessageQueue.nativePollOnce(Native Method)
03-09 19:22:19.311 u0_a4 30807 30807 E AndroidRuntime: 	at android.os.MessageQueue.next(MessageQueue.java:325)
03-09 19:22:19.311 u0_a4 30807 30807 E AndroidRuntime: 	at android.os.Looper.loop(Looper.java:142)
03-09 19:22:19.311 u0_a4 30807 30807 E AndroidRuntime: 	at android.app.ActivityThread.main(ActivityThread.java:6626)
03-09 19:22:19.311 u0_a4 30807 30807 E AndroidRuntime: 	at java.lang.reflect.Method.invoke(Native Method)
03-09 19:22:19.311 u0_a4 30807 30807 E AndroidRuntime: 	at com.android.internal.os.RuntimeInit$MethodAndArgsCaller.run(RuntimeInit.java:438)
03-09 19:22:19.311 u0_a4 30807 30807 E AndroidRuntime: 	at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:811)`

",haganete,b'models:research stat:awaiting response',2019-03-10T01:11:42Z,2019-03-22T21:12:22Z,,,,,,,
6315,"Release Models trained on Open Image Dataset V4,  minor refactors and fixes to object detection","236813471  by lzc:

    Internal change.

--
236507310  by lzc:

    Fix preprocess.random_resize_method config type issue. The target height and width will be passed as ""size"" to tf.image.resize_images which only accepts integer.

--
236409989  by Zhichao Lu:

    Config export_to_tpu from function parameter instead of HParams for TPU inference.

--
236403186  by Zhichao Lu:

    Make graph file names optional arguments.

--
236237072  by Zhichao Lu:

    Minor bugfix for keyword args.

--
236209602  by Zhichao Lu:

    Add support for PartitionedVariable to get_variables_available_in_checkpoint.

--
235828658  by Zhichao Lu:

    Automatically stop evaluation jobs when training is finished.

--
235817964  by Zhichao Lu:

    Add an optional process_metrics_fn callback to eval_util, it gets called
    with evaluation results once each evaluation is complete.

--
235788721  by lzc:

    Fix yml file tf runtime version.

--
235262897  by Zhichao Lu:

    Add keypoint support to the random_pad_image preprocessor method.

--
235257380  by Zhichao Lu:

    Support InputDataFields.groundtruth_confidences in retain_groundtruth(), retain_groundtruth_with_positive_classes(), filter_groundtruth_with_crowd_boxes(), filter_groundtruth_with_nan_box_coordinates(), filter_unrecognized_classes().

--
235109188  by Zhichao Lu:

    Fix bug in pad_input_data_to_static_shapes for num_additional_channels > 0; make color-specific data augmentation only touch RGB channels.

--
235045010  by Zhichao Lu:

    Don't slice class_predictions_with_background when add_background_class is false.

--
235026189  by lzc:

    Fix import in g3doc.

--
234863426  by Zhichao Lu:

    Added fixes in exporter to allow writing a checkpoint to a specified temporary directory.

--
234671886  by lzc:

    Internal Change.

--
234630803  by rathodv:

    Internal Change.

--
233985896  by Zhichao Lu:

    Add Neumann optimizer to object detection.

--
233560911  by Zhichao Lu:

    Add NAS-FPN object detection with Resnet and Mobilenet v2.

--
233513536  by Zhichao Lu:

    Export TPU compatible object detection model

--
233495772  by lzc:

    Internal change.

--
233453557  by Zhichao Lu:

    Create Keras-based SSD+MobilenetV1 for object detection.

--
233220074  by lzc:

    Update release notes date.

--
233165761  by Zhichao Lu:

    Support depth_multiplier and min_depth in _SSDResnetV1FpnFeatureExtractor.

--
233160046  by lzc:

    Internal change.

--
232926599  by Zhichao Lu:

    [tf.data] Switching tf.data functions to use `defun`, providing an escape hatch to continue using the legacy `Defun`.

    There are subtle differences between the implementation of `defun` and `Defun` (such as resources handling or control flow) and it is possible that input pipelines that use control flow or resources in their functions might be affected by this change. To migrate majority of existing pipelines to the recommended way of creating functions in TF 2.0 world, while allowing (a small number of) existing pipelines to continue relying on the deprecated behavior, this CL provides an escape hatch.

    If your input pipeline is affected by this CL, it should apply the escape hatch by replacing `foo.map(...)` with `foo.map_with_legacy_function(...)`.

--
232891621  by Zhichao Lu:

    Modify faster_rcnn meta architecture to normalize raw detections.

--
232875817  by Zhichao Lu:

    Make calibration a post-processing step.

    Specifically:
    - Move the calibration config from pipeline.proto --> post_processing.proto
    - Edit post_processing_builder.py to return a calibration function. If no calibration config is provided, it None.
    - Edit SSD and FasterRCNN meta architectures to optionally call the calibration function on detection scores after score conversion and before NMS.

--
232704481  by Zhichao Lu:

    Edit calibration builder to build a function that will be used within a detection model's `postprocess` method, after score conversion and before non-maxima suppression.

    Specific Edits:
    - The returned function now accepts class_predictions_with_background as its argument instead of detection_scores and detection_classes.
    - Class-specific calibration was temporarily removed, as it requires more significant refactoring. Will be added later.

--
232615379  by Zhichao Lu:

    Internal change

--
232483345  by ronnyvotel:

    Making the use of bfloat16 restricted to TPUs.

--
232399572  by Zhichao Lu:

    Edit calibration builder and proto to support class-agnostic calibration.

    Specifically:
    - Edit calibration protos to include path to relevant label map if required for class-specific calibration. Previously, label maps were inferred from other parts of the pipeline proto; this allows all information required by the builder stay within the calibration proto and remove extraneous information from being passed with class-agnostic calibration.
    - Add class-agnostic protos to the calibration config.

    Note that the proto supports sigmoid and linear interpolation parameters, but the builder currently only supports linear interpolation.

--
231613048  by Zhichao Lu:

    Add calibration builder for applying calibration transformations from output of object detection models.

    Specifically:
    - Add calibration proto to support sigmoid and isotonic regression (stepwise function) calibration.
    - Add a builder to support calibration from isotonic regression outputs.

--
231519786  by lzc:

    model_builder test refactor.
    - removed proto text boilerplate in each test case and let them call a create_default_proto function instead.
    - consolidated all separate ssd model creation tests into one.
    - consolidated all separate faster rcnn model creation tests into one.
    - used parameterized test for testing mask rcnn models and use_matmul_crop_and_resize
    - added all failures test.

--
231448169  by Zhichao Lu:

    Return static shape as a constant tensor.

--
231423126  by lzc:

    Add a release note for OID v4 models.

--
231401941  by Zhichao Lu:

    Adding correct labelmap for the models trained on Open Images V4 (*oid_v4
    config suffix).

--
231320357  by Zhichao Lu:

    Add scope to Nearest Neighbor Resize op so that it stays in the same name scope as the original resize ops.

--
231257699  by Zhichao Lu:

    Switch to using preserve_aspect_ratio in tf.image.resize_images rather than using a custom implementation.

--
231247368  by rathodv:

    Internal change.

--
231004874  by lzc:

    Update documentations to use tf 1.12 for object detection API.

--
230999911  by rathodv:

    Use tf.batch_gather instead of ops.batch_gather

--
230999720  by huizhongc:

    Fix weight equalization test in ops_test.

--
230984728  by rathodv:

    Internal update.

--
230929019  by lzc:

    Add an option to replace preprocess operation with placeholder for ssd feature extractor.

--
230845266  by lzc:

    Require tensorflow version 1.12 for object detection API and rename keras_applications to keras_models

--
230392064  by lzc:

    Add RetinaNet 101 checkpoint trained on OID v4 to detection model zoo.

--
230014128  by derekjchow:

    This file was re-located below the tensorflow/lite/g3doc/convert

--
229941449  by lzc:

    Update SSD mobilenet v2 quantized model download path.

--
229843662  by lzc:

    Add an option to use native resize tf op in fpn top-down feature map generation.

--
229636034  by rathodv:

    Add deprecation notice to a few old parameters in train.proto

--
228959078  by derekjchow:

    Remove duplicate elif case in _check_and_convert_legacy_input_config_key

--
228749719  by rathodv:

    Minor refactoring to make exporter's `build_detection_graph` method public.

--
228573828  by rathodv:

    Mofity model.postprocess to return raw detections and raw scores.

    Modify, post-process methods in core/model.py and the meta architectures to export raw detection (without any non-max suppression) and raw multiclass score logits for those detections.

--
228420670  by Zhichao Lu:

    Add shims for custom architectures for object detection models.

--
228241692  by Zhichao Lu:

    Fix the comment on ""losses_mask"" in ""Loss"" class.

--
228223810  by Zhichao Lu:

    Support other_heads' predictions in WeightSharedConvolutionalBoxPredictor. Also remove a few unused parameters and fix a couple of comments in convolutional_box_predictor.py.

--
228200588  by Zhichao Lu:

    Add Expected Calibration Error and an evaluator that calculates the metric for object detections.

--
228167740  by lzc:

    Add option to use bounded activations in FPN top-down feature map generation.

--
227767700  by rathodv:

    Internal.

--
226295236  by Zhichao Lu:

    Add Open Image V4 Resnet101-FPN training config to third_party

--
226254842  by Zhichao Lu:

    Fix typo in documentation.

--
225833971  by Zhichao Lu:

    Option to have no resizer in object detection model.

--
225824890  by lzc:

    Fixes p3 compatibility for model_lib.py

--
225760897  by menglong:

    normalizer should be at least 1.

--
225559842  by menglong:

    Add extra logic filtering unrecognized classes.

--
225379421  by lzc:

    Add faster_rcnn_inception_resnet_v2_atrous_oid_v4 config to third_party

--
225368337  by Zhichao Lu:

    Add extra logic filtering unrecognized classes.

--
225341095  by Zhichao Lu:

    Adding Open Images V4 models to OD API model zoo and corresponding configs to the
    configs.

--
225218450  by menglong:

    Add extra logic filtering unrecognized classes.

--
225057591  by Zhichao Lu:

    Internal change.

--
224895417  by rathodv:

    Internal change.

--
224209282  by Zhichao Lu:

    Add two data augmentations to object detection: (1) Self-concat (2) Absolute pads.

--
224073762  by Zhichao Lu:

    Do not create tf.constant until _generate() is actually called in the object detector.

--

PiperOrigin-RevId: 236813471",pkulzc,b'cla: yes',2019-03-07T00:01:09Z,2019-03-13T11:49:50Z,,,,,,,
6310,offline_eval_map_corloc,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",gfjiyue,None,2019-03-06T07:25:03Z,2019-03-06T07:25:59Z,,,,,,,
6308,Feature request: Cloud ML engine training support for tensorflow version 1.13 ,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
models/research/
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Ubuntu 16
- **TensorFlow installed from (source or binary)**:
Binary
- **TensorFlow version (use command below)**:
1.13
- **Bazel version (if compiling from source)**:
N/A
- **CUDA/cuDNN version**:
10
- **GPU model and memory**:
Nvidia Tesla V100
- **Exact command to reproduce**:
       python object_detection/model_main.py \
    --pipeline_config_path=${PIPELINE_CONFIG_PATH} \
    --model_dir=${MODEL_DIR} \
    --num_train_steps=${NUM_TRAIN_STEPS} \
    --sample_1_of_n_eval_examples=$SAMPLE_1_OF_N_EVAL_EXAMPLES \
    --alsologtostderr

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.
Training a model locally is equivalent to shooting in the dark at present. The logtostderr flag doesn't work as it doesn't log loss and model evaluation results. It would be really helpful if you include support for latest tensorflow version (tf1.13) on Google's Cloud ML engine. 

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.

N/A
",kulkarnivishal,None,2019-03-05T18:55:20Z,2020-03-25T23:05:22Z,,,,,,,
6305,Mask RCNN issue with CUDA: Check failed: work_element_count > 0 (-2064695296 vs. 0),"### System information
- **What is the top-level directory of the model you are using**: models/research/object_detection/
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: pip3
- **TensorFlow version (use command below)**:tensorflow-gpu 1.13.1
- **CUDA/cuDNN version**: CUDA 10/cuDNN v7.4.2
- **GPU model and memory**: GTX 1080Ti, 11GB
- **Exact command to reproduce**:
python3 object_detection/model_main.py \
--pipeline_config_path=""/path/to/config"" \
--model_dir=""/path/to/model"" \
--alsologtostderr \
--checkpoint_dir=""path/to/checkpoints""


### Describe the problem
1. I followed the sample code from ""create_pet_tf_record.py"" to create dataset for Mask-RCNN (I'm using model ""mask_rcnn_resnet101_atrous_coco_2018_01_28""). I made my own modification due to the sample code is for one object per category, not for multiple objects and categories.


2. The training process is fine without any problems. However, when I evaluate the model, it returns this error:

```
2019-03-05 13:33:44.814437: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library libcublas.so.10.0 locally
2019-03-05 13:33:46.705803: F ./tensorflow/core/util/cuda_launch_config.h:126] Check failed: work_element_count > 0 (-2064695296 vs. 0)
Aborted (core dumped)
```

I'm not sure whether this is a bug in tensorflow or an error within my model. The sizes of images are 200x200.

3. How to limit the amount of GPU memory during training process (for instance, 60%) so that the rest of memory will be used or use CPU only for evaluation?

Thank you very much.",nguyenkhaithinh,b'models:research',2019-03-05T07:35:44Z,2020-03-25T23:05:22Z,,,,,,,
6300,"tensorflow.python.framework.errors_impl.NotFoundError: Restoring from checkpoint failed. This is most likely due to a Variable name or other graph key that is missing from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:  Op type not registered 'ExperimentalMapAndBatchDataset' in binary running on n-6ca716a0-w-0. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.","I wanted to fine-tuning with BERT. When I run the example code below it works properly.

python /home/schen/bert/run_classifier.py \
    --task_name=MRPC  \
    --do_train=true \
    --do_eval=true \
    --data_dir=/home/schen/glue/glue_data/MRPC \
    --vocab_file=/home/schen/bert/uncased_L-12_H-768_A-12/vocab.txt \
    --bert_config_file=/home/schen/bert/uncased_L-12_H-768_A-12/bert_config.json \
    --init_checkpoint=/home/schen/bert/uncased_L-12_H-768_A-12/bert_model.ckpt \
    --max_seq_length=128 \
    --train_batch_size=32 \
    --learning_rate=2e-5 \
    --num_train_epochs=3.0 \
    --output_dir=/tmp/mrpc_output/ 


However, when I tried to run on Cloud TPU with more flags as follow,

python /home/schen/bert/run_classifier.py \
    --task_name=MRPC  \
    --do_train=true \
    --do_eval=true \
    --data_dir=/home/schen/glue/glue_data/MRPC \
    --vocab_file=/home/schen/bert/uncased_L-12_H-768_A-12/vocab.txt \
    --bert_config_file=/home/schen/bert/uncased_L-12_H-768_A-12/bert_config.json \
    --init_checkpoint=/home/schen/bert/uncased_L-12_H-768_A-12/bert_model.ckpt \
    --max_seq_length=128 \
    --train_batch_size=32 \
    --learning_rate=2e-5 \
    --num_train_epochs=3.0 \
    --output_dir=/tmp/mrpc_output/ 
    --use_tpu=True \
    --tpu_name=ai

It gives me the error below:

tensorflow.python.framework.errors_impl.NotFoundError: Restoring from checkpoint failed. This is most likely due to a Variable name or other graph key that is missing from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:

Op type not registered 'ExperimentalMapAndBatchDataset' in binary running on n-6ca716a0-w-0. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.

If I change the flag --output_dir=gs://gcs_bucket_name/bert/ where gcs_bucket_name is my project  Google Cloud Storage bucket name, it also gives me quite the same error:

tensorflow.python.framework.errors_impl.NotFoundError: Op type not registered 'ExperimentalMapAndBatchDataset' in binary running on n-6ca716a0-w-0. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.

I just followed the instructions from this link:

https://github.com/google-research/bert

FYI, if I run the command ""ctpu st"" it shows:

Your cluster is running!
	Compute Engine VM:  RUNNING
	Cloud TPU:          RUNNING

Any idea for fixed this bug? Thanks in advance.",chenshaolong,None,2019-03-04T01:40:02Z,2019-11-13T18:49:01Z,,,,,,,
6285,[DEBUGGING PLEASE DO NOT MERGE] Add Keras XLA Benchmarks,Add Keras XLA benchmarks and monkey-patched the `assert_broadcastable` op to avoid OOM. The monkey patch should be reverted once the OOM issue is fixed.,haoyuz,b'cla: yes',2019-02-28T18:54:43Z,2019-02-28T18:56:03Z,,,,,,,
6284,"Feature request: A single graph with 3 lines (training, testing and validating accuracy)  to determine the model is either overfitting or underfitting.","Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",aaronhan92,None,2019-02-28T15:38:55Z,2020-03-25T23:05:21Z,,,,,,,
6272,Release models trained on Open Images Dataset V4 and minor refactors and fixes.,"235262897  by Zhichao Lu:

    Add keypoint support to the random_pad_image preprocessor method.

--
235257380  by Zhichao Lu:

    Support InputDataFields.groundtruth_confidences in retain_groundtruth(), retain_groundtruth_with_positive_classes(), filter_groundtruth_with_crowd_boxes(), filter_groundtruth_with_nan_box_coordinates(), filter_unrecognized_classes().

--
235109188  by Zhichao Lu:

    Fix bug in pad_input_data_to_static_shapes for num_additional_channels > 0; make color-specific data augmentation only touch RGB channels.

--
235045010  by Zhichao Lu:

    Don't slice class_predictions_with_background when add_background_class is false.

--
235026189  by lzc:

    Fix import in g3doc.

--
234863426  by Zhichao Lu:

    Added fixes in exporter to allow writing a checkpoint to a specified temporary directory.

--
234671886  by lzc:

    Internal Change.

--
234630803  by rathodv:

    Internal Change.

--
233985896  by Zhichao Lu:

    Add Neumann optimizer to object detection.

--
233560911  by Zhichao Lu:

    Add NAS-FPN object detection with Resnet and Mobilenet v2.

--
233513536  by Zhichao Lu:

    Export TPU compatible object detection model

--
233495772  by lzc:

    Internal change.

--
233453557  by Zhichao Lu:

    Create Keras-based SSD+MobilenetV1 for object detection.

--
233220074  by lzc:

    Update release notes date.

--
233165761  by Zhichao Lu:

    Support depth_multiplier and min_depth in _SSDResnetV1FpnFeatureExtractor.

--
233160046  by lzc:

    Internal change.

--
232926599  by Zhichao Lu:

    [tf.data] Switching tf.data functions to use `defun`, providing an escape hatch to continue using the legacy `Defun`.

    There are subtle differences between the implementation of `defun` and `Defun` (such as resources handling or control flow) and it is possible that input pipelines that use control flow or resources in their functions might be affected by this change. To migrate majority of existing pipelines to the recommended way of creating functions in TF 2.0 world, while allowing (a small number of) existing pipelines to continue relying on the deprecated behavior, this CL provides an escape hatch.

    If your input pipeline is affected by this CL, it should apply the escape hatch by replacing `foo.map(...)` with `foo.map_with_legacy_function(...)`.

--
232891621  by Zhichao Lu:

    Modify faster_rcnn meta architecture to normalize raw detections.

--
232875817  by Zhichao Lu:

    Make calibration a post-processing step.

    Specifically:
    - Move the calibration config from pipeline.proto --> post_processing.proto
    - Edit post_processing_builder.py to return a calibration function. If no calibration config is provided, it None.
    - Edit SSD and FasterRCNN meta architectures to optionally call the calibration function on detection scores after score conversion and before NMS.

--
232704481  by Zhichao Lu:

    Edit calibration builder to build a function that will be used within a detection model's `postprocess` method, after score conversion and before non-maxima suppression.

    Specific Edits:
    - The returned function now accepts class_predictions_with_background as its argument instead of detection_scores and detection_classes.
    - Class-specific calibration was temporarily removed, as it requires more significant refactoring. Will be added later.

--
232615379  by Zhichao Lu:

    Internal change

--
232483345  by ronnyvotel:

    Making the use of bfloat16 restricted to TPUs.

--
232399572  by Zhichao Lu:

    Edit calibration builder and proto to support class-agnostic calibration.

    Specifically:
    - Edit calibration protos to include path to relevant label map if required for class-specific calibration. Previously, label maps were inferred from other parts of the pipeline proto; this allows all information required by the builder stay within the calibration proto and remove extraneous information from being passed with class-agnostic calibration.
    - Add class-agnostic protos to the calibration config.

    Note that the proto supports sigmoid and linear interpolation parameters, but the builder currently only supports linear interpolation.

--
231613048  by Zhichao Lu:

    Add calibration builder for applying calibration transformations from output of object detection models.

    Specifically:
    - Add calibration proto to support sigmoid and isotonic regression (stepwise function) calibration.
    - Add a builder to support calibration from isotonic regression outputs.

--
231519786  by lzc:

    model_builder test refactor.
    - removed proto text boilerplate in each test case and let them call a create_default_proto function instead.
    - consolidated all separate ssd model creation tests into one.
    - consolidated all separate faster rcnn model creation tests into one.
    - used parameterized test for testing mask rcnn models and use_matmul_crop_and_resize
    - added all failures test.

--
231448169  by Zhichao Lu:

    Return static shape as a constant tensor.

--
231423126  by lzc:

    Add a release note for OID v4 models.

--
231401941  by Zhichao Lu:

    Adding correct labelmap for the models trained on Open Images V4 (*oid_v4
    config suffix).

--
231320357  by Zhichao Lu:

    Add scope to Nearest Neighbor Resize op so that it stays in the same name scope as the original resize ops.

--
231257699  by Zhichao Lu:

    Switch to using preserve_aspect_ratio in tf.image.resize_images rather than using a custom implementation.

--
231247368  by rathodv:

    Internal change.

--
231004874  by lzc:

    Update documentations to use tf 1.12 for object detection API.

--
230999911  by rathodv:

    Use tf.batch_gather instead of ops.batch_gather

--
230999720  by huizhongc:

    Fix weight equalization test in ops_test.

--
230984728  by rathodv:

    Internal update.

--
230929019  by lzc:

    Add an option to replace preprocess operation with placeholder for ssd feature extractor.

--
230845266  by lzc:

    Require tensorflow version 1.12 for object detection API and rename keras_applications to keras_models

--
230392064  by lzc:

    Add RetinaNet 101 checkpoint trained on OID v4 to detection model zoo.

--
230014128  by derekjchow:

    This file was re-located below the tensorflow/lite/g3doc/convert

--
229941449  by lzc:

    Update SSD mobilenet v2 quantized model download path.

--
229843662  by lzc:

    Add an option to use native resize tf op in fpn top-down feature map generation.

--
229636034  by rathodv:

    Add deprecation notice to a few old parameters in train.proto

--
228959078  by derekjchow:

    Remove duplicate elif case in _check_and_convert_legacy_input_config_key

--
228749719  by rathodv:

    Minor refactoring to make exporter's `build_detection_graph` method public.

--
228573828  by rathodv:

    Mofity model.postprocess to return raw detections and raw scores.

    Modify, post-process methods in core/model.py and the meta architectures to export raw detection (without any non-max suppression) and raw multiclass score logits for those detections.

--
228420670  by Zhichao Lu:

    Add shims for custom architectures for object detection models.

--
228241692  by Zhichao Lu:

    Fix the comment on ""losses_mask"" in ""Loss"" class.

--
228223810  by Zhichao Lu:

    Support other_heads' predictions in WeightSharedConvolutionalBoxPredictor. Also remove a few unused parameters and fix a couple of comments in convolutional_box_predictor.py.

--
228200588  by Zhichao Lu:

    Add Expected Calibration Error and an evaluator that calculates the metric for object detections.

--
228167740  by lzc:

    Add option to use bounded activations in FPN top-down feature map generation.

--
227767700  by rathodv:

    Internal.

--
226295236  by Zhichao Lu:

    Add Open Image V4 Resnet101-FPN training config to third_party

--
226254842  by Zhichao Lu:

    Fix typo in documentation.

--
225833971  by Zhichao Lu:

    Option to have no resizer in object detection model.

--
225824890  by lzc:

    Fixes p3 compatibility for model_lib.py

--
225760897  by menglong:

    normalizer should be at least 1.

--
225559842  by menglong:

    Add extra logic filtering unrecognized classes.

--
225379421  by lzc:

    Add faster_rcnn_inception_resnet_v2_atrous_oid_v4 config to third_party

--
225368337  by Zhichao Lu:

    Add extra logic filtering unrecognized classes.

--
225341095  by Zhichao Lu:

    Adding Open Images V4 models to OD API model zoo and corresponding configs to the
    configs.

--
225218450  by menglong:

    Add extra logic filtering unrecognized classes.

--
225057591  by Zhichao Lu:

    Internal change.

--
224895417  by rathodv:

    Internal change.

--
224209282  by Zhichao Lu:

    Add two data augmentations to object detection: (1) Self-concat (2) Absolute pads.

--
224073762  by Zhichao Lu:

    Do not create tf.constant until _generate() is actually called in the object detector.

--

PiperOrigin-RevId: 235262897",pkulzc,b'cla: yes',2019-02-26T21:40:53Z,2019-03-05T22:25:06Z,,,,,,,
6266,Not able to MeanIOU or confusion matrix for deepLabv3+ inference,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",justrish,b'models:research stat:awaiting model gardener',2019-02-26T01:28:14Z,2020-03-25T23:05:21Z,,,,,,,
6264,Ask for instructions on setting weight for unbalance dataset,"### System information
- **What is the top-level directory of the model you are using**: deeplab
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu18
- **TensorFlow installed from (source or binary)**: nvidia-docker-tf-gpu
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**: 10.0
- **GPU model and memory**: GTX TITAN 12G
- **Exact command to reproduce**: 
### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.
I have modified the ADE20K scene parsing benchmark produced by MIT. The original dataset contains 150 categoried(151 include background) and set background=0 to be ignored.
I have chosen 17 categories and set the previous background(label as 0) to 255, and set the other categories as 0(background). Thus ignore_class = 255

I count the pixels in the 20210 images after the modification. <category idx, number of pixel counts>
0,1637454744
1,737138625
2,503599787
3,414602893
4,290185267
5,211497624
6,93447406
7,84733791
8,78265150
9,74475972
10,70227430
11,55492152
12,28967419
13,28361240
14,24627334
15,9994821
16,7816482
17,3719357
255,411637498

The background is 0.6 of all the other categories in total(1-17)
However, the background is 440 times the 17th category. (1637454744 / 3719357= 440.3)
(16th: 1637454744 / 7816482 = 209.5)
Does anyone have any suggestion on how to set the weight for these categories?
Should I adjust the weight for only a few categories or all of the 17 categories?

```
weights = tf.to_float(tf.equal(scaled_labels, 0)) * label0_weight + tf.to_float(tf.equal(scaled_labels, 1)) * label1_weight + tf.to_float(tf.equal(scaled_labels, ignore_label)) * 0.0
    where you need to tune the label0_weight and label1_weight (e.g., set label0_weight=1 and increase label1_weight).
```
",Eavis,b'models:research stat:awaiting model gardener',2019-02-25T18:39:37Z,2020-03-25T23:06:10Z,,,,,,,
6252,Object Never Used (type <class 'tensorflow.python.framework.ops.Tensor'>):,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**: models/research/inception
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Only some simple printf to collect timing
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: CentOS
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: r1.12
- **Bazel version (if compiling from source)**: 0.15.0
- **CUDA/cuDNN version**: none
- **GPU model and memory**: none
- **Exact command to reproduce**:`bazel-bin/inception/imagenet_distributed_train --batch_size=32 --data_dir=/global/cscratch1/sd/jw447/imagenet-data --job_name='ps' --task_id=0 $ps_hosts $worker_hosts`

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

The distributed training of inception failed at the end of training. Both workers output the same error:

> ERROR:tensorflow:==================================
Object was never used (type <class 'tensorflow.python.framework.ops.Tensor'>):
<tf.Tensor 'report_uninitialized_variables/boolean_mask/GatherV2:0' shape=(?,) dtype=string>
If you want to mark it as used call its ""mark_used()"" method.
It was originally created here:
  File ""/global/cscratch1/sd/jw447/models/research/inception/bazel-bin/inception/imagenet_distributed_train.runfiles/inception/inception/imagenet_distributed_train.py"", line 69, in <module>
    tf.app.run()  File ""/global/homes/j/jw447/.conda/envs/python-tf/lib/python3.6/site-packages/tensorflow/python/platform/app.py"", line 125, in run
    _sys.exit(main(argv))  File ""/global/cscratch1/sd/jw447/models/research/inception/bazel-bin/inception/imagenet_distributed_train.runfiles/inception/inception/imagenet_distributed_train.py"", line 65, in main
    inception_distributed_train.train(server.target, dataset, cluster_spec)  File ""/global/cscratch1/sd/jw447/models/research/inception/bazel-bin/inception/imagenet_distributed_train.runfiles/inception/inception/inception_distributed_train.py"", line 329, in train
    tf.logging.info(""Time for saving model checkpoint: %.3f sec"" % duration)  File ""/global/homes/j/jw447/.conda/envs/python-tf/lib/python3.6/site-packages/tensorflow/python/training/sync_replicas_optimizer.py"", line 343, in apply_gradients
    return train_op  File ""/global/homes/j/jw447/.conda/envs/python-tf/lib/python3.6/site-packages/tensorflow/python/util/tf_should_use.py"", line 189, in wrapped
    return _add_should_use_warning(fn(*args, **kwargs))
==================================
INFO:tensorflow:Time for saving model checkpoint: 4.109 sec
ERROR:tensorflow:==================================
Object was never used (type <class 'tensorflow.python.framework.ops.Tensor'>):
<tf.Tensor 'report_uninitialized_variables/boolean_mask/GatherV2:0' shape=(?,) dtype=string>
If you want to mark it as used call its ""mark_used()"" method.
It was originally created here:
  File ""/global/cscratch1/sd/jw447/models/research/inception/bazel-bin/inception/imagenet_distributed_train.runfiles/inception/inception/imagenet_distributed_train.py"", line 69, in <module>
    tf.app.run()  File ""/global/homes/j/jw447/.conda/envs/python-tf/lib/python3.6/site-packages/tensorflow/python/platform/app.py"", line 125, in run
    _sys.exit(main(argv))  File ""/global/cscratch1/sd/jw447/models/research/inception/bazel-bin/inception/imagenet_distributed_train.runfiles/inception/inception/imagenet_distributed_train.py"", line 65, in main
    inception_distributed_train.train(server.target, dataset, cluster_spec)  File ""/global/cscratch1/sd/jw447/models/research/inception/bazel-bin/inception/imagenet_distributed_train.runfiles/inception/inception/inception_distributed_train.py"", line 329, in train
    tf.logging.info(""Time for saving model checkpoint: %.3f sec"" % duration)  File ""/global/homes/j/jw447/.conda/envs/python-tf/lib/python3.6/site-packages/tensorflow/python/training/sync_replicas_optimizer.py"", line 343, in apply_gradients
    return train_op  File ""/global/homes/j/jw447/.conda/envs/python-tf/lib/python3.6/site-packages/tensorflow/python/util/tf_should_use.py"", line 189, in wrapped
    return _add_should_use_warning(fn(*args, **kwargs))

The error occurred after the saver.save() function. 

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.

Source code can be found from the models/research/inception.",jw447,b'models:research stat:awaiting model gardener',2019-02-22T18:51:07Z,2020-07-03T10:35:13Z,,,,,,,
6219,Tranformer Attention cannot get Layers,"I am trying to make `official/transformer` work with tf2.0 because I have not had been able to get it to work with previous versions of tf and I guess just wanted to add some pain to my life. 

### System information
`cat tf_env.txt`
```
== cat /etc/issue ===============================================
Darwin MacBook-Pro-5.local 18.0.0 Darwin Kernel Version 18.0.0: Wed Aug 22 20:13:40 PDT 2018; root:xnu-4903.201.2~1/RELEASE_X86_64 x86_64
Mac OS X 10.14

== are we in docker =============================================
No

== compiler =====================================================
Apple LLVM version 10.0.0 (clang-1000.11.45.2)
Target: x86_64-apple-darwin18.0.0
Thread model: posix
InstalledDir: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin

== uname -a =====================================================
Darwin MacBook-Pro-5.local 18.0.0 Darwin Kernel Version 18.0.0: Wed Aug 22 20:13:40 PDT 2018; root:xnu-4903.201.2~1/RELEASE_X86_64 x86_64

== check pips ===================================================
numpy                            1.16.1
protobuf                         3.6.1
tensorflow                       1.12.0
tensorflow-estimator-2.0-preview 1.14.0.dev2019021700

== check for virtualenv =========================================
False

== tensorflow import ============================================
Traceback (most recent call last):
  File ""<string>"", line 1, in <module>
ImportError: No module named tensorflow

== env ==========================================================
LD_LIBRARY_PATH is unset
DYLD_LIBRARY_PATH is unset

== nvidia-smi ===================================================
-bash: nvidia-smi: command not found

== cuda libs  ===================================================

== cat /etc/issue ===============================================
Darwin MacBook-Pro-5.local 18.0.0 Darwin Kernel Version 18.0.0: Wed Aug 22 20:13:40 PDT 2018; root:xnu-4903.201.2~1/RELEASE_X86_64 x86_64
Mac OS X 10.14

== are we in docker =============================================
No

== compiler =====================================================
Apple LLVM version 10.0.0 (clang-1000.11.45.2)
Target: x86_64-apple-darwin18.0.0
Thread model: posix
InstalledDir: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin

== uname -a =====================================================
Darwin MacBook-Pro-5.local 18.0.0 Darwin Kernel Version 18.0.0: Wed Aug 22 20:13:40 PDT 2018; root:xnu-4903.201.2~1/RELEASE_X86_64 x86_64

== check pips ===================================================
numpy                            1.16.1
protobuf                         3.6.1
tensorflow                       1.12.0
tensorflow-estimator-2.0-preview 1.14.0.dev2019021700

== check for virtualenv =========================================
False

== tensorflow import ============================================
Traceback (most recent call last):
  File ""<string>"", line 1, in <module>
ImportError: No module named tensorflow

== env ==========================================================
LD_LIBRARY_PATH is unset
DYLD_LIBRARY_PATH is unset

== nvidia-smi ===================================================
-bash: nvidia-smi: command not found

== cuda libs  ===================================================

== cat /etc/issue ===============================================
Darwin MacBook-Pro-5.local 18.0.0 Darwin Kernel Version 18.0.0: Wed Aug 22 20:13:40 PDT 2018; root:xnu-4903.201.2~1/RELEASE_X86_64 x86_64
Mac OS X 10.14

== are we in docker =============================================
No

== compiler =====================================================
Apple LLVM version 10.0.0 (clang-1000.11.45.2)
Target: x86_64-apple-darwin18.0.0
Thread model: posix
InstalledDir: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin

== uname -a =====================================================
Darwin MacBook-Pro-5.local 18.0.0 Darwin Kernel Version 18.0.0: Wed Aug 22 20:13:40 PDT 2018; root:xnu-4903.201.2~1/RELEASE_X86_64 x86_64

== check pips ===================================================
numpy                            1.16.1
protobuf                         3.6.1
tensorflow                       1.12.0
tensorflow-estimator-2.0-preview 1.14.0.dev2019021700

== check for virtualenv =========================================
False

== tensorflow import ============================================
Traceback (most recent call last):
  File ""<string>"", line 1, in <module>
ImportError: No module named tensorflow

== env ==========================================================
LD_LIBRARY_PATH is unset
DYLD_LIBRARY_PATH is unset

== nvidia-smi ===================================================
-bash: nvidia-smi: command not found

== cuda libs  ===================================================
```

#NOTE I could not get the version above using https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh
but I could this way: 

`python -c 'import tensorflow as tf; print(tf.__version__)'`
2.0.0-dev20190217
- **Exact command to reproduce**:

but also not this way

` python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

Traceback (most recent call last):
  File ""<string>"", line 1, in <module>
AttributeError: module 'tensorflow' has no attribute 'GIT_VERSION'

### Describe the problem


When running the command:
`... official/transformer$ python transformer_main.py --data_dir=/Users/ian/data/transformer_data/translate_ende/ --model_dir=test_output --vocab_file=/Users/ian/data/transformer_data/translate_ende/vocab.ende.33945 --param_set=big`
I get the error
```
Traceback (most recent call last):
  File ""transformer_main.py"", line 38, in <module>
    from official.transformer.model import transformer
  File ""/Users/ian/git/cloned_repos/models-1/official/transformer/model/transformer.py"", line 27, in <module>
    from official.transformer.model import attention_layer
  File ""/Users/ian/git/cloned_repos/models-1/official/transformer/model/attention_layer.py"", line 24, in <module>
    class Attention(tf.layers.Layer):
AttributeError: module 'tensorflow' has no attribute 'layers'
```

Replacing tensorflow.layers with tensorflow.keras and rerunning yields:
```
Traceback (most recent call last):
  File ""transformer_main.py"", line 38, in <module>
    from official.transformer.model import transformer
  File ""/Users/ian/git/cloned_repos/models-1/official/transformer/model/transformer.py"", line 27, in <module>
    from official.transformer.model import attention_layer
  File ""/Users/ian/git/cloned_repos/models-1/official/transformer/model/attention_layer.py"", line 24, in <module>
    class Attention(tf.keras.Layer):
AttributeError: module 'tensorflow.python.keras.api._v2.keras' has no attribute 'Layer'
```

Admittedly I am unskilled in debugging TF especially during version upgrades. Assistance would certainly be appreciated. 
",mystredesign,None,2019-02-18T06:23:51Z,2019-02-18T15:33:11Z,,,,,,,
6207,[Object detection TFlite] PPN tflite show total wrong result on mobile,"**System information**
* Have I written custom code (as opposed to using a stock example script provided in TensorFlow):N
* OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
* Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: HUAWEI MATE20
* TensorFlow installed from (source or binary):binary
* TensorFlow version (use command below):1.10
* Python version:3.6
* Bazel version (if compiling from source):1.15
* GCC/Compiler version (if compiling from source):1.9
* CUDA/cuDNN version:8.0
* GPU model and memory:16GB

I used object detection API, the ssd_mobilenetV2 is working well including the train, eval ,inference on pc ,and .tflite on phone.
Recently, i try ppn_mobilenetv1, the train and eval is well. The frozen_inference_graph.pb also work well on pc and the results are right. When i convert it to tflite_graph.pb, then convert it to detect.tflite. No errors occur. But when it runs on the mobile, it shows totally wrong results. I Look through the export_tflite_ssd_graph.py and export_inference_graph.py . I wonder how it works well for ssd_mobilenetV2 and wrong for ppn_mobilenetv1 on mobile, and how it works well for ppn_mobilenetv1 on pc and wrong on the mobile. Looking forward to your help.

To reproduce the bug as following:
1.Download the ppn_mobilnetV1 http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v1_ppn_shared_box_predictor_300x300_coco14_sync_2018_07_03.tar.gz
2.Conver it to tflite, no errors occur
```
CONFIG_PATH=../pipeline.config 
CHECKPOINT_PATH=../model.ckpt 
OUTPUT_DIR=../results/	
```
```
python object_detection/export_tflite_ssd_graph.py \ 
--pipeline_config_path $CONFIG_PATH \ 
--trained_checkpoint_prefix $CHECKPOINT_PATH \ 
--output_directory $OUTPUT_DIR \ 
--add_postprocessing_op=true
```
```
bazel-bin/tensorflow/contrib/lite/toco/toco \ 
--input_file=$OUTPUT_DIR/tflite_graph.pb \
--output_file=$OUTPUT_DIR/detect.tflite \ 
--input_shapes=1,300,300,3 \ 
--input_arrays=normalized_input_image_tensor \ 
--output_arrays='TFLite_Detection_PostProcess','TFLite_Detection_PostProcess:1','TFLite_Detection_PostProcess:2','TFLite_Detection_PostProcess:3' \ 
--inference_type=FLOAT \
--allow_custom_ops
```
3. Run it on mobile, i use the tensorflow-lite from tensoflow 1.10",holyhao,b'comp:lite models:research stat:awaiting model gardener type:bug',2019-02-15T06:51:56Z,2020-03-25T23:06:07Z,,,,,,,
6198,"How to add layer to the pre-trained model for retrain? I know it is very easy to add a layer in CAFFE(just change prototxt formate file), how to do it in tensorflow?","Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",peterpaniff,b'type:support',2019-02-14T01:54:34Z,2020-03-25T23:06:06Z,,,,,,,
6189,ndition,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",darshdonnii,None,2019-02-12T07:44:00Z,2019-02-12T19:00:10Z,,,,,,,
6172,How can train deeplab like pretrain pb,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**: deeplab
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**:1.12.0
- **Bazel version (if compiling from source)**:0.13.0
- **CUDA/cuDNN version**:9.x
- **GPU model and memory**:tesla k90, 12G
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
I downloaded mobilenetv2_coco_voc_trainaug mode (frozen_inference_graph.pb) in  https://github.com/tensorflow/models/blob/master/research/deeplab/g3doc/model_zoo.md

""Downloaded mobilenetv2_coco_voc_trainaug.pb has ""ResizeBilinear_3"", but I trained by ""local_test_mobilenetv2.sh"" has none.

why is different ? How can I make like  Downloaded mobilenetv2_coco_voc_trainaug.pb?
",ilous12,b'models:research',2019-02-08T15:44:03Z,2019-03-04T04:41:39Z,,,,,,,
6169,vid2depth - Cannot reproduce depth estimation results with default Hyperparameter Values,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**: * models/research/vid2depth*
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: *Yes* - I have included code to estimate the validation loss
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: *Linux Ubuntu 16.04*
- **TensorFlow installed from (source or binary)**: *via pip*
- **TensorFlow version (use command below)**: *1.8.0*
- **Bazel version (if compiling from source)**: -
- **CUDA/cuDNN version**:  *cuda 9.0*
- **GPU model and memory**: *Tesla V100-SXM2*
- **Exact command to reproduce**:     * python inference.py   --kitti_dir kitti-raw-uncompressed   --output_dir inference   --kitti_video kitti-raw-uncompressed/2011_09_26/2011_09_26_drive_0001_sync   --model_ckpt trained-model/model-119496*

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
I followed the instructions given in README.md to analyse the depth estimation performance of the pretrained model (model-119496). I would like to reproduce the results by training the network from scratch. 
I used the entire KITTI dataset (175 GB - mentioned in the README) and i trained the networks using the default Hyperparameter values provided in *train.py*. However my results are subpar. I altered the train_steps from 200,000 (default in train.py) to 119,496 (referring to the filename of the pretrained-model). This too did not produce the expected results. I referred to the paper, the github issues section and stackoverflow, but could not find any extra information regarding this topic. 


I have attached screenshots of the results from inference. I have used the same frame from the kitti-raw-eigen dataset for comparison. Left - The model i trained for 119496 Iterations; Centre - Pretrained model from Tensorflow; Right - Model i trained for 212645 iterations.
As can be seen, in case of both the models i have trained, there are pixels which are estimated to have infinite depth.  

Could you please recommend some directions to optimize the network? Should i further reduce the learning rate form 0.0002 or change the batch size from 4.


### Source code / logs
Here is the train.py i updated to included to estimate the validation loss along with the training loss.

from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import math
import os
import random
import time
from absl import app
from absl import flags
from absl import logging
import model
import reader
import numpy as np
import tensorflow as tf
import util

gfile = tf.gfile

HOME_DIR = os.path.expanduser('~')
DEFAULT_DATA_DIR = os.path.join(HOME_DIR, 'vid2depth/data/kitti_raw_eigen')
DEFAULT_CHECKPOINT_DIR = os.path.join(HOME_DIR, 'vid2depth/checkpoints')

flags.DEFINE_string('data_dir', DEFAULT_DATA_DIR, 'Preprocessed data.')
flags.DEFINE_float('learning_rate', 0.0002, 'Adam learning rate.')
flags.DEFINE_float('beta1', 0.9, 'Adam momentum.')
flags.DEFINE_float('reconstr_weight', 0.85, 'Frame reconstruction loss weight.')
flags.DEFINE_float('smooth_weight', 0.05, 'Smoothness loss weight.')
flags.DEFINE_float('ssim_weight', 0.15, 'SSIM loss weight.')
flags.DEFINE_float('icp_weight', 0.0, 'ICP loss weight.')
flags.DEFINE_integer('batch_size', 4, 'The size of a sample batch')
flags.DEFINE_integer('img_height', 128, 'Input frame height.')
flags.DEFINE_integer('img_width', 416, 'Input frame width.')
### Note: Training time grows linearly with sequence length.  Use 2 or 3.
flags.DEFINE_integer('seq_length', 3, 'Number of frames in sequence.')
flags.DEFINE_string('pretrained_ckpt', None, 'Path to checkpoint with '
                    'pretrained weights.  Do not include .data* extension.')
flags.DEFINE_string('checkpoint_dir', DEFAULT_CHECKPOINT_DIR,
                    'Directory to save model checkpoints.')
flags.DEFINE_integer('train_steps', 500000, 'Number of training steps.')
flags.DEFINE_integer('summary_freq', 100, 'Save summaries every N steps.')
flags.DEFINE_bool('legacy_mode', False, 'Whether to limit losses to using only '
                  'the middle frame in sequence as the target frame.')
FLAGS = flags.FLAGS


MAX_TO_KEEP = 500

NUM_SCALES = 4


def main(_):

  seed = 8964
  tf.set_random_seed(seed)
  np.random.seed(seed)
  random.seed(seed)

  if FLAGS.legacy_mode and FLAGS.seq_length < 3:
    raise ValueError('Legacy mode supports sequence length > 2 only.')

  if not gfile.Exists(FLAGS.checkpoint_dir):
    gfile.MakeDirs(FLAGS.checkpoint_dir)

  train_model = model.Model(data_dir=FLAGS.data_dir,
                            is_training=True,
                            learning_rate=FLAGS.learning_rate,
                            beta1=FLAGS.beta1,
                            reconstr_weight=FLAGS.reconstr_weight,
                            smooth_weight=FLAGS.smooth_weight,
                            ssim_weight=FLAGS.ssim_weight,
                            icp_weight=FLAGS.icp_weight,
                            batch_size=FLAGS.batch_size,
                            img_height=FLAGS.img_height,
                            img_width=FLAGS.img_width,
                            seq_length=FLAGS.seq_length,
                            legacy_mode=FLAGS.legacy_mode)

  ### creating an instance of DataReader to obtain the necessary image_stacks
  ### which can then be passed to the session in the feed_dict
  train_model.reader = reader.DataReader(train_model.data_dir, train_model.batch_size,
                                      train_model.img_height, train_model.img_width,
                                      train_model.seq_length, NUM_SCALES)

  ### returns the training image stack
  (image_stack_training, _, _) = (train_model.reader.read_data('train')) 
  ###print(image_stack_train)

  ### Returns the validation image stack
  (image_stack_validation, _, _) = (train_model.reader.read_data('val'))

  train(train_model, FLAGS.pretrained_ckpt, FLAGS.checkpoint_dir,
        FLAGS.train_steps, FLAGS.summary_freq, image_stack_training, image_stack_validation)


def train(train_model, pretrained_ckpt, checkpoint_dir, train_steps,
          summary_freq, image_stack_train, image_stack_val):
  """"""Train model.""""""
  best_val_loss = 10
  if pretrained_ckpt is not None:
    vars_to_restore = util.get_vars_to_restore(pretrained_ckpt)
    pretrain_restorer = tf.train.Saver(vars_to_restore)
  vars_to_save = util.get_vars_to_restore()
  saver = tf.train.Saver(vars_to_save + [train_model.global_step],
                         max_to_keep=MAX_TO_KEEP)
  sv = tf.train.Supervisor(logdir=checkpoint_dir, save_summaries_secs=0,
                           saver=None)
  config = tf.ConfigProto()
  config.gpu_options.allow_growth = True
  with sv.managed_session(config=config) as sess:
    if pretrained_ckpt is not None:
      logging.info('Restoring pretrained weights from %s', pretrained_ckpt)
      pretrain_restorer.restore(sess, pretrained_ckpt)
    logging.info('Attempting to resume training from %s...', checkpoint_dir)
    checkpoint = tf.train.latest_checkpoint(checkpoint_dir)
    logging.info('Last checkpoint found: %s', checkpoint)
    if checkpoint:
      saver.restore(sess, checkpoint)
      
    logging.info('Training...')
    start_time = time.time()
    last_summary_time = time.time()
    steps_per_epoch = train_model.reader.steps_per_epoch
    step = 1
    
    while step <= train_steps:
      train_model.image_stack = image_stack_train

      fetches = {
          'train': train_model.train_op,
          'global_step': train_model.global_step,
          'incr_global_step': train_model.incr_global_step
      }     

      if step % summary_freq == 0:
        fetches['loss'] = train_model.total_loss        
        fetches['summary'] = sv.summary_op

      #results = sess.run(fetches, feed_dict={train_model.image_stack: image_stack_train})      
      results = sess.run(fetches)
      
      global_step = results['global_step']

      #print(""step = {}"".format(step))
      #print('global_step = {}'.format(global_step))
      #print('train_steps = {}'.format(train_steps))

      if step % summary_freq == 0:
        #print('step / summary_freq == 0')
        train_model.image_stack = image_stack_val
        fetches_val = {
          'validation_loss': train_model.total_loss,
        }
        results_val, validation_summary = sess.run([fetches_val, train_model.validation_loss])
        

      if step % summary_freq == 0:        
        sv.summary_writer.add_summary(results['summary'], global_step)
        sv.summary_writer.add_summary(validation_summary, global_step)
        train_epoch = math.ceil(global_step / steps_per_epoch)
        train_step = global_step - (train_epoch - 1) * steps_per_epoch
        this_cycle = time.time() - last_summary_time
        last_summary_time += this_cycle
        logging.info(
            'Epoch: [%2d] [%5d/%5d] iteration no.: %.3f time: %4.2fs (%ds total) loss: %.3f validation_loss: %.3f',
            train_epoch, train_step, steps_per_epoch, global_step, this_cycle,
            time.time() - start_time, results['loss'], results_val['validation_loss'])
        #print('Validation Summary: {}'.format(validation_summary))

      if step % steps_per_epoch == 0:
        ###print('step steps per epoch')
        if results_val['validation_loss'] < best_val_loss:
          print('[*] Validation Loss decreased from {} to {}. Saving checkpoint to {}...'.format(best_val_loss, results_val['validation_loss'], checkpoint_dir))
          best_val_loss = results_val['validation_loss']
          saver.save(sess, os.path.join(checkpoint_dir, 'model'),
                        global_step=global_step)
        else:
            print('[*] Validation loss did not decrease from {}. Saving checkpoint to {}...'.format(best_val_loss, checkpoint_dir))
            saver.save(sess, os.path.join(checkpoint_dir, 'last_model'))

      ### Setting step to global_step allows for training for a total of
      ### train_steps even if the program is restarted during training.
      step = global_step + 1


if __name__ == '__main__':
  app.run(main)
![vid2dpeth_compare](https://user-images.githubusercontent.com/30627046/52472219-0c6a7100-2b93-11e9-8c54-1515e9c73bc9.png)

",ajithkrishnan,b'models:research',2019-02-08T10:17:43Z,2020-03-25T23:06:05Z,,,,,,,
6168,input/output change,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**: deeplab
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: little bit
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**:0.12.0
- **TensorFlow version (use command below)**: 1.8.0
- **Bazel version (if compiling from source)**: 0.13.0
- **CUDA/cuDNN version**: 9.0
- **GPU model and memory**: 12G
- **Exact command to reproduce**:

### Describe the problem
When I saw good trained deeplab models. subgraphs was belows

>     input_tensors: sub_7
>     output_tensors: ResizeBilinear_2
>     input_shapes: 1,513,513,3
>    output_shapes: 1,65,65,21

How can I modify graph on deeplab?
# Input / Output change
# input_shapes / output shapes change
",ilous12,b'models:research',2019-02-08T09:24:50Z,2019-03-25T03:44:10Z,,,,,,,
6165,2 ROOTS in English sentences while running script tensorflow/demo.sh in docker image tensorflow/syntaxnet,"### System information
- **What is the top-level directory of the model you are using**:
 models/research/syntaxnet/

- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
Modified syntaxnet/demo.sh from the docker image listed below to output CONLL format, and *not* call conll2tree.

- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:

docker image tensorflow/syntaxnet from https://hub.docker.com/r/tensorflow/syntaxnet running on Ubuntu 18.04

- **Exact command to reproduce**:

See below.

### Describe the problem

While running containers based on the docker image tensorflow/syntaxnet, I am very often getting multiple roots on English sentences. So far it is always 2 roots, where the second root is always the punctuation ending the sentence.

The container was started in the following way:

$ docker run -it -v /home/amartyo/English/:/models tensorflow/syntaxnet /bin/bash


Here is the list of containers running on my laptop with their IDs and the images they are derived from:
$ docker container ls
CONTAINER ID        IMAGE                  COMMAND             CREATED             STATUS              PORTS               NAMES
db6821aa7def        tensorflow/syntaxnet   ""/bin/bash""         10 days ago         Up 21 hours         8888/tcp            admiring_cori
635c31cf0b80        brianlow/syntaxnet     ""/bin/bash""         10 days ago         Up 21 hours                             zealous_ramanujan

Here are the list of docker images on my laptop and their respective IDS:
$ docker image ls
REPOSITORY             TAG                 IMAGE ID            CREATED             SIZE
<none>                 <none>              21a090b765dd        2 weeks ago         4.1GB
tensorflow/syntaxnet   latest              2f7af814b2c4        22 months ago       4.04GB
brianlow/syntaxnet     latest              4fe2174cc7f5        2 years ago         2.35GB

I am running syntaxnet/demo.sh, which I have modified to output CONLL format without calling conll2tree. Here is my modified demo.sh:
$ docker container exec -i db6821aa7def cat syntaxnet/demo.sh
\#!/bin/bash
\# Copyright 2016 Google Inc. All Rights Reserved.
\#
\# Licensed under the Apache License, Version 2.0 (the ""License"");
\# you may not use this file except in compliance with the License.
\# You may obtain a copy of the License at
\#
\#     http://www.apache.org/licenses/LICENSE-2.0
\#
\# Unless required by applicable law or agreed to in writing, software
\# distributed under the License is distributed on an ""AS IS"" BASIS,
\# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
\# See the License for the specific language governing permissions and
\# limitations under the License.
\# ==============================================================================

\# A script that runs a tokenizer, a part-of-speech tagger and a dependency
\# parser on an English text file, with one sentence per line.
\#
\# Example usage:
\#  echo ""Parsey McParseface is my favorite parser!"" | syntaxnet/demo.sh

\# To run on a conll formatted file, add the --conll command line argument.
\#

PARSER_EVAL=bazel-bin/syntaxnet/parser_eval
MODEL_DIR=syntaxnet/models/parsey_mcparseface
[[ ""$1"" == ""--conll"" ]] && INPUT_FORMAT=stdin-conll || INPUT_FORMAT=stdin

$PARSER_EVAL \\
  --input=$INPUT_FORMAT \\
  --output=stdout-conll \\
  --hidden_layer_sizes=64 \\
  --arg_prefix=brain_tagger \\
  --graph_builder=structured \\
  --task_context=$MODEL_DIR/context.pbtxt \\
  --model_path=$MODEL_DIR/tagger-params \\
  --slim_model \\
  --batch_size=1024 \\
  --alsologtostderr \\
   | \\
  $PARSER_EVAL \\
  --input=stdin-conll \\
  --output=stdout-conll \\
  --hidden_layer_sizes=512,512 \\
  --arg_prefix=brain_parser \\
  --graph_builder=structured \\
  --task_context=$MODEL_DIR/context.pbtxt \\
  --model_path=$MODEL_DIR/parser-params \\
  --slim_model \\
  --batch_size=1024 \\
  --alsologtostderr 
\#  | \\
\#  bazel-bin/syntaxnet/conll2tree \\
\#  --task_context=$MODEL_DIR/context.pbtxt \\
\#  --alsologtostderr


The first sentence is 'Parsey McParseface is my favorite parser!', taken from the source code of syntaxnet/demo.sh. Here is the CONLL output of this sentence:

$ echo 'Parsey McParseface is my favorite parser!'|docker container exec -i db6821aa7def /bin/bash syntaxnet/demo.sh 2> /dev/null
1	Parsey	_	NOUN	NNP	_	2	nn	_	_
2	McParseface	_	NOUN	NNP	_	6	nsubj	_	_
3	is	_	VERB	VBZ	_	6	cop	_	_
4	my	_	PRON	PRP$	_	6	poss	_	_
5	favorite	_	ADJ	JJ	_	6	amod	_	_
6	parser	_	NOUN	NN	_	0	ROOT	_	_
7	!	_	.	.	_	0	ROOT	_	_

Now consider the following 3 sentences, where the the last 2 sentences are referrering to the first sentence:
The quick brown fox jumps over the lazy dog.
The above sentence uses all the letters in the English alphabet.
It is used as a test of proficiency in typing with 10 fingers.

Here is the CONLL output of these 3 sentences:

$ echo 'The quick brown fox jumps over the lazy dog.'|docker container exec -i db6821aa7def /bin/bash syntaxnet/demo.sh 2> /dev/null
1	The	_	DET	DT	_	4	det	_	_
2	quick	_	ADJ	JJ	_	4	amod	_	_
3	brown	_	ADJ	JJ	_	4	amod	_	_
4	fox	_	NOUN	NN	_	5	nsubj	_	_
5	jumps	_	VERB	VBZ	_	0	ROOT	_	_
6	over	_	ADP	IN	_	5	prep	_	_
7	the	_	DET	DT	_	9	det	_	_
8	lazy	_	ADJ	JJ	_	9	amod	_	_
9	dog	_	NOUN	NN	_	6	pobj	_	_
10	.	_	.	.	_	5	punct	_	_

$ echo 'The above sentence uses all the letters in the English alphabet.'|docker container exec -i db6821aa7def /bin/bash syntaxnet/demo.sh 2> /dev/null
1	The	_	DET	DT	_	3	det	_	_
2	above	_	ADJ	JJ	_	3	amod	_	_
3	sentence	_	NOUN	NN	_	4	nsubj	_	_
4	uses	_	VERB	VBZ	_	0	ROOT	_	_
5	all	_	DET	PDT	_	7	predet	_	_
6	the	_	DET	DT	_	7	det	_	_
7	letters	_	NOUN	NNS	_	4	dobj	_	_
8	in	_	ADP	IN	_	7	prep	_	_
9	the	_	DET	DT	_	11	det	_	_
10	English	_	NOUN	NNP	_	11	nn	_	_
11	alphabet	_	NOUN	NN	_	8	pobj	_	_
12	.	_	.	.	_	0	ROOT	_	_

$ echo 'It is used as a test of proficiency in typing with 10 fingers.'|docker container exec -i db6821aa7def /bin/bash syntaxnet/demo.sh 2> /dev/null
1	It	_	PRON	PRP	_	3	nsubjpass	_	_
2	is	_	VERB	VBZ	_	3	auxpass	_	_
3	used	_	VERB	VBN	_	0	ROOT	_	_
4	as	_	ADP	IN	_	3	prep	_	_
5	a	_	DET	DT	_	6	det	_	_
6	test	_	NOUN	NN	_	4	pobj	_	_
7	of	_	ADP	IN	_	6	prep	_	_
8	proficiency	_	NOUN	NN	_	7	pobj	_	_
9	in	_	ADP	IN	_	6	prep	_	_
10	typing	_	VERB	VBG	_	9	pobj	_	_
11	with	_	ADP	IN	_	10	prep	_	_
12	10	_	NUM	CD	_	13	num	_	_
13	fingers	_	NOUN	NNS	_	11	pobj	_	_
14	.	_	.	.	_	0	ROOT	_	_

As you can see, in 2 out of the 3 sentences 2 ROOTs are being output for one sentence, and the second ROOT is the terminal punctuation mark.

Here are 2 sentences that often turn up on the internet as examples of the importance of punctuation:
Let's eat Grandma!
Let's eat, Grandma!

Here is the CONLL output of these sentences:

$ echo ""Let's eat Grandma!""|docker container exec -i db6821aa7def /bin/bash syntaxnet/demo.sh 2> /dev/null
1	Let	_	VERB	VB	_	0	ROOT	_	_
2	's	_	PRON	PRP	_	3	nsubj	_	_
3	eat	_	VERB	VB	_	1	ccomp	_	_
4	Grandma	_	NOUN	NNP	_	3	dobj	_	_
5	!	_	.	.	_	0	ROOT	_	_

amartyo@TNQ-LTP-185:~$ echo ""Let's eat, Grandma!""|docker container exec -i db6821aa7def /bin/bash syntaxnet/demo.sh 2> /dev/null
1	Let	_	VERB	VB	_	0	ROOT	_	_
2	's	_	PRON	PRP	_	3	nsubj	_	_
3	eat	_	VERB	VB	_	1	ccomp	_	_
4	,	_	.	,	_	3	punct	_	_
5	Grandma	_	NOUN	NNP	_	3	dobj	_	_
6	!	_	.	.	_	0	ROOT	_	_

In this case both sentences have multiple ROOTS.

Here are 2 sentences often found on the internet as examples of the importance of the placement of the comma, and how it can change the meaning of a sentence completely:
Pardon impossible, to be sent to Siberia
Pardon, impossible to be sent to Siberia.

$ echo 'Pardon impossible, to be sent to Siberia.'|docker container exec -i db6821aa7def /bin/bash syntaxnet/demo.sh 2> /dev/null
1	Pardon	_	NOUN	NNP	_	0	ROOT	_	_
2	impossible	_	ADJ	JJ	_	1	acomp	_	_
3	,	_	.	,	_	1	punct	_	_
4	to	_	PRT	TO	_	6	aux	_	_
5	be	_	VERB	VB	_	6	auxpass	_	_
6	sent	_	VERB	VBN	_	1	xcomp	_	_
7	to	_	ADP	IN	_	6	prep	_	_
8	Siberia	_	NOUN	NNP	_	7	pobj	_	_
9	.	_	.	.	_	1	punct	_	_

$ echo 'Pardon, impossible to be sent to Siberia.'|docker container exec -i db6821aa7def /bin/bash syntaxnet/demo.sh 2> /dev/null
1	Pardon	_	NOUN	NNP	_	0	ROOT	_	_
2	,	_	.	,	_	1	punct	_	_
3	impossible	_	ADJ	JJ	_	1	dep	_	_
4	to	_	PRT	TO	_	6	aux	_	_
5	be	_	VERB	VB	_	6	auxpass	_	_
6	sent	_	VERB	VBN	_	3	xcomp	_	_
7	to	_	ADP	IN	_	6	prep	_	_
8	Siberia	_	NOUN	NNP	_	7	pobj	_	_
9	.	_	.	.	_	0	ROOT	_	_

Here, changing the position of the comma has resulted in the second sentence having 2 ROOTs, unlike the first one. Here too, the second ROOT is the terminal punctuation mark, in this case a full stop.

Finally, here are 3 sentences often used to illustrate how the choice of punctuation can completely change the meaning of a sentence:
Woman without her man is nothing.
Woman, without her man, is nothing.
Woman: Without her, man is nothing.

$ echo 'Woman without her man is nothing.'|docker container exec -i db6821aa7def /bin/bash syntaxnet/demo.sh 2> /dev/null
1	Woman	_	NOUN	NN	_	6	nsubj	_	_
2	without	_	ADP	IN	_	1	prep	_	_
3	her	_	PRON	PRP$	_	4	poss	_	_
4	man	_	NOUN	NN	_	2	pobj	_	_
5	is	_	VERB	VBZ	_	6	cop	_	_
6	nothing	_	NOUN	NN	_	0	ROOT	_	_
7	.	_	.	.	_	0	ROOT	_	_

$ echo 'Woman, without her man, is nothing.'|docker container exec -i db6821aa7def /bin/bash syntaxnet/demo.sh 2> /dev/null
1	Woman	_	NOUN	NNP	_	8	discourse	_	_
2	,	_	.	,	_	8	punct	_	_
3	without	_	ADP	IN	_	8	prep	_	_
4	her	_	PRON	PRP$	_	5	poss	_	_
5	man	_	NOUN	NN	_	3	pobj	_	_
6	,	_	.	,	_	8	punct	_	_
7	is	_	VERB	VBZ	_	8	cop	_	_
8	nothing	_	NOUN	NN	_	0	ROOT	_	_
9	.	_	.	.	_	0	ROOT	_	_

$ echo 'Woman: Without her, man is nothing.'|docker container exec -i db6821aa7def /bin/bash syntaxnet/demo.sh 2> /dev/null
1	Woman	_	NOUN	NN	_	0	ROOT	_	_
2	:	_	.	:	_	1	punct	_	_
3	Without	_	ADP	IN	_	8	prep	_	_
4	her	_	PRON	PRP	_	3	pobj	_	_
5	,	_	.	,	_	8	punct	_	_
6	man	_	NOUN	NN	_	8	nsubj	_	_
7	is	_	VERB	VBZ	_	8	cop	_	_
8	nothing	_	NOUN	NN	_	1	dep	_	_
9	.	_	.	.	_	0	ROOT	_	_

In this case, all 3 sentences have 2 ROOTs with the 2nd ROOT being the terminal sentence punctuation.

By contrast, when I use a container based on a different docker image, i.e. brianlow/syntaxnet, which also has a syntaxnet/demo.sh script, I don't get multiple roots in a single sentence. The container was started with the following command:
$ docker run -it brianlow/syntaxnet /bin/bash

Here too I have modified demo.sh to only output CONLL. Here is my modified version of demo.sh:

$ docker container exec -i 635c31cf0b80 cat syntaxnet/demo.sh
\#!/bin/bash
\# Copyright 2016 Google Inc. All Rights Reserved.
\#
\# Licensed under the Apache License, Version 2.0 (the ""License"");
\# you may not use this file except in compliance with the License.
\# You may obtain a copy of the License at
\#
\#     http://www.apache.org/licenses/LICENSE-2.0
\#
\# Unless required by applicable law or agreed to in writing, software
\# distributed under the License is distributed on an ""AS IS"" BASIS,
\# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
\# See the License for the specific language governing permissions and
\# limitations under the License.
\# ==============================================================================

\# A script that runs a tokenizer, a part-of-speech tagger and a dependency
\# parser on an English text file, with one sentence per line.
\#
\# Example usage:
\#  echo ""Parsey McParseface is my favorite parser!"" | syntaxnet/demo.sh

\# To run on a conll formatted file, add the --conll command line argument.
\#

PARSER_EVAL=bazel-bin/syntaxnet/parser_eval
MODEL_DIR=syntaxnet/models/parsey_mcparseface
[[ ""$1"" == ""--conll"" ]] && INPUT_FORMAT=stdin-conll || INPUT_FORMAT=stdin

$PARSER_EVAL \\
  --input=$INPUT_FORMAT \\
  --output=stdout-conll \\
  --hidden_layer_sizes=64 \\
  --arg_prefix=brain_tagger \\
  --graph_builder=structured \\
  --task_context=$MODEL_DIR/context.pbtxt \\
  --model_path=$MODEL_DIR/tagger-params \\
  --slim_model \\
  --batch_size=1024 \\
  --alsologtostderr \\
   | \\
  $PARSER_EVAL \\
  --input=stdin-conll \\
  --output=stdout-conll \\
  --hidden_layer_sizes=512,512 \\
  --arg_prefix=brain_parser \\
  --graph_builder=structured \\
  --task_context=$MODEL_DIR/context.pbtxt \\
  --model_path=$MODEL_DIR/parser-params \\
  --slim_model \\
  --batch_size=1024 \\
  --alsologtostderr

Here is the output of running the same set of sentences against the modified syntaxnet/demo.sh:

$ cat sentences.txt|docker container exec -i 635c31cf0b80 /bin/bash syntaxnet/demo.sh 2> /dev/null
1	Parsey	_	NOUN	NNP	_	2	nn	_	_
2	McParseface	_	NOUN	NNP	_	6	nsubj	_	_
3	is	_	VERB	VBZ	_	6	cop	_	_
4	my	_	PRON	PRP$	_	6	poss	_	_
5	favorite	_	ADJ	JJ	_	6	amod	_	_
6	parser	_	NOUN	NN	_	0	ROOT	_	_
7	!	_	.	.	_	6	punct	_	_

1	The	_	DET	DT	_	4	det	_	_
2	quick	_	ADJ	JJ	_	4	amod	_	_
3	brown	_	ADJ	JJ	_	4	amod	_	_
4	fox	_	NOUN	NN	_	5	nsubj	_	_
5	jumps	_	VERB	VBZ	_	0	ROOT	_	_
6	over	_	ADP	IN	_	5	prep	_	_
7	the	_	DET	DT	_	9	det	_	_
8	lazy	_	ADJ	JJ	_	9	amod	_	_
9	dog	_	NOUN	NN	_	6	pobj	_	_
10	.	_	.	.	_	5	punct	_	_

1	The	_	DET	DT	_	3	det	_	_
2	above	_	ADJ	JJ	_	3	amod	_	_
3	sentence	_	NOUN	NN	_	4	nsubj	_	_
4	uses	_	VERB	VBZ	_	0	ROOT	_	_
5	all	_	DET	PDT	_	7	predet	_	_
6	the	_	DET	DT	_	7	det	_	_
7	letters	_	NOUN	NNS	_	4	dobj	_	_
8	in	_	ADP	IN	_	7	prep	_	_
9	the	_	DET	DT	_	11	det	_	_
10	English	_	NOUN	NNP	_	11	nn	_	_
11	alphabet	_	NOUN	NN	_	8	pobj	_	_
12	.	_	.	.	_	4	punct	_	_

1	It	_	PRON	PRP	_	3	nsubjpass	_	_
2	is	_	VERB	VBZ	_	3	auxpass	_	_
3	used	_	VERB	VBN	_	0	ROOT	_	_
4	as	_	ADP	IN	_	3	prep	_	_
5	a	_	DET	DT	_	6	det	_	_
6	test	_	NOUN	NN	_	4	pobj	_	_
7	of	_	ADP	IN	_	6	prep	_	_
8	proficiency	_	NOUN	NN	_	7	pobj	_	_
9	in	_	ADP	IN	_	6	prep	_	_
10	typing	_	VERB	VBG	_	9	pobj	_	_
11	with	_	ADP	IN	_	10	prep	_	_
12	10	_	NUM	CD	_	13	num	_	_
13	fingers	_	NOUN	NNS	_	11	pobj	_	_
14	.	_	.	.	_	3	punct	_	_

1	Let	_	VERB	VB	_	0	ROOT	_	_
2	's	_	PRON	PRP	_	3	nsubj	_	_
3	eat	_	VERB	VB	_	1	ccomp	_	_
4	Grandma	_	NOUN	NNP	_	3	dobj	_	_
5	!	_	.	.	_	1	punct	_	_

1	Let	_	VERB	VB	_	0	ROOT	_	_
2	's	_	PRON	PRP	_	3	nsubj	_	_
3	eat	_	VERB	VB	_	1	ccomp	_	_
4	,	_	.	,	_	3	punct	_	_
5	Grandma	_	NOUN	NNP	_	3	dobj	_	_
6	!	_	.	.	_	1	punct	_	_

1	Pardon	_	NOUN	NNP	_	6	nsubjpass	_	_
2	impossible	_	ADJ	JJ	_	1	acomp	_	_
3	,	_	.	,	_	6	punct	_	_
4	to	_	PRT	TO	_	6	aux	_	_
5	be	_	VERB	VB	_	6	auxpass	_	_
6	sent	_	VERB	VBN	_	0	ROOT	_	_
7	to	_	ADP	IN	_	6	prep	_	_
8	Siberia	_	NOUN	NNP	_	7	pobj	_	_
9	.	_	.	.	_	6	punct	_	_

1	Pardon	_	NOUN	NNP	_	0	ROOT	_	_
2	,	_	.	,	_	1	punct	_	_
3	impossible	_	ADJ	JJ	_	6	advmod	_	_
4	to	_	PRT	TO	_	6	aux	_	_
5	be	_	VERB	VB	_	6	auxpass	_	_
6	sent	_	VERB	VBN	_	1	dep	_	_
7	to	_	ADP	IN	_	6	prep	_	_
8	Siberia	_	NOUN	NNP	_	7	pobj	_	_
9	.	_	.	.	_	1	punct	_	_

1	Woman	_	NOUN	NN	_	6	nsubj	_	_
2	without	_	ADP	IN	_	1	prep	_	_
3	her	_	PRON	PRP$	_	4	poss	_	_
4	man	_	NOUN	NN	_	2	pobj	_	_
5	is	_	VERB	VBZ	_	6	cop	_	_
6	nothing	_	NOUN	NN	_	0	ROOT	_	_
7	.	_	.	.	_	6	punct	_	_

1	Woman	_	NOUN	NNP	_	8	nsubj	_	_
2	,	_	.	,	_	8	punct	_	_
3	without	_	ADP	IN	_	8	prep	_	_
4	her	_	PRON	PRP$	_	5	poss	_	_
5	man	_	NOUN	NN	_	3	pobj	_	_
6	,	_	.	,	_	8	punct	_	_
7	is	_	VERB	VBZ	_	8	cop	_	_
8	nothing	_	NOUN	NN	_	0	ROOT	_	_
9	.	_	.	.	_	8	punct	_	_

1	Woman	_	NOUN	NN	_	0	ROOT	_	_
2	:	_	.	:	_	1	punct	_	_
3	Without	_	ADP	IN	_	8	prep	_	_
4	her	_	PRON	PRP	_	3	pobj	_	_
5	,	_	.	,	_	8	punct	_	_
6	man	_	NOUN	NN	_	8	nsubj	_	_
7	is	_	VERB	VBZ	_	8	cop	_	_
8	nothing	_	NOUN	NN	_	1	dep	_	_
9	.	_	.	.	_	1	punct	_	_

Here every sentence has a single ROOT, and the terminal punctuation mark is always recognized as such.

In both tensorflow/syntaxnet and brianlow/syntaxnet images, demo.sh is originally identical. Both invoke the program bazel-bin/syntaxnet/parser_eval and use the parsey_mcparseface model. It seems to me there is a regression either in bazel-bin/syntaxnet/parser_eval or in the parsey_mcparseface model.

Is there any workaround for this bug? Where should I file a bug report, and against what? Please give me any suggestions you may have.
Thanks.",amartyobanerjee,b'models:research',2019-02-07T12:14:47Z,2020-03-25T23:06:04Z,,,,,,,
6152,How to add a new class to the existing model,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem

Hello,
I have a model ('frozen inference graph and checkpoints')  of 27 different types of logos now i want to add few more logs to my model but currently i don't have a data sets of pre-trained model that consists of 27 logos. Is their a way to add some more classes to the current model. Please ping me if any one have a solution.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",HarshaPaladugu,b'type:support',2019-02-04T15:08:24Z,2020-03-25T23:06:36Z,,,,,,,
6140,how to find the co-ordinates of the bounding box xo-ordinates?,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",kalpalathika,None,2019-02-01T22:17:10Z,2019-02-01T22:18:37Z,,,,,,,
6139,how to find the co-ordinates of the bounding box ?,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",kalpalathika,None,2019-02-01T22:17:09Z,2019-02-01T22:19:05Z,,,,,,,
6133,How to find the bounding box coordinates,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",kalpalathika,b'type:support',2019-02-01T09:00:47Z,2020-03-25T23:06:35Z,,,,,,,
6129,"Hello, ","Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",andreicatana,None,2019-01-31T10:24:39Z,2019-01-31T15:03:37Z,,,,,,,
6127,exclude,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",priyasundaresan,None,2019-01-31T08:22:39Z,2019-02-01T21:35:47Z,,,,,,,
6118,Possible bug in adversarial_text ,"
------------------------

### System information
- **What is the top-level directory of the model you are using**: models/research/adversarial_text/

### Describe the problem
In the adversarial_losses.py file (L59-67) (https://github.com/tensorflow/models/blob/b3158fb0183809400e9e7f8092dd541201b1c4d4/research/adversarial_text/adversarial_losses.py#L67), you are re-calculating the loss with embedded + perturb where perturb is the gradient of log probability with respect to word embeddings. Shouldn't it be (embedded - perturb) because in the [paper](https://arxiv.org/pdf/1605.07725.pdf), in equation 5-6, they are adding r_adv which is the negative of the norm constrained gradient and the perturb that you are calculating is positive norm constrained gradient.

@a-dai 
",prashantbudania,b'stat:awaiting response',2019-01-30T23:38:21Z,2019-01-31T20:36:07Z,,,,,,,
6115,ResourceExhaustedError OOM while running inference on a docker container,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**: object detection
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04)
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.12
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**: 9.0.176
- **GPU model and memory**:  NVIDIA Docker: 2.0.3
- **Exact command to reproduce**:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.
I have created a docker container which has tensorflow's inference code embedded into it.  I am trying to send an image for inference and verify how many features are being detected by the ml model. 
at the moment the model is only able to handle a single image per inference. It craps out while running a second image with the error shown below.  Does anyone have insights on how to fix this?







### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.

ResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[1,64,400,528] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc
     [[node FirstStageFeatureExtractor/InceptionV2/InceptionV2/Conv2d_1a_7x7/separable_conv2d (defined at /opt/program/predictor.py:101)  = Conv2D[T=DT_FLOAT, data_format=""NCHW"", dilations=[1, 1, 1, 1], padding=""VALID"", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](FirstStageFeatureExtractor/InceptionV2/InceptionV2/Conv2d_1a_7x7/separable_conv2d/depthwise, FirstStageFeatureExtractor/InceptionV2/Conv2d_1a_7x7/pointwise_weights)]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.
You can collect some of this information using our environment capture script:
",tarunluthra,None,2019-01-30T16:20:40Z,2020-03-25T23:06:34Z,,,,,,,
6111,Solution for result = ''.join(_cescape_highbit_to_str[ord(c)] for c in result) IndexError: list index out of range,"hi guys, I met the problem a few days ago .now I solved it ,so shared with you

when I run model_mian.py, it occoured 
`result = ''.join(_cescape_highbit_to_str[ord(c)] for c in result) IndexError: list index out of range`

someone told that it may be caused by Chinese characters ,but I checked for many times ,and quite sure that there were not. so I found the code where threw error (text_encoding.py), and add try except, like this:
`  try:
      result = ''.join(_cescape_highbit_to_str[ord(c)] for c in result)
  except:
      print(result)`

then occured a new error: 
`'ascii' codec can't encode character u'\u202a' in position...`
and printed the path of train.record and test.record I wrote in pipeline config file(for me is ssd_resnet50_v1_fpn_shared_box_predictor_640x640_coco14_sync.config,'input_path','label_map_path')

the path is correct,but what is the strange code  '\u202a‘, I finally find that it is caused because I directly copy the file path in Windows and paste, which may add some strange code in the head of your real path. in windows, you think the path is 'data/train.record'
but in fact,when you copy the path and paste,may change to '\u202adata/train.record'
just delete and manually input，the problem will be solved!

This little bug wastes a lot of time of me, so I share with you and hope it works.

",junjieliwhu,b'stat:awaiting response',2019-01-30T07:44:40Z,2020-03-25T23:06:33Z,,,,,,,
6093,Exception has occurred: tensorflow.python.framework.errors_impl.NotFoundError,"------------------------

### System information
- **What is the top-level directory of the model you are using**:C:\tf_od_api\mask_rcnn_restnet50
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: windows 7x64
- **TensorFlow installed from (source or binary)**: binary  pip install
- **TensorFlow version (use command below)**:1.12
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:CUDA9.0 cudnn 7.3.1
- **GPU model and memory**:nvidia GTX1060 6GB
- **Exact command to reproduce**:
python object_detection/legacy/train.py --train_dir=C:\\tf_od_api\\mask_rcnn_restnet50 --pipeline_config_path=C:\\tf_od_api\\mask_rcnn_restnet50\\mask_rcnn_resnet50_atrous_coco.config
You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

I created the  TFrecords from [here](https://github.com/priya-dwivedi/Deep-Learning/blob/master/Custom_Mask_RCNN/create_pet_tf_record.py)
1 class and 1010 png images and Mask R-CNN with Resnet-50 (v1), Atrous version  model from [ here](http://download.tensorflow.org/models/object_detection/mask_rcnn_resnet50_atrous_coco_2018_01_28.tar.gz) config from [here](https://github.com/tensorflow/models/blob/master/research/object_detection/samples/configs/mask_rcnn_resnet50_atrous_coco.config)
I  modified the path and the tfrecord name in config and the image type,
when I used the command above, the errors showed up:


Exception has occurred: tensorflow.python.framework.errors_impl.NotFoundError
Restoring from checkpoint failed. This is most likely due to a Variable name or other graph key that is missing from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:  Key Conv/biases/Momentum not found in checkpoint    [[node save/RestoreV2 (defined at C:\Users\willy_sung\AppData\Local\Continuum\anaconda3\envs\venv\lib\site-packages\object_detection-0.1-py3.6.egg\object_detection\legacy\trainer.py:377)  = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, ..., DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_INT64], _device=""/job:localhost/replica:0/task:0/device:CPU:0""](_arg_save/Const_0_0, save/RestoreV2/tensor_names, save/RestoreV2/shape_and_slices)]]  Caused by op 'save/RestoreV2', defined at:   File ""c:\Users\willy_sung\.vscode\extensions\ms-python.python-2018.12.1\pythonFiles\ptvsd_launcher.py"", line 45, in <module>     main(ptvsdArgs)   File ""c:\Users\willy_sung\.vscode\extensions\ms-python.python-2018.12.1\pythonFiles\lib\python\ptvsd\__main__.py"", line 265, in main     wait=args.wait)   File ""c:\Users\willy_sung\.vscode\extensions\ms-python.python-2018.12.1\pythonFiles\lib\python\ptvsd\__main__.py"", line 258, in handle_args     debug_main(addr, name, kind, *extra, **kwargs)   File ""c:\Users\willy_sung\.vscode\extensions\ms-python.python-2018.12.1\pythonFiles\lib\python\ptvsd\_local.py"", line 45, in debug_main     run_file(address, name, *extra, **kwargs)   File ""c:\Users\willy_sung\.vscode\extensions\ms-python.python-2018.12.1\pythonFiles\lib\python\ptvsd\_local.py"", line 79, in run_file     run(argv, addr, **kwargs)   File ""c:\Users\willy_sung\.vscode\extensions\ms-python.python-2018.12.1\pythonFiles\lib\python\ptvsd\_local.py"", line 140, in _run     _pydevd.main()   File ""c:\Users\willy_sung\.vscode\extensions\ms-python.python-2018.12.1\pythonFiles\lib\python\ptvsd\_vendored\pydevd\pydevd.py"", line 1925, in main     debugger.connect(host, port)   File ""c:\Users\willy_sung\.vscode\extensions\ms-python.python-2018.12.1\pythonFiles\lib\python\ptvsd\_vendored\pydevd\pydevd.py"", line 1283, in run     return self._exec(is_module, entry_point_fn, module_name, file, globals, locals)   File ""c:\Users\willy_sung\.vscode\extensions\ms-python.python-2018.12.1\pythonFiles\lib\python\ptvsd\_vendored\pydevd\pydevd.py"", line 1290, in _exec     pydev_imports.execfile(file, globals, locals)  # execute the script   File ""c:\Users\willy_sung\.vscode\extensions\ms-python.python-2018.12.1\pythonFiles\lib\python\ptvsd\_vendored\pydevd\_pydev_imps\_pydev_execfile.py"", line 25, in execfile     exec(compile(contents+""\n"", file, 'exec'), glob, loc)   File ""c:\models\research\object_detection\legacy\train.py"", line 184, in <module>     tf.app.run()   File ""C:\Users\willy_sung\AppData\Local\Continuum\anaconda3\envs\venv\lib\site-packages\tensorflow\python\platform\app.py"", line 125, in run     _sys.exit(main(argv))   File ""C:\Users\willy_sung\AppData\Local\Continuum\anaconda3\envs\venv\lib\site-packages\tensorflow\python\util\deprecation.py"", line 306, in new_func     return func(*args, **kwargs)   File ""c:\models\research\object_detection\legacy\train.py"", line 180, in main     graph_hook_fn=graph_rewriter_fn)   File ""C:\Users\willy_sung\AppData\Local\Continuum\anaconda3\envs\venv\lib\site-packages\object_detection-0.1-py3.6.egg\object_detection\legacy\trainer.py"", line 377, in train     keep_checkpoint_every_n_hours=keep_checkpoint_every_n_hours)   File ""C:\Users\willy_sung\AppData\Local\Continuum\anaconda3\envs\venv\lib\site-packages\tensorflow\python\training\saver.py"", line 1102, in __init__     self.build()   File ""C:\Users\willy_sung\AppData\Local\Continuum\anaconda3\envs\venv\lib\site-packages\tensorflow\python\training\saver.py"", line 1114, in build     self._build(self._filename, build_save=True, build_restore=True)   File ""C:\Users\willy_sung\AppData\Local\Continuum\anaconda3\envs\venv\lib\site-packages\tensorflow\python\training\saver.py"", line 1151, in _build     build_save=build_save, build_restore=build_restore)   File ""C:\Users\willy_sung\AppData\Local\Continuum\anaconda3\envs\venv\lib\site-packages\tensorflow\python\training\saver.py"", line 795, in _build_internal     restore_sequentially, reshape)   File ""C:\Users\willy_sung\AppData\Local\Continuum\anaconda3\envs\venv\lib\site-packages\tensorflow\python\training\saver.py"", line 406, in _AddRestoreOps     restore_sequentially)   File ""C:\Users\willy_sung\AppData\Local\Continuum\anaconda3\envs\venv\lib\site-packages\tensorflow\python\training\saver.py"", line 862, in bulk_restore     return io_ops.restore_v2(filename_tensor, names, slices, dtypes)   File ""C:\Users\willy_sung\AppData\Local\Continuum\anaconda3\envs\venv\lib\site-packages\tensorflow\python\ops\gen_io_ops.py"", line 1550, in restore_v2     shape_and_slices=shape_and_slices, dtypes=dtypes, name=name)   File ""C:\Users\willy_sung\AppData\Local\Continuum\anaconda3\envs\venv\lib\site-packages\tensorflow\python\framework\op_def_library.py"", line 787, in _apply_op_helper     op_def=op_def)   File ""C:\Users\willy_sung\AppData\Local\Continuum\anaconda3\envs\venv\lib\site-packages\tensorflow\python\util\deprecation.py"", line 488, in new_func     return func(*args, **kwargs)   File ""C:\Users\willy_sung\AppData\Local\Continuum\anaconda3\envs\venv\lib\site-packages\tensorflow\python\framework\ops.py"", line 3274, in create_op     op_def=op_def)   File ""C:\Users\willy_sung\AppData\Local\Continuum\anaconda3\envs\venv\lib\site-packages\tensorflow\python\framework\ops.py"", line 1770, in __init__     self._traceback = tf_stack.extract_stack()  NotFoundError (see above for traceback): Restoring from checkpoint failed. This is most likely due to a Variable name or other graph key that is missing from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:  Key Conv/biases/Momentum not found in checkpoint    [[node save/RestoreV2 (defined at C:\Users\willy_sung\AppData\Local\Continuum\anaconda3\envs\venv\lib\site-packages\object_detection-0.1-py3.6.egg\object_detection\legacy\trainer.py:377)  = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, ..., DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_INT64], _device=""/job:localhost/replica:0/task:0/device:CPU:0""](_arg_save/Const_0_0, save/RestoreV2/tensor_names, save/RestoreV2/shape_and_slices)]] 

the path of the data and model is in the image
<img width=""964"" alt=""tfodapiissue"" src=""https://user-images.githubusercontent.com/7753153/51660244-15324300-1fe8-11e9-9aee-2c04e02fd676.png"">
It seems the model is not right to the config file, 
but there is the same error when I try the maskrcnninceptionv2 model too.
can anyone help me how to solve this problem?",lunasdejavu,None,2019-01-24T07:01:52Z,2020-03-19T01:35:30Z,,,,,,,
6091,[DeepLab] Reproducing frozen inference graph,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**: deeplab
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: no
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.10.0
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**: CUDA 9.0/cuDNN 7.0.5
- **GPU model and memory**: nVidia GeForce GTX 1080 8GB
- **Exact command to reproduce**: 
python deeplab/export_model.py --checkpoint_path=/data/tf_saved_models/deeplabv3_cityscapes_train/model.ckpt --export_path=/data/tf_saved_models/deeplabv3_cityscapes_train/frozen_inference_graph_new.pb --model_variant=""xception_65"" --atrous_rates=6 --atrous_rates=12 --atrous_rates=18 --output_stride=16 --decoder_output_stride=4 --train_crop_size=769 --train_crop_size=769 --num_classes=19
You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Starting from the xception65 deeplabv3_cityscapes_train model checkpoint in the DeepLab model zoo, using the export_model.py script in the DeepLab folder, I can re-export the trained checkpoint as above to a new frozen inference graph, which I can load into a session and query successfully. However I notice that the graph I generate is not exactly identical to the frozen_inference_graph.pb supplied for that model: the graph I generate differs in size by about 0.1 MB. Is it possible for me to exactly reproduce the frozen inference graph supplied in the model zoo, using the export code in that folder?

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",lgutzwil,b'models:research',2019-01-23T19:47:16Z,2020-03-25T23:06:31Z,,,,,,,
6088,model zoo ckpt file is not match,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

I use ""ssd_mobilenet_v1_fpn_shared_box_predictor_640x640_coco14_sync.config"" file.
in config file set below

  fine_tune_checkpoint: ""xxxxxxxxxx/ssd_mobilenet_v1_fpn_shared_box_predictor_640x640_coco14_sync_2018_07_03/model.ckpt""

and then run model_main.py

console :
WARNING:root:Variable [MobilenetV1/Conv2d_0/BatchNorm/beta] is not available in checkpoint
WARNING:root:Variable [MobilenetV1/Conv2d_0/BatchNorm/gamma] is not available in checkpoint
WARNING:root:Variable [MobilenetV1/Conv2d_0/BatchNorm/moving_mean] is not available in checkpoint
WARNING:root:Variable [MobilenetV1/Conv2d_0/BatchNorm/moving_variance] is not available in checkpoint
WARNING:root:Variable [MobilenetV1/Conv2d_0/weights] is not available in checkpoint
WARNING:root:Variable [MobilenetV1/Conv2d_10_depthwise/BatchNorm/beta] is not available in checkpoint

so print tensor name of ssd_mobilenet_v1_fpn_shared_box_predictor_640x640_coco14_sync_2018_07_03/model.ckp

...
tensor_name:  FeatureExtractor/MobilenetV1/Conv2d_0/BatchNorm/beta
...
tensor_name:  FeatureExtractor/MobilenetV1/Conv2d_5_depthwise/BatchNorm/gamma
...

not match between model file and ckpt 

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",hongym7,b'type:support',2019-01-23T09:03:59Z,2020-03-25T23:06:31Z,,,,,,,
6077,Any plan for Tensorflow 2.0,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:N/A
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:MS Windows10 X64 1809 build17763
- **TensorFlow installed from (source or binary)**:source 
- **TensorFlow version (use command below)**:1.12
- **Bazel version (if compiling from source)**:0.19
- **CUDA/cuDNN version**:10.0
- **GPU model and memory**:NVIDIA Geforce RTX2080TI 11GB * 2
- **Exact command to reproduce**: N/A

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
N/A
### Source code / logs
N/A


I have noticed that Tensorflow 2.0 will abandon the TF.SLIM module(from https://medium.com/tensorflow/standardizing-on-keras-guidance-on-high-level-apis-in-tensorflow-2-0-bad2b04c819a). TF2.0 gives up backward compatibility is really a bad news.Many projects in /research currently rely on the slim module.Many model implementations and pre-training weights are also provided in slim/net.I want to know the fate of this project after the official release of TF2.0.Thank you.",rootkitchao,None,2019-01-21T18:58:03Z,2019-03-05T17:23:40Z,,,,,,,
6068,research/object_detection/dockerfiles/android: Dockerfile doesn't build,"### System information
- **What is the top-level directory of the model you are using**:
research/object_detection/dockerfiles/android
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Ubuntu 18.04.1 LTS
- **TensorFlow installed from (source or binary)**:
N/A
- **TensorFlow version (use command below)**:
N/A
- **Bazel version (if compiling from source)**:
N/A
- **CUDA/cuDNN version**:
N/A
- **GPU model and memory**:
N/A
- **Exact command to reproduce**:
docker version
docker build --tag detect-tf .

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

I am attempting to build a docker image using the Dockerfile in this directory. It fails to build.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.

``` bash
$  lsb_release -a
No LSB modules are available.
Distributor ID:	Ubuntu
Description:	Ubuntu 18.04.1 LTS
Release:	18.04
Codename:	bionic
$ docker version
Client:
 Version:      18.03.1-ce
 API version:  1.37
 Go version:   go1.9.5
 Git commit:   9ee9f40
 Built:        Thu Apr 26 07:17:38 2018
 OS/Arch:      linux/amd64
 Experimental: false
 Orchestrator: swarm

Server:
 Engine:
  Version:      18.03.1-ce
  API version:  1.37 (minimum version 1.12)
  Go version:   go1.9.5
  Git commit:   9ee9f40
  Built:        Thu Apr 26 07:15:45 2018
  OS/Arch:      linux/amd64
  Experimental: false
$ docker build --tag detect-tf .
Sending build context to Docker daemon  27.14kB
Step 1/21 : FROM tensorflow/tensorflow:nightly-devel
 ---> 5c0cfcf0facb
Step 2/21 : RUN git clone --depth 1 https://github.com/tensorflow/models.git &&     mv models /tensorflow/models
 ---> Using cache
 ---> 5bec1e897792
Step 3/21 : RUN export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)"" &&     echo ""deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" | tee -a /etc/apt/sources.list.d/google-cloud-sdk.list &&     curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add - &&     apt-get update -y && apt-get install google-cloud-sdk -y
 ---> Running in b36a2d4db863
deb http://packages.cloud.google.com/apt cloud-sdk-bionic main
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0Warning: apt-key output should not be parsed (stdout is not a terminal)
100  1326  100  1326    0     0   8392      0 --:--:-- --:--:-- --:--:--  8392
gpg: failed to start agent '/usr/bin/gpg-agent': No such file or directory
gpg: can't connect to the agent: No such file or directory
gpg: failed to start agent '/usr/bin/gpg-agent': No such file or directory
gpg: can't connect to the agent: No such file or directory
The command '/bin/sh -c export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)"" &&     echo ""deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" | tee -a /etc/apt/sources.list.d/google-cloud-sdk.list &&     curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add - &&     apt-get update -y && apt-get install google-cloud-sdk -y' returned a non-zero code: 2
```
",ctessum,b'models:research',2019-01-18T16:48:00Z,2020-03-18T21:09:15Z,,,,,,,
6056,"My system is windows 10, python 3.6 and I install protoc-3.4.0-win32 not protoc-3.5.0-win32, **protoc-3.5 for windows has bug!!!**","My system is windows 10, python 3.6 and I install protoc-3.4.0-win32 not protoc-3.5.0-win32, **protoc-3.5 for windows has bug!!!**
After running protoc object_detection/protos/*.proto --python_out=.
just change 
`from utils import label_map_util`  
to 
`from object_detection.utils import label_map_util`

_Originally posted by @duancaohui in https://github.com/tensorflow/models/issues/1990#issuecomment-374976015_",vidit2011998,b'models:research',2019-01-15T20:22:50Z,2020-03-25T23:06:54Z,,,,,,,
6052,ModuleNotFoundError: No module named '_pywrap_tensorflow_internal',"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",JAY-KISHAN-PANJIYAR,None,2019-01-15T15:01:11Z,2019-02-01T22:08:12Z,,,,,,,
6043,Struct2depth: NaNs in inf_norm,"System information

What is the top-level directory of the model you are using: models/research/struct2depth
Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No (beyond fixing #5857 )
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
TensorFlow installed from (source or binary): Binary
TensorFlow version (use command below):v1.12.0-0-ga6d8ffae09 1.12.0
Bazel version (if compiling from source): N/A
CUDA/cuDNN version: libcudart.so.9.0.176
GPU model and memory: 1080Ti 11Gb
Exact command to reproduce: python train.py 
--logtostderr 
--checkpoint_dir=ckpt 
--data_dir=/opt/bigdata/kitti_processed 
--architecture=resnet 
--imagenet_norm=true 
--joint_encoder=false --summary_freq=1
Describe the problem

Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

I am running into errors of the form ""LossTensor is inf or nan : Tensor had NaN values"". This appears to be from the inf_loss contribution:
losses = tf.map_fn(
get_losses, object_masks, dtype=tf.float32)
self.inf_loss += tf.reduce_mean(losses)

In particular, losses will occasionally contain a nan value, as shown here:
[array([ 0.92789054, 5.1210318 , 4.9717507 , 5.6173134 , 60.209503 ,
33.976864 , 0. ], dtype=float32), array([ 0.92788905, 4.3226395 , 4.3226404 , 4.3226247 , 60.209442 ,
33.97685 , nan], dtype=float32), array([ 0.9278935, 3.9967735, 3.8008199, 4.100856 , 60.20948 ,
29.60478 , 29.60479 ], dtype=float32)]

(As I understand it, these are the losses for j=0,1,2 in the loop ""for j in range(self.seq_length)"" )

Note that the nan in the j=1 row is paired with a 0 in the j=0 row, this appears to be consistent behavior.

The only thing I've found that triggers this is if the object mask is particularly small, but there doesn't seem to be an absolute threshold.",kesinger,b'models:research',2019-01-14T15:40:13Z,2020-03-25T23:06:52Z,,,,,,,
6041, Could not find a version that satisfies the requirement syntaxnet-with-tensorflow (from versions: ),"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**: syntaxnet
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: no 
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**:  1.12.0
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:  10.0 
- **GPU model and memory**:
- **Exact command to reproduce**: pip install syntaxnet-with-tensorflow

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",ConnieTong,b'models:research',2019-01-14T07:51:54Z,2020-03-25T23:06:52Z,,,,,,,
6030,steps_per_epoch not honored in tf.keras.fit,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",dmt013,None,2019-01-11T18:17:13Z,2019-01-11T18:18:43Z,,,,,,,
6022,TF detect app crash Getting crash,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",M1thun,b'comp:lite type:build/install',2019-01-10T17:39:30Z,2019-01-22T06:30:46Z,,,,,,,
6008,Do not merge: debugging failures in presubmit,I'm seeing mysterious SIGABRT's and this is a scratch space for running presubmits to debug them.,robieta,b'cla: yes',2019-01-08T01:05:10Z,2019-01-08T17:51:31Z,,,,,,,
6007,"Loss skyrockets randomly, cause and effect unkno","Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. Really, they do. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow, per-say.

I left your pre-written message here so you could be as annoyed with it as I am.  

------------------------

### System information
- **What is the top-level directory of the model you are using**: `models/research/`
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: no
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Debian 9 nightly
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: nightly
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**: nightly
- **GPU model and memory**: Tesla K80
- **Exact command to reproduce**: follow your own ""pet detector"" tutorial. <-- seriously, just do this

You can collect some of this information using our environment capture script:

### Describe the problem
Loss leaps occasionally, scheduled learning rates shouldn't permit such dramatic changes. Not sure that they're actually causing a problem, but want to get your insight on what's going on here. Happens every ~10,000 steps, started after ~25k steps. Causes?

### Source code / logs
```
 master-replica-0 loss = 0.049381822, step = 62104 (56.439 sec) I  master-replica-0
 master-replica-0 loss = 0.20843819, step = 62204 (57.136 sec) I  master-replica-0
 master-replica-0 loss = 0.08859253, step = 62304 (56.564 sec) I  master-replica-0
 master-replica-0 loss = 0.14603062, step = 62404 (56.244 sec) I  master-replica-0
 master-replica-0 loss = 5676524600000000.0, step = 62504 (56.958 sec) I  master-replica-0
 master-replica-0 loss = 0.083275326, step = 62604 (56.345 sec) master-replica-0 
```",npeirson,b'models:research',2019-01-07T19:03:57Z,2020-03-25T23:07:28Z,,,,,,,
6006,model.ckpt is generated or we should have this file before running train.py,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",Poonamjo,b'stat:awaiting response type:support',2019-01-07T09:53:57Z,2019-06-10T22:05:28Z,,,,,,,
6002,"accoon_dataset_master\data\object_detection.pbtxt : The filename, directory name, or volume label syntax is incorrect. ; Unknown error","Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",Poonamjo,None,2019-01-07T07:50:44Z,2020-03-25T23:07:27Z,,,,,,,
6000,Inference Time between Tesla K80 and GTX 1080 in Tensorflow,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem

Hi all. I have a question. I run object detection application in tensorflow But K80 inference time is higher than gtx 1080. (by example_file_pipeline.py)

Common : CUDA 9.0, Python 3.5, Tensorflow 1.12
A : Tesla K80 1, Windows Server 2012 R2
B : GTX 1080 1, Windows 7
C : GTX 1080 Ti 1, Ubuntu 16.04

A inference time is 3.2s ~ 3.4s
B inference time is 1.6s ~ 1.8s
C inference time is 1.0s ~ 1.1s

Why ?





### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",hongym7,b'type:support',2019-01-07T02:00:02Z,2020-03-25T23:07:27Z,,,,,,,
5979,object detection predict error ,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
can't show the image 

### Source code / logs

QObject::moveToThread: Current thread (0x7f3a44ba2800) is not the object's thread (0x7f3a4dd7a900).
Cannot move to target thread (0x7f3a44ba2800)

QPixmap: Must construct a QApplication before a QPaintDevice
Aborted (core dumped)

",xxllp,b'models:research stat:awaiting response type:bug',2019-01-02T04:23:08Z,2019-06-10T22:04:31Z,,,,,,,
5968,SSD MobileNet v2 quantized on COCO,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
I tried to evaluate the provided ssd_mobilenet_v2 quantized model from the model zoo and obtained mAP = 8.3% on the COCO validation set using the provided pipeline.config. In the model zoo table the mAP is reported as 22%. Any ideas why this discrepancy is happening?

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.

",llevkova,b'type:docs',2018-12-28T22:40:32Z,2020-02-07T18:51:23Z,,,,,,,
5966,[object detection]dose preprocessor.py's random_image_scale conflict with image_resizer,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
I have a question: config file has a option:
`image_resizer {
      keep_aspect_ratio_resizer {
        min_dimension: 600
        max_dimension: 1024
      }
    }`
And i can use option: `data_augmentation_options {
    random_image_scale {
    }
  }`
if my image is 1024 * 1024,if it feed training model,it maybe 2048 * 2048 or always can not exceed 1024*1024
### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",a819721810,None,2018-12-28T06:26:49Z,2018-12-28T23:13:37Z,,,,,,,
5957,A bug in pcl_rl replay_buffer code,"it would raise this ValueEroor when n = max_size in https://github.com/tensorflow/models/blob/master/research/pcl_rl/replay_buffer.py#L136

```
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/usr/local/lib/python2.7/dist-packages/numpy/core/fromnumeric.py"", line 757, in argpartition
    return _wrapfunc(a, 'argpartition', kth, axis=axis, kind=kind, order=order)
  File ""/usr/local/lib/python2.7/dist-packages/numpy/core/fromnumeric.py"", line 51, in _wrapfunc
    return getattr(obj, method)(*args, **kwds)
ValueError: kth(=10) out of bounds (10)
```",yogurfrul,b'type:support',2018-12-25T07:35:26Z,2020-02-07T18:53:03Z,,,,,,,
5956,fix bug in replay_buffer.py,"it would raise this ValueEroor when n = max_size 
```
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/usr/local/lib/python2.7/dist-packages/numpy/core/fromnumeric.py"", line 757, in argpartition
    return _wrapfunc(a, 'argpartition', kth, axis=axis, kind=kind, order=order)
  File ""/usr/local/lib/python2.7/dist-packages/numpy/core/fromnumeric.py"", line 51, in _wrapfunc
    return getattr(obj, method)(*args, **kwds)
ValueError: kth(=10) out of bounds (10)
```",yogurfrul,b'cla: no',2018-12-25T07:32:46Z,2020-04-24T15:30:30Z,,,,,,,
5954,SSD resnet50 fpn model not detecting at all.,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",BalajiB3663,b'type:support',2018-12-24T11:02:15Z,2019-12-23T07:42:19Z,,,,,,,
5952,OOM error after 10000 epoch (bidirectional rnn),"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",libphy,b'type:docs',2018-12-23T22:35:06Z,2018-12-28T22:52:07Z,,,,,,,
5941,r,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",FlipWebApps,None,2018-12-20T08:32:08Z,2018-12-20T08:35:46Z,,,,,,,
5932,[Feature request]:  models/research/object_detection load tfrecords from regex for infer_detections.py,"### System information
- **What is the top-level directory of the model you are using**: tensorflow/models/research/object_detection
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No, using stock from git
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux  4.19.8-arch1-1-ARCH Antergos
- **Python version**: Python 3.6.7 |Anaconda, Inc.| (default, Oct 23 2018, 19:16:44) 
- **TensorFlow installed from (source or binary)**: N/A
- **TensorFlow version (use command below)**: 1.12
- **Bazel version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: 10.0/7.4
- **GPU model and memory**: Nvidia Quadro K2100M 2GB
- **Exact command to reproduce**: 
```sh
python object_detection/inference/infer_detections.py \
--input_tfrecord_paths=data/labels/airbus_boats_test.tfrecord-00000-of-00004,data/labels/airbus_boats_test.tfrecord-00000-of-00004,data/labels/airbus_boats_test.tfrecord-00001-of-00004,data/labels/airbus_boats_test.tfrecord-00002-of-00004,data/labels/airbus_boats_test.tfrecord-00003-of-00004 \
--output_tfrecord_path=eval/detections.tfrecord \
--inference_graph=models/ssd_resnet50_v1_fpn_shared_box_predictor_640x640_coco14/frozen_inference_graph.pb
```
### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

We must pass a comma separated list of tfrecords to --input_tf_records_path but it is inconvenient when we have alot of tfrecords. It would be best if we could pass a proto config file like for the model_main.py file. but a regexed or pseudo regexed implementation would also do

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.

I devised a simple solution for myself:

```python
    input_tfrecord_paths = [os.path.join(input_tfrecord_root_path,f) 
                            for f in os.listdir(input_tfrecord_root_path) 
                            if re.match(input_tfrecord_fname, f)]
```
instead of 
```python
input_tfrecord_paths = [
       v for v in FLAGS.input_tfrecord_paths.split(',') if v]
```

So now i can use
```sh
python object_detection/inference/infer_detections.py \
--input_tfrecord_paths=data/labels/airbus_boats_test.tfrecord-00[0-9]+-of-00128 \
--output_tfrecord_path=eval/detections.tfrecord \
--inference_graph=models/ssd_resnet50_v1_fpn_shared_box_predictor_640x640_coco14/frozen_inference_graph.pb
```",yaceben,b'help wanted type:feature',2018-12-19T01:04:44Z,2020-02-07T18:52:35Z,,,,,,,
5920,ssd_mobilenetv2_oidv4 download link not working,"The download link of the ssd_mobilenetv2_oidv4 model (from the Tensorflow detection model zoo page) trained on open images is not working.

Page where the link can be found: https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md

Link: http://download.tensorflow.org/models/object_detection/ssd_mobilenetv2_oidv4_2018_10_30.tar.gz

Error message: 

```
<Error>
<Code>AccessDenied</Code>
<Message>Access denied.</Message>
<Details>
Anonymous caller does not have storage.objects.get access to download.tensorflow.org/models/object_detection/ssd_mobilenetv2_oidv4_2018_10_30.tar.gz.
</Details>
</Error>
```",bocsiboti,b'type:bug',2018-12-17T08:21:53Z,2020-02-19T19:20:21Z,,,,,,,
5914,"interactive_text_analyzer notebook error: ""Key lookahead/cell/cell_0/layer_norm_basic_lstm_cell/kernel not found""","### System information
- **What is the top-level directory of the model you are using**: models/research/syntaxnet/examples/dragnn
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: stock example below
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 18.04
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: ('v1.11.0-0-gc19e29306c', '1.11.0')
- **Bazel version (if compiling from source)**: 0.15.2
- **CUDA/cuDNN version**: 10.0 / 7.3.1.20
- **GPU model and memory**: RTX 2080 ti 11GB
- **Exact command to reproduce**: run 1st cell in: models/research/syntaxnet/examples/dragnn/interactive_text_analyzer.ipynb

### Describe the problem
I am unable to run jupyter notebook ""interactive_text_analyzer.ipynb"", located in models/research/syntaxnet/examples/dragnn. 
It returns the error shown below. can someone advise on how to get the interactive_text_analyzer notebook to run?
`NotFoundError: Key lookahead/cell/cell_0/layer_norm_basic_lstm_cell/kernel not found in checkpoint
	 [[Node: save/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, ..., DT_FLOAT, DT_FLOAT, DT_INT32, DT_INT32, DT_FLOAT], _device=""/job:localhost/replica:0/task:0/device:CPU:0""](_arg_save/Const_0_0, save/RestoreV2/tensor_names, save/RestoreV2/shape_and_slices)]]`
`	 [[Node: save/RestoreV2/_17 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device_incarnation=1, tensor_name=""edge_24_save/RestoreV2"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:GPU:0""]()]`

I saw a reference to using a checkpoint converter ([here](https://github.com/KranthiGV/Pretrained-Show-and-Tell-model/issues/9#issuecomment-366816238)), and ran converter like this:
```
anatolii@ubun:~/models/research/syntaxnet/examples/dragnn$ python2 ~/models/research/syntaxnet/tensorflow/tensorflow/contrib/rnn/python/tools/checkpoint_convert.py ./data/en/segmenter/checkpoint ./data-new/en/segmenter/
2018-12-15 16:54:22.748978: I external/org_tensorflow/tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2018-12-15 16:54:22.930786: I external/org_tensorflow/tensorflow/core/common_runtime/gpu/gpu_device.cc:1356] Found device 0 with properties: 
name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.665
pciBusID: 0000:05:00.0
totalMemory: 10.73GiB freeMemory: 10.03GiB
2018-12-15 16:54:22.930811: I external/org_tensorflow/tensorflow/core/common_runtime/gpu/gpu_device.cc:1435] Adding visible gpu devices: 0
2018-12-15 16:54:23.143174: I external/org_tensorflow/tensorflow/core/common_runtime/gpu/gpu_device.cc:923] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-12-15 16:54:23.143205: I external/org_tensorflow/tensorflow/core/common_runtime/gpu/gpu_device.cc:929]      0 
2018-12-15 16:54:23.143212: I external/org_tensorflow/tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 0:   N 
2018-12-15 16:54:23.143415: I external/org_tensorflow/tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9689 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:05:00.0, compute capability: 7.5)
```
but it results in a small `checkpoint` file 59 bytes long with this content:
```
model_checkpoint_path: "".""
all_model_checkpoint_paths: "".""
```

### Source Code of the notebook cell that's failing:
```
import os
import ipywidgets as widgets
import tensorflow as tf
from IPython import display
from dragnn.protos import spec_pb2
from dragnn.python import graph_builder
from dragnn.python import spec_builder
from dragnn.python import load_dragnn_cc_impl  # This loads the actual op definitions
from dragnn.python import render_parse_tree_graphviz
from dragnn.python import visualization
from google.protobuf import text_format
from syntaxnet import load_parser_ops  # This loads the actual op definitions
from syntaxnet import sentence_pb2
from syntaxnet.ops import gen_parser_ops
from tensorflow.python.platform import tf_logging as logging

def load_model(base_dir, master_spec_name, checkpoint_name):
    # Read the master spec
    master_spec = spec_pb2.MasterSpec()
    with open(os.path.join(base_dir, master_spec_name), ""r"") as f:
        text_format.Merge(f.read(), master_spec)
    spec_builder.complete_master_spec(master_spec, None, base_dir)
    logging.set_verbosity(logging.WARN)  # Turn off TensorFlow spam.

    # Initialize a graph
    graph = tf.Graph()
    with graph.as_default():
        hyperparam_config = spec_pb2.GridPoint()
        builder = graph_builder.MasterBuilder(master_spec, hyperparam_config)
        # This is the component that will annotate test sentences.
        annotator = builder.add_annotation(enable_tracing=True)
        builder.add_saver()  # ""Savers"" can save and load models; here, we're only going to load.

    sess = tf.Session(graph=graph)
    with graph.as_default():
        #sess.run(tf.global_variables_initializer())
        #sess.run('save/restore_all', {'save/Const:0': os.path.join(base_dir, checkpoint_name)})
        checkpointPath = os.path.join(base_dir, checkpoint_name)
        print (""calling saver.restore on"",checkpointPath)
        builder.saver.restore(sess, checkpointPath)
        
    def annotate_sentence(sentence):
        with graph.as_default():
            return sess.run([annotator['annotations'], annotator['traces']],
                            feed_dict={annotator['input_batch']: [sentence]})
    return annotate_sentence

segmenter_model = load_model(""data/en/segmenter"", ""spec.textproto"", ""checkpoint"")
parser_model = load_model(""data/en"", ""parser_spec.textproto"", ""checkpoint"")
```
### Output of the cell:
```
WARNING:tensorflow:tf.op_scope(values, name, default_name) is deprecated, use tf.name_scope(name, default_name, values)
WARNING:tensorflow:tf.op_scope(values, name, default_name) is deprecated, use tf.name_scope(name, default_name, values)
('calling saver.restore on', 'data/en/segmenter/checkpoint')
---------------------------------------------------------------------------
NotFoundError                             Traceback (most recent call last)
<ipython-input-1-6469534a5d58> in <module>()
     48     return annotate_sentence
     49 
---> 50 segmenter_model = load_model(""data/en/segmenter"", ""spec.textproto"", ""checkpoint"")
     51 parser_model = load_model(""data/en"", ""parser_spec.textproto"", ""checkpoint"")

<ipython-input-1-6469534a5d58> in load_model(base_dir, master_spec_name, checkpoint_name)
     40         checkpointPath = os.path.join(base_dir, checkpoint_name)
     41         print (""calling saver.restore on"",checkpointPath)
---> 42         builder.saver.restore(sess, checkpointPath)
     43 
     44     def annotate_sentence(sentence):

/home/anatolii/models/research/syntaxnet/bazel-bin/dragnn/tools/oss_notebook_launcher.runfiles/org_tensorflow/tensorflow/python/training/saver.pyc in restore(self, sess, save_path)
   1800     else:
   1801       sess.run(self.saver_def.restore_op_name,
-> 1802                {self.saver_def.filename_tensor_name: save_path})
   1803 
   1804   @staticmethod

/home/anatolii/models/research/syntaxnet/bazel-bin/dragnn/tools/oss_notebook_launcher.runfiles/org_tensorflow/tensorflow/python/client/session.pyc in run(self, fetches, feed_dict, options, run_metadata)
    898     try:
    899       result = self._run(None, fetches, feed_dict, options_ptr,
--> 900                          run_metadata_ptr)
    901       if run_metadata:
    902         proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)

/home/anatolii/models/research/syntaxnet/bazel-bin/dragnn/tools/oss_notebook_launcher.runfiles/org_tensorflow/tensorflow/python/client/session.pyc in _run(self, handle, fetches, feed_dict, options, run_metadata)
   1133     if final_fetches or final_targets or (handle and feed_dict_tensor):
   1134       results = self._do_run(handle, final_targets, final_fetches,
-> 1135                              feed_dict_tensor, options, run_metadata)
   1136     else:
   1137       results = []

/home/anatolii/models/research/syntaxnet/bazel-bin/dragnn/tools/oss_notebook_launcher.runfiles/org_tensorflow/tensorflow/python/client/session.pyc in _do_run(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)
   1314     if handle is None:
   1315       return self._do_call(_run_fn, feeds, fetches, targets, options,
-> 1316                            run_metadata)
   1317     else:
   1318       return self._do_call(_prun_fn, handle, feeds, fetches)

/home/anatolii/models/research/syntaxnet/bazel-bin/dragnn/tools/oss_notebook_launcher.runfiles/org_tensorflow/tensorflow/python/client/session.pyc in _do_call(self, fn, *args)
   1333         except KeyError:
   1334           pass
-> 1335       raise type(e)(node_def, op, message)
   1336 
   1337   def _extend_graph(self):

NotFoundError: Key lookahead/cell/cell_0/layer_norm_basic_lstm_cell/kernel not found in checkpoint
	 [[Node: save/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, ..., DT_FLOAT, DT_FLOAT, DT_INT32, DT_INT32, DT_FLOAT], _device=""/job:localhost/replica:0/task:0/device:CPU:0""](_arg_save/Const_0_0, save/RestoreV2/tensor_names, save/RestoreV2/shape_and_slices)]]
	 [[Node: save/RestoreV2/_17 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device_incarnation=1, tensor_name=""edge_24_save/RestoreV2"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:GPU:0""]()]]

Caused by op u'save/RestoreV2', defined at:
  File ""/usr/lib/python2.7/runpy.py"", line 174, in _run_module_as_main
    ""__main__"", fname, loader, pkg_name)
  File ""/usr/lib/python2.7/runpy.py"", line 72, in _run_code
    exec code in run_globals
  File ""/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py"", line 16, in <module>
    app.launch_new_instance()
  File ""/usr/local/lib/python2.7/dist-packages/traitlets/config/application.py"", line 658, in launch_instance
    app.start()
  File ""/usr/local/lib/python2.7/dist-packages/ipykernel/kernelapp.py"", line 499, in start
    self.io_loop.start()
  File ""/usr/local/lib/python2.7/dist-packages/tornado/ioloop.py"", line 1073, in start
    handler_func(fd_obj, events)
  File ""/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py"", line 300, in null_wrapper
    return fn(*args, **kwargs)
  File ""/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py"", line 450, in _handle_events
    self._handle_recv()
  File ""/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py"", line 480, in _handle_recv
    self._run_callback(callback, msg)
  File ""/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py"", line 432, in _run_callback
    callback(*args, **kwargs)
  File ""/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py"", line 300, in null_wrapper
    return fn(*args, **kwargs)
  File ""/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py"", line 283, in dispatcher
    return self.dispatch_shell(stream, msg)
  File ""/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py"", line 233, in dispatch_shell
    handler(stream, idents, msg)
  File ""/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py"", line 399, in execute_request
    user_expressions, allow_stdin)
  File ""/usr/local/lib/python2.7/dist-packages/ipykernel/ipkernel.py"", line 208, in do_execute
    res = shell.run_cell(code, store_history=store_history, silent=silent)
  File ""/usr/local/lib/python2.7/dist-packages/ipykernel/zmqshell.py"", line 537, in run_cell
    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)
  File ""/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py"", line 2714, in run_cell
    interactivity=interactivity, compiler=compiler, result=result)
  File ""/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py"", line 2818, in run_ast_nodes
    if self.run_code(code, result):
  File ""/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py"", line 2878, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File ""<ipython-input-1-6469534a5d58>"", line 50, in <module>
    segmenter_model = load_model(""data/en/segmenter"", ""spec.textproto"", ""checkpoint"")
  File ""<ipython-input-1-6469534a5d58>"", line 32, in load_model
    builder.add_saver()  # ""Savers"" can save and load models; here, we're only going to load.
  File ""/home/anatolii/models/research/syntaxnet/bazel-bin/dragnn/tools/oss_notebook_launcher.runfiles/__main__/dragnn/python/graph_builder.py"", line 720, in add_saver
    write_version=saver_pb2.SaverDef.V1)
  File ""/home/anatolii/models/research/syntaxnet/bazel-bin/dragnn/tools/oss_notebook_launcher.runfiles/org_tensorflow/tensorflow/python/training/saver.py"", line 1338, in __init__
    self.build()
  File ""/home/anatolii/models/research/syntaxnet/bazel-bin/dragnn/tools/oss_notebook_launcher.runfiles/org_tensorflow/tensorflow/python/training/saver.py"", line 1347, in build
    self._build(self._filename, build_save=True, build_restore=True)
  File ""/home/anatolii/models/research/syntaxnet/bazel-bin/dragnn/tools/oss_notebook_launcher.runfiles/org_tensorflow/tensorflow/python/training/saver.py"", line 1384, in _build
    build_save=build_save, build_restore=build_restore)
  File ""/home/anatolii/models/research/syntaxnet/bazel-bin/dragnn/tools/oss_notebook_launcher.runfiles/org_tensorflow/tensorflow/python/training/saver.py"", line 835, in _build_internal
    restore_sequentially, reshape)
  File ""/home/anatolii/models/research/syntaxnet/bazel-bin/dragnn/tools/oss_notebook_launcher.runfiles/org_tensorflow/tensorflow/python/training/saver.py"", line 472, in _AddRestoreOps
    restore_sequentially)
  File ""/home/anatolii/models/research/syntaxnet/bazel-bin/dragnn/tools/oss_notebook_launcher.runfiles/org_tensorflow/tensorflow/python/training/saver.py"", line 886, in bulk_restore
    return io_ops.restore_v2(filename_tensor, names, slices, dtypes)
  File ""/home/anatolii/models/research/syntaxnet/bazel-bin/dragnn/tools/oss_notebook_launcher.runfiles/org_tensorflow/tensorflow/python/ops/gen_io_ops.py"", line 1463, in restore_v2
    shape_and_slices=shape_and_slices, dtypes=dtypes, name=name)
  File ""/home/anatolii/models/research/syntaxnet/bazel-bin/dragnn/tools/oss_notebook_launcher.runfiles/org_tensorflow/tensorflow/python/framework/op_def_library.py"", line 787, in _apply_op_helper
    op_def=op_def)
  File ""/home/anatolii/models/research/syntaxnet/bazel-bin/dragnn/tools/oss_notebook_launcher.runfiles/org_tensorflow/tensorflow/python/framework/ops.py"", line 3392, in create_op
    op_def=op_def)
  File ""/home/anatolii/models/research/syntaxnet/bazel-bin/dragnn/tools/oss_notebook_launcher.runfiles/org_tensorflow/tensorflow/python/framework/ops.py"", line 1718, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access

NotFoundError (see above for traceback): Key lookahead/cell/cell_0/layer_norm_basic_lstm_cell/kernel not found in checkpoint
	 [[Node: save/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, ..., DT_FLOAT, DT_FLOAT, DT_INT32, DT_INT32, DT_FLOAT], _device=""/job:localhost/replica:0/task:0/device:CPU:0""](_arg_save/Const_0_0, save/RestoreV2/tensor_names, save/RestoreV2/shape_and_slices)]]
	 [[Node: save/RestoreV2/_17 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device_incarnation=1, tensor_name=""edge_24_save/RestoreV2"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:GPU:0""]()]]
```
",toli-belo,b'type:bug',2018-12-16T01:04:14Z,2020-02-07T18:50:56Z,,,,,,,
5908, cd ..         ^ SyntaxError: invalid syntax,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",veket,None,2018-12-14T02:57:08Z,2018-12-19T20:53:11Z,,,,,,,
5905,"object_detection:TypeError: a bytes-like object is required, not 'str'","### System information
- **What is the top-level directory of the model you are using**:object dection
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: 
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04
- **TensorFlow installed from (source or binary)**:pip
- **TensorFlow version (use command below)**:gpu-1.12
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:9.0.176
- **GPU model and memory**:12G
- **Exact command to reproduce**:python3.5



### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

object_detection.
ssd_inception_v3_pets.config
ssd_inception_v2_coco_2018_01_28

Do:
python object_detection/model_main.py --alsologtostderr --model_dir=object_detection/train_ssd_inception_v2/ --pipeline_config_path=object_detection/train_ssd_inception_v2/ssd_inception_v3_pets.config




### Source code / logs
WARNING:tensorflow:Forced number of epochs for all eval validations to be 1.
W1213 20:11:20.126205 139980489991936 tf_logging.py:125] Forced number of epochs for all eval validations to be 1.
INFO:tensorflow:Maybe overwriting sample_1_of_n_eval_examples: 1
I1213 20:11:20.126504 139980489991936 tf_logging.py:115] Maybe overwriting sample_1_of_n_eval_examples: 1
INFO:tensorflow:Maybe overwriting train_steps: None
I1213 20:11:20.126622 139980489991936 tf_logging.py:115] Maybe overwriting train_steps: None
INFO:tensorflow:Maybe overwriting load_pretrained: True
I1213 20:11:20.126714 139980489991936 tf_logging.py:115] Maybe overwriting load_pretrained: True
INFO:tensorflow:Ignoring config override key: load_pretrained
I1213 20:11:20.126804 139980489991936 tf_logging.py:115] Ignoring config override key: load_pretrained
INFO:tensorflow:Maybe overwriting eval_num_epochs: 1
I1213 20:11:20.127182 139980489991936 tf_logging.py:115] Maybe overwriting eval_num_epochs: 1
WARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.
W1213 20:11:20.127314 139980489991936 tf_logging.py:125] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.
INFO:tensorflow:create_estimator_and_inputs: use_tpu False, export_to_tpu False
I1213 20:11:20.127432 139980489991936 tf_logging.py:115] create_estimator_and_inputs: use_tpu False, export_to_tpu False
INFO:tensorflow:Using config: {'_device_fn': None, '_model_dir': 'object_detection/train_ssd_inception_v2/', '_save_checkpoints_secs': 600, '_train_distribute': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f4f96dbd7f0>, '_service': None, '_tf_random_seed': None, '_protocol': None, '_global_id_in_cluster': 0, '_keep_checkpoint_every_n_hours': 10000, '_session_config': allow_soft_placement: true
graph_options {
  rewrite_options {
    meta_optimizer_iterations: ONE
  }
}
, '_is_chief': True, '_evaluation_master': '', '_master': '', '_save_checkpoints_steps': None, '_task_type': 'worker', '_keep_checkpoint_max': 5, '_task_id': 0, '_num_worker_replicas': 1, '_save_summary_steps': 100, '_eval_distribute': None, '_log_step_count_steps': 100, '_num_ps_replicas': 0, '_experimental_distribute': None}
I1213 20:11:20.127867 139980489991936 tf_logging.py:115] Using config: {'_device_fn': None, '_model_dir': 'object_detection/train_ssd_inception_v2/', '_save_checkpoints_secs': 600, '_train_distribute': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f4f96dbd7f0>, '_service': None, '_tf_random_seed': None, '_protocol': None, '_global_id_in_cluster': 0, '_keep_checkpoint_every_n_hours': 10000, '_session_config': allow_soft_placement: true
graph_options {
  rewrite_options {
    meta_optimizer_iterations: ONE
  }
}
, '_is_chief': True, '_evaluation_master': '', '_master': '', '_save_checkpoints_steps': None, '_task_type': 'worker', '_keep_checkpoint_max': 5, '_task_id': 0, '_num_worker_replicas': 1, '_save_summary_steps': 100, '_eval_distribute': None, '_log_step_count_steps': 100, '_num_ps_replicas': 0, '_experimental_distribute': None}
WARNING:tensorflow:Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7f4f96dd77b8>) includes params argument, but params are not passed to Estimator.
W1213 20:11:20.128126 139980489991936 tf_logging.py:125] Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7f4f96dd77b8>) includes params argument, but params are not passed to Estimator.
INFO:tensorflow:Not using Distribute Coordinator.
I1213 20:11:20.128751 139980489991936 tf_logging.py:115] Not using Distribute Coordinator.
INFO:tensorflow:Running training and evaluation locally (non-distributed).
I1213 20:11:20.128986 139980489991936 tf_logging.py:115] Running training and evaluation locally (non-distributed).
INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.
I1213 20:11:20.129307 139980489991936 tf_logging.py:115] Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.
Traceback (most recent call last):
  File ""/home/models/research/object_detection/utils/label_map_util.py"", line 137, in load_labelmap
    text_format.Merge(label_map_string, label_map)
  File ""/home/py3/lib/python3.5/site-packages/google/protobuf/text_format.py"", line 536, in Merge
    descriptor_pool=descriptor_pool)
  File ""/home/py3/lib/python3.5/site-packages/google/protobuf/text_format.py"", line 590, in MergeLines
    return parser.MergeLines(lines, message)
  File ""/home/py3/lib/python3.5/site-packages/google/protobuf/text_format.py"", line 623, in MergeLines
    self._ParseOrMerge(lines, message)
  File ""/home/py3/lib/python3.5/site-packages/google/protobuf/text_format.py"", line 638, in _ParseOrMerge
    self._MergeField(tokenizer, message)
  File ""/home/py3/lib/python3.5/site-packages/google/protobuf/text_format.py"", line 730, in _MergeField
    (message_descriptor.full_name, name))
google.protobuf.text_format.ParseError: 7:1 : Message type ""object_detection.protos.StringIntLabelMap"" has no field named ""model"".

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""object_detection/model_main.py"", line 115, in <module>
    tf.app.run()
  File ""/home/py3/lib/python3.5/site-packages/tensorflow/python/platform/app.py"", line 125, in run
    _sys.exit(main(argv))
  File ""object_detection/model_main.py"", line 110, in main
    tf.estimator.train_and_evaluate(estimator, train_spec, eval_specs[0])
  File ""/home/py3/lib/python3.5/site-packages/tensorflow/python/estimator/training.py"", line 471, in train_and_evaluate
    return executor.run()
  File ""/home/py3/lib/python3.5/site-packages/tensorflow/python/estimator/training.py"", line 610, in run
    return self.run_local()
  File ""/home/py3/lib/python3.5/site-packages/tensorflow/python/estimator/training.py"", line 711, in run_local
    saving_listeners=saving_listeners)
  File ""/home/py3/lib/python3.5/site-packages/tensorflow/python/estimator/estimator.py"", line 354, in train
    loss = self._train_model(input_fn, hooks, saving_listeners)
  File ""/home/py3/lib/python3.5/site-packages/tensorflow/python/estimator/estimator.py"", line 1207, in _train_model
    return self._train_model_default(input_fn, hooks, saving_listeners)
  File ""/home/py3/lib/python3.5/site-packages/tensorflow/python/estimator/estimator.py"", line 1234, in _train_model_default
    input_fn, model_fn_lib.ModeKeys.TRAIN))
  File ""/home/py3/lib/python3.5/site-packages/tensorflow/python/estimator/estimator.py"", line 1075, in _get_features_and_labels_from_input_fn
    self._call_input_fn(input_fn, mode))
  File ""/home/py3/lib/python3.5/site-packages/tensorflow/python/estimator/estimator.py"", line 1162, in _call_input_fn
    return input_fn(**kwargs)
  File ""/home/models/research/object_detection/inputs.py"", line 479, in _train_input_fn
    batch_size=params['batch_size'] if params else train_config.batch_size)
  File ""/home/models/research/object_detection/builders/dataset_builder.py"", line 123, in build
    num_additional_channels=input_reader_config.num_additional_channels)
  File ""/home/models/research/object_detection/data_decoders/tf_example_decoder.py"", line 297, in __init__
    default_value=''),
  File ""/home/models/research/object_detection/data_decoders/tf_example_decoder.py"", line 59, in __init__
    label_map_proto_file, use_display_name=False)
  File ""/home/models/research/object_detection/utils/label_map_util.py"", line 165, in get_label_map_dict
    label_map = load_labelmap(label_map_path)
  File ""/home/models/research/object_detection/utils/label_map_util.py"", line 139, in load_labelmap
    label_map.ParseFromString(label_map_string)
TypeError: a bytes-like object is required, not 'str'

",Loovelj,None,2018-12-13T12:36:03Z,2018-12-13T12:56:47Z,,,,,,,
5901,Can Not Replicate Transformer Base Bleu Scores,"### System information
- **What is the top-level directory of the model you are using**: /models/official/transformer
- **Have I written custom code** : No
- **OS Platform and Distribution** :Ubuntu 16.04.5 LTS
- **TensorFlow installed from (source or binary)**: Binary
- **TensorFlow version** : v1.12.0-0-ga6d8ffae09 1.12.0
- **CUDA/cuDNN version**: release 9.0, V9.0.176
- **GPU model and memory**: Tesla K40m/12GB
- **Exact command to reproduce**: Official Instructions
- **Bazel version**: N/A

### Describe the problem
I have been trying to replicate models/offical/tensorflow/ **Base**. I followed the official instructions  yet I was faced with two problems:
1- The size of the generated vocabulary was bigger than the one defined in /models/offical/tranformer/model/model_params.py. The program would not work, I fixed it by changing the value in model_params.py to the actual vocabulary size of 33945.
2- The second problem, and the one I could not solve,  is that Blue scores after **10 epochs** are not consistent with what is reported in models/official/tensorflow.  Running, as instructed,  compute_bleu.py gives **case-insensitive** Bleu scores of **26.04** far bellow the ""promised"" **27.7** Bleu for **Base** Transformer.

I have trained **3** models and even though there are fluctuation in Bleu scores these are minimal being the biggest difference **0,1 Bleu**.   

### Source code / logs
python compute_bleu.py --translation=translation.en --reference=test_data/newstest2014.de                                                          
I1212 11:03:35.484694 140343540246272 tf_logging.py:115] Case-insensitive results: 26.038009
I1212 11:03:40.145630 140343540246272 tf_logging.py:115] Case-sensitive results: 25.506699

",rodasoares,b'type:bug',2018-12-12T13:31:14Z,2020-06-21T22:42:20Z,,,,,,,
5899,Unicode error when building ADE20K dataset tf record for deeplab.,"### System information
- **What is the top-level directory of the model you are using**:deeplab
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:Ubuntu16.04
- **TensorFlow installed from (source or binary)**:pip
- **TensorFlow version (use command below)**:1.90 gpu
- **Bazel version (if compiling from source)**:None
- **CUDA/cuDNN version**:9.0,7.1
- **GPU model and memory**:TITAN,1080ti
- **Exact command to reproduce**:bash download_and_convert_ade20k.sh

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
```
>> Converting image 1/20210 shard 0Traceback (most recent call last):
  File ""./build_ade20k_data.py"", line 118, in <module>
    tf.app.run()
  File ""/home/re01/anaconda3/lib/python3.5/site-packages/tensorflow/python/platform/app.py"", line 125, in run
    _sys.exit(main(argv))
  File ""./build_ade20k_data.py"", line 113, in main
    'train', FLAGS.train_image_folder, FLAGS.train_image_label_folder)
  File ""./build_ade20k_data.py"", line 94, in _convert_dataset
    image_data = tf.gfile.FastGFile(image_filename, 'r').read()
  File ""/home/re01/anaconda3/lib/python3.5/site-packages/tensorflow/python/lib/io/file_io.py"", line 132, in read
    pywrap_tensorflow.ReadFromStream(self._read_buf, length, status))
  File ""/home/re01/anaconda3/lib/python3.5/site-packages/tensorflow/python/lib/io/file_io.py"", line 100, in _prepare_value
    return compat.as_str_any(val)
  File ""/home/re01/anaconda3/lib/python3.5/site-packages/tensorflow/python/util/compat.py"", line 107, in as_str_any
    return as_str(value)
  File ""/home/re01/anaconda3/lib/python3.5/site-packages/tensorflow/python/util/compat.py"", line 80, in as_text
    return bytes_or_text.decode(encoding)
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte

```",QuantumLiu,b'type:bug',2018-12-12T06:14:33Z,2019-03-06T13:18:06Z,,,,,,,
5898,First sequence is not a list,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",asd463644535,None,2018-12-12T02:49:37Z,2018-12-12T03:01:17Z,,,,,,,
5895,Use distutils.version.StrictVersion for version comparisons,"Now, version comparison is performed in the following way.

```python
""1.4"" <= tf_version
```

This is problematic. For example, when `tf_version` is `1.10.1`, we would expect the above statement to return `True`. However, it will return `False` since it is using string comparison.

```python
>>> import tensorflow as tf
>>> tf_version = tf.__version__
>>> print(tf_version)
1.10.1
>>> ""1.4"" <= tf_version
False
```

To fix this bug, we need to use some version comparison packages for Python. And in `object_detection_tutorial.ipynb`, `distutils.version.StrictVersion` is used. So it is also used here to be consistent.",jianchao-li,b'cla: yes',2018-12-11T10:29:42Z,2019-07-31T00:09:08Z,,,,,,,
5887,about earlystopping,"I run object detection API.
I wanna use 'early stopping' API.

Below 

    early_stopping = tf.contrib.estimator.stop_if_no_decrease_hook(
        estimator,
        metric_name='loss_1',
        max_steps_without_decrease=1
    )

    train_spec, eval_specs = model_lib.create_train_and_eval_specs(
        train_input_fn,
        early_stopping,
        eval_input_fns,
        eval_on_train_input_fn,
        predict_input_fn,
        train_steps,
        eval_on_train_data=False)

I changed metric_name to 'loss_1', 'total_loss', 'loss'.
But I can't use early stopping function.
Help me.



Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:  Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",hongym7,b'type:support',2018-12-10T09:13:42Z,2020-02-07T18:50:56Z,,,,,,,
5880,clip,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",yin-zhang,None,2018-12-07T16:22:51Z,2018-12-07T16:23:08Z,,,,,,,
5879,Save positive and negative crop samples,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/53671993/save-positive-and-negative-samples-used-in-tensorflow-object-detection-api

I use Tensorflow Object Detection API with MobilenetV2 as network backbone and SSD as meta-structure to do the object detection job.

In SSD, for each anchor point, we make several candidate bounding boxes with different aspect_ratios. For each bounding box, if its intersection with the bounding box ground-truth is greater than a threshold, we say that this bounding box is positive. Otherwise, it is negative. And then we use these positive and negative to do the training. (So it is important to note that it is NOT the entire image is used to train, but only one (or several) crops of these images are used)

To debug, I'd like to save these positive and negative crops to hard disk to see what are really samples that the algorithm uses to train.

I read the python code of Tensorflow Object Detection API but I'm lost :(

If you have any hint, please show me !

Thanks !

------------------------

### System information
- **What is the top-level directory of the model you are using**: model_main.py in folder object_detection
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: NO
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 18.04
- **TensorFlow installed from (source or binary)**: Binary
- **TensorFlow version (use command below)**: 1.10.1 (GPU)
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**: CUDA 9.0.176, cuDNN 7.2.1
- **GPU model and memory**: GeForce GTX 105, 4GRam
- **Exact command to reproduce**:
",a2bc,b'type:support',2018-12-07T15:24:34Z,2020-02-07T18:52:33Z,,,,,,,
5878,load resnet_v2_50.ckpt has error,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:ubuntu 16.04
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:1.9.0 tensorlfow-gpu
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:cuda-9.0
- **GPU model and memory**:16GB
- **Exact command to reproduce**:

### Describe the problem
when I restore the pre_trained resnet_v2_50.ckpt,it shows can not find batchnorm/beta.

### Source code / logs
ITraceback (most recent call last):
  File ""/home/swx/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1322, in _do_call
    return fn(*args)
  File ""/home/swx/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1307, in _run_fn
    options, feed_dict, fetch_list, target_list, run_metadata)
  File ""/home/swx/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1409, in _call_tf_sessionrun
    run_metadata)
tensorflow.python.framework.errors_impl.NotFoundError: Tensor name ""resnet_v2_50/resnet_v2_50/block1/unit_1/bottleneck_v2/conv1/BatchNorm/beta"" not found in checkpoint files ./resnet_v2_50.ckpt
	 [[Node: save/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, ..., DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=""/job:localhost/replica:0/task:0/device:CPU:0""](_arg_save/Const_0_0, save/RestoreV2/tensor_names, save/RestoreV2/shape_and_slices)]]
	 [[Node: save/RestoreV2/_301 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device_incarnation=1, tensor_name=""edge_306_save/RestoreV2"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:GPU:0""]()]]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/home/swx/head_detection/myssd/trans_resnet50_from_slim.py"", line 18, in <module>
    saver.restore(sess,'./resnet_v2_50.ckpt')
  File ""/home/swx/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/training/saver.py"", line 1768, in restore
    six.reraise(exception_type, exception_value, exception_traceback)
  File ""/home/swx/anaconda3/envs/tensorflow/lib/python3.6/site-packages/six.py"", line 693, in reraise
    raise value
  File ""/home/swx/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/training/saver.py"", line 1752, in restore
    {self.saver_def.filename_tensor_name: save_path})
  File ""/home/swx/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 900, in run
    run_metadata_ptr)
  File ""/home/swx/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1135, in _run
    feed_dict_tensor, options, run_metadata)
  File ""/home/swx/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1316, in _do_run
    run_metadata)
  File ""/home/swx/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1335, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.NotFoundError: Tensor name ""resnet_v2_50/resnet_v2_50/block1/unit_1/bottleneck_v2/conv1/BatchNorm/beta"" not found in checkpoint files ./resnet_v2_50.ckpt
	 [[Node: save/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, ..., DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=""/job:localhost/replica:0/task:0/device:CPU:0""](_arg_save/Const_0_0, save/RestoreV2/tensor_names, save/RestoreV2/shape_and_slices)]]
	 [[Node: save/RestoreV2/_301 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device_incarnation=1, tensor_name=""edge_306_save/RestoreV2"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:GPU:0""]()]]

Caused by op 'save/RestoreV2', defined at:
  File ""/home/swx/head_detection/myssd/trans_resnet50_from_slim.py"", line 16, in <module>
    saver  = tf.train.Saver()
  File ""/home/swx/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/training/saver.py"", line 1284, in __init__
    self.build()
  File ""/home/swx/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/training/saver.py"", line 1296, in build
    self._build(self._filename, build_save=True, build_restore=True)
  File ""/home/swx/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/training/saver.py"", line 1333, in _build
    build_save=build_save, build_restore=build_restore)
  File ""/home/swx/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/training/saver.py"", line 781, in _build_internal
    restore_sequentially, reshape)
  File ""/home/swx/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/training/saver.py"", line 400, in _AddRestoreOps
    restore_sequentially)
  File ""/home/swx/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/training/saver.py"", line 832, in bulk_restore
    return io_ops.restore_v2(filename_tensor, names, slices, dtypes)
  File ""/home/swx/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/gen_io_ops.py"", line 1463, in restore_v2
    shape_and_slices=shape_and_slices, dtypes=dtypes, name=name)
  File ""/home/swx/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py"", line 787, in _apply_op_helper
    op_def=op_def)
  File ""/home/swx/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 3414, in create_op
    op_def=op_def)
  File ""/home/swx/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 1740, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access

NotFoundError (see above for traceback): Tensor name ""resnet_v2_50/resnet_v2_50/block1/unit_1/bottleneck_v2/conv1/BatchNorm/beta"" not found in checkpoint files ./resnet_v2_50.ckpt
	 [[Node: save/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, ..., DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=""/job:localhost/replica:0/task:0/device:CPU:0""](_arg_save/Const_0_0, save/RestoreV2/tensor_names, save/RestoreV2/shape_and_slices)]]
	 [[Node: save/RestoreV2/_301 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device_incarnation=1, tensor_name=""edge_306_save/RestoreV2"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:GPU:0""]()]]

",swxhss,b'type:support',2018-12-07T04:04:55Z,2020-02-07T18:50:55Z,,,,,,,
5876,"Tensorflow-TensorRT ""Engine buffer is full""","------------------------

### System information
- **What is the top-level directory of the model you are using**: object_detection
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 18.04
- **TensorFlow installed from (source or binary)**: Binary
- **TensorFlow version (use command below)**: 1.12
- **Bazel version (if compiling from source)**: n/a
- **CUDA/cuDNN version**: 10/7
- **GPU model and memory**: Jetson Xavier 16GB shared w/ RAM
- **Exact command to reproduce**: sess.run()

### Describe the problem

I'm trying to convert the frozen weights from faster_rcnn_resnet50_coco to TensorRT and I'm getting the following error when I call session.run():

`2018-12-06 12:21:53.405304: W tensorflow/contrib/tensorrt/kernels/trt_engine_op.cc:260] Engine buffer is full. buffer limit=1, current entries=1, requested batch=100
2018-12-06 12:21:53.405458: W tensorflow/contrib/tensorrt/kernels/trt_engine_op.cc:277] Failed to get engine batch, running native segment for my_trt_op_1`

Is this a bug? If not, what is the cause of this error?

### Source code / logs

Here is a minimal example of the code:

    trt_graph = trt.create_inference_graph(
        input_graph_def=frozen_graph,
        outputs=output_names,
        max_batch_size=1,
        max_workspace_size_bytes=4000000000,
        precision_mode='FP16',
        minimum_segment_size=50
    )
    
    tf_config = tf.ConfigProto()
    tf_config.gpu_options.allow_growth = True
    tf_sess = tf.Session(config=tf_config)
    tf.import_graph_def(trt_graph, name='')\
    scores, boxes, classes, num_detections = tf_sess.run([tf_scores, tf_boxes, tf_classes, tf_num_detections], feed_dict={
        tf_input: image_resized[None, ...]
    })

I'm following [this](https://github.com/NVIDIA-AI-IOT/tf_trt_models/blob/master/examples/classification/classification.ipynb) guide in an NVIDIA repo if you want to see the complete code. Supposedly someone else got the same faster-rcnn working so it should work.",atyshka,b'stat:awaiting model gardener type:bug',2018-12-06T19:04:29Z,2020-01-29T23:00:36Z,,,,,,,
5871,SSL certificate verification failed in mnist.py,"### System information
- **What is the top-level directory of the model you are using**: `models/official/mnist`
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: no
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: macOS 10.14.1
- **TensorFlow installed from (source or binary)**: binary (with `pip`)
- **TensorFlow version (use command below)**: v1.12.0-rc2-3-ga6d8ffae09 1.12.0
- **Bazel version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: none
- **GPU model and memory**: no GPU support (on macOS)
- **Exact command to reproduce**: `python mnist.py`

### Describe the problem

I cannot download the MNIST data due to a certificate failure:
```
ssl.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:847)
```

I believe I followed the steps in the [README](https://github.com/tensorflow/models/tree/master/official/mnist). I installed [Python 3.6.7](https://www.python.org/downloads/release/python-367/), created a virtual environment, cloned this repo, added it to the PYTHONPATH, and ran `python mnist.py`.

Following [this thread on StackOverflow](https://stackoverflow.com/questions/46858630/python-ssl-certification-problems-in-tensorflow), I replaced line 70 of `models/official/mnist/dataset.py`:

```
  url = 'https://storage.googleapis.com/cvdf-datasets/mnist/' + filename + '.gz'
```

with the insecure version:
```
  url = 'http://storage.googleapis.com/cvdf-datasets/mnist/' + filename + '.gz'
```

This works, but it's a hack. I tried directing Python to a different binary of OpenSSL, such as LibreSSL, but it seems that I would have to recompile Python instead of installing from a package installer. I would think that TensorFlow would work right out of the box, so I'm not sure if this is a bug or if I am doing something wrong.

### Source code / logs

My bash script that installed the setup is:

```
# Install Python 3.6.7 manually from this page
# https://www.python.org/downloads/release/python-367/

# Then verify installation with
python3 --version
pip3 --version

# Install virtualenv for current user
export PYTHONUSERBASE=$HOME
pip3 install virtualenv

# Create and activate a new virtual environment
virtualenv --system-site-packages -p python3 ./venv
source ./venv/bin/activate

# Upgrade pip in this environment
pip3 install --upgrade pip

# Install TensorFlow (no GPU support on macOS):
pip3 install --upgrade tensorflow

# Verify that TensorFlow is working with:
python -c ""import tensorflow as tf; tf.enable_eager_execution(); print(tf.reduce_sum(tf.random_normal([1000, 1000])))""

# Use MNIST as an official model from this repo
git clone git@github.com:tensorflow/models.git
export PYTHONPATH=""$PYTHONPATH:$HOME/models""
pip3 install --user -r models/official/requirements.txt
```

The `bash` log is below in two parts, before and after the change in protocol.

Before the change:
```
(venv) $ grep -r ""https://storage.googleapis.com/cvdf-datasets/mnist"" models
Binary file models/official/mnist/__pycache__/dataset.cpython-36.pyc matches
models/official/mnist/dataset.py:  url = 'https://storage.googleapis.com/cvdf-datasets/mnist/' + filename + '.gz'
models/tutorials/image/mnist/convolutional.py:SOURCE_URL = 'https://storage.googleapis.com/cvdf-datasets/mnist/'
(venv) $ python models/official/mnist/mnist.py 
2018-12-05 12:28:17.752081: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
I1205 12:28:19.777540 4566869440 tf_logging.py:115] Initializing RunConfig with distribution strategies.
I1205 12:28:19.777722 4566869440 tf_logging.py:115] Not using Distribute Coordinator.
I1205 12:28:19.777999 4566869440 tf_logging.py:115] Using config: {'_model_dir': '/tmp/mnist_model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': <tensorflow.contrib.distribute.python.one_device_strategy.OneDeviceStrategy object at 0x12aeb72e8>, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x12aeb7358>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_distribute_coordinator_mode': None}
Downloading https://storage.googleapis.com/cvdf-datasets/mnist/train-images-idx3-ubyte.gz to /var/folders/zx/j_gjm0ld081b_mcqmg3gp9l1zp59y6/T/tmpkx13zmq0.gz
Traceback (most recent call last):
  File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py"", line 1318, in do_open
    encode_chunked=req.has_header('Transfer-encoding'))
  File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/http/client.py"", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/http/client.py"", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/http/client.py"", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/http/client.py"", line 1026, in _send_output
    self.send(msg)
  File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/http/client.py"", line 964, in send
    self.connect()
  File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/http/client.py"", line 1400, in connect
    server_hostname=server_hostname)
  File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/ssl.py"", line 407, in wrap_socket
    _context=self, _session=session)
  File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/ssl.py"", line 817, in __init__
    self.do_handshake()
  File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/ssl.py"", line 1077, in do_handshake
    self._sslobj.do_handshake()
  File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/ssl.py"", line 689, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:847)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""models/official/mnist/mnist.py"", line 236, in <module>
    absl_app.run(main)
  File ""~/venv/lib/python3.6/site-packages/absl/app.py"", line 300, in run
    _run_main(main, args)
  File ""~/venv/lib/python3.6/site-packages/absl/app.py"", line 251, in _run_main
    sys.exit(main(argv))
  File ""models/official/mnist/mnist.py"", line 230, in main
    run_mnist(flags.FLAGS)
  File ""models/official/mnist/mnist.py"", line 211, in run_mnist
    mnist_classifier.train(input_fn=train_input_fn, hooks=train_hooks)
  File ""~/venv/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py"", line 354, in train
    loss = self._train_model(input_fn, hooks, saving_listeners)
  File ""~/venv/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py"", line 1205, in _train_model
    return self._train_model_distributed(input_fn, hooks, saving_listeners)
  File ""~/venv/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py"", line 1273, in _train_model_distributed
    input_fn, model_fn_lib.ModeKeys.TRAIN, self._train_distribution)
  File ""~/venv/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py"", line 1064, in _get_iterator_from_input_fn
    lambda: self._call_input_fn(input_fn, mode))
  File ""~/venv/lib/python3.6/site-packages/tensorflow/contrib/distribute/python/one_device_strategy.py"", line 66, in distribute_dataset
    self._call_dataset_fn(dataset_fn), [self._device],
  File ""~/venv/lib/python3.6/site-packages/tensorflow/python/training/distribute.py"", line 537, in _call_dataset_fn
    result = dataset_fn()
  File ""~/venv/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py"", line 1064, in <lambda>
    lambda: self._call_input_fn(input_fn, mode))
  File ""~/venv/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py"", line 1162, in _call_input_fn
    return input_fn(**kwargs)
  File ""models/official/mnist/mnist.py"", line 192, in train_input_fn
    ds = dataset.train(flags_obj.data_dir)
  File ""~/models/official/mnist/dataset.py"", line 112, in train
    'train-labels-idx1-ubyte')
  File ""~/models/official/mnist/dataset.py"", line 84, in dataset
    images_file = download(directory, images_file)
  File ""~/models/official/mnist/dataset.py"", line 73, in download
    urllib.request.urlretrieve(url, zipped_filepath)
  File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py"", line 248, in urlretrieve
    with contextlib.closing(urlopen(url, data)) as fp:
  File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py"", line 223, in urlopen
    return opener.open(url, data, timeout)
  File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py"", line 526, in open
    response = self._open(req, data)
  File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py"", line 544, in _open
    '_open', req)
  File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py"", line 504, in _call_chain
    result = func(*args)
  File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py"", line 1361, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py"", line 1320, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:847)>
```

After the change in protocol to HTTP, as evidenced by the result of the `grep` command:
```
(venv) $ grep -r ""://storage.googleapis.com/cvdf-datasets/mnist"" models
Binary file models/official/mnist/__pycache__/dataset.cpython-36.pyc matches
models/official/mnist/dataset.py:  url = 'http://storage.googleapis.com/cvdf-datasets/mnist/' + filename + '.gz'
models/tutorials/image/mnist/convolutional.py:SOURCE_URL = 'https://storage.googleapis.com/cvdf-datasets/mnist/'
(venv) $ python models/official/mnist/mnist.py 
2018-12-05 12:28:57.989102: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
I1205 12:28:59.933488 4764476864 tf_logging.py:115] Initializing RunConfig with distribution strategies.
I1205 12:28:59.933668 4764476864 tf_logging.py:115] Not using Distribute Coordinator.
I1205 12:28:59.933948 4764476864 tf_logging.py:115] Using config: {'_model_dir': '/tmp/mnist_model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': <tensorflow.contrib.distribute.python.one_device_strategy.OneDeviceStrategy object at 0x12c5942e8>, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x12c594358>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_distribute_coordinator_mode': None}
Downloading http://storage.googleapis.com/cvdf-datasets/mnist/train-images-idx3-ubyte.gz to /var/folders/zx/j_gjm0ld081b_mcqmg3gp9l1zp59y6/T/tmp4667tagp.gz
Downloading http://storage.googleapis.com/cvdf-datasets/mnist/train-labels-idx1-ubyte.gz to /var/folders/zx/j_gjm0ld081b_mcqmg3gp9l1zp59y6/T/tmp7qxgbdwg.gz
I1205 12:29:01.782899 4764476864 tf_logging.py:115] Calling model_fn.
I1205 12:29:02.112184 4764476864 tf_logging.py:115] Done calling model_fn.
I1205 12:29:02.141009 4764476864 tf_logging.py:115] Create CheckpointSaverHook.
I1205 12:29:02.263503 4764476864 tf_logging.py:115] Graph was finalized.
I1205 12:29:02.439916 4764476864 tf_logging.py:115] Running local_init_op.
I1205 12:29:02.446758 4764476864 tf_logging.py:115] Done running local_init_op.
I1205 12:29:02.677207 4764476864 tf_logging.py:115] Saving checkpoints for 0 into /tmp/mnist_model/model.ckpt.
I1205 12:29:05.109802 4764476864 tf_logging.py:115] cross_entropy = 2.3048978, learning_rate = 1e-04, train_accuracy = 0.05
I1205 12:29:05.109989 4764476864 tf_logging.py:115] loss = 2.3048978, step = 0
I1205 12:29:14.766379 4764476864 tf_logging.py:115] global_step/sec: 10.3554
I1205 12:29:14.766859 4764476864 tf_logging.py:115] cross_entropy = 0.3506276, learning_rate = 1e-04, train_accuracy = 0.48 (9.657 sec)
I1205 12:29:14.766991 4764476864 tf_logging.py:115] loss = 0.3506276, step = 100 (9.657 sec)
I1205 12:29:24.416563 4764476864 tf_logging.py:115] global_step/sec: 10.3625
I1205 12:29:24.417036 4764476864 tf_logging.py:115] cross_entropy = 0.111308776, learning_rate = 1e-04, train_accuracy = 0.65 (9.650 sec)
I1205 12:29:24.417161 4764476864 tf_logging.py:115] loss = 0.111308776, step = 200 (9.650 sec)
I1205 12:29:33.866394 4764476864 tf_logging.py:115] global_step/sec: 10.5822
I1205 12:29:33.866874 4764476864 tf_logging.py:115] cross_entropy = 0.22374004, learning_rate = 1e-04, train_accuracy = 0.725 (9.450 sec)
I1205 12:29:33.867074 4764476864 tf_logging.py:115] loss = 0.22374004, step = 300 (9.450 sec)
I1205 12:29:43.441606 4764476864 tf_logging.py:115] global_step/sec: 10.4436
I1205 12:29:43.442087 4764476864 tf_logging.py:115] cross_entropy = 0.14755917, learning_rate = 1e-04, train_accuracy = 0.772 (9.575 sec)
I1205 12:29:43.442266 4764476864 tf_logging.py:115] loss = 0.14755917, step = 400 (9.575 sec)
I1205 12:29:53.074919 4764476864 tf_logging.py:115] global_step/sec: 10.3806
I1205 12:29:53.075423 4764476864 tf_logging.py:115] cross_entropy = 0.14501753, learning_rate = 1e-04, train_accuracy = 0.8 (9.633 sec)
I1205 12:29:53.075557 4764476864 tf_logging.py:115] loss = 0.14501753, step = 500 (9.633 sec)
I1205 12:30:02.875329 4764476864 tf_logging.py:115] Saving checkpoints for 600 into /tmp/mnist_model/model.ckpt.
I1205 12:30:03.097067 4764476864 tf_logging.py:115] Finalize system.
I1205 12:30:03.207376 4764476864 tf_logging.py:115] Loss for final step: 0.13695708.
Downloading http://storage.googleapis.com/cvdf-datasets/mnist/t10k-images-idx3-ubyte.gz to /var/folders/zx/j_gjm0ld081b_mcqmg3gp9l1zp59y6/T/tmp8h4voiac.gz
Downloading http://storage.googleapis.com/cvdf-datasets/mnist/t10k-labels-idx1-ubyte.gz to /var/folders/zx/j_gjm0ld081b_mcqmg3gp9l1zp59y6/T/tmpo0jnubw3.gz
I1205 12:30:04.159009 4764476864 tf_logging.py:115] Calling model_fn.
I1205 12:30:04.264031 4764476864 tf_logging.py:115] Done calling model_fn.
I1205 12:30:04.278503 4764476864 tf_logging.py:115] Starting evaluation at 2018-12-05-12:30:04
I1205 12:30:04.333271 4764476864 tf_logging.py:115] Graph was finalized.
I1205 12:30:04.334044 4764476864 tf_logging.py:115] Restoring parameters from /tmp/mnist_model/model.ckpt-600
I1205 12:30:04.367141 4764476864 tf_logging.py:115] Running local_init_op.
I1205 12:30:04.374906 4764476864 tf_logging.py:115] Done running local_init_op.
I1205 12:30:08.018642 4764476864 tf_logging.py:115] Finished evaluation at 2018-12-05-12:30:08
I1205 12:30:08.018784 4764476864 tf_logging.py:115] Saving dict for global step 600: accuracy = 0.9681, global_step = 600, loss = 0.1036345
I1205 12:30:08.061439 4764476864 tf_logging.py:115] Saving 'checkpoint_path' summary for global step 600: /tmp/mnist_model/model.ckpt-600

Evaluation results:
	{'accuracy': 0.9681, 'loss': 0.1036345, 'global_step': 600}

...
```",miguelmorin,None,2018-12-05T15:55:25Z,2018-12-13T10:54:51Z,,,,,,,
5869,from google3.pyglib import logging,"lstm_object_detection 

error:

  File ""/root/Desktop/models/research/lstm_object_detection/trainer.py"", line 24, in <module>
    from google3.pyglib import logging
ModuleNotFoundError: No module named 'google3'

run:

models/research/lstm_object_detection#     python train.py \
>         --logtostderr \
>         --train_dir=/root/Desktop/models/research/lstm_object_detection/configs \
>         --pipeline_config_path=/root/Desktop/models/research/lstm_object_detection/configs/lstm_ssd_mobilenet_v1_imagenet.config

",zyxcambridge,b'type:bug',2018-12-05T13:59:55Z,2019-07-23T02:35:56Z,,,,,,,
5856,Object Detection use_bfloat16 error.,"### System information
- **What is the top-level directory of the model you are using**: object_detection
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: Installed with pip
- **TensorFlow version (use command below)**: 1.12
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**: 9.0 / 7.1
- **GPU model and memory**: 1080ti 
- **Exact command to reproduce**: Standard training job with use_bfloat16=true in pipeline.config

### Describe the problem
I am attempting to train and object detection model using bfloat16 ops.
When setting ""use_bfloat16"" to ""true"" from protos/train.proto with Faster RCNN meta, I am getting the following exception:

**_TypeError: Value passed to parameter 'image' has DataType bfloat16 not in list of allowed values: uint8, uint16, int8, int16, int32, int64, float16, float32, float64_**

After some quick debugging, this is coming from when tf.image.crop_and_resize is called, which does not support bfloat16 images. 

### Source code / logs
_TypeError: Value passed to parameter 'image' has DataType bfloat16 not in list of allowed values: uint8, uint16, int8, int16, int32, int64, float16, float32, float64_

**in file:**

tensorflow-env-1.12-python3/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py"", line 60, in _SatisfiesTypeConstraint
",louisquinn,None,2018-12-04T03:50:22Z,2020-01-29T23:00:25Z,,,,,,,
5845,The replica ps 0 exited with a non-zero status of 1. Termination reason: Error. The replica ps 1 exited with a non-zero status of 1. Termination reason: Error. The replica ps 2 exited with a non-zero status of 1. Termination reason: Error. ,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**: Object Detection- fasterRCNN
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: no
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Mac OS
- **TensorFlow installed from (source or binary)**: official website
- **TensorFlow version (use command below)**: 1.11.0 (This is the version on my PC, but I wanted to train on Google Cloud)
- **Bazel version (if compiling from source)**: 
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:
gcloud ml-engine jobs submit training `whoami`_waterpolo_`date +%m_%d_%Y_%H_%M_%S` \
    --job-dir=gs://waterpolo_datax \
    --packages dist/object_detection-0.1.tar.gz,slim/dist/slim-0.1.tar.gz \
    --module-name object_detection.train \
    --config object_detection/samples/cloud/cloud.yml \
    -- \
    --pipeline_config_path=gs://waterpolo_datax/pipeline.config

**- **Source code:** 
import functools
import json
import os
import tensorflow as tf

from google.protobuf import text_format

from object_detection.legacy import trainer
from object_detection.builders import input_reader_builder
from object_detection.builders import model_builder
from object_detection.protos import input_reader_pb2
from object_detection.protos import model_pb2
from object_detection.protos import pipeline_pb2
from object_detection.protos import train_pb2

tf.logging.set_verbosity(tf.logging.INFO)

flags = tf.app.flags
flags.DEFINE_string('master', '', 'BNS name of the TensorFlow master to use.')
flags.DEFINE_integer('task', 0, 'task id')
flags.DEFINE_integer('num_clones', 1, 'Number of clones to deploy per worker.')
flags.DEFINE_boolean('clone_on_cpu', False,
                     'Force clones to be deployed on CPU.  Note that even if '
                     'set to False (allowing ops to run on gpu), some ops may '
                     'still be run on the CPU if they have no GPU kernel.')
flags.DEFINE_integer('worker_replicas', 1, 'Number of worker+trainer '
                     'replicas.')
flags.DEFINE_integer('ps_tasks', 0,
                     'Number of parameter server tasks. If None, does not use '
                     'a parameter server.')
flags.DEFINE_string('train_dir', '',
                    'Directory to save the checkpoints and training summaries.')

flags.DEFINE_string('pipeline_config_path', '',
                    'Path to a pipeline_pb2.TrainEvalPipelineConfig config '
                    'file. If provided, other configs are ignored')

flags.DEFINE_string('train_config_path', '',
                    'Path to a train_pb2.TrainConfig config file.')
flags.DEFINE_string('input_config_path', '',
                    'Path to an input_reader_pb2.InputReader config file.')
flags.DEFINE_string('model_config_path', '',
                    'Path to a model_pb2.DetectionModel config file.')

FLAGS = flags.FLAGS


def get_configs_from_pipeline_file():
  """"""Reads training configuration from a pipeline_pb2.TrainEvalPipelineConfig.

  Reads training config from file specified by pipeline_config_path flag.

  Returns:
    model_config: model_pb2.DetectionModel
    train_config: train_pb2.TrainConfig
    input_config: input_reader_pb2.InputReader
  """"""
  pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()
  with tf.gfile.GFile(FLAGS.pipeline_config_path, 'r') as f:
    text_format.Merge(f.read(), pipeline_config)

  model_config = pipeline_config.model
  train_config = pipeline_config.train_config
  input_config = pipeline_config.train_input_reader

  return model_config, train_config, input_config


def get_configs_from_multiple_files():
  """"""Reads training configuration from multiple config files.

  Reads the training config from the following files:
    model_config: Read from --model_config_path
    train_config: Read from --train_config_path
    input_config: Read from --input_config_path

  Returns:
    model_config: model_pb2.DetectionModel
    train_config: train_pb2.TrainConfig
    input_config: input_reader_pb2.InputReader
  """"""
  train_config = train_pb2.TrainConfig()
  with tf.gfile.GFile(FLAGS.train_config_path, 'r') as f:
    text_format.Merge(f.read(), train_config)

  model_config = model_pb2.DetectionModel()
  with tf.gfile.GFile(FLAGS.model_config_path, 'r') as f:
    text_format.Merge(f.read(), model_config)

  input_config = input_reader_pb2.InputReader()
  with tf.gfile.GFile(FLAGS.input_config_path, 'r') as f:
    text_format.Merge(f.read(), input_config)

  return model_config, train_config, input_config


def main(_):
  assert FLAGS.train_dir, '`train_dir` is missing.'
  if FLAGS.pipeline_config_path:
    model_config, train_config, input_config = get_configs_from_pipeline_file()
  else:
    model_config, train_config, input_config = get_configs_from_multiple_files()

  model_fn = functools.partial(
      model_builder.build,
      model_config=model_config,
      is_training=True)

  create_input_dict_fn = functools.partial(
      input_reader_builder.build, input_config)

  env = json.loads(os.environ.get('TF_CONFIG', '{}'))
  cluster_data = env.get('cluster', None)
  cluster = tf.train.ClusterSpec(cluster_data) if cluster_data else None
  task_data = env.get('task', None) or {'type': 'master', 'index': 0}
  task_info = type('TaskSpec', (object,), task_data)
  
  # Parameters for a single worker.
  ps_tasks = 0
  worker_replicas = 1
  worker_job_name = 'lonely_worker'
  task = 0
  is_chief = True
  master = ''

  if cluster_data and 'worker' in cluster_data:
    # Number of total worker replicas include ""worker""s and the ""master"".
    worker_replicas = len(cluster_data['worker']) + 1
  if cluster_data and 'ps' in cluster_data:
    ps_tasks = len(cluster_data['ps'])

  if worker_replicas > 1 and ps_tasks < 1:
    raise ValueError('At least 1 ps task is needed for distributed training.')

  if worker_replicas >= 1 and ps_tasks > 0:
    # Set up distributed training.
    server = tf.train.Server(tf.train.ClusterSpec(cluster), protocol='grpc',
                             job_name=task_info.type,
                             task_index=task_info.index)
    if task_info.type == 'ps':
      server.join()
      return

    worker_job_name = '%s/task:%d' % (task_info.type, task_info.index)
    task = task_info.index
    is_chief = (task_info.type == 'master')
    master = server.target

  trainer.train(create_input_dict_fn, model_fn, train_config, master, task,
                FLAGS.num_clones, worker_replicas, FLAGS.clone_on_cpu, ps_tasks,
                worker_job_name, is_chief, FLAGS.train_dir)


if __name__ == '__main__':
  tf.app.run()

",christyChenYa,None,2018-11-30T20:28:08Z,2020-02-07T18:50:54Z,,,,,,,
5841,word2vec: AttributeError: 'module' object has no attribute 'get_compile_flags',"I think it's a bug, please delete if not.
I try to start the following model word2vec example from the repository:

https://github.com/tensorflow/models/tree/master/tutorials/embedding

The data preparation works:

```
curl http://mattmahoney.net/dc/text8.zip > text8.zip
unzip text8.zip
curl https://storage.googleapis.com/google-code-archive-source/v2/code.google.com/word2vec/source-archive.zip > source-archive.zip
unzip -p source-archive.zip  word2vec/trunk/questions-words.txt > questions-words.txt
rm text8.zip source-archive.zip
```

But the attempt to add the custom tensorflow operation fails like described in the following:

```
TF_CFLAGS=( $(python -c 'import tensorflow as tf; print("" "".join(tf.sysconfig.get_compile_flags()))') )
```

Results in:

```
Traceback (most recent call last):
  File ""<string>"", line 1, in <module>
AttributeError: 'module' object has no attribute 'get_compile_flags'
```

The newest tensorflow version (```v1.12.0```) is installed via pip:

```
pip install --upgrade tensorflow
```

The python version is ```v2.7.15```.
",tech509201941,b'stat:awaiting response',2018-11-30T12:08:27Z,2020-02-07T18:52:19Z,,,,,,,
5840,How to change the config after downloading?,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",kakacharles10,None,2018-11-30T12:05:55Z,2018-11-30T22:13:19Z,,,,,,,
5834,error on compiling object_detection_tutorial,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",ElizaNami,None,2018-11-29T06:31:51Z,2020-02-07T18:50:54Z,,,,,,,
5827,fix a bug in rnn\ptb model that deals with '\n' incorrectly,"In line:33 and line:35, if `'\n'` is replaced by '<eof>', the the `<eof>` will be concatenated with the word before it and after it.
**for example:**
>I would like\n
>Do you?

After processed in this initial code, it would become `like<eof>Do`
And this token makes no sense.

So I modify it to ' <eof> ' with two space before and after it.
Then after being splited, the example mentioned above would be 
> I would like \<eof\> Do you",egg-west,b'cla: yes',2018-11-28T12:46:46Z,2020-04-24T07:06:49Z,,,,,,,
5810,model_main.py does not save checkpoint?,"### System information
- **What is the top-level directory of the model you are using**:
https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Windows 10 64 bit
- **TensorFlow installed from (source or binary)**:
pip installed

- **TensorFlow version (use command below)**:
1.12
- **Bazel version (if compiling from source)**:

- **CUDA/cuDNN version**:
CUDA 9.0
- **GPU model and memory**:
GTX 1060 6 Gb

- **Exact command to reproduce**:
python E:\\Documents\\Projects\\tensorflow\\models\\research\\object_detection\\model_main.py --alsologtostderr  --pipeline_config_path=experiments/training/ssdlite_mobilenet_v2_coco.config --model_dir=/experiments/training/ --num_train_steps=50000 --NUM_EVAL_STEPS=2000 

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

model_main doesn't save training checkpoints, I see the status (see below) but I dont see any checkpoints being saved during training, what's going on?

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.

I see this but its not saving any checkpoint to this directory

tensorflow:Saving 'checkpoint_path' summary for global step 40469: /experiments/training/model.ckpt-40469
I1125 05:27:49.819430  7500 tf_logging.py:115] Saving 'checkpoint_path' summary for global step 40469: /experiments/training/model.ckpt-40469
",zubairahmed-ai,None,2018-11-25T00:30:25Z,2020-03-28T21:41:01Z,,,,,,,
5807,TFLite have not support standard NMS in TFLite_Detection_PostProcess,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:NO
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:Darwin Kernel Version 17.7.0
- **TensorFlow installed from (source or binary)**:source
- **TensorFlow version (use command below)**:v1.12.0-rc2
- **Bazel version (if compiling from source)**:0.18.1
- **CUDA/cuDNN version**:
- **GPU model and memory**:mobilenet-ssd
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

The TFLite_Detection_PostProcess Operation is not support standard NMS（Non Maximal Suppression）, it use the fast NMS by default.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.

TfLiteStatus NonMaxSuppressionMultiClass(TfLiteContext* context,
                                         TfLiteNode* node, OpData* op_data) {

  …………
  NonMaxSuppressionMultiClassFastHelper(context, node, op_data,
                                        GetTensorData<float>(scores));
  return kTfLiteOk;
}

// This function implements a fast version of Non Maximal Suppression for
// multiple classes where
// 1) we keep the top-k scores for each anchor and
// 2) during NMS, each anchor only uses the highest class score for sorting.
// 3) Compared to standard NMS, the worst runtime of this version is O(N^2)
// instead of O(KN^2) where N is the number of anchors and K the number of
// classes.
TfLiteStatus NonMaxSuppressionMultiClassFastHelper(TfLiteContext* context,
                                                   TfLiteNode* node,
                                                   OpData* op_data,
                                                   const float* scores){……}
",dinghuanghao,b'comp:lite models:research stat:awaiting response type:support',2018-11-23T08:29:47Z,2019-07-08T17:52:59Z,,,,,,,
5806," Assign requires shapes of both tensors to match. lhs shape= [1,1,256,256] rhs shape= [1,1,1280,256]          [[Node: save/Assign_348 = Assign[T=DT_FLOAT, _class=[""loc:@FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/weights""], use_locking=true, validate_shape=true, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/weights, save/RestoreV2:348)]]","------------------------

### System information
- **What is the top-level directory of the model you are using**:
https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Windows 10 64 bit
- **TensorFlow installed from (source or binary)**:
pip installed

- **TensorFlow version (use command below)**:
1.9.0
- **Bazel version (if compiling from source)**:

- **CUDA/cuDNN version**:
CUDA 9.0
- **GPU model and memory**:
GTX 1060 6 Gb
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:
Train model_main.py gives following error

**InvalidArgumentError (see above for traceback): Assign requires shapes of both tensors to match. lhs shape= [1,1,256,256] rhs shape= [1,1,1280,256]
         [[Node: save/Assign_348 = Assign[T=DT_FLOAT, _class=[""loc:@FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/weights""], use_locking=true, validate_shape=true, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/weights, save/RestoreV2:348)]]
         [[Node: save/RestoreV2/_599 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device_incarnation=1, tensor_name=""edge_728_save/RestoreV2"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:GPU:0""]()]]**


### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

When using **model_main.py** under objectdetection I get the following error

InvalidArgumentError (see above for traceback): Assign requires shapes of both tensors to match. lhs shape= [1,1,256,256] rhs shape= [1,1,1280,256]
         [[Node: save/Assign_348 = Assign[T=DT_FLOAT, _class=[""loc:@FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/weights""], use_locking=true, validate_shape=true, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/weights, save/RestoreV2:348)]]
         [[Node: save/RestoreV2/_599 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device_incarnation=1, tensor_name=""edge_728_save/RestoreV2"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:GPU:0""]()]]

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.


python E:\\Documents\\Projects\\tensorflow\\models\\research\\object_detection\\model_main.py --alsologtostderr  --pipeline_config_path=experiments/training_/ssdlite_mobilenet_v2_coco.config --model_dir=experiments/training_/ --num_train_steps=50000 --NUM_EVAL_STEPS=2000
WARNING:tensorflow:Forced number of epochs for all eval validations to be 1.
W1123 09:11:18.686478  7432 tf_logging.py:125] Forced number of epochs for all eval validations to be 1.
WARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.
W1123 09:11:18.687448  7432 tf_logging.py:125] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.
WARNING:tensorflow:Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x000001E641D31268>) includes params argument, but params are not passed to Estimator.
W1123 09:11:18.688472  7432 tf_logging.py:125] Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x000001E641D31268>) includes params argument, but params are not passed to Estimator.
2018-11-23 09:11:23.084879: I T:\src\github\tensorflow\tensorflow\core\platform\cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2
2018-11-23 09:11:23.365711: I T:\src\github\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:1392] Found device 0 with properties:
name: GeForce GTX 1060 6GB major: 6 minor: 1 memoryClockRate(GHz): 1.835
pciBusID: 0000:01:00.0
totalMemory: 6.00GiB freeMemory: 4.97GiB
2018-11-23 09:11:23.372771: I T:\src\github\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:1471] Adding visible gpu devices: 0
2018-11-23 09:11:24.001841: I T:\src\github\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-11-23 09:11:24.004967: I T:\src\github\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:958]      0
2018-11-23 09:11:24.007058: I T:\src\github\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:971] 0:   N
2018-11-23 09:11:24.009175: I T:\src\github\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 4741 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1060 6GB, pci bus id: 0000:01:00.0, compute capability: 6.1)
Traceback (most recent call last):
  File ""D:\ProgramData\Anaconda3\envs\tfod\lib\site-packages\tensorflow\python\client\session.py"", line 1322, in _do_call
    return fn(*args)
  File ""D:\ProgramData\Anaconda3\envs\tfod\lib\site-packages\tensorflow\python\client\session.py"", line 1307, in _run_fn
    options, feed_dict, fetch_list, target_list, run_metadata)
  File ""D:\ProgramData\Anaconda3\envs\tfod\lib\site-packages\tensorflow\python\client\session.py"", line 1409, in _call_tf_sessionrun
    run_metadata)
tensorflow.python.framework.errors_impl.InvalidArgumentError: Assign requires shapes of both tensors to match. lhs shape= [1,1,256,256] rhs shape= [1,1,1280,256]
         [[Node: save/Assign_348 = Assign[T=DT_FLOAT, _class=[""loc:@FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/weights""], use_locking=true, validate_shape=true, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/weights, save/RestoreV2:348)]]
         [[Node: save/RestoreV2/_599 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device_incarnation=1, tensor_name=""edge_728_save/RestoreV2"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:GPU:0""]()]]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""E:\\Documents\\Projects\\tensorflow\\models\\research\\object_detection\\model_main.py"", line 109, in <module>
    tf.app.run()
  File ""D:\ProgramData\Anaconda3\envs\tfod\lib\site-packages\tensorflow\python\platform\app.py"", line 125, in run
    _sys.exit(main(argv))
  File ""E:\\Documents\\Projects\\tensorflow\\models\\research\\object_detection\\model_main.py"", line 105, in main
    tf.estimator.train_and_evaluate(estimator, train_spec, eval_specs[0])
  File ""D:\ProgramData\Anaconda3\envs\tfod\lib\site-packages\tensorflow\python\estimator\training.py"", line 447, in train_and_evaluate
    return executor.run()
  File ""D:\ProgramData\Anaconda3\envs\tfod\lib\site-packages\tensorflow\python\estimator\training.py"", line 531, in run
    return self.run_local()
  File ""D:\ProgramData\Anaconda3\envs\tfod\lib\site-packages\tensorflow\python\estimator\training.py"", line 681, in run_local
    eval_result, export_results = evaluator.evaluate_and_export()
  File ""D:\ProgramData\Anaconda3\envs\tfod\lib\site-packages\tensorflow\python\estimator\training.py"", line 886, in evaluate_and_export
    hooks=self._eval_spec.hooks)
  File ""D:\ProgramData\Anaconda3\envs\tfod\lib\site-packages\tensorflow\python\estimator\estimator.py"", line 460, in evaluate
    output_dir=self.eval_dir(name))
  File ""D:\ProgramData\Anaconda3\envs\tfod\lib\site-packages\tensorflow\python\estimator\estimator.py"", line 1386, in _evaluate_run
    config=self._session_config)
  File ""D:\ProgramData\Anaconda3\envs\tfod\lib\site-packages\tensorflow\python\training\evaluation.py"", line 209, in _evaluate_once
    session_creator=session_creator, hooks=hooks) as session:
  File ""D:\ProgramData\Anaconda3\envs\tfod\lib\site-packages\tensorflow\python\training\monitored_session.py"", line 826, in __init__
    stop_grace_period_secs=stop_grace_period_secs)
  File ""D:\ProgramData\Anaconda3\envs\tfod\lib\site-packages\tensorflow\python\training\monitored_session.py"", line 549, in __init__
    self._sess = _RecoverableSession(self._coordinated_creator)
  File ""D:\ProgramData\Anaconda3\envs\tfod\lib\site-packages\tensorflow\python\training\monitored_session.py"", line 1012, in __init__
    _WrappedSession.__init__(self, self._create_session())
  File ""D:\ProgramData\Anaconda3\envs\tfod\lib\site-packages\tensorflow\python\training\monitored_session.py"", line 1017, in _create_session
    return self._sess_creator.create_session()
  File ""D:\ProgramData\Anaconda3\envs\tfod\lib\site-packages\tensorflow\python\training\monitored_session.py"", line 706, in create_session
    self.tf_sess = self._session_creator.create_session()
  File ""D:\ProgramData\Anaconda3\envs\tfod\lib\site-packages\tensorflow\python\training\monitored_session.py"", line 477, in create_session
    init_fn=self._scaffold.init_fn)
  File ""D:\ProgramData\Anaconda3\envs\tfod\lib\site-packages\tensorflow\python\training\session_manager.py"", line 281, in prepare_session
    config=config)
  File ""D:\ProgramData\Anaconda3\envs\tfod\lib\site-packages\tensorflow\python\training\session_manager.py"", line 195, in _restore_checkpoint
    saver.restore(sess, checkpoint_filename_with_path)
  File ""D:\ProgramData\Anaconda3\envs\tfod\lib\site-packages\tensorflow\python\training\saver.py"", line 1752, in restore
    {self.saver_def.filename_tensor_name: save_path})
  File ""D:\ProgramData\Anaconda3\envs\tfod\lib\site-packages\tensorflow\python\client\session.py"", line 900, in run
    run_metadata_ptr)
  File ""D:\ProgramData\Anaconda3\envs\tfod\lib\site-packages\tensorflow\python\client\session.py"", line 1135, in _run
    feed_dict_tensor, options, run_metadata)
  File ""D:\ProgramData\Anaconda3\envs\tfod\lib\site-packages\tensorflow\python\client\session.py"", line 1316, in _do_run
    run_metadata)
  File ""D:\ProgramData\Anaconda3\envs\tfod\lib\site-packages\tensorflow\python\client\session.py"", line 1335, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.InvalidArgumentError: Assign requires shapes of both tensors to match. lhs shape= [1,1,256,256] rhs shape= [1,1,1280,256]
         [[Node: save/Assign_348 = Assign[T=DT_FLOAT, _class=[""loc:@FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/weights""], use_locking=true, validate_shape=true, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/weights, save/RestoreV2:348)]]
         [[Node: save/RestoreV2/_599 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device_incarnation=1, tensor_name=""edge_728_save/RestoreV2"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:GPU:0""]()]]

Caused by op 'save/Assign_348', defined at:
  File ""E:\\Documents\\Projects\\tensorflow\\models\\research\\object_detection\\model_main.py"", line 109, in <module>
    tf.app.run()
  File ""D:\ProgramData\Anaconda3\envs\tfod\lib\site-packages\tensorflow\python\platform\app.py"", line 125, in run
    _sys.exit(main(argv))
  File ""E:\\Documents\\Projects\\tensorflow\\models\\research\\object_detection\\model_main.py"", line 105, in main
    tf.estimator.train_and_evaluate(estimator, train_spec, eval_specs[0])
  File ""D:\ProgramData\Anaconda3\envs\tfod\lib\site-packages\tensorflow\python\estimator\training.py"", line 447, in train_and_evaluate
    return executor.run()
  File ""D:\ProgramData\Anaconda3\envs\tfod\lib\site-packages\tensorflow\python\estimator\training.py"", line 531, in run
    return self.run_local()
  File ""D:\ProgramData\Anaconda3\envs\tfod\lib\site-packages\tensorflow\python\estimator\training.py"", line 681, in run_local
    eval_result, export_results = evaluator.evaluate_and_export()
  File ""D:\ProgramData\Anaconda3\envs\tfod\lib\site-packages\tensorflow\python\estimator\training.py"", line 886, in evaluate_and_export
    hooks=self._eval_spec.hooks)
  File ""D:\ProgramData\Anaconda3\envs\tfod\lib\site-packages\tensorflow\python\estimator\estimator.py"", line 460, in evaluate
    output_dir=self.eval_dir(name))
  File ""D:\ProgramData\Anaconda3\envs\tfod\lib\site-packages\tensorflow\python\estimator\estimator.py"", line 1386, in _evaluate_run
    config=self._session_config)
  File ""D:\ProgramData\Anaconda3\envs\tfod\lib\site-packages\tensorflow\python\training\evaluation.py"", line 209, in _evaluate_once
    session_creator=session_creator, hooks=hooks) as session:
  File ""D:\ProgramData\Anaconda3\envs\tfod\lib\site-packages\tensorflow\python\training\monitored_session.py"", line 826, in __init__
    stop_grace_period_secs=stop_grace_period_secs)
  File ""D:\ProgramData\Anaconda3\envs\tfod\lib\site-packages\tensorflow\python\training\monitored_session.py"", line 549, in __init__
    self._sess = _RecoverableSession(self._coordinated_creator)
  File ""D:\ProgramData\Anaconda3\envs\tfod\lib\site-packages\tensorflow\python\training\monitored_session.py"", line 1012, in __init__
    _WrappedSession.__init__(self, self._create_session())
  File ""D:\ProgramData\Anaconda3\envs\tfod\lib\site-packages\tensorflow\python\training\monitored_session.py"", line 1017, in _create_session
    return self._sess_creator.create_session()
  File ""D:\ProgramData\Anaconda3\envs\tfod\lib\site-packages\tensorflow\python\training\monitored_session.py"", line 706, in create_session
    self.tf_sess = self._session_creator.create_session()
  File ""D:\ProgramData\Anaconda3\envs\tfod\lib\site-packages\tensorflow\python\training\monitored_session.py"", line 468, in create_session
    self._scaffold.finalize()
  File ""D:\ProgramData\Anaconda3\envs\tfod\lib\site-packages\tensorflow\python\training\monitored_session.py"", line 212, in finalize
    self._saver = training_saver._get_saver_or_default()  # pylint: disable=protected-access
  File ""D:\ProgramData\Anaconda3\envs\tfod\lib\site-packages\tensorflow\python\training\saver.py"", line 856, in _get_saver_or_default
    saver = Saver(sharded=True, allow_empty=True)
  File ""D:\ProgramData\Anaconda3\envs\tfod\lib\site-packages\tensorflow\python\training\saver.py"", line 1284, in __init__
    self.build()
  File ""D:\ProgramData\Anaconda3\envs\tfod\lib\site-packages\tensorflow\python\training\saver.py"", line 1296, in build
    self._build(self._filename, build_save=True, build_restore=True)
  File ""D:\ProgramData\Anaconda3\envs\tfod\lib\site-packages\tensorflow\python\training\saver.py"", line 1333, in _build
    build_save=build_save, build_restore=build_restore)
  File ""D:\ProgramData\Anaconda3\envs\tfod\lib\site-packages\tensorflow\python\training\saver.py"", line 775, in _build_internal
    restore_sequentially, reshape)
  File ""D:\ProgramData\Anaconda3\envs\tfod\lib\site-packages\tensorflow\python\training\saver.py"", line 453, in _AddShardedRestoreOps
    name=""restore_shard""))
  File ""D:\ProgramData\Anaconda3\envs\tfod\lib\site-packages\tensorflow\python\training\saver.py"", line 422, in _AddRestoreOps
    assign_ops.append(saveable.restore(saveable_tensors, shapes))
  File ""D:\ProgramData\Anaconda3\envs\tfod\lib\site-packages\tensorflow\python\training\saver.py"", line 113, in restore
    self.op.get_shape().is_fully_defined())
  File ""D:\ProgramData\Anaconda3\envs\tfod\lib\site-packages\tensorflow\python\ops\state_ops.py"", line 219, in assign
    validate_shape=validate_shape)
  File ""D:\ProgramData\Anaconda3\envs\tfod\lib\site-packages\tensorflow\python\ops\gen_state_ops.py"", line 63, in assign
    use_locking=use_locking, name=name)
  File ""D:\ProgramData\Anaconda3\envs\tfod\lib\site-packages\tensorflow\python\framework\op_def_library.py"", line 787, in _apply_op_helper
    op_def=op_def)
  File ""D:\ProgramData\Anaconda3\envs\tfod\lib\site-packages\tensorflow\python\framework\ops.py"", line 3414, in create_op
    op_def=op_def)
  File ""D:\ProgramData\Anaconda3\envs\tfod\lib\site-packages\tensorflow\python\framework\ops.py"", line 1740, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access

InvalidArgumentError (see above for traceback): Assign requires shapes of both tensors to match. lhs shape= [1,1,256,256] rhs shape= [1,1,1280,256]
         [[Node: save/Assign_348 = Assign[T=DT_FLOAT, _class=[""loc:@FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/weights""], use_locking=true, validate_shape=true, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/weights, save/RestoreV2:348)]]
         [[Node: save/RestoreV2/_599 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device_incarnation=1, tensor_name=""edge_728_save/RestoreV2"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:GPU:0""]()]]",zubairahmed-ai,None,2018-11-23T04:18:24Z,2020-09-01T08:57:09Z,,,,,,,
5803,Tensorflow API Object Detection train.py crashes after INFO:tensorflow:Starting Queues.,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:tensorflow1
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:na
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:windows 10
- **TensorFlow installed from (source or binary)**:na
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:na
- **CUDA/cuDNN version**:9 and cudnn 9
- **GPU model and memory**:gtx 1050 4G
- **Exact command to reproduce**:python train.py --logtostderr --train_dir=training/ --pipeline_config_path=training/faster_rcnn_inception_v2_pets.config

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""1.12

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.
I run the above command and get the following output

(tensorflow1) C:\Tensorflow1\models\research\object_detection>python train.py --logtostderr --train_dir=training/ --pipeline_config_path=training/faster_rcnn_inception_v2_pets.config
INFO:tensorflow:Scale of 0 disables regularizer.
INFO:tensorflow:Scale of 0 disables regularizer.
WARNING:tensorflow:From C:\Users\Andreas Shepley\Anaconda3\envs\tensorflow1\lib\site-packages\object_detection-0.1-py3.5.egg\object_detection\trainer.py:228: create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Please switch to tf.train.create_global_step
WARNING:tensorflow:From C:\Users\Andreas Shepley\Anaconda3\envs\tensorflow1\lib\site-packages\object_detection-0.1-py3.5.egg\object_detection\utils\dataset_util.py:130: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.experimental.parallel_interleave(...)`.
WARNING:tensorflow:From C:\Users\Andreas Shepley\Anaconda3\envs\tensorflow1\lib\site-packages\tensorflow\python\ops\sparse_ops.py:1165: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.
WARNING:tensorflow:From C:\Users\Andreas Shepley\Anaconda3\envs\tensorflow1\lib\site-packages\object_detection-0.1-py3.5.egg\object_detection\core\preprocessor.py:2962: calling squeeze (from tensorflow.python.ops.array_ops) with squeeze_dims is deprecated and will be removed in a future version.
Instructions for updating:
Use the `axis` argument instead
WARNING:tensorflow:From C:\Users\Andreas Shepley\Anaconda3\envs\tensorflow1\lib\site-packages\object_detection-0.1-py3.5.egg\object_detection\core\batcher.py:96: batch (from tensorflow.python.training.input) is deprecated and will be removed in a future version.
Instructions for updating:
Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.batch(batch_size)` (or `padded_batch(...)` if `dynamic_pad=True`).
WARNING:tensorflow:From C:\Users\Andreas Shepley\Anaconda3\envs\tensorflow1\lib\site-packages\tensorflow\python\training\input.py:751: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.
Instructions for updating:
To construct input pipelines, use the `tf.data` module.
WARNING:tensorflow:From C:\Users\Andreas Shepley\Anaconda3\envs\tensorflow1\lib\site-packages\tensorflow\python\training\input.py:751: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.
Instructions for updating:
To construct input pipelines, use the `tf.data` module.
INFO:tensorflow:Scale of 0 disables regularizer.
INFO:tensorflow:Scale of 0 disables regularizer.
INFO:tensorflow:depth of additional conv before box predictor: 0
WARNING:tensorflow:From C:\Users\Andreas Shepley\Anaconda3\envs\tensorflow1\lib\site-packages\object_detection-0.1-py3.5.egg\object_detection\core\box_predictor.py:391: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.
Instructions for updating:
keep_dims is deprecated, use keepdims instead
WARNING:tensorflow:From C:\Users\Andreas Shepley\Anaconda3\envs\tensorflow1\lib\site-packages\object_detection-0.1-py3.5.egg\object_detection\core\losses.py:306: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.
Instructions for updating:

Future major versions of TensorFlow will allow gradients to flow
into the labels input on backprop by default.

See `tf.nn.softmax_cross_entropy_with_logits_v2`.

WARNING:tensorflow:From C:\Users\Andreas Shepley\Anaconda3\envs\tensorflow1\lib\site-packages\object_detection-0.1-py3.5.egg\object_detection\meta_architectures\faster_rcnn_meta_arch.py:1952: get_or_create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Please switch to tf.train.get_or_create_global_step
INFO:tensorflow:Summary name /clone_loss is illegal; using clone_loss instead.
C:\Users\Andreas Shepley\Anaconda3\envs\tensorflow1\lib\site-packages\tensorflow\python\ops\gradients_impl.py:112: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  ""Converting sparse IndexedSlices to a dense Tensor of unknown shape. ""
WARNING:tensorflow:From C:\Users\Andreas Shepley\Anaconda3\envs\tensorflow1\lib\site-packages\tensorflow\contrib\slim\python\slim\learning.py:737: Supervisor.__init__ (from tensorflow.python.training.supervisor) is deprecated and will be removed in a future version.
Instructions for updating:
Please switch to tf.train.MonitoredTrainingSession
2018-11-22 17:35:40.639199: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2
2018-11-22 17:35:42.000975: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties:
name: GeForce GTX 1050 major: 6 minor: 1 memoryClockRate(GHz): 1.493
pciBusID: 0000:01:00.0
totalMemory: 4.00GiB freeMemory: 3.30GiB
2018-11-22 17:35:42.065095: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2018-11-22 17:35:45.385849: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-11-22 17:35:45.412676: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0
2018-11-22 17:35:45.437288: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N
2018-11-22 17:35:45.455739: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 3020 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050, pci bus id: 0000:01:00.0, compute capability: 6.1)
INFO:tensorflow:Restoring parameters from C:/tensorflow1/models/research/object_detection/faster_rcnn_inception_v2_coco_2018_01_28/model.ckpt
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Starting Session.
INFO:tensorflow:Saving checkpoint to path training/model.ckpt
INFO:tensorflow:Starting Queues.

The program does not go any further? It stops at this point.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",traderandreas,None,2018-11-22T08:28:21Z,2020-02-07T18:50:53Z,,,,,,,
5798,Images are not getting added in tf.event files,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
models/research/object_detection
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
TPU
- **TensorFlow installed from (source or binary)**:
binary
- **TensorFlow version (use command below)**:
1.9
- **Bazel version (if compiling from source)**:
NA
- **CUDA/cuDNN version**:
NA (Cloud ML engine TPU)
- **GPU model and memory**:
TPU basic tier
- **Exact command to reproduce**:
Training: 
```gcloud ml-engine jobs submit training $JOB_NAME_`date +%m_%d_%Y_%H_%M_%S` --job-dir=${MODEL_DIR} --packages dist/object_detection-0.1.tar.gz,slim/dist/slim-0.1.tar.gz,/tmp/pycocotools/pycocotools-2.0.tar.gz --module-name object_detection.model_tpu_main --runtime-version 1.9 --scale-tier BASIC_TPU --region us-central1 -- \ --tpu_zone us-central1 --model_dir=${MODEL_DIR} --pipeline_config_path=${PIPELINE_CONFIG_PATH}```
Evaluation: 
```gcloud ml-engine jobs submit training $JOB_NAME_eval_`date +%m_%d_%Y_%H_%M_%S` --runtime-version 1.9 --job-dir=${MODEL_DIR}    --packages dist/object_detection-0.1.tar.gz,slim/dist/slim-0.1.tar.gz,/tmp/pycocotools/pycocotools-2.0.tar.gz --module-name object_detection.model_main --region us-central1 --scale-tier BASIC_GPU -- \ --model_dir=${MODEL_DIR} --pipeline_config_path=${PIPELINE_CONFIG_PATH} --checkpoint_dir=${MODEL_DIR}```

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.
**Images are not getting added to event files and because of this the tensorboard shows no information apart from loss and learning rate.** 

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
![image](https://user-images.githubusercontent.com/36867201/48858825-3e78ed80-ed71-11e8-926e-f9eda3744879.png)
",kulkarnivishal,None,2018-11-21T17:40:00Z,2020-02-07T18:50:53Z,,,,,,,
5795,    from nets import inception_resnet_v2 ModuleNotFoundError: No module named 'nets',"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",Luoice,None,2018-11-21T07:17:33Z,2020-02-07T18:50:53Z,,,,,,,
5794,"Why i use graph_rewrite training model such slowly,5s per step?","Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:ssdlite_mobilenet_v2_coco_2018_05_09/model.ckpt
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:Linux Ubuntu 16.04.5
- **TensorFlow installed from (source or binary)**:binary
- **TensorFlow version (use command below)**:1.12.0
- **Bazel version (if compiling from source)**:0.19.1
- **CUDA/cuDNN version**:9.0
- **GPU model and memory**:three 1080 ti 11G
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
 And excessive memory usage but i only use batch_size 48 


### Source code / logs
2018-11-21 14:44:21.759806: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:03:00.0
totalMemory: 10.91GiB freeMemory: 10.35GiB
2018-11-21 14:44:21.961547: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 1 with properties: 
name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:04:00.0
totalMemory: 10.91GiB freeMemory: 10.75GiB
2018-11-21 14:44:21.963074: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0, 1

INFO:tensorflow:global step 234: loss = 2.1614 (5.394 sec/step)
I1121 15:11:57.188936 140018120492800 tf_logging.py:115] global step 234: loss = 2.1614 (5.394 sec/step)
INFO:tensorflow:global step 235: loss = 2.0140 (5.465 sec/step)
I1121 15:12:02.656718 140018120492800 tf_logging.py:115] global step 235: loss = 2.0140 (5.465 sec/step)
INFO:tensorflow:global step 236: loss = 1.9067 (5.226 sec/step)
I1121 15:12:07.885817 140018120492800 tf_logging.py:115] global step 236: loss = 1.9067 (5.226 sec/step)
INFO:tensorflow:global step 237: loss = 2.5041 (5.481 sec/step)
I1121 15:12:13.369063 140018120492800 tf_logging.py:115] global step 237: loss = 2.5041 (5.481 sec/step)
INFO:tensorflow:global step 238: loss = 1.9676 (5.412 sec/step)
I1121 15:12:18.783356 140018120492800 tf_logging.py:115] global step 238: loss = 1.9676 (5.412 sec/step)
INFO:tensorflow:global step 239: loss = 2.2165 (5.401 sec/step)
I1121 15:12:24.187036 140018120492800 tf_logging.py:115] global step 239: loss = 2.2165 (5.401 sec/step)
INFO:tensorflow:global step 240: loss = 2.3579 (5.381 sec/step)
I1121 15:12:29.570735 140018120492800 tf_logging.py:115] global step 240: loss = 2.3579 (5.381 sec/step)

model {
  ssd {
    num_classes: 7
    image_resizer {
      fixed_shape_resizer {
        height: 300
        width: 300
      }
    }
    feature_extractor {
      type: ""ssd_mobilenet_v2""
      depth_multiplier: 1.0
      min_depth: 16
      conv_hyperparams {
        regularizer {
          l2_regularizer {
            weight: 3.99999989895e-05
          }
        }
        initializer {
          random_normal_initializer {
            mean: 0.0
            stddev: 0.00999999977648
          }
        }
        activation: RELU_6
        batch_norm {
          decay: 0.9997
          center: true
          scale: true
          epsilon: 0.0010000000475
        }
      }
      override_base_feature_extractor_hyperparams: true
    }
    box_coder {
      faster_rcnn_box_coder {
        y_scale: 10.0
        x_scale: 10.0
        height_scale: 5.0
        width_scale: 5.0
      }
    }
    matcher {
      argmax_matcher {
        matched_threshold: 0.5
        unmatched_threshold: 0.5
        ignore_thresholds: false
        negatives_lower_than_unmatched: true
        force_match_for_each_row: true
        use_matmul_gather: true
      }
    }
    similarity_calculator {
      iou_similarity {
      }
    }
    box_predictor {
      convolutional_box_predictor {
        conv_hyperparams {
          regularizer {
            l2_regularizer {
              weight: 3.99999989895e-05
            }
          }
          initializer {
            truncated_normal_initializer {
              mean: 0.0
              stddev: 0.03
            }
          }
          activation: RELU_6
          batch_norm {
            decay: 0.9997
            center: true
            scale: true
            epsilon: 0.0010000000475
          }
        }
        min_depth: 0
        max_depth: 0
        num_layers_before_predictor: 0
        use_dropout: false
        dropout_keep_probability: 0.800000011921
        kernel_size: 3
	use_depthwise:true
        box_code_size: 4
        apply_sigmoid_to_scores: false
        class_prediction_bias_init: 0.0
	class_prediction_bias_init: -4.59999990463
      }
    }
    anchor_generator {
      ssd_anchor_generator {
        num_layers: 6
        min_scale: 0.20000000298
        max_scale: 0.949999988079
        aspect_ratios: 2.0
        aspect_ratios: 1.5
        aspect_ratios: 0.8
        aspect_ratios: 1.82
        aspect_ratios: 1.0
      }
    }
    post_processing {
      batch_non_max_suppression {
        score_threshold: 0.3
        iou_threshold: 0.600000023842
        max_detections_per_class: 100
        max_total_detections: 100
      }
      score_converter: SIGMOID
    }
    normalize_loss_by_num_matches: true
    loss {
      localization_loss {
        weighted_smooth_l1 {
        }
      }
      classification_loss {
        weighted_sigmoid {
        }
      }
      hard_example_miner {
        num_hard_examples: 1000
        iou_threshold: 0.99
        loss_type: CLASSIFICATION
        max_negatives_per_positive: 3
        min_negatives_per_image: 3
      }
      classification_weight: 1.0
      localization_weight: 1.0
    }
    encode_background_as_zeros: true
    normalize_loc_loss_by_codesize: false
  }
}
train_config {
  batch_size: 48
  data_augmentation_options {
    random_horizontal_flip {
    }
  }
  data_augmentation_options {
    ssd_random_crop {
    }
  }
  sync_replicas: false
  optimizer {
    rms_prop_optimizer: {
      learning_rate: {
        exponential_decay_learning_rate {
          initial_learning_rate: 0.0035
          decay_steps: 800456
          decay_factor: 0.95
        }
      }
      momentum_optimizer_value: 0.9
      decay: 0.9
      epsilon: 1.0
    }
    use_moving_average: true
  }
  #fine_tune_checkpoint: ""/media/ubuntu/data1/models/research/object_detection/ssdlite_mobilenet_v2_coco_2018_05_09/model.ckpt""
  fine_tune_checkpoint: ""/media/ubuntu/data1/models/research/object_detection/mymodel/model/train/model.ckpt-69744""
  #fine_tune_checkpoint: ""/media/ubuntu/data1/models/research/object_detection/ssd_mobilenet_v2_quantized_300x300_coco_2018_09_14/model.ckpt""
  fine_tune_checkpoint_type: ""detection""
  num_steps: 69744
  #startup_delay_steps: 0.0
  #replicas_to_aggregate: 8
  max_number_of_boxes: 50
  unpad_groundtruth_tensors: false
  summarize_gradients:false
}
train_input_reader {
  label_map_path: ""../mymodel/label_map.pbtxt""
  tf_record_input_reader {
    input_path: ""../mymodel/data/train.record""
  }
}
eval_config {
  num_examples: 655
  metrics_set: ""coco_detection_metrics""
  use_moving_averages: true
  num_visualizations:30
  batch_size:10
}

eval_input_reader {
  label_map_path: ""../mymodel/data/label_map.pbtxt""
  shuffle: true
  num_readers: 1
  tf_record_input_reader {
    input_path: ""../mymodel/data/valid.record""
  }
}

graph_rewriter {
  quantization {
    delay: 0
    weight_bits: 8
    activation_bits: 8
  }
}",S601327412,None,2018-11-21T07:14:02Z,2019-06-27T06:58:55Z,,,,,,,
5790," Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x000001FC1818AD08>) includes params argument, but params are not passed to Estimator.","Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",Luoice,None,2018-11-21T01:32:51Z,2019-08-04T19:35:43Z,,,,,,,
5785,"google.protobuf.text_format.ParseError: 174:3 : Message type ""object_detection.protos.InputReader"" has no field named ""td_record_input_reader"".","Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**: tensorflow object detection api 
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: no
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Mac OS high Sierra
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: 1.18 (in python 3.6)
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:
PIPELINE_CONFIG_PATH=/Users/spencerkraisler/Desktop/raccoon/models/model/ssd_mobilenet_v2_coco.config
MODEL_DIR=/Users/spencerkraisler/Desktop/raccoon/models/model
NUM_TRAIN_STEPS=1000
SAMPLE_1_OF_N_EVAL_EXAMPLES=1
python3 object_detection/model_main.py \
    --pipeline_config_path=${PIPELINE_CONFIG_PATH} \
    --model_dir=${MODEL_DIR} \
    --num_train_steps=${NUM_TRAIN_STEPS} \
    --sample_1_of_n_eval_examples=$SAMPLE_1_OF_N_EVAL_EXAMPLES \
    --alsologtostderrs

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
PIPELINE_CONFIG_PATH=/Users/spencerkraisler/Desktop/raccoon/models/model/ssd_mobilenet_v2_coco.config
MODEL_DIR=/Users/spencerkraisler/Desktop/raccoon/models/model
NUM_TRAIN_STEPS=1000
SAMPLE_1_OF_N_EVAL_EXAMPLES=1
python3 object_detection/model_main.py \
    --pipeline_config_path=${PIPELINE_CONFIG_PATH} \
    --model_dir=${MODEL_DIR} \
    --num_train_steps=${NUM_TRAIN_STEPS} \
    --sample_1_of_n_eval_examples=$SAMPLE_1_OF_N_EVAL_EXAMPLES \
    --alsologtostderrs

This produces error when I run model_main.py 

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.",spencerkraisler,None,2018-11-20T01:41:00Z,2020-02-12T04:29:25Z,,,,,,,
5780,Google Cloud ML score_threshold error,"- **What is the top-level directory of the model you are using**:  /opt/models/research
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: NO
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Debian Google Cloud instance
- **TensorFlow installed from (source or binary)**: Followed pip install 
- **TensorFlow version (use command below)**: 1.10
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**: Google Cloud ML
- **Exact command to reproduce**: Started Training as per instruction specifying the google storage buckets

You can collect some of this information using our environment capture script:

worker-replica-4
Traceback (most recent call last): File ""/usr/lib/python2.7/runpy.py"", line 174, in _run_module_as_main ""__main__"", fname, loader, pkg_name) File ""/usr/lib/python2.7/runpy.py"", line 72, in _run_code exec code in run_globals File ""/root/.local/lib/python2.7/site-packages/object_detection/model_main.py"", line 109, in <module> tf.app.run() File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 126, in run _sys.exit(main(argv)) File ""/root/.local/lib/python2.7/site-packages/object_detection/model_main.py"", line 105, in main tf.estimator.train_and_evaluate(estimator, train_spec, eval_specs[0]) File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/training.py"", line 439, in train_and_evaluate executor.run() File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/training.py"", line 546, in run getattr(self, task_to_run)() File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/training.py"", line 556, in run_worker return self._start_distributed_training() File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/training.py"", line 739, in _start_distributed_training saving_listeners=saving_listeners) File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py"", line 363, in train loss = self._train_model(input_fn, hooks, saving_listeners) File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py"", line 843, in _train_model return self._train_model_default(input_fn, hooks, saving_listeners) File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py"", line 856, in _train_model_default features, labels, model_fn_lib.ModeKeys.TRAIN, self.config) File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py"", line 831, in _call_model_fn model_fn_results = self._model_fn(features=features, **kwargs) File ""/root/.local/lib/python2.7/site-packages/object_detection/model_lib.py"", line 269, in model_fn features[fields.InputDataFields.true_image_shape]) File ""/root/.local/lib/python2.7/site-packages/object_detection/meta_architectures/faster_rcnn_meta_arch.py"", line 688, in predict self._anchors.get(), image_shape, true_image_shapes)) File ""/root/.local/lib/python2.7/site-packages/object_detection/meta_architectures/faster_rcnn_meta_arch.py"", line 775, in _predict_second_stage anchors, image_shape_2d, true_image_shapes) File ""/root/.local/lib/python2.7/site-packages/object_detection/meta_architectures/faster_rcnn_meta_arch.py"", line 1285, in _postprocess_rpn clip_window=clip_window) File ""/root/.local/lib/python2.7/site-packages/object_detection/core/post_processing.py"", line 478, in batch_multiclass_non_max_suppression parallel_iterations=parallel_iterations) File ""/root/.local/lib/python2.7/site-packages/object_detection/utils/shape_utils.py"", line 228, in static_or_dynamic_map_fn return tf.map_fn(fn, elems, dtype, parallel_iterations, back_prop) File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/functional_ops.py"", line 423, in map_fn swap_memory=swap_memory) File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py"", line 3224, in while_loop result = loop_context.BuildLoop(cond, body, loop_vars, shape_invariants) File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py"", line 2956, in BuildLoop pred, body, original_loop_vars, loop_vars, shape_invariants) File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py"", line 2893, in _BuildLoop body_result = body(*packed_vars_for_body) File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/functional_ops.py"", line 413, in compute packed_fn_values = fn(packed_values) File ""/root/.local/lib/python2.7/site-packages/object_detection/core/post_processing.py"", line 452, in _single_image_nms_fn additional_fields=per_image_additional_fields) File ""/root/.local/lib/python2.7/site-packages/object_detection/core/post_processing.py"", line 170, in multiclass_non_max_suppression score_threshold=score_thresh) TypeError: non_max_suppression() got an unexpected keyword argument 'score_threshold'

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

Google Cloud ML 

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

Possibly a fix required to complete the training on tensorflow",rampizen,None,2018-11-19T15:16:15Z,2018-11-19T15:21:07Z,,,,,,,
5779,score_threshold error,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",rampizen,None,2018-11-19T15:07:27Z,2018-11-19T15:19:44Z,,,,,,,
5773,ModuleNotFoundError: No module named 'object_detection' mac,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",vidit2011998,None,2018-11-18T04:45:30Z,2018-12-02T18:01:09Z,,,,,,,
5769,"Mask R-CNN with Inception Resnet v2, Atrous version; ValueError(""Shapes %s and %s are incompatible"" % (self, other))","Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:models/research/
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 18.04
- **TensorFlow installed from (source or binary)**: Source
- **TensorFlow version (use command below)**: 1.11.0
- **Bazel version (if compiling from source)**: /
- **CUDA/cuDNN version**: 
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2017 NVIDIA Corporation
Built on Fri_Nov__3_21:07:56_CDT_2017
Cuda compilation tools, release 9.1, V9.1.85
- **GPU model and memory**:
GeForce GTX 1080 (12gb)
Memory:
                    total        used        free      shared  buff/cache   available
Mem:          32084        2966       24809          96        4307       28565
Swap:          2047        1850         197


- **Exact command to reproduce**:
python object_detection/model_main.py --pipeline_config_path=object_detection/models/scratches/mask_rcnn_inception_resnet_v2_atrous_coco.config --model_dir=object_detection/models/scratches/train/ --num_train_steps=1000000 --sample_1_of_n_eval_examples=100 --alsologtostderr



### Describe the problem
When using the ""Mask R-CNN with Inception Resnet v2, Atrous version"" config on a custom dataset (not a pretrained model) the training runs well for 10 minutes, but at the evaluation step the process stops with the following error:
File ""/home/dietermaes/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py"", line 1190, in boolean_mask
    shape_tensor[axis:axis + ndims_mask].assert_is_compatible_with(shape_mask)
  File ""/home/dietermaes/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/framework/tensor_shape.py"", line 848, in assert_is_compatible_with
    raise ValueError(""Shapes %s and %s are incompatible"" % (self, other))
ValueError: Shapes (100, 91) and (300, 91) are incompatible

**the complete error trace is shown in the logs below the source code**

Dataset: 1000 training images with mask provided (possible multiple per image), 100 evaluation images also with masks provided.

I have used exactly the same dataset to train & eval on a ""Mask R-CNN with Inception V2"" config, this works fine (already trained for 175k steps & evaluated tons of times). But I would like to train the same data on the inception_resnet_v2 model to see if there is difference in accuracy.

I have also tried running the legacy train.py with the Inception Resnet v2, this works fine, but when I try the legacy eval.py on the trained data it gives me the same error.




### Source code 
# Mask R-CNN with Inception Resnet v2, Atrous version

model {
  faster_rcnn {
    num_classes: 90
    image_resizer {
      keep_aspect_ratio_resizer {
        min_dimension: 800
        max_dimension: 1365
      }
    }
    number_of_stages: 3
    feature_extractor {
      type: 'faster_rcnn_inception_resnet_v2'
      first_stage_features_stride: 8
    }
    first_stage_anchor_generator {
      grid_anchor_generator {
        scales: [0.25, 0.5, 1.0, 2.0]
        aspect_ratios: [0.5, 1.0, 2.0]
        height_stride: 8
        width_stride: 8
      }
    }
    first_stage_atrous_rate: 2
    first_stage_box_predictor_conv_hyperparams {
      op: CONV
      regularizer {
        l2_regularizer {
          weight: 0.0
        }
      }
      initializer {
        truncated_normal_initializer {
          stddev: 0.01
        }
      }
    }
    first_stage_nms_score_threshold: 0.0
    first_stage_nms_iou_threshold: 0.7
    first_stage_max_proposals: 300
    first_stage_localization_loss_weight: 2.0
    first_stage_objectness_loss_weight: 1.0
    initial_crop_size: 17
    maxpool_kernel_size: 1
    maxpool_stride: 1
    second_stage_box_predictor {
      mask_rcnn_box_predictor {
        use_dropout: false
        dropout_keep_probability: 1.0
        predict_instance_masks: true
        mask_height: 33
        mask_width: 33
        mask_prediction_conv_depth: 0
        mask_prediction_num_conv_layers: 4
        fc_hyperparams {
          op: FC
          regularizer {
            l2_regularizer {
              weight: 0.0
            }
          }
          initializer {
            variance_scaling_initializer {
              factor: 1.0
              uniform: true
              mode: FAN_AVG
            }
          }
        }
        conv_hyperparams {
          op: CONV
          regularizer {
            l2_regularizer {
              weight: 0.0
            }
          }
          initializer {
            truncated_normal_initializer {
              stddev: 0.01
            }
          }
        }
      }
    }
    second_stage_post_processing {
      batch_non_max_suppression {
        score_threshold: 0.0
        iou_threshold: 0.6
        max_detections_per_class: 100
        max_total_detections: 100
      }
      score_converter: SOFTMAX
    }
    second_stage_localization_loss_weight: 2.0
    second_stage_classification_loss_weight: 1.0
    second_stage_mask_prediction_loss_weight: 4.0
  }
}

train_config: {
  batch_size: 1
  optimizer {
    momentum_optimizer: {
      learning_rate: {
        manual_step_learning_rate {
          initial_learning_rate: 0.003
          schedule {
            step: 50000
            learning_rate: .0003
          }
          schedule {
            step: 100000
            learning_rate: .00003
          }
          schedule {
            step: 150000
            learning_rate: .000003
          }
        }
      }
      momentum_optimizer_value: 0.9
    }
    use_moving_average: false
  }
  gradient_clipping_by_norm: 10.0
  ##fine_tune_checkpoint: ""object_detection/models/scratches/train/model.ckpt-44.index""
  from_detection_checkpoint: true

  num_steps: 1000000
  data_augmentation_options {
    random_horizontal_flip {
    }
  }
}

train_input_reader: {
  tf_record_input_reader {
    input_path: ""object_detection/data/scratchestrain.record""
  }
  label_map_path: ""object_detection/data/label_map.pbtxt""
  load_instance_masks: true
  mask_type: PNG_MASKS
}

eval_config: {
  num_examples:100
  ##max_evals: 10
}

eval_input_reader: {
  tf_record_input_reader {
    input_path: ""object_detection/data/scratcheseval.record""
  }
  label_map_path: ""object_detection/data/label_map.pbtxt""
  load_instance_masks: true
  mask_type: PNG_MASKS
  shuffle: false
  num_readers: 1
}



### Logs
(tf) dietermaes@PCSooi:~/Documents/Tensorflowv2/models/research$ python object_detection/model_main.py --pipeline_config_path=object_detection/models/scratches/mask_rcnn_inception_resnet_v2_atrous_coco.config --model_dir=object_detection/models/scratches/train/ --num_train_steps=1000000 --sample_1_of_n_eval_examples=100 --alsologtostderr
/home/dietermaes/Documents/Tensorflowv2/models/research/object_detection/utils/visualization_utils.py:27: UserWarning: matplotlib.pyplot as already been imported, this call will have no effect.
  import matplotlib; matplotlib.use('Agg')  # pylint: disable=multiple-statements
WARNING:tensorflow:Forced number of epochs for all eval validations to be 1.
W1117 12:44:48.994960 140311471769408 tf_logging.py:125] Forced number of epochs for all eval validations to be 1.
WARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.
W1117 12:44:48.995174 140311471769408 tf_logging.py:125] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.
WARNING:tensorflow:Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7f9c27b96e18>) includes params argument, but params are not passed to Estimator.
W1117 12:44:48.995556 140311471769408 tf_logging.py:125] Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7f9c27b96e18>) includes params argument, but params are not passed to Estimator.
WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.
W1117 12:44:49.015062 140311471769408 tf_logging.py:125] num_readers has been reduced to 1 to match input file shards.
WARNING:tensorflow:From /home/dietermaes/Documents/Tensorflowv2/models/research/object_detection/builders/dataset_builder.py:148: batch_and_drop_remainder (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.batch(..., drop_remainder=True)`.
W1117 12:44:49.702305 140311471769408 tf_logging.py:125] From /home/dietermaes/Documents/Tensorflowv2/models/research/object_detection/builders/dataset_builder.py:148: batch_and_drop_remainder (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.batch(..., drop_remainder=True)`.
WARNING:tensorflow:From /home/dietermaes/Documents/Tensorflowv2/models/research/object_detection/predictors/heads/box_head.py:93: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.
Instructions for updating:
keep_dims is deprecated, use keepdims instead
W1117 12:44:58.801386 140311471769408 tf_logging.py:125] From /home/dietermaes/Documents/Tensorflowv2/models/research/object_detection/predictors/heads/box_head.py:93: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.
Instructions for updating:
keep_dims is deprecated, use keepdims instead
WARNING:tensorflow:From /home/dietermaes/Documents/Tensorflowv2/models/research/object_detection/core/losses.py:345: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.
Instructions for updating:

Future major versions of TensorFlow will allow gradients to flow
into the labels input on backprop by default.

See `tf.nn.softmax_cross_entropy_with_logits_v2`.

W1117 12:44:59.133028 140311471769408 tf_logging.py:125] From /home/dietermaes/Documents/Tensorflowv2/models/research/object_detection/core/losses.py:345: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.
Instructions for updating:

Future major versions of TensorFlow will allow gradients to flow
into the labels input on backprop by default.

See `tf.nn.softmax_cross_entropy_with_logits_v2`.

/home/dietermaes/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  ""Converting sparse IndexedSlices to a dense Tensor of unknown shape. ""
2018-11-17 12:45:12.597581: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
Traceback (most recent call last):
  File ""object_detection/model_main.py"", line 109, in <module>
    tf.app.run()
  File ""/home/dietermaes/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/platform/app.py"", line 125, in run
    _sys.exit(main(argv))
  File ""object_detection/model_main.py"", line 105, in main
    tf.estimator.train_and_evaluate(estimator, train_spec, eval_specs[0])
  File ""/home/dietermaes/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/estimator/training.py"", line 471, in train_and_evaluate
    return executor.run()
  File ""/home/dietermaes/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/estimator/training.py"", line 610, in run
    return self.run_local()
  File ""/home/dietermaes/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/estimator/training.py"", line 711, in run_local
    saving_listeners=saving_listeners)
  File ""/home/dietermaes/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py"", line 356, in train
    loss = self._train_model(input_fn, hooks, saving_listeners)
  File ""/home/dietermaes/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py"", line 1181, in _train_model
    return self._train_model_default(input_fn, hooks, saving_listeners)
  File ""/home/dietermaes/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py"", line 1215, in _train_model_default
    saving_listeners)
  File ""/home/dietermaes/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py"", line 1409, in _train_with_estimator_spec
    _, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])
  File ""/home/dietermaes/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py"", line 671, in run
    run_metadata=run_metadata)
  File ""/home/dietermaes/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py"", line 1148, in run
    run_metadata=run_metadata)
  File ""/home/dietermaes/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py"", line 1239, in run
    raise six.reraise(*original_exc_info)
  File ""/home/dietermaes/anaconda3/envs/tf/lib/python3.6/site-packages/six.py"", line 693, in reraise
    raise value
  File ""/home/dietermaes/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py"", line 1224, in run
    return self._sess.run(*args, **kwargs)
  File ""/home/dietermaes/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py"", line 1304, in run
    run_metadata=run_metadata))
  File ""/home/dietermaes/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/training/basic_session_run_hooks.py"", line 581, in after_run
    if self._save(run_context.session, global_step):
  File ""/home/dietermaes/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/training/basic_session_run_hooks.py"", line 606, in _save
    if l.after_save(session, step):
  File ""/home/dietermaes/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/estimator/training.py"", line 517, in after_save
    self._evaluate(global_step_value)  # updates self.eval_result
  File ""/home/dietermaes/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/estimator/training.py"", line 537, in _evaluate
    self._evaluator.evaluate_and_export())
  File ""/home/dietermaes/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/estimator/training.py"", line 912, in evaluate_and_export
    hooks=self._eval_spec.hooks)
  File ""/home/dietermaes/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py"", line 476, in evaluate
    return _evaluate()
  File ""/home/dietermaes/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py"", line 462, in _evaluate
    self._evaluate_build_graph(input_fn, hooks, checkpoint_path))
  File ""/home/dietermaes/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py"", line 1422, in _evaluate_build_graph
    self._call_model_fn_eval(input_fn, self.config))
  File ""/home/dietermaes/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py"", line 1458, in _call_model_fn_eval
    features, labels, model_fn_lib.ModeKeys.EVAL, config)
  File ""/home/dietermaes/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py"", line 1169, in _call_model_fn
    model_fn_results = self._model_fn(features=features, **kwargs)
  File ""/home/dietermaes/Documents/Tensorflowv2/models/research/object_detection/model_lib.py"", line 307, in model_fn
    prediction_dict, features[fields.InputDataFields.true_image_shape])
  File ""/home/dietermaes/Documents/Tensorflowv2/models/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py"", line 1710, in loss
    groundtruth_masks_list,
  File ""/home/dietermaes/Documents/Tensorflowv2/models/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py"", line 1983, in _loss_box_classifier
    tf.greater(one_hot_flat_cls_targets_with_background, 0))
  File ""/home/dietermaes/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py"", line 1190, in boolean_mask
    shape_tensor[axis:axis + ndims_mask].assert_is_compatible_with(shape_mask)
  File ""/home/dietermaes/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/framework/tensor_shape.py"", line 848, in assert_is_compatible_with
    raise ValueError(""Shapes %s and %s are incompatible"" % (self, other))
ValueError: Shapes (100, 91) and (300, 91) are incompatible

I'm looking for solutions but have not found them on stackoverflow/here.

I am guessing that during the training images & masks are resized, but that this doesn't happen on the eval data which results in an incompatible shape? 
Please let me know if you also have encountered this issue + how can it be solved.

Thanks in advance,
Dieter Maes",MaesIT,None,2018-11-17T12:07:41Z,2020-01-29T22:59:19Z,,,,,,,
5765,where is autoencoder model code?,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",hellozjj,None,2018-11-16T10:52:02Z,2018-11-16T10:53:27Z,,,,,,,
5764,  import matplotlib; matplotlib.use('Agg')  # pylint: disable=multiple-statements WARNING:tensorflow:Forced number of epochs for all eval validations to be 1.,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",zbyuan,None,2018-11-16T08:24:46Z,2020-02-07T18:49:46Z,,,,,,,
5763,  import matplotlib; matplotlib.use('Agg')  # pylint: disable=multiple-statements WARNING:tensorflow:Forced number of epochs for all eval validations to be 1.,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",zbyuan,None,2018-11-16T08:23:01Z,2018-12-03T21:20:45Z,,,,,,,
5758,Python stalls (infinite bouncing rocket) when I try to use model_main.py ,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: High Sierra Mac os 
- **TensorFlow installed from (source or binary)**: source 
- **TensorFlow version (use command below)**: 1.12
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:using CPU
- **Exact command to reproduce**:
PIPELINE_CONFIG_PATH=/Users/kraisler/Desktop/raccoon_tutorial/models/model/ssd_mobilenet_v1_pets.config
MODEL_DIR=/Users/kraisler/Desktop/raccoon_tutorial/models/model
NUM_TRAIN_STEPS=50000
SAMPLE_1_OF_N_EVAL_EXAMPLES=1
python object_detection/model_main.py \
    --pipeline_config_path=${PIPELINE_CONFIG_PATH} \
    --model_dir=${MODEL_DIR} \
    --num_train_steps=${NUM_TRAIN_STEPS} \
    --sample_1_of_n_eval_examples=$SAMPLE_1_OF_N_EVAL_EXAMPLES \
    --alsologtostderr

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
I am following this tutorial: https://towardsdatascience.com/how-to-train-your-own-object-detector-with-tensorflows-object-detector-api-bec72ecfe1d9
I try to run model_main.py to train a model but it just prints this out and stalls. I've trained other models before, but not SSD's like mobile net (the one I'm using).
It stays like this forever. 

note: this works whether I use python 3.6 or python 2.7. 

### Source code / logs
OUGL-2-NW-C04-M:research kraisler$ PIPELINE_CONFIG_PATH=/Users/kraisler/Desktop/raccoon_tutorial/models/model/ssd_mobilenet_v1_pets.config
OUGL-2-NW-C04-M:research kraisler$ MODEL_DIR=/Users/kraisler/Desktop/raccoon_tutorial/models/model
OUGL-2-NW-C04-M:research kraisler$ NUM_TRAIN_STEPS=50000
OUGL-2-NW-C04-M:research kraisler$ SAMPLE_1_OF_N_EVAL_EXAMPLES=1
OUGL-2-NW-C04-M:research kraisler$ python object_detection/model_main.py \
>     --pipeline_config_path=${PIPELINE_CONFIG_PATH} \
>     --model_dir=${MODEL_DIR} \
>     --num_train_steps=${NUM_TRAIN_STEPS} \
>     --sample_1_of_n_eval_examples=$SAMPLE_1_OF_N_EVAL_EXAMPLES \
>     --alsologtostderr
/Users/kraisler/models/research/object_detection/utils/visualization_utils.py:27: UserWarning: 
This call to matplotlib.use() has no effect because the backend has already
been chosen; matplotlib.use() must be called *before* pylab, matplotlib.pyplot,
or matplotlib.backends is imported for the first time.

The backend was *originally* set to 'MacOSX' by the following code:
  File ""object_detection/model_main.py"", line 26, in <module>
    from object_detection import model_lib
  File ""/Users/kraisler/models/research/object_detection/model_lib.py"", line 27, in <module>
    from object_detection import eval_util
  File ""/Users/kraisler/models/research/object_detection/eval_util.py"", line 27, in <module>
    from object_detection.metrics import coco_evaluation
  File ""/Users/kraisler/models/research/object_detection/metrics/coco_evaluation.py"", line 20, in <module>
    from object_detection.metrics import coco_tools
  File ""/Users/kraisler/models/research/object_detection/metrics/coco_tools.py"", line 47, in <module>
    from pycocotools import coco
  File ""/usr/local/lib/python2.7/site-packages/pycocotools/coco.py"", line 49, in <module>
    import matplotlib.pyplot as plt
  File ""/usr/local/lib/python2.7/site-packages/matplotlib/pyplot.py"", line 71, in <module>
    from matplotlib.backends import pylab_setup
  File ""/usr/local/lib/python2.7/site-packages/matplotlib/backends/__init__.py"", line 16, in <module>
    line for line in traceback.format_stack()


  import matplotlib; matplotlib.use('Agg')  # pylint: disable=multiple-statements
WARNING:tensorflow:Forced number of epochs for all eval validations to be 1.
W1114 20:46:22.522630 140735970734976 tf_logging.py:125] Forced number of epochs for all eval validations to be 1.
WARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.
W1114 20:46:22.522892 140735970734976 tf_logging.py:125] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.
WARNING:tensorflow:Estimator's model_fn (<function model_fn at 0x12f965488>) includes params argument, but params are not passed to Estimator.
W1114 20:46:22.523379 140735970734976 tf_logging.py:125] Estimator's model_fn (<function model_fn at 0x12f965488>) includes params argument, but params are not passed to Estimator.
WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.
W1114 20:46:22.552421 140735970734976 tf_logging.py:125] num_readers has been reduced to 1 to match input file shards.
WARNING:tensorflow:From /Users/kraisler/models/research/object_detection/builders/dataset_builder.py:80: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.experimental.parallel_interleave(...)`.
W1114 20:46:22.618475 140735970734976 tf_logging.py:125] From /Users/kraisler/models/research/object_detection/builders/dataset_builder.py:80: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.experimental.parallel_interleave(...)`.
WARNING:tensorflow:From /usr/local/lib/python2.7/site-packages/tensorflow/python/ops/sparse_ops.py:1165: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.
W1114 20:46:22.779803 140735970734976 tf_logging.py:125] From /usr/local/lib/python2.7/site-packages/tensorflow/python/ops/sparse_ops.py:1165: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.
WARNING:tensorflow:From /Users/kraisler/models/research/object_detection/core/preprocessor.py:1208: calling squeeze (from tensorflow.python.ops.array_ops) with squeeze_dims is deprecated and will be removed in a future version.
Instructions for updating:
Use the `axis` argument instead
W1114 20:46:22.908727 140735970734976 tf_logging.py:125] From /Users/kraisler/models/research/object_detection/core/preprocessor.py:1208: calling squeeze (from tensorflow.python.ops.array_ops) with squeeze_dims is deprecated and will be removed in a future version.
Instructions for updating:
Use the `axis` argument instead
WARNING:tensorflow:From /Users/kraisler/models/research/object_detection/builders/dataset_builder.py:148: batch_and_drop_remainder (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.batch(..., drop_remainder=True)`.
W1114 20:46:24.049441 140735970734976 tf_logging.py:125] From /Users/kraisler/models/research/object_detection/builders/dataset_builder.py:148: batch_and_drop_remainder (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.batch(..., drop_remainder=True)`.
W1114 20:46:26.257921 140735970734976 variables_helper.py:141] Variable [BoxPredictor_0/ClassPredictor/biases] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[273]], model variable shape: [[6]]. This variable will not be initialized from the checkpoint.
W1114 20:46:26.258060 140735970734976 variables_helper.py:141] Variable [BoxPredictor_0/ClassPredictor/weights] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[1, 1, 512, 273]], model variable shape: [[1, 1, 512, 6]]. This variable will not be initialized from the checkpoint.
W1114 20:46:26.258198 140735970734976 variables_helper.py:141] Variable [BoxPredictor_1/ClassPredictor/biases] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[546]], model variable shape: [[12]]. This variable will not be initialized from the checkpoint.
W1114 20:46:26.258268 140735970734976 variables_helper.py:141] Variable [BoxPredictor_1/ClassPredictor/weights] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[1, 1, 1024, 546]], model variable shape: [[1, 1, 1024, 12]]. This variable will not be initialized from the checkpoint.
W1114 20:46:26.258414 140735970734976 variables_helper.py:141] Variable [BoxPredictor_2/ClassPredictor/biases] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[546]], model variable shape: [[12]]. This variable will not be initialized from the checkpoint.
W1114 20:46:26.258490 140735970734976 variables_helper.py:141] Variable [BoxPredictor_2/ClassPredictor/weights] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[1, 1, 512, 546]], model variable shape: [[1, 1, 512, 12]]. This variable will not be initialized from the checkpoint.
W1114 20:46:26.258668 140735970734976 variables_helper.py:141] Variable [BoxPredictor_3/ClassPredictor/biases] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[546]], model variable shape: [[12]]. This variable will not be initialized from the checkpoint.
W1114 20:46:26.258763 140735970734976 variables_helper.py:141] Variable [BoxPredictor_3/ClassPredictor/weights] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[1, 1, 256, 546]], model variable shape: [[1, 1, 256, 12]]. This variable will not be initialized from the checkpoint.
W1114 20:46:26.258913 140735970734976 variables_helper.py:141] Variable [BoxPredictor_4/ClassPredictor/biases] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[546]], model variable shape: [[12]]. This variable will not be initialized from the checkpoint.
W1114 20:46:26.258995 140735970734976 variables_helper.py:141] Variable [BoxPredictor_4/ClassPredictor/weights] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[1, 1, 256, 546]], model variable shape: [[1, 1, 256, 12]]. This variable will not be initialized from the checkpoint.
W1114 20:46:26.259133 140735970734976 variables_helper.py:141] Variable [BoxPredictor_5/ClassPredictor/biases] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[546]], model variable shape: [[12]]. This variable will not be initialized from the checkpoint.
W1114 20:46:26.259224 140735970734976 variables_helper.py:141] Variable [BoxPredictor_5/ClassPredictor/weights] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[1, 1, 128, 546]], model variable shape: [[1, 1, 128, 12]]. This variable will not be initialized from the checkpoint.
W1114 20:46:26.262506 140735970734976 variables_helper.py:144] Variable [global_step] is not available in checkpoint
2018-11-14 20:46:42.850174: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA",spencerkraisler,None,2018-11-15T04:53:11Z,2020-02-07T18:49:45Z,,,,,,,
5756,Where could i get slim?,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",MeowsQAQ,b'type:support',2018-11-15T04:30:40Z,2019-06-10T22:05:49Z,,,,,,,
5751,SyntaxNet Bazel Test Fail,"INFO: From Compiling external/org_tensorflow/tensorflow/core/kernels/boosted_trees/training_ops.cc [for host]:
external/org_tensorflow/tensorflow/core/kernels/boosted_trees/training_ops.cc: In member function 'virtual void tensorflow::BoostedTreesUpdateEnsembleOp::Compute(tensorflow::OpKernelContext*)':
external/org_tensorflow/tensorflow/core/kernels/boosted_trees/training_ops.cc:159:57: warning: 'ensemble_resource' may be used uninitialized in this function [-Wmaybe-uninitialized]
           ensemble_resource->PostPruneTree(current_tree);
                                                         ^
ERROR: /root/models/research/syntaxnet/bazel_root/d78cc2bbfe399a9a2f97a3fcc389326e/external/grpc/BUILD:1287:1: C++ compilation of rule '@grpc//:grpc_resolver_dns_ares' failed (Exit 1) gcc failed: error executing command /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -B/usr/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG ... (remaining 55 argument(s) skipped)

Use --sandbox_debug to see verbose messages from the sandbox
external/grpc/src/core/ext/filters/client_channel/resolver/dns/c_ares/grpc_ares_wrapper.cc:30:18: fatal error: ares.h: No such file or directory
compilation terminated.
",ChildrenGreens,None,2018-11-14T03:07:23Z,2020-02-07T18:49:37Z,,,,,,,
5736,How to initialize object-detection model from Imagenet classification checkpoint,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

On research/object_detection/samples/configs/ssd_mobilenet_v1_fpn_shared_box_predictor_640x640_coco14_sync.config,line 4:
Trained on COCO, initialized from Imagenet classification checkpoint

Does this mean using the imagenet trained classifier to initialize the filter in the object detection model?It seems that the object detection API does not provide a related method.If I want to train my own object detection model on MSCOCO,Do I need to write my own code to complete this step?Thanks.
",rootkitchao,b'stat:awaiting response',2018-11-10T20:48:26Z,2019-12-05T06:59:38Z,,,,,,,
5731,how to solve that,"#! /usr/bin/python
# -*- coding: utf-8 -*-

import tensorflow as tf
import tensorlayer as tl

tf.logging.set_verbosity(tf.logging.DEBUG)
tl.logging.set_verbosity(tl.logging.DEBUG)

sess = tf.InteractiveSession()

# prepare data
X_train, y_train, X_val, y_val, X_test, y_test = tl.files.load_mnist_dataset(shape=(-1, 784))
# define placeholder
x = tf.placeholder(tf.float32, shape=[None, 784], name='x')
y_ = tf.placeholder(tf.int64, shape=[None], name='y_')

# define the network
network = tl.layers.InputLayer(x, name='input')
network = tl.layers.DropoutLayer(network, keep=0.8, name='drop1')
network = tl.layers.DenseLayer(network, 800, tf.nn.relu, name='relu1')
network = tl.layers.DropoutLayer(network, keep=0.5, name='drop2')
network = tl.layers.DenseLayer(network, 800, tf.nn.relu, name='relu2')
network = tl.layers.DropoutLayer(network, keep=0.5, name='drop3')
# the softmax is implemented internally in tl.cost.cross_entropy(y, y_) to
# speed up computation, so we use identity here.
# see tf.nn.sparse_softmax_cross_entropy_with_logits()
network = tl.layers.DenseLayer(network, n_units=10, act=None, name='output')

# define cost function and metric.
y = network.outputs
cost = tl.cost.cross_entropy(y, y_, name='cost')
correct_prediction = tf.equal(tf.argmax(y, 1), y_)
acc = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))
y_op = tf.argmax(tf.nn.softmax(y), 1)

# define the optimizer
train_params = network.all_params
train_op = tf.train.AdamOptimizer(learning_rate=0.0001).minimize(cost, var_list=train_params)

# initialize all variables in the session
tl.layers.initialize_global_variables(sess)

# print network information
network.print_params()
network.print_layers()

# train the network
tl.utils.fit(sess, network, train_op, cost, X_train, y_train, x, y_, acc=acc, batch_size=500, \
    n_epoch=500, print_freq=5, X_val=X_val, y_val=y_val, eval_train=False)

# evaluation
tl.utils.test(sess, network, acc, X_test, y_test, x, y_, batch_size=None, cost=cost)

# save the network to .npz file
tl.files.save_npz(network.all_params, name='model.npz')
sess.close()
---------------------------------------------------------------------------------------------------
runfile('C:/Users/Administrator/.spyder-py3/temp.py', wdir='C:/Users/Administrator/.spyder-py3')
C:\ProgramData\Anaconda3\lib\site-packages\h5py\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
[TL] Load or Download MNIST > data\mnist
[TL] data\mnist\train-images-idx3-ubyte.gz
Traceback (most recent call last):

  File ""<ipython-input-1-8044f5c39b77>"", line 1, in <module>
    runfile('C:/Users/Administrator/.spyder-py3/temp.py', wdir='C:/Users/Administrator/.spyder-py3')

  File ""C:\ProgramData\Anaconda3\lib\site-packages\spyder\utils\site\sitecustomize.py"", line 705, in runfile
    execfile(filename, namespace)

  File ""C:\ProgramData\Anaconda3\lib\site-packages\spyder\utils\site\sitecustomize.py"", line 102, in execfile
    exec(compile(f.read(), filename, 'exec'), namespace)

  File ""C:/Users/Administrator/.spyder-py3/temp.py"", line 13, in <module>
    X_train, y_train, X_val, y_val, X_test, y_test = tl.files.load_mnist_dataset(shape=(-1, 784))

  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorlayer\files\dataset_loaders\mnist_dataset.py"", line 31, in load_mnist_dataset
    return _load_mnist_dataset(shape, path, name='mnist', url='http://yann.lecun.com/exdb/mnist/')

  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorlayer\files\utils.py"", line 178, in _load_mnist_dataset
    X_train = load_mnist_images(path, 'train-images-idx3-ubyte.gz')

  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorlayer\files\utils.py"", line 159, in load_mnist_images
    data = np.frombuffer(f.read(), np.uint8, offset=16)

  File ""C:\ProgramData\Anaconda3\lib\gzip.py"", line 276, in read
    return self._buffer.read(size)

  File ""C:\ProgramData\Anaconda3\lib\gzip.py"", line 482, in read
    raise EOFError(""Compressed file ended before the ""

EOFError: Compressed file ended before the end-of-stream marker was reached",jamesjakeies,b'stat:awaiting response',2018-11-09T17:25:00Z,2018-11-13T17:39:21Z,,,,,,,
5699,Fix bug in dataset.py when batch_size==max_length.,"Each batch contains sequences of length in [buckets_min, buckets_max), so that the longest instance in a batch will have length buckets_max - 1. Without this fix, instances with length == batch_size will result in buckets of zero elements, causing the dataset iterator to crash.

As a bonus this adds an extra instance per batch.",oscartackstrom,b'cla: yes',2018-11-06T09:21:41Z,2020-04-24T07:02:04Z,,,,,,,
5693,[Object Detection] How large can a .record file be before causing performance issues?,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**: ObjectDetection
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.10.1
- **Bazel version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: 9.0
- **GPU model and memory**: Titan Xp / 12 GiB
- **Exact command to reproduce**: N/A

### Describe the problem
This isn't so much a problem but a criticism of the documentation.  In the ""Using Your Own Dataset"" part of the Object Detection documentation, TF advocates sharding if using more than a few thousand examples.  I feel that this is a bit imprecise and it would be nice to have guidance in the form of a file size to know if we are using sufficient/too many shards.  Is there a trade-off involved at all?  What kind of performance gains can we hope to see?  These would all be nice to know.

### Source code / logs
Not applicable
",valmunos,None,2018-11-05T20:34:20Z,2018-11-09T20:00:08Z,,,,,,,
5676,Feature Request [Object Detection]: Training  from Scratch,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
What is the top-level directory of the model you are using: N/A
Have I written custom code: No
OS Platform and Distribution: Linux Ubuntu 16.04
TensorFlow installed from: pip
TensorFlow version: 1.10.1
Bazel version: N/A
CUDA/cuDNN version: 9.0
GPU model and memory: Titan Xp / 12 GiB
Exact command to reproduce: N/A

### Describe the problem
Feature Request:

It's already possible to train feature extractors from scratch, and implement them as part of an object detection architecture.  It could be helpful train the CNNs in the zoo from scratch without having to implement the network and the functions described in the [""Defining Your Own Model""](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/defining_your_own_model.md) readme.  Training the extractor and network simultaneously would cut down on training and debugging time, and make life simpler for people looking to train from scratch.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",valmunos,None,2018-11-03T09:30:15Z,2020-02-07T18:49:03Z,,,,,,,
5667,parameter is_training when train a resnet_v1_50 from scratch and eval with the saved checkpoint file ,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:  models/research/slim
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: 
 no
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: ubuntu16.04
- **TensorFlow installed from (source or binary)**: 
- **TensorFlow version (use command below)**: 1.8
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**: cuda9.0-cudnn7
- **GPU model and memory**: Tesla V100
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

 i trained a resnet_v1_50 model from scartch on imagenet dataset and then validated on the same dataset using the saved checkpoint files. while **the validation accuracy** was **alomst 0** when the is_parameter parameter was **False** in the eval_image_classifier.py and was **0.57692** when i changed the is_traing to **True**. the accuracy is acceptable since the training step is not finished. i think there is something wrong about the batch nomarlization layer.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
my train command : 
python train_image_classifier.py \
    --train_dir= \
    --dataset_name=imagenet \
    --dataset_split_name=train \
    --dataset_dir= \
    --model_name=resnet_v1_50 \
    --learning_rate = 0.1 \
    --batch_size =128
the eval command:
     python eval_image_classifier.py
     --dataset_name=imagenet \
     --dataset_split_name=validation \
     --model_name= resnet_v1_50 \
     --preprocessing_name=vgg\
      --labels_offset=0
and i chenged this paremeter in the eval_image_classifier.py
![image](https://user-images.githubusercontent.com/39900603/47896565-14868680-dea9-11e8-96bc-30a0ed2bc03e.png)

@tensorflow-jenkins 
",wx1111,None,2018-11-02T06:08:57Z,2018-11-14T03:13:49Z,,,,,,,
5648,Fix minor bug in images/sec calculation.,,reedwm,b'cla: yes',2018-10-31T17:21:40Z,2019-03-08T01:01:55Z,,,,,,,
5643,What will happen if I set the batch size to 1? Train.py,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**: object_detection
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: no
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 8 
- **TensorFlow installed from (source or binary)**: I dont know. But I am sure I installed it using pip 
- **TensorFlow version (use command below)**: 1.9.0
- **Bazel version (if compiling from source)**: Did't use bazel
- **CUDA/cuDNN version**: Used tensorflow CPU instead
- **GPU model and memory**: N/A
- **Exact command to reproduce**: Run the train.py command and edited the ssd_mobilenet_v1_pets configuration and set the batch size to 1 (due to cant start training because of insuficient system memory)

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request. 

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",GeneratorEX,None,2018-10-30T22:46:59Z,2020-02-12T04:32:05Z,,,,,,,
5638,"A feature request - distribution_utils.get_distribution_strategy does NOT support CollectiveAllReduceStrategy, is this as designed?","Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

distribution_utils.get_distribution_strategy does NOT support CollectiveAllReduceStrategy, is this as designed?
CollectiveAllReduceStrategy is introduced by r1.11, but it is NOT supported by models yet.
But MirroredStrategy is available. 
Is there any plan to make CollectiveAllReduceStrategy available?



### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",clustarycx,None,2018-10-30T06:43:23Z,2018-10-31T02:39:20Z,,,,,,,
5606,Transformer -  replicating results with no. of steps instead of epochs,"### System information
- **What is the top-level directory of the model you are using**: models
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: RHEL 7.4
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**:  1.10.1
- **Bazel version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: N/A  training on CPU's
- **GPU model and memory**: N/A
- **Exact command to reproduce**: N/A

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

How is ""batches per epoch"" calculated in the Benchmarks Training Times mentioned in the document?
It is shown as 41365 for BIG transformer, but if you calculate using the code in the schedule.py, the results are different. 

Code segment that is used to calculate steps from epochs ,

total_num_tokens = NUM_EXAMPLES[mode] * self.max_length * num_epochs
return total_num_tokens // self.batch_size

if you choose the parameters from schedule.py and model_params.py,
NUM_EXAMPLES[train] = 4572160
max_length=256
batch_size=4096

Then the number of steps for 1 epoch would be 285760 and not  41365.
I understand the code segment I mentioned above is for TPU which uses static batch size, but I didn't find any code that did conversion for GPU/CPU. 
I'm trying to replicate results by mentioning the number of steps instead of number of epochs, any insights would be helpful.

Thanks 

",srinivas-varadharajan,None,2018-10-25T04:06:48Z,2020-02-12T04:33:59Z,,,,,,,
5605,running_pets dependencies and transfer learning issues,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:research/object_detection
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:no
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:Debian 4.9.110 (in fact, a GCE n1-standard-1)
- **TensorFlow installed from (source or binary)**: pip
- **TensorFlow version (use command below)**: ('v1.11.0-0-gc19e29306c', '1.11.0')
- **Bazel version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**:
from https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/running_pets.md
```
$ gcloud ml-engine jobs submit training `whoami`_object_detection_pets_`date +%m_%d_%Y_%H_%M_%S` \
    --runtime-version 1.8 \
    --job-dir=gs://${YOUR_GCS_BUCKET}/model_dir \
    --packages dist/object_detection-0.1.tar.gz,slim/dist/slim-0.1.tar.gz,/tmp/pycocotools/pycocotools-2.0.tar.gz \
    --module-name object_detection.model_main \
    --region us-central1 \
    --config object_detection/samples/cloud/cloud.yml \
    -- \
    --model_dir=gs://${YOUR_GCS_BUCKET}/model_dir \
    --pipeline_config_path=gs://${YOUR_GCS_BUCKET}/data/faster_rcnn_resnet101_pets.config
```
You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.
1. dependencies issue: regarding the gcloud parameter '--runtime-version', all versions <=1.8 are not working. 1.9 and 1.10 DO work. Seems like the problem in TF runtime installed in the gcloud ML Engine side.

2. transfer learning issue: with 1.9 or 1.10, training up to 12 hrs doesn't give a single label in the tensorboard images tab (you know, in Detection_Left_Groundtruth_Right, the left label is always empty).
This issue was double checked by https://github.com/tensorflow/models/blob/master/research/object_detection/object_detection_tutorial.ipynb
With the vanilia faster_rcnn_resnet101_coco_11_06_2017 .pb, the prediction works fine. However, after transfer learning with the vanilia, the exported .pb always predicts empty label.
Tried auditing the code and tweaked the deprecated configs (faster_rcnn_resnet101_pets.config):
```
    fine_tune_checkpoint: ""PATH_TO_BE_CONFIGURED/model.ckpt""
    from_detection_checkpoint: true
    load_all_detection_checkpoint_vars: true
  +fine_tune_checkpoint_type: ""detection""
```
but, with/without the +, it should be the same according to code auditing from line275-282 https://github.com/tensorflow/models/blob/master/research/object_detection/model_lib.py

> As you can see, already tried my best to study the issue. Please 1. confirm the gloud ml-engine <=1.8 dependency issue and 2. provide some insights to solve the transfer learning issue

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.

1. Regarding the dependency issue, runtime_version<=1.8 can't even kickstart training:
The XXX 0 exited with a non-zero status of 1. Termination reason: Error. Traceback (most recent call last):
<various... not a single point of failure anyway>

2. No error at all. In Tensorboard, every thing, from loss to mAP, seems fine, but no detection label at all i.e. transfer learning is not working",johnght,None,2018-10-25T03:58:59Z,2018-10-25T10:19:50Z,,,,,,,
5595,r,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",kletechuni,None,2018-10-24T05:22:45Z,2018-12-26T22:19:10Z,,,,,,,
5593,I using graph tranforms tool after export inference models to optimize_graph.pb . After load model have error :,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",dont32,None,2018-10-24T02:43:38Z,2020-02-12T04:33:39Z,,,,,,,
5581,Inference example code for imagenet_main.py traning,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**: imagenet_main.py
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: NO
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: macOS High Sierra, MacBook Pro, 3.1 GHz Intel Core i5, 8 GB 2133 MHz LPDDR3, Intel Iris Plus Graphics 650 1536 MB
- **TensorFlow installed from (source or binary)**: source, pip install tensorflow
- **TensorFlow version (use command below)**:  v1.11.0-rc2-4-gc19e29306c 1.11.0
- **Bazel version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**:

Training:
python3.6 imagenet_main.py --data_dir=(data directory, tfrecords files) --model_dir=(ouput directory) --export_dir=(saved model directory) --train_epochs=100

Inference:
python3.6 classify_image.py --model_dir=""/Users/duckhahwang/Downloads/imagenet_test"" --image_file=""/Users/duckhahwang/Downloads/airplane/airplane/frame_62.jpg"" 

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

Training:
python3.6 imagenet_main.py --data_dir=(data directory, tfrecords files) --model_dir=(ouput directory) --export_dir=(saved model directory) --train_epochs=100

Inference:
python3.6 classify_image.py --model_dir=""/Users/duckhahwang/Downloads/imagenet_test"" --image_file=""/Users/duckhahwang/Downloads/airplane/airplane/frame_62.jpg"" 

I trained a new model with other data that is not imagenet image data, new classes, and labels. This is scratch training. But my problem is that after scratch training I stuck by inference or predict new image with the trained model. 

I found a tutorial code:

https://www.tensorflow.org/tutorials/images/image_recognition

https://github.com/tensorflow/models/blob/master/tutorials/image/imagenet/classify_image.py

This code is that only let me know how to use the pre-trained model with ""classify_image_graph_def.pb"", 
First, I tried the same code and ""saved_model.pb"" that from export_dir but it is not working. 

Second, I tried freez_graph.py with checkpoint.
https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/tools/freeze_graph.py
But, this method also not working.

Third, using tensorrt, this is quite close to what I want to use. but my MacPro not supports to Tensorrt GPU. 
https://github.com/tensorflow/models/tree/master/research/tensorrt

Could I get any sample or tutorial code for inference, predict test code for my trained model with imagenet_main.py? 

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.

Error message from First, and Second way to predict new data with code.
saved_model.pb and freez_pragh.pb

Traceback (most recent call last):
  File ""classify_image.py"", line 264, in <module>
    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)
  File ""/Users/duckhahwang/anaconda3/lib/python3.6/site-packages/tensorflow/python/platform/app.py"", line 125, in run
    _sys.exit(main(argv))
  File ""classify_image.py"", line 230, in main
    run_inference_on_image(image)
  File ""classify_image.py"", line 192, in run_inference_on_image
    softmax_tensor = sess.graph.get_tensor_by_name('softmax:0')
  File ""/Users/duckhahwang/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 3664, in get_tensor_by_name
    return self.as_graph_element(name, allow_tensor=True, allow_operation=False)
  File ""/Users/duckhahwang/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 3488, in as_graph_element
    return self._as_graph_element_locked(obj, allow_tensor, allow_operation)
  File ""/Users/duckhahwang/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 3530, in _as_graph_element_locked
    ""graph."" % (repr(name), repr(op_name)))
KeyError: ""The name 'softmax:0' refers to a Tensor which does not exist. The operation, 'softmax', does not exist in the graph.""


",personableduck,None,2018-10-22T18:38:31Z,2020-02-07T18:48:36Z,,,,,,,
5564,Update model_lib.py,"lead a bug ""TYPEERROR: CAN'T PICKLE DICTVALUES OBJECTS""",1453042287,b'cla: no stat:awaiting review',2018-10-18T09:25:56Z,2020-04-26T02:44:30Z,,,,,,,
5549,May be a bug -> the avg_cost in models/../Autoencoder.py,"Your cost is:  

> self.cost = 0.5 * tf.reduce_sum(tf.pow(tf.subtract(self.reconstruction, self.x), 2.0))

this is sum,

Then the function:

> def partial_fit(self, X):
        cost, opt = self.sess.run((self.cost, self.optimizer), feed_dict={self.x: X})
        return cost

in runner script, you use this function to calculate batch examples total cost,
but in a train loop each epoch:  

> avg_cost += cost / n_samples * batch_size

you multiply by batch_size,

I think ""batch_size"" should remove.",DinLei,b'stat:awaiting response',2018-10-17T01:44:50Z,2020-01-29T23:05:12Z,,,,,,,
5548,Is CycleGAN missing a networks.py?,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
`models/research/gan/cyclegan`
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
Nope!
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
macOS 10.14
- **TensorFlow installed from (source or binary)**:
Installed via pip
- **TensorFlow version (use command below)**:
v1.11.0-rc2-4-gc19e29306c 1.11.0
- **Bazel version (if compiling from source)**:
N/A
- **CUDA/cuDNN version**:
N/A
- **GPU model and memory**:
N/A
- **Exact command to reproduce**:
`python3 train.py`

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem

Running the `train.py` script in the CycleGAN example gives this error:
```
Traceback (most recent call last):
  File ""train.py"", line 26, in <module>
    import networks
ModuleNotFoundError: No module named 'networks'
```
And I noticed that unlike the other examples there's no `networks.py`. Is this missing?",bubba,None,2018-10-16T21:10:15Z,2020-01-30T16:33:31Z,,,,,,,
5545,SSD Android Object Detection Issue,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",SolemnSomit,None,2018-10-16T14:37:43Z,2018-10-16T14:37:58Z,,,,,,,
5537,vid2depth how to inference camera poses for kitti odometry dataset?,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",lraxue,None,2018-10-15T16:55:25Z,2018-10-28T01:39:36Z,,,,,,,
5519,mobilenet misspelled dictionary key word,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**: slim.nets.mobilenet
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: no
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: ubuntu 16.04
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.11
- **Bazel version (if compiling from source)**: n/a
- **CUDA/cuDNN version**: 9.0
- **GPU model and memory**: gtx 1080 ti
- **Exact command to reproduce**: n/a

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

misspelled word `multiplier_transorm`, should it be `multiplier_transform`?

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.

https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet/mobilenet.py#L113
",junweima,None,2018-10-13T20:09:19Z,2020-02-12T04:36:40Z,,,,,,,
5515,Error while using mnist dataset -Negative dimension  size caused by subtracting 3 from 1 for 'AttentionOcr_v1/conv_tower_fn/INCE/Inc eptionV3/Conv2d_4a_3x3/Conv2D' (op: 'Conv2D')  ,"Trying to test the model on the mnist dataset and encountered this error.

Tensorflow Version: 1.10 
OS: Windows 10
Installation: Anaconda (Python 3.6)


python train.py --checkpoint_inception=./datasets/inception_v3.ckpt --data
set_name=newtextdataset

INFO 2018-10-13 05:41:51.000365: train.py: 167 Use already existing training dir
ectory /tmp/attention_ocr/train
INFO 2018-10-13 05:41:51.000366: fsns.py: 130 Using MYDATASET dataset split_name
=train dataset_dir=D://***//tensorflow_models//models-master//research//
attention_ocr//python//datasets//data//fsns
DEBUG 2018-10-13 05:41:52.000233: model.py: 354 images: Tensor(""shuffle_batch:0""
, shape=(32, 100, 48, 3), dtype=float32)
DEBUG 2018-10-13 05:41:52.000237: model.py: 359 Views=4 single view: Tensor(""Att
entionOcr_v1/split:0"", shape=(32, 100, 12, 3), dtype=float32)
DEBUG 2018-10-13 05:41:52.000238: model.py: 200 Using final_endpoint=Mixed_5d
Traceback (most recent call last):
  File ""D:\ProgramFiles\Anaconda\envs\TFCore\lib\site-packages\tensorflow\python
\framework\ops.py"", line 1576, in _create_c_op
    c_op = c_api.TF_FinishOperation(op_desc)
tensorflow.python.framework.errors_impl.InvalidArgumentError: Negative dimension
 size caused by subtracting 3 from 1 for 'AttentionOcr_v1/conv_tower_fn/INCE/Inc
eptionV3/Conv2d_4a_3x3/Conv2D' (op: 'Conv2D') with input shapes: [32,23,1,80], [
3,3,80,192].",ATS-Official,None,2018-10-13T09:53:44Z,2020-02-12T04:36:26Z,,,,,,,
5507,Find a bug in when initializing with mobilenet v2 checkpoints,"Hi there:
     I try to retrain the deeplab model with mobilenet V2  and set the ""depth_multiplier = 0.5"", when initializing the model with the checkpoints pretrained on ImageNet provided in https://github.com/tensorflow/models/tree/master/research/slim/nets/mobilenet    
""mobilenet_v2_0.5_224"". An  error "" InvalidArgumentError (see above for traceback): Assign requires shapes of both tensors to match. lhs shape= [12] rhs shape= [16]
	 [[Node: save/Assign_26 = Assign[T=DT_FLOAT, _class=[""loc:@MobilenetV2/expanded_conv_1/project/BatchNorm/gamma""], use_locking=true, validate_shape=true, _device=""/job:localhost/replica:0/task:0/cpu:0""](MobilenetV2/expanded_conv_1/project/BatchNorm/gamma, save/RestoreV2_26)]]"" is reported.
After investigation, i found this error is result in  a  bug in ""deep/core/feature_extractor.py"", line 65:
""divisible_by=8 if depth_multiplier == 1.0 else 1"" , should be ""divisible_by=8 if depth_multiplier != 1.0 else 1""

",Shenghsin,None,2018-10-12T02:21:25Z,2020-09-15T10:16:37Z,,,,,,,
5472,bug fix and python3 compatability,"fixed bug and introduced python3 compatability.
describtion: The automated marco did not account for the output of the tensorflow model enumerated the dictionary keys in the order of the scores. 

Additionally removed the conversion to % ",JonathanJuhl,b'cla: yes',2018-10-11T06:31:02Z,2018-10-11T15:35:58Z,,,,,,,
5454,can use tensorflow post_training_quantize quantize ssd_mobilenet_v2,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",cjr0106,None,2018-10-08T14:10:07Z,2018-10-19T23:12:18Z,,,,,,,
5452,Train.py handles pipeline file error when using object_detection,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:tensorflow/models/research/object_detection
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:windows10
- **TensorFlow installed from (source or binary)**:no
- **TensorFlow version (use command below)**:1.8.0
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:on CPU
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
When I used the target detection api, this error occurred. I generated the data according to the official tutorial and configured the pipeline file. When I run train.py, the following code reports an error.
Configs = config_util.get_configs_from_pipeline_file(
         FLAGS.pipeline_config_path)
The follow-up error is in the \research\object_detection\utils\config_util.py directory, the 97th line of code error: text_format.Merge(proto_str, pipeline_config), this is a headache I hope to help me solve, thank you!

### Source code / logs
WARNING:tensorflow:From D:\develop\Python3.6.4\lib\site-packages\tensorflow\python\platform\app.py:126: main (from __main__) is deprecated and will be removed in a future version.
Instructions for updating:
Use object_detection/model_main.py.
W1008 17:21:25.471641  3112 tf_logging.py:126] From D:\develop\Python3.6.4\lib\site-packages\tensorflow\python\platform\app.py:126: main (from __main__) is deprecated and will be removed in a future version.
Instructions for updating:
Use object_detection/model_main.py.
Traceback (most recent call last):
  File ""D:\workspace\eclipsejee\TensorFlow-model\research\object_detection\legacy\train.py"", line 198, in <module>
    tf.app.run()
  File ""D:\develop\Python3.6.4\lib\site-packages\tensorflow\python\platform\app.py"", line 126, in run
    _sys.exit(main(argv))
  File ""D:\develop\Python3.6.4\lib\site-packages\tensorflow\python\util\deprecation.py"", line 250, in new_func
    return func(*args, **kwargs)
  File ""D:\workspace\eclipsejee\TensorFlow-model\research\object_detection\legacy\train.py"", line 107, in main
    FLAGS.pipeline_config_path)
  File ""D:\workspace\eclipsejee\TensorFlow-model\research\object_detection\utils\config_util.py"", line 97, in get_configs_from_pipeline_file
    text_format.Merge(proto_str, pipeline_config)
  File ""D:\develop\Python3.6.4\lib\site-packages\google\protobuf\text_format.py"", line 536, in Merge
    descriptor_pool=descriptor_pool)
  File ""D:\develop\Python3.6.4\lib\site-packages\google\protobuf\text_format.py"", line 590, in MergeLines
    return parser.MergeLines(lines, message)
  File ""D:\develop\Python3.6.4\lib\site-packages\google\protobuf\text_format.py"", line 623, in MergeLines
    self._ParseOrMerge(lines, message)
  File ""D:\develop\Python3.6.4\lib\site-packages\google\protobuf\text_format.py"", line 638, in _ParseOrMerge
    self._MergeField(tokenizer, message)
  File ""D:\develop\Python3.6.4\lib\site-packages\google\protobuf\text_format.py"", line 763, in _MergeField
    merger(tokenizer, message, field)
  File ""D:\develop\Python3.6.4\lib\site-packages\google\protobuf\text_format.py"", line 837, in _MergeMessageField
    self._MergeField(tokenizer, sub_message)
  File ""D:\develop\Python3.6.4\lib\site-packages\google\protobuf\text_format.py"", line 763, in _MergeField
    merger(tokenizer, message, field)
  File ""D:\develop\Python3.6.4\lib\site-packages\google\protobuf\text_format.py"", line 837, in _MergeMessageField
    self._MergeField(tokenizer, sub_message)
  File ""D:\develop\Python3.6.4\lib\site-packages\google\protobuf\text_format.py"", line 763, in _MergeField
    merger(tokenizer, message, field)
  File ""D:\develop\Python3.6.4\lib\site-packages\google\protobuf\text_format.py"", line 888, in _MergeScalarField
    value = tokenizer.ConsumeString()
  File ""D:\develop\Python3.6.4\lib\site-packages\google\protobuf\text_format.py"", line 1251, in ConsumeString
    the_bytes = self.ConsumeByteString()
  File ""D:\develop\Python3.6.4\lib\site-packages\google\protobuf\text_format.py"", line 1266, in ConsumeByteString
    the_list = [self._ConsumeSingleByteString()]
  File ""D:\develop\Python3.6.4\lib\site-packages\google\protobuf\text_format.py"", line 1291, in _ConsumeSingleByteString
    result = text_encoding.CUnescape(text[1:-1])
  File ""D:\develop\Python3.6.4\lib\site-packages\google\protobuf\text_encoding.py"", line 103, in CUnescape
    result = ''.join(_cescape_highbit_to_str[ord(c)] for c in result)
  File ""D:\develop\Python3.6.4\lib\site-packages\google\protobuf\text_encoding.py"", line 103, in <genexpr>
    result = ''.join(_cescape_highbit_to_str[ord(c)] for c in result)
IndexError: list index out of range
",abigeer,None,2018-10-08T09:41:24Z,2020-02-07T18:48:13Z,,,,,,,
5427,vid2depth bazel error: no org_bzip_bzip2 package,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**: vid2depth
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: no
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04.4 LTS 
- **TensorFlow installed from (source or binary)**: binary (pip)
- **TensorFlow version (use command below)**: v1.11.0-0-gc19e29306c 1.11.0
- **Bazel version (if compiling from source)**: 0.17.2
- **CUDA/cuDNN version**: CUDA Version 8.0.61
- **GPU model and memory**: NVIDIA-SMI 384.130 
- **Exact command to reproduce**: bazel build ops:pcl_demo

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem

When I run the command `bazel build ops:pcl_demo`, which is required for running `vid2depth`, I get the following error:
```
ERROR: Analysis of target '//ops:pcl_demo' failed; build aborted: no such package '@org_bzip_bzip2//': Error downloading [http://www.bzip.org/1.0.6/bzip2-1.0.6.tar.gz] to /home/fabio/.cache/bazel/_bazel_fabio/0d97ea14302a2780e97a4c982df93810/external/org_bzip_bzip2/bzip2-1.0.6.tar.gz: Checksum was 04ccd15864975864b819c059a1442cbf8d3dd29ab81290661035512d9992037a but wanted a2848f34fcd5d6cf47def00461fcb528a0484d8edef8208d6d2e2909dc61d9cd
INFO: Elapsed time: 1.014s
INFO: 0 processes.
FAILED: Build did NOT complete successfully (0 packages loaded)
```",IgorFobia,b'stat:awaiting maintainer',2018-10-02T17:43:53Z,2020-05-31T13:31:57Z,,,,,,,
5404,deps/swiftshader-src/third_party/pnacl-subzero is empty,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",xiyacao,None,2018-09-30T05:06:15Z,2018-09-30T05:06:39Z,,,,,,,
5403,ptb_word_lm.py no longer working for multi-gpu with tf 1.11,"when running with multi-gpu, ptb_word_lm.py will throw an exception when OptimizeGraph(). I tried from tf 1.8-1.11, and this bug can be reproduced from all versions.

```
Traceback (most recent call last):
  File ""ptb_word_lm.py"", line 527, in <module>
    tf.app.run()
  File ""/home/chao/anaconda3/lib/python3.6/site-packages/tensorflow/python/platform/app.py"", line 125, in run
    _sys.exit(main(argv))
  File ""ptb_word_lm.py"", line 498, in main
    util.auto_parallel(metagraph, m)
  File ""/home/chao/Project/models/tutorials/rnn/ptb/util.py"", line 96, in auto_parallel
    optimized_graph = tf_optimizer.OptimizeGraph(rewriter_config, metagraph)
  File ""/home/chao/anaconda3/lib/python3.6/site-packages/tensorflow/python/grappler/tf_optimizer.py"", line 39, in OptimizeGraph
    verbose, graph_id, status)
  File ""/home/chao/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py"", line 526, in __exit__
    c_api.TF_GetCode(self.status.status))
tensorflow.python.framework.errors_impl.InvalidArgumentError: Non-existent input AutoParallel-Replica-0/AutoParallel-Div-Const for node AutoParallel-Replica-0/AutoParallel-Div-AutoParallel-Replica-0/Train/Model/GradientDescent/update_Model/RNN/multi_rnn_cell/cell_0/basic_lstm_cell/bias/ApplyGradientDescent
```

### System information
- **What is the top-level directory of the model you are using**: tutorials
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: no
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: v1.11.0-0-gc19e29306c 1.11.0
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**: 9.0/7
- **GPU model and memory**: GTX 1080 Ti 11G
- **Exact command to reproduce**:  python ptb_word_lm.py --data_path=$HOME/ProjData/ptb/ --model=small --num_gpus 3

",pcgreat,None,2018-09-30T04:30:08Z,2020-02-12T04:39:16Z,,,,,,,
5398,ValueError: The first layer in a Sequential model must get an `input_shape` or `batch_input_shape` argument.,"import tensorflow as tf

mnist = tf.keras.datasets.mnist # 28x28 images of handwritten digits 0-9

(x_train, y_train),(x_test, y_test) = mnist.load_data()

x_train = tf.keras.utils.normalize(x_train, axis=1)
x_test = tf.keras.utils.normalize(x_test, axis=1)

model = tf.keras.models.Sequential()
model.add(tf.keras.layers.Flatten())
model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))
model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))
model.add(tf.keras.layers.Dense(10, activation=tf.nn.softmax))

model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

model.fit(x_train, y_train, epochs=3)

ValueError                                Traceback (most recent call last)
<ipython-input-46-90d8be7d1552> in <module>()
      9 
     10 model = tf.keras.models.Sequential()
---> 11 model.add(tf.keras.layers.Flatten())
     12 model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))
     13 model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))

E:\Anaconda3\lib\site-packages\tensorflow\python\keras\_impl\keras\models.py in add(self, layer)
    459         # create an input layer
    460         if not hasattr(layer, '_batch_input_shape'):
--> 461           raise ValueError('The first layer in a '
    462                            'Sequential model must '
    463                            'get an `input_shape` or '

ValueError: The first layer in a Sequential model must get an `input_shape` or `batch_input_shape` argument.


Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",3dstorm,None,2018-09-28T18:13:02Z,2018-12-27T10:08:10Z,,,,,,,
5388,[Object Detection][Bug] keep_aspect_ratio_resizer doesn't work well with pad_to_max_dimension,"### System information
- **What is the top-level directory of the model you are using**: object_detection
- **Have I written custom code**: no
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.10.
- **Bazel version (if compiling from source)**: -
- **CUDA/cuDNN version**: CUDA 9
- **GPU model and memory**: 1080Ti, 12GB
- **Exact command to reproduce**: training and evaluating ssdlite_mobilenet_v2_coco_2018_05_09 using object_detection/model_main.py.

### Describe the problem
For a while now I tried to train a model using keep_aspect_ratio_resizer without any luck. I believe I found that the reason is that this resizer simply doesn't work well.
Here's a keep_aspect_ratio_resizer configuration I've been used:
```
      keep_aspect_ratio_resizer {
        min_dimension: 480
        max_dimension: 640
        pad_to_max_dimension: true
      }
```
The way I expected it to work is to resize the image such that the longer axis will have length 640 while keeping the original aspect ratio, and then the image is padded (right-bottom) in order to achieve 640x640. Moreover, the bounding boxes should be resized in the same manner.
BTW, the reason I use the padding is to have batch_size>1. Otherwise, multiple images which don't have the same dimensions won't fit together to a single tensor.

Here you can see visualization of GT with **keep_aspect_ratio_resizer** and **pad_to_max_dimension** (note how the aspect ratio is not kept, and that the BBs have the original shape and location):
![image](https://user-images.githubusercontent.com/38940293/46131974-9ef21f80-c245-11e8-84d8-2d010278e40c.png)
![image](https://user-images.githubusercontent.com/38940293/46132022-bb8e5780-c245-11e8-9dbc-816708f1c7b4.png)
and here the same images with fixed_shape_resizer:
![image](https://user-images.githubusercontent.com/38940293/46132047-cba63700-c245-11e8-924e-3744b588e832.png)
![image](https://user-images.githubusercontent.com/38940293/46132055-d1038180-c245-11e8-8ef1-ac14866fa3f4.png)

Thanks in advance,",netanel-s,None,2018-09-27T08:11:20Z,2020-02-07T18:48:09Z,,,,,,,
5383,[Object Detection][Bug/Feature Request] Leave evaluation time out of training time,"### System information
- **What is the top-level directory of the model you are using**: object_detection
- **Have I written custom code**: no
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.10.
- **Bazel version (if compiling from source)**: -
- **CUDA/cuDNN version**: CUDA 9
- **GPU model and memory**: 1080Ti, 12GB
- **Exact command to reproduce**: training and evaluating ssdlite_mobilenet_v2_coco_2018_05_09 using object_detection/model_main.py.

### Describe the problem
When the model is evaluated, the time that the ""training clock"" isn't stopping, so it includes the time that evaluation takes.
Therefore, the training steps which the evaluation takes place in have longer time (see step=3400 below for example), and the value of global_step/sec is not relevant as can be seen in Tensorboard:
![image](https://user-images.githubusercontent.com/38940293/46076919-b83c9280-c197-11e8-88fb-584843eb1004.png)

```
INFO:tensorflow:Starting evaluation at 2018-09-26-11:07:54
INFO:tensorflow:Starting evaluation at 2018-09-26-11:07:54
...
INFO:tensorflow:Evaluation [<500-5000>/5000]
...
<COCO_metrics>
INFO:tensorflow:Finished evaluation at 2018-09-26-11:14:11
INFO:tensorflow:Finished evaluation at 2018-09-26-11:14:11
INFO:tensorflow:Saving dict for global step 3389: <evaluation_dict>
INFO:tensorflow:Saving 'checkpoint_path' summary for global step 3389: <model_path>
INFO:tensorflow:Saving 'checkpoint_path' summary for global step 3389: <model_path>
INFO:tensorflow:global_step/sec: 0.206893
INFO:tensorflow:global_step/sec: 0.206893
INFO:tensorflow:loss = 9.355345, step = 3400 (483.343 sec)
INFO:tensorflow:loss = 9.355345, step = 3400 (483.343 sec)
INFO:tensorflow:global_step/sec: 1.01595
INFO:tensorflow:global_step/sec: 1.01595
INFO:tensorflow:loss = 9.42148, step = 3500 (98.430 sec)
INFO:tensorflow:loss = 9.42148, step = 3500 (98.430 sec)
INFO:tensorflow:global_step/sec: 1.01467
INFO:tensorflow:global_step/sec: 1.01467
INFO:tensorflow:loss = 9.942209, step = 3600 (98.554 sec)
INFO:tensorflow:loss = 9.942209, step = 3600 (98.554 sec)
```

I think that you might want to keep both exclusive training time (which will be used in particular for golbal_step/sec) and exclusive evaluation time (since this value is important as well), and their sum will give the total time.

Thanks in advance.",netanel-s,None,2018-09-26T11:33:21Z,2020-02-07T18:48:09Z,,,,,,,
5371,"[Object Detection] TypeError: `name` must be string, given: 0","### System information
- **What is the top-level directory of the model you are using**: ~/tf_1_10_src/tensorflow/tensorflow/models
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:Ubuntu 16.04.3 LTS
- **TensorFlow installed from (source or binary)**: source 
- **TensorFlow version (use command below)**: 1.10.1
- **Bazel version (if compiling from source)**: 0.15.2
- **CUDA/cuDNN version**: CUDA 9.0/cuDNN 7.3
- **GPU model and memory**: GTX TitanXp
- **Exact command to reproduce**: `cd ~/tf_1_10_src/tensorflow/tensorflow/models/research; ~/train_object_detection_v1.sh`

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs

Script train_object_detection_v1.sh source:
```
!/bin/bash
echo ""Object detection script v.1""
echo ""Check execution path""
if [[ ""$PWD"" = ""$TFMODELPATH/research"" ]]
then
  echo ""Current working directory is correct.""
  
  PROJECT_DIR=/media/nikita/LinuxBD4Tb/SSD_PROJECT
  PIPELINE_CONFIG_PATH=$PROJECT_DIR/ssd_inception_v2_coco_nik.config
  MODEL_DIR=$PROJECT_DIR/models/model
  NUM_TRAIN_STEPS=4000000
  SAMPLE_1_OF_N_EVAL_EXAMPLES=1
  
  echo ""PIPELINE_CONFIG_PATH=$PIPELINE_CONFIG_PATH""
  echo ""MODEL_DIR=$MODEL_DIR""
  echo ""NUM_TRAIN_STEPS=$NUM_TRAIN_STEPS""
  echo ""SAMPLE_1_OF_N_EVAL_EXAMPLES=$SAMPLE_1_OF_N_EVAL_EXAMPLES""
  echo ""-----------------""
  echo ""Start object_detection/model_main.py""
  python object_detection/model_main.py \
    --pipeline_config_path=${PIPELINE_CONFIG_PATH} \
    --model_dir=${MODEL_DIR} \
    --num_train_steps=${NUM_TRAIN_STEPS} \
    --sample_1_of_n_eval_examples=$SAMPLE_1_OF_N_EVAL_EXAMPLES \
    --alsologtostderr 
else
  echo ""Current working directory must be 'tensorflow/models/research/'.""
  echo ""Correct path is '$TFMODELPATH/research'""
  echo ""Exit.""  
fi
```
Dir struct:

```
./SSD_PROJECT/
├── data
│   ├── mscoco_label_map.pbtxt
│   ├── mscoco_train.record
│   └── mscoco_val.record
├── models
│   └── model
│       ├── eval
│       ├── pipeline.config
│       └── train
└── ssd_inception_v2_coco_nik.config
```
File ssd_inception_v2_coco_nik.config:
```
model {
  ssd {
    num_classes: 90
    box_coder {
      faster_rcnn_box_coder {
        y_scale: 10.0
        x_scale: 10.0
        height_scale: 5.0
        width_scale: 5.0
      }
    }
    matcher {
      argmax_matcher {
        matched_threshold: 0.5
        unmatched_threshold: 0.5
        ignore_thresholds: false
        negatives_lower_than_unmatched: true
        force_match_for_each_row: true
      }
    }
    similarity_calculator {
      iou_similarity {
      }
    }
    anchor_generator {
      ssd_anchor_generator {
        num_layers: 6
        min_scale: 0.2
        max_scale: 0.95
        aspect_ratios: 1.0
        aspect_ratios: 2.0
        aspect_ratios: 0.5
        aspect_ratios: 3.0
        aspect_ratios: 0.3333
        reduce_boxes_in_lowest_layer: true
      }
    }
    image_resizer {
      fixed_shape_resizer {
        height: 300
        width: 300
      }
    }
    box_predictor {
      convolutional_box_predictor {
        min_depth: 0
        max_depth: 0
        num_layers_before_predictor: 0
        use_dropout: false
        dropout_keep_probability: 0.8
        kernel_size: 3
        box_code_size: 4
        apply_sigmoid_to_scores: false
        conv_hyperparams {
          activation: RELU_6,
          regularizer {
            l2_regularizer {
              weight: 0.00004
            }
          }
          initializer {
            truncated_normal_initializer {
              stddev: 0.03
              mean: 0.0
            }
          }
        }
      }
    }
    feature_extractor {
      type: 'ssd_inception_v2'
      min_depth: 16
      depth_multiplier: 1.0
      conv_hyperparams {
        activation: RELU_6,
        regularizer {
          l2_regularizer {
            weight: 0.00004
          }
        }
        initializer {
          truncated_normal_initializer {
            stddev: 0.03
            mean: 0.0
          }
        }
        batch_norm {
          train: true,
          scale: true,
          center: true,
          decay: 0.9997,
          epsilon: 0.001,
        }
      }
      override_base_feature_extractor_hyperparams: true
    }
    loss {
      classification_loss {
        weighted_sigmoid {
        }
      }
      localization_loss {
        weighted_smooth_l1 {
        }
      }
      hard_example_miner {
        num_hard_examples: 3000
        iou_threshold: 0.99
        loss_type: CLASSIFICATION
        max_negatives_per_positive: 3
        min_negatives_per_image: 0
      }
      classification_weight: 1.0
      localization_weight: 1.0
    }
    normalize_loss_by_num_matches: true
    post_processing {
      batch_non_max_suppression {
        score_threshold: 1e-8
        iou_threshold: 0.6
        max_detections_per_class: 100
        max_total_detections: 100
      }
      score_converter: SIGMOID
    }
  }
}

train_config: {
  batch_size: 32
  optimizer {
    rms_prop_optimizer: {
      learning_rate: {
        exponential_decay_learning_rate {
          initial_learning_rate: 0.004
          decay_steps: 800720
          decay_factor: 0.95
        }
      }
      momentum_optimizer_value: 0.9
      decay: 0.9
      epsilon: 1.0
    }
  }
  fine_tune_checkpoint: ""/home/nikita/tf_1_10_src/pretrained_InceptionV2_ImageNet_CLS2012/inception_v2.ckpt""
  from_detection_checkpoint: false
  # Note: The below line limits the training process to 200K steps, which we
  # empirically found to be sufficient enough to train the pets dataset. This
  # effectively bypasses the learning rate schedule (the learning rate will
  # never decay). Remove the below line to train indefinitely.
  #num_steps: 300000
  data_augmentation_options {
    random_horizontal_flip {
    }
  }
  data_augmentation_options {
    ssd_random_crop {
    }
  }
}

train_input_reader: {
  tf_record_input_reader {
    input_path: ""/media/nikita/LinuxBD4Tb/SSD_PROJECT/data/mscoco_train.record""
  }
  label_map_path: ""/media/nikita/LinuxBD4Tb/SSD_PROJECT/data/mscoco_label_map.pbtxt""
}

eval_config: {
  num_examples: 5000
  # Note: The below line limits the evaluation process to 10 evaluations.
  # Remove the below line to evaluate indefinitely.
  max_evals: 10
}

eval_input_reader: {
  tf_record_input_reader {
    input_path: ""/media/nikita/LinuxBD4Tb/SSD_PROJECT/data/mscoco_val.record""
  }
  label_map_path: ""/media/nikita/LinuxBD4Tb/SSD_PROJECT/data/mscoco_label_map.pbtxt""
  shuffle: false
  num_readers: 1
}
```


Error log:
```
nikita@ubuntulinux:~/tf_1_10_src/tensorflow/tensorflow/models/research$ ~/train_object_detection_v1.sh 
Object detection script v.1
Check execution path
Current working directory is correct.
PIPELINE_CONFIG_PATH=/media/nikita/LinuxBD4Tb/SSD_PROJECT/ssd_inception_v2_coco_nik.config
MODEL_DIR=/media/nikita/LinuxBD4Tb/SSD_PROJECT/models/model
NUM_TRAIN_STEPS=4000000
SAMPLE_1_OF_N_EVAL_EXAMPLES=1
-----------------
Start object_detection/model_main.py
/home/nikita/tf_1_10_src/tensorflow/tensorflow/models/research/object_detection/utils/visualization_utils.py:27: UserWarning: 
This call to matplotlib.use() has no effect because the backend has already
been chosen; matplotlib.use() must be called *before* pylab, matplotlib.pyplot,
or matplotlib.backends is imported for the first time.

The backend was *originally* set to u'TkAgg' by the following code:
  File ""object_detection/model_main.py"", line 26, in <module>
    from object_detection import model_lib
  File ""/home/nikita/tf_1_10_src/tensorflow/tensorflow/models/research/object_detection/model_lib.py"", line 27, in <module>
    from object_detection import eval_util
  File ""/home/nikita/tf_1_10_src/tensorflow/tensorflow/models/research/object_detection/eval_util.py"", line 27, in <module>
    from object_detection.metrics import coco_evaluation
  File ""/home/nikita/tf_1_10_src/tensorflow/tensorflow/models/research/object_detection/metrics/coco_evaluation.py"", line 20, in <module>
    from object_detection.metrics import coco_tools
  File ""/home/nikita/tf_1_10_src/tensorflow/tensorflow/models/research/object_detection/metrics/coco_tools.py"", line 47, in <module>
    from pycocotools import coco
  File ""/home/nikita/tf_1_10_src/tensorflow/tensorflow/models/research/pycocotools/coco.py"", line 49, in <module>
    import matplotlib.pyplot as plt
  File ""/usr/local/lib/python2.7/dist-packages/matplotlib/pyplot.py"", line 69, in <module>
    from matplotlib.backends import pylab_setup
  File ""/usr/local/lib/python2.7/dist-packages/matplotlib/backends/__init__.py"", line 14, in <module>
    line for line in traceback.format_stack()


  import matplotlib; matplotlib.use('Agg')  # pylint: disable=multiple-statements
WARNING:tensorflow:Forced number of epochs for all eval validations to be 1.
W0924 15:58:51.491380 140112981780224 tf_logging.py:125] Forced number of epochs for all eval validations to be 1.
WARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.
W0924 15:58:51.491605 140112981780224 tf_logging.py:125] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.
WARNING:tensorflow:Estimator's model_fn (<function model_fn at 0x7f6e49985c80>) includes params argument, but params are not passed to Estimator.
W0924 15:58:51.491858 140112981780224 tf_logging.py:125] Estimator's model_fn (<function model_fn at 0x7f6e49985c80>) includes params argument, but params are not passed to Estimator.
1) exporter_name=Servo_0; eval_spec_name=0(type <type 'int'>)
Traceback (most recent call last):
  File ""object_detection/model_main.py"", line 109, in <module>
    tf.app.run()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run
    _sys.exit(main(argv))
  File ""object_detection/model_main.py"", line 102, in main
    eval_on_train_data=False)
  File ""/home/nikita/tf_1_10_src/tensorflow/tensorflow/models/research/object_detection/model_lib.py"", line 659, in create_train_and_eval_specs
    exporters=exporter))
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/training.py"", line 237, in __new__
    raise TypeError('`name` must be string, given: {}'.format(name))
TypeError: `name` must be string, given: 0
```

Debug of file object_detection/model_lib.py shows:
File modifications:
```
eval_specs = [] #line 646
  cntr = 0 # add counter
  for eval_spec_name, eval_input_fn in zip(eval_spec_names, eval_input_fns):
    cntr += 1 # add counter inc
    exporter_name = '{}_{}'.format(final_exporter_name, eval_spec_name)
    print(""{}) exporter_name={}; eval_spec_name={}(type {})"".format(cntr, exporter_name, eval_spec_name, type(eval_spec_name))) # add debuging variables
    exporter = tf.estimator.FinalExporter(
        name=exporter_name, serving_input_receiver_fn=predict_input_fn)
    eval_specs.append(
        tf.estimator.EvalSpec(
            name=eval_spec_name),
            input_fn=eval_input_fn,
            steps=None,
            exporters=exporter))
```
Result:
```
...
1) exporter_name=Servo_0; eval_spec_name=0(type <type 'int'>)
...
```
Possible solution (IMHO):
Change in object_detection/model_lib.py:
```
eval_specs.append(
        tf.estimator.EvalSpec(
            name=eval_spec_name),
            input_fn=eval_input_fn,
            steps=None,
            exporters=exporter))
```
to:
```
eval_specs.append(
        tf.estimator.EvalSpec(
            name=str(eval_spec_name),
            input_fn=eval_input_fn,
            steps=None,
            exporters=exporter))
```

P.S. Can't understand why in file object_detection/model_lib.py at line 644 list of integers generated:
```
if eval_spec_names is None: # line 643
  eval_spec_names = range(len(eval_input_fns)) # creates integers. Line 644
```
",nikitaverbis,None,2018-09-24T14:27:21Z,2020-02-07T18:48:08Z,,,,,,,
5369,NameError: name 'unicode' is not defined on object_detection_evaluation.py,"### System information
- **What is the top-level directory of the model you are using**:tensorflow/models/
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:MS Windows 10 Pro 64bit Build 17134
- **TensorFlow installed from (source or binary)**:binary（tensorflow-gpu)
- **TensorFlow version (use command below)**:v1.10.0-rc1-19-g656e7a2b34' 1.10.0
- **Bazel version (if compiling from source)**:N/A
- **CUDA/cuDNN version**:9.0/7.1
- **GPU model and memory**:NVIDIA Geforce GTX1080TI 11GB
- **Exact command to reproduce**:

Hello I have found a bug when I was trying to evaluate a model I trained myself.When i use the command python legacy/eval.py --logtostderr --checkpoint_dir= --pipeline_config_path= --eval_dir=.An error has occurred:File ""\tensorflow-models\research\object_detection\utils\object_detection_evaluation.py"", line 307, in evaluate
    category_name = unicode(category_name, 'utf-8')
NameError: name 'unicode' is not defined

unicode() is note work on python 3.6,it should be str().I hope some people can fix this.
thanks.

",rootkitchao,b'stat:awaiting model gardener',2018-09-24T04:04:13Z,2020-02-07T18:52:52Z,,,,,,,
5363,[Object detection API] Bug in code of testing installation,"Found a bug while testing Object detector API.

**1. How to repeat a bug**
Tensorflow version = branch 1.10 (build from source)
tensorflow/models = last version (23.09.2018).
protoc version = 3.6.1

From `~/<tensorflow_dir>/models/research`
Run command: `python object_detection/builders/model_builder_test.py`

**Error log:**
```
Traceback (most recent call last):
  File ""object_detection/builders/model_builder_test.py"", line 23, in <module>
    from object_detection.builders import model_builder
  File ""<tensorflow_dir>/models/research/object_detection/builders/model_builder.py"", line 46, in <module>
    from object_detection.models.ssd_mobilenet_v1_fpn_feature_extractor import SSDMobileNetV1FpnFeatureExtractor
  File ""<tensorflow_dir>/models/research/object_detection/models/ssd_mobilenet_v1_fpn_feature_extractor.py"", line 38, in <module>
    _CONV_DEFS = _create_modified_mobilenet_config()
  File ""<tensorflow_dir>/models/research/object_detection/models/ssd_mobilenet_v1_fpn_feature_extractor.py"", line 34, in _create_modified_mobilenet_config
    conv_defs = copy.copy(mobilenet_v1.MOBILENETV1_CONV_DEFS)
AttributeError: 'module' object has no attribute 'MOBILENETV1_CONV_DEFS'
```

**Notes:** At line 124 of file [https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet_v1.py](url) you will see:
```
# _CONV_DEFS specifies the MobileNet body
_CONV_DEFS = [
```

**Solution:**
In file /ssd_mobilenet_v1_fpn_feature_extractor.py change 

`conv_defs = copy.copy(mobilenet_v1.MOBILENETV1_CONV_DEFS)`

to 

`conv_defs = copy.copy(mobilenet_v1._CONV_DEFS)`
",nikitaverbis,None,2018-09-23T11:54:16Z,2018-09-24T16:29:03Z,,,,,,,
5360," DuplicateFlagError: The flag 'master' is defined twice. First from E:/project/models/research/object_detection/train.py, Second from E:/project/models/research/object_detection/train.py.  Description from first occurrence: Name of the TensorFlow master to use.","Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",moinkhan3012,None,2018-09-22T16:07:14Z,2020-09-12T06:54:41Z,,,,,,,
5359,No module named 'nets',"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",moinkhan3012,None,2018-09-22T15:22:15Z,2018-09-25T20:28:31Z,,,,,,,
5336,Model detects only 1 class,"### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

I want to recognize my fist and palm.

So I follow the Tensorflow Object Dection API

But I could see my model recognizing only one palm

I adjusted the number of images in the palm and fist to be the same.

I also modified the label file, generate_tfrecord, ssd_mobilenet_v1_pets.

I want to train the model to detect 2 classes, but after training it recognize only 1 class

I would appreciate it if someone could help.


I will upload the file I modified.
[Desktop.zip](https://github.com/tensorflow/models/files/2399404/Desktop.zip)




### System information
- **What is the top-level directory of the model you are using**: models-master/research/object_detection/
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.7.1
- **Bazel version (if compiling from source)**: 
- **CUDA/cuDNN version**: CUDA 9.0 / cuDNN 7.1
- **GPU model and memory**: GeForce GTX 1080 Ti / 64GB
- **Exact command to reproduce**: python legacy/train.py --logtostderr --train_dir=training/ --pipeline_config_path=training/ssd_mobilenet_v1_pets.config

",mking1011,None,2018-09-20T02:45:04Z,2020-02-07T18:48:00Z,,,,,,,
5329,【deeplab】InvalidArgumentError (see above for traceback): Assign requires shapes of both tensors to match. lhs shape= [320] rhs shape= [2048],"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",xm1112,None,2018-09-19T06:45:03Z,2020-02-07T18:50:52Z,,,,,,,
5323,"Training from checkpoint issue: lots of ""not found"" and ""root variable not available"" errors","
### System information
- **What is the top-level directory of the model you are using**: object_detection
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Stock example
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10 Pro 64 bits
- **TensorFlow installed from (source or binary)**: binary - ""pip install --ignore-installed --upgrade tensorflow"" with a new env in anaconda
- **GPU model and memory**: 16Gb RAM and AMD Ryzen 7 1700 (CPU)
- **Tensorflow version**: 1.10.0
- **Bazel version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: CPU version
- **GPU model and memory**: 16Gb RAM and AMD Ryzen 7 1700 (CPU)
- **Exact command to reproduce**:  python train.py --logtostderr --train_dir=ssdlite_mobilenet_v2_coco_2018_05_09/ --pipeline_config_path=ssdlite_mobilenet_v2_coco_2018_05_09/ssdlite.config

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request. (I am not 100% sure whether this is a bug or just a wrong setup, but I have trained networks using tensorflow before.)

I have downloaded the pretrained network (ssdlite_mobilenet_v2_coco) and used the default checkpoint from: https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md 

After properly creating the train and test.record files from my image dataset and setting the configuration file, I executed the following command:

python train.py --logtostderr --train_dir=ssdlite_mobilenet_v2_coco_2018_05_09/ --pipeline_config_path=ssdlite_mobilenet_v2_coco_2018_05_09/ssdlite.config

But a lot of ""not found"" and ""root variable not available"" errors popped up, halting the process. The detailed log is attached below.

I don't know if it helps much to mention, but I have this same repo in my google drive and tried to execute the command using google codelab, but I encountered the same errors. I've attached the error log, the config file I used, the result from the environment capture script and the print of my training directory.

Also guys I really appreciate the help given, please if there is anything I can improve in my description I will be happy to do it, since I am depending on this project to finish my bachelors 🙏  

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.

Error log after issuing command:
[error_log.txt](https://github.com/tensorflow/models/files/2390634/error_log.txt)

Environment capture script result:
[tf_env.txt](https://github.com/tensorflow/models/files/2390635/tf_env.txt)

Config file:
[ssdlite.txt](https://github.com/tensorflow/models/files/2390655/ssdlite.txt)

Print of training directory content:
![training_folder](https://user-images.githubusercontent.com/34986200/45657092-3a092d80-babf-11e8-87d4-1b660b9797e8.JPG)
",Art31,None,2018-09-18T00:45:24Z,2020-01-31T00:48:45Z,,,,,,,
5321,efficient-hrl environment has bug,"Hi @ofirnachum it looks like your environment is not able to start. 
I cloned your code, and run `python environments/__init__.py --env=AntMaze`, got an error

> Traceback (most recent call last):
>   File ""__init__.py"", line 125, in <module>
>     run_environment(args.env_name, args.episode_length, args.num_episodes)
>   File ""__init__.py"", line 83, in run_environment
>     create_maze_env.create_maze_env(env_name),
>   File ""/Users/Alex/Downloads/ant-env/create_maze_env.py"", line 30, in create_maze_env
>     return AntMazeEnv(maze_id=maze_id)
>   File ""/Users/Alex/Downloads/ant-env/maze_env.py"", line 191, in __init__
>     self.wrapped_env = model_cls(*args, file_path=file_path, **kwargs)
>   File ""/Users/Alex/Downloads/ant-env/ant.py"", line 35, in __init__
>     mujoco_env.MujocoEnv.__init__(self, file_path, 5)
>   File ""/Users/Alex/anaconda2/envs/rllab3/lib/python3.5/site-packages/gym/envs/mujoco/mujoco_env.py"", line 27, in __init__
>     self.model = mujoco_py.load_model_from_path(fullpath)
>   File ""cymj.pyx"", line 122, in mujoco_py.cymj.load_model_from_path
>   File ""cymj.pyx"", line 128, in mujoco_py.cymj.load_model_from_path
> RuntimeError: Unrecognized extension for /var/folders/fr/wgbc6hrs7dn5dr1550bmv9lsv3jxdh/T/tmpce32fzf2. Expected .xml or .mjb

I am using tensorflow 1.8.0 installed from pip, Mac OS, python version is 3.5.2, conda env, and most recent Gym and mujoco-py==1.5.0.",ghost,None,2018-09-17T19:04:56Z,2018-11-10T08:45:30Z,,,,,,,
5318,"hello everyone, I want to using tf.fft3d on image, but i don't know how to do it ,can someone help me? sincerely thankful.","Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",chensongkui,None,2018-09-17T11:01:25Z,2018-09-17T20:52:29Z,,,,,,,
5317,consider not using pycocotools since it doesn't work on windows,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

_== cat /etc/issue ===============================================
MINGW64_NT-10.0 Beast 2.6.0(0.304/5/3) 2016-09-09 09:46 x86_64 Msys

== are we in docker =============================================
No

== compiler =====================================================
bash: c++: command not found

== uname -a =====================================================
MINGW64_NT-10.0 Beast 2.6.0(0.304/5/3) 2016-09-09 09:46 x86_64 Msys

== check pips ===================================================
numpy              1.14.2   
protobuf           3.6.1    
tensorflow         1.7.0    
tensorflow-gpu     1.10.0   
tensorflow-hub     0.1.1    

== check for virtualenv =========================================
False

== tensorflow import ============================================
tf.VERSION = 1.10.0
tf.GIT_VERSION = b'v1.10.0-rc1-19-g656e7a2b34'
tf.COMPILER_VERSION = b'v1.10.0-rc1-19-g656e7a2b34'
Sanity check: array([1])_

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
the current model_main.py script for object detection uses pycoco and pycocotools. There is a known bug in pycocotools and the maintainers of that project have no plans to support windows. This means anyone using windows has to use the legacy.trainer.py instead. On MacOS model_main.py works fine. Until pycocotools maintainers decide to support windows, I suggest not using pycocotools or at least let users know it only works on Mac and Linux.

### Source code / logs


The exact issue with pycocotools can be found at this link. https://github.com/cocodataset/cocoapi/issues/169
The error when you try to run pip install pycocotools on windows.

  Running setup.py clean for pycocotools
Failed to build pycocotools
Installing collected packages: pycocotools
  Running setup.py install for pycocotools ... error
    Complete output from command d:\python\python36\python.exe -u -c ""import setuptools, tokenize;__file__='C:\\Users\\P
ETERL~1\\AppData\\Local\\Temp\\pip-install-qwoxf3_t\\pycocotools\\setup.py';f=getattr(tokenize, 'open', open)(__file__);
code=f.read().replace('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))"" install --record C:\Users\PETERL~1\
AppData\Local\Temp\pip-record-nkxviuzj\install-record.txt --single-version-externally-managed --compile:
    running install
    running build
    running build_py
    creating build
    creating build\lib.win-amd64-3.6
    creating build\lib.win-amd64-3.6\pycocotools
    copying pycocotools\coco.py -> build\lib.win-amd64-3.6\pycocotools
    copying pycocotools\cocoeval.py -> build\lib.win-amd64-3.6\pycocotools
    copying pycocotools\mask.py -> build\lib.win-amd64-3.6\pycocotools
    copying pycocotools\__init__.py -> build\lib.win-amd64-3.6\pycocotools
    running build_ext
    building 'pycocotools._mask' extension
    creating build\temp.win-amd64-3.6
    creating build\temp.win-amd64-3.6\Release
    creating build\temp.win-amd64-3.6\Release\pycocotools
    creating build\temp.win-amd64-3.6\Release\common
    C:\Program Files (x86)\Microsoft Visual Studio\2017\Community\VC\Tools\MSVC\14.14.26428\bin\HostX86\x64\cl.exe /c /n
ologo /Ox /W3 /GL /DNDEBUG /MD -Id:\python\python36\lib\site-packages\numpy\core\include -Icommon -Id:\python\python36\i
nclude -Id:\python\python36\include ""-IC:\Program Files (x86)\Microsoft Visual Studio\2017\Community\VC\Tools\MSVC\14.14
.26428\ATLMFC\include"" ""-IC:\Program Files (x86)\Microsoft Visual Studio\2017\Community\VC\Tools\MSVC\14.14.26428\includ
e"" ""-IC:\Program Files (x86)\Windows Kits\NETFXSDK\4.6.1\include\um"" ""-IC:\Program Files (x86)\Windows Kits\10\include\1
0.0.17134.0\ucrt"" ""-IC:\Program Files (x86)\Windows Kits\10\include\10.0.17134.0\shared"" ""-IC:\Program Files (x86)\Windo
ws Kits\10\include\10.0.17134.0\um"" ""-IC:\Program Files (x86)\Windows Kits\10\include\10.0.17134.0\winrt"" ""-IC:\Program
Files (x86)\Windows Kits\10\include\10.0.17134.0\cppwinrt"" /Tcpycocotools/_mask.c /Fobuild\temp.win-amd64-3.6\Release\py
cocotools/_mask.obj -Wno-cpp -Wno-unused-function -std=c99
    cl : Command line error D8021 : invalid numeric argument '/Wno-cpp'
    error: command 'C:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\VC\\Tools\\MSVC\\14.14.26428\\bin
\\HostX86\\x64\\cl.exe' failed with exit status 2

    ----------------------------------------",woolfel,None,2018-09-17T10:55:49Z,2020-02-07T18:47:59Z,,,,,,,
5308,mask rcnn,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",hlw787075497,None,2018-09-14T02:00:45Z,2018-09-14T02:01:40Z,,,,,,,
5306,[Bug] learning_to_remember_rare_events: shape mismatch when calculating teacher_loss,"Hello,

It looks like there is bug when calculating teacher_loss because the shapes of neg_teacher_vals and teacher_vals don't match. 

https://github.com/tensorflow/models/blob/34beb7adfcd2f394e09acfecf05fdc0bdb8143c5/research/learning_to_remember_rare_events/memory.py#L216

The shape of teacher_vals is [batch_size, batch_size] whereas neg_teacher_vals is [batch_size, 1]. This results in teacher_loss having a shape of [batch_size, batch_size], when it should really have a shape of [batch_size]. This bug is later masked by tf.reduce_mean(teacher_loss) at line 260 which returns a scalar.

This bug can be fixed by simply changing line 207 to:

teacher_vals *= tf.expand_dims( 1 - tf.to_float(tf.equal(0.0, tf.reduce_sum(teacher_hints, 1))), 1)

___

### System information
- **What is the top-level directory of the model you are using**:
research/learning_to_remember_rare_events

- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
No

- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Linux Ubuntu 16.04

- **TensorFlow installed from (source or binary)**:
binary

- **TensorFlow version (use command below)**:
1.10.0

- **Bazel version (if compiling from source)**:
N/A

- **CUDA/cuDNN version**:
CUDA Version 9.0.176

- **GPU model and memory**:
Tesla V100 16GB

- **Exact command to reproduce**:
N/A",kasrahbar,b'stat:awaiting maintainer',2018-09-13T22:48:34Z,2018-10-18T17:26:27Z,,,,,,,
5304,"tflogging.py reports ""TypeError: not all arguments converted during string formatting"" during transformer evaluation.","Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**: ~/models/official/transformer
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Rhel 7.5
- **TensorFlow installed from (source or binary)**: Binary
- **TensorFlow version (use command below)**: 1.8
- **Bazel version (if compiling from source)**: 
- **CUDA/cuDNN version**: 9.2.88-1 / 7.0.4
- **GPU model and memory**: 4xTesla P100, 16GB
- **Exact command to reproduce**: python transformer_main.py --data_dir=$DATA_DIR --model_dir=$MODEL_DIR --vocab_file=$VOCAB_FILE --param_set=$PARAM_SET --bleu_source=test_data/newstest2014.en --bleu_ref=test_data/newstest2014.de

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.

After training for an epoch (or # of steps), during evaluation, tf.logging.py throws error  - ""TypeError: not all arguments converted during string formatting"". Due to this, not able to get bleu score from evaluation.

I0913 12:57:17.766772 70366521413712 tf_logging.py:116] Writing to file /tmp/tmp6MU5MO
Traceback (most recent call last):
  File ""/home/prashant/anaconda2/lib/python2.7/logging/__init__.py"", line 861, in emit
    msg = self.format(record)
  File ""/home/prashant/anaconda2/lib/python2.7/logging/__init__.py"", line 734, in format
    return fmt.format(record)
  File ""/home/prashant/anaconda2/lib/python2.7/site-packages/absl/logging/__init__.py"", line 818, in format
    return prefix + super(PythonFormatter, self).format(record)
  File ""/home/prashant/anaconda2/lib/python2.7/logging/__init__.py"", line 465, in format
    record.message = record.getMessage()
  File ""/home/prashant/anaconda2/lib/python2.7/logging/__init__.py"", line 329, in getMessage
    msg = msg % self.args
TypeError: not all arguments converted during string formatting
Logged from file tf_logging.py, line 116
Traceback (most recent call last):
  File ""/home/prashant/anaconda2/lib/python2.7/logging/__init__.py"", line 861, in emit
    msg = self.format(record)
  File ""/home/prashant/anaconda2/lib/python2.7/logging/__init__.py"", line 734, in format
    return fmt.format(record)
  File ""/home/prashant/anaconda2/lib/python2.7/site-packages/absl/logging/__init__.py"", line 818, in format
    return prefix + super(PythonFormatter, self).format(record)
  File ""/home/prashant/anaconda2/lib/python2.7/logging/__init__.py"", line 465, in format
    record.message = record.getMessage()
  File ""/home/prashant/anaconda2/lib/python2.7/logging/__init__.py"", line 329, in getMessage
    msg = msg % self.args
TypeError: not all arguments converted during string formatting
Logged from file tf_logging.py, line 116
I0913 12:57:24.777055 70366521413712 tf_logging.py:116] Benchmark metric: {'name': 'bleu_uncased', 'timestamp': '2018-09-13T17:57:24.777002Z', 'value': 19.70687061548233, 'extras': [], 'unit': None, 'global_step': 312000}
I0913 12:57:24.777210 70366521413712 tf_logging.py:116] Benchmark metric: {'name': 'bleu_cased', 'timestamp': '2018-09-13T17:57:24.777191Z', 'value': 19.149336218833923, 'extras': [], 'unit': None, 'global_step': 312000}
",pksubbarao,None,2018-09-13T18:19:31Z,2020-02-12T04:41:26Z,,,,,,,
5294,any one know how to build owner mobilenetv2-ssd model for object_detection,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",cjr0106,None,2018-09-12T08:40:25Z,2020-02-07T18:50:52Z,,,,,,,
5291,"[BUG] When changing the batch_size of the official ResNet model, raised dimension mismatch error.","
------------------------

### System information
- **What is the top-level directory of the model you are using**: /models/
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: I've copied some original code to modify, but just some small changes like variable name changing, the most of the code remains unchanged.
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: pip
- **TensorFlow version (use command below)**: tf_1.8.0
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**: CUDA 9.0
- **GPU model and memory**: GTX 1080ti, 11GB Memory
- **Exact command to reproduce**: ```python cifar10_main.py```

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
In the official resnet code(cifar10) , the default batch_size is 64, since the images' size in cifar10 is small, we can use bigger batch_size, but when I want to change the batch_size to 16, it'll raise the dimension mismatch error:
> InvalidArgumentError (see above for traceback): Incompatible shapes: [64] vs. [16]
         [[Node: Equal = Equal[T=DT_INT64, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](ArgMax, ArgMax_1)]]
         [[Node: cross_entropy/_1585 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device_incarnation=1, tensor_name=""edge_4572_cross_entropy"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:CPU:0""]()]]

After debugging, I found that the 'final_size' of the resnet was hard-coded, in ```resnet_model.py``` line 472:
```
inputs = tf.reshape(inputs, [-1, self.final_size])
```
-1 means the batch_size, the batch_size is calculated by ```4096 // self.final_size```, it must be match with the default batch_size(64), so the `self.final_size` was hard-coded to 64 (4096//batch_size=64), as you can see in `cifar10_main.py` line 187:
```
final_size=64,
```
But if you want to change the batch_size, you have to also change the final_size of the resnet, otherwise it'll raise dimension mismatch error, but there's no notes to remind us to do that!

### Advice
Don't hard-coded the final_size, we can calculate the final_size before we put that in model building function,
```
_BATCH_SIZE = 32   # define the batch_size first
class Cifar10Model(resnet_model.Model):
    """"""Model class with appropriate defaults for CIFAR-10 data.""""""

    def __init__(self, resnet_size, data_format=None, num_classes=_NUM_CLASSES,
                 version=resnet_model.DEFAULT_VERSION):
        """"""These are the parameters that work for CIFAR-10 data.
    """"""
        if resnet_size % 6 != 2:
            raise ValueError('resnet_size must be 6n + 2:', resnet_size)

        num_blocks = (resnet_size - 2) // 6

        super(Cifar10Model, self).__init__(
            resnet_size=resnet_size,
            bottleneck=False,
            num_classes=num_classes,
            num_filters=16,
            kernel_size=3,
            conv_stride=1,
            first_pool_size=None,
            first_pool_stride=None,
            second_pool_size=8,
            second_pool_stride=1,
            block_sizes=[num_blocks] * 3,
            block_strides=[1, 2, 2],
            final_size= int(4096/_BATCH_SIZE), # And calculate the final_size using _BATCH_SIZE
            version=version,
            data_format=data_format)
```

### Source code / logs

> Traceback (most recent call last):
  File ""/home/jto/anaconda3/envs/tf/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 1322, in _do_call
    return fn(*args)
  File ""/home/jto/anaconda3/envs/tf/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 1307, in _run_fn
    options, feed_dict, fetch_list, target_list, run_metadata)
  File ""/home/jto/anaconda3/envs/tf/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 1409, in _call_tf_sessionrun
    run_metadata)
tensorflow.python.framework.errors_impl.InvalidArgumentError: Incompatible shapes: [64] vs. [16]
         [[Node: Equal = Equal[T=DT_INT64, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](ArgMax, ArgMax_1)]]
         [[Node: cross_entropy/_1585 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device_incarnation=1, tensor_name=""edge_4572_cross_entropy"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:CPU:0""]()]]

> During handling of the above exception, another exception occurred:
Traceback (most recent call last):
  File ""main.py"", line 327, in <module>
    main(argv=sys.argv)
  File ""main.py"", line 322, in main
    shape=[_HEIGHT, _WIDTH, _NUM_CHANNELS])
  File ""/home/jto/projects/dogs_cats_tf/official/resnet/resnet_run_loop.py"", line 396, in resnet_main
    max_steps=flags.max_train_steps)
  File ""/home/jto/anaconda3/envs/tf/lib/python3.5/site-packages/tensorflow/python/estimator/estimator.py"", line 363, in train
    loss = self._train_model(input_fn, hooks, saving_listeners)
  File ""/home/jto/anaconda3/envs/tf/lib/python3.5/site-packages/tensorflow/python/estimator/estimator.py"", line 843, in _train_model
    return self._train_model_default(input_fn, hooks, saving_listeners)
  File ""/home/jto/anaconda3/envs/tf/lib/python3.5/site-packages/tensorflow/python/estimator/estimator.py"", line 859, in _train_model_default
    saving_listeners)
  File ""/home/jto/anaconda3/envs/tf/lib/python3.5/site-packages/tensorflow/python/estimator/estimator.py"", line 1059, in _train_with_estimator_spec
    _, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])
  File ""/home/jto/anaconda3/envs/tf/lib/python3.5/site-packages/tensorflow/python/training/monitored_session.py"", line 567, in run
    run_metadata=run_metadata)
  File ""/home/jto/anaconda3/envs/tf/lib/python3.5/site-packages/tensorflow/python/training/monitored_session.py"", line 1043, in run
    run_metadata=run_metadata)
  File ""/home/jto/anaconda3/envs/tf/lib/python3.5/site-packages/tensorflow/python/training/monitored_session.py"", line 1134, in run
    raise six.reraise(*original_exc_info)
  File ""/home/jto/anaconda3/envs/tf/lib/python3.5/site-packages/six.py"", line 686, in reraise
    raise value
  File ""/home/jto/anaconda3/envs/tf/lib/python3.5/site-packages/tensorflow/python/training/monitored_session.py"", line 1119, in run
    return self._sess.run(*args, **kwargs)
  File ""/home/jto/anaconda3/envs/tf/lib/python3.5/site-packages/tensorflow/python/training/monitored_session.py"", line 1191, in run
    run_metadata=run_metadata)
  File ""/home/jto/anaconda3/envs/tf/lib/python3.5/site-packages/tensorflow/python/training/monitored_session.py"", line 971, in run
    return self._sess.run(*args, **kwargs)
  File ""/home/jto/anaconda3/envs/tf/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 900, in run
    run_metadata_ptr)
  File ""/home/jto/anaconda3/envs/tf/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 1135, in _run
    feed_dict_tensor, options, run_metadata)
  File ""/home/jto/anaconda3/envs/tf/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 1316, in _do_run
    run_metadata)
  File ""/home/jto/anaconda3/envs/tf/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 1335, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.InvalidArgumentError: Incompatible shapes: [64] vs. [16]
         [[Node: Equal = Equal[T=DT_INT64, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](ArgMax, ArgMax_1)]]
         [[Node: cross_entropy/_1585 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device_incarnation=1, tensor_name=""edge_4572_cross_entropy"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:CPU:0""]()]]

> Caused by op 'Equal', defined at:
  File ""main.py"", line 327, in <module>
    main(argv=sys.argv)
  File ""main.py"", line 322, in main
    shape=[_HEIGHT, _WIDTH, _NUM_CHANNELS])
  File ""/home/jto/projects/dogs_cats_tf/official/resnet/resnet_run_loop.py"", line 396, in resnet_main
    max_steps=flags.max_train_steps)
  File ""/home/jto/anaconda3/envs/tf/lib/python3.5/site-packages/tensorflow/python/estimator/estimator.py"", line 363, in train
    loss = self._train_model(input_fn, hooks, saving_listeners)
  File ""/home/jto/anaconda3/envs/tf/lib/python3.5/site-packages/tensorflow/python/estimator/estimator.py"", line 843, in _train_model
    return self._train_model_default(input_fn, hooks, saving_listeners)
  File ""/home/jto/anaconda3/envs/tf/lib/python3.5/site-packages/tensorflow/python/estimator/estimator.py"", line 856, in _train_model_default
    features, labels, model_fn_lib.ModeKeys.TRAIN, self.config)
  File ""/home/jto/anaconda3/envs/tf/lib/python3.5/site-packages/tensorflow/python/estimator/estimator.py"", line 831, in _call_model_fn
    model_fn_results = self._model_fn(features=features, **kwargs)
  File ""main.py"", line 303, in dogscats_model_fn
    multi_gpu=params['multi_gpu'])
  File ""/home/jto/projects/dogs_cats_tf/official/resnet/resnet_run_loop.py"", line 281, in resnet_model_fn
    tf.argmax(labels, axis=1), predictions['classes'])
  File ""/home/jto/anaconda3/envs/tf/lib/python3.5/site-packages/tensorflow/python/ops/metrics_impl.py"", line 407, in accuracy
    is_correct = math_ops.to_float(math_ops.equal(predictions, labels))
  File ""/home/jto/anaconda3/envs/tf/lib/python3.5/site-packages/tensorflow/python/ops/gen_math_ops.py"", line 2529, in equal
    ""Equal"", x=x, y=y, name=name)
  File ""/home/jto/anaconda3/envs/tf/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py"", line 787, in _apply_op_helper
    op_def=op_def)
  File ""/home/jto/anaconda3/envs/tf/lib/python3.5/site-packages/tensorflow/python/framework/ops.py"", line 3392, in create_op
    op_def=op_def)
  File ""/home/jto/anaconda3/envs/tf/lib/python3.5/site-packages/tensorflow/python/framework/ops.py"", line 1718, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access

> InvalidArgumentError (see above for traceback): Incompatible shapes: [64] vs. [16]
         [[Node: Equal = Equal[T=DT_INT64, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](ArgMax, ArgMax_1)]]
         [[Node: cross_entropy/_1585 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device_incarnation=1, tensor_name=""edge_4572_cross_entropy"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:CPU:0""]()]]

",JustinhoCHN,None,2018-09-12T03:27:30Z,2018-09-25T21:59:09Z,,,,,,,
5289,"Release iNaturalist Species-trained models, refactor of evaluation, box predictor for object detection.","212389173  by Zhichao Lu:

    1. Replace tf.boolean_mask with tf.where

--
212282646  by Zhichao Lu:

    1. Fix a typo in model_builder.py and add a test to cover it.

--
212142989  by Zhichao Lu:

    Only resize masks in meta architecture if it has not already been resized in the input pipeline.

--
212136935  by Zhichao Lu:

    Choose matmul or native crop_and_resize in the model builder instead of faster r-cnn meta architecture.

--
211907984  by Zhichao Lu:

    Make eval input reader repeated field and update config util to handle this field.

--
211858098  by Zhichao Lu:

    Change the implementation of merge_boxes_with_multiple_labels.

--
211843915  by Zhichao Lu:

    Add Mobilenet v2 + FPN support.

--
211655076  by Zhichao Lu:

    Bug fix for generic keys in config overrides

    In generic configuration overrides, we had a duplicate entry for train_input_config and we were missing the eval_input_config and eval_config.

    This change also introduces testing for all config overrides.

--
211157501  by Zhichao Lu:

    Make the locally-modified conv defs a copy.

    So that it doesn't modify MobileNet conv defs globally for other code that
    transitively imports this package.

--
211112813  by Zhichao Lu:

    Refactoring visualization tools for Estimator's eval_metric_ops. This will make it easier for future models to take advantage of a single interface and mechanics.

--
211109571  by Zhichao Lu:

    A test decorator.

--
210747685  by Zhichao Lu:

    For FPN, when use_depthwise is set to true, use slightly modified mobilenet v1 config.

--
210723882  by Zhichao Lu:

    Integrating the losses mask into the meta architectures. When providing groundtruth, one can optionally specify annotation information (i.e. which images are labeled vs. unlabeled). For any image that is unlabeled, there is no loss accumulation.

--
210673675  by Zhichao Lu:

    Internal change.

--
210546590  by Zhichao Lu:

    Internal change.

--
210529752  by Zhichao Lu:

    Support batched inputs with ops.matmul_crop_and_resize.

    With this change the new inputs are images of shape [batch, heigh, width, depth] and boxes of shape [batch, num_boxes, 4]. The output tensor is of the shape [batch, num_boxes, crop_height, crop_width, depth].

--
210485912  by Zhichao Lu:

    Fix TensorFlow version check in object_detection_tutorial.ipynb

--
210484076  by Zhichao Lu:

    Reduce TPU memory required for single image matmul_crop_and_resize.

    Using tf.einsum eliminates intermediate tensors, tiling and expansion. for an image of size [40, 40, 1024] and boxes of shape [300, 4] HBM memory usage goes down from 3.52G to 1.67G.

--
210468361  by Zhichao Lu:

    Remove PositiveAnchorLossCDF/NegativeAnchorLossCDF to resolve ""Main thread is not in main loop error"" issue in local training.

--
210100253  by Zhichao Lu:

    Pooling pyramid feature maps: add option to replace max pool with convolution layers.

--
209995842  by Zhichao Lu:

    Fix a bug which prevents variable sharing in Faster RCNN.

--
209965526  by Zhichao Lu:

    Add support for enabling export_to_tpu through the estimator.

--
209946440  by Zhichao Lu:

    Replace deprecated tf.train.Supervisor with tf.train.MonitoredSession. MonitoredSession also takes away the hassle of starting queue runners.

--
209888003  by Zhichao Lu:

    Implement function to handle data where source_id is not set.

    If the field source_id is found to be the empty string for any image during runtime, it will be replaced with a random string. This avoids hash-collisions on dataset where many examples do not have source_id set. Those hash-collisions have unintended site effects and may lead to bugs in the detection pipeline.

--
209842134  by Zhichao Lu:

    Converting loss mask into multiplier, rather than using it as a boolean mask (which changes tensor shape). This is necessary, since other utilities (e.g. hard example miner) require a loss matrix with the same dimensions as the original prediction tensor.

--
209768066  by Zhichao Lu:

    Adding ability to remove loss computation from specific images in a batch, via an optional boolean mask.

--
209722556  by Zhichao Lu:

    Remove dead code.

    (_USE_C_API was flipped to True by default in TensorFlow 1.8)

--
209701861  by Zhichao Lu:

    This CL cleans-up some tf.Example creation snippets, by reusing the convenient tf.train.Feature building functions in dataset_util.

--
209697893  by Zhichao Lu:

    Do not overwrite num_epoch for eval input. This leads to errors in some cases.

--
209694652  by Zhichao Lu:

    Sample boxes by jittering around the currently given boxes.

--
209550300  by Zhichao Lu:

    `create_category_index_from_labelmap()` function now accepts `use_display_name` parameter.
    Also added create_categories_from_labelmap function for convenience

--
209490273  by Zhichao Lu:

    Check result_dict type before accessing image_id via key.

--
209442529  by Zhichao Lu:

    Introducing the capability to sample examples for evaluation. This makes it easy to specify one full epoch of evaluation, or a subset (e.g. sample 1 of every N examples).

--
208941150  by Zhichao Lu:

    Adding the capability of exporting the results in json format.

--
208888798  by Zhichao Lu:

    Fixes wrong dictionary key for num_det_boxes_per_image.

--
208873549  by Zhichao Lu:

    Reduce the number of HLO ops created by matmul_crop_and_resize.

    Do not unroll along the channels dimension. Instead, transpose the input image dimensions, apply tf.matmul and transpose back.

    The number of HLO instructions for 1024 channels reduce from 12368 to 110.

--
208844315  by Zhichao Lu:

    Add an option to use tf.non_maximal_supression_padded in SSD post-process

--
208731380  by Zhichao Lu:

    Add field in box_predictor config to enable mask prediction and update builders accordingly.

--
208699405  by Zhichao Lu:

    This CL creates a keras-based multi-resolution feature map extractor.

--
208557208  by Zhichao Lu:

    Add TPU tests for Faster R-CNN Meta arch.

    * Tests that two_stage_predict and total_loss tests run successfully on TPU.
    * Small mods to multiclass_non_max_suppression to preserve static shapes.

--
208499278  by Zhichao Lu:

    This CL makes sure the Keras convolutional box predictor & head layers apply activation layers *after* normalization (as opposed to before).

--
208391694  by Zhichao Lu:

    Updating visualization tool to produce multiple evaluation images.

--
208275961  by Zhichao Lu:

    This CL adds a Keras version of the Convolutional Box Predictor, as well as more general infrastructure for making Keras Prediction heads & Keras box predictors.

--
208275585  by Zhichao Lu:

    This CL enables the Keras layer hyperparameter object to build a dedicated activation layer, and to disable activation by default in the op layer construction kwargs.

    This is necessary because in most cases the normalization layer must be applied before the activation layer. So, in Keras models we must set the convolution activation in a dedicated layer after normalization is applied, rather than setting it in the convolution layer construction args.

--
208263792  by Zhichao Lu:

    Add a new SSD mask meta arch that can predict masks for SSD models.
    Changes including:
     - overwrite loss function to add mask loss computation.
     - update ssd_meta_arch to handle masks if predicted in predict and postprocessing.

--
208000218  by Zhichao Lu:

    Make FasterRCNN choose static shape operations only in training mode.

--
207997797  by Zhichao Lu:

    Add static boolean_mask op to box_list_ops.py and use that in faster_rcnn_meta_arch.py to support use_static_shapes option.

--
207993460  by Zhichao Lu:

    Include FGVC detection models in model zoo.

--
207971213  by Zhichao Lu:

    remove the restriction to run tf.nn.top_k op on CPU

--
207961187  by Zhichao Lu:

    Build the first stage NMS function in the model builder and pass it to FasterRCNN meta arch.

--
207960608  by Zhichao Lu:

    Internal Change.

--
207927015  by Zhichao Lu:

    Have an option to use the TPU compatible NMS op cl/206673787, in the batch_multiclass_non_max_suppression function. On setting pad_to_max_output_size to true, the output nmsed boxes are padded to be of length max_size_per_class.

    This can be used in first stage Region Proposal Network in FasterRCNN model by setting the first_stage_nms_pad_to_max_proposals field to true in config proto.

--
207809668  by Zhichao Lu:

    Add option to use depthwise separable conv instead of conv2d in FPN and WeightSharedBoxPredictor. More specifically, there are two related configs:
    - SsdFeatureExtractor.use_depthwise
    - WeightSharedConvolutionalBoxPredictor.use_depthwise

--
207808651  by Zhichao Lu:

    Fix the static balanced positive negative sampler's TPU tests

--
207798658  by Zhichao Lu:

    Fixes a post-refactoring bug where the pre-prediction convolution layers in the convolutional box predictor are ignored.

--
207796470  by Zhichao Lu:

    Make slim endpoints visible in FasterRCNNMetaArch.

--
207787053  by Zhichao Lu:

    Refactor ssd_meta_arch so that the target assigner instance is passed into the SSDMetaArch constructor rather than constructed inside.

--

PiperOrigin-RevId: 212389173",pkulzc,b'cla: yes',2018-09-11T23:50:50Z,2018-09-21T23:46:08Z,,,,,,,
5286,Audioset out of date with the current starter code that Youtube-8m provides,"
------------------------

### System information
- **What is the top-level directory of the model you are using**: Audioset
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Stock Example
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux 16.04
- **TensorFlow installed from (source or binary)**: Source
- **TensorFlow version (use command below)**: 1.10
- **Bazel version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: Cuda compilation tools, release 9.0, V9.0.176
- **GPU model and memory**: 6gpu / 112gb RAM
- **Exact command to reproduce**: `python train.py --train_data_pattern='features/audioset_v1_embeddings/bal_train/*.tfrecord' --model=FrameLevelLogisticModel  --frame_features=True --train_dir=$MODEL_DIR/frame_level_logistic_model --feature_names=""audio_embedding"" --feature_sizes=""128"" --batch_size=128`


### Describe the problem
Issues when leveraging the Youtube-8m training models against the Audioset features. When downloading the Audioset tfRecords and running the train.py script for frame level audio youtube videos, I received an error stating `Context feature 'id' is required but could not be found.`

There seems to be a version inconsistency with audioset data and the current Youtube-8m model scripts.

### Source code / logs
Below is the Output from the command.
What we did can also be found in this [Jupyter Notebook](https://colab.research.google.com/drive/1vOR5boy9ZMVMJVe8sWm3K8wbBPDz0PAm)

``` logs
INFO:tensorflow:/job:master/task:0: Tensorflow version: 1.10.1.
INFO:tensorflow:/job:master/task:0: No checkpoint file found. Building a new model.
INFO:tensorflow:No GPUs found. Training on CPU.
INFO:tensorflow:Using batch size of 128 for training.
INFO:tensorflow:Number of training files: 4070.
WARNING:tensorflow:From youtube-8m/train.py:436: __init__ (from tensorflow.python.training.supervisor) is deprecated and will be removed in a future version.
Instructions for updating:
Please switch to tf.train.MonitoredTrainingSession
INFO:tensorflow:/job:master/task:0: Starting managed session.
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Starting standard services.
INFO:tensorflow:Starting queue runners.
INFO:tensorflow:Saving checkpoint to path /frame_level_logistic_model/model.ckpt
INFO:tensorflow:/job:master/task:0: Entering training loop.
INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.InvalidArgumentError'>, Name: , Context feature 'id' is required but could not be found.
	 [[Node: train_input/ParseSingleSequenceExample_6/ParseSingleSequenceExample = ParseSingleSequenceExample[Ncontext_dense=1, Ncontext_sparse=1, Nfeature_list_dense=1, Nfeature_list_sparse=0, Tcontext_dense=[DT_STRING], context_dense_shapes=[[]], context_sparse_types=[DT_INT64], feature_list_dense_shapes=[[]], feature_list_dense_types=[DT_STRING], feature_list_sparse_types=[], _device=""/job:localhost/replica:0/task:0/device:CPU:0""](train_input/ReaderReadV2_6:1, train_input/ParseSingleSequenceExample_6/ParseSingleSequenceExample/feature_list_dense_missing_assumed_empty, train_input/ParseSingleSequenceExample_6/ParseSingleSequenceExample/context_sparse_keys_0, train_input/ParseSingleSequenceExample_6/ParseSingleSequenceExample/context_dense_keys_0, train_input/ParseSingleSequenceExample_6/ParseSingleSequenceExample/feature_list_dense_keys_0, train_input/ParseSingleSequenceExample_6/ParseSingleSequenceExample/feature_list_dense_missing_assumed_empty, train_input/ParseSingleSequenceExample_6/ParseSingleSequenceExample/debug_name)]]
INFO:tensorflow:global_step/sec: 0
INFO:tensorflow:/frame_level_logistic_model/model.ckpt-0 is not in all_model_checkpoint_paths. Manually adding it.
INFO:tensorflow:/job:master/task:0: Done training -- epoch limit reached.
Traceback (most recent call last):
  File ""youtube-8m/train.py"", line 696, in <module>
    app.run()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run
    _sys.exit(main(argv))
  File ""youtube-8m/train.py"", line 687, in main
    FLAGS.export_model_steps).run(start_new_model=FLAGS.start_new_model)
  File ""youtube-8m/train.py"", line 491, in run
    task_as_string(self.task))
  File ""/usr/lib/python2.7/contextlib.py"", line 24, in __exit__
    self.gen.next()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/supervisor.py"", line 1005, in managed_session
    self.stop(close_summary_writer=close_summary_writer)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/supervisor.py"", line 833, in stop
    ignore_live_threads=ignore_live_threads)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/coordinator.py"", line 389, in join
    six.reraise(*self._exc_info_to_raise)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/queue_runner_impl.py"", line 252, in _run
    enqueue_callable()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1205, in _single_operation_run
    self._call_tf_sessionrun(None, {}, [], target_list, None)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1350, in _call_tf_sessionrun
    run_metadata)
tensorflow.python.framework.errors_impl.InvalidArgumentError: Name: , Context feature 'id' is required but could not be found.
	 [[Node: train_input/ParseSingleSequenceExample_6/ParseSingleSequenceExample = ParseSingleSequenceExample[Ncontext_dense=1, Ncontext_sparse=1, Nfeature_list_dense=1, Nfeature_list_sparse=0, Tcontext_dense=[DT_STRING], context_dense_shapes=[[]], context_sparse_types=[DT_INT64], feature_list_dense_shapes=[[]], feature_list_dense_types=[DT_STRING], feature_list_sparse_types=[], _device=""/job:localhost/replica:0/task:0/device:CPU:0""](train_input/ReaderReadV2_6:1, train_input/ParseSingleSequenceExample_6/ParseSingleSequenceExample/feature_list_dense_missing_assumed_empty, train_input/ParseSingleSequenceExample_6/ParseSingleSequenceExample/context_sparse_keys_0, train_input/ParseSingleSequenceExample_6/ParseSingleSequenceExample/context_dense_keys_0, train_input/ParseSingleSequenceExample_6/ParseSingleSequenceExample/feature_list_dense_keys_0, train_input/ParseSingleSequenceExample_6/ParseSingleSequenceExample/feature_list_dense_missing_assumed_empty, train_input/ParseSingleSequenceExample_6/ParseSingleSequenceExample/debug_name)]]
```
",NathanielRose,None,2018-09-11T17:58:13Z,2020-06-09T15:35:05Z,,,,,,,
5272,A bug of argmax_matcher.ArgMaxMatcher when force_match_for_each_row = True,"### Describe the problem
In method `object_detection.core.target_assigner.TargetAssigner.assign`, when `match_quality_matrix` has one or many zero rows (which can happen due to `object_detection.inputs.pad_input_data_to_static_shapes`), in the line 180 `match = self._matcher.match(match_quality_matrix, **params)` where `self._matcher` is `argmax_matcher.ArgMaxMatcher` with `force_match_for_each_row = True`, `match` will  give an unexpected match.This is because the `matchers.argmax_atcher.ArgMaxMatcher._match` 
```
if self._force_match_for_each_row:
        similarity_matrix_shape = shape_utils.combined_static_and_dynamic_shape(
            similarity_matrix)
        force_match_column_ids = tf.argmax(similarity_matrix, 1,
                                           output_type=tf.int32)
        force_match_column_indicators = tf.one_hot(
            force_match_column_ids, depth=similarity_matrix_shape[1])
        force_match_row_ids = tf.argmax(force_match_column_indicators, 0,
                                        output_type=tf.int32)
        force_match_column_mask = tf.cast(
            tf.reduce_max(force_match_column_indicators, 0), tf.bool)
        final_matches = tf.where(force_match_column_mask,
                                 force_match_row_ids, matches)
        return final_matches
``` 
is implemented unproperly.
### Source code / logs
```
import numpy as np
import tensorflow as tf
from object_detection.matchers import argmax_matcher

match_quality_matrix = np.zeros((4, 10))
match_quality_matrix[0][1] = 0.9
match_quality_matrix[1][9] = 0.7
match_quality_matrix_tensor = tf.constant(match_quality_matrix, dtype=tf.float32)
matcher = argmax_matcher.ArgMaxMatcher(matched_threshold=0.7,
                                           unmatched_threshold=0.3,
                                           force_match_for_each_row=True,
                                           use_matmul_gather=False)

match = matcher.match(match_quality_matrix_tensor)
sess = tf.InteractiveSession()
sess.run(match.match_results)
```
The expected result is:
```
[ -1,  0, -1, -1, -1, -1, -1, -1, -1,  1]
```
BUT the code gives:
```
[ 2,  0, -1, -1, -1, -1, -1, -1, -1,  1]
```",RobertLexis,b'stat:awaiting response',2018-09-10T02:56:02Z,2020-02-07T18:52:48Z,,,,,,,
5267,Tensorflow GPU not using GPU,"
[object_detection_tutorial2.zip](https://github.com/tensorflow/models/files/2363376/object_detection_tutorial2.zip)

Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
The form below must be filled out.
Here's why we have that policy: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

System information
What is the top-level directory of the model you are using:
Object detection
Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
Yes, just to insert a video instead of using the webcam
OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Windows 10 64 bits (Last version)
TensorFlow installed from (source or binary):
Binary
TensorFlow version (use command below):
v1.8.0-0-g93bc2e2072' 1.8.0
Bazel version (if compiling from source):
N/A
CUDA/cuDNN version:
CUDA: cuda_9.0.176
cuDNN: cudnn-9.0
GPU model and memory:
MSI Geforce GTX 1070 8gb
Exact command to reproduce:
N/A
You can collect some of this information using our environment capture script:
https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

Describe the problem
Long ago I come with this problem, and tried everything, reinstall, format the PC and again reinstall but my software runs with CPU only, just use one (9% of GPU)
I added these sentences:
       device_name = tf.test.gpu_device_name ()

       print ('Found GPU at: {}'. format (device_name))
And it clearly says that it uses GPU = ""Found GPU at: / device: GPU: 0""
I can not get my programs to work with GPU and this takes too long, since the video is less than 30 fps

Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
The code I use is in a .zip file
PS: I'm sorry for my English

",magick2,None,2018-09-08T14:26:39Z,2020-02-07T18:47:58Z,,,,,,,
5264,from object_detection.protos import input_reader_pb2 ImportError: cannot import name 'input_reader_pb2',"Hey. I'm trying to run train.py from _models/research/object_detection/legacy_ but it's throwing this error

`from object_detection.protos import input_reader_pb2
ImportError: cannot import name 'input_reader_pb2'`
 
I did the following as well but no luck

From tensorflow/models/research/
protoc object_detection/protos/*.proto --python_out=.

From tensorflow/models/research/
export PYTHONPATH=$PYTHONPATH:`pwd`:`pwd`/slim

PS: I also run the model_main.py from _models/research/object_detection_ but the same error.",hammadullah125,b'type:bug',2018-09-07T09:51:48Z,2020-08-20T08:24:17Z,,,,,,,
5249,[feature request] freeze classification weights when training for detection,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

I have trained mobilenet model which has a pretty good mAP, would like to train mobilenet-ssd model on top of that. I understand that I can load it as a fine-tune checkpoint and set from_detection_checkpoint to false. However the result is not good. Looks like when start training I need to freeze mobilenet weights during the first few epoch and then unfreeze them. However I don't see such an entry in the config file.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",tensorbuffer,None,2018-09-05T15:54:55Z,2020-02-12T04:43:12Z,,,,,,,
5238,Why are multiple-gpu slower than single gpu,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
I trained textsum at 4-gpus and 1-gpu ,I found 4-gpus is slower than single gpu , and they all have low utilization, anyone can help me resolve this problem?",YOUYOUYOU,None,2018-09-04T10:07:30Z,2018-09-04T19:51:35Z,,,,,,,
5231,slim inception preprocessing wrapper function miss central_fraction arguments,"Since it is a very obvious bug, I didn't provide my system information.

### Describe the problem
Can't fully use the  preprocess_for_eval function in models/research/slim/preprocessing/inception_preprocessing.py  by the wrapper function preprocess_image. Specifically, we can't adjust the central crop property by this wrapper function, because of missing the 'central_fraction' parameter.

###
```
Traceback (most recent call last):
  File ""extract_features.py"", line 136, in <module>
    main(parser.parse_args())
  File ""extract_features.py"", line 132, in main
    extract_features(args)
  File ""extract_features.py"", line 69, in extract_features
    pro_image = image_preprocessing_fn(image, eval_image_size, eval_image_size, central_fraction=None, scope=None)
  File ""~/models/research/slim/preprocessing/preprocessing_factory.py"", line 78, in preprocessing_fn
    image, output_height, output_width, is_training=is_training, **kwargs)
TypeError: preprocess_image() got an unexpected keyword argument 'central_fraction'

```
",neouyghur,b'stat:awaiting response',2018-09-03T06:09:52Z,2020-02-07T18:47:56Z,,,,,,,
5222,the problem of json.encoder.FLOAT_REPR not exist in python3.x,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",cjr0106,None,2018-09-01T07:02:45Z,2020-02-12T04:44:22Z,,,,,,,
5218,The problem of coco_evaluation_test.py,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",cjr0106,b'stat:awaiting model gardener',2018-08-31T12:17:53Z,2020-02-07T18:50:51Z,,,,,,,
5213,resume training for object detection,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
object detection
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
no
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
ubuntu 16.04
- **TensorFlow installed from (source or binary)**:
binary
- **TensorFlow version (use command below)**:
tensorflow-gpu=1.9.0
- **Bazel version (if compiling from source)**:
n/a
- **CUDA/cuDNN version**:
9.0
- **GPU model and memory**:
nvidia 1080ti
- **Exact command to reproduce**:
python model_main.py

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

I'm training ssdlite model with mobileNetV2 on coco dataset, everything is default. The training was interrupted and killed and now I want to restore the model and resume training. 

However, the current script does not support this feature. I tried to set fine_tune_checkpoint_type: ""detection"", the model is loaded but the script only runs evaluation without training. Is there a way to resume training?

I've seen this https://github.com/tensorflow/models/issues/4116 post but I'm not sure which part was modified and train.py seemed to be moved to legacy folder now. 

Specifically, I just want to ask 1. Is there a feature for resuming training? If so, which flags should I set? 2. If there is no such feature, could you give some pointers on how to add this feature? I can make a PR if needed. 

Thanks.",junweima,None,2018-08-31T03:16:15Z,2018-08-31T16:33:39Z,,,,,,,
5207,"Weird ""decoder_output_stride"" flag issue while exporting model in deeplab","### System information
- **What is the top-level directory of the model you are using**: deeplab
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: binary (using pip)
- **TensorFlow version (use command below)**: 1.7.0
- **Bazel version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: CUDA 9.0/cudnn7
- **GPU model and memory**: 8GB
- **Exact command to reproduce**:
python export_model.py \
      --logtostderr \
      --atrous_rates=12 \
      --atrous_rates=24 \
      --atrous_rates=36 \
      --output_stride=8 \
      --checkpoint_path=""/models/model.ckpt-30000"" \
      --export_path=""frozen/test_frozen.pb"" \
      --model_variant=""mobilenet_v2"" \
      --num_classes=5 \
      --crop_size=241 \
      --crop_size=321 \
      --inference_scales=1.0

### Describe the problem
I have trained `deeplab` on my custom dataset. The training works without any problem.

python train.py \
              --logtostderr \
              --training_number_of_steps=30000 \
              --train_split=""train"" \
              --model_variant=""mobilenet_v2"" \
              --atrous_rates=12 \
              --atrous_rates=24 \
              --atrous_rates=36 \
              --output_stride=8 \
              --decoder_output_stride=4 \
              --train_crop_size=241 \
              --train_crop_size=321 \
              --train_batch_size=24 \
              --dataset=""${DATASET}"" \
              --initialize_last_layer=false \
              ...

Then I used `vis.py` and `eval.py` similarly both work fine. I get all the predictions properly.

Now when I try to freeze the model using `export_model.py` (with the stated arguments), I get the frozen model. But the predictions from the model is always all 0 (background class). I had [another issue](https://github.com/tensorflow/models/issues/5192) opened but that time I had no idea why it was failing. After tons of debugging. This is what I found...

**If I use the `export_model.py` without `--decoder_output_stride=4` flag (as used in training) it always outputs 0.**

After finding this I think that this problem is not specific to `deeplab`. Because there is no direct use of this flag in the `deeplab` code. Anyone can mistakenly skip this flag while freezing and waste hours in debugging, I think this flag should be added on the [doc](https://github.com/tensorflow/models/blob/master/research/deeplab/g3doc/export_model.md) commands for exporting the model as the training, vis and eval [commands](https://github.com/tensorflow/models/blob/master/research/deeplab/g3doc/pascal.md) include the flag.

Thanks.",sumsuddin,None,2018-08-30T10:40:53Z,2019-10-12T08:56:42Z,,,,,,,
5198,Bug residual bottleneck unit implementation in slim. ,"### System information
- **What is the top-level directory of the model you are using**: N/A
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: N/A
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: N/A
- **TensorFlow installed from (source or binary)**: N/A
- **TensorFlow version (use command below)**: N/A
- **Bazel version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**: N/A

------------------------
### Problem Description
In the documentation of the `bottleneck()` function here: https://github.com/tensorflow/models/blob/master/research/slim/nets/resnet_v2.py

It says the bottleneck unit is a direct adaptation of figure 1)(b) here: https://arxiv.org/pdf/1603.05027.pdf

However, there are differences, for instance, the code has only one batch norm layer whereas the figure has two. ",zeyademam,None,2018-08-28T22:34:54Z,2020-02-07T18:52:32Z,,,,,,,
5192,Wrong prediction using deeplab custom dataset trained model after freezing,"### System information
- **What is the top-level directory of the model you are using**: deeplab
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: binary (using pip)
- **TensorFlow version (use command below)**: 1.7.0
- **Bazel version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: CUDA 9.0/cudnn7
- **GPU model and memory**: 8GB
- **Exact command to reproduce**:
python export_model.py \
      --logtostderr \
      --atrous_rates=12 \
      --atrous_rates=24 \
      --atrous_rates=36 \
      --output_stride=8 \
      --checkpoint_path=""/models/model.ckpt-30000"" \
      --export_path=""frozen/test_frozen.pb"" \
      --model_variant=""mobilenet_v2"" \
      --num_classes=5 \
      --crop_size=241 \
      --crop_size=321 \
      --inference_scales=1.0

### Describe the problem
I am trying to train deeplab on my custom dataset. All of my training images are of size 320 X 240. So I used the following command to train. The training works without any problem.

python train.py \
              --logtostderr \
              --training_number_of_steps=30000 \
              --train_split=""train"" \
              --model_variant=""mobilenet_v2"" \
              --atrous_rates=12 \
              --atrous_rates=24 \
              --atrous_rates=36 \
              --output_stride=8 \
              --decoder_output_stride=4 \
              --train_crop_size=241 \
              --train_crop_size=321 \
              --train_batch_size=24 \
              --dataset=""${DATASET}"" \
              --initialize_last_layer=false \
              ...

Then I used `vis.py` and `eval.py` similarly both work fine. I get all the predictions properly.

Now when I try to freeze the model using `export_model.py` (with the stated arguments), I get the frozen model. But the predictions from the model is always all 0 (background class). The script I used was with some modification of the `deeplab_demo.ipynb` script. I tested it by freezing the pascal_voc model. It worked fine.

**But while using my custom dataset model even though `vis.py` works, it doesn't work after freezing. I get all 0.**

I know there is too little information but I'm not sure how to debug this problem.",sumsuddin,None,2018-08-27T10:28:24Z,2019-08-11T16:46:46Z,,,,,,,
5190,deeplabv3+ eval.py result,"

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

**Even though the loss value falls. the same mIOU value(0.03491) always comes out**

 python train.py --logtostderr 
--training_number_of_steps=30000 
--train_split='train' 
--model_variant='xception_65' 
--atrous_rates=6 
--atrous_rates=12 
--atrous_rates=18 
--output_stride=16 
--decoder_output_stride=4 
--train_crop_size=513 
--train_crop_size=513 
--train_batch_size=5 
--dataset='pascal_voc_seg' 
--train_logdir=""/storage/models-master/research/deeplab/datasets/pascal_voc_seg/exp/train_on_train_set/train/DGX_0824_1"" 
--dataset_dir=""/storage/models-master/research/deeplab/datasets/pascal_voc_seg/tfrecord"" 
--tf_initial_checkpoint=""/storage/models-master/research/deeplab/datasets/pascal_voc_seg/init_models/deeplabv3_pascal_train_aug/model.ckpt"" --fine_tune_batch_norm=false

python eval.py --logtostderr 
--eval_split='val' 
--model_variant='xception_65' 
--atrous_rates=6 
--atrous_rates=12 
--atrous_rates=18 
--output_stride=16 
--deocder_output_stride=4 
--eval_crop_size=513 
--eval_crop_size=513 
--checkpoint_dir=""/storage/models-master/research/deeplab/datasets/pascal_voc_seg/exp/train_on_train_set/train/DGX_0824_1"" 
--eval_logdir=""/storage/models-master/research/deeplab/datasets/pascal_voc_seg/exp/train_on_train_set/val/DGX_0824_1"" 
--dataset_dir=""/storage/models-master/research/deeplab/datasets/pascal_voc_seg/tfrecord"" 
--max_number_of_evaluations=1

Total_loss is about 0.16~0.18
mIOU 0.03491

-----------------------------------------------------------------------------------------------------------

python train.py --logtostderr 
--training_number_of_steps=10 
--train_split='train' 
--model_variant='xception_65' 
--atrous_rates=6 
--atrous_rates=12 
--atrous_rates=18 
--output_stride=16 
--decoder_output_stride=4 
--train_crop_size=513 
--train_crop_size=513 
--train_batch_size=5 
--dataset='pascal_voc_seg' 
--train_logdir=""/storage/SEG_jhm2/models-master/research/deeplab/datasets/pascal_voc_seg/exp/train_on_train_set/train/Titan_0827_test"" 
--dataset_dir=""/storage/SEG_jhm2/models-master/research/deeplab/datasets/pascal_voc_seg/tfrecord"" --tf_initial_checkpoint=""/storage/SEG_jhm2/models-master/research/deeplab/datasets/pascal_voc_seg/init_models/deeplabv3_pascal_train_aug/model.ckpt"" --fine_tune_batch_norm=false

python eval.py --logtostderr 
--eval_split='val' 
--model_variant='xception_65' 
--atrous_rates=6 
--atrous_rates=12 
--atrous_rates=18 
--output_stride=16 
--deocder_output_stride=4 
--eval_crop_size=513 
--eval_crop_size=513 
--checkpoint_dir=""/storage/SEG_jhm2/models-master/research/deeplab/datasets/pascal_voc_seg/exp/train_on_train_set/train/Titan_0827_test"" 
--eval_logdir=""/storage/SEG_jhm2/models-master/research/deeplab/datasets/pascal_voc_seg/exp/train_on_train_set/val/Titan_0827_test"" 
--dataset_dir=""/storage/SEG_jhm2/models-master/research/deeplab/datasets/pascal_voc_seg/tfrecord"" --max_number_of_evaluations=1

mIOU 0.03491",ghost,b'stat:awaiting response',2018-08-27T01:16:23Z,2019-07-15T09:48:31Z,,,,,,,
5183,Fix bug on distributed training in mnist using MirroredStrategy API,I tried to run distributed tensorflow with mnist but it did not work. So I fixed such problem with MirroredStrategy API.,parkjaeman,b'cla: yes',2018-08-24T09:37:42Z,2018-08-28T23:08:07Z,,,,,,,
5181,Does 'VOC 2012 train_aug set' contain validation data??,"

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

![image](https://user-images.githubusercontent.com/42659973/44569696-3206e800-a7b6-11e8-90e1-710143ce793a.png)
Has the model pretrained with train_aug been pretrained as validation data?
",ghost,None,2018-08-24T06:57:41Z,2018-08-24T09:24:42Z,,,,,,,
5180,Is it possible to get 94% mIOU of pascal voc 'val' data?,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:

- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
NO
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Ubuntu 16.04
- **TensorFlow installed from (source or binary)**:
binary
- **TensorFlow version (use command below)**:
1.10
- **Bazel version (if compiling from source)**:

- **CUDA/cuDNN version**:
cuda:8.0-cudnn6

- **GPU model and memory**:
Titan 12194MiB
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

I trained deeplabv3+ and got about 94% mIOU results of PASCAL voc val data Is that possible result?

I am worried that there is something wrong with it because it is higher than I thought

I used the deeplabv3 + code provided by tensorflow

I start training from pre-trained deeplabv3+ provided by tensorflow

Below is the hyperparameter value

python train.py --logtostderr \
--train_split=""trainval"" \
--model_variant=""xception_65"" \
--atrous_rates=6  \
--atrous_rates=12 \
--atrous_rates=18 \ 
--output_stride=16 \
--decoder_ouput_stride=4 \
--train_crop_size=513 \
--train_crop_size=513 \
--train_batch_size=5 \                                             
--training_number_of_steps=30000 \ 
--fine_tune_batch_norm=false \
--tf_initial_checkpoint=""/storage/models-master/research/deeplab/datasets/pascal_voc_seg/init_models/deeplabv3_pascal_train_aug/model.ckpt"" \
--train_logdir=""/storage/models-master/research/deeplab/datasets/pascal_voc_seg/exp/train_on_trainval_set/train0821_1"" \
--dataset_dir=""/storage/models-master/research/deeplab/datasets/pascal_voc_seg/tfrecord"" \

Below is the hyperparameter of eval.py

python eval.py
--logtostderr
--eval_split='val'
--model_variant='xception_65'
--atrous_rates=6
--atrous_rates=12
--atrous_rates=18
--output_stride=16
--deocder_output_stride=4
--eval_crop_size=513
--eval_crop_size=513
--checkpoint_dir=""/storage/models-master/research/deeplab/datasets/pascal_voc_seg/exp/train_on_trainval_set/train0821_1""
--eval_logdir=""/storage/models-master/research/deeplab/datasets/pascal_voc_seg/exp/train_on_trainval_set/val""
--dataset_dir=""/storage/models-master/research/deeplab/datasets/pascal_voc_seg/tfrecord""
--max_number_of_evaluations=1


### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",ghost,None,2018-08-23T23:50:06Z,2018-08-27T22:08:05Z,,,,,,,
5165,Loss increases suddenly after training the model nicely for ~30 mins ,"### System information
- **What is the top-level directory of the model you are using**: models/research/object-detection
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04.4 LTS
- **TensorFlow installed from (source or binary)**: pip install tensorflow-gpu
- **TensorFlow version (use command below)**: 1.8.0    
- **GPU model and memory**: GeForce GTX 980 Ti
- **CUDA/cuDNN version**: N/A
- **Bazel version**: N/A
- **Have I written custom code**: N/A
- **Exact command to reproduce**: python train.py --logtostderr --train_dir=training/ --pipeline_config_path=training/faster_rcnn_resnet101_coco.config --num_clones=2 --ps_tasks=1

### Describe the problem
I gathered labelled data for object detection using my own camera, trained the model, ran predictions, everything works okay. Then I decided to supplement the data with labelled data from Open Images Dataset: cleaned up data, added zero padding to resize it to 1920x1080, and trained on it. The loss decreased steadily, as expected, for ~30 mins, after which it suddenly increases and the model never converges after that (see attached TotalLoss log plots).

Could someone tell me what's wrong? I'm not sure if it is a bug or if I'm doing anything wrong.


**ZOOMED IN :**

![Zoomed In](https://user-images.githubusercontent.com/25410696/44469230-0557a280-a5f5-11e8-88e7-f42a4874f096.jpg)

**ZOOMED OUT :**

![Zoomed Out](https://user-images.githubusercontent.com/25410696/44469258-12749180-a5f5-11e8-8def-2e69a6b80f61.jpg)
   ",harshilpatel312,b'stat:awaiting maintainer',2018-08-22T14:24:23Z,2020-02-07T18:51:22Z,,,,,,,
5154,Keypointnet Training,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
research/keypointnet
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
MacBook Pro 13
- **TensorFlow installed from (source or binary)**:

source

- **TensorFlow version (use command below)**:
1.10
- **Bazel version (if compiling from source)**:
no
- **CUDA/cuDNN version**:
no
- **GPU model and memory**:
no


How do I prepare the dataset to annotate for training keypointnet?",Zumbalamambo,b'stat:awaiting response',2018-08-21T12:14:51Z,2018-08-21T21:49:10Z,,,,,,,
5137,f,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",BenSoltau,None,2018-08-19T13:25:36Z,2018-08-21T02:59:02Z,,,,,,,
5132,add_n ValueError,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",lizaigaoge550,b'stat:awaiting response',2018-08-18T11:04:40Z,2020-02-07T18:47:47Z,,,,,,,
5129,Slim: Data Lost or Disorderly When Reading Data from tfrecord Files,"### System information
- **What is the top-level directory of the model you are using**: Research/Slim
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
 Yes, we tested the problem with few parameters changed, a tfPrint() to display data, and some tfrecord file with batch of same lable (please see my situation below)
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.8.0
- **Bazel version (if compiling from source)**: 0.15.0
- **CUDA/cuDNN version**: None (CPU used)
- **GPU model and memory**: None (CPU used)
- **Exact command to reproduce**: use fine-tuning_inception-v3_on_flowers shell script to run the example but need to generate tfrecord file with serial tags

### Describe the problem
Our datasets are from videos so we hope they can be read in their original order. We have 200 videos and we extracted 32 frames from each of them, tagging them with the same tag number for the same video. After disable the shuffle function, we still found that the order is changed or some data are missing as below when doing training. We used `tf.Print()` to print out the tags after `tf.train.batch()`. It appeared like:
`labels=[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0]
....
labels=[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1]
....
labels=[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2]
....`
It didn't happen in each data read, just randomly decrease a few tags sometimes. When we applied the same method to evaluation, it was totally fine to show the result we want, like:
`labels=[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
labels=[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]
labels=[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]`
A bunch of 32 tags was read together, no data missing or disorderly.
I am not sure if it is a bug or not? Also, how can we make sure our data is read in order and without missing?
Thanks

### Source code / logs
in `train_image_classifier.py`
##############################################################
Create a dataset provider that loads data from the dataset
##############################################################
`with tf.device(deploy_config.inputs_device()):
  provider = slim.dataset_data_provider.DatasetDataProvider(
      dataset,
      num_readers=FLAGS.num_readers,
      shuffle=_data_shuffle,
      common_queue_capacity=20 * FLAGS.batch_size,
      common_queue_min=10 * FLAGS.batch_size)
  [image, label] = provider.get(['image', 'label'])
  label -= FLAGS.labels_offset
  train_image_size = FLAGS.train_image_size or network_fn.default_image_size

  image = image_preprocessing_fn(image, train_image_size, train_image_size)

  images, labels = tf.train.batch(
      [image, label],
      batch_size=FLAGS.batch_size,
      num_threads=FLAGS.num_preprocessing_threads,
      capacity=5 * FLAGS.batch_size)

  labels = tf.Print(labels,[labels], ""....labels="",summarize=32)

  labels = slim.one_hot_encoding(
      labels, dataset.num_classes - FLAGS.labels_offset)
  batch_queue = slim.prefetch_queue.prefetch_queue(
      [images, labels], capacity=2 * deploy_config.num_clones) `

Only `tf.Print()` is added in it.

We added `shuffle=false` and set `num_readers=1` in the script, trying to let the data_provider() read data in sequence without parallel jobs. For tf.train.batch(), `num_preprocessing_threads=1` is also set in script.",arlcurten,None,2018-08-17T21:20:58Z,2020-01-29T23:24:35Z,,,,,,,
5118,deeplab: some question about Data augmentation,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:deeplab
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:None
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**:source
- **TensorFlow version (use command below)**:1.9.0
- **Bazel version (if compiling from source)**:None
- **CUDA/cuDNN version**:9.0
- **GPU model and memory**:10GB
- **Exact command to reproduce**:None

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.

as the papers describes: We apply data augmentation by
randomly scaling the input images (from 0.5 to 2.0) and
randomly left-right flipping during training.
my question is :why only use these two methods? what about increase or decrease brightness ?",DaPenggg,None,2018-08-17T02:03:28Z,2018-09-13T09:18:55Z,,,,,,,
5107,Potential documentation error in custom estimators,"

### System information
- **What is the top-level directory of the model you are using**:
https://github.com/tensorflow/models/blob/master/samples/core/get_started/premade_estimator.py

- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
(not really relevant)

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

There seems to be a problem in the documentation examples but I'm not sure, thus I'm filing an issue.

At the time of writing, the following guide gives the following code example:
https://www.tensorflow.org/guide/custom_estimators

```
def train_input_fn(features, labels, batch_size):
    """"""An input function for training""""""
    # Convert the inputs to a Dataset.
    dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))

    # Shuffle, repeat, and batch the examples.
    dataset = dataset.shuffle(1000).repeat().batch(batch_size)

    # Return the read end of the pipeline.
    return dataset.make_one_shot_iterator().get_next()
```

1. It says ""Our custom Estimator implementation uses the same input function as our pre-made Estimator implementation, from iris_data.py.""
However, iris_data.py does not call make_one_shot_iterator().get_next()

2. Is the make_one_shot_iterator().get_next() call intended to be there? My understanding from this is that input_fn is called exactly once, and the way the function is currently structured, this is going return a single iteration of `batch_size` of the Iterator to train on, which doesn't seem quite right...you'd want to return the whole dataset, right?

Either way, this seems to contradict other examples throughout the guides (and iris_data.py) where the whole Dataset object is returned.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",louisrli,b'help wanted type:docs',2018-08-16T08:44:39Z,2019-01-16T23:53:37Z,,,,,,,
5083,[Object Detection] Assign requires shapes of both tensors to match.,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**: tensorflow/models/research
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Mac OS 10.13.6
- **TensorFlow installed from (source or binary)**: pip install
- **TensorFlow version (use command below)**: 1.9
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**: No
- **Exact command to reproduce**: python object_detection/model_main.py     --pipeline_config_path=${PIPELINE_CONFIG_PATH}     --model_dir=${MODEL_DIR}     --num_train_steps=${NUM_TRAIN_STEPS}     --num_eval_steps=${NUM_EVAL_STEPS}     --alsologtostderr


You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
I am trying to train an object detection task using the ssd_mobilenet_v1_coco_2018_01_28 model. I am following the instructions given here (https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/running_locally.md). 
I have a directory structure that looks like this:
+data
- train.tfrecord
- test.tfrecord
- label_map.pbtxt
+models
++ ssd_mobilenet_v1_coco_2018_01_28
-checkpoints
-frozen_inference_graph.pb
-model.ckpt
-pipeline.config



### Source code / logs
/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/h5py/__init__.py:34: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  from ._conv import register_converters as _register_converters
/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/h5py/__init__.py:43: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  from . import h5a, h5d, h5ds, h5f, h5fd, h5g, h5r, h5s, h5t, h5p, h5z
/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/h5py/_hl/group.py:24: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  from .. import h5g, h5i, h5o, h5r, h5t, h5l, h5p
/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/scipy/sparse/lil.py:16: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  from . import _csparsetools
/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/scipy/sparse/csgraph/__init__.py:167: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  from ._shortest_path import shortest_path, floyd_warshall, dijkstra,\
/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/scipy/sparse/csgraph/_validation.py:5: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  from ._tools import csgraph_to_dense, csgraph_from_dense,\
/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/scipy/sparse/csgraph/__init__.py:169: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  from ._traversal import breadth_first_order, depth_first_order, \
/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/scipy/sparse/csgraph/__init__.py:171: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  from ._min_spanning_tree import minimum_spanning_tree
/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/scipy/sparse/csgraph/__init__.py:172: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  from ._reordering import reverse_cuthill_mckee, maximum_bipartite_matching, \
/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/scipy/linalg/basic.py:17: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  from ._solve_toeplitz import levinson
/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/scipy/linalg/__init__.py:191: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  from ._decomp_update import *
/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/scipy/special/__init__.py:640: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  from ._ufuncs import *
/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/scipy/special/_ellip_harm.py:7: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  from ._ellip_harm_2 import _ellipsoid, _ellipsoid_norm
/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/scipy/optimize/_numdiff.py:8: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  from ._group_columns import group_dense, group_sparse
/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/scipy/interpolate/_bsplines.py:9: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  from . import _bspl
/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/scipy/spatial/__init__.py:94: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  from .ckdtree import *
/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/scipy/spatial/__init__.py:95: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  from .qhull import *
/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/scipy/spatial/_spherical_voronoi.py:18: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  from . import _voronoi
/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/scipy/spatial/distance.py:121: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  from . import _hausdorff
/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/scipy/ndimage/measurements.py:36: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  from . import _ni_label
/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/pandas/__init__.py:7: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility
  from . import hashtable, tslib, lib
/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/pandas/__init__.py:7: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility
  from . import hashtable, tslib, lib
/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/pandas/core/index.py:13: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility
  import pandas.index as _index
/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/pandas/core/index.py:13: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility
  import pandas.index as _index
/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/pandas/sparse/array.py:16: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility
  from pandas._sparse import BlockIndex, IntIndex
/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/pandas/sparse/array.py:16: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility
  from pandas._sparse import BlockIndex, IntIndex
/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/pandas/io/parsers.py:26: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility
  import pandas.parser as _parser
/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/pandas/io/parsers.py:26: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility
  import pandas.parser as _parser
/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/pandas/io/packers.py:63: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility
  from pandas.msgpack import Unpacker as _Unpacker, Packer as _Packer
/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/pandas/io/packers.py:63: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility
  from pandas.msgpack import Unpacker as _Unpacker, Packer as _Packer
/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/matplotlib/__init__.py:1405: UserWarning: 
This call to matplotlib.use() has no effect because the backend has already
been chosen; matplotlib.use() must be called *before* pylab, matplotlib.pyplot,
or matplotlib.backends is imported for the first time.

  warnings.warn(_use_error_msg)
/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/sklearn/utils/__init__.py:10: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  from .murmurhash import murmurhash3_32
/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/sklearn/utils/__init__.py:10: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192, got 176
  from .murmurhash import murmurhash3_32
/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/scipy/stats/_continuous_distns.py:17: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  from . import _stats
/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/sklearn/utils/extmath.py:24: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  from ._logistic_sigmoid import _log_logistic_sigmoid
/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/sklearn/utils/extmath.py:24: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192, got 176
  from ._logistic_sigmoid import _log_logistic_sigmoid
/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/sklearn/utils/extmath.py:26: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  from .sparsefuncs_fast import csr_row_norms
/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/sklearn/utils/extmath.py:26: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192, got 176
  from .sparsefuncs_fast import csr_row_norms
/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/sklearn/metrics/cluster/supervised.py:24: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  from .expected_mutual_info_fast import expected_mutual_information
/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/sklearn/metrics/cluster/supervised.py:24: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192, got 176
  from .expected_mutual_info_fast import expected_mutual_information
/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/sklearn/metrics/pairwise.py:29: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  from .pairwise_fast import _chi2_kernel_fast, _sparse_manhattan
/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/sklearn/metrics/pairwise.py:29: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192, got 176
  from .pairwise_fast import _chi2_kernel_fast, _sparse_manhattan
WARNING:tensorflow:Estimator's model_fn (<function model_fn at 0x123ea92a8>) includes params argument, but params are not passed to Estimator.
2018-08-13 20:12:12.931472: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
Traceback (most recent call last):
  File ""object_detection/model_main.py"", line 101, in <module>
    tf.app.run()
  File ""/Users/manishrai/Library/Python/2.7/lib/python/site-packages/tensorflow/python/platform/app.py"", line 125, in run
    _sys.exit(main(argv))
  File ""object_detection/model_main.py"", line 97, in main
    tf.estimator.train_and_evaluate(estimator, train_spec, eval_specs[0])
  File ""/Users/manishrai/Library/Python/2.7/lib/python/site-packages/tensorflow/python/estimator/training.py"", line 447, in train_and_evaluate
    return executor.run()
  File ""/Users/manishrai/Library/Python/2.7/lib/python/site-packages/tensorflow/python/estimator/training.py"", line 531, in run
    return self.run_local()
  File ""/Users/manishrai/Library/Python/2.7/lib/python/site-packages/tensorflow/python/estimator/training.py"", line 681, in run_local
    eval_result, export_results = evaluator.evaluate_and_export()
  File ""/Users/manishrai/Library/Python/2.7/lib/python/site-packages/tensorflow/python/estimator/training.py"", line 886, in evaluate_and_export
    hooks=self._eval_spec.hooks)
  File ""/Users/manishrai/Library/Python/2.7/lib/python/site-packages/tensorflow/python/estimator/estimator.py"", line 460, in evaluate
    output_dir=self.eval_dir(name))
  File ""/Users/manishrai/Library/Python/2.7/lib/python/site-packages/tensorflow/python/estimator/estimator.py"", line 1386, in _evaluate_run
    config=self._session_config)
  File ""/Users/manishrai/Library/Python/2.7/lib/python/site-packages/tensorflow/python/training/evaluation.py"", line 209, in _evaluate_once
    session_creator=session_creator, hooks=hooks) as session:
  File ""/Users/manishrai/Library/Python/2.7/lib/python/site-packages/tensorflow/python/training/monitored_session.py"", line 826, in __init__
    stop_grace_period_secs=stop_grace_period_secs)
  File ""/Users/manishrai/Library/Python/2.7/lib/python/site-packages/tensorflow/python/training/monitored_session.py"", line 549, in __init__
    self._sess = _RecoverableSession(self._coordinated_creator)
  File ""/Users/manishrai/Library/Python/2.7/lib/python/site-packages/tensorflow/python/training/monitored_session.py"", line 1012, in __init__
    _WrappedSession.__init__(self, self._create_session())
  File ""/Users/manishrai/Library/Python/2.7/lib/python/site-packages/tensorflow/python/training/monitored_session.py"", line 1017, in _create_session
    return self._sess_creator.create_session()
  File ""/Users/manishrai/Library/Python/2.7/lib/python/site-packages/tensorflow/python/training/monitored_session.py"", line 706, in create_session
    self.tf_sess = self._session_creator.create_session()
  File ""/Users/manishrai/Library/Python/2.7/lib/python/site-packages/tensorflow/python/training/monitored_session.py"", line 477, in create_session
    init_fn=self._scaffold.init_fn)
  File ""/Users/manishrai/Library/Python/2.7/lib/python/site-packages/tensorflow/python/training/session_manager.py"", line 281, in prepare_session
    config=config)
  File ""/Users/manishrai/Library/Python/2.7/lib/python/site-packages/tensorflow/python/training/session_manager.py"", line 195, in _restore_checkpoint
    saver.restore(sess, checkpoint_filename_with_path)
  File ""/Users/manishrai/Library/Python/2.7/lib/python/site-packages/tensorflow/python/training/saver.py"", line 1752, in restore
    {self.saver_def.filename_tensor_name: save_path})
  File ""/Users/manishrai/Library/Python/2.7/lib/python/site-packages/tensorflow/python/client/session.py"", line 900, in run
    run_metadata_ptr)
  File ""/Users/manishrai/Library/Python/2.7/lib/python/site-packages/tensorflow/python/client/session.py"", line 1135, in _run
    feed_dict_tensor, options, run_metadata)
  File ""/Users/manishrai/Library/Python/2.7/lib/python/site-packages/tensorflow/python/client/session.py"", line 1316, in _do_run
    run_metadata)
  File ""/Users/manishrai/Library/Python/2.7/lib/python/site-packages/tensorflow/python/client/session.py"", line 1335, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.InvalidArgumentError: Assign requires shapes of both tensors to match. lhs shape= [1,1,512,141] rhs shape= [1,1,512,273]
	 [[Node: save/Assign_3 = Assign[T=DT_FLOAT, _class=[""loc:@BoxPredictor_0/ClassPredictor/weights""], use_locking=true, validate_shape=true, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](BoxPredictor_0/ClassPredictor/weights, save/RestoreV2:3)]]

Caused by op u'save/Assign_3', defined at:
  File ""object_detection/model_main.py"", line 101, in <module>
    tf.app.run()
  File ""/Users/manishrai/Library/Python/2.7/lib/python/site-packages/tensorflow/python/platform/app.py"", line 125, in run
    _sys.exit(main(argv))
  File ""object_detection/model_main.py"", line 97, in main
    tf.estimator.train_and_evaluate(estimator, train_spec, eval_specs[0])
  File ""/Users/manishrai/Library/Python/2.7/lib/python/site-packages/tensorflow/python/estimator/training.py"", line 447, in train_and_evaluate
    return executor.run()
  File ""/Users/manishrai/Library/Python/2.7/lib/python/site-packages/tensorflow/python/estimator/training.py"", line 531, in run
    return self.run_local()
  File ""/Users/manishrai/Library/Python/2.7/lib/python/site-packages/tensorflow/python/estimator/training.py"", line 681, in run_local
    eval_result, export_results = evaluator.evaluate_and_export()
  File ""/Users/manishrai/Library/Python/2.7/lib/python/site-packages/tensorflow/python/estimator/training.py"", line 886, in evaluate_and_export
    hooks=self._eval_spec.hooks)
  File ""/Users/manishrai/Library/Python/2.7/lib/python/site-packages/tensorflow/python/estimator/estimator.py"", line 460, in evaluate
    output_dir=self.eval_dir(name))
  File ""/Users/manishrai/Library/Python/2.7/lib/python/site-packages/tensorflow/python/estimator/estimator.py"", line 1386, in _evaluate_run
    config=self._session_config)
  File ""/Users/manishrai/Library/Python/2.7/lib/python/site-packages/tensorflow/python/training/evaluation.py"", line 209, in _evaluate_once
    session_creator=session_creator, hooks=hooks) as session:
  File ""/Users/manishrai/Library/Python/2.7/lib/python/site-packages/tensorflow/python/training/monitored_session.py"", line 826, in __init__
    stop_grace_period_secs=stop_grace_period_secs)
  File ""/Users/manishrai/Library/Python/2.7/lib/python/site-packages/tensorflow/python/training/monitored_session.py"", line 549, in __init__
    self._sess = _RecoverableSession(self._coordinated_creator)
  File ""/Users/manishrai/Library/Python/2.7/lib/python/site-packages/tensorflow/python/training/monitored_session.py"", line 1012, in __init__
    _WrappedSession.__init__(self, self._create_session())
  File ""/Users/manishrai/Library/Python/2.7/lib/python/site-packages/tensorflow/python/training/monitored_session.py"", line 1017, in _create_session
    return self._sess_creator.create_session()
  File ""/Users/manishrai/Library/Python/2.7/lib/python/site-packages/tensorflow/python/training/monitored_session.py"", line 706, in create_session
    self.tf_sess = self._session_creator.create_session()
  File ""/Users/manishrai/Library/Python/2.7/lib/python/site-packages/tensorflow/python/training/monitored_session.py"", line 468, in create_session
    self._scaffold.finalize()
  File ""/Users/manishrai/Library/Python/2.7/lib/python/site-packages/tensorflow/python/training/monitored_session.py"", line 212, in finalize
    self._saver = training_saver._get_saver_or_default()  # pylint: disable=protected-access
  File ""/Users/manishrai/Library/Python/2.7/lib/python/site-packages/tensorflow/python/training/saver.py"", line 856, in _get_saver_or_default
    saver = Saver(sharded=True, allow_empty=True)
  File ""/Users/manishrai/Library/Python/2.7/lib/python/site-packages/tensorflow/python/training/saver.py"", line 1284, in __init__
    self.build()
  File ""/Users/manishrai/Library/Python/2.7/lib/python/site-packages/tensorflow/python/training/saver.py"", line 1296, in build
    self._build(self._filename, build_save=True, build_restore=True)
  File ""/Users/manishrai/Library/Python/2.7/lib/python/site-packages/tensorflow/python/training/saver.py"", line 1333, in _build
    build_save=build_save, build_restore=build_restore)
  File ""/Users/manishrai/Library/Python/2.7/lib/python/site-packages/tensorflow/python/training/saver.py"", line 775, in _build_internal
    restore_sequentially, reshape)
  File ""/Users/manishrai/Library/Python/2.7/lib/python/site-packages/tensorflow/python/training/saver.py"", line 453, in _AddShardedRestoreOps
    name=""restore_shard""))
  File ""/Users/manishrai/Library/Python/2.7/lib/python/site-packages/tensorflow/python/training/saver.py"", line 422, in _AddRestoreOps
    assign_ops.append(saveable.restore(saveable_tensors, shapes))
  File ""/Users/manishrai/Library/Python/2.7/lib/python/site-packages/tensorflow/python/training/saver.py"", line 113, in restore
    self.op.get_shape().is_fully_defined())
  File ""/Users/manishrai/Library/Python/2.7/lib/python/site-packages/tensorflow/python/ops/state_ops.py"", line 219, in assign
    validate_shape=validate_shape)
  File ""/Users/manishrai/Library/Python/2.7/lib/python/site-packages/tensorflow/python/ops/gen_state_ops.py"", line 60, in assign
    use_locking=use_locking, name=name)
  File ""/Users/manishrai/Library/Python/2.7/lib/python/site-packages/tensorflow/python/framework/op_def_library.py"", line 787, in _apply_op_helper
    op_def=op_def)
  File ""/Users/manishrai/Library/Python/2.7/lib/python/site-packages/tensorflow/python/framework/ops.py"", line 3414, in create_op
    op_def=op_def)
  File ""/Users/manishrai/Library/Python/2.7/lib/python/site-packages/tensorflow/python/framework/ops.py"", line 1740, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access

InvalidArgumentError (see above for traceback): Assign requires shapes of both tensors to match. lhs shape= [1,1,512,141] rhs shape= [1,1,512,273]
	 [[Node: save/Assign_3 = Assign[T=DT_FLOAT, _class=[""loc:@BoxPredictor_0/ClassPredictor/weights""], use_locking=true, validate_shape=true, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](BoxPredictor_0/ClassPredictor/weights, save/RestoreV2:3)]]
",Manish-rai21bit,None,2018-08-14T01:12:52Z,2018-08-28T19:55:49Z,,,,,,,
5076,Could only save 5 checkpoints w/ model_main.py,"### System information
- **What is the top-level directory of the model you are using**:
research/object_detection
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Ubuntu 18.04
- **TensorFlow installed from (source or binary)**:
Source
- **TensorFlow version (use command below)**:
1.10
- **Bazel version (if compiling from source)**:
0.15.2
- **CUDA/cuDNN version**:
9.2/7.1.4.18
- **GPU model and memory**:
GTX 960/4G
- **Exact command to reproduce**:
python tf_models/research/object_detection/model_main.py --alsologtostderr \
            --pipeline_config_path=ssdlite_mobilenet_v2_coco.config --model_dir=XXX
### Describe the problem
Looks like the new model_main.py hardcodes many parameters. It simply ignores keep_checkpoint_every_n_hours. In another [bug](https://github.com/tensorflow/models/issues/5067), it only exports one image to tensorboard, ignoring
num_visualizations.",YijinLiu,None,2018-08-13T06:39:06Z,2020-07-09T07:08:13Z,,,,,,,
5065,Open Inference graph file as a binary file,"An inference graph file should be opened as a binary file. Please fix a bug reported here. https://github.com/tensorflow/models/issues/2892 , https://github.com/tensorflow/models/issues/3772 and https://github.com/tensorflow/models/issues/3903 .",yukoba,b'cla: yes',2018-08-11T07:40:52Z,2019-02-14T10:20:04Z,,,,,,,
5058,minor bug fix,"- fixed entropy sign 
- changed entropy implementation for numeric stability",raymond-yuan,b'cla: yes',2018-08-10T16:53:25Z,2018-08-30T16:19:18Z,,,,,,,
5053,object_detection training silently exits without doing anything,"------------------------

### System information
- **What is the top-level directory of the model you are using**:
MODEL_DIR=/home/seth/tensorflow/BurmesePython/ssd_inception_v2_coco_2018_01_28
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: running bundled script object_detection/model_main.py
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
# more tf_env.txt 

== cat /etc/issue ===============================================
Linux ubuntu 4.15.0-29-generic #31~16.04.1-Ubuntu SMP Wed Jul 18 08:54:04 UTC 2
018 x86_64 x86_64 x86_64 GNU/Linux
VERSION=""16.04.5 LTS (Xenial Xerus)""
VERSION_ID=""16.04""
VERSION_CODENAME=xenial

== are we in docker =============================================
No

== compiler =====================================================
c++ (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609
Copyright (C) 2015 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.


== uname -a =====================================================
Linux ubuntu 4.15.0-29-generic #31~16.04.1-Ubuntu SMP Wed Jul 18 08:54:04 UTC 2
018 x86_64 x86_64 x86_64 GNU/Linux

== check pips ===================================================
numpy                         1.14.5                
protobuf                      3.6.0                 
tensorflow                    1.10.0                

== check for virtualenv =========================================
True

== tensorflow import ============================================
tf.VERSION = 1.10.0
tf.GIT_VERSION = v1.10.0-0-g656e7a2b34
tf.COMPILER_VERSION = v1.10.0-0-g656e7a2b34
Sanity check: array([1], dtype=int32)

== env ==========================================================
LD_LIBRARY_PATH is unset
DYLD_LIBRARY_PATH is unset

== nvidia-smi ===================================================
./env.sh: line 105: nvidia-smi: command not found

== cuda libs  ===================================================

- **TensorFlow installed from (source or binary)**: installed using pip3
- **TensorFlow version (use command below)**: v1.10.0-0-g656e7a2b34 1.10.0
- **Bazel version (if compiling from source)**: n/a
- **CUDA/cuDNN version**:n/a
- **GPU model and memory**:n/a
- **Exact command to reproduce**:

MODEL_DIR=/home/seth/tensorflow/BurmesePython/ssd_inception_v2_coco_2018_01_28
PIPELINE_CONFIG_PATH=/home/seth/tensorflow/BurmesePython/ssd_inception_v2_coco.config
NUM_TRAIN_STEPS=200000
NUM_EVAL_STEPS=2000
python3 object_detection/model_main.py \
    --pipeline_config_path=${PIPELINE_CONFIG_PATH} \
    --model_dir=${MODEL_DIR} \
    --num_train_steps=${NUM_TRAIN_STEPS} \
    --num_eval_steps=${NUM_EVAL_STEPS} \
    --alsologtostderr

### Describe the problem

Trying to train my model using the tf records I've created.  Seems like processing never begins, but the pipeline.config file is written to the models directory as the timestamp is updated. Modifying my model config file to include broken references to tf record files does not yield an error, so it seems that the training process doesn't ever begin. 

I have modified the model_main.py file to enable logging: tf.logging.set_verbosity(tf.logging.DEBUG)

Running tensorboard in parallel also never observes any activity.

### Source code / logs

```

INFO:tensorflow:Maybe overwriting eval_steps: 2000
INFO:tensorflow:Maybe overwriting train_steps: 200000
INFO:tensorflow:Maybe overwriting retain_original_images_in_eval: True
INFO:tensorflow:Maybe overwriting load_pretrained: True
INFO:tensorflow:Ignoring config override key: load_pretrained
INFO:tensorflow:create_estimator_and_inputs: use_tpu False
INFO:tensorflow:Using config: {'_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f3c53771ba8>, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tf_random_seed': None, '_task_type': 'worker', '_global_id_in_cluster': 0, '_log_step_count_steps': 100, '_save_summary_steps': 100, '_keep_checkpoint_every_n_hours': 10000, '_evaluation_master': '', '_save_checkpoints_secs': 600, '_device_fn': None, '_master': '', '_train_distribute': None, '_is_chief': True, '_task_id': 0, '_model_dir': '/home/seth/tensorflow/BurmesePython/ssd_inception_v2_coco_2018_01_28', '_session_config': None, '_service': None}
WARNING:tensorflow:Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7f3c53712b70>) includes params argument, but params are not passed to Estimator.
INFO:tensorflow:Writing pipeline config file to /home/seth/tensorflow/BurmesePython/ssd_inception_v2_coco_2018_01_28/pipeline.config
INFO:tensorflow:Running training and evaluation locally (non-distributed).
INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.
INFO:tensorflow:Skipping training since max_steps has already saved.


```",seth-johnson-sp,None,2018-08-10T09:50:05Z,2020-06-04T12:47:16Z,,,,,,,
5048,.,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",xinyi,None,2018-08-10T00:03:25Z,2018-08-15T14:30:45Z,,,,,,,
5042,Training my own data set is worse than the pre training model,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",SubWayss,None,2018-08-09T08:57:37Z,2020-02-07T18:50:51Z,,,,,,,
5024,"tensorflow.python.framework.errors_impl.InvalidArgumentError: assertion failed: [Unable to decode bytes as JPEG, PNG, GIF, or BMP]","Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using: /models-master/research/slim
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: NO
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu16.04 64bit
 - **TensorFlow installed from (source or binary)**: pip install tensorflow-gpu==1.9
- **TensorFlow version (use command below)**:  1.9
- **Bazel version (if compiling from source)**:  never use Bazel
- **CUDA/cuDNN version**: cuda9.0 cudnn7.0
- **GPU model and memory**: gtx1070
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
```
python mobilenet_v1_eval.py   \
--eval_dir  ""/home/icare/yqli/evalu/mobilenet/image"" \
--checkpoint_dir ""/home/icare/yqli/model/mobilenet_v1/mobilenet_v1_1.0_224.ckpt"" \
--dataset_dir ""/home/icare/yqli/data/mobilenet"" \
--num_classes ""1001""

2018-08-07 20:32:20.691261: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2018-08-07 20:32:20.778043: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:897] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-08-07 20:32:20.778460: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1392] Found device 0 with properties: 
name: GeForce GTX 1080 major: 6 minor: 1 memoryClockRate(GHz): 1.8225
pciBusID: 0000:01:00.0
totalMemory: 7.92GiB freeMemory: 7.77GiB
2018-08-07 20:32:20.778473: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2018-08-07 20:32:20.957114: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-08-07 20:32:20.957147: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2018-08-07 20:32:20.957153: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2018-08-07 20:32:20.957361: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7502 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0, compute capability: 6.1)
eval/Recall_5[-nan]eval/Accuracy[0]

Traceback (most recent call last):
  File ""mobilenet_v1_eval.py"", line 152, in <module>
    tf.app.run(main)
  File ""/home/icare/.local/lib/python2.7/site-packages/tensorflow/python/platform/app.py"", line 125, in run
    _sys.exit(main(argv))
  File ""mobilenet_v1_eval.py"", line 148, in main
    eval_model()
  File ""mobilenet_v1_eval.py"", line 144, in eval_model
    eval_op=eval_ops)
  File ""/home/icare/.local/lib/python2.7/site-packages/tensorflow/contrib/slim/python/slim/evaluation.py"", line 212, in evaluate_once
    config=session_config)
  File ""/home/icare/.local/lib/python2.7/site-packages/tensorflow/python/training/evaluation.py"", line 212, in _evaluate_once
    session.run(eval_ops, feed_dict)
  File ""/home/icare/.local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py"", line 689, in __exit__
    self._close_internal(exception_type)
  File ""/home/icare/.local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py"", line 726, in _close_internal
    self._sess.close()
  File ""/home/icare/.local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py"", line 974, in close
    self._sess.close()
  File ""/home/icare/.local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py"", line 1118, in close
    ignore_live_threads=True)
  File ""/home/icare/.local/lib/python2.7/site-packages/tensorflow/python/training/coordinator.py"", line 389, in join
    six.reraise(*self._exc_info_to_raise)
  File ""/home/icare/.local/lib/python2.7/site-packages/tensorflow/python/training/queue_runner_impl.py"", line 252, in _run
    enqueue_callable()
  File ""/home/icare/.local/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 1244, in _single_operation_run
    self._call_tf_sessionrun(None, {}, [], target_list, None)
  File ""/home/icare/.local/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 1409, in _call_tf_sessionrun
    run_metadata)
tensorflow.python.framework.errors_impl.InvalidArgumentError: assertion failed: [Unable to decode bytes as JPEG, PNG, GIF, or BMP]
	 [[Node: case/cond/cond_jpeg/decode_image/cond_jpeg/cond_png/cond_gif/Assert_1/Assert = Assert[T=[DT_STRING], summarize=3, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](case/cond/cond_jpeg/decode_image/cond_jpeg/cond_png/cond_gif/is_bmp, case/cond/cond_jpeg/decode_image/cond_jpeg/cond_png/cond_gif/Assert_1/Assert/data_0)]]
	 [[Node: case/cond/cond_jpeg/decode_image/cond_jpeg/cond_png/cond_gif/DecodeBmp/_943 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device_incarnation=1, tensor_name=""edge_156_case/cond/cond_jpeg/decode_image/cond_jpeg/cond_png/cond_gif/DecodeBmp"", tensor_type=DT_UINT8, _device=""/job:localhost/replica:0/task:0/device:GPU:0""]()]]
```


### Source code / logs
the script that transform image2012 .jpg to tfrecord belows
```
# -*- coding = utf-8 -*-
 
from __future__ import absolute_import,division,print_function
 
import numpy as np
import tensorflow as tf
import time
from scipy.misc import imread,imresize
from os import  walk
from os.path import join
 
#
#DATA_DIR = 'data/'
DATA_DIR = ""D:\image""
 
#
IMG_HEIGHT = 224
IMG_WIDTH = 224
IMG_CHANNELS = 3
NUM_TRAIN = 40000
NUM_VALIDARION = 10000
 
#
def count_string(str):
#    num = 0
#    for i in str:
#        if str[i]==',':
#            num = num + 1
    return str.count(',')
	
def read_images(path):
    filenames = next(walk(path))[2]
    num_files = len(filenames)
    images = np.zeros((num_files,IMG_HEIGHT,IMG_WIDTH,IMG_CHANNELS),dtype=np.uint8)
    #images1 = np.zeros((num_files,IMG_HEIGHT,IMG_WIDTH,IMG_CHANNELS),dtype=np.uint8)
    labels = np.zeros((num_files, ), dtype=np.uint8)
    f = open('label.txt')
    lines = f.readlines()
    j = 0
    count = 0
    for i,filename in enumerate(filenames):
        img = imread(join(path,filename))
        img = imresize(img,(IMG_HEIGHT,IMG_WIDTH))
        #print(img.shape)
        if (str(img.shape)).count(',')==1 :
            #print(filename)
            count = count + 1
            continue
        temp_str = str(img.shape).split(',')[2]
        #print(temp_str[1])	
#        print(str(img.shape).split(',')[2])	
		
        if temp_str[1] != '3':
           #print(filename)
           #print("",,4)"")
           count = count + 1
           continue
			
        images[i] = img
        #images1[j] = img
        #j = j+1        
        labels[i] = int(lines[i].split()[1])
    f.close()
    print(count)
    #print(i)
    #print(j)
    return images,labels
 
def _int64_feature(value):
    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))
 
def _bytes_feature(value):
    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))
 
def convert(images,labels,name):
    num = images.shape[0]
    filename = name+'.tfrecords'
    print('Writting',filename)
    writer = tf.python_io.TFRecordWriter(filename)
    for i in range(num):
        img_raw = images[i].tostring()
        example = tf.train.Example(features=tf.train.Features(feature={
            'label': _int64_feature(int(labels[i])),
            'image_raw': _bytes_feature(img_raw)}))
 
        writer.write(example.SerializeToString())
    writer.close()
    print('Writting End')
 
def main(argv):
    print('reading images begin')
    start_time = time.time()
    train_images,train_labels = read_images(DATA_DIR)
    duration = time.time() - start_time
    print(""reading images end , cost %d sec"" %duration)
 
    #get validation
    validation_images = train_images[:NUM_VALIDARION,:,:,:]
    validation_labels = train_labels[:NUM_VALIDARION]
    train_images = train_images[NUM_VALIDARION:,:,:,:]
    train_labels = train_labels[NUM_VALIDARION:]
 
    #convert to tfrecords
    print('convert to tfrecords begin')
    start_time = time.time()
    convert(train_images,train_labels,'train')
    convert(validation_images,validation_labels,'validation')
    duration = time.time() - start_time
    print('convert to tfrecords end , cost %d sec' %duration)
 
if __name__ == '__main__':
    tf.app.run()
```",sxsxsx,None,2018-08-07T12:35:27Z,2018-10-30T11:33:07Z,,,,,,,
5015,fix a bug,change xrange with range to adapt python3,GeneralLi95,b'cla: no',2018-08-07T06:46:42Z,2018-08-07T06:50:24Z,,,,,,,
4996,[object_detection] Python 3 incompatibilities and other errors,"### System information
- **What is the top-level directory of the model you are using**: research/object_detection
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows
- **TensorFlow installed from (source or binary)**: binary 
- **TensorFlow version (use command below)**: 1.9.0
- **Bazel version (if compiling from source)**: -
- **CUDA/cuDNN version**: 9
- **GPU model and memory**: GeForce GTX 1080 Ti
- **Exact command to reproduce**: `model_main.py --pipeline_config_path=""samples/configs/ssd_mobilenet_v1_0.75_depth_quantized_300x300_pets_sync.config"" --model_dir=""data/pet-train"" --logtostderr`

> Note that for running the script on Windows, you need the adapted [pycocotools](https://github.com/philferriere/cocoapi).

### Describe the problem
**Summary:** I've tried to run the tutorial for training pets detection locally, but couldn't get it to run, due to numerous bugs.

The latest version of Tensorflow Object Detection API is incompatible with Python 3 and even following the [official tutorial](https://medium.com/tensorflow/training-and-serving-a-realtime-mobile-object-detector-in-30-minutes-with-cloud-tpus-b78971cf1193) does not work appropriately, when trying to train locally.

I've encountered the following issues, when trying to clone the repo and run from master-branch (commit [f0e10716](https://github.com/tensorflow/models/commit/f0e10716160cd048618ccdd4b6e18336223a172f)):
- Python 2 constructs, that are incompatible with Python 3. I've fixed [two issues in this branch of my fork](https://github.com/apacha/TensorflowObjectDetection/tree/Python3-Compatibility).
- After fixing the Python 3 incompatibilities, training started, but both the `--logtostderror` (how it used to be) and the [`--alsologtostderror`](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/running_locally.md#running-the-training-job) flags were simply ignored by the [`model_main.py`](https://github.com/tensorflow/models/blob/master/research/object_detection/model_main.py) script and no output was produced on the std-output (information to the tensorboard was written, though).
- There is no clear commit/tag/branch, which would indicate the acclaimed [July 13 release](https://github.com/tensorflow/models/tree/master/research/object_detection#july-13-2018). I've asked that question also on [SO](https://stackoverflow.com/questions/51656728/is-there-such-a-thing-as-a-release-version-for-tensorflow-object-detection-api).
- Finally, it started to train but crashed when running the evaluation with a `TypeError: can't pickle dict_values objects` (see log below).

### Source code / logs
```
2018-08-03 16:59:36.773937: W T:\src\github\tensorflow\tensorflow\core\framework\op_kernel.cc:1306] Invalid argument: TypeError: can't pickle dict_values objects
Traceback (most recent call last):

  File ""C:\Programmieren\Anaconda3\lib\site-packages\tensorflow\python\ops\script_ops.py"", line 158, in __call__
    ret = func(*args)

  File ""C:\Users\Alex\Repositories\MusicObjectDetector-TF2\research\object_detection\metrics\coco_evaluation.py"", line 339, in first_value_func
    self._metrics = self.evaluate()

  File ""C:\Users\Alex\Repositories\MusicObjectDetector-TF2\research\object_detection\metrics\coco_evaluation.py"", line 193, in evaluate
    self._detection_boxes_list)

  File ""C:\Users\Alex\Repositories\MusicObjectDetector-TF2\research\object_detection\metrics\coco_tools.py"", line 118, in LoadAnnotations
    results.dataset['categories'] = copy.deepcopy(self.dataset['categories'])

  File ""C:\Programmieren\Anaconda3\lib\copy.py"", line 169, in deepcopy
    rv = reductor(4)

TypeError: can't pickle dict_values objects


Traceback (most recent call last):
  File ""C:\Programmieren\Anaconda3\lib\site-packages\tensorflow\python\client\session.py"", line 1322, in _do_call
    return fn(*args)
  File ""C:\Programmieren\Anaconda3\lib\site-packages\tensorflow\python\client\session.py"", line 1307, in _run_fn
    options, feed_dict, fetch_list, target_list, run_metadata)
  File ""C:\Programmieren\Anaconda3\lib\site-packages\tensorflow\python\client\session.py"", line 1409, in _call_tf_sessionrun
    run_metadata)
tensorflow.python.framework.errors_impl.InvalidArgumentError: TypeError: can't pickle dict_values objects
Traceback (most recent call last):

  File ""C:\Programmieren\Anaconda3\lib\site-packages\tensorflow\python\ops\script_ops.py"", line 158, in __call__
    ret = func(*args)

  File ""C:\Users\Alex\Repositories\MusicObjectDetector-TF2\research\object_detection\metrics\coco_evaluation.py"", line 339, in first_value_func
    self._metrics = self.evaluate()

  File ""C:\Users\Alex\Repositories\MusicObjectDetector-TF2\research\object_detection\metrics\coco_evaluation.py"", line 193, in evaluate
    self._detection_boxes_list)

  File ""C:\Users\Alex\Repositories\MusicObjectDetector-TF2\research\object_detection\metrics\coco_tools.py"", line 118, in LoadAnnotations
    results.dataset['categories'] = copy.deepcopy(self.dataset['categories'])

  File ""C:\Programmieren\Anaconda3\lib\copy.py"", line 169, in deepcopy
    rv = reductor(4)

TypeError: can't pickle dict_values objects


	 [[Node: PyFunc_1 = PyFunc[Tin=[], Tout=[DT_FLOAT], token=""pyfunc_7"", _device=""/job:localhost/replica:0/task:0/device:CPU:0""]()]]
	 [[Node: Postprocessor/BatchMultiClassNonMaxSuppression/MultiClassNonMaxSuppression/non_max_suppression_25/NonMaxSuppressionV3/_4177 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device_incarnation=1, tensor_name=""edge_4912_...pressionV3"", tensor_type=DT_INT32, _device=""/job:localhost/replica:0/task:0/device:GPU:0""]()]]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:/Users/Alex/Repositories/MusicObjectDetector-TF2/research/object_detection/model_main.py"", line 101, in <module>
    tf.app.run()
  File ""C:\Programmieren\Anaconda3\lib\site-packages\tensorflow\python\platform\app.py"", line 125, in run
    _sys.exit(main(argv))
  File ""C:/Users/Alex/Repositories/MusicObjectDetector-TF2/research/object_detection/model_main.py"", line 97, in main
    tf.estimator.train_and_evaluate(estimator, train_spec, eval_specs[0])
  File ""C:\Programmieren\Anaconda3\lib\site-packages\tensorflow\python\estimator\training.py"", line 447, in train_and_evaluate
    return executor.run()
  File ""C:\Programmieren\Anaconda3\lib\site-packages\tensorflow\python\estimator\training.py"", line 531, in run
    return self.run_local()
  File ""C:\Programmieren\Anaconda3\lib\site-packages\tensorflow\python\estimator\training.py"", line 681, in run_local
    eval_result, export_results = evaluator.evaluate_and_export()
  File ""C:\Programmieren\Anaconda3\lib\site-packages\tensorflow\python\estimator\training.py"", line 886, in evaluate_and_export
    hooks=self._eval_spec.hooks)
  File ""C:\Programmieren\Anaconda3\lib\site-packages\tensorflow\python\estimator\estimator.py"", line 460, in evaluate
    output_dir=self.eval_dir(name))
  File ""C:\Programmieren\Anaconda3\lib\site-packages\tensorflow\python\estimator\estimator.py"", line 1386, in _evaluate_run
    config=self._session_config)
  File ""C:\Programmieren\Anaconda3\lib\site-packages\tensorflow\python\training\evaluation.py"", line 212, in _evaluate_once
    session.run(eval_ops, feed_dict)
  File ""C:\Programmieren\Anaconda3\lib\site-packages\tensorflow\python\training\monitored_session.py"", line 689, in __exit__
    self._close_internal(exception_type)
  File ""C:\Programmieren\Anaconda3\lib\site-packages\tensorflow\python\training\monitored_session.py"", line 721, in _close_internal
    h.end(self._coordinated_creator.tf_sess)
  File ""C:\Programmieren\Anaconda3\lib\site-packages\tensorflow\python\training\basic_session_run_hooks.py"", line 824, in end
    self._final_ops, feed_dict=self._final_ops_feed_dict)
  File ""C:\Programmieren\Anaconda3\lib\site-packages\tensorflow\python\client\session.py"", line 900, in run
    run_metadata_ptr)
  File ""C:\Programmieren\Anaconda3\lib\site-packages\tensorflow\python\client\session.py"", line 1135, in _run
    feed_dict_tensor, options, run_metadata)
  File ""C:\Programmieren\Anaconda3\lib\site-packages\tensorflow\python\client\session.py"", line 1316, in _do_run
    run_metadata)
  File ""C:\Programmieren\Anaconda3\lib\site-packages\tensorflow\python\client\session.py"", line 1335, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.InvalidArgumentError: TypeError: can't pickle dict_values objects
Traceback (most recent call last):

  File ""C:\Programmieren\Anaconda3\lib\site-packages\tensorflow\python\ops\script_ops.py"", line 158, in __call__
    ret = func(*args)

  File ""C:\Users\Alex\Repositories\MusicObjectDetector-TF2\research\object_detection\metrics\coco_evaluation.py"", line 339, in first_value_func
    self._metrics = self.evaluate()

  File ""C:\Users\Alex\Repositories\MusicObjectDetector-TF2\research\object_detection\metrics\coco_evaluation.py"", line 193, in evaluate
    self._detection_boxes_list)

  File ""C:\Users\Alex\Repositories\MusicObjectDetector-TF2\research\object_detection\metrics\coco_tools.py"", line 118, in LoadAnnotations
    results.dataset['categories'] = copy.deepcopy(self.dataset['categories'])

  File ""C:\Programmieren\Anaconda3\lib\copy.py"", line 169, in deepcopy
    rv = reductor(4)

TypeError: can't pickle dict_values objects


	 [[Node: PyFunc_1 = PyFunc[Tin=[], Tout=[DT_FLOAT], token=""pyfunc_7"", _device=""/job:localhost/replica:0/task:0/device:CPU:0""]()]]
	 [[Node: Postprocessor/BatchMultiClassNonMaxSuppression/MultiClassNonMaxSuppression/non_max_suppression_25/NonMaxSuppressionV3/_4177 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device_incarnation=1, tensor_name=""edge_4912_...pressionV3"", tensor_type=DT_INT32, _device=""/job:localhost/replica:0/task:0/device:GPU:0""]()]]

Caused by op 'PyFunc_1', defined at:
  File ""C:/Users/Alex/Repositories/MusicObjectDetector-TF2/research/object_detection/model_main.py"", line 101, in <module>
    tf.app.run()
  File ""C:\Programmieren\Anaconda3\lib\site-packages\tensorflow\python\platform\app.py"", line 125, in run
    _sys.exit(main(argv))
  File ""C:/Users/Alex/Repositories/MusicObjectDetector-TF2/research/object_detection/model_main.py"", line 97, in main
    tf.estimator.train_and_evaluate(estimator, train_spec, eval_specs[0])
  File ""C:\Programmieren\Anaconda3\lib\site-packages\tensorflow\python\estimator\training.py"", line 447, in train_and_evaluate
    return executor.run()
  File ""C:\Programmieren\Anaconda3\lib\site-packages\tensorflow\python\estimator\training.py"", line 531, in run
    return self.run_local()
  File ""C:\Programmieren\Anaconda3\lib\site-packages\tensorflow\python\estimator\training.py"", line 681, in run_local
    eval_result, export_results = evaluator.evaluate_and_export()
  File ""C:\Programmieren\Anaconda3\lib\site-packages\tensorflow\python\estimator\training.py"", line 886, in evaluate_and_export
    hooks=self._eval_spec.hooks)
  File ""C:\Programmieren\Anaconda3\lib\site-packages\tensorflow\python\estimator\estimator.py"", line 453, in evaluate
    input_fn, hooks, checkpoint_path)
  File ""C:\Programmieren\Anaconda3\lib\site-packages\tensorflow\python\estimator\estimator.py"", line 1348, in _evaluate_build_graph
    features, labels, model_fn_lib.ModeKeys.EVAL, self.config)
  File ""C:\Programmieren\Anaconda3\lib\site-packages\tensorflow\python\estimator\estimator.py"", line 1107, in _call_model_fn
    model_fn_results = self._model_fn(features=features, **kwargs)
  File ""C:\Users\Alex\Repositories\MusicObjectDetector-TF2\research\object_detection\model_lib.py"", line 387, in model_fn
    include_metrics_per_category=eval_config.include_metrics_per_category)
  File ""C:\Users\Alex\Repositories\MusicObjectDetector-TF2\research\object_detection\eval_util.py"", line 629, in get_eval_metric_ops_for_evaluators
    input_data_fields.groundtruth_is_crowd)))
  File ""C:\Users\Alex\Repositories\MusicObjectDetector-TF2\research\object_detection\metrics\coco_evaluation.py"", line 349, in get_estimator_eval_metric_ops
    first_value_op = tf.py_func(first_value_func, [], tf.float32)
  File ""C:\Programmieren\Anaconda3\lib\site-packages\tensorflow\python\ops\script_ops.py"", line 384, in py_func
    func=func, inp=inp, Tout=Tout, stateful=stateful, eager=False, name=name)
  File ""C:\Programmieren\Anaconda3\lib\site-packages\tensorflow\python\ops\script_ops.py"", line 227, in _internal_py_func
    input=inp, token=token, Tout=Tout, name=name)
  File ""C:\Programmieren\Anaconda3\lib\site-packages\tensorflow\python\ops\gen_script_ops.py"", line 130, in py_func
    ""PyFunc"", input=input, token=token, Tout=Tout, name=name)
  File ""C:\Programmieren\Anaconda3\lib\site-packages\tensorflow\python\framework\op_def_library.py"", line 787, in _apply_op_helper
    op_def=op_def)
  File ""C:\Programmieren\Anaconda3\lib\site-packages\tensorflow\python\framework\ops.py"", line 3414, in create_op
    op_def=op_def)
  File ""C:\Programmieren\Anaconda3\lib\site-packages\tensorflow\python\framework\ops.py"", line 1740, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access

InvalidArgumentError (see above for traceback): TypeError: can't pickle dict_values objects
Traceback (most recent call last):

  File ""C:\Programmieren\Anaconda3\lib\site-packages\tensorflow\python\ops\script_ops.py"", line 158, in __call__
    ret = func(*args)

  File ""C:\Users\Alex\Repositories\MusicObjectDetector-TF2\research\object_detection\metrics\coco_evaluation.py"", line 339, in first_value_func
    self._metrics = self.evaluate()

  File ""C:\Users\Alex\Repositories\MusicObjectDetector-TF2\research\object_detection\metrics\coco_evaluation.py"", line 193, in evaluate
    self._detection_boxes_list)

  File ""C:\Users\Alex\Repositories\MusicObjectDetector-TF2\research\object_detection\metrics\coco_tools.py"", line 118, in LoadAnnotations
    results.dataset['categories'] = copy.deepcopy(self.dataset['categories'])

  File ""C:\Programmieren\Anaconda3\lib\copy.py"", line 169, in deepcopy
    rv = reductor(4)

TypeError: can't pickle dict_values objects


	 [[Node: PyFunc_1 = PyFunc[Tin=[], Tout=[DT_FLOAT], token=""pyfunc_7"", _device=""/job:localhost/replica:0/task:0/device:CPU:0""]()]]
	 [[Node: Postprocessor/BatchMultiClassNonMaxSuppression/MultiClassNonMaxSuppression/non_max_suppression_25/NonMaxSuppressionV3/_4177 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device_incarnation=1, tensor_name=""edge_4912_...pressionV3"", tensor_type=DT_INT32, _device=""/job:localhost/replica:0/task:0/device:GPU:0""]()]]


```",apacha,None,2018-08-03T15:03:37Z,2018-12-28T22:01:54Z,,,,,,,
4989,Fix bug where data_async_generation.py would freeze.,"The data_async_generation.py process would print to stderr, but the main process would redirect it's stderr to a pipe. The main process never read from the pipe, so when the pipe was full, data_async_generation.py would stall on a write to stderr. This change makes data_async_generation.py not write to stdout/stderr.",reedwm,b'cla: yes',2018-08-02T19:32:39Z,2018-08-02T19:51:13Z,,,,,,,
4987,Bug fix: change dict.iteritems() to dict.items(),`iteritems()` was removed from python3. `items()` does the same functionality so changing it will work in both python2 and python3. The only difference as far as I know is `iteritems()` returns a generator where `items` returns a list. But for this this code it will not make any difference where we are just changing the key of the dict to a string.,TwistedHardware,b'cla: yes',2018-08-02T15:07:12Z,2018-08-03T20:42:57Z,,,,,,,
4984,tensorflow.python.framework.errors_impl.FailedPreconditionError: GetNext() failed because the iterator has not been initialized. Ensure that you have run the initializer operation for this iterator before getting the next element.,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:win10
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:tensorflow-cpu-1.6
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:CUDA8.0
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.
run train.py
report error:
tensorflow.python.framework.errors_impl.FailedPreconditionError: GetNext() failed because the iterator has not been initialized. Ensure that you have run the initializer operation for this iterator before getting the next element.
	 [[Node: IteratorGetNext = IteratorGetNext[output_shapes=[[], [?], [?,4], [?], [?], [?], [?], [?], [?], [?,?,3], [], [], []], output_types=[DT_STRING, DT_FLOAT, DT_FLOAT, DT_INT64, DT_INT64, DT_INT64, DT_INT64, DT_BOOL, DT_FLOAT, DT_UINT8, DT_STRING, DT_INT32, DT_STRING], _device=""/job:localhost/replica:0/task:0/device:CPU:0""](Iterator)]]



### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
# Copyright 2017 The TensorFlow Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ==============================================================================

r""""""Training executable for detection models.

This executable is used to train DetectionModels. There are two ways of
configuring the training job:

1) A single pipeline_pb2.TrainEvalPipelineConfig configuration file
can be specified by --pipeline_config_path.

Example usage:
    ./train \
        --logtostderr \
        --train_dir=path/to/train_dir \
        --pipeline_config_path=pipeline_config.pbtxt

2) Three configuration files can be provided: a model_pb2.DetectionModel
configuration file to define what type of DetectionModel is being trained, an
input_reader_pb2.InputReader file to specify what training data will be used and
a train_pb2.TrainConfig file to configure training parameters.

Example usage:
    ./train \
        --logtostderr \
        --train_dir=path/to/train_dir \
        --model_config_path=model_config.pbtxt \
        --train_config_path=train_config.pbtxt \
        --input_config_path=train_input_config.pbtxt
""""""

import functools
import json
import os
import tensorflow as tf

from object_detection.legacy import trainer
from object_detection.builders import dataset_builder
from object_detection.builders import graph_rewriter_builder
from object_detection.builders import model_builder
from object_detection.utils import config_util
from object_detection.utils import dataset_util

tf.logging.set_verbosity(tf.logging.INFO)

flags = tf.app.flags
flags.DEFINE_string('master', '', 'Name of the TensorFlow master to use.')
flags.DEFINE_integer('task', 0, 'task id')
flags.DEFINE_integer('num_clones', 1, 'Number of clones to deploy per worker.')
flags.DEFINE_boolean('clone_on_cpu', False,
                     'Force clones to be deployed on CPU.  Note that even if '
                     'set to False (allowing ops to run on gpu), some ops may '
                     'still be run on the CPU if they have no GPU kernel.')
flags.DEFINE_integer('worker_replicas', 1, 'Number of worker+trainer '
                     'replicas.')
flags.DEFINE_integer('ps_tasks', 0,
                     'Number of parameter server tasks. If None, does not use '
                     'a parameter server.')
flags.DEFINE_string('train_dir', '',
                    'Directory to save the checkpoints and training summaries.')

flags.DEFINE_string('pipeline_config_path', '',
                    'Path to a pipeline_pb2.TrainEvalPipelineConfig config '
                    'file. If provided, other configs are ignored')

flags.DEFINE_string('train_config_path', '',
                    'Path to a train_pb2.TrainConfig config file.')
flags.DEFINE_string('input_config_path', '',
                    'Path to an input_reader_pb2.InputReader config file.')
flags.DEFINE_string('model_config_path', '',
                    'Path to a model_pb2.DetectionModel config file.')

FLAGS = flags.FLAGS


def main(_):
  assert FLAGS.train_dir, '`train_dir` is missing.'
  if FLAGS.task == 0: tf.gfile.MakeDirs(FLAGS.train_dir)
  if FLAGS.pipeline_config_path:
    configs = config_util.get_configs_from_pipeline_file(
        FLAGS.pipeline_config_path)
    if FLAGS.task == 0:
      tf.gfile.Copy(FLAGS.pipeline_config_path,
                    os.path.join(FLAGS.train_dir, 'pipeline.config'),
                    overwrite=True)
  else:
    configs = config_util.get_configs_from_multiple_files(
        model_config_path=FLAGS.model_config_path,
        train_config_path=FLAGS.train_config_path,
        train_input_config_path=FLAGS.input_config_path)
    if FLAGS.task == 0:
      for name, config in [('model.config', FLAGS.model_config_path),
                           ('train.config', FLAGS.train_config_path),
                           ('input.config', FLAGS.input_config_path)]:
        tf.gfile.Copy(config, os.path.join(FLAGS.train_dir, name),
                      overwrite=True)

  model_config = configs['model']
  print(""model_config:"")
  print(model_config)
  train_config = configs['train_config']
  print(""train_config"")
  print(train_config)
  input_config = configs['train_input_config']
  print(""input_config"")
  print(input_config)


  model_fn = functools.partial(
      model_builder.build,
      model_config=model_config,
      is_training=True)
  print(""yunxing"")#
  def get_next(config):
    data=dataset_builder.build(config)
    data1=data.make_initializable_iterator()
    data2=data1.get_next()
    return data2
    # return dataset_util.make_initializable_iterator(
    #     dataset_builder.build(config)).get_next()

  create_input_dict_fn = functools.partial(get_next, input_config)

  env = json.loads(os.environ.get('TF_CONFIG', '{}'))
  cluster_data = env.get('cluster', None)
  cluster = tf.train.ClusterSpec(cluster_data) if cluster_data else None
  task_data = env.get('task', None) or {'type': 'master', 'index': 0}
  task_info = type('TaskSpec', (object,), task_data)

  # Parameters for a single worker.
  ps_tasks = 0
  worker_replicas = 1
  worker_job_name = 'lonely_worker'
  task = 0
  is_chief = True
  master = ''

  if cluster_data and 'worker' in cluster_data:
    # Number of total worker replicas include ""worker""s and the ""master"".
    worker_replicas = len(cluster_data['worker']) + 1
  if cluster_data and 'ps' in cluster_data:
    ps_tasks = len(cluster_data['ps'])

  if worker_replicas > 1 and ps_tasks < 1:
    raise ValueError('At least 1 ps task is needed for distributed training.')

  if worker_replicas >= 1 and ps_tasks > 0:
    # Set up distributed training.
    server = tf.train.Server(tf.train.ClusterSpec(cluster), protocol='grpc',
                             job_name=task_info.type,
                             task_index=task_info.index)
    if task_info.type == 'ps':
      server.join()
      return

    worker_job_name = '%s/task:%d' % (task_info.type, task_info.index)
    task = task_info.index
    is_chief = (task_info.type == 'master')
    master = server.target

  graph_rewriter_fn = None
  if 'graph_rewriter_config' in configs:
    graph_rewriter_fn = graph_rewriter_builder.build(
        configs['graph_rewriter_config'], is_training=True)

  trainer.train(
      create_input_dict_fn,
      model_fn,
      train_config,
      master,
      task,
      FLAGS.num_clones,
      worker_replicas,
      FLAGS.clone_on_cpu,
      ps_tasks,
      worker_job_name,
      is_chief,
      FLAGS.train_dir,
      graph_hook_fn=graph_rewriter_fn)",Distance789,None,2018-08-02T10:58:22Z,2018-08-07T01:39:54Z,,,,,,,
4983,AttributeError: module 'object_detection.utils.dataset_util' has no attribute 'make_initializable_iterator',"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:win10
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:tensorflow-cpu-1.6
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:CUDA8.0
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.
run train.py,report
AttributeError: module 'object_detection.utils.dataset_util' has no attribute 'make_initializable_iterator'


### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
  def get_next(config):
    return dataset_util.make_initializable_iterator(
        dataset_builder.build(config)).get_next()
",Distance789,None,2018-08-02T10:23:44Z,2018-08-24T07:11:13Z,,,,,,,
4981,"[Object Detection] InvalidArgumentError: Expected size[0] in [0, 100], but got 109","### System information
- **What is the top-level directory of the model you are using**:
tensorflow/model/research
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
No. Only with custom tfrecord data.
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**:
Binary
- **TensorFlow version (use command below)**:
tf.VERSION = 1.9.0
tf.GIT_VERSION = v1.9.0-0-g25c197e023
tf.COMPILER_VERSION = v1.9.0-0-g25c197e023
Sanity check: array([1], dtype=int32)
- **Bazel version (if compiling from source)**:
Not compiling from source.
- **CUDA/cuDNN version**:
Not using CUDA.
- **GPU model and memory**:
Not using GPU.
- **Exact command to reproduce**:
python object_detection/model_main.py   \\
   --pipeline_config_path=/ssd_mobilenet_v2_face.config   \\
   --model_dir=model/train  \\
   --num_train_steps=50000  \\
   --num_eval_steps=2000  \\
   --alsologtostderr


You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

[tf_env.txt](https://github.com/tensorflow/models/files/2252912/tf_env.txt)


### Describe the problem
I guess this is a bug. Using `legacy/train.py` the training process goes well, but failed with `model_main.py`.

The error message is like: 
`InvalidArgumentError (see above for traceback): Expected size[0] in [0, 100], but got 109`

It's not always 109, the number varies in defferent running.

### Source code / logs
The commit ID is: 02a9969e94feb51966f9bacddc1836d811f8ce69

#### Logs
```
/opt/models/research/object_detection/utils/visualization_utils.py:25: UserWarning: 
This call to matplotlib.use() has no effect because the backend has already
been chosen; matplotlib.use() must be called *before* pylab, matplotlib.pyplot,
or matplotlib.backends is imported for the first time.

The backend was *originally* set to 'TkAgg' by the following code:
  File ""object_detection/model_main.py"", line 26, in <module>
    from object_detection import model_lib
  File ""/opt/models/research/object_detection/model_lib.py"", line 26, in <module>
    from object_detection import eval_util
  File ""/opt/models/research/object_detection/eval_util.py"", line 28, in <module>
    from object_detection.metrics import coco_evaluation
  File ""/opt/models/research/object_detection/metrics/coco_evaluation.py"", line 20, in <module>
    from object_detection.metrics import coco_tools
  File ""/opt/models/research/object_detection/metrics/coco_tools.py"", line 47, in <module>
    from pycocotools import coco
  File ""/opt/models/research/pycocotools/coco.py"", line 49, in <module>
    import matplotlib.pyplot as plt
  File ""/home/robin/.local/lib/python2.7/site-packages/matplotlib/pyplot.py"", line 71, in <module>
    from matplotlib.backends import pylab_setup
  File ""/home/robin/.local/lib/python2.7/site-packages/matplotlib/backends/__init__.py"", line 16, in <module>
    line for line in traceback.format_stack()


  import matplotlib; matplotlib.use('Agg')  # pylint: disable=multiple-statements
WARNING:tensorflow:Estimator's model_fn (<function model_fn at 0x7f646c4b7e60>) includes params argument, but params are not passed to Estimator.
WARNING:tensorflow:num_readers has been reduced to 10 to match input file shards.
WARNING:tensorflow:From /opt/models/research/object_detection/core/preprocessor.py:1205: calling squeeze (from tensorflow.python.ops.array_ops) with squeeze_dims is deprecated and will be removed in a future version.
Instructions for updating:
Use the `axis` argument instead
2018-08-02 15:29:10.072903: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
Traceback (most recent call last):
  File ""object_detection/model_main.py"", line 101, in <module>
    tf.app.run()
  File ""/home/robin/.local/lib/python2.7/site-packages/tensorflow/python/platform/app.py"", line 125, in run
    _sys.exit(main(argv))
  File ""object_detection/model_main.py"", line 97, in main
    tf.estimator.train_and_evaluate(estimator, train_spec, eval_specs[0])
  File ""/home/robin/.local/lib/python2.7/site-packages/tensorflow/python/estimator/training.py"", line 447, in train_and_evaluate
    return executor.run()
  File ""/home/robin/.local/lib/python2.7/site-packages/tensorflow/python/estimator/training.py"", line 531, in run
    return self.run_local()
  File ""/home/robin/.local/lib/python2.7/site-packages/tensorflow/python/estimator/training.py"", line 669, in run_local
    hooks=train_hooks)
  File ""/home/robin/.local/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.py"", line 366, in train
    loss = self._train_model(input_fn, hooks, saving_listeners)
  File ""/home/robin/.local/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.py"", line 1119, in _train_model
    return self._train_model_default(input_fn, hooks, saving_listeners)
  File ""/home/robin/.local/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.py"", line 1135, in _train_model_default
    saving_listeners)
  File ""/home/robin/.local/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.py"", line 1336, in _train_with_estimator_spec
    _, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])
  File ""/home/robin/.local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py"", line 577, in run
    run_metadata=run_metadata)
  File ""/home/robin/.local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py"", line 1053, in run
    run_metadata=run_metadata)
  File ""/home/robin/.local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py"", line 1144, in run
    raise six.reraise(*original_exc_info)
  File ""/home/robin/.local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py"", line 1129, in run
    return self._sess.run(*args, **kwargs)
  File ""/home/robin/.local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py"", line 1201, in run
    run_metadata=run_metadata)
  File ""/home/robin/.local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py"", line 981, in run
    return self._sess.run(*args, **kwargs)
  File ""/home/robin/.local/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 900, in run
    run_metadata_ptr)
  File ""/home/robin/.local/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 1135, in _run
    feed_dict_tensor, options, run_metadata)
  File ""/home/robin/.local/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 1316, in _do_run
    run_metadata)
  File ""/home/robin/.local/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 1335, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.InvalidArgumentError: Expected size[0] in [0, 100], but got 109
	 [[Node: Slice_83 = Slice[Index=DT_INT32, T=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](unstack_4:11, zeros_48, stack_83)]]

Caused by op u'Slice_83', defined at:
  File ""object_detection/model_main.py"", line 101, in <module>
    tf.app.run()
  File ""/home/robin/.local/lib/python2.7/site-packages/tensorflow/python/platform/app.py"", line 125, in run
    _sys.exit(main(argv))
  File ""object_detection/model_main.py"", line 97, in main
    tf.estimator.train_and_evaluate(estimator, train_spec, eval_specs[0])
  File ""/home/robin/.local/lib/python2.7/site-packages/tensorflow/python/estimator/training.py"", line 447, in train_and_evaluate
    return executor.run()
  File ""/home/robin/.local/lib/python2.7/site-packages/tensorflow/python/estimator/training.py"", line 531, in run
    return self.run_local()
  File ""/home/robin/.local/lib/python2.7/site-packages/tensorflow/python/estimator/training.py"", line 669, in run_local
    hooks=train_hooks)
  File ""/home/robin/.local/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.py"", line 366, in train
    loss = self._train_model(input_fn, hooks, saving_listeners)
  File ""/home/robin/.local/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.py"", line 1119, in _train_model
    return self._train_model_default(input_fn, hooks, saving_listeners)
  File ""/home/robin/.local/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.py"", line 1132, in _train_model_default
    features, labels, model_fn_lib.ModeKeys.TRAIN, self.config)
  File ""/home/robin/.local/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.py"", line 1107, in _call_model_fn
    model_fn_results = self._model_fn(features=features, **kwargs)
  File ""/opt/models/research/object_detection/model_lib.py"", line 216, in model_fn
    unpad_groundtruth_tensors=train_config.unpad_groundtruth_tensors)
  File ""/opt/models/research/object_detection/model_lib.py"", line 163, in unstack_batch
    unpadded_tensor = tf.slice(padded_tensor, slice_begin, slice_size)
  File ""/home/robin/.local/lib/python2.7/site-packages/tensorflow/python/ops/array_ops.py"", line 576, in slice
    return gen_array_ops._slice(input_, begin, size, name=name)
  File ""/home/robin/.local/lib/python2.7/site-packages/tensorflow/python/ops/gen_array_ops.py"", line 7177, in _slice
    ""Slice"", input=input, begin=begin, size=size, name=name)
  File ""/home/robin/.local/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py"", line 787, in _apply_op_helper
    op_def=op_def)
  File ""/home/robin/.local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 3414, in create_op
    op_def=op_def)
  File ""/home/robin/.local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 1740, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access

InvalidArgumentError (see above for traceback): Expected size[0] in [0, 100], but got 109
	 [[Node: Slice_83 = Slice[Index=DT_INT32, T=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](unstack_4:11, zeros_48, stack_83)]]
```
#### Config
```
# SSD with Mobilenet v2 configuration for WIDERFACE Dataset.
model {
  ssd {
    num_classes: 1

    box_coder {
      faster_rcnn_box_coder {
        y_scale: 10.0
        x_scale: 10.0
        height_scale: 5.0
        width_scale: 5.0
      }
    }

    matcher {
      argmax_matcher {
        matched_threshold: 0.5
        unmatched_threshold: 0.5
        ignore_thresholds: false
        negatives_lower_than_unmatched: true
        force_match_for_each_row: true
      }
    }

    similarity_calculator {
      iou_similarity {
      }
    }

    anchor_generator {
      ssd_anchor_generator {
        num_layers: 6
        min_scale: 0.2
        max_scale: 0.95
        aspect_ratios: 1.0
        aspect_ratios: 2.0
        aspect_ratios: 0.5
        aspect_ratios: 3.0
        aspect_ratios: 0.3333
      }
    }

    image_resizer {
      fixed_shape_resizer {
        height: 300
        width: 300
      }
    }

    box_predictor {
      convolutional_box_predictor {
        min_depth: 0
        max_depth: 0
        num_layers_before_predictor: 0
        use_dropout: false
        dropout_keep_probability: 0.8
        kernel_size: 3
        box_code_size: 4
        apply_sigmoid_to_scores: false
        conv_hyperparams {
          activation: RELU_6,
          regularizer {
            l2_regularizer {
              weight: 0.00004
            }
          }
          initializer {
            truncated_normal_initializer {
              stddev: 0.03
              mean: 0.0
            }
          }
          batch_norm {
            train: true,
            scale: true,
            center: true,
            decay: 0.9997,
            epsilon: 0.001,
          }
        }
      }
    }

    feature_extractor {
      type: 'ssd_mobilenet_v2'
      min_depth: 16
      depth_multiplier: 1.0
      conv_hyperparams {
        activation: RELU_6,
        regularizer {
          l2_regularizer {
            weight: 0.00004
          }
        }
        initializer {
          truncated_normal_initializer {
            stddev: 0.03
            mean: 0.0
          }
        }
        batch_norm {
          train: true,
          scale: true,
          center: true,
          decay: 0.9997,
          epsilon: 0.001,
        }
      }
      use_depthwise: true
    }

    loss {
      classification_loss {
        weighted_sigmoid_focal {
          gamma: 2.0
          alpha: 0.75
        }
      }
      localization_loss {
        weighted_smooth_l1 {

        }
      }
      classification_weight: 1.0
      localization_weight: 1.0
    }
    normalize_loss_by_num_matches: true
    post_processing {
      batch_non_max_suppression {
        score_threshold: 1e-8
        iou_threshold: 0.6
        max_detections_per_class: 100
        max_total_detections: 100
      }
      score_converter: SIGMOID
    }
  }
}

# Configuration for training.
train_config: {
  batch_size: 24
  optimizer {
    rms_prop_optimizer: {
      learning_rate: {
        exponential_decay_learning_rate {
          initial_learning_rate: 0.004
          decay_steps: 800720
          decay_factor: 0.95
        }
      }
      momentum_optimizer_value: 0.9
      decay: 0.9
      epsilon: 1.0
    }
  }
  # NOT USING TRANSFER LEARNING
  # fine_tune_checkpoint: ""/home/ubuntu/face_ssd_mobilenet_v2/model/restore/model.ckpt""
  # fine_tune_checkpoint_type:  ""detection""
  # Note: The below line limits the training process to 200K steps, which we
  # empirically found to be sufficient enough to train the pets dataset. This
  # effectively bypasses the learning rate schedule (the learning rate will
  # never decay). Remove the below line to train indefinitely.
  num_steps: 200000
  data_augmentation_options {
    random_horizontal_flip {
    }
  }
  data_augmentation_options {
    ssd_random_crop {
    }
  }
}


# Configuration for training input.
train_input_reader: {
  tf_record_input_reader {
    input_path: ""/home/ubuntu/face_ssd_mobilenet_v2/data/wider_train.record-?????-of-00010""
  }
  label_map_path: ""/home/ubuntu/face_ssd_mobilenet_v2/model/configs/label_map.pbtxt""
}


# Configuration for evaluation.
eval_config: {
  num_examples: 8000
  # Note: The below line limits the evaluation process to 10 evaluations.
  # Remove the below line to evaluate indefinitely.
  max_evals: 10
}


# Configuration for evaluation input.
eval_input_reader: {
  tf_record_input_reader {
    input_path: ""/home/ubuntu/face_ssd_mobilenet_v2/data/wider_val.record-?????-of-00010""
  }
  label_map_path: ""/home/ubuntu/face_ssd_mobilenet_v2/model/configs/label_map.pbtxt""
  shuffle: false
  num_readers: 1
}
```
I also uploaded a TFRecord file here:
https://drive.google.com/open?id=1NtNA1LefRYGSbRwTiahO_PrHfSjrR4mU
",yinguobing,None,2018-08-02T09:42:17Z,2020-06-18T17:41:10Z,,,,,,,
4979,accoon\labelmap.pbtxt : \udcceļ\udcfe\udcc3\udcfb\udca1\udca2Ŀ¼\udcc3\udcfb\udcbb\udcf2\udcbe\udced\udcb1\udcea\udcd3﷨\udcb2\udcbb\udcd5\udcfdȷ\udca1\udca3 ; Unknown error,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:win10
- **TensorFlow installed from (source or binary)**:windows anaconda3
- **TensorFlow version (use command below)**:tensorflow-cpu-1.6
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:CUDA8.0
- **GPU model and memory**:CPU
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.
use train.py to train data,have problem about label.pbtxt file.


**errors** 
Traceback (most recent call last):
  File ""E:/raccoon/train.py"", line 191, in <module>
    tf.app.run()
  File ""E:\Python36\lib\site-packages\tensorflow\python\platform\app.py"", line 126, in run
    _sys.exit(main(argv))
  File ""E:/raccoon/train.py"", line 187, in main
    graph_hook_fn=graph_rewriter_fn)
  File ""E:\models\research\object_detection\legacy\trainer.py"", line 277, in train
    train_config.prefetch_queue_capacity, data_augmentation_options)
  File ""E:\models\research\object_detection\legacy\trainer.py"", line 59, in create_input_queue
    tensor_dict = create_tensor_dict_fn()
  File ""E:/raccoon/train.py"", line 128, in get_next
    dataset_builder.build(config)).get_next()
  File ""E:\models\research\object_detection\builders\dataset_builder.py"", line 123, in build
    num_additional_channels=input_reader_config.num_additional_channels)
  File ""E:\models\research\object_detection\data_decoders\tf_example_decoder.py"", line 271, in __init__
    use_display_name)
  File ""E:\models\research\object_detection\utils\label_map_util.py"", line 152, in get_label_map_dict
    label_map = load_labelmap(label_map_path)
  File ""E:\models\research\object_detection\utils\label_map_util.py"", line 132, in load_labelmap
    label_map_string = fid.read()
  File ""E:\Python36\lib\site-packages\tensorflow\python\lib\io\file_io.py"", line 120, in read
    self._preread_check()
  File ""E:\Python36\lib\site-packages\tensorflow\python\lib\io\file_io.py"", line 80, in _preread_check
    compat.as_bytes(self.__name), 1024 * 512, status)
  File ""E:\Python36\lib\site-packages\tensorflow\python\framework\errors_impl.py"", line 516, in __exit__
    c_api.TF_GetCode(self.status.status))
accoon\labelmap.pbtxt : \udcceļ\udcfe\udcc3\udcfb\udca1\udca2Ŀ¼\udcc3\udcfb\udcbb\udcf2\udcbe\udced\udcb1\udcea\udcd3﷨\udcb2\udcbb\udcd5\udcfdȷ\udca1\udca3
; Unknown error


### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
train.py

import functools
import json
import os
import tensorflow as tf

from object_detection.legacy import trainer
from object_detection.builders import dataset_builder
from object_detection.builders import graph_rewriter_builder
from object_detection.builders import model_builder
from object_detection.utils import config_util
from object_detection.utils import dataset_util

tf.logging.set_verbosity(tf.logging.INFO)

flags = tf.app.flags
flags.DEFINE_string('master', '', 'Name of the TensorFlow master to use.')
flags.DEFINE_integer('task', 0, 'task id')
flags.DEFINE_integer('num_clones', 1, 'Number of clones to deploy per worker.')
flags.DEFINE_boolean('clone_on_cpu', False,
                     'Force clones to be deployed on CPU.  Note that even if '
                     'set to False (allowing ops to run on gpu), some ops may '
                     'still be run on the CPU if they have no GPU kernel.')
flags.DEFINE_integer('worker_replicas', 1, 'Number of worker+trainer '
                     'replicas.')
flags.DEFINE_integer('ps_tasks', 0,
                     'Number of parameter server tasks. If None, does not use '
                     'a parameter server.')
flags.DEFINE_string('train_dir', '',
                    'Directory to save the checkpoints and training summaries.')

flags.DEFINE_string('pipeline_config_path', '',
                    'Path to a pipeline_pb2.TrainEvalPipelineConfig config '
                    'file. If provided, other configs are ignored')

flags.DEFINE_string('train_config_path', '',
                    'Path to a train_pb2.TrainConfig config file.')
flags.DEFINE_string('input_config_path', '',
                    'Path to an input_reader_pb2.InputReader config file.')
flags.DEFINE_string('model_config_path', '',
                    'Path to a model_pb2.DetectionModel config file.')

FLAGS = flags.FLAGS


def main(_):
  assert FLAGS.train_dir, '`train_dir` is missing.'
  if FLAGS.task == 0: tf.gfile.MakeDirs(FLAGS.train_dir)
  if FLAGS.pipeline_config_path:
    configs = config_util.get_configs_from_pipeline_file(
        FLAGS.pipeline_config_path)
    if FLAGS.task == 0:
      tf.gfile.Copy(FLAGS.pipeline_config_path,
                    os.path.join(FLAGS.train_dir, 'pipeline.config'),
                    overwrite=True)
  else:
    configs = config_util.get_configs_from_multiple_files(
        model_config_path=FLAGS.model_config_path,
        train_config_path=FLAGS.train_config_path,
        train_input_config_path=FLAGS.input_config_path)
    if FLAGS.task == 0:
      for name, config in [('model.config', FLAGS.model_config_path),
                           ('train.config', FLAGS.train_config_path),
                           ('input.config', FLAGS.input_config_path)]:
        tf.gfile.Copy(config, os.path.join(FLAGS.train_dir, name),
                      overwrite=True)

  model_config = configs['model']
  print(""model_config:"")
  print(model_config)
  train_config = configs['train_config']
  print(""train_config"")
  print(train_config)
  input_config = configs['train_input_config']
  print(""input_config"")
  print(input_config)


  model_fn = functools.partial(
      model_builder.build,
      model_config=model_config,
      is_training=True)
  print(""yunxing"")#
  def get_next(config):
    return dataset_util.make_initializable_iterator(
        dataset_builder.build(config)).get_next()

  create_input_dict_fn = functools.partial(get_next, input_config)

  env = json.loads(os.environ.get('TF_CONFIG', '{}'))
  cluster_data = env.get('cluster', None)
  cluster = tf.train.ClusterSpec(cluster_data) if cluster_data else None
  task_data = env.get('task', None) or {'type': 'master', 'index': 0}
  task_info = type('TaskSpec', (object,), task_data)

  # Parameters for a single worker.
  ps_tasks = 0
  worker_replicas = 1
  worker_job_name = 'lonely_worker'
  task = 0
  is_chief = True
  master = ''

  if cluster_data and 'worker' in cluster_data:
    # Number of total worker replicas include ""worker""s and the ""master"".
    worker_replicas = len(cluster_data['worker']) + 1
  if cluster_data and 'ps' in cluster_data:
    ps_tasks = len(cluster_data['ps'])

  if worker_replicas > 1 and ps_tasks < 1:
    raise ValueError('At least 1 ps task is needed for distributed training.')

  if worker_replicas >= 1 and ps_tasks > 0:
    # Set up distributed training.
    server = tf.train.Server(tf.train.ClusterSpec(cluster), protocol='grpc',
                             job_name=task_info.type,
                             task_index=task_info.index)
    if task_info.type == 'ps':
      server.join()
      return

    worker_job_name = '%s/task:%d' % (task_info.type, task_info.index)
    task = task_info.index
    is_chief = (task_info.type == 'master')
    master = server.target

  graph_rewriter_fn = None
  if 'graph_rewriter_config' in configs:
    graph_rewriter_fn = graph_rewriter_builder.build(
        configs['graph_rewriter_config'], is_training=True)

  trainer.train(
      create_input_dict_fn,
      model_fn,
      train_config,
      master,
      task,
      FLAGS.num_clones,
      worker_replicas,
      FLAGS.clone_on_cpu,
      ps_tasks,
      worker_job_name,
      is_chief,
      FLAGS.train_dir,
      graph_hook_fn=graph_rewriter_fn)


if __name__ == '__main__':
  tf.app.run()



part of reccoon.config
train_input_reader: {
  tf_record_input_reader {
    input_path: 'E:\raccoon\data\train.record'
  }
  label_map_path: 'E:\raccoon\labelmap.pbtxt' 
}

eval_config: {
  num_examples: 40
  # Note: The below line limits the evaluation process to 10 evaluations.
  # Remove the below line to evaluate indefinitely.
  metrics_set:""pascal_voc_metrics""
  max_evals: 10
}

eval_input_reader: {
  tf_record_input_reader {
    input_path: 'E:\raccoon\data\val.record'
  }
  label_map_path: 'E:\raccoon\labelmap.pbtxt' 
  shuffle: false
  num_readers: 1
}




",Distance789,None,2018-08-02T08:54:56Z,2018-08-02T10:50:40Z,,,,,,,
4966,Wide_Deep Exists/Does-not-execute with train_epochs=1,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:official/wide_deep
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:Linux
- **TensorFlow installed from (source or binary)**:irrelevant
- **TensorFlow version (use command below)**:irrelevant
- **Bazel version (if compiling from source)**:irrelvant
- **CUDA/cuDNN version**:irrelevant
- **GPU model and memory**:irrelevant
- **Exact command to reproduce**:
python census_main.py --train_epochs=1 

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem

FLAGS.epochs_between_evals is set to 2 and 
https://github.com/tensorflow/models/blob/master/official/wide_deep/wide_deep_run_loop.py#L101-L104 
show that the train loop is not determined by train_epochs, but train_epochs/2 (by default).
Therefore, there is no work to do when train_epochs is 1. 
Also, when users specify train_epochs=40, it only gets trained for 20 epochs? 


### Source code / logs
Code prints out some log and exits.
",wei-v-wang,None,2018-08-01T00:35:27Z,2018-08-01T19:58:36Z,,,,,,,
4953,"ValueError: Tensor conversion requested dtype string for Tensor with dtype float32: 'Tensor(""arg0:0"", shape=(), dtype=float32, device=/device:CPU:0)'","Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:/models/research/object_detection
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:no
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: windows10 64-bit
- **TensorFlow installed from (source or binary)**:binary
- **TensorFlow version (use command below)**:1.9.0
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:CPU version
- **GPU model and memory**:CPU version
- **Exact command to reproduce**: python train.py --logtostderr --train_dir=training/ --pipeline_config_path=training/ssd_mobilenet_v1_pets.config

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
iam trying to train my model with trian.py, i set all thing like tfrecord files and images, but when start training this error appear please help 
thanks in advenced

### Source code / logs
WARNING:tensorflow:From C:\Users\DELL\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\platform\app.py:125: main (from __main__) is deprecated and will be removed in a future version.
Instructions for updating:
Use object_detection/model_main.py.
WARNING:tensorflow:From E:\projectx\model-master\models-master\research\object_detection\legacy\trainer.py:262: create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Please switch to tf.train.create_global_step
WARNING:tensorflow:num_readers has been reduced to 0 to match input file shards.
Traceback (most recent call last):
  File ""train.py"", line 184, in <module>
    tf.app.run()
  File ""C:\Users\DELL\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\platform\app.py"", line 125, in run
    _sys.exit(main(argv))
  File ""C:\Users\DELL\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\util\deprecation.py"", line 250, in new_func
    return func(*args, **kwargs)
  File ""train.py"", line 180, in main
    graph_hook_fn=graph_rewriter_fn)
  File ""E:\projectx\model-master\models-master\research\object_detection\legacy\trainer.py"", line 276, in train
    train_config.prefetch_queue_capacity, data_augmentation_options)
  File ""E:\projectx\model-master\models-master\research\object_detection\legacy\trainer.py"", line 59, in create_input_queue
    tensor_dict = create_tensor_dict_fn()
  File ""train.py"", line 121, in get_next
    dataset_builder.build(config)).get_next()
  File ""E:\projectx\model-master\models-master\research\object_detection\builders\dataset_builder.py"", line 134, in build
    config.input_path[:], input_reader_config)
  File ""E:\projectx\model-master\models-master\research\object_detection\builders\dataset_builder.py"", line 80, in read_dataset
    sloppy=config.shuffle))
  File ""C:\Users\DELL\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\data\ops\dataset_ops.py"", line 1002, in apply
    dataset = transformation_func(self)
  File ""C:\Users\DELL\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\contrib\data\python\ops\interleave_ops.py"", line 88, in _apply_fn
    buffer_output_elements, prefetch_input_elements)
  File ""C:\Users\DELL\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\data\ops\readers.py"", line 130, in __init__
    cycle_length, block_length)
  File ""C:\Users\DELL\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\data\ops\dataset_ops.py"", line 1988, in __init__
    super(InterleaveDataset, self).__init__(input_dataset, map_func)
  File ""C:\Users\DELL\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\data\ops\dataset_ops.py"", line 1957, in __init__
    self._map_func.add_to_graph(ops.get_default_graph())
  File ""C:\Users\DELL\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\framework\function.py"", line 475, in add_to_graph
    self._create_definition_if_needed()
  File ""C:\Users\DELL\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\framework\function.py"", line 331, in _create_definition_if_needed
    self._create_definition_if_needed_impl()
  File ""C:\Users\DELL\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\framework\function.py"", line 340, in _create_definition_if_needed_impl
    self._capture_by_value, self._caller_device)
  File ""C:\Users\DELL\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\framework\function.py"", line 804, in func_graph_from_py_func
    outputs = func(*func_graph.inputs)
  File ""C:\Users\DELL\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\data\ops\dataset_ops.py"", line 1945, in tf_map_func
    dataset = map_func(nested_args)
  File ""C:\Users\DELL\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\data\ops\readers.py"", line 196, in __init__
    filenames = ops.convert_to_tensor(filenames, dtype=dtypes.string)
  File ""C:\Users\DELL\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\framework\ops.py"", line 1011, in convert_to_tensor
    as_ref=False)
  File ""C:\Users\DELL\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\framework\ops.py"", line 1107, in internal_convert_to_tensor
    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
  File ""C:\Users\DELL\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\framework\ops.py"", line 944, in _TensorTensorConversionFunction
    (dtype.name, t.dtype.name, str(t)))
ValueError: Tensor conversion requested dtype string for Tensor with dtype float32: 'Tensor(""arg0:0"", shape=(), dtype=float32, device=/device:CPU:0)'
",D0o0D,None,2018-07-31T13:15:27Z,2019-02-23T06:11:49Z,,,,,,,
4941,Save Best Model option for eval.py,"- **What is the top-level directory of the model you are using**: object_detection
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:no
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: N/a
- **TensorFlow installed from (source or binary)**:source 
- **TensorFlow version (use command below)**:N/a
- **Bazel version (if compiling from source)**:N/a
- **CUDA/cuDNN version**:N/a
- **GPU model and memory**:N/a
- **Exact command to reproduce**:N/a

New feature, 
Hi I know that in keras, when you train there is an option `save_best` for saving the best model evaluation depend on the matric you want (`loss`, `acc`, or custom )

is there an option to add this when using eval.py for evaluating the train model? 
the matric can be one of the `metrics_set` in the eval_config 
that can save space when training for long time and you don't want to save all the train checkpoint 

Thanks.

 

Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",mbenami,None,2018-07-30T15:00:29Z,2020-02-03T10:22:52Z,,,,,,,
4939,Changes in the API not documented ,"### System information
- **What is the top-level directory of the model you are using**: Object Detection
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: 16.04
- **TensorFlow installed from (source or binary)**: Binary
- **TensorFlow version (use command below)**: 1.8
- **Bazel version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: Cuda 9.0
- **GPU model and memory**: K80
- **Exact command to reproduce**: N/A


### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

Since the day OpenImageData challenge has started, the API has changed a lot. I have two repos cloned in my computer. The older one contains `train.py`, `eval.py`, etc and everything worked as it was documented in the source code. Now, this whole API has changed and the worst thing is nothing in the documentation has been updated how to run the models or evaluate them. Also, it feels like everything is in favour of TPUs, which of course most people don't use. Also, earlier API was compatible with both Python2 and Python3. Now the `coco_evaluation` py file used is incompatible with Python3.5. 

Can you please clear what's going on here?
",AakashKumarNain,None,2018-07-30T09:26:42Z,2020-01-30T16:16:49Z,,,,,,,
4937,TypeError: __new__() got an unexpected keyword argument 'file',"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",ttcctt,None,2018-07-30T05:11:49Z,2018-07-30T23:31:00Z,,,,,,,
4936,object_detection.model_main.py error:Paddings must be non-negative,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

System information
- What is the top-level directory of the model you are using:research/object_detection
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):no
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Linux Ubuntu 16.04
- TensorFlow installed from (source or binary):binary
- TensorFlow version (use command below):1.8.0
- Bazel version (if compiling from source):
- CUDA/cuDNN version:9.0.176 7.0.5
- GPU model and memory:GeForce GTX 1080 Ti totalMemory: 10.92GiB freeMemory: 10.35GiB
- Exact command to reproduce:python /models/research/object_detection/model_main.py --pipeline_config_path=faster_rcnn_inception_resnet_v2.config --model_dir=. /

### Describe the problem
When my dataset contains small objects(bbox height / image height <=0.02, same with bbox width), the error happens as follows:

![image](https://user-images.githubusercontent.com/17944419/43378088-1dce775e-93f7-11e8-8c1b-87206fb7f19e.png)
However, when i filtered out those samll objects, it can run without any errors.
Anyone could help me explain that's why. Thank you very much.
",zhangmengya,None,2018-07-30T04:58:17Z,2018-08-01T18:43:56Z,,,,,,,
4927,Fix a couple of bugs and edit spacing,"Bugs fixed:
 * replaced the fizzbuzz call whose signature no longer matched
 * remove the Flatter layer which seems to be buggy

Note: is there a way to include external colabs into tests?",mdanatg,b'cla: yes',2018-07-28T12:42:47Z,2018-07-30T14:02:48Z,,,,,,,
4909,"ValueError: Tensor conversion requested dtype string for Tensor with dtype float32: 'Tensor(""arg0:0"", shape=(), dtype=float32, device=/device:CPU:0)'","Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**: /models/research/object_detection
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04 LTS
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: Tensorflow 1.9.0
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**: none, CPU version
- **GPU model and memory**: none
- **Exact command to reproduce**: python model_main.py --logtostderr --model_dir=training/ --pipeline_config_path=training/ssd_mobilenet_v1_pets.config

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
It is a bug. I am trying to train my model using model_main.py in the object detection folder. I have tf_record, images and other data setup. I get this error when I run both model_main.py and train.py. Please help me train the model.

### Source code / logs
/models/research/object_detection$ python model_main.py --logtostderr --model_dir=training/ --pipeline_config_path=training/ssd_mobilenet_v1_pets.config
WARNING:tensorflow:Estimator's model_fn (<function model_fn at 0x7f1bc431f6e0>) includes params argument, but params are not passed to Estimator.
WARNING:tensorflow:num_readers has been reduced to 0 to match input file shards.
Traceback (most recent call last):
  File ""model_main.py"", line 101, in <module>
    tf.app.run()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run
    _sys.exit(main(argv))
  File ""model_main.py"", line 97, in main
    tf.estimator.train_and_evaluate(estimator, train_spec, eval_specs[0])
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/training.py"", line 447, in train_and_evaluate
    return executor.run()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/training.py"", line 531, in run
    return self.run_local()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/training.py"", line 669, in run_local
    hooks=train_hooks)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py"", line 366, in train
    loss = self._train_model(input_fn, hooks, saving_listeners)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py"", line 1119, in _train_model
    return self._train_model_default(input_fn, hooks, saving_listeners)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py"", line 1129, in _train_model_default
    input_fn, model_fn_lib.ModeKeys.TRAIN))
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py"", line 985, in _get_features_and_labels_from_input_fn
    result = self._call_input_fn(input_fn, mode)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py"", line 1074, in _call_input_fn
    return input_fn(**kwargs)
  File ""/home/kumar/Data/rec/Tesnorflow_Beginners/models/research/object_detection/inputs.py"", line 412, in _train_input_fn
    batch_size=params['batch_size'] if params else train_config.batch_size)
  File ""/home/kumar/Data/rec/Tesnorflow_Beginners/models/research/object_detection/builders/dataset_builder.py"", line 134, in build
    config.input_path[:], input_reader_config)
  File ""/home/kumar/Data/rec/Tesnorflow_Beginners/models/research/object_detection/builders/dataset_builder.py"", line 80, in read_dataset
    sloppy=config.shuffle))
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py"", line 1002, in apply
    dataset = transformation_func(self)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/data/python/ops/interleave_ops.py"", line 88, in _apply_fn
    buffer_output_elements, prefetch_input_elements)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/data/ops/readers.py"", line 130, in __init__
    cycle_length, block_length)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py"", line 1988, in __init__
    super(InterleaveDataset, self).__init__(input_dataset, map_func)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py"", line 1957, in __init__
    self._map_func.add_to_graph(ops.get_default_graph())
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/function.py"", line 475, in add_to_graph
    self._create_definition_if_needed()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/function.py"", line 331, in _create_definition_if_needed
    self._create_definition_if_needed_impl()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/function.py"", line 340, in _create_definition_if_needed_impl
    self._capture_by_value, self._caller_device)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/function.py"", line 804, in func_graph_from_py_func
    outputs = func(*func_graph.inputs)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py"", line 1945, in tf_map_func
    dataset = map_func(nested_args)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/data/ops/readers.py"", line 196, in __init__
    filenames = ops.convert_to_tensor(filenames, dtype=dtypes.string)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 1011, in convert_to_tensor
    as_ref=False)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 1107, in internal_convert_to_tensor
    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 944, in _TensorTensorConversionFunction
    (dtype.name, t.dtype.name, str(t)))
ValueError: Tensor conversion requested dtype string for Tensor with dtype float32: 'Tensor(""arg0:0"", shape=(), dtype=float32, device=/device:CPU:0)'",manu1a,b'stat:awaiting response',2018-07-26T12:35:02Z,2020-08-16T07:54:37Z,,,,,,,
4896,[Transformer] ResourceExhaustedError: OOM during training official/transformer,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
official
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
1.9.0
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
P100
- **Exact command to reproduce**:
PARAM_SET=big
DATA_DIR=$HOME/transformer/data
MODEL_DIR=$HOME/transformer/model_$PARAM_SET
VOCAB_FILE=$DATA_DIR/vocab.ende.32768
python data_download.py --data_dir=$DATA_DIR
python transformer_main.py --data_dir=$DATA_DIR --model_dir=$MODEL_DIR \
      --vocab_file=$VOCAB_FILE --param_set=$PARAM_SET \
      --bleu_source=test_data/newstest2014.en --bleu_ref=test_data/newstest2014.de

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.
It throws ResourceExhaustedError: OOM when training a Transformer model in models/official/transformer with instructions of Walkthrough on the page of https://github.com/tensorflow/models/tree/master/official/transformer

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",theJiangYu,None,2018-07-25T17:27:31Z,2018-07-26T03:56:15Z,,,,,,,
4894,"""RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility"" when importing tensorflow","Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**: research
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 18.01 (Nvidia GPU Container)
- **TensorFlow installed from (source or binary)**: Nvidia GPu Cloud Tensorflow Container
- **TensorFlow version (use command below)**: 1.4.0
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**: CUDA 9.0 / cuDNN 7.0.5
- **GPU model and memory**: Tesla K80 11GB
- **Exact command to reproduce**: python -c 'import numpy; print(numpy.__file__, numpy.__version__)'

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.
When I try to import tensorflow in python, I get too many warnings related to numpy. I am using tensorflow  provided by NVIDIA GPU Cloud. I have managed to run train.py before in the exact same environment before so warnings has nothing to do with Docker container. Here is the log when I run `python object_detection/legacy/train.py --logtostderr --train_dir=/home/Traffic-Signs-Detect-German/models/faster/ --pipeline_config_path=/home/Traffic-Signs-Detect-German/models/faster/faster_rcnn_inception_v2_coco_2018_01_28/pipeline.config`:

`/usr/local/lib/python2.7/dist-packages/h5py/__init__.py:36: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  from ._conv import register_converters as _register_converters
/usr/local/lib/python2.7/dist-packages/h5py/__init__.py:45: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  from . import h5a, h5d, h5ds, h5f, h5fd, h5g, h5r, h5s, h5t, h5p, h5z
/usr/local/lib/python2.7/dist-packages/h5py/_hl/group.py:22: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  from .. import h5g, h5i, h5o, h5r, h5t, h5l, h5p
/usr/local/lib/python2.7/dist-packages/scipy/linalg/basic.py:17: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  from ._solve_toeplitz import levinson
/usr/local/lib/python2.7/dist-packages/scipy/linalg/__init__.py:207: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  from ._decomp_update import *
/usr/local/lib/python2.7/dist-packages/scipy/special/__init__.py:640: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  from ._ufuncs import *
/usr/local/lib/python2.7/dist-packages/scipy/special/_ellip_harm.py:7: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  from ._ellip_harm_2 import _ellipsoid, _ellipsoid_norm
/usr/local/lib/python2.7/dist-packages/scipy/interpolate/_bsplines.py:10: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  from . import _bspl
/usr/local/lib/python2.7/dist-packages/scipy/sparse/lil.py:19: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  from . import _csparsetools
/usr/local/lib/python2.7/dist-packages/scipy/sparse/csgraph/__init__.py:165: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  from ._shortest_path import shortest_path, floyd_warshall, dijkstra,\
/usr/local/lib/python2.7/dist-packages/scipy/sparse/csgraph/_validation.py:5: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  from ._tools import csgraph_to_dense, csgraph_from_dense,\
/usr/local/lib/python2.7/dist-packages/scipy/sparse/csgraph/__init__.py:167: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  from ._traversal import breadth_first_order, depth_first_order, \
/usr/local/lib/python2.7/dist-packages/scipy/sparse/csgraph/__init__.py:169: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  from ._min_spanning_tree import minimum_spanning_tree
/usr/local/lib/python2.7/dist-packages/scipy/sparse/csgraph/__init__.py:170: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  from ._reordering import reverse_cuthill_mckee, maximum_bipartite_matching, \
/usr/local/lib/python2.7/dist-packages/scipy/spatial/__init__.py:95: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  from .ckdtree import *
/usr/local/lib/python2.7/dist-packages/scipy/spatial/__init__.py:96: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  from .qhull import *
/usr/local/lib/python2.7/dist-packages/scipy/spatial/_spherical_voronoi.py:18: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  from . import _voronoi
/usr/local/lib/python2.7/dist-packages/scipy/spatial/distance.py:122: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  from . import _hausdorff
/usr/local/lib/python2.7/dist-packages/scipy/ndimage/measurements.py:36: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  from . import _ni_label
/usr/local/lib/python2.7/dist-packages/pandas/_libs/__init__.py:4: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  from .tslib import iNaT, NaT, Timestamp, Timedelta, OutOfBoundsDatetime
/usr/local/lib/python2.7/dist-packages/pandas/__init__.py:26: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  from pandas._libs import (hashtable as _hashtable,
/usr/local/lib/python2.7/dist-packages/pandas/core/dtypes/common.py:6: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  from pandas._libs import algos, lib
/usr/local/lib/python2.7/dist-packages/pandas/core/util/hashing.py:7: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  from pandas._libs import hashing, tslib
/usr/local/lib/python2.7/dist-packages/pandas/core/indexes/base.py:7: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  from pandas._libs import (lib, index as libindex, tslib as libts,
/usr/local/lib/python2.7/dist-packages/pandas/tseries/offsets.py:21: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  import pandas._libs.tslibs.offsets as liboffsets
/usr/local/lib/python2.7/dist-packages/pandas/core/ops.py:16: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  from pandas._libs import algos as libalgos, ops as libops
/usr/local/lib/python2.7/dist-packages/pandas/core/indexes/interval.py:32: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  from pandas._libs.interval import (
/usr/local/lib/python2.7/dist-packages/pandas/core/internals.py:14: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  from pandas._libs import internals as libinternals
/usr/local/lib/python2.7/dist-packages/pandas/core/sparse/array.py:33: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  import pandas._libs.sparse as splib
/usr/local/lib/python2.7/dist-packages/pandas/core/window.py:36: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  import pandas._libs.window as _window
/usr/local/lib/python2.7/dist-packages/pandas/core/groupby/groupby.py:68: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  from pandas._libs import (lib, reduction,
/usr/local/lib/python2.7/dist-packages/pandas/core/reshape/reshape.py:30: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  from pandas._libs import algos as _algos, reshape as _reshape
/usr/local/lib/python2.7/dist-packages/pandas/io/parsers.py:45: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  import pandas._libs.parsers as parsers
/usr/local/lib/python2.7/dist-packages/pandas/io/pytables.py:50: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  from pandas._libs import algos, lib, writers as libwriters
WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py:48: main (from __main__) is deprecated and will be removed in a future version.
Instructions for updating:
Use object_detection/model_main.py.
WARNING:tensorflow:From /home/models/research/object_detection/legacy/trainer.py:262: create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Please switch to tf.train.create_global_step
WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.
Traceback (most recent call last):
  File ""object_detection/legacy/train.py"", line 184, in <module>
    tf.app.run()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 48, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/util/deprecation.py"", line 136, in new_func
    return func(*args, **kwargs)
  File ""object_detection/legacy/train.py"", line 180, in main
    graph_hook_fn=graph_rewriter_fn)
  File ""/home/models/research/object_detection/legacy/trainer.py"", line 276, in train
    train_config.prefetch_queue_capacity, data_augmentation_options)
  File ""/home/models/research/object_detection/legacy/trainer.py"", line 59, in create_input_queue
    tensor_dict = create_tensor_dict_fn()
  File ""object_detection/legacy/train.py"", line 121, in get_next
    dataset_builder.build(config)).get_next()
  File ""/home/models/research/object_detection/builders/dataset_builder.py"", line 134, in build
    config.input_path[:], input_reader_config)
  File ""/home/models/research/object_detection/builders/dataset_builder.py"", line 76, in read_dataset
    tf.contrib.data.parallel_interleave(
AttributeError: 'module' object has no attribute 'parallel_interleave'`

However, I get the same same numpy warnings/errors when I do `python -c 'import numpy; print(numpy.__file__, numpy.__version__)'`.

I can't understand why numpy raises this error.

Lastly what is ""AttributeError: 'module' object has no attribute 'parallel_interleave'"" error and how can I fix this? Thanks in advance.


### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",doruksonmez,None,2018-07-25T10:49:05Z,2018-07-25T13:20:44Z,,,,,,,
4872,[ObjectDetecion]model_main.py stop working without any error throw.,"# System information
- What is the top-level directory of the model you are using: Object Detection
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 1.9.0
- Bazel version (if compiling from source):
- CUDA/cuDNN version:  CUDA 9.0
- GPU model and memory: GTX 1080TI 11GB
- Python  Version: 3.6.5
- Code Version: @MarkDaoust Merge pull request #4784 from rrrutledge/patch-1 
- Exact command to reproduce:
```cmd
python model_main.py \
-model_dir=F:\Pascal\model \
-pipeline_config_path=F:\Pascal\faster_rcnn_resnet101_voc07.tfconfig \
-num_train_steps=10 \
-num_eval_steps=1
```
# Describe the problem
model_main.py stop working without any error throw.

# Custom code
```python
# learning_schedules.py line171-176
if six.PY2:
    rate_index = tf.reduce_max(tf.where(tf.greater_equal(global_step, boundaries),
                                        range(num_boundaries),
                                        [0] * num_boundaries))
else:
    rate_index = tf.reduce_max(tf.where(tf.greater_equal(global_step, boundaries),
                                        list(range(num_boundaries)),
                                        [0] * num_boundaries))


# model_lib.py 
# line282-283
if six.PY2:
    losses = [loss_tensor for loss_tensor in losses_dict.itervalues()]
else:
    losses = [loss_tensor for loss_tensor in losses_dict.values()]

# lin379-383
if six.PY2:
    eval_metric_ops = eval_util.get_eval_metric_ops_for_evaluators(
            eval_metrics,
            category_index.values(),
            eval_dict,
            include_metrics_per_category=eval_config.include_metrics_per_category)
else:
     eval_metric_ops = eval_util.get_eval_metric_ops_for_evaluators(
            eval_metrics,
            list(category_index.values()),
            eval_dict,
            include_metrics_per_category=eval_config.include_metrics_per_category)

# line 391
if six.PY2:
    eval_metric_ops = {str(k): v for k, v in eval_metric_ops.iteritems()}
else:
    eval_metric_ops = {str(k): v for k, v in eval_metric_ops.items()}

# obeject_detection_evalution: 
# line 842-844: print **->print(***) 
# line 775-775: pycharm tell me error in this line, but I do not know how to fix.
```

# Log
```
D:\Python\v3.6.5\python.exe D:\PyCharm\helpers\pydev\pydevd.py --multiproc --qt-support=auto --client 127.0.0.1 --port 60069 --file E:/Python/Tensorflow/models/research/object_detection/model_main.py -model_dir=F:\Pascal\model_v1 -pipeline_config_path=F:\Pascal\faster_rcnn_resnet101_voc07.tfconfig -num_train_steps=10 -num_eval_steps=1
pydev debugger: process 9040 is connecting

Connected to pydev debugger (build 181.5087.37)
E:\Python\Tensorflow\models\research\object_detection\utils\visualization_utils.py:25: UserWarning: 
This call to matplotlib.use() has no effect because the backend has already
been chosen; matplotlib.use() must be called *before* pylab, matplotlib.pyplot,
or matplotlib.backends is imported for the first time.

The backend was *originally* set to 'module://backend_interagg' by the following code:
  File ""D:\PyCharm\helpers\pydev\pydevd.py"", line 1664, in <module>
    main()
  File ""D:\PyCharm\helpers\pydev\pydevd.py"", line 1658, in main
    globals = debugger.run(setup['file'], None, None, is_module)
  File ""D:\PyCharm\helpers\pydev\pydevd.py"", line 1068, in run
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File ""D:\PyCharm\helpers\pydev\_pydev_imps\_pydev_execfile.py"", line 18, in execfile
    exec(compile(contents+""\n"", file, 'exec'), glob, loc)
  File ""E:/Python/Tensorflow/models/research/object_detection/model_main.py"", line 26, in <module>
    from object_detection import model_lib
  File ""E:\Python\Tensorflow\models\research\object_detection\model_lib.py"", line 27, in <module>
    from object_detection import eval_util
  File ""E:\Python\Tensorflow\models\research\object_detection\eval_util.py"", line 28, in <module>
    from object_detection.metrics import coco_evaluation
  File ""E:\Python\Tensorflow\models\research\object_detection\metrics\coco_evaluation.py"", line 20, in <module>
    from object_detection.metrics import coco_tools
  File ""E:\Python\Tensorflow\models\research\object_detection\metrics\coco_tools.py"", line 47, in <module>
    from pycocotools import coco
  File ""E:\Python\Tensorflow\models\research\pycocotools\coco.py"", line 49, in <module>
    import matplotlib.pyplot as plt
  File ""D:\Python\v3.6.5\lib\site-packages\matplotlib\pyplot.py"", line 71, in <module>
    from matplotlib.backends import pylab_setup
  File ""D:\Python\v3.6.5\lib\site-packages\matplotlib\backends\__init__.py"", line 16, in <module>
    line for line in traceback.format_stack()


 import matplotlib; matplotlib.use('Agg')  # pylint: disable=multiple-statements
WARNING:tensorflow:Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x000001DBA7F699D8>) includes params argument, but params are not passed to Estimator.
WARNING:tensorflow:From E:\Python\Tensorflow\models\research\object_detection\core\box_predictor.py:407: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.
Instructions for updating:
keep_dims is deprecated, use keepdims instead
WARNING:tensorflow:From E:\Python\Tensorflow\models\research\object_detection\core\losses.py:317: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.
Instructions for updating:

Future major versions of TensorFlow will allow gradients to flow
into the labels input on backprop by default.

See @{tf.nn.softmax_cross_entropy_with_logits_v2}.

2018-07-24 09:39:43.894154: I T:\src\github\tensorflow\tensorflow\core\platform\cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2
2018-07-24 09:39:44.134999: I T:\src\github\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:1392] Found device 0 with properties: 
name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.6575
pciBusID: 0000:04:00.0
totalMemory: 11.00GiB freeMemory: 9.10GiB
2018-07-24 09:39:44.135293: I T:\src\github\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:1471] Adding visible gpu devices: 0
2018-07-24 09:39:44.786038: I T:\src\github\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-07-24 09:39:44.786213: I T:\src\github\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:958]      0 
2018-07-24 09:39:44.786323: I T:\src\github\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:971] 0:   N 
2018-07-24 09:39:44.786553: I T:\src\github\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 8799 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:04:00.0, compute capability: 6.1)
creating index...
index created!
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=0.00s).
Accumulating evaluation results...
DONE (t=0.03s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000
2018-07-24 09:40:07.278933: I T:\src\github\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:1471] Adding visible gpu devices: 0
2018-07-24 09:40:07.279149: I T:\src\github\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-07-24 09:40:07.279332: I T:\src\github\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:958]      0 
2018-07-24 09:40:07.279443: I T:\src\github\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:971] 0:   N 
2018-07-24 09:40:07.279608: I T:\src\github\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 8799 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:04:00.0, compute capability: 6.1)

Process finished with exit code -1
```

# faster_rcnn_resnet101_voc07.tfconfig
only eval_config, train_config, and PATH_TO_BE_CONFIGURED changed.
```prototxt
eval_config: {
  num_examples: 2000
  max_evals: 10
  eval_interval_secs: 10
  metrics_set: ""coco_detection_metrics""
}
train_config {
 ...
 # fine_tune_checkpoint: ""F:/Pascal/rfcn_resnet101_coco_2018_01_28/model.ckpt""
 # from_detection_checkpoint: false
 ...
}
```",kingstarcraft,None,2018-07-24T02:13:08Z,2019-01-16T01:05:13Z,,,,,,,
4869,No step/loss information while training.,"### System information
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
xubuntu-16.04.4-desktop-amd64
- **TensorFlow installed from (source or binary)**:
installed via pip
- **TensorFlow version (use command below)**:
v1.9.0-0-g25c197e023 1.9.0
- **GPU model and memory**:
I am using the cpu version.



### Describe the problem
Today I pulled the new version and updated as mentioned above to tensorflow 1.9 . 
I'm using the ssd_mobilenet_v2_coco checkpoint to train on images of raccoons provided in this repository https://github.com/datitran/raccoon_dataset.
While training there is no output regarding step and or loss. This was previously the case. Is this working as intended or is it a bug? 

EDIT: I had to set the logging to INFO. Nevermind me.",FG-33,None,2018-07-23T14:53:44Z,2018-07-27T07:35:43Z,,,,,,,
4863,[object_detection] image summary 'Detections_Left_Groundtruth_Right' in eval_metric_ops caused OutOfRangeError,"### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: binary 
- **TensorFlow version (use command below)**: 1.10.0-dev20180721
- **Bazel version (if compiling from source)**: 
- **CUDA/cuDNN version**: 9.0/7
- **GPU model and memory**: Tesla K80
- **Exact command to reproduce**: 

Set `eval_input_reader.num_epochs` of `${PIPELINE_CONFIG}` to `1`, and set `eval_config.num_examples` of `${PIPELINE_CONFIG}` to some value greater than the number of examples in `eval_input_reader`. 

Run
`python3 object_detection/model_main.py --pipeline_config_path=${PIPELINE_CONFIG} --checkpoint_dir=${MODEL_DIR}`

---

After [evaluating all the examples](https://github.com/tensorflow/tensorflow/blob/fa9d8aab41249cfc901338dfcb38cedb7ed1e603/tensorflow/python/training/evaluation.py#L211) in the input source, `Estimator` will [run](https://github.com/tensorflow/tensorflow/blob/fa9d8aab41249cfc901338dfcb38cedb7ed1e603/tensorflow/python/training/evaluation.py#L211) `value_op`s of `eval_metric_ops` to get the `eval_results`.

The `value_op` of `eval_metric_ops['Detections_Left_Groundtruth_Right']` is [`img_summary`](https://github.com/tensorflow/models/blob/85dd5fa4ba406b953550f20269cadddac5303241/research/object_detection/model_lib.py#L390), which is a tensor depending on the input source. Running `img_summary` will cause `OutOfRangeError` if the input source has been exhausted.

[Removing `Detections_Left_Groundtruth_Right` from `eval_metric_ops`](https://github.com/tensorflow/models/blob/85dd5fa4ba406b953550f20269cadddac5303241/research/object_detection/model_lib.py#L388-L390) or save the summary to a `Variable` may be temporary workarounds.",manipopopo,b'stat:awaiting maintainer type:bug',2018-07-22T06:21:01Z,2020-01-30T01:07:11Z,,,,,,,
4849,Loss diverges to very high values in Object Detection API,"### System information
- **What is the top-level directory of the model you are using**: object_detection
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.8
- **Bazel version (if compiling from source)**: no
- **CUDA/cuDNN version**: 9.0/7.0
- **GPU model and memory**: NVIDIA GeForce GTX 1080 Ti
- **Exact command to reproduce**: python train.py --logtostderr --pipeline_config_path=rfcn_resnet101_custom.config --train_dir=custom_train_dir

### Describe the problem
While training a detection model with the object detection API (RFCN with Resnet v1 101 feature extractor) I encountered what looks like a bug to me (maybe an overflow). After learning for a little while without problems (with a custom dataset) the loss begins to display very large values that grow very quickly. At first I thought there was an overflow on the loss value but it seems more progressive:
INFO:tensorflow:global step 69: loss = 0.5207 (0.422 sec/step)
INFO:tensorflow:global step 70: loss = 0.2422 (0.406 sec/step)
INFO:tensorflow:global step 71: loss = 0.5621 (0.391 sec/step)
INFO:tensorflow:global step 72: loss = 1.5380 (0.422 sec/step)
INFO:tensorflow:global step 73: loss = 0.3814 (0.422 sec/step)
INFO:tensorflow:global step 74: loss = 0.6671 (0.406 sec/step)
INFO:tensorflow:global step 75: loss = 1.8687 (0.422 sec/step)
INFO:tensorflow:global step 76: loss = 1.4388 (0.438 sec/step)
INFO:tensorflow:global step 77: loss = 5.7769 (0.391 sec/step)
INFO:tensorflow:global step 78: loss = 15.7012 (0.391 sec/step)
INFO:tensorflow:global step 79: loss = 18.4020 (0.391 sec/step)
INFO:tensorflow:global step 80: loss = 0.1409 (0.422 sec/step)
INFO:tensorflow:global step 81: loss = 41.4890 (0.391 sec/step)
INFO:tensorflow:global step 82: loss = 391.0323 (0.391 sec/step)
INFO:tensorflow:global step 83: loss = 1184.6780 (0.391 sec/step)
INFO:tensorflow:global step 84: loss = 113833.9297 (0.406 sec/step)
INFO:tensorflow:global step 85: loss = 1028554.8125 (0.422 sec/step)
INFO:tensorflow:global step 86: loss = 2339703.2500 (0.406 sec/step)
INFO:tensorflow:global step 87: loss = 4837331.0000 (0.406 sec/step)
INFO:tensorflow:global step 88: loss = 120685024.0000 (0.406 sec/step)
INFO:tensorflow:global step 89: loss = 3053880832.0000 (0.375 sec/step)
INFO:tensorflow:global step 90: loss = 74913587200.0000 (0.406 sec/step)
INFO:tensorflow:global step 91: loss = 299197333504.0000 (0.406 sec/step)
INFO:tensorflow:global step 92: loss = 22885305417728.0000 (0.406 sec/step)
INFO:tensorflow:global step 93: loss = 710914261123072.0000 (0.406 sec/step)

See the attached log file for more details. I was not able to locate any memory allocation problems during the execution. I also included the custom code I used to transform my data into a tfrecord file (taken from the create_pascal_tf_record.py script), the label map and config I used. The strange thing is that when I do exactly the same thing with a label map with only 1 label, the training works fine and converges. I know there are some mistakes for some labels associated to the bounding boxes, but they are not that frequent, and if it was a problem caused for example by too few data for some classes, isn't the training supposed only not to converge instead of displaying very high values? Do you have any idea of what can cause this behavior? Thanks a lot for your help.


### Source code / logs
[object_detection.zip](https://github.com/tensorflow/models/files/2213972/object_detection.zip)

",Rayndell,None,2018-07-20T12:58:18Z,2019-10-23T12:16:40Z,,,,,,,
4824,Feature request: Support for Eager Execution during debugging,Currently the eager execution does not for tensorflow 1.7. Even when you upgrade to 1.8 there are issues with the queue for the eager execution. Having the capability of eager execution would be great for debugging.,ravikantgupta9,b'stat:awaiting response type:support',2018-07-18T20:44:41Z,2020-07-10T09:55:08Z,,,,,,,
4822,Fixed minor bug in STEVE which sometimes prevented resuming experiments.,"Tiny bug: sometimes, when resuming an experiment, the experiment would resume right at a logging step, and would attempt to log even though there has not yet been any data stored, leading to a divide-by-zero.",buckman-google,b'cla: yes',2018-07-18T18:44:13Z,2018-07-20T19:35:29Z,,,,,,,
4819,New Object Detection Estimator-based doesn't have GPU options?,"
### System information
- **What is the top-level directory of the model you are using**: object_detection
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: Binary
- **TensorFlow version (use command below)**: 1.8.0
- **Bazel version (if compiling from source)**: None
- **CUDA/cuDNN version**: 9.0
- **GPU model and memory**: 4 GTX 1080 TI 
- **Exact command to reproduce**: `python model_main.py ...`

### Describe the problem

The `train.py` script now in `/legacy` had simple options to set number of GPUs to use. I don't see any corresponding options in the new `model_main.py`. Is this a bug? There must still be functionality for selecting GPUs without rewriting the model code, right? Or else this seems like a step backwards?


",austinmw,None,2018-07-18T15:22:24Z,2020-02-07T18:47:19Z,,,,,,,
4813,[object-detection] Paddings must be non-negative: 0 -16,"## Bug

### System information
- **What is the top-level directory of the model you are using**: models/research
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes, but not relevant to bug.
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: ubuntu 16.04
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: 1.8.0
- **Bazel version (if compiling from source)**: 0.14.0
- **CUDA/cuDNN version**: 8.0/6.0
- **GPU model and memory**: 1080 Ti, 12 GB
- **Exact command to reproduce**:

```
python object_detection/model_main.py \
--logtostderr \
--model_dir /media/ssd1/sat_data_models/frcnn/train \
--pipeline_config_path {path_to_pipeline/pipeline.config} \
--num_train_steps 800000 \
--num_train_steps 20000
```

_Note: abstracted pipeline_config_path and model_dir, but these were set correctly._

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

Seems like a padding issue with an op using tf.pad.

Unable to trace stack due to `Estimator's` abstraction.

Trailing error lines:

```
session.run(eval_ops, feed_dict)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py"", line 567, in run
    run_metadata=run_metadata)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py"", line 1043, in run
    run_metadata=run_metadata)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py"", line 1134, in run
    raise six.reraise(*original_exc_info)
  File ""/home/user/.local/lib/python3.5/site-packages/six.py"", line 693, in reraise
    raise value
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py"", line 1119, in run
    return self._sess.run(*args, **kwargs)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py"", line 1191, in run
    run_metadata=run_metadata)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py"", line 971, in run
    return self._sess.run(*args, **kwargs)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py"", line 900, in run
    run_metadata_ptr)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py"", line 1135, in _run
    feed_dict_tensor, options, run_metadata)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py"", line 1316, in _do_run
    run_metadata)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py"", line 1335, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.InvalidArgumentError: Paddings must be non-negative: 0 -16
	 [[Node: Pad_11 = Pad[T=DT_FLOAT, Tpaddings=DT_INT32](cond_2/Merge, stack_11)]]
	 [[Node: IteratorGetNext = IteratorGetNext[output_shapes=[[1], [1,300,300,3], [1,?,?,3], [1,3], [1,100], [1,100,4], [1,100,60], [1,100], [1,100], [1,100], [1]], output_types=[DT_INT32, DT_FLOAT, DT_UINT8, DT_INT32, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_INT32, DT_BOOL, DT_FLOAT, DT_INT32], _device=""/job:localhost/replica:0/task:0/device:CPU:0""](Iterator)]]
```

The legacy train script was however doing okay.

Also seems like the Estimator built `model_main` doesn't output logs to std (of loss, global step). Only warnings and info are updated.

###  Config File (train config only uploaded)
 
```
train_config: {
  batch_size: 4
  optimizer {
    momentum_optimizer: {
      learning_rate: {
        manual_step_learning_rate {
          initial_learning_rate: 0.000003
          schedule {
            step: 900000
            learning_rate: .00000003
          }
          schedule {
            step: 1200000
            learning_rate: .000000003
          }
        }

  
  data_augmentation_options {
    random_horizontal_flip {
    }
    random_adjust_brightness{
    }
    random_adjust_contrast{
    }
    random_adjust_hue{
    }
    random_adjust_saturation{
    }
    random_distort_color{
    }
    random_crop_pad_image{
    }
    random_vertical_flip{
    }
    random_rotation90{
    }
  }
}


```",varun19299,None,2018-07-18T11:15:10Z,2020-02-07T18:47:19Z,,,,,,,
4808,Another Dataset,"Hello,
I want to ask, if there is a possibility to use your deep lab implementation on my own dataset for semantic segmentation task.
I have a dataset with semantic segmentation labels of 12 classes, is it possible to use your model ?






Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",mhusseinsh,b'stat:awaiting model gardener',2018-07-18T08:12:13Z,2020-02-07T18:47:18Z,,,,,,,
4799,[object_detection] Python has stopped working when I run model_main.py,"### System information
- **What is the top-level directory of the model you are using**: faster rcnn 101 resnet
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: N
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: tf-gpu 1.8.0rc0
- **Bazel version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: 9.0/v7
- **GPU model and memory**: GTX 1080TI
- **Exact command to reproduce**:

python object_detection/model_main.py --pipeline_config_path=object_detection/faster_rcnn_resnet_101.config --model_dir=object_detection/model/ --num_train_steps=30000 --num_eval_steps=2000

### Describe the problem
Every time I run the command, ""python has stopped working"" show up. When I ran on pycharm, I got ""Process finished with exit code -1073741819 (0xC0000005)"". 

### Source code / logs
(debug on MSVS2015)
'python.exe' (Win32): Loaded 'C:\Users\asd\anaconda3\Lib\site-packages\pandas\_libs\testing.cp35-win_amd64.pyd'. Module was built without symbols.
'python.exe' (Win32): Loaded 'C:\Users\asd\anaconda3\Lib\site-packages\matplotlib\_contour.cp35-win_amd64.pyd'. Module was built without symbols.
'python.exe' (Win32): Loaded 'C:\Users\asd\anaconda3\Lib\site-packages\matplotlib\ft2font.cp35-win_amd64.pyd'. Module was built without symbols.
'python.exe' (Win32): Loaded 'C:\Users\asd\anaconda3\Library\bin\freetype.dll'. Module was built without symbols.
'python.exe' (Win32): Loaded 'C:\Users\asd\anaconda3\Library\bin\libpng16.dll'. Module was built without symbols.
'python.exe' (Win32): Loaded 'C:\Users\asd\anaconda3\Lib\site-packages\matplotlib\_png.cp35-win_amd64.pyd'. Module was built without symbols.
'python.exe' (Win32): Loaded 'C:\Users\asd\anaconda3\Lib\site-packages\kiwisolver.cp35-win_amd64.pyd'. Module was built without symbols.
'python.exe' (Win32): Loaded 'C:\Users\asd\anaconda3\Lib\site-packages\matplotlib\_image.cp35-win_amd64.pyd'. Module was built without symbols.
'python.exe' (Win32): Loaded 'C:\Users\asd\anaconda3\Lib\site-packages\matplotlib\_tri.cp35-win_amd64.pyd'. Module was built without symbols.
'python.exe' (Win32): Loaded 'C:\Users\asd\anaconda3\Lib\site-packages\matplotlib\_qhull.cp35-win_amd64.pyd'. Module was built without symbols.
'python.exe' (Win32): Loaded 'C:\Users\asd\anaconda3\Lib\site-packages\matplotlib\backends\_backend_agg.cp35-win_amd64.pyd'. Module was built without symbols.
'python.exe' (Win32): Loaded 'C:\Users\asd\anaconda3\Lib\site-packages\sip.pyd'. Module was built without symbols.
'python.exe' (Win32): Loaded 'C:\Users\asd\anaconda3\Lib\site-packages\PyQt5\QtCore.pyd'. Module was built without symbols.
'python.exe' (Win32): Loaded 'C:\Users\asd\anaconda3\Library\bin\Qt5Core.dll'. Module was built without symbols.
'python.exe' (Win32): Loaded 'C:\Windows\System32\mpr.dll'. Cannot find or open the PDB file.
'python.exe' (Win32): Loaded 'C:\Users\asd\anaconda3\Library\bin\icuin58.dll'. Module was built without symbols.
'python.exe' (Win32): Loaded 'C:\Users\asd\anaconda3\Library\bin\icuuc58.dll'. Module was built without symbols.
'python.exe' (Win32): Loaded 'C:\Users\asd\anaconda3\Library\bin\icudt58.dll'. Module was built without symbols.
The thread 0x29c8 has exited with code 0 (0x0).
Unhandled exception at 0x000000005D0374A9 (python35.dll) in python.exe: 0xC0000005: Access violation reading location 0xFFFFFFFFFFFFFFFF.
",ycui123,None,2018-07-17T14:37:16Z,2018-07-25T13:16:34Z,,,,,,,
4787,[recommendation] protobuf::FatalException error,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:  models/official/recommendation
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04
- **TensorFlow installed from (source or binary)**:
pip anaconda  https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-1.9.0-cp34-cp34m-linux_x86_64.whl
- **TensorFlow version (use command below)**: branch r1.9.0
- **Bazel version (if compiling from source)**: 1.9.0
- **CUDA/cuDNN version**: cuda 9.2 / cuDNN7.0.5
- **GPU model and memory**:  Titan Xp, 12192MiB
- **Exact command to reproduce**: python ncf_main.py --model_dir model_20m  --data_dir data --dataset ml-20m



### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

code stops running with error messages

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.

$ python
Python 2.7.15 |Anaconda custom (64-bit)| (default, May  1 2018, 23:32:55) 

$ python ncf_main.py --model_dir model_20m  --data_dir data --dataset ml-20m
/home/n/anaconda3/envs/p27_cu92/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
2018-07-13 10:52:04.831652: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2018-07-13 10:52:04.915329: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:897] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-07-13 10:52:04.915744: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1392] Found device 0 with properties:
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:01:00.0
totalMemory: 11.91GiB freeMemory: 11.53GiB
2018-07-13 10:52:04.915755: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2018-07-13 10:52:05.065370: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-07-13 10:52:05.065407: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0
2018-07-13 10:52:05.065412: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N
2018-07-13 10:52:05.065610: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/device:GPU:0 with 11162 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:01:00.0, compute capability: 6.1)
I0713 10:52:05.157206 139797621028608 tf_logging.py:115] Data preprocessing...
I0713 10:53:16.772550 139797621028608 tf_logging.py:115] Creating Estimator from Keras model...
I0713 10:53:17.262474 139797621028608 tf_logging.py:115] Using the Keras model provided.
I0713 10:53:17.262778 139797621028608 tf_logging.py:115] Using config: {'_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_task_type': 'worker', '_global_id_in_cluster': 0, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f214e0a7210>, '_evaluation_master': '', '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_master': '', '_device_fn': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_model_dir': 'model_20m', '_train_distribute': <tensorflow.contrib.distribute.python.one_device_strategy.OneDeviceStrategy object at 0x7f214e0a71d0>, '_save_summary_steps': 100}
2018-07-13 10:53:17.263159: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2018-07-13 10:53:17.263193: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-07-13 10:53:17.263199: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0
2018-07-13 10:53:17.263218: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N
2018-07-13 10:53:17.263362: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11162 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:01:00.0, compute capability: 6.1)
2018-07-13 10:53:17.354058: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2018-07-13 10:53:17.354097: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-07-13 10:53:17.354103: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0
2018-07-13 10:53:17.354108: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N
2018-07-13 10:53:17.354218: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11162 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:01:00.0, compute capability: 6.1)
2018-07-13 10:53:19.087784: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2018-07-13 10:53:19.087843: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-07-13 10:53:19.087848: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0
2018-07-13 10:53:19.087852: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N
2018-07-13 10:53:19.088024: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/device:GPU:0 with 11162 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:01:00.0, compute capability: 6.1)
I0713 10:53:19.088659 139797621028608 tf_logging.py:115] Benchmark run: {'machine_config': {'cpu_info': {'cpu_info': 'Intel(R) Core(TM) i7-8700K CPU @ 3.70GHz', 'mhz_per_cpu': 3700.0, 'num_cores': 12}, 'gpu_info': {'count': 1, 'model': u'TITAN Xp'}, 'memory_total': 67480199168, 'memory_available': 60690792448}, 'run_date': '2018-07-13T17:53:17.670323Z', 'tensorflow_version': {'git_hash': 'v1.9.0-rc0-2716-ge1436b2952', 'version': '1.9.0-rc0'}, 'dataset': {'name': 'ml-20m'}, 'tensorflow_environment_variables': [], 'run_parameters': [{'long_value': 256, 'name': 'batch_size'}, {'name': 'hr_threshold', 'string_value': 'None'}, {'long_value': 8, 'name': 'number_factors'}, {'long_value': 2, 'name': 'train_epochs'}], 'model_name': 'recommendation'}
I0713 10:53:19.088999 139797621028608 tf_logging.py:115] Starting a training cycle: 1/2
I0713 10:55:52.807188 139797621028608 tf_logging.py:115] Calling model_fn.
I0713 10:55:53.052728 139797621028608 tf_logging.py:115] Done calling model_fn.
I0713 10:55:53.089109 139797621028608 tf_logging.py:115] Create CheckpointSaverHook.
[libprotobuf FATAL external/protobuf_archive/src/google/protobuf/message_lite.cc:68] CHECK failed: (byte_size_before_serialization) == (byte_size_after_serialization): tensorflow.GraphDef was modified concurrently during serialization.
terminate called after throwing an instance of 'google::protobuf::FatalException'
  what():  CHECK failed: (byte_size_before_serialization) == (byte_size_after_serialization): tensorflow.GraphDef was modified concurrently during serialization.
Aborted (core dumped)
",christ1ne,None,2018-07-16T20:40:08Z,2018-11-18T00:25:39Z,,,,,,,
4784,Loss -> Accuracy,"* Bug in label discovered at OSCON with @random-forests.
* I'm not exactly sure how to test, but the change seems straightforward enough to submit.",rrrutledge,b'cla: yes',2018-07-16T18:25:01Z,2018-07-18T23:07:12Z,,,,,,,
4782,model_main.py - invalid syntax,"### System information
- **What is the top-level directory of the model you are using**: tensorflow/models/research
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: NO
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:Ubuntu 16.04.3 LTS
- **TensorFlow installed from (source or binary)**:pip install tensorflow-gpu
- **TensorFlow version (use command below)**:v1.9.0-0-g25c197e023 1.9.0
- **Bazel version (if compiling from source)**:none
- **CUDA/cuDNN version**: cuda 9.0 cudnn 7.1
- **GPU model and memory**: tesla v100
- **Exact command to reproduce**: see bug report

### Describe the problem
Not able to run object detection training locally. Did all steps in https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/installation.md (tests are passing), followed https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/running_pets.md (I copied data to ~/gcs/data instead of gs bucket), got stuck on trying to run training and eval locally.

### Source code / logs
$ python object_detection/model_main.py --pipeline_config_path=~/gcs/data/faster_rcnn_resnet101_pets.config --model_dir=~/gcs/data/ --num_train_steps=50000 --num_eval_steps=2000 --alsologtostderr
/home/paperspace/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Traceback (most recent call last):
  File ""object_detection/model_main.py"", line 26, in <module>
    from object_detection import model_lib
  File ""/home/paperspace/tensorflow/models/research/object_detection/model_lib.py"", line 26, in <module>
    from object_detection import eval_util
  File ""/home/paperspace/tensorflow/models/research/object_detection/eval_util.py"", line 28, in <module>
    from object_detection.metrics import coco_evaluation
  File ""/home/paperspace/tensorflow/models/research/object_detection/metrics/coco_evaluation.py"", line 21, in <module>
    from object_detection.utils import object_detection_evaluation
  File ""/home/paperspace/tensorflow/models/research/object_detection/utils/object_detection_evaluation.py"", line 842
    print 'Scores and tpfp per class label: {}'.format(class_index)
                                              ^
SyntaxError: invalid syntax

------------------------
",lukaszs-appdate,None,2018-07-16T15:02:51Z,2018-09-14T01:44:46Z,,,,,,,
4758,object_detection train.py moved to legacy,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**: ~/tensorflow/models/research/object_detection
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: See tf_env_collect.sh output below
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**: python train.py

tf_env_collect.sh output:
== cat /etc/issue ===============================================
Linux rkalliot2 4.15.0-24-generic #26~16.04.1-Ubuntu SMP Fri Jun 15 14:35:08 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux
VERSION=""16.04.4 LTS (Xenial Xerus)""
VERSION_ID=""16.04""
VERSION_CODENAME=xenial

== are we in docker =============================================
No

== compiler =====================================================
c++ (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609
Copyright (C) 2015 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.


== uname -a =====================================================
Linux rkalliot2 4.15.0-24-generic #26~16.04.1-Ubuntu SMP Fri Jun 15 14:35:08 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux

== check pips ===================================================
numpy               1.14.5   
protobuf            3.5.2    
tensorflow          1.8.0    

== check for virtualenv =========================================
False

== tensorflow import ============================================
tf.VERSION = 1.8.0
tf.GIT_VERSION = b'unknown'
tf.COMPILER_VERSION = b'unknown'
Sanity check: array([1], dtype=int32)

== env ==========================================================
LD_LIBRARY_PATH is unset
DYLD_LIBRARY_PATH is unset

== nvidia-smi ===================================================
Thu Jul 12 19:25:30 2018       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 390.67                 Driver Version: 390.67                    |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  TITAN Xp            Off  | 00000000:81:00.0  On |                  N/A |
| 23%   38C    P0    73W / 250W |   1046MiB / 12190MiB |      3%      Default |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID   Type   Process name                             Usage      |
|=============================================================================|
|    0      1522      G   /usr/lib/xorg/Xorg                           709MiB |
|    0      2373      G   compiz                                       197MiB |
|    0      7397      G   ...-token=8E2E44D2DE2D7583A9BB9AAC21704BF0   136MiB |
+-----------------------------------------------------------------------------+

== cuda libs  ===================================================


### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

it appears that train.py (and a number of other files) have been moved to object_detection/legacy. However, all documentation and tutorials and examples have the code running object_detection/train.py.
QUESTION: is there a new way to train object_detection models? If so, can you provide examples or documentation?

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",radzfoto,b'stat:awaiting maintainer',2018-07-13T02:32:11Z,2018-07-13T21:58:57Z,,,,,,,
4755,Add image name to tensorboard ,"[object detection]
if it possible to add the name of the image when display on tensorboard 
it can help for debugging when the dataset is changing all the time 
one simple way to do that is reusing the keep_image_id_for_visualization_export flag and 
adding in eval_utils.py: 

```
  if export_dir:
    if keep_image_id_for_visualization_export and result_dict[fields.
                                                              InputDataFields()
                                                              .key]:
      export_path = os.path.join(export_dir, 'export-{}-{}.png'.format(
          tag, result_dict[fields.InputDataFields().key]))
    else:
      export_path = os.path.join(export_dir, 'export-{}.png'.format(tag))
    vis_utils.save_image_array_as_png(image, export_path)
  elif keep_image_id_for_visualization_export:
    tag += ' - ' + result_dict[fields.InputDataFields().key]
```
thanks ",mbenami,b'stat:awaiting model gardener',2018-07-12T20:28:36Z,2020-02-07T18:46:50Z,,,,,,,
4754,AssertionError: Model diverged with loss = NaN,"When I am trying the tutorial to apply the multiple GPUs, there is an error:
python3 cifar10_multi_gpu_train.py --num_gpus=2
Traceback (most recent call last):
  File ""cifar10_multi_gpu_train.py"", line 277, in <module>
    tf.app.run()
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/platform/app.py"", line 48, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""cifar10_multi_gpu_train.py"", line 273, in main
    train()
  File ""cifar10_multi_gpu_train.py"", line 246, in train
    assert not np.isnan(loss_value), 'Model diverged with loss = NaN'
AssertionError: Model diverged with loss = NaN
I have modified the LEARNING_RATE from 0.1 to 0.01, however it doesn't help.
Any suggestions?

Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",Strange369,None,2018-07-12T15:27:08Z,2020-02-07T18:46:50Z,,,,,,,
4735,blank in filename or label mask_rcnn_inception_v2,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
The form below must be filled out.
Here's why we have that policy: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

System information
What is the top-level directory of the model you are using:
/models/object_detection

Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
use data_tools/create_pet_tf_record.py with faces_only False (i want mask)

OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Debian 9

TensorFlow installed from (source or binary):
install from pip3

TensorFlow version (use command below):
1.8.0

Bazel version (if compiling from source):

CUDA/cuDNN version:

GPU model and memory:

Exact command to reproduce:


put blank in png and xml and jpg files and in label
launch create_pet_record_coco_tf.py

WARNING:root:Could not find /home/tensorflow/object_detection/images/mask/annotations/xmls/.xml, ignoring example.


https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

the problem is i have blank name like ""Laptop Lenovo Yoga.xml/jpg/png"" and same lable in label xml, so i cut after the first blank


Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.",leccyril,None,2018-07-10T18:44:54Z,2020-02-07T18:46:48Z,,,,,,,
4720,[object_detection] Passing batch of images to inference of Mask R-CNN model won't work,"### System information
- **What is the top-level directory of the model you are using**: models/researc/object_detection
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.7.0
- **Bazel version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**: N/A

### Problem
I'm crating masks to detect exact locations of cars in images, thus I'm using the pretrained COCO Models of your model zoo in combination with the object_detection_tutorial jupyter notebook. To speed up performance, I'm trying to pass a batch of images to the sess.run() command (I've modified the jupyter notebook slightly). Batch shape is (batch_size, image_width, image_height, 3) and while using Faster R-CNN models it works perfectly like this:
```
output_dict = sess.run(tensor_dict, feed_dict={image_tensor: image_batch})
```

But for some reason this won't work with Mask R-CNN models. The sess.run() command will return this error message:
```
InvalidArgumentError (see above for traceback): Tried to explicitly squeeze dimension 0 but dimension was not 1: 2
     [[Node: Squeeze_5 = Squeeze[T=DT_FLOAT, squeeze_dims=[0], _device=""/job:localhost/replica:0/task:0/device:CPU:0""](detection_boxes)]
```

It seems to squeeze the image_batch back to dimension (image_width, image_height, 3), which will only work with a batch_size of 1. But why is that? Is there some explanation for this behavior or is this a bug? Is batching for the Mask R-CNN models not available? Although comments in these lines of code indicate, that it is:
```
if 'detection_masks' in tensor_dict:
            # The following processing is only for single image
            detection_boxes = tf.squeeze(tensor_dict['detection_boxes'], [0])
            detection_masks = tf.squeeze(tensor_dict['detection_masks'], [0])
            # # Reframe is required to translate mask from box coordinates to image coordinates and fit the image size.
            real_num_detection = tf.cast(tensor_dict['num_detections'][0], tf.int32)
            detection_boxes = tf.slice(detection_boxes, [0, 0], [real_num_detection, -1])
            detection_masks = tf.slice(detection_masks, [0, 0, 0], [real_num_detection, -1, -1])
            detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(
                detection_masks, detection_boxes, image_batch.shape[1], image_batch.shape[2])
            detection_masks_reframed = tf.cast(
                tf.greater(detection_masks_reframed, 0.5), tf.uint8)
            # Follow the convention by adding back the batch dimension
            tensor_dict['detection_masks'] = tf.expand_dims(
                detection_masks_reframed, 0)
```

Clarification would help a lot! Thank you in advance!",Thommy257,None,2018-07-09T08:27:17Z,2018-08-26T15:52:28Z,,,,,,,
4705,Unable to run ”fetch_imagenet_models.sh”，can not download the models of “voc_0712_80k-110k.tgz”，The url is False. ,"https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
The form below must be filled out.
It shouldn't be a TensorBoard issue. Those go here.
Here's why we have that policy: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

System information
· Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes

· OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Win10-x64

· TensorFlow installed from (source or binary): git clone https://github.com/tensorflow/tensorflow.git

· TensorFlow version (use command below): r1.8, command :
git checkout -b v1.8 -f origin/r1.8

· Python version: Anaconda3 - python3.6

· Bazel version (if compiling from source): I used CMAKE 3.11.1

· GCC/Compiler version (if compiling from source): both Visual Studio 2015 and Visual Studio 2015' MSBuild

· CUDA/cuDNN version: CUDA9.0, cudnn-9.0-win10-7.1

· GPU model and memory: GTX-860m with 2Gb Memory

Describe the problem
When configuring the environment of the Faster-RCNN project from github：
Unable to run file “fetch_imagenet_models.sh”，Unable to download the models of VGG16 cause the url is not OK, so I can not get download ""voc_0712_80k-110k.tgz"".

cd $FRCN_ROOT ./data/scripts/fetch_imagenet_models.sh

Source code / logs
cd $FRCN_ROOT ./data/scripts/fetch_imagenet_models.sh


     
 

",EdwardVincentMa,b'stat:awaiting response',2018-07-06T05:30:09Z,2018-09-02T14:51:45Z,,,,,,,
4701,[Deeplabv3+] Models pretrained without the separable conv,"Hi Yukun, Jay and George,

I went through the deeplab model zoo (https://github.com/tensorflow/models/blob/master/research/deeplab/g3doc/model_zoo.md) but couldn't find the models pretrained without the separable conv. 

Would you release trained models without the separable conv? I understand the separable conv is a good strategy to reduce the parameters and computations, and I am curious to finetune the models without the separable conv on other datasets. ;)

Best,
Zhuotun

------------------------

### System information
- **What is the top-level directory of the model you are using**: deeplab
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu16.04
- **TensorFlow installed from (source or binary)**: 
- **TensorFlow version (use command below)**: tensorflow-gpu 1.7.0 
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**: CUDA 9.0/ cuDNN 7
- **GPU model and memory**:16GB V100
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",sunformoon,None,2018-07-05T17:33:55Z,2018-07-06T20:00:44Z,,,,,,,
4685,train my own object detection model,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**: 
models/research/object_detection

- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: use train.py 

- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: 
Windows 10

- **TensorFlow installed from (source or binary)**:
PIP3
- **TensorFlow version (use command below)**:
1.8.0
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

use train.py with faster_rcnn_inception_v2 or other model, 2 classes, 500 in TRAINfolder, 94 in TEST/FOLDER folder


You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

the regression losses classification go to < .0.5 after only 1K step, after 5K increase to 25 so i had to stop when it begins to increase very high, the problem after is i could not detect well object in picture.

for example i train for samsung watch, but when apple watch is in picture it is detected as samsung watch (not working). or i have picture car, the wheels are detected as samsung watch. i labelized only clear picture, whole, and face. 300x300

what i am doing wrong ? i tried faster_rcnn_atrous/inception, ssd_inception ...
[tosend.zip](https://github.com/tensorflow/models/files/2159103/tosend.zip)

thank you for your great work i would really make it work, several weeks on it !

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",leccyril,None,2018-07-03T11:51:58Z,2018-07-13T09:45:44Z,,,,,,,
4680,How to do the inference for deeplab on cityscape dataset?,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.



How to do the inference on cityscape dataset on deeplab
",chowkamlee81,None,2018-07-03T02:44:38Z,2018-07-03T16:37:01Z,,,,,,,
4670,batching and epochs,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",SakshiGarg123,None,2018-07-02T11:56:13Z,2018-07-09T19:58:53Z,,,,,,,
4669,I m running train_image_classifier.py.,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",SakshiGarg123,None,2018-07-02T11:55:09Z,2018-07-02T11:59:16Z,,,,,,,
4662,[vid2depth] tiny readme typos,"Hi Reza and thank you very much for the code. 
2 typos you might want to update in the readme:
- for running the inference, parameter is written ""--video"" instead of ""--kitti_video
- for the wget of the kitti_archives_to_download.txt, link is to the git page. The raw file address instead is 
https://raw.githubusercontent.com/mrharicot/monodepth/master/utils/kitti_archives_to_download.txt

Thank you again.
K. 
",kalanityL,b'type:bug type:docs',2018-07-01T09:36:14Z,2020-02-07T18:52:30Z,,,,,,,
4659,custom dataset for pascal voc,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",halebery,None,2018-06-30T19:28:45Z,2018-06-30T19:29:57Z,,,,,,,
4639,How can we dispaly the confidence score or the prediction probability score of each class in the tensorrt program while printing the inferrence results?,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",R-Miner,None,2018-06-26T20:13:38Z,2018-06-29T17:46:01Z,,,,,,,
4637,Mask RCNN: get scores for all 90 classes of a single box,"### Describe the problem
I know this is **NOT** a bug but few people on stackoverflow know the solution. So I didn't fill out the information required.

I'm using the `mask_rcnn_inception_v2_coco_2018_01_28` model for instance segmentation, and the model outputs detection_scores with dims=[1, 100], which corresponds to the 100 boxes.

While I wonder if I can obtain scores with dims=[90, 100], i.e., for each box I need 90 scores for all the classes, rather than just the highest score.

Similarly, I also want the masks with dims=[90, 100, 15, 15], rather than [1, 100, 15, 15].

I tried to find the solution by examining the model (I visualise the model using tensorboard, the files is on [GoogleDrive](https://drive.google.com/file/d/1hxoo7ItwinLUNf79EvLBFae-rGYpqnTp/view?usp=sharing)). But is really confused by the graph.

### Source code / logs
The code is [here](https://github.com/tensorflow/models/blob/master/research/object_detection/object_detection_tutorial.ipynb). And I'm using the C++ API to do the inference:

```c++
Status run_status = session->Run({{input_layer, resized_tensor}},
                                   {""num_detections:0"", ""detection_boxes:0"",
                                    ""detection_scores:0"", ""detection_classes:0"",
                                    ""detection_masks:0""},
                                   {}, &outputs); // original:{output_layer}
```

with output:

```
==============================
detection_scores:0
Tensor<type: float shape: [1,100] values: [0.998502731 0.986097693 0.821735203]...>

==============================
detection_classes:0
Tensor<type: float shape: [1,100] values: [18 18 1]...>

==============================
detection_masks:0
Tensor<type: float shape: [1,100,15,15] values: [[[0.000649190042 0.000243070099 0.000696995761]]]...>
```
",dongmingsun,b'stat:awaiting response',2018-06-26T17:24:26Z,2019-09-03T16:30:01Z,,,,,,,
4635,https://github.com/tensorflow/models/tree/master/official/wide_deep/wide_deep.py is not present as it is mentioned in documentation,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",snkreddy,None,2018-06-26T16:02:36Z,2020-02-07T18:46:34Z,,,,,,,
4630,"[Deeplab v3+], The relation between num_shards and training batch size","Hi Jay, George, and Yukun,

It there any rule I should follow when I set the num_shards and training batch size? Like, the num_clones is set for how many GPUs I am using.

 In the given example of local_test.sh and build_voc2012_data.py, the batch size is set to be 4 and the _NUM_SHARDS is set to be 4 as well.

Best,
Zhuotun

------------------------

### System information
- **What is the top-level directory of the model you are using**: deeplab
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu16.04
- **TensorFlow installed from (source or binary)**: 
- **TensorFlow version (use command below)**: tensorflow-gpu 1.7.0 
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**: CUDA 9.0/ cuDNN 7
- **GPU model and memory**:16GB V100
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",sunformoon,None,2018-06-26T01:17:23Z,2018-06-26T17:18:12Z,,,,,,,
4620,A Few Works Of Quantization on object_detection,"I added a few new features for supporting Quantization on object_detection and also fixed some small bugs in this project.
1. add .gitignore for ignoring proto generated files
2. suppress double logging info
3. use growth gpu memory allocating strategy when evaluating and training on one gpu.
4. solved several py2/py3 compatibility problems by six moudule
5. fix the bug that learning_rate may sometimes not be added to summary and tensorboard
6. add new options when restore variables from a checkpoint
(Which may important for quantize. tf.contrib.quantize.create_training_graph slows down the speed of training. So you may train the model without graph rewriter. After the first-time's convergence of model, the rewriter will be activated and then keep on training to refine the accuracy. However, the variable restoration from previous checkpoint will restore the variable generated by optimizer which slows down the second-time's convergence because of low learning rate.)
7. support for exporting tflite compatible subgraph
8. add a few documents and config samples for quantize

Tests passed:
faster_rcnn_meta_arch_test.py
rfcn_meta_arch_test.py
ssd_meta_arch_test.py
model_lib_test.py
trainer_test.py
eval_util_test
exporter_test.py",aeloyq,b'cla: yes',2018-06-25T11:47:09Z,2019-12-03T07:09:31Z,,,,,,,
4605,Can we save this optimized tenosrrt model for inerence purposes instead of running it again and again?,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",R-Miner,b'stat:awaiting response',2018-06-22T19:19:32Z,2020-02-07T18:44:23Z,,,,,,,
4601,where can i get the tutorial for understanding how flatbuffermodel is being used in the code ?,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",bajajyukta7,None,2018-06-22T06:08:28Z,2018-07-11T16:14:01Z,,,,,,,
4589,My Distributed training code gain slower speed sec/batch than cifar10_train.py,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Based on cifar10_train.py and tensorflow distributed doc, I writed a cifar10_train_distributed.py in distributed version and ran on a k8s with 2 worker and 1 ps. But slower speed displayed.  cifar10_train in 1  GPU (Tesla p 100), gained  0.008 sec/batch.   cifar10_train_distributed gained 0.027 sec/batch. here is my code . I do not understand!!! Help!

### Source code / logs
def train():
    print(""here"")
    tf_config_json = FLAGS.tf_config
    tf_config = json.loads(tf_config_json)
    #get cluster info and build spec object that used to init each node
    cluster_spec = tf_config.get(""cluster"", {})
    cluster_spec_object = tf.train.ClusterSpec(cluster_spec)
    #get current task
    task = tf_config.get(""task"", {})
    job_name = task['type']
    job_index = task['index']
    #tf server definition
    server_def = tf.train.ServerDef(
        cluster=cluster_spec_object.as_cluster_def(),
        protocol=""grpc"",
        job_name=job_name,
        task_index=job_index)
    #init cluster
    #cluster = tf.train.ClusterSpec(cluster_spec)
    print(cluster_spec, task)
    print(""hello"")
    server = tf.train.Server(server_def)
    is_chief = (job_name == ""master"")
    if 'ps' == job_name:
        print(""ps join..\n"")
        server.join()
    worker_device = ""/job:%s/task:%d"" % (job_name, job_index)
    print(worker_device)
    with tf.device(tf.train.replica_device_setter(
            worker_device=worker_device, cluster=cluster_spec_object)):
            """"""Train CIFAR-10 for a number of steps.""""""
        global_step = tf.train.get_or_create_global_step()
        # Get images and labels for CIFAR-10.
        # Force input pipeline to CPU:0 to avoid operations sometimes ending up on
        # GPU and resulting in a slow down.
        with tf.device(""/cpu:0""):
            images, labels = cifar10.distorted_inputs()
            # Build a Graph that computes the logits predictions from the
        # inference model.
        logits = cifar10.inference(images)
        # Calculate loss.
        loss = cifar10.loss(logits, labels)
        # Build a Graph that trains the model with one batch of examples and
        # updates the model parameters.
        train_op = cifar10.train(loss, global_step)
    with tf.train.MonitoredTrainingSession(
        master=server.target,
        is_chief=is_chief,
        checkpoint_dir=FLAGS.train_dir,
        hooks=[tf.train.StopAtStepHook(last_step=FLAGS.max_steps),
        tf.train.NanTensorHook(loss),],
        config=tf.ConfigProto(
             log_device_placement=FLAGS.log_device_placement)) as mon_sess:
        start_train_time = time.time()
        count_step = 0
        while not mon_sess.should_stop():
            step_start_time = time.time()
            _, loss_value = mon_sess.run([train_op, loss])
            step_end_time = time.time()
            if count_step % FLAGS.log_frequency == 0:
                duration = step_end_time - step_start_time
                examples_per_sec =  FLAGS.batch_size / duration
                format_str = ('%s: step %d %s, loss = %.2f (%.1f examples/sec; %.3f '
                    'sec/batch)')
                print (format_str % (datetime.now(),count_step, job_name, loss_value,
                    examples_per_sec, duration))
            count_step += 1
    end_train_time = time.time()
    cost_train_time = end_train_time - start_train_time
    print(""training cost : %d"" % cost_train_time)
",Told,None,2018-06-20T13:24:02Z,2018-07-11T16:13:30Z,,,,,,,
4565,[DeepLab] Error when starting cityscapes training with pre-trained ImageNet checkpoint,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**: deeplab
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.8.0
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

** [tf_env.txt](https://github.com/tensorflow/models/files/2109971/tf_env.txt) **


### Problem

I am using this commit for tensorflow/models:

```sh
commit 2310bc34cc372122a61dd49eaea52e2684e74ae0
Merge: 1f82c22 e2e820c
Author: Yukun Zhu <YknZhu@users.noreply.github.com>
Date:   Thu Jun 14 22:24:53 2018 -0700

    Merge pull request #4534 from huihui-personal/master

    PiperOrigin-RevId: 200493322
```

I was able to run the `model_test.py` and `local_test.sh` without problems as [here](https://github.com/tensorflow/models/blob/master/research/deeplab/g3doc/installation.md)

However, when I tried to train cityscapes using ImageNet pre-train weights as [here](https://github.com/tensorflow/models/blob/master/research/deeplab/g3doc/cityscapes.md), I get an error message.

The ImageNet pretrained checkpoint is [here](https://github.com/tensorflow/models/blob/master/research/deeplab/g3doc/model_zoo.md)
xception_65. Linke http://download.tensorflow.org/models/deeplabv3_xception_2018_01_04.tar.gz

I ran `sh convert_cityscapes.sh` already.
Perhaps this problem is related to #4464?
Which hash of this repo is used to generate the pre-trained checkpoint?

### Source code / logs

```
PATH_TO_INITIAL_CHECKPOINT=/notebooks/deeplab_checkpoints/imagenet_pretrain_xception_65_deeplabv3_xception_2018_01_04/xception/
PATH_TO_TRAIN_DIR=/notebooks/models/research/deeplab/datasets/cityscapes/exp/train_on_train_set/train/
PATH_TO_DATASET=/notebooks/models/research/deeplab/datasets/cityscapes/tfrecord
```

```
root@ac31b3bca4bf:/notebooks/models/research# python deeplab/train.py \
>     --logtostderr \
>     --training_number_of_steps=90000 \
>     --train_split=""train"" \
>     --model_variant=""xception_65"" \
>     --atrous_rates=6 \
>     --atrous_rates=12 \
>     --atrous_rates=18 \
>     --output_stride=16 \
>     --decoder_output_stride=4 \
>     --train_crop_size=769 \
>     --train_crop_size=769 \
>     --train_batch_size=1 \
>     --dataset=""cityscapes"" \
>     --tf_initial_checkpoint=${PATH_TO_INITIAL_CHECKPOINT} \
>     --train_logdir=${PATH_TO_TRAIN_DIR} \
>     --dataset_dir=${PATH_TO_DATASET}
INFO:tensorflow:Training on train set
INFO:tensorflow:Initializing model from path: /notebooks/deeplab_checkpoints/imagenet_pretrain_xception_65_deeplabv3_xception_2018_01_04/xception/
Traceback (most recent call last):
  File ""deeplab/train.py"", line 394, in <module>
    tf.app.run()
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/platform/app.py"", line 126, in run
    _sys.exit(main(argv))
  File ""deeplab/train.py"", line 384, in main
    ignore_missing_vars=True),
  File ""/notebooks/models/research/deeplab/utils/train_utils.py"", line 118, in get_model_init_fn
    ignore_missing_vars=ignore_missing_vars)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/framework/python/ops/variables.py"", line 674, in assign_from_checkpoint_fn
    reader = pywrap_tensorflow.NewCheckpointReader(model_path)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 290, in NewCheckpointReader
    return CheckpointReader(compat.as_bytes(filepattern), status)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/errors_impl.py"", line 519, in __exit__
    c_api.TF_GetCode(self.status.status))
tensorflow.python.framework.errors_impl.NotFoundError: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for /notebooks/deeplab_checkpoints/imagenet_pretrain_xception_65_deeplabv3_xception_2018_01_04/xception/
```

```
root@ac31b3bca4bf:/notebooks# ls /notebooks/deeplab_checkpoints/imagenet_pretrain_xception_65_deeplabv3_xception_2018_01_04/xception/
model.ckpt.data-00000-of-00001  model.ckpt.index
```",rlan,None,2018-06-18T05:24:29Z,2019-10-18T16:52:54Z,,,,,,,
4559,"train a textsum model : a bytes-like object is required, not 'str' ","Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- Linux Ubuntu 16.04
- TensorFlow installed from (source or binary)**:
- TensorFlow version '1.6.0'
- Bazel version 0.14.1
- Python 3.6.3
- 
- 

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

When I try to train a texsum model,  I use the command below. I end up with this error ""a bytes-like object is required, not 'str' ""

bazel-bin/textsum/seq2seq_attention \
    --mode=train \
    --article_key=article \
    --abstract_key=abstract \
    --data_path=data/training-* \
    --vocab_path=data/vocab \
    --log_root=textsum/log_root \
    --train_dir=textsum/log_root/train

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",ConnieTong,None,2018-06-17T07:03:35Z,2020-01-13T09:23:26Z,,,,,,,
4548,[bug] Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available,"InvalidArgumentError (see above for traceback): Cannot assign a device for operation 'InceptionV4/Logits/Predictions': Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available.
         [[Node: InceptionV4/Logits/Predictions = Softmax[T=DT_FLOAT, _device=""/device:GPU:0""](InceptionV4/Logits/Logits/BiasAdd)]]",hyybuaa,b'models:research stat:awaiting response',2018-06-15T08:33:52Z,2020-02-07T18:46:14Z,,,,,,,
4546,"[bug]Using ""faster_rcnn_resnet50_coco.config"" produce "".pb"" to ""sess.run""","Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:object_detection
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:NO
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:win7
- **TensorFlow installed from (source or binary)**:source 
- **TensorFlow version (use command below)**:tensorflow-1.8.0
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Using ""faster_rcnn_resnet50_coco.config"" to train model by my own dataset,then i freeze model.ckpt to pb.When i used pb and tensorlfow-1.8.0 to derive result,it reported error:
![image](https://user-images.githubusercontent.com/10041362/41454685-ec935d34-70ac-11e8-96ca-6f0d34cb3ef1.png)
But when i used pb and tensorflow-1.4.0 and tensorflow-1.5.0 to derive result,it was ok.And I used ""faster_rcnn_inception_resnet_v2_atrous_coco.config"" to train model,then freeze it.Tensorflow-1.8.0 and Tensorflow-1.4.0 were useful,it did't report error.
### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",a819721810,None,2018-06-15T07:03:26Z,2018-06-27T07:32:25Z,,,,,,,
4545,[bug]AttributeError: 'KeepAspectRatioResizer' object has no attribute 'per_channel_pa d_value',"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:object_detection
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:NO
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:window7
- **TensorFlow installed from (source or binary)**:binary
- **TensorFlow version (use command below)**:tensorflow-1.8.0
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
I updated tensorflow/models today.However,i used""python3 export_inference_graph.py"",it report error:
![image](https://user-images.githubusercontent.com/10041362/41453851-dd33e00a-70a9-11e8-90c2-cb2517b1a428.png)
![image](https://user-images.githubusercontent.com/10041362/41453858-e3441762-70a9-11e8-8da9-6fa358e791f8.png)

And i returned old version,it's ok.
### Source code / logs
There are my pipeconfig:

model {
  faster_rcnn {
    num_classes: 2
    image_resizer {
      keep_aspect_ratio_resizer {
        min_dimension: 600
        max_dimension: 1024
	convert_to_grayscale :True
      }
    }
    feature_extractor {
      type: 'faster_rcnn_resnet50'
      first_stage_features_stride: 16
    }
    first_stage_anchor_generator {
      grid_anchor_generator {
        scales: [0.25, 0.5, 1.0, 2.0]
        aspect_ratios: [0.5, 1.0, 2.0]
        height_stride: 16
        width_stride: 16
      }
    }
    first_stage_box_predictor_conv_hyperparams {
      op: CONV
      regularizer {
        l2_regularizer {
          weight: 0.0
        }
      }
      initializer {
        truncated_normal_initializer {
          stddev: 0.01
        }
      }
    }
    first_stage_nms_score_threshold: 0.0
    first_stage_nms_iou_threshold: 0.7
    first_stage_max_proposals: 300
    first_stage_localization_loss_weight: 2.0
    first_stage_objectness_loss_weight: 1.0
    initial_crop_size: 14
    maxpool_kernel_size: 2
    maxpool_stride: 2
    second_stage_box_predictor {
      mask_rcnn_box_predictor {
        use_dropout: false
        dropout_keep_probability: 1.0
        fc_hyperparams {
          op: FC
          regularizer {
            l2_regularizer {
              weight: 0.0
            }
          }
          initializer {
            variance_scaling_initializer {
              factor: 1.0
              uniform: true
              mode: FAN_AVG
            }
          }
        }
      }
    }
    second_stage_post_processing {
      batch_non_max_suppression {
        score_threshold: 0.0
        iou_threshold: 0.6
        max_detections_per_class: 100
        max_total_detections: 300
      }
      score_converter: SOFTMAX
    }
    second_stage_localization_loss_weight: 2.0
    second_stage_classification_loss_weight: 1.0
  }
}

train_config: {
  batch_size: 24
  optimizer {
    momentum_optimizer: {
      learning_rate: {
        manual_step_learning_rate {
          initial_learning_rate: 0.0125
          schedule {
            step: 11000
            learning_rate: .00125
          }
          schedule {
            step: 60000
            learning_rate: .000125
          }
        }
      }
      momentum_optimizer_value: 0.9
    }
    use_moving_average: false
  }
  gradient_clipping_by_norm: 10.0
  fine_tune_checkpoint: ""pb/model.ckpt-71052""
  from_detection_checkpoint: true
  num_steps: 2000000
  data_augmentation_options {
    random_horizontal_flip {
    }
  }
}

train_input_reader: {
  tf_record_input_reader {
    input_path: ""record/pascal.record""
  }
  label_map_path: ""dataset/pascal_label_map.pbtxt""
}

eval_config: {
  num_examples: 2000
  max_evals: 1
}

eval_input_reader: {
  tf_record_input_reader {
    input_path: ""record/pascal_eval.record""
  }
  label_map_path: ""dataset/pascal_label_map.pbtxt""
  shuffle: false
  num_readers: 1
}

",a819721810,None,2018-06-15T06:43:46Z,2018-06-20T02:14:52Z,,,,,,,
4537,Incredibly Large Losses Being Reported during Training ,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:models/object_detection/Object-Detection/ I am working from an earlier commit. 
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes. 
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: TF 1.5
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**: 
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request. I recently after a much painful debugging period of several weeks finally got a tensorflow model set up for training on images of shape [None, None, 1]. One issue i had was i was decoding using tf.uint8 before, and now i'm decoding raw data using tf.int32 and the training started smoothly, but this is what it's reporting so far :
018-06-14 10:12:46.832715: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2
INFO:tensorflow:Restoring parameters from faster_rcnn_resnet101_kitti_2018_01_28_edit/model.ckpt
INFO:tensorflow:Starting Session.
INFO:tensorflow:Saving checkpoint to path training_dir/Training8_FRCNN/model.ckpt
INFO:tensorflow:Starting Queues.
INFO:tensorflow:global_step/sec: 0
INFO:tensorflow:Recording summary at step 0.
INFO:tensorflow:global step 1: loss = 2111620.5000 (92.193 sec/step)
INFO:tensorflow:global_step/sec: 0.00882505
INFO:tensorflow:Recording summary at step 1.
INFO:tensorflow:global step 2: loss = 3.0828 (64.799 sec/step)
INFO:tensorflow:global step 3: loss = 2.8934 (55.309 sec/step)
INFO:tensorflow:global_step/sec: 0.0166667
INFO:tensorflow:Recording summary at step 3.
INFO:tensorflow:global step 4: loss = 397766.8750 (62.280 sec/step)
INFO:tensorflow:global step 5: loss = 151397.8594 (56.366 sec/step)
INFO:tensorflow:global_step/sec: 0.0166667
INFO:tensorflow:Recording summary at step 5.
INFO:tensorflow:global step 6: loss = 0.9747 (62.037 sec/step)
INFO:tensorflow:global step 7: loss = 1310138.8750 (52.413 sec/step)
INFO:tensorflow:global_step/sec: 0.0166666
INFO:tensorflow:Recording summary at step 7.
INFO:tensorflow:global step 8: loss = 60647.3984 (58.173 sec/step)
INFO:tensorflow:global step 9: loss = 299056.2188 (49.699 sec/step)
INFO:tensorflow:Saving checkpoint to path training_dir/Training8_FRCNN/model.ckpt
INFO:tensorflow:global step 10: loss = 0.6832 (47.258 sec/step)
INFO:tensorflow:global_step/sec: 0.024997
INFO:tensorflow:Recording summary at step 10.
INFO:tensorflow:global step 11: loss = 1.0021 (50.228 sec/step)
INFO:tensorflow:global step 12: loss = 41494812.0000 (41.387 sec/step)
INFO:tensorflow:global_step/sec: 0.0166688
INFO:tensorflow:Recording summary at step 12.
INFO:tensorflow:global step 13: loss = 1.0045 (46.058 sec/step)
INFO:tensorflow:global step 14: loss = 1.0183 (37.177 sec/step)
INFO:tensorflow:global step 15: loss = 4732048.0000 (37.373 sec/step)
INFO:tensorflow:global_step/sec: 0.025
INFO:tensorflow:Recording summary at step 15.
INFO:tensorflow:global step 16: loss = 158327.9375 (43.464 sec/step)

Why and how is the Loss growing so large, an then shrinking back down near 1.0?

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",cmbowyer13,None,2018-06-14T14:31:55Z,2018-06-16T16:21:41Z,,,,,,,
4533,A display bug  when training ssd model with pretrained mobilenet ,"Please go to the end lines,the training informations are printed twice when training ssd model with pretrained mobilenet_v2_1.0_224 (downloaded at https://github.com/tensorflow/models/tree/master/research/slim/nets/mobilenet)

**concerned train_configs in pipeline.config:
  fine_tune_checkpoint: ""/XXXXXXXX/mobilenet_v2_0.75_224/mobilenet_v2_0.75_224.ckpt""
  fine_tune_checkpoint_type:  ""classification""
  num_steps: 200000**

INFO:tensorflow:depth of additional conv before box predictor: 0
INFO:tensorflow:depth of additional conv before box predictor: 0
INFO:tensorflow:depth of additional conv before box predictor: 0
INFO:tensorflow:depth of additional conv before box predictor: 0
INFO:tensorflow:depth of additional conv before box predictor: 0
INFO:tensorflow:depth of additional conv before box predictor: 0
WARNING:root:Variable [MobilenetV2/layer_19_1_Conv2d_2_1x1_256/BatchNorm/beta] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_1_Conv2d_2_1x1_256/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_1_Conv2d_2_1x1_256/BatchNorm/beta/RMSProp] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_1_Conv2d_2_1x1_256/BatchNorm/beta/RMSProp_1] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_1_Conv2d_2_1x1_256/BatchNorm/gamma] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_1_Conv2d_2_1x1_256/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_1_Conv2d_2_1x1_256/BatchNorm/gamma/RMSProp] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_1_Conv2d_2_1x1_256/BatchNorm/gamma/RMSProp_1] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_1_Conv2d_2_1x1_256/BatchNorm/moving_mean] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_1_Conv2d_2_1x1_256/BatchNorm/moving_variance] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_1_Conv2d_2_1x1_256/weights] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_1_Conv2d_2_1x1_256/weights/ExponentialMovingAverage] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_1_Conv2d_2_1x1_256/weights/RMSProp] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_1_Conv2d_2_1x1_256/weights/RMSProp_1] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_1_Conv2d_3_1x1_128/BatchNorm/beta] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_1_Conv2d_3_1x1_128/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_1_Conv2d_3_1x1_128/BatchNorm/beta/RMSProp] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_1_Conv2d_3_1x1_128/BatchNorm/beta/RMSProp_1] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_1_Conv2d_3_1x1_128/BatchNorm/gamma] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_1_Conv2d_3_1x1_128/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_1_Conv2d_3_1x1_128/BatchNorm/gamma/RMSProp] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_1_Conv2d_3_1x1_128/BatchNorm/gamma/RMSProp_1] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_1_Conv2d_3_1x1_128/BatchNorm/moving_mean] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_1_Conv2d_3_1x1_128/BatchNorm/moving_variance] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_1_Conv2d_3_1x1_128/weights] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_1_Conv2d_3_1x1_128/weights/ExponentialMovingAverage] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_1_Conv2d_3_1x1_128/weights/RMSProp] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_1_Conv2d_3_1x1_128/weights/RMSProp_1] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_1_Conv2d_4_1x1_128/BatchNorm/beta] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_1_Conv2d_4_1x1_128/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_1_Conv2d_4_1x1_128/BatchNorm/beta/RMSProp] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_1_Conv2d_4_1x1_128/BatchNorm/beta/RMSProp_1] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_1_Conv2d_4_1x1_128/BatchNorm/gamma] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_1_Conv2d_4_1x1_128/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_1_Conv2d_4_1x1_128/BatchNorm/gamma/RMSProp] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_1_Conv2d_4_1x1_128/BatchNorm/gamma/RMSProp_1] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_1_Conv2d_4_1x1_128/BatchNorm/moving_mean] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_1_Conv2d_4_1x1_128/BatchNorm/moving_variance] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_1_Conv2d_4_1x1_128/weights] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_1_Conv2d_4_1x1_128/weights/ExponentialMovingAverage] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_1_Conv2d_4_1x1_128/weights/RMSProp] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_1_Conv2d_4_1x1_128/weights/RMSProp_1] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_1_Conv2d_5_1x1_64/BatchNorm/beta] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_1_Conv2d_5_1x1_64/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_1_Conv2d_5_1x1_64/BatchNorm/beta/RMSProp] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_1_Conv2d_5_1x1_64/BatchNorm/beta/RMSProp_1] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_1_Conv2d_5_1x1_64/BatchNorm/gamma] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_1_Conv2d_5_1x1_64/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_1_Conv2d_5_1x1_64/BatchNorm/gamma/RMSProp] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_1_Conv2d_5_1x1_64/BatchNorm/gamma/RMSProp_1] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_1_Conv2d_5_1x1_64/BatchNorm/moving_mean] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_1_Conv2d_5_1x1_64/BatchNorm/moving_variance] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_1_Conv2d_5_1x1_64/weights] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_1_Conv2d_5_1x1_64/weights/ExponentialMovingAverage] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_1_Conv2d_5_1x1_64/weights/RMSProp] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_1_Conv2d_5_1x1_64/weights/RMSProp_1] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/BatchNorm/beta] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/BatchNorm/beta/RMSProp] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/BatchNorm/beta/RMSProp_1] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/BatchNorm/gamma] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/BatchNorm/gamma/RMSProp] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/BatchNorm/gamma/RMSProp_1] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/BatchNorm/moving_mean] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/BatchNorm/moving_variance] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/weights] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/weights/ExponentialMovingAverage] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/weights/RMSProp] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/weights/RMSProp_1] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512_depthwise/BatchNorm/beta] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512_depthwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512_depthwise/BatchNorm/beta/RMSProp] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512_depthwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512_depthwise/BatchNorm/gamma] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512_depthwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512_depthwise/BatchNorm/gamma/RMSProp] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512_depthwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512_depthwise/BatchNorm/moving_mean] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512_depthwise/BatchNorm/moving_variance] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512_depthwise/depthwise_weights] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512_depthwise/depthwise_weights/ExponentialMovingAverage] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512_depthwise/depthwise_weights/RMSProp] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512_depthwise/depthwise_weights/RMSProp_1] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/BatchNorm/beta] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/BatchNorm/beta/RMSProp] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/BatchNorm/beta/RMSProp_1] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/BatchNorm/gamma] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/BatchNorm/gamma/RMSProp] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/BatchNorm/gamma/RMSProp_1] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/BatchNorm/moving_mean] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/BatchNorm/moving_variance] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/weights] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/weights/ExponentialMovingAverage] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/weights/RMSProp] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/weights/RMSProp_1] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256_depthwise/BatchNorm/beta] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256_depthwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256_depthwise/BatchNorm/beta/RMSProp] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256_depthwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256_depthwise/BatchNorm/gamma] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256_depthwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256_depthwise/BatchNorm/gamma/RMSProp] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256_depthwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256_depthwise/BatchNorm/moving_mean] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256_depthwise/BatchNorm/moving_variance] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256_depthwise/depthwise_weights] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256_depthwise/depthwise_weights/ExponentialMovingAverage] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256_depthwise/depthwise_weights/RMSProp] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256_depthwise/depthwise_weights/RMSProp_1] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/BatchNorm/beta] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/BatchNorm/beta/RMSProp] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/BatchNorm/beta/RMSProp_1] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/BatchNorm/gamma] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/BatchNorm/gamma/RMSProp] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/BatchNorm/gamma/RMSProp_1] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/BatchNorm/moving_mean] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/BatchNorm/moving_variance] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/weights] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/weights/ExponentialMovingAverage] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/weights/RMSProp] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/weights/RMSProp_1] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256_depthwise/BatchNorm/beta] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256_depthwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256_depthwise/BatchNorm/beta/RMSProp] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256_depthwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256_depthwise/BatchNorm/gamma] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256_depthwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256_depthwise/BatchNorm/gamma/RMSProp] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256_depthwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256_depthwise/BatchNorm/moving_mean] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256_depthwise/BatchNorm/moving_variance] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256_depthwise/depthwise_weights] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256_depthwise/depthwise_weights/ExponentialMovingAverage] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256_depthwise/depthwise_weights/RMSProp] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256_depthwise/depthwise_weights/RMSProp_1] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/BatchNorm/beta] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/BatchNorm/beta/RMSProp] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/BatchNorm/beta/RMSProp_1] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/BatchNorm/gamma] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/BatchNorm/gamma/RMSProp] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/BatchNorm/gamma/RMSProp_1] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/BatchNorm/moving_mean] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/BatchNorm/moving_variance] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/weights] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/weights/ExponentialMovingAverage] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/weights/RMSProp] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/weights/RMSProp_1] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128_depthwise/BatchNorm/beta] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128_depthwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128_depthwise/BatchNorm/beta/RMSProp] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128_depthwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128_depthwise/BatchNorm/gamma] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128_depthwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128_depthwise/BatchNorm/gamma/RMSProp] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128_depthwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128_depthwise/BatchNorm/moving_mean] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128_depthwise/BatchNorm/moving_variance] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128_depthwise/depthwise_weights] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128_depthwise/depthwise_weights/ExponentialMovingAverage] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128_depthwise/depthwise_weights/RMSProp] is not available in checkpoint
WARNING:root:Variable [MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128_depthwise/depthwise_weights/RMSProp_1] is not available in checkpoint
WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/slim/python/slim/learning.py:736: __init__ (from tensorflow.python.training.supervisor) is deprecated and will be removed in a future version.
Instructions for updating:
Please switch to tf.train.MonitoredTrainingSession
WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/slim/python/slim/learning.py:736: __init__ (from tensorflow.python.training.supervisor) is deprecated and will be removed in a future version.
Instructions for updating:
Please switch to tf.train.MonitoredTrainingSession
2018-06-14 12:05:36.095070: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2018-06-14 12:05:36.578163: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1105] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:05:00.0
totalMemory: 11.90GiB freeMemory: 11.37GiB
2018-06-14 12:05:36.822183: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1105] Found device 1 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:09:00.0
totalMemory: 11.90GiB freeMemory: 11.74GiB
2018-06-14 12:05:36.823139: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Device peer to peer matrix
2018-06-14 12:05:36.826738: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1126] DMA: 0 1 
2018-06-14 12:05:36.826748: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1136] 0:   Y Y 
2018-06-14 12:05:36.826752: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1136] 1:   Y Y 
2018-06-14 12:05:36.826760: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1195] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: TITAN Xp, pci bus id: 0000:05:00.0, compute capability: 6.1)
2018-06-14 12:05:36.826766: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1195] Creating TensorFlow device (/device:GPU:1) -> (device: 1, name: TITAN Xp, pci bus id: 0000:09:00.0, compute capability: 6.1)
INFO:tensorflow:Restoring parameters from /home/eco/test_trans_learning3/mobilenet_v2_1.0_224/mobilenet_v2_1.0_224.ckpt
INFO:tensorflow:Restoring parameters from /home/eco/test_trans_learning3/mobilenet_v2_1.0_224/mobilenet_v2_1.0_224.ckpt
INFO:tensorflow:Starting Session.
INFO:tensorflow:Starting Session.
INFO:tensorflow:Saving checkpoint to path /home/eco/test_trans_learning3/model.ckpt
INFO:tensorflow:Saving checkpoint to path /home/eco/test_trans_learning3/model.ckpt
INFO:tensorflow:Starting Queues.
INFO:tensorflow:Starting Queues.
INFO:tensorflow:global_step/sec: 0
INFO:tensorflow:global_step/sec: 0
**INFO:tensorflow:Recording summary at step 0.
INFO:tensorflow:Recording summary at step 0.
INFO:tensorflow:global step 1: loss = 85.5841 (20.408 sec/step)
INFO:tensorflow:global step 1: loss = 85.5841 (20.408 sec/step)
INFO:tensorflow:global step 2: loss = 78.7843 (0.534 sec/step)
INFO:tensorflow:global step 2: loss = 78.7843 (0.534 sec/step)
INFO:tensorflow:global step 3: loss = 72.4312 (0.785 sec/step)
INFO:tensorflow:global step 3: loss = 72.4312 (0.785 sec/step)
INFO:tensorflow:global step 4: loss = 68.7148 (0.732 sec/step)
INFO:tensorflow:global step 4: loss = 68.7148 (0.732 sec/step)
INFO:tensorflow:global step 5: loss = 67.2820 (0.754 sec/step)
INFO:tensorflow:global step 5: loss = 67.2820 (0.754 sec/step)
INFO:tensorflow:global step 6: loss = 66.5206 (0.772 sec/step)
INFO:tensorflow:global step 6: loss = 66.5206 (0.772 sec/step)
INFO:tensorflow:global step 7: loss = 64.2771 (0.728 sec/step)
INFO:tensorflow:global step 7: loss = 64.2771 (0.728 sec/step)
INFO:tensorflow:global step 8: loss = 63.6546 (0.800 sec/step)
INFO:tensorflow:global step 8: loss = 63.6546 (0.800 sec/step)
INFO:tensorflow:global step 9: loss = 61.9096 (0.898 sec/step)
INFO:tensorflow:global step 9: loss = 61.9096 (0.898 sec/step)
INFO:tensorflow:global step 10: loss = 60.7216 (0.944 sec/step)
INFO:tensorflow:global step 10: loss = 60.7216 (0.944 sec/step)
INFO:tensorflow:global step 11: loss = 60.6402 (0.751 sec/step)
INFO:tensorflow:global step 11: loss = 60.6402 (0.751 sec/step)
INFO:tensorflow:global step 12: loss = 58.8133 (0.721 sec/step)
INFO:tensorflow:global step 12: loss = 58.8133 (0.721 sec/step)
INFO:tensorflow:global step 13: loss = 58.4023 (0.713 sec/step)
INFO:tensorflow:global step 13: loss = 58.4023 (0.713 sec/step)
INFO:tensorflow:global step 14: loss = 57.8213 (0.821 sec/step)
INFO:tensorflow:global step 14: loss = 57.8213 (0.821 sec/step)
INFO:tensorflow:global step 15: loss = 56.2347 (0.966 sec/step)
INFO:tensorflow:global step 15: loss = 56.2347 (0.966 sec/step)**
",liangxiao05,None,2018-06-14T06:46:18Z,2020-02-07T18:46:13Z,,,,,,,
4525,[deeplab + cityscape] Frozen inference graph provided is slower than a self-exported graph.,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**: deeplab
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: 1.7.0
- **Bazel version (if compiling from source)**: NA
- **CUDA/cuDNN version**: CUDA 9.0 / cuDNN 5.1
- **GPU model and memory**: Quadro M4000
- **Exact command to reproduce**: NA

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
1. Ran inference on cityscapes image using the frozen inference graph provided and got a run time of ~3.7s
2. Ran inference on cityscapes image using the frozen inference graph exported using the checkpoint provided and got a run time of ~0.9s
(Although both are running less than the 5s runtime given in model_zoo.md)

I have used the official codes to do the export. Arguments passed to it is shown below :
--checkpoint_path=""/path/to/model.ckpt""
--export_path=""/path/to/frozen_inference_graph.pb""
--model_variant=""xception_65""
--atrous_rates=6
--atrous_rates=12
--atrous_rates=18
--output_stride=16
--decoder_output_stride=4
--num_classes=19
--crop_size=1025
--crop_size=2049
--inference_scales=1.0

The only change i made is pulling the inference code out of ipynb, added time.time() for timing, and added some util function to loop through the directory of images.

A quick check with tensorboard shows that my exported graph has just 1216 nodes compared to the 1311 nodes in the graph provided.

**Question**:
1. Is the difference in runtime due to my export argument being wrong?
2. Is the frozen graph created from another checkpoint leading to the difference in runtime?
3. Am i missing something here?

Thank you.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",cheneeheng,None,2018-06-13T18:08:41Z,2020-06-24T16:34:55Z,,,,,,,
4521,Fixing bug for evaluating the quantized model in research/object_detection,Fix the bug that evaluator don't reload the min-max values of fake_quantize op which automatically added by tf.contrib.create_eval_graph() from latest checkpoint.,aeloyq,b'cla: yes',2018-06-13T10:18:57Z,2018-06-15T11:01:36Z,,,,,,,
4520,"slim example not work for mobilenet_v2, request an explicit example","Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:  slim
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04
- **TensorFlow installed from (source or binary)**:  source
- **TensorFlow version (use command below)**: 1.80
- **Bazel version (if compiling from source)**: N.A
- **CUDA/cuDNN version**:  Cuda 9.0
- **GPU model and memory**:  1080 Ti
- **Exact command to reproduce**:   
https://github.com/tensorflow/models/blob/master/research/slim/slim_walkthrough.ipynb

You can collect some of this information using our environment capture script:  

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

I go through the ipython notebook provided in slim folder, it works well for me. However, when I try to replace the model with mobile net,  I find that it is not working for me.   Therefore,  an example for mobile net would be great.
 
### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.

Example of fine tune  mobile net on flower dataset.  I follow the code from fine tune example in:
https://github.com/tensorflow/models/blob/master/research/slim/slim_walkthrough.ipynb


```import os
from datasets import flowers
from nets import inception
from preprocessing import vgg_preprocessing
from tensorflow.contrib import slim

def  get_init_fn():

     checkpoint_exclude_scopes=[""MobilenetV2/Logits, MobilenetV2/Predictions, MobilenetV2/predics""]
     exclusions = [scope.strip() for scope in checkpoint_exclude_scopes]
     variables_to_restore = []
     for var in slim.get_model_variables():
         for exclusion in exclusions:
              if var.op.name.startswith(exclusion):
                 break
             else:
                variables_to_restore.append(var)

     return slim.assign_from_checkpoint_fn(
      os.path.join(checkpoints_dir, 'mobilenet_v2_1.0_224.ckpt'),
      variables_to_restore)

 train_dir = '/tmp/inception_finetuned/'

 with tf.Graph().as_default():
    tf.logging.set_verbosity(tf.logging.INFO)
    
    dataset = flowers.get_split('train', flowers_data_dir)
    images, _, labels = load_batch(dataset, height=image_size, width=image_size)
    
    # Create the model, use the default arg scope to configure the batch norm parameters.
    with slim.arg_scope(mobilenet_v2.training_scope(is_training=True)):
         logits, _ = mobilenet_v2.mobilenet(images, num_classes=dataset.num_classes)

    # Specify the loss function:
    one_hot_labels = slim.one_hot_encoding(labels, dataset.num_classes)
    slim.losses.softmax_cross_entropy(logits, one_hot_labels)
    total_loss = slim.losses.get_total_loss()

    # Create some summaries to visualize the training process:
    tf.summary.scalar('losses/Total Loss', total_loss)
  
    # Specify the optimizer and create the train op:
    optimizer = tf.train.AdamOptimizer(learning_rate=0.01)
    train_op = slim.learning.create_train_op(total_loss, optimizer)
    
    # Run the training:
    final_loss = slim.learning.train(
        train_op,
        logdir=train_dir,
        init_fn=get_init_fn(),
        number_of_steps=2)
        
  
  print('Finished training. Last batch loss %f' % final_loss)

With code you can see, I only replace the inception v3 to mobileNet.  

Error from following shows that the last layer is not match.  I guess I already exclude the logits layer in mobile net. 

InvalidArgumentError (see above for traceback): Assign requires shapes of both tensors to match. lhs shape= [5] rhs shape= [1001]
         [[Node: save/Assign_10 = Assign[T=DT_FLOAT, _class=[""loc:@MobilenetV2/Logits/Conv2d_1c_1x1/biases""], use_locking=true, validate_shape=true, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](MobilenetV2/Logits/Conv2d_1c_1x1/biases,save/RestoreV2/_1)]]
         [[Node: save/RestoreV2/_78 = _Send[T=DT_FLOAT, client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device_incarnation=1, tensor_name=""edge_84_save/RestoreV2"", _device=""/job:localhost/replica:0/task:0/device:CPU:0""](save/RestoreV2:107)]]",ywang370,None,2018-06-13T07:20:21Z,2018-06-13T20:36:11Z,,,,,,,
4504,faster_rcnn_nas_coco ValueError setting --num_clones,"Not sure if this is a bug or not since I can run other models fine.

### System information

- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
have added PR curves from here: https://github.com/tensorflow/models/issues/3081
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Nvidia-docker, Ubuntu 16.04
- **TensorFlow installed from (source or binary)**:
Conda tensorflow-gpu
- **TensorFlow version (use command below)**:
1.8.0
- **CUDA/cuDNN version**:
9.0/7
- **GPU model and memory**:
(4) GTX 1080
- **Exact command to reproduce**:
```
run_train()
{
export CUDA_VISIBLE_DEVICES=0,1,2
python3 /home/ubuntu/training/train.py --logtostderr --pipeline_config_path=/home/ubuntu/training/faster_rcnn_nas_coco.config --train_dir=/home/ubuntu/training/models/train --num_clones=3 --ps_tasks=1
unset CUDA_VISIBLE_DEVICES
}
```
### Describe the problem

I've previously tried two models: `ssd_mobilenet_v1_coco_2017_11_17` and `faster_rcnn_inception_resnet_v2_atrous_coco_2018_01_28` which will both run like this:

```
run_train()
{
export CUDA_VISIBLE_DEVICES=0,1,2
python3 /home/ubuntu/training/train.py --logtostderr --pipeline_config_path=/home/ubuntu/training/faster_rcnn_nas_coco.config --train_dir=/home/ubuntu/training/models/train --num_clones=3 --ps_tasks=1
unset CUDA_VISIBLE_DEVICES
}
```

I have 4 GPU's so I've been setting the first three to train and the last one to eval. However, for some reason I'm unable to do the same for the model `faster_rcnn_nas_coco_2018_01_28`. When I try to set `--num_clones=3` I get the error: 

> WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.
> Traceback (most recent call last):
>   File ""/home/awelch/training/train.py"", line 184, in <module>
>     tf.app.run()
>   File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/platform/app.py"", line 126, in run
>     _sys.exit(main(argv))
>   File ""/home/awelch/training/train.py"", line 180, in main
>     graph_hook_fn=graph_rewriter_fn)
>   File ""/tensorflow/models/research/object_detection/trainer.py"", line 285, in train
>     clones = model_deploy.create_clones(deploy_config, model_fn, [input_queue])
>   File ""/tensorflow/models/research/slim/deployment/model_deploy.py"", line 193, in create_clones
>     outputs = model_fn(*args, **kwargs)
>   File ""/tensorflow/models/research/object_detection/trainer.py"", line 177, in _create_losses
>     train_config.use_multiclass_scores)
> ValueError: not enough values to unpack (expected 7, got 0)

Could anyone please explain why this is or how I can fix it so that I can run this model with more than 1 GPU?
",austinmw,b'stat:awaiting response',2018-06-11T13:55:38Z,2018-08-07T01:57:45Z,,,,,,,
4500,What do all the Summaries in Tensorboard exactly mean ?,"I am not reporting any bug or issue. So , I do not think I need to give the technical information.

I am currently using the latest version of tensorflow object detection api. I just want to know what do all the summaries we see in the ""SCALARS"" section of Tensorboard mean.
E.g:-  Loss/HardExampleMiner/NumNegatives, TargetAssignment/Loss/TargetAssignment/AvgNumIgnoredAnchorsPerImage etc.,

I think there should be a simple description of each of these summaries. If this has been done already, please point me towards it. 
",memahesh,b'stat:awaiting response',2018-06-11T06:42:01Z,2019-01-30T04:45:52Z,,,,,,,
4489,"ParseError: 165:2 : Message type ""object_detection.protos.SSDRandomCropPad"" has no field named ""min_padded_size_ratio""","Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**: `models/research`
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: `No`
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: `Linux Ubuntu 16.04`
- **TensorFlow installed from (source or binary)**: `binary`
- **TensorFlow version (use command below)**: 1.8.0
- **Bazel version (if compiling from source)**: NA
- **CUDA/cuDNN version**: NA
- **GPU model and memory**: NA
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
I am training an Inception SSD using Tensorflow's Object Detection API on Cloud ML Engine and using @pkulzc's branch of `tensorflow/models` as mentioned [here](https://github.com/pkulzc/models/tree/gcp-ready-1.2). 

However while training I immediately run into the following error:

```
ps-replica-0
Traceback (most recent call last): File ""/usr/lib/python2.7/runpy.py"", line 174, in _run_module_as_main ""__main__"", fname, loader, pkg_name) File ""/usr/lib/python2.7/runpy.py"", line 72, in _run_code exec code in run_globals File ""/root/.local/lib/python2.7/site-packages/object_detection/train.py"", line 163, in <module> tf.app.run() File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 48, in run _sys.exit(main(_sys.argv[:1] + flags_passthrough)) File ""/root/.local/lib/python2.7/site-packages/object_detection/train.py"", line 91, in main FLAGS.pipeline_config_path) File ""/root/.local/lib/python2.7/site-packages/object_detection/utils/config_util.py"", line 43, in get_configs_from_pipeline_file text_format.Merge(proto_str, pipeline_config) File ""/usr/local/lib/python2.7/dist-packages/google/protobuf/text_format.py"", line 533, in Merge descriptor_pool=descriptor_pool) File ""/usr/local/lib/python2.7/dist-packages/google/protobuf/text_format.py"", line 587, in MergeLines return parser.MergeLines(lines, message) File ""/usr/local/lib/python2.7/dist-packages/google/protobuf/text_format.py"", line 620, in MergeLines self._ParseOrMerge(lines, message) File ""/usr/local/lib/python2.7/dist-packages/google/protobuf/text_format.py"", line 635, in _ParseOrMerge self._MergeField(tokenizer, message) File ""/usr/local/lib/python2.7/dist-packages/google/protobuf/text_format.py"", line 735, in _MergeField merger(tokenizer, message, field) File ""/usr/local/lib/python2.7/dist-packages/google/protobuf/text_format.py"", line 823, in _MergeMessageField self._MergeField(tokenizer, sub_message) File ""/usr/local/lib/python2.7/dist-packages/google/protobuf/text_format.py"", line 735, in _MergeField merger(tokenizer, message, field) File ""/usr/local/lib/python2.7/dist-packages/google/protobuf/text_format.py"", line 823, in _MergeMessageField self._MergeField(tokenizer, sub_message) File ""/usr/local/lib/python2.7/dist-packages/google/protobuf/text_format.py"", line 735, in _MergeField merger(tokenizer, message, field) File ""/usr/local/lib/python2.7/dist-packages/google/protobuf/text_format.py"", line 823, in _MergeMessageField self._MergeField(tokenizer, sub_message) File ""/usr/local/lib/python2.7/dist-packages/google/protobuf/text_format.py"", line 703, in _MergeField (message_descriptor.full_name, name)) ParseError: 165:2 : Message type ""object_detection.protos.SSDRandomCropPad"" has no field named ""min_padded_size_ratio"".
```
I have added data augmentation as suggested in the [preprocessor.proto](https://github.com/tensorflow/models/blob/master/research/object_detection/protos/preprocessor.proto) file. Can someone let me know if this is a bug or am I doing something wrong?

### Source code / logs
Attaching the `config` file:

```
# SSD with Inception v2 configured for Oxford-IIIT Pets Dataset.
# Users should configure the fine_tune_checkpoint field in the train config as
# well as the label_map_path and input_path fields in the train_input_reader and
# eval_input_reader. Search for ""gs://shopinod/od_multiple_cats_16/data"" to find the fields that
# should be configured.

model {
  ssd {
    num_classes: 16
    box_coder {
      faster_rcnn_box_coder {
        y_scale: 10.0
        x_scale: 10.0
        height_scale: 5.0
        width_scale: 5.0
      }
    }
    matcher {
      argmax_matcher {
        matched_threshold: 0.5
        unmatched_threshold: 0.5
        ignore_thresholds: false
        negatives_lower_than_unmatched: true
        force_match_for_each_row: true
      }
    }
    similarity_calculator {
      iou_similarity {
      }
    }
    anchor_generator {
      ssd_anchor_generator {
        num_layers: 6
        min_scale: 0.2
        max_scale: 0.95
        aspect_ratios: 1.0
        aspect_ratios: 2.0
        aspect_ratios: 0.5
        aspect_ratios: 3.0
        aspect_ratios: 0.3333
        reduce_boxes_in_lowest_layer: true
      }
    }
    image_resizer {
      fixed_shape_resizer {
        height: 300
        width: 300
      }
    }
    box_predictor {
      convolutional_box_predictor {
        min_depth: 0
        max_depth: 0
        num_layers_before_predictor: 0
        use_dropout: false
        dropout_keep_probability: 0.8
        kernel_size: 3
        box_code_size: 4
        apply_sigmoid_to_scores: false
        conv_hyperparams {
          activation: RELU_6,
          regularizer {
            l2_regularizer {
              weight: 0.00004
            }
          }
          initializer {
            truncated_normal_initializer {
              stddev: 0.03
              mean: 0.0
            }
          }
        }
      }
    }
    feature_extractor {
      type: 'ssd_inception_v2'
      min_depth: 16
      depth_multiplier: 1.0
      conv_hyperparams {
        activation: RELU_6,
        regularizer {
          l2_regularizer {
            weight: 0.00004
          }
        }
        initializer {
          truncated_normal_initializer {
            stddev: 0.03
            mean: 0.0
          }
        }
        batch_norm {
          train: true,
          scale: true,
          center: true,
          decay: 0.9997,
          epsilon: 0.001,
        }
      }
    }
    loss {
      classification_loss {
        weighted_sigmoid {
          anchorwise_output: true
        }
      }
      localization_loss {
        weighted_smooth_l1 {
          anchorwise_output: true
        }
      }
      hard_example_miner {
        num_hard_examples: 3000
        iou_threshold: 0.99
        loss_type: CLASSIFICATION
        max_negatives_per_positive: 3
        min_negatives_per_image: 0
      }
      classification_weight: 1.0
      localization_weight: 1.0
    }
    normalize_loss_by_num_matches: true
    post_processing {
      batch_non_max_suppression {
        score_threshold: 1e-8
        iou_threshold: 0.6
        max_detections_per_class: 100
        max_total_detections: 100
      }
      score_converter: SIGMOID
    }
  }
}

train_config: {
  batch_size: 16
  optimizer {
    rms_prop_optimizer: {
      learning_rate: {
        exponential_decay_learning_rate {
          initial_learning_rate: 0.0001
          decay_steps: 20000
          decay_factor: 0.95
        }
      }
      momentum_optimizer_value: 0.9
      decay: 0.9
      epsilon: 1.0
    }
  }
  fine_tune_checkpoint: ""gs://shopinod/od_multiple_cats_16/data/model.ckpt""
  from_detection_checkpoint: true
  # Note: The below line limits the training process to 200K steps, which we
  # empirically found to be sufficient enough to train the pets dataset. This
  # effectively bypasses the learning rate schedule (the learning rate will
  # never decay). Remove the below line to train indefinitely.
  num_steps: 2000000
  data_augmentation_options {
    random_horizontal_flip {
    }
  }
  data_augmentation_options {
    ssd_random_crop_pad {
	min_padded_size_ratio: (16.0, 16.0)
	max_padded_size_ratio: (16.0, 16.0)
	random_coef: 0.5
    }
  }
  data_augmentation_options {
    random_rotation90 {
    }
  }
  data_augmentation_options {
    random_vertical_flip {
    }
  }
}

train_input_reader: {
  tf_record_input_reader {
    input_path: ""gs://shopinod/od_multiple_cats_16/data/train_1021.record""
  }
  label_map_path: ""gs://shopinod/od_multiple_cats_16/data/label_map.pbtxt""
}

eval_config: {
  num_examples: 2000
  num_visualizations: 10
  # Note: The below line limits the evaluation process to 10 evaluations.
  # Remove the below line to evaluate indefinitely.
  # max_evals: 10
}

eval_input_reader: {
  tf_record_input_reader {
    input_path: ""gs://shopinod/od_multiple_cats_16/data/test.record""
  }
  label_map_path: ""gs://shopinod/od_multiple_cats_16/data/label_map.pbtxt""
  shuffle: true
  num_readers: 1
}
```
",jashshah,None,2018-06-08T13:41:49Z,2018-06-11T10:26:09Z,,,,,,,
4481,x86_64-linux-gnu-gcc: error: pycocotools/_mask.c: No such file or directory,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",shan1322,None,2018-06-07T12:22:45Z,2019-02-17T19:57:51Z,,,,,,,
4477,BugFix: python3 compatability,"Wrapped range() with a list, for python3 compatability.

See: https://github.com/tensorflow/models/issues/4455",dori-reichmann,b'cla: yes',2018-06-07T07:30:12Z,2019-12-03T07:09:27Z,,,,,,,
4467,"Using pb inefficiently in ""object_detection_tutorial.ipynb""","Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:object_detection
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:NO
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:win7
- **TensorFlow installed from (source or binary)**:binary
- **TensorFlow version (use command below)**:tensorflow-gpu-1.8.0
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:9.0/7.0.5
- **GPU model and memory**:GTX960
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
when i used many picture to detect my model by pb as ""research/object_detection/object_detection_tutorial.ipynb"" did,it was very slow.I found it will open Session and close once by detecting one picture.So, i think it was very slow in ""object_detection_tutorial.ipynb""

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",a819721810,None,2018-06-06T07:03:27Z,2020-02-07T18:46:00Z,,,,,,,
4451,about the transformer,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Currently this project is an example of ende, which sharing the same vocabulary file. If I want to train two vocabulary files such as enzh, how can I change the code? Can you support it?

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",rgwt123,None,2018-06-05T02:46:44Z,2020-02-07T18:45:59Z,,,,,,,
4448,Object Detection Score Points,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.

Hi, 

Mines are 2 quick questions:
1- The scores we are obtaining in the object_detection python file, how can I convert them to probabilities plotted on the output images? It does not look like z-score or t-score or etc...
2- for ssd_mobilenet_v1, faster_rcnn_resnet101, and faster_rcnn_inception_resnet; how many layers are we training when we do training with these models? 

Thank you,
Selin",BanuSelinTosun,None,2018-06-05T00:56:18Z,2018-06-14T22:45:05Z,,,,,,,
4441,"[Deeplab]Training works well,but evaling and visualizing fail.","**System information:**
What is the top-level directory of the model you are using: tensorflow
Have I written custom code (as opposed to using a stock example script provided in TensorFlow): no
OS Platform and Distribution: Linux Ubuntu 14.04
TensorFlow installed from (source or binary): source
TensorFlow version (use command below): r1.6
Bazel version (if compiling from source): 0.11.1
CUDA/cuDNN version: Cuda compilation tools, release 8.0, V8.0.61
GPU model and memory: Titan XP, 12GB
Python version:2.7.6
GCC Version: 5.5.0
Exact command to reproduce: sh local_test.sh or ./local_test.sh

**Describe the problem:**
I modified the script local_test.sh slightly and used it to train and eval on pascal voc2012. When I set train_crop_size and eval_crop_size both to 513x513, it worked well. Then I changed both to 321x321,training still worked well,but evaling failed. 
Error information:
OP_REQUIRES failed at queue_ops.cc:105 : Invalid argument: Shape mismatch in tuple component 1. Expected [321,321,3], got [366,500,3]
INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.InvalidArgumentError'>, Shape mismatch in tuple component 1. Expected [321,321,3], got [366,500,3]
	 [[Node: batch/padding_fifo_queue_enqueue = QueueEnqueueV2[Tcomponents=[DT_INT64, DT_FLOAT, DT_STRING, DT_INT32, DT_UINT8, DT_INT64], timeout_ms=-1, _device=""/job:localhost/replica:0/task:0/device

I tried to use pdb to find the bug,but failed. Could someone help me? Thanks a lot.

**My modified script:**
cd ..

export CUDA_VISIBLE_DEVICES=""0,1""
export PYTHONPATH=$PYTHONPATH:`pwd`:`pwd`/slim

CURRENT_DIR=$(pwd)
WORK_DIR=""${CURRENT_DIR}/deeplab""
DATASET_DIR=""${WORK_DIR}/datasets""
cd ""${CURRENT_DIR}""

PASCAL_FOLDER=""${DATASET_DIR}/pascal_voc_seg""
TRAIN_LOGDIR=""${PASCAL_FOLDER}/logging/train""
EVAL_LOGDIR=""${PASCAL_FOLDER}/logging/eval""
VIS_LOGDIR=""${PASCAL_FOLDER}/logging/vis""
mkdir -p ""${TRAIN_LOGDIR}""
mkdir -p ""${EVAL_LOGDIR}""
mkdir -p ""${VIS_LOGDIR}""

PASCAL_DATASET=""${PASCAL_FOLDER}/tfrecord""

NUM_ITERATIONS=30000
python ""${WORK_DIR}""/train.py \
  --logtostderr \
  --training_number_of_steps=""${NUM_ITERATIONS}"" \
  --train_split=""train"" \
  --model_variant=""xception_65"" \
  --atrous_rates=6 \
  --atrous_rates=12 \
  --atrous_rates=18 \
  --output_stride=16 \
  --decoder_output_stride=4 \
  --train_crop_size=321 \
  --train_crop_size=321 \
  --train_batch_size=12 \
  --dataset=""pascal_voc_seg"" \
  --fine_tune_batch_norm=true \
  --tf_initial_checkpoint=""${WORK_DIR}/ini_ckpt/xception_pascal_trainval/model.ckpt"" \
  --train_logdir=""${TRAIN_LOGDIR}"" \
  --dataset_dir=""${PASCAL_DATASET}""

python ""${WORK_DIR}""/eval.py \
  --logtostderr \
  --eval_split=""val"" \
  --model_variant=""xception_65"" \
  --atrous_rates=6 \
  --atrous_rates=12 \
  --atrous_rates=18 \
  --output_stride=16 \
  --decoder_output_stride=4 \
  --eval_crop_size=321 \
  --eval_crop_size=321 \
  --checkpoint_dir=""${TRAIN_LOGDIR}"" \
  --eval_logdir=""${EVAL_LOGDIR}"" \
  --dataset_dir=""${PASCAL_DATASET}"" \
  --max_number_of_evaluations=1


",ghost,None,2018-06-04T13:30:25Z,2018-12-01T14:24:43Z,,,,,,,
4439,SSD mobilenet checkpoints are broken,"- **What is the top-level directory of the model you are using**:
research/
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
NO
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Ubuntu 16.04
- **TensorFlow installed from (source or binary)**:
binary
- **TensorFlow version (use command below)**:
1.6 (pip install --ignore-installed --upgrade https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow_gpu-1.6.0-cp27-none-linux_x86_64.whl)
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
CUDA9.0 cuDNN7.0.5
- **GPU model and memory**:
1080Ti, 11GB
- **Exact command to reproduce**:
python object_detection/train.py \
    --logtostderr \
    --pipeline_config_path=/home/dingxiaohan/rda/ssd_mobilenet_v2_coco.config \
    --train_dir=p2_debug

python object_detection/eval.py \
    --logtostderr \
    --pipeline_config_path=/home/dingxiaohan/rda/ssd_mobilenet_v2_coco.config \
    --checkpoint_dir=p2_debug \
    --eval_dir=p2_debug_eval


### Describe the problem
I am trying to train the pre-trained SSD and faster rcnn models on COCO.
But when the training of SSD-mobilenet-v1 began, the loss was initially above 300 and decreased drastically. When the loss became stable (around 5) after a few minutes, the visualization of the detections made no sense, as the image is filled up with big boxes of all classes. After ten hours of training, the predictions started to make some sense. I think this suggests that the checkpoints do not work on COCO. I am sure that the checkpoints are loaded by the codes, as the parameters do not look like randomly initialized (I ran codes like [print(np.sum(sess.run(SOME_CONV_KERNEL_TENSORS)))] and got values with large magnitude (100 ~ 3000)).
SSD-mobilenet-v2 behaved similarly, where the initial loss was around 280.
The SSD-mobilenet models were downloaded from the model zoo (http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v1_coco_2017_11_17.tar.gz, http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v2_coco_2018_03_29.tar.gz).
Faster-rcnn-resnet101 works fine for me.
Only the path-related lines in the config files were modified.
Switching py27 to py36 made no difference.

",ShawnDing1994,None,2018-06-04T11:36:27Z,2020-02-07T18:45:58Z,,,,,,,
4438,feature request : accuracy metrics in train.py/eval.py in object_detection module ,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:  object_detection
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:no
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 15.04
- **TensorFlow installed from (source or binary)**:binary
- **TensorFlow version (use command below)**:1.6
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:cudnn 7
- **GPU model and memory**: Tesla V100
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.
I am doing training for my customized object using train.py available in object_detection module and want to add accuracy metrics to train.py and eval.py in object_detection module.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",DharaBagadia,None,2018-06-04T09:01:34Z,2020-02-07T18:45:58Z,,,,,,,
4416,Remove drop remainder from ResNet pipeline. (temporary),There is a bug where setting drop_remainder=True in fused map and batch is causing lockups. I plan to add it back in when the issue is resolved.,robieta,b'cla: yes',2018-05-31T16:07:39Z,2018-06-03T18:29:37Z,,,,,,,
4407,"how do u solve the problem when load checkpoint in transfer learning ssd mobile v2 ,","Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
finetuning ssd mobile v2 ,when restoring  checkpoint ,there is a problem

### Source code / logs
ncodingPredictor/biases/ExponentialMovingAverage not found in checkpoint
INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.NotFoundError'>, Key BoxPredictor_0/BoxEncodingPredictor/biases/ExponentialMovingAverage not found in checkpoint
         [[Node: save/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, ..., DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_INT64], _device=""/job:localhost/replica:0/task:0/device:CPU:0""](_arg_save/Const_0_0, save/RestoreV2/tensor_names, save/RestoreV2/shape_and_slices)]]

Caused by op 'save/RestoreV2', defined at:
  File ""/home/vsoon/liangpeijun/models-master/research/object_detection/train.py"", line 184, in <module>
    tf.app.run()
  File ""/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/platform/app.py"", line 126, in run
    _sys.exit(main(argv))
  File ""/home/vsoon/liangpeijun/models-master/research/object_detection/train.py"", line 180, in main
    graph_hook_fn=graph_rewriter_fn)
  File ""/opt/anaconda3/lib/python3.6/site-packages/object_detection-0.1-py3.6.egg/object_detection/trainer.py"", line 361, in train
    keep_checkpoint_every_n_hours=keep_checkpoint_every_n_hours)
  File ""/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py"", line 1311, in __init__
    self.build()
  File ""/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py"", line 1320, in build
    self._build(self._filename, build_save=True, build_restore=True)
  File ""/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py"", line 1357, in _build
    build_save=build_save, build_restore=build_restore)
  File ""/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py"", line 809, in _build_internal
    restore_sequentially, reshape)
  File ""/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py"", line 448, in _AddRestoreOps
    restore_sequentially)
  File ""/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py"", line 860, in bulk_restore
    return io_ops.restore_v2(filename_tensor, names, slices, dtypes)
  File ""/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_io_ops.py"", line 1458, in restore_v2
    shape_and_slices=shape_and_slices, dtypes=dtypes, name=name)
  File ""/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py"", line 787, in _apply_op_helper
    op_def=op_def)
  File ""/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 3290, in create_op
    op_def=op_def)
  File ""/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 1654, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access

NotFoundError (see above for traceback): Key BoxPredictor_0/BoxEncodingPredictor/biases/ExponentialMovingAverage not found in checkpoint
         [[Node: save/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, ..., DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_INT64], _device=""/job:localhost/replica:0/task:0/device:CPU:0""](_arg_save/Const_0_0, save/RestoreV2/tensor_names, save/RestoreV2/shape_and_slices)]]

INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.NotFoundError'>, Key BoxPredictor_0/BoxEncodingPredictor/biases/ExponentialMovingAverage not found in checkpoint
         [[Node: save/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, ..., DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_INT64], _device=""/job:localhost/replica:0/task:0/device:CPU:0""](_arg_save/Const_0_0, save/RestoreV2/tensor_names, save/RestoreV2/shape_and_slices)]]

Caused by op 'save/RestoreV2', defined at:
  File ""/home/vsoon/liangpeijun/models-master/research/object_detection/train.py"", line 184, in <module>
    tf.app.run()
  File ""/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/platform/app.py"", line 126, in run
    _sys.exit(main(argv))
  File ""/home/vsoon/liangpeijun/models-master/research/object_detection/train.py"", line 180, in main
    graph_hook_fn=graph_rewriter_fn)
  File ""/opt/anaconda3/lib/python3.6/site-packages/object_detection-0.1-py3.6.egg/object_detection/trainer.py"", line 361, in train
    keep_checkpoint_every_n_hours=keep_checkpoint_every_n_hours)
  File ""/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py"", line 1311, in __init__
    self.build()
  File ""/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py"", line 1320, in build
    self._build(self._filename, build_save=True, build_restore=True)
  File ""/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py"", line 1357, in _build
    build_save=build_save, build_restore=build_restore)
  File ""/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py"", line 809, in _build_internal
    restore_sequentially, reshape)
  File ""/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py"", line 448, in _AddRestoreOps
    restore_sequentially)
  File ""/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py"", line 860, in bulk_restore
    return io_ops.restore_v2(filename_tensor, names, slices, dtypes)
  File ""/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_io_ops.py"", line 1458, in restore_v2
    shape_and_slices=shape_and_slices, dtypes=dtypes, name=name)
  File ""/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py"", line 787, in _apply_op_helper
    op_def=op_def)
  File ""/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 3290, in create_op
    op_def=op_def)
  File ""/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 1654, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access

NotFoundError (see above for traceback): Key BoxPredictor_0/BoxEncodingPredictor/biases/ExponentialMovingAverage not found in checkpoint
         [[Node: save/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, ..., DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_INT64], _device=""/job:localhost/replica:0/task:0/device:CPU:0""](_arg_save/Const_0_0, save/RestoreV2/tensor_names, save/RestoreV2/shape_and_slices)]]

Traceback (most recent call last):
  File ""/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1327, in _do_call
    return fn(*args)
  File ""/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1312, in _run_fn
    options, feed_dict, fetch_list, target_list, run_metadata)
  File ""/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1420, in _call_tf_sessionrun
    status, run_metadata)
  File ""/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py"", line 516, in __exit__
    c_api.TF_GetCode(self.status.status))
tensorflow.python.framework.errors_impl.NotFoundError: Key BoxPredictor_0/BoxEncodingPredictor/biases/ExponentialMovingAverage not found in checkpoint
         [[Node: save/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, ..., DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_INT64], _device=""/job:localhost/replica:0/task:0/device:CPU:0""](_arg_save/Const_0_0, save/RestoreV2/tensor_names, save/RestoreV2/shape_and_slices)]]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/home/vsoon/liangpeijun/models-master/research/object_detection/train.py"", line 184, in <module>
    tf.app.run()
  File ""/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/platform/app.py"", line 126, in run
    _sys.exit(main(argv))
  File ""/home/vsoon/liangpeijun/models-master/research/object_detection/train.py"", line 180, in main
    graph_hook_fn=graph_rewriter_fn)
  File ""/opt/anaconda3/lib/python3.6/site-packages/object_detection-0.1-py3.6.egg/object_detection/trainer.py"", line 399, in train
    saver=saver)
  File ""/opt/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/slim/python/slim/learning.py"", line 747, in train
    master, start_standard_services=False, config=session_config) as sess:
  File ""/opt/anaconda3/lib/python3.6/contextlib.py"", line 81, in __enter__
    return next(self.gen)
  File ""/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/supervisor.py"", line 1000, in managed_session
    self.stop(close_summary_writer=close_summary_writer)
  File ""/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/supervisor.py"", line 828, in stop
    ignore_live_threads=ignore_live_threads)
  File ""/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/coordinator.py"", line 389, in join
    six.reraise(*self._exc_info_to_raise)
  File ""/opt/anaconda3/lib/python3.6/site-packages/six.py"", line 693, in reraise
    raise value
  File ""/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/supervisor.py"", line 989, in managed_session
    start_standard_services=start_standard_services)
  File ""/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/supervisor.py"", line 726, in prepare_or_wait_for_session
    init_feed_dict=self._init_feed_dict, init_fn=self._init_fn)
  File ""/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/session_manager.py"", line 275, in prepare_session
    config=config)
  File ""/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/session_manager.py"", line 207, in _restore_checkpoint
    saver.restore(sess, ckpt.model_checkpoint_path)
  File ""/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py"", line 1775, in restore
    {self.saver_def.filename_tensor_name: save_path})
  File ""/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 905, in run
    run_metadata_ptr)
  File ""/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1140, in _run
    feed_dict_tensor, options, run_metadata)
  File ""/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1321, in _do_run
    run_metadata)
  File ""/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1340, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.NotFoundError: Key BoxPredictor_0/BoxEncodingPredictor/biases/ExponentialMovingAverage not found in checkpoint
         [[Node: save/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, ..., DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_INT64], _device=""/job:localhost/replica:0/task:0/device:CPU:0""](_arg_save/Const_0_0, save/RestoreV2/tensor_names, save/RestoreV2/shape_and_slices)]]

Caused by op 'save/RestoreV2', defined at:
  File ""/home/vsoon/liangpeijun/models-master/research/object_detection/train.py"", line 184, in <module>
    tf.app.run()
  File ""/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/platform/app.py"", line 126, in run
    _sys.exit(main(argv))
  File ""/home/vsoon/liangpeijun/models-master/research/object_detection/train.py"", line 180, in main
    graph_hook_fn=graph_rewriter_fn)
  File ""/opt/anaconda3/lib/python3.6/site-packages/object_detection-0.1-py3.6.egg/object_detection/trainer.py"", line 361, in train
    keep_checkpoint_every_n_hours=keep_checkpoint_every_n_hours)
  File ""/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py"", line 1311, in __init__
    self.build()
  File ""/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py"", line 1320, in build
    self._build(self._filename, build_save=True, build_restore=True)
  File ""/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py"", line 1357, in _build
    build_save=build_save, build_restore=build_restore)
  File ""/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py"", line 809, in _build_internal
    restore_sequentially, reshape)
  File ""/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py"", line 448, in _AddRestoreOps
    restore_sequentially)
  File ""/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py"", line 860, in bulk_restore
    return io_ops.restore_v2(filename_tensor, names, slices, dtypes)
  File ""/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_io_ops.py"", line 1458, in restore_v2
    shape_and_slices=shape_and_slices, dtypes=dtypes, name=name)
  File ""/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py"", line 787, in _apply_op_helper
    op_def=op_def)
  File ""/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 3290, in create_op
    op_def=op_def)
  File ""/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 1654, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access

NotFoundError (see above for traceback): Key BoxPredictor_0/BoxEncodingPredictor/biases/ExponentialMovingAverage not found in checkpoint
         [[Node: save/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, ..., DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_INT64], _device=""/job:localhost/replica:0/task:0/device:CPU:0""](_arg_save/Const_0_0, save/RestoreV2/tensor_names, save/RestoreV2/shape_and_slices)]]
",pageedward,None,2018-05-30T10:00:04Z,2020-02-07T18:45:48Z,,,,,,,
4403,"how to train own model using our image ,I want to use the Xception_65 checkpoint file","Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",liangfengjiao,None,2018-05-30T02:05:29Z,2018-11-21T21:49:02Z,,,,,,,
4399,..,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",sx2154,None,2018-05-29T20:29:00Z,2018-09-21T00:04:19Z,,,,,,,
4392,bug report: DEFINE_boolean not work fot tensorflow 1.8,"from tensorflow.python.platform.flags import DEFINE_float, DEFINE_string, DEFINE_integer, DEFINE_boolean, DEFINE_bool

this two functions DEFINE_boolean, DEFINE_bool is not working， when i try to run my code 
in a cmd windows. i can not set boolean parameters by function  DEFINE_boolean or DEFINE_bool.

python XXXX.py --stringTest hello --integerTest 500 --booleanTest False --floatTest 0.95

my code here:
DEFINE_string(""stringTest"", 'StringTest的测试数据', '默认测试数据是 StringTest的测试数据')
DEFINE_integer('integerTest', 20, '默认测试数据是20')
DEFINE_boolean('booleanTest', True, ""默认测试数据是True"")
DEFINE_float('floatTest', 0.65, ""默认测试数据是0.65"")

Flags = tf.app.flags.FLAGS

def main(_):
    str1 = Flags.stringTest
    print(str1, type(str1))
    integer1 = Flags.integerTest
    print(integer1, type(integer1))
    bool1 = Flags.booleanTest
    print(bool1, type(bool1))
    float1 = Flags.floatTest
    print(float1, type(float1))

if __name__ == '__main__':
    tf.app.run()",tnkong,b'stat:awaiting response',2018-05-29T06:18:29Z,2020-02-07T18:45:47Z,,,,,,,
4383,[Syntaxnet] Build errors while following readme on Mac,"- **What is the top-level directory of the model you are using**: models/research/syntaxnet
- **Have I written custom code**: No
- **OS Platform and Distribution**: MacOS High Sierra
- **TensorFlow installed from/version**: I'm installing syntaxnet from source, isn't it bundled with TF of required version?
- **Bazel version**: 0.11.1
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**:
```
bazel test --linkopt=-headerpad_max_install_names \
    dragnn/... syntaxnet/... util/utf8/...
```

I'm following the https://github.com/tensorflow/models/blob/master/research/syntaxnet/README.md and got the exact versions of the dependencies listed (protobuf 3.3.0 in particular). I've also installed protobuf runtime and system includes (strange that there's nothing about that in readme). All python dependencies live in virtual env and I'm building from an env.

The problem is, that when building, I've got the following error
```
ERROR: /Users/screamer/dev/syntaxnet/models/research/syntaxnet/util/utf8/BUILD:35:1: C++ compilation of rule '//util/utf8:unicodetext_main' failed (Exit 1)
In file included from util/utf8/unicodetext_main.cc:26:
In file included from ./util/utf8/unicodetext.h:25:
In file included from ./syntaxnet/base.h:28:
In file included from external/org_tensorflow/tensorflow/core/lib/core/status.h:23:
bazel-out/darwin-opt/genfiles/external/org_tensorflow/tensorflow/core/lib/core/error_codes.pb.h:12:2: error: This file was generated by a newer version of protoc which is
#error This file was generated by a newer version of protoc which is
 ^
bazel-out/darwin-opt/genfiles/external/org_tensorflow/tensorflow/core/lib/core/error_codes.pb.h:13:2: error: incompatible with your Protocol Buffer headers.  Please update
#error incompatible with your Protocol Buffer headers.  Please update
 ^
bazel-out/darwin-opt/genfiles/external/org_tensorflow/tensorflow/core/lib/core/error_codes.pb.h:14:2: error: your headers.
#error your headers.
 ^
bazel-out/darwin-opt/genfiles/external/org_tensorflow/tensorflow/core/lib/core/error_codes.pb.h:39:46: error: no type named 'FieldMetadata' in namespace 'google::protobuf::internal'
  static const ::google::protobuf::internal::FieldMetadata field_metadata[];
               ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^
bazel-out/darwin-opt/genfiles/external/org_tensorflow/tensorflow/core/lib/core/error_codes.pb.h:40:46: error: no type named 'SerializationTable' in namespace 'google::protobuf::internal'
  static const ::google::protobuf::internal::SerializationTable serialization_table[];
```

With protobuf 3.5.1 it builds fine, but a bunch of test fail:
```
INFO: Build completed, 20 tests FAILED, 118 total actions
//dragnn/components/stateless:stateless_component_test                   PASSED in 0.2s
//dragnn/components/syntaxnet:syntaxnet_component_test                   PASSED in 0.3s
//dragnn/components/syntaxnet:syntaxnet_link_feature_extractor_test      PASSED in 0.3s
//dragnn/components/syntaxnet:syntaxnet_transition_state_test            PASSED in 0.2s
//dragnn/core:beam_test                                                  PASSED in 0.2s
//dragnn/core:compute_session_impl_test                                  PASSED in 0.3s
//dragnn/core:compute_session_pool_test                                  PASSED in 0.2s
//dragnn/core:dragnn_bulk_op_kernels_test                                PASSED in 0.2s
//dragnn/core:dragnn_op_kernels_test                                     PASSED in 0.3s
//dragnn/core:index_translator_test                                      PASSED in 0.2s
//dragnn/core:input_batch_cache_test                                     PASSED in 0.2s
//dragnn/core:resource_container_test                                    PASSED in 0.2s
//dragnn/io:sentence_input_batch_test                                    PASSED in 0.2s
//dragnn/mst:disjoint_set_forest_test                                    PASSED in 0.2s
//dragnn/mst:mst_solver_test                                             PASSED in 0.2s
//dragnn/mst:spanning_tree_iterator_test                                 PASSED in 0.3s
//dragnn/python:composite_optimizer_test                                 PASSED in 9.3s
//dragnn/python:digraph_ops_test                                         PASSED in 5.8s
//dragnn/python:evaluation_test                                          PASSED in 4.9s
//dragnn/python:render_parse_tree_graphviz_test                          PASSED in 5.4s
//dragnn/python:render_spec_with_graphviz_test                           PASSED in 5.4s
//dragnn/python:trainer_lib_test                                         PASSED in 5.3s
//dragnn/python:visualization_test                                       PASSED in 5.1s
//dragnn/tools/benchmarks:beam_benchmark                                 PASSED in 0.2s
//syntaxnet:arc_standard_transitions_test                                PASSED in 0.2s
//syntaxnet:binary_segment_state_test                                    PASSED in 0.2s
//syntaxnet:binary_segment_transitions_test                              PASSED in 0.2s
//syntaxnet:char_ngram_string_extractor_test                             PASSED in 0.2s
//syntaxnet:char_properties_test                                         PASSED in 0.2s
//syntaxnet:char_shift_transitions_test                                  PASSED in 0.2s
//syntaxnet:fml_parser_test                                              PASSED in 0.2s
//syntaxnet:generic_features_test                                        PASSED in 0.2s
//syntaxnet:head_label_transitions_test                                  PASSED in 0.3s
//syntaxnet:head_transitions_test                                        PASSED in 0.2s
//syntaxnet:label_transitions_test                                       PASSED in 0.2s
//syntaxnet:morphology_label_set_test                                    PASSED in 0.2s
//syntaxnet:once_transitions_test                                        PASSED in 0.2s
//syntaxnet:parser_features_test                                         PASSED in 0.2s
//syntaxnet:registry_test                                                PASSED in 0.2s
//syntaxnet:registry_test_with_duplicate                                 PASSED in 0.2s
//syntaxnet:segmenter_utils_test                                         PASSED in 0.2s
//syntaxnet:sentence_features_test                                       PASSED in 0.2s
//syntaxnet:shared_store_test                                            PASSED in 0.2s
//syntaxnet:tagger_transitions_test                                      PASSED in 0.2s
//syntaxnet:term_frequency_map_test                                      PASSED in 0.2s
//syntaxnet:whole_sentence_features_test                                 PASSED in 0.2s
//syntaxnet/util:check_test                                              PASSED in 4.6s
//syntaxnet/util:registry_test                                           PASSED in 4.6s
//syntaxnet/util:resources_test                                          PASSED in 4.5s
//util/utf8:unicodetext_unittest                                         PASSED in 0.2s
//dragnn/python:biaffine_units_test                                      FAILED in 4.6s
  /private/var/tmp/_bazel_screamer/18e2c8b2c8dff4a4063d43a04ecb656f/execroot/__main__/bazel-out/darwin-opt/testlogs/dragnn/python/biaffine_units_test/test.log
//dragnn/python:bulk_component_test                                      FAILED in 4.7s
  /private/var/tmp/_bazel_screamer/18e2c8b2c8dff4a4063d43a04ecb656f/execroot/__main__/bazel-out/darwin-opt/testlogs/dragnn/python/bulk_component_test/test.log
//dragnn/python:component_test                                           FAILED in 4.7s
  /private/var/tmp/_bazel_screamer/18e2c8b2c8dff4a4063d43a04ecb656f/execroot/__main__/bazel-out/darwin-opt/testlogs/dragnn/python/component_test/test.log
//dragnn/python:dragnn_model_saver_lib_test                              FAILED in 5.0s
  /private/var/tmp/_bazel_screamer/18e2c8b2c8dff4a4063d43a04ecb656f/execroot/__main__/bazel-out/darwin-opt/testlogs/dragnn/python/dragnn_model_saver_lib_test/test.log
//dragnn/python:lexicon_test                                             FAILED in 4.8s
  /private/var/tmp/_bazel_screamer/18e2c8b2c8dff4a4063d43a04ecb656f/execroot/__main__/bazel-out/darwin-opt/testlogs/dragnn/python/lexicon_test/test.log
//dragnn/python:mst_ops_test                                             FAILED in 4.7s
  /private/var/tmp/_bazel_screamer/18e2c8b2c8dff4a4063d43a04ecb656f/execroot/__main__/bazel-out/darwin-opt/testlogs/dragnn/python/mst_ops_test/test.log
//dragnn/python:mst_units_test                                           FAILED in 4.8s
  /private/var/tmp/_bazel_screamer/18e2c8b2c8dff4a4063d43a04ecb656f/execroot/__main__/bazel-out/darwin-opt/testlogs/dragnn/python/mst_units_test/test.log
//dragnn/python:network_units_test                                       FAILED in 5.2s
  /private/var/tmp/_bazel_screamer/18e2c8b2c8dff4a4063d43a04ecb656f/execroot/__main__/bazel-out/darwin-opt/testlogs/dragnn/python/network_units_test/test.log
//dragnn/python:runtime_support_test                                     FAILED in 5.1s
  /private/var/tmp/_bazel_screamer/18e2c8b2c8dff4a4063d43a04ecb656f/execroot/__main__/bazel-out/darwin-opt/testlogs/dragnn/python/runtime_support_test/test.log
//dragnn/python:sentence_io_test                                         FAILED in 5.2s
  /private/var/tmp/_bazel_screamer/18e2c8b2c8dff4a4063d43a04ecb656f/execroot/__main__/bazel-out/darwin-opt/testlogs/dragnn/python/sentence_io_test/test.log
//dragnn/python:spec_builder_test                                        FAILED in 5.2s
  /private/var/tmp/_bazel_screamer/18e2c8b2c8dff4a4063d43a04ecb656f/execroot/__main__/bazel-out/darwin-opt/testlogs/dragnn/python/spec_builder_test/test.log
//dragnn/python:transformer_units_test                                   FAILED in 5.1s
  /private/var/tmp/_bazel_screamer/18e2c8b2c8dff4a4063d43a04ecb656f/execroot/__main__/bazel-out/darwin-opt/testlogs/dragnn/python/transformer_units_test/test.log
//dragnn/tools:model_trainer_test                                        FAILED in 3.7s
  /private/var/tmp/_bazel_screamer/18e2c8b2c8dff4a4063d43a04ecb656f/execroot/__main__/bazel-out/darwin-opt/testlogs/dragnn/tools/model_trainer_test/test.log
//syntaxnet:beam_reader_ops_test                                         FAILED in 4.4s
  /private/var/tmp/_bazel_screamer/18e2c8b2c8dff4a4063d43a04ecb656f/execroot/__main__/bazel-out/darwin-opt/testlogs/syntaxnet/beam_reader_ops_test/test.log
//syntaxnet:graph_builder_test                                           FAILED in 4.4s
  /private/var/tmp/_bazel_screamer/18e2c8b2c8dff4a4063d43a04ecb656f/execroot/__main__/bazel-out/darwin-opt/testlogs/syntaxnet/graph_builder_test/test.log
//syntaxnet:lexicon_builder_test                                         FAILED in 4.4s
  /private/var/tmp/_bazel_screamer/18e2c8b2c8dff4a4063d43a04ecb656f/execroot/__main__/bazel-out/darwin-opt/testlogs/syntaxnet/lexicon_builder_test/test.log
//syntaxnet:parser_trainer_test                                          FAILED in 4.3s
  /private/var/tmp/_bazel_screamer/18e2c8b2c8dff4a4063d43a04ecb656f/execroot/__main__/bazel-out/darwin-opt/testlogs/syntaxnet/parser_trainer_test/test.log
//syntaxnet:reader_ops_test                                              FAILED in 4.4s
  /private/var/tmp/_bazel_screamer/18e2c8b2c8dff4a4063d43a04ecb656f/execroot/__main__/bazel-out/darwin-opt/testlogs/syntaxnet/reader_ops_test/test.log
//syntaxnet:text_formats_test                                            FAILED in 3.9s
  /private/var/tmp/_bazel_screamer/18e2c8b2c8dff4a4063d43a04ecb656f/execroot/__main__/bazel-out/darwin-opt/testlogs/syntaxnet/text_formats_test/test.log
//dragnn/python:graph_builder_test                                       FAILED in 5 out of 5 in 4.9s
  Stats over 5 runs: max = 4.9s, min = 1.9s, avg = 2.6s, dev = 1.2s
  /private/var/tmp/_bazel_screamer/18e2c8b2c8dff4a4063d43a04ecb656f/execroot/__main__/bazel-out/darwin-opt/testlogs/dragnn/python/graph_builder_test/shard_4_of_5/test.log
  /private/var/tmp/_bazel_screamer/18e2c8b2c8dff4a4063d43a04ecb656f/execroot/__main__/bazel-out/darwin-opt/testlogs/dragnn/python/graph_builder_test/shard_1_of_5/test.log
  /private/var/tmp/_bazel_screamer/18e2c8b2c8dff4a4063d43a04ecb656f/execroot/__main__/bazel-out/darwin-opt/testlogs/dragnn/python/graph_builder_test/shard_2_of_5/test.log
  /private/var/tmp/_bazel_screamer/18e2c8b2c8dff4a4063d43a04ecb656f/execroot/__main__/bazel-out/darwin-opt/testlogs/dragnn/python/graph_builder_test/shard_5_of_5/test.log
  /private/var/tmp/_bazel_screamer/18e2c8b2c8dff4a4063d43a04ecb656f/execroot/__main__/bazel-out/darwin-opt/testlogs/dragnn/python/graph_builder_test/shard_3_of_5/test.log

Executed 70 out of 70 tests: 50 tests pass and 20 fail locally.
There were tests whose specified size is too big. Use the --test_verbose_timeout_warnings command line option to see which ones these are.
```
Each of the test logs have the same contents:
```
exec ${PAGER:-/usr/bin/less} ""$0"" || exit 1
-----------------------------------------------------------------------------
python(5945,0x7fff8df61380) malloc: *** error for object 0x10c7af7a0: pointer being freed was not allocated
*** set a breakpoint in malloc_error_break to debug
Abort trap: 6
```

I will appreciate any help and will be happy to provide any additional information, if necessary.",place-for-your-ad,b'models:research type:support',2018-05-27T14:37:28Z,2020-07-10T10:13:43Z,,,,,,,
4382,Distributed training mode: the master node does training work but shouldn't,"I spent some time debugging distributed training mode and noticed something.  I'm not sure if it's intentional or not.  In particular, when you start distributed training by setting a TF_CONFIG, the master node ends up evaluating training data, computing loss, and optimizing is.  This is in addition to the worker nodes.  The master node appears to do dual duty (master coordination in addition to training).

I've worked in distributed computing for a while, and the convention is that the master node doesn't do training work- it's harder to configure the resource requests for a master that does dual duty, and there are subtle performance problems as the training and the master coordination tend to fight for limited CPU availability.  It also plays poorly with frameworks that handle distributed training (for example, kubeflow has a TFJob that makes it easy to set up distributed training on k8s; it assumes the ""master"" container doesn't need or want GPU.

Before going further, I'd like to ask: is the choice of doing training work on the master node intentional?  I am guessing it's just an oversight, and that the code for converting the TF_CONFIG to a computation needs to explicitly ensure that work is only assigned to worker nodes.

If the choice is intentional, then I'll have to make adjustments to my distributed training pipeline to include additional resources for the master node (more CPU, along with GPU), and spend time debugging performance problems.  If the choice is not intentional, then i think we can proceed to repair the script.",dakoner,None,2018-05-26T14:46:51Z,2020-01-29T23:42:20Z,,,,,,,
4380,how to create confusion matrix for object_detection model in tensorflow,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",naoufelfrioui,None,2018-05-26T13:34:01Z,2018-05-28T17:46:26Z,,,,,,,
4377,Make boosted_trees Garden-official,"Hi All,

I update the boosted_trees code to make it more garden-style:
1. Add official flags in data_download.py, and fix a minor bug
2. Add benchmark logger in train_higgs.py
3. Update single quote with double quotes",yhliang2018,b'cla: yes',2018-05-25T23:39:52Z,2018-05-29T22:47:33Z,,,,,,,
4358,Properly assign dataset in the second resnet prefetch call,Fix a bug in the resnet pipeline reported in https://github.com/tensorflow/models/issues/4354.,robieta,b'cla: yes',2018-05-24T12:40:15Z,2018-05-24T16:41:40Z,,,,,,,
4354,Potential bug in resnet_run_loop dataset code,"### System information
- **What is the top-level directory of the model you are using**: models/official/resnet
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:N/A
- **TensorFlow installed from (source or binary)**: N/A
- **TensorFlow version (use command below)**: N/A
- **Bazel version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**: N/A

### Describe the problem
I was looking at the resnet code as an example of a high performance input pipeline and noticed that the final prefetch op on the dataset is not assigned to anything:
https://github.com/tensorflow/models/blob/fd1d1780d7e5627973a41951a3061f3c41601fe5/official/resnet/resnet_run_loop.py#L91

Unless prefetch mutates the dataset (the docs don't indicate that it does), that line doesn't appear to be having its intended effect.",ed-alertedh,None,2018-05-24T04:56:05Z,2018-05-25T16:02:52Z,,,,,,,
4344,LabelImage.java gives different results than Python label_image.py,"### Describe the problem
When I retrain inception3 using the flowers example provided on the Tensorflow web site, the Python label_image.py produces the correct results.  When I try to access the same output_graph.pb via LabelImage.java, the results are really inaccurate, even though it is using the same model.  I changed the LabelImage.java code to resize to 299x299.

### Source code / logs
For the daisy image 21652746_cc379e0eea_m.jpg, Java gives predicts roses with the following output:
0.0
0.0
1.0
0.0
1.2818058E-19

Python label_image.py, predicts daisies with the following output:
daisy 0.9979862
sunflowers 0.0011138984
tulips 0.0004278467
dandelion 0.0003640769
roses 0.000108063316

I've tried loading this via a SavedModelBundle and also used the simplified version of LabelImage.  I get the same problems no matter what.  I've searched Stackoverflow.com and can't find a solution, so I think it must be a bug with the Java-to-Tensorflow interface.",tom-neumark,None,2018-05-23T03:40:56Z,2018-05-26T13:08:17Z,,,,,,,
4331,"mAP in tensorboard are all 0 or close to 0, even though the detector is able to detect many objects well","Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**: object_detection
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:no
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**:source
- **TensorFlow version (use command below)**:1.8
- **Bazel version (if compiling from source)**:-
- **CUDA/cuDNN version**:CUDA 9/ cuDNN 7
- **GPU model and memory**: Tesla K-80, (number:2). Each has a memory of 12GB
- **Exact command to reproduce**:tensorboard --logdir=eval/ 


You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
I am training a faster rcnn model on a custom dataset using the object detection API. The training seems to be going well with losses currently:

INFO:tensorflow:global step 4766: loss = 2.8091 (2.764 sec/step)
INFO:tensorflow:global step 4767: loss = 1.6403 (2.768 sec/step)
INFO:tensorflow:global step 4767: loss = 1.6403 (2.768 sec/step)

However, when I try to visualize the metrics using `tensorboard --logdir=eval/`on tensorboard, I get mAPs in all categories either 0 or very close to 0 as shown below:

![map_tensorboard_0](https://user-images.githubusercontent.com/25709940/40321957-61ffc76c-5cf6-11e8-931a-217900ae9b3e.png)

When I look at the images tab in tensorboard, the detector seems to be finding decent boxes

![good_detection_4k](https://user-images.githubusercontent.com/25709940/40321998-88cdef9a-5cf6-11e8-8d70-bf7ecd80df84.png)

![night_time_4k](https://user-images.githubusercontent.com/25709940/40322005-9197ae54-5cf6-11e8-9691-70e932773ab1.png)

My configuration file is:


model {
  faster_rcnn {
    num_classes: 12
    image_resizer {
      keep_aspect_ratio_resizer {
        # Raw KITTI images have a resolution of 1242x375, if we wish to resize
        # them to have a height of 600 then their width should be
        # 1242/(375/600)=1987.2
        min_dimension: 1000
        max_dimension: 1600
      }
    }
    feature_extractor {
      type: 'faster_rcnn_resnet101'
      first_stage_features_stride: 16
    }
    first_stage_anchor_generator {
      grid_anchor_generator {
        scales: [0.25, 0.5, 1.0, 2.0]
        aspect_ratios: [0.5, 1.0, 2.0]
        height_stride: 16
        width_stride: 16
      }
    }
    first_stage_box_predictor_conv_hyperparams {
      op: CONV
      regularizer {
        l2_regularizer {
          weight: 0.0
        }
      }
      initializer {
        truncated_normal_initializer {
          stddev: 0.01
        }
      }
    }
    first_stage_nms_score_threshold: 0.0
    first_stage_nms_iou_threshold: 0.7
    first_stage_max_proposals: 300
    first_stage_localization_loss_weight: 2.0
    first_stage_objectness_loss_weight: 1.0
    initial_crop_size: 14
    maxpool_kernel_size: 2
    maxpool_stride: 2
    second_stage_box_predictor {
      mask_rcnn_box_predictor {
        use_dropout: false
        dropout_keep_probability: 1.0
        fc_hyperparams {
          op: FC
          regularizer {
            l2_regularizer {
              weight: 0.0
            }
          }
          initializer {
            variance_scaling_initializer {
              factor: 1.0
              uniform: true
              mode: FAN_AVG
            }
          }
        }
      }
    }
    second_stage_post_processing {
      batch_non_max_suppression {
        score_threshold: 0.0
        iou_threshold: 0.6
        max_detections_per_class: 100
        max_total_detections: 300
      }
      score_converter: SOFTMAX
    }
    second_stage_localization_loss_weight: 2.0
    second_stage_classification_loss_weight: 1.0
  }
}

train_config: {
  batch_size: 4
  optimizer {
    momentum_optimizer: {
      learning_rate: {
        manual_step_learning_rate {
          initial_learning_rate: 0.0001
          schedule {
            step: 500000
            learning_rate: .00001
          }
          schedule {
            step: 700000
            learning_rate: .000001
          }
        }
      }
      momentum_optimizer_value: 0.9
    }
    use_moving_average: false
  }
  gradient_clipping_by_norm: 10.0
  fine_tune_checkpoint: ""faster_rcnn_resnet101_kitti_2018_01_28/model.ckpt""
  from_detection_checkpoint: true
  num_steps: 800000
  data_augmentation_options {
    random_horizontal_flip {
    }
  }
}

train_input_reader: {
  label_map_path:""data/object-detection.pbtxt""
  tf_record_input_reader: {
    input_path: ""data/train_latest.record""
  }
}

eval_config: {
  use_moving_averages: false
  num_examples: 500
}

eval_input_reader: {
  label_map_path: ""data/object-detection.pbtxt""
  tf_record_input_reader: {
    input_path: ""data/val_latest.record""
  }
  }

Why are mAP values so bad? Please let me know if there is any other information I can provide.

Thanks and Regards,
Karthik



### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",Karthik-Suresh93,None,2018-05-21T18:02:51Z,2020-02-07T18:45:43Z,,,,,,,
4329,Object Detection custom imagen,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
The form below must be filled out.
Here's why we have that policy: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

System information
What is the top-level directory of the model you are using:
Object detection
Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
Yes, just to insert a video instead of using the webcam
OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Windows 10 64 bits (Last version)
TensorFlow installed from (source or binary):
Binary
TensorFlow version (use command below):
v1.8.0-0-g93bc2e2072' 1.8.0
Bazel version (if compiling from source):
N/A
CUDA/cuDNN version:
CUDA: cuda_9.0.176
cuDNN: cudnn-9.0
GPU model and memory:
MSI Geforce GTX 1070 8gb
Exact command to reproduce:
N/A
You can collect some of this information using our environment capture script:
https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

Describe the problem
Hello, I tried to run a .bat with the following commands to use Train.py but skip errors like train_dir is not recognized as a command, etc ...

Source code / logs
Default train.py or tensorflow object detection.",magick2,None,2018-05-21T15:26:38Z,2018-11-21T21:42:49Z,,,,,,,
4306,[Bug Report]: returned shape of resize_to_range() function in preprocessor of object detection API,"I use this [function](https://github.com/tensorflow/models/blob/master/research/object_detection/core/preprocessor.py#L2125) for image resizing and padding during image preprocessing. Based on the document, the output shape should be like `[max_dim, max_dim, 3]` if I turn on `pad_to_max_dimension` parameter. But unfortunately it fails.  I check the source code and it seems that code like `new_size = tf.stack([max_dimension, max_dimension, 3])`  should be added in [this block](https://github.com/tensorflow/models/blob/master/research/object_detection/core/preprocessor.py#L2183), right?
",CasiaFan,b'stat:awaiting maintainer',2018-05-18T09:34:41Z,2020-02-07T18:45:31Z,,,,,,,
4299,Tensorflow-gpu utilize only CPU,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
The form below must be filled out.
Here's why we have that policy: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

What is the top-level directory of the model you are using:
Object detection
Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
Yes, just to insert a video instead of using the webcam
OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Windows 10 64 bits (Last version)
TensorFlow installed from (source or binary):
Binary
TensorFlow version (use command below):
v1.8.0-0-g93bc2e2072' 1.8.0
Bazel version (if compiling from source):
N/A
CUDA/cuDNN version:
CUDA: cuda_9.0.176
cuDNN: cudnn-9.0
GPU model and memory:
MSI Geforce GTX 1070 8gb
Exact command to reproduce:
N/A
You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

Describe the problem
I have the installed version of tensorflow-GPU however it executes the code with CPU.

I reopen the issue, since they have not given me a solution but they have closed it and in stackoverflow they did not know how to help me either

Source code / logs
[object_detection_tutorial.zip](https://github.com/tensorflow/models/files/2014390/object_detection_tutorial.zip)
",magick2,None,2018-05-17T18:54:37Z,2018-05-17T20:24:09Z,,,,,,,
4282,Tensorflow-gpu utilize only CPU,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

What is the top-level directory of the model you are using:
Object detection
Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
Yes, just to insert a video instead of using the webcam
OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Windows 10 64 bits (Last version)
TensorFlow installed from (source or binary):
Binary
TensorFlow version (use command below):
v1.8.0-0-g93bc2e2072' 1.8.0
Bazel version (if compiling from source):
N/A
CUDA/cuDNN version:
CUDA: cuda_9.0.176
cuDNN: cudnn-9.0
GPU model and memory:
MSI Geforce GTX 1070 8gb
Exact command to reproduce:
N/A
You can collect some of this information using our environment capture script:


https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
I have the installed version of tensorflow-GPU however it executes the code with CPU.

### Source code / logs
[object_detection_tutorial.zip](https://github.com/tensorflow/models/files/2011309/object_detection_tutorial.zip)

",magick2,None,2018-05-17T01:27:05Z,2018-05-18T23:08:16Z,,,,,,,
4263,"Using object_detection/eval.py to eval result ,but it's stuck","Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:ea6d6aabe5c121102a645d3f08cf819fa28d2a03
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**:binary
- **TensorFlow version (use command below)**:tensorflow-gpu-1.7.0
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:CUDA:9.0/cudnn:7.0.5
- **GPU model and memory**:3*1080Ti/11GB
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
when i used object_detection/eval.py to eval result, it was stuck at restoring parameters
![image](https://user-images.githubusercontent.com/10041362/40042339-93d666bc-5853-11e8-87ad-f7301a2b0703.png)


and result liked this permanently：
![image](https://user-images.githubusercontent.com/10041362/40042414-dc646b86-5853-11e8-93dc-813583e1c94f.png)


There are my parameters:
![image](https://user-images.githubusercontent.com/10041362/40042527-4d410d64-5854-11e8-80dc-960d35da8be8.png)

![image](https://user-images.githubusercontent.com/10041362/40042450-fdcfa204-5853-11e8-9eff-777c580974f7.png)

I tried different config,there were stuck.



### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",a819721810,None,2018-05-15T07:26:24Z,2019-04-11T10:16:13Z,,,,,,,
4259,Training bug in mobilenet v1 extractor for Faster r-cnn,"### System information
- **What is the top-level directory of the model you are using**: object_detection
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
custom kitti format dataset (good performance in Inception, Resnet extractor)
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**:
Source
- **TensorFlow version (use command below)**: 1.6.0
- **Python version**: 3.4
- **Bazel version (if compiling from source)**: No
- **GCC/Compiler version (if compiling from source)**: GCC 4.8.4
- **CUDA/cuDNN version**: 9, 7
- **GPU model and memory**: Tesla 40
- **Exact command to reproduce**:

### Describe the problem
It seems like training bug with Faster R-CNN Mobilenet.
I've been training Faster R-CNN with mobilenet feature extractor for 400k iteration, batch 8, learning rate 3e-03(mentioned in HuangMurphy_2017_Speed,accuracy trade-offs for modern convolutional object detectors). But it's mAP is ""zero"".  I'm using my own dataset and it's going well with InceptionV2, Resnet50, 101. mAP of InceptionV2, Resnet50, 101 is 0.7. So it's not about hyperparameter tuning problem.


### Source code / logs
here is loss of inception v2, which has good mAP.
![image](https://user-images.githubusercontent.com/39238559/40033921-76956e36-5835-11e8-966f-347359f9588d.png)

here is loss of mobilenet. Second stage loss is strangely low (loss is zero almost of time)
![image](https://user-images.githubusercontent.com/39238559/40033856-352ec6ae-5835-11e8-973e-44c2806cacea.png)

here is mAP of mobilenet. How can it be a zero?
![image](https://user-images.githubusercontent.com/39238559/40033951-b43a1142-5835-11e8-8166-c4315a83a17c.png)

here is my tensorboard distributions of mobilenet. Compared to Incepction V2, mobilenet has No change in second stage conv2d_12, conv2d_13 - moving_mean, moving_variance. I think it could be a clue of cause.
![image](https://user-images.githubusercontent.com/39238559/40034051-1937993e-5836-11e8-860c-e722bb71725b.png)

",yryun,b'stat:awaiting maintainer',2018-05-15T02:57:25Z,2020-02-07T18:45:28Z,,,,,,,
4245,Will a softmax with focal loss be implemented? ,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**: models/research/object_detection
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Trying to, see below
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: used pip install
- **TensorFlow version (use command below)**: 1.8.0
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**: 
- **GPU model and memory**: K80 with 12GB
- **Exact command to reproduce**: See below

Thanks for the awesome Object Detection API!

I wanted to be able to use the [focal loss](http://openaccess.thecvf.com/content_ICCV_2017/papers/Lin_Focal_Loss_for_ICCV_2017_paper.pdf) with a softmax classification loss so I can apply it to R-FCN and Faster-RCNN based models.

Will there ever be any implementation for this? I tried doing it myself within the `WeightedSoftmaxClassificationLoss` function in `losses.py` like below:
```python
def _compute_loss(self, prediction_tensor, target_tensor, weights):
    """"""Compute loss function.

    Args:
      prediction_tensor: A float tensor of shape [batch_size, num_anchors,
        num_classes] representing the predicted logits for each class
      target_tensor: A float tensor of shape [batch_size, num_anchors,
        num_classes] representing one-hot encoded classification targets
      weights: a float tensor of shape [batch_size, num_anchors]

    Returns:
      loss: a float tensor of shape [batch_size, num_anchors]
        representing the value of the loss function.
    """"""
    num_classes = prediction_tensor.get_shape().as_list()[-1]
    prediction_tensor = tf.divide(
        prediction_tensor, self._logit_scale, name='scale_logit')
    per_row_cross_ent = (tf.nn.softmax_cross_entropy_with_logits(
        labels=tf.reshape(target_tensor, [-1, num_classes]),
        logits=tf.reshape(prediction_tensor, [-1, num_classes])))

    ####################################################
    # FOCAL LOSS PART START
    ####################################################
    prediction_probabilities = tf.nn.softmax(prediction_tensor)
    p_t = ((target_tensor * prediction_probabilities) +
           ((1 - target_tensor) * (1 - prediction_probabilities)))

    modulating_factor = 1.0
    if self._gamma:
      modulating_factor = tf.pow(1.0 - p_t, self._gamma)
    alpha_weight_factor = 1.0
    if self._alpha is not None:
      alpha_weight_factor = (target_tensor * self._alpha +
                             (1 - target_tensor) * (1 - self._alpha))
    focal_cross_entropy_loss = (modulating_factor * alpha_weight_factor *
                                per_row_cross_ent)

    ####################################################
    # FOCAL LOSS PART END
    ####################################################
    return tf.reshape(focal_cross_entropy_loss, tf.shape(weights)) * weights
``` 

My idea was to follow the same style as the already implemented Sigmoid-based focal loss. But with TensorFlow, the shape of the tensor that `sigmoid_cross_entropy_with_logits` returns is different from that of `softmax_cross_entropy_with_logits`. It seems that the latter function computes a summation across the last dimension before the output, while the former does not. As a result, the additional factor of `alpha*(1-p_t)^gamma` can't be applied, since it is supposed to be done element wise on the `per_entry_cross_ent` tensor (before the summation across the last dimension).

I though of implemented a cross_entropy myself, but many TensorFlow people seem to recommend against it due to numerical instability and speed: https://github.com/tensorflow/tensorflow/issues/2462

Are there any work-arounds for this?

Thank you!

",GeorgeSeif,b'stat:awaiting model gardener',2018-05-11T20:29:26Z,2018-10-12T09:23:14Z,,,,,,,
4228,not available to use,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",adityaparida,None,2018-05-10T13:09:17Z,2018-05-14T17:51:35Z,,,,,,,
4224,Fix bugs in object detection docs,"According to code here:
https://github.com/tensorflow/models/blob/master/research/object_detection/meta_architectures/ssd_meta_arch.py#L780

The interface that DetectionModels should implement to load a checkpoint into the Tensorflow graph should be `restore_map` rather than `restore`.",xiaoyongzhu,b'cla: yes',2018-05-10T03:29:29Z,2019-12-03T07:08:32Z,,,,,,,
4215,object detection dataset_util.py potential bug,"Hi,

I have noticed that in the object detection repo, training data is not shuffled as expected. And in ```object_detection/utils/dataset_util.py``` I noticed that line 137 seems should be changed from the current ```records_dataset.shuffle(config.shuffle_buffer_size)``` to ```records_dataset = records_dataset.shuffle(config.shuffle_buffer_size)```. When I made the change locally, I see the shuffle to behave much better. Thanks.",lwyjc,b'stat:awaiting maintainer',2018-05-09T05:30:37Z,2018-10-31T21:04:14Z,,,,,,,
4205,Fixed Bug regarding tfrecord shuffling in object_detection,"In current implementation in `models/research/object_detection/utils/dataset_util.py` at `line 137` `records_dataset.shuffle(config.shuffle_buffer_size)` is not assigned to variable, and it should be `
records_dataset = records_dataset.shuffle(config.shuffle_buffer_size)`",vladpaunescu,b'cla: yes',2018-05-08T14:18:15Z,2018-05-15T04:00:43Z,,,,,,,
4191,Mismatch between checkpoint and model when I restored Nasnet,"There is no bug in the codes. The code is as below.
The length of var_list is 3117,while the length of variables_to_restore is 1547.
I don't know what causes the difference.
checkpoint  is nasnet-a_large downloaded from https://storage.googleapis.com/download.tensorflow.org/models/nasnet-a_large_04_10_2017.tar.gz

 
```
import tensorflow as tf
from tensorflow.contrib.slim.python.slim.nets import inception_resnet_v2
from tensorflow.contrib.framework.python.framework import checkpoint_utils
from tensorflow.contrib.slim.python.slim.nets.nasnet import nasnet

slim = tf.contrib.slim
checkpoint_file=""./model_weight_nasnet/model.ckpt""
model_dir=""./model_weight_nasnet/""
cnt=0

#checkpoint_file=tf.train.latest_checkpoint(""./model_weight/"")
var_list = checkpoint_utils.list_variables(checkpoint_file)
#
for v in var_list:
    print(""No %d:%s"" %(cnt,v))
    cnt+=1


NUM_CLASS=1001

image = tf.placeholder(tf.float32, shape=[331, 331, 3])


image_reshape = tf.reshape(image, [-1, 331, 331, 3])
with slim.arg_scope(nasnet.nasnet_large_arg_scope()):

    logits,_ = nasnet.build_nasnet_large(image_reshape, num_classes=NUM_CLASS, is_training=False)

    global_step = tf.Variable(0, name='global_step',dtype=tf.int64, trainable=False)

    variables_to_restore = slim.get_variables_to_restore()

    cnt = 0
    for i in variables_to_restore:
        print(""No %d:%s"" % (cnt, v))
        cnt+=1

    saver = tf.train.Saver(variables_to_restore)


    init_op = tf.initialize_all_variables()

variable_list=[]


saver2 = tf.train.Saver(tf.global_variables())

sess=tf.Session()
sess.run(init_op)
sess.run(variables_to_restore)

saver.restore(sess, checkpoint_file)

saver2.save(sess, model_dir + ""/nasnet_initial.ckpt"", global_step=0)



```
",fengsky401,b'stat:awaiting response',2018-05-07T10:00:10Z,2020-02-07T18:45:17Z,,,,,,,
4183,How do convert my own set of images to TFRecords? I have a similar directory structure like Flowers dataset.,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",fafz1234,None,2018-05-05T18:52:58Z,2018-05-07T15:10:41Z,,,,,,,
4177,tensorflow.python.framework.errors_impl.UnknownError: Failed to rename:,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
D:\GitRepro\UIUC\CS498AML\Week12\cifar10\part2a>
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
It is example code modified for our class assignment
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Windows 10 Pro 1709
- **TensorFlow installed from (source or binary)**:
Python Package install
- **TensorFlow version (use command below)**:
1.7.0
- **Bazel version (if compiling from source)**:  n/a
- **CUDA/cuDNN version**:
CUDA 8.0/cuDNN64_7 which v7.04 
- **GPU model and memory**:
2 GPUs GTX 1080ti with 11 GB for each
- **Exact command to reproduce**:
Traceback (most recent call last):
  File ""cifar10_train.py"", line 145, in <module>
    tf.app.run()
  File ""c:\users\john3\venv\lib\site-packages\tensorflow\python\platform\app.py"", line 126, in run
    _sys.exit(main(argv))
  File ""cifar10_train.py"", line 141, in main
    train()
  File ""cifar10_train.py"", line 133, in train
    mon_sess.run(train_op)
  File ""c:\users\john3\venv\lib\site-packages\tensorflow\python\training\monitored_session.py"", line 546, in run
    run_metadata=run_metadata)
  File ""c:\users\john3\venv\lib\site-packages\tensorflow\python\training\monitored_session.py"", line 1022, in run
    run_metadata=run_metadata)
  File ""c:\users\john3\venv\lib\site-packages\tensorflow\python\training\monitored_session.py"", line 1113, in run
    raise six.reraise(*original_exc_info)
  File ""c:\users\john3\venv\lib\site-packages\six.py"", line 693, in reraise
    raise value
  File ""c:\users\john3\venv\lib\site-packages\tensorflow\python\training\monitored_session.py"", line 1098, in run
    return self._sess.run(*args, **kwargs)
  File ""c:\users\john3\venv\lib\site-packages\tensorflow\python\training\monitored_session.py"", line 1178, in run
    run_metadata=run_metadata))
  File ""c:\users\john3\venv\lib\site-packages\tensorflow\python\training\basic_session_run_hooks.py"", line 458, in after_run
    self._save(run_context.session, global_step)
  File ""c:\users\john3\venv\lib\site-packages\tensorflow\python\training\basic_session_run_hooks.py"", line 474, in _save
    self._get_saver().save(session, self._save_path, global_step=step)
  File ""c:\users\john3\venv\lib\site-packages\tensorflow\python\training\saver.py"", line 1686, in save
    save_relative_paths=self._save_relative_paths)
  File ""c:\users\john3\venv\lib\site-packages\tensorflow\python\training\saver.py"", line 1041, in _update_checkpoint_state
    text_format.MessageToString(ckpt))
  File ""c:\users\john3\venv\lib\site-packages\tensorflow\python\lib\io\file_io.py"", line 431, in atomic_write_string_to_file
    rename(temp_pathname, filename, overwrite)
  File ""c:\users\john3\venv\lib\site-packages\tensorflow\python\lib\io\file_io.py"", line 410, in rename
    compat.as_bytes(oldname), compat.as_bytes(newname), overwrite, status)
  File ""c:\users\john3\venv\lib\site-packages\tensorflow\python\framework\errors_impl.py"", line 516, in __exit__
    c_api.TF_GetCode(self.status.status))
tensorflow.python.framework.errors_impl.UnknownError: Failed to rename: D:/GitRepro/UIUC/CS498AML/Week12/cifar10/data/cifar10_train_part2a\checkpoint.tmp7d34a7365c60428f8bb597559422ebcf to: D:/GitRepro/UIUC/CS498AML/Week12/cifar10/data/cifar10_train_part2a\checkpoint : Access is denied.
; Input/output error

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request. 
I have been training model updates all day long with runs about 25 to 45 minutes.  Several times it has generated this same error each time at different points.  In the stack trace above it was the 2nd time in a row on the same model which is running through 65k steps.  I have had runs complete with no issue even up to 134k steps. While the training  is running I have it mapped to 1 GPU and have cifar10_eval.py running and mapped to another GPU.  While those are running I also have TensorBoard running so that I see the progress in the scalar graphs.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.

[part2A.zip](https://github.com/tensorflow/models/files/1976273/part2A.zip)


",PythonWillRule,None,2018-05-05T03:02:18Z,2020-07-22T08:32:29Z,,,,,,,
4169,AttributeError: module 'tensorflow.contrib.data' has no attribute 'TFRecordDataset',"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:the newest model
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**:binary
- **TensorFlow version (use command below)**:1.70
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:CUDA:9.0   cudnn:7.0.5
- **GPU model and memory**:1080Ti and 11GB
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
when i run /models/tutorials/image/cifar10_estimator/cifar10_main.py ,it show some errors:

![image](https://user-images.githubusercontent.com/10041362/39617855-ddd5701c-4fb3-11e8-8462-fe2af54e0395.png)


### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",a819721810,b'stat:awaiting maintainer',2018-05-04T07:57:52Z,2018-10-31T21:02:45Z,,,,,,,
4164,Object detection Slow processing video,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
Object detection
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
Yes, just to insert a video instead of using the webcam
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Windows 10 64 bits (Last version)
- **TensorFlow installed from (source or binary)**:
Binary
- **TensorFlow version (use command below)**:
v1.8.0-0-g93bc2e2072' 1.8.0
- **Bazel version (if compiling from source)**:
N/A
- **CUDA/cuDNN version**:
CUDA: cuda_9.0.176
cuDNN: cudnn-9.0
- **GPU model and memory**:
MSI Geforce GTX 1070 8gb
- **Exact command to reproduce**:
N/A
You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
I'm running the sample code that comes with the Object Detection model, I made a modification to read a video instead of a webcam the problem is that the window opens and plays the video but in extreme slow (really is very slow , does not exceed 1 fps I think) and when you run it does not use any PC resources (I clarify it in case they ask if the PC saturates and that's why the video is wrong)

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
The code I use is in a .zip file
PS: I'm sorry for my English


[object_detection_tutorial.zip](https://github.com/tensorflow/models/files/1972843/object_detection_tutorial.zip)
",magick2,None,2018-05-03T22:27:50Z,2020-02-07T18:45:15Z,,,,,,,
4157,Internal changes to object detection.,"195147413  by Zhichao Lu:

    SSDLite config for mobilenet v2.

--
194883585  by Zhichao Lu:

    Simplify TPU compatible nearest neighbor upsampling using reshape and broadcasting.

--
194851009  by Zhichao Lu:

    Include ava v2.1 detection models in model zoo.

--
194510347  by Zhichao Lu:

    Contains implementation of Visual Relations Detection evaluation metric
    (evaluation metric itself).

--
194292198  by Zhichao Lu:

    Add option to evaluate any checkpoint (without requiring write access to that directory and overwriting any existing logs there).

--
194122420  by Zhichao Lu:

    num_gt_boxes_per_image and num_det_boxes_per_image value incorrect.
    Should be not the expand dim.

--
193974479  by Zhichao Lu:

    Fixing a bug in the coco evaluator.

--
193959861  by Zhichao Lu:

    Read the default batch size from config file.

--
193737238  by Zhichao Lu:

    Fix data augmentation functions.

--
193576336  by Zhichao Lu:

    Add support for training keypoints.

--
193409179  by Zhichao Lu:

    Update protobuf requirements to 3+ in installation docs.

--
193382651  by Zhichao Lu:

    Updating coco evaluation metrics to allow for a batch of image info, rather than a single image.

--
193244778  by Zhichao Lu:

    Remove deprecated batch_norm_trainable field from ssd mobilenet v2 config

--
193228972  by Zhichao Lu:

    Make sure the final layers are also resized proportional to conv_depth_ratio.

--
193204364  by Zhichao Lu:

    Do not add batch norm parameters to final conv2d ops that predict boxes encodings and class scores in weight shared conv box predictor.

    This allows us to set proper bias and force initial predictions to be background when using focal loss.

--
193137342  by Zhichao Lu:

    Add a util function to visualize value histogram as a tf.summary.image.

--
193119411  by Zhichao Lu:

    Adding support for reading in logits as groundtruth labels and applying an optional temperature (scaling) before softmax in support of distillation.

--
193087707  by Zhichao Lu:

    Post-process now works again in train mode.

--
193067658  by Zhichao Lu:

    fix flakiness in testSSDRandomCropWithMultiClassScores due to randomness.

--
192922089  by Zhichao Lu:

    Add option to set dropout for classification net in weight shared box predictor.

--
192850747  by Zhichao Lu:

    Remove inaccurate caveat from proto file.

--
192837477  by Zhichao Lu:

    Extend to accept different ratios of conv channels.

--
192813444  by Zhichao Lu:

    Adding option for one_box_for_all_classes to the box_predictor

--
192624207  by Zhichao Lu:

    Update to trainer to allow for reading multiclass scores

--
192583425  by Zhichao Lu:

    Contains implementation of Visual Relations Detection evaluation metric (per
    image evaluation).

--
192529600  by Zhichao Lu:

    Modify the ssd meta arch to allow the option of not adding an implicit background class.

--
192512429  by Zhichao Lu:

    Refactor model_tpu_main.py files and move continuous eval loop into model_lib.py

--
192494267  by Zhichao Lu:

    Update create_pascal_tf_record.py and create_pet_tf_record.py

--
192485456  by Zhichao Lu:

    Enforcing that all eval metric ops have valid python strings.

--
192472546  by Zhichao Lu:

    Set regularize_depthwise to true in mobilenet_v1_argscope.

--
192421843  by Zhichao Lu:

    Refactoring of Mask-RCNN to put all mask prediction code in third stage.

--
192320460  by Zhichao Lu:

    Returning eval_on_train_input_fn from create_estimator_and_inputs(), rather than using train_input_fn in EVAL mode (which will still have data augmentation).

--
192226678  by Zhichao Lu:

    Access TPUEstimator and CrossShardOptimizer from tf namesspace.

--
192195514  by Zhichao Lu:

    Fix test that was flaky due to randomness

--
192166224  by Zhichao Lu:

    Minor fixes to match git repo.

--
192147130  by Zhichao Lu:

    use shape utils for assertion in feature extractor.

--
192132440  by Zhichao Lu:

    Class agnostic masks for mask_rcnn

--
192006190  by Zhichao Lu:

    Add learning rate summary in EVAL mode in model.py

--
192004845  by Zhichao Lu:

    Migrating away from Experiment class, as it is now deprecated. Also, refactoring into a separate model library and binaries.

--
191957195  by Zhichao Lu:

    Add classification_loss and localiztion_loss metrics for TPU jobs.

--
191932855  by Zhichao Lu:

    Add an option to skip the last striding in mobilenet. The modified network has nominal output stride 16 instead of 32.

--
191787921  by Zhichao Lu:

    Add option to override base feature extractor hyperparams in SSD models. This would allow us to use the same set of hyperparams for the complete feature extractor (base + new layers) if desired.

--
191743097  by Zhichao Lu:

    Adding an attribute to SSD model to indicate which fields in prediction dictionary have a batch dimension. This will be useful for future video models.

--
191668425  by Zhichao Lu:

    Internal change.

--
191649512  by Zhichao Lu:

    Introduce two parameters in ssd.proto - freeze_batchnorm, inplace_batchnorm_update - and set up slim arg_scopes in ssd_meta_arch.py such that applies it to all batchnorm ops in the predict() method.

    This centralizes the control of freezing and doing inplace batchnorm updates.

--
191620303  by Zhichao Lu:

    Modifications to the preprocessor to support multiclass scores

--

PiperOrigin-RevId: 195147413",pkulzc,b'cla: yes',2018-05-03T05:28:14Z,2018-05-03T20:30:49Z,,,,,,,
4154,"line 127 - ""_"" used as local variable","line 127 - ""_"" used as local variable
Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",samimmolla,b'stat:awaiting response',2018-05-02T21:41:59Z,2018-11-09T22:02:08Z,,,,,,,
4146,A bug when running faster_rcnn_inception_resnet_v2_atrous_oid!,"Under Tensorflow 1.5.0, when loading the model named "" faster_rcnn_inception_resnet_v2_atrous_oid_2018_01_28"" and testing it, there are some errors. 
See the following trackbacks:
`InvalidArgumentError (see above for traceback): NodeDef mentions attr 'dilations' not in Op<name=Conv2D; signature=input:T, filter:T -> output:T; attr=T:type,allowed=[DT_HALF, DT_FLOAT]; attr=strides:list(int); attr=use_cudnn_on_gpu:bool,default=true; attr=padding:string,allowed=[""SAME"", ""VALID""]; attr=data_format:string,default=""NHWC"",allowed=[""NHWC"", ""NCHW""]>; NodeDef: FirstStageFeatureExtractor/InceptionResnetV2/InceptionResnetV2/Conv2d_1a_3x3/Conv2D = Conv2D[T=DT_FLOAT, data_format=""NHWC"", dilations=[1, 1, 1, 1], padding=""SAME"", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](Preprocessor/sub, FirstStageFeatureExtractor/InceptionResnetV2/Conv2d_1a_3x3/weights/read/_711__cf__717). (Check whether your GraphDef-interpreting binary is up to date with your GraphDef-generating binary.).
	 [[Node: FirstStageFeatureExtractor/InceptionResnetV2/InceptionResnetV2/Conv2d_1a_3x3/Conv2D = Conv2D[T=DT_FLOAT, data_format=""NHWC"", dilations=[1, 1, 1, 1], padding=""SAME"", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](Preprocessor/sub, FirstStageFeatureExtractor/InceptionResnetV2/Conv2d_1a_3x3/weights/read/_711__cf__717)]]`

1.What is the top-level directory of the model you are using?
A: models-master / research / object_detection
2.Have I written custom code?
A: No, I simply copy the code from object_detection_tutorial.ipynb into a .py file 
And change the line into `MODEL_NAME = 'faster_rcnn_inception_resnet_v2_atrous_oid_2018_01_28'`,
since I tried to use faster rcnn trained on oid.
3.OS Platform and Distribution
A: Windows 10 64bit
4.TensorFlow installed from
A: pip
5.TensroFlow version
A:1.5.0-dev20171120
6. Bazel version
A:N/A
7. CUDA/cuDNN version
A:CUDA 8.0,  cuDNN6.0
8.GPU model and memory
A: Nvidia Geforce GTX 960M, with 4GB memory
9 Exact command to reproduce
A: python object_detection_tutorial.py

Also, Using the same code, change the line`MODEL_NAME = 'faster_rcnn_inception_resnet_v2_atrous_oid_2018_01_28` into other available model name, it runs successfully. And only using `faster_rcnn_inception_resnet_v2_atrous_oid_2018_01_28`, it throws errors.",YJHMITWEB,b'stat:awaiting response',2018-05-02T13:21:03Z,2018-12-05T21:43:40Z,,,,,,,
4126,fix import errors and type error in numpy for the PATE implementation,"This PR fixes two minor bugs related to PATE:

* missing init files creating import errors
* type error in a PATE script most likely due to an update to numpy",npapernot,b'cla: yes',2018-04-29T22:22:02Z,2018-04-29T22:35:34Z,,,,,,,
4123,Increase minimum TF version for DEFINE_enum and rename variable mappings for change to RNN variable names.,Thanks to Yaoming Zhu for pointing out the bug.,a-dai,b'cla: yes',2018-04-29T09:08:58Z,2018-04-30T05:07:07Z,,,,,,,
4109,[bugs] Object Detection Protobuf Compilation Failed!,"**System information**

- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04
- TensorFlow installed from (source or binary): Source
- TensorFlow version (use command below): 1.8.0rc0
- Python version:2.7.12
- Bazel version (if compiling from source): 0.12.0
- CUDA/cuDNN version: cuda-9.0/7.0
- GPU model and memory: GeForce GTX 1080/8105MiB
- Exact command to reproduce: N/A
- Phone: N/A

**Describe the problem**
I git the latest version of the tensorflow/models,  when compiling the Protobuf librarie [Protobuf Compilation](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/installation.md),
 I encounter the following errors:
```
# From tensorflow/models/research/
$ protoc object_detection/protos/*.proto --python_out=.
object_detection/protos/ssd.proto:87:3: Expected ""required"", ""optional"", or ""repeated"".
object_detection/protos/ssd.proto:87:12: Expected field name.
object_detection/protos/model.proto: Import ""object_detection/protos/ssd.proto"" was not found or had errors.
object_detection/protos/model.proto:12:5: ""Ssd"" is not defined.
```


",WenguoLi,None,2018-04-27T11:20:05Z,2018-05-02T00:40:44Z,,,,,,,
4095,[Object detection] Feature Request: Running the API  when you have access to limited GPU,"### System information
- **What is the top-level directory of the model you are using**: object_detection
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: conda
- **TensorFlow version (use command below)**: 
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

This is not a bug but a feature request. The official documentation recommends starting both the training and evaluation scripts in parallel to monitor the training and model convergance. This however works properly only when you have 2 or more GPUs. If you have only one GPU eg a GTX 1060 or 1080, The above recommended way will create horrible drag in training. This is because, when the evaluation script runs it will try to hog the GPU thereby creating a training bottleneck. Faster RCNN with considerably large image sizes example (1500 x 1500 pixels)  are prone to this problem .There are two ways to go about this problem: 

1. Run training in GPU and run evaluation in CPU. Even this solution does not guarantee that your training will work without freezing if you have RAM less than 16GB or when you are using a heavy model

2. Run only training script for specific iterations and then run the evaluation script, to check if the model has converged. I know this is a round about way but, I couldn't think of any better solution. But the evaluation script will run the evaluation on the recent checkpoint and not all the checkpoints. 

I have added both of these features in this pull request #4038. ",Abhijit-2592,b'stat:awaiting maintainer',2018-04-26T04:07:11Z,2020-02-07T18:45:13Z,,,,,,,
4093,Check whether your GraphDef-interpreting binary is up to date with your GraphDef-generating binary,"

### System information
- **What is the top-level directory of the model you are using**:
object_detection

- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: 
Follow this tutorial
https://pythonprogramming.net/video-tensorflow-object-detection-api-tutorial/
to write a script to
1. load faster_rcnn_resnet101_kitti or ssd_inception_v2_coco
2. process the video with the loaded pre-trained model.

- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Linux Ubuntu 14.04

- **TensorFlow installed from (source or binary)**:
binary

- **TensorFlow version (use command below)**:
1.4.1

- **Bazel version (if compiling from source)**:
X

- **CUDA/cuDNN version**:
CUDA: release 8.0, V8.0.61
cuDNN: CUDNN_MAJOR 7

- **GPU model and memory**:
GeForce GTX 1050 Ti, 4G memory

- **Exact command to reproduce**:

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

1. `tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid`: load frozen_inference_graph.ph file.
2. `sess = tf.Session(graph=detection_graph)`: initalize session.
3. `sess.run`: get error messages.
The following error message only appears when loading faster_rcnn_resnet101_kitti.
ssd_inception_v2_coco works successfully.


### Source code / logs
Source code: Please refer to the link above.

Error:
[error.txt](https://github.com/tensorflow/models/files/1949081/error.txt)

Thank you.
",willSapgreen,None,2018-04-25T22:51:21Z,2020-08-08T02:27:04Z,,,,,,,
4089,[deeplab] Unable to Evaluate on ADE20k,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:  ?
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: The stock example is not **explicitly** available
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: 1.7.0
- **Bazel version (if compiling from source)**:  0.11
- **CUDA/cuDNN version**: 7.1.3
- **GPU model and memory**: NVIDIA Titan V 12GB 
- **Exact command to reproduce**: 

```
python deeplab/eval.py \
    --logtostderr \
    --eval_split=""val"" \
    --model_variant=""xception_65"" \
    --atrous_rates=6 \
    --atrous_rates=12 \
    --atrous_rates=18 \
    --output_stride=16 \
    --decoder_output_stride=4 \
    --eval_crop_size=513 \
    --eval_crop_size=513 \
    --dataset=""ade20k"" \
    --checkpoint_dir='deeplab/datasets/ADE20K/exp/train_on_train_set/train' \
    --eval_logdir='deeplab/datasets/ADE20K/exp/train_on_train_set/eval' \
    --dataset_dir='deeplab/datasets/ADE20K/tfrecord' 
```


You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

_It seems that the script is not correctly cropping the images before execution._ 


### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.

`2018-04-25 17:26:15.635672: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1344] Found device 0 with properties: 
name: TITAN V major: 7 minor: 0 memoryClockRate(GHz): 1.455
pciBusID: 0000:09:00.0
totalMemory: 11.78GiB freeMemory: 11.36GiB
2018-04-25 17:26:15.635730: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1423] Adding visible gpu devices: 0
2018-04-25 17:26:16.432618: I tensorflow/core/common_runtime/gpu/gpu_device.cc:911] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-04-25 17:26:16.432667: I tensorflow/core/common_runtime/gpu/gpu_device.cc:917]      0 
2018-04-25 17:26:16.432678: I tensorflow/core/common_runtime/gpu/gpu_device.cc:930] 0:   N 
2018-04-25 17:26:16.433049: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10989 MB memory) -> physical GPU (device: 0, name: TITAN V, pci bus id: 0000:09:00.0, compute capability: 7.0)
INFO:tensorflow:Restoring parameters from deeplab/datasets/ADE20K/exp/train_on_train_set/train/model.ckpt-50000
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
2018-04-25 17:26:19.373963: W tensorflow/core/framework/op_kernel.cc:1273] OP_REQUIRES failed at queue_ops.cc:105 : Invalid argument: Shape mismatch in tuple component 1. Expected [513,513,3], got [513,683,3]
INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.InvalidArgumentError'>, Shape mismatch in tuple component 1. Expected [513,513,3], got [513,683,3]
         [[Node: batch/padding_fifo_queue_enqueue = QueueEnqueueV2[Tcomponents=[DT_INT64, DT_FLOAT, DT_STRING, DT_INT32, DT_UINT8, DT_INT64], timeout_ms=-1, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](batch/padding_fifo_queue, ParseSingleExample/ParseSingleExample:3, add_2/_4681, ParseSingleExample/ParseSingleExample:1, add_3/_4683, batch/packed, ParseSingleExample/ParseSingleExample:6)]]
INFO:tensorflow:Starting evaluation at 2018-04-25-17:26:20
INFO:tensorflow:Finished evaluation at 2018-04-25-17:26:20
miou_1.0[0]
Traceback (most recent call last):
  File ""deeplab/eval.py"", line 176, in <module>
    tf.app.run()
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/platform/app.py"", line 126, in run
    _sys.exit(main(argv))
  File ""deeplab/eval.py"", line 169, in main
    eval_interval_secs=FLAGS.eval_interval_secs)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/slim/python/slim/evaluation.py"", line 301, in evaluation_loop
    timeout=timeout)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/training/python/training/evaluation.py"", line 455, in evaluate_repeatedly
    '%Y-%m-%d-%H:%M:%S', time.gmtime()))
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py"", line 658, in __exit__
    self._close_internal(exception_type)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py"", line 695, in _close_internal
    self._sess.close()
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py"", line 943, in close
    self._sess.close()
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py"", line 1087, in close
    ignore_live_threads=True)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/coordinator.py"", line 389, in join
    six.reraise(*self._exc_info_to_raise)
  File ""/usr/local/lib/python3.5/dist-packages/six.py"", line 692, in reraise
    raise value.with_traceback(tb)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/queue_runner_impl.py"", line 252, in _run
    enqueue_callable()
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py"", line 1249, in _single_operation_run
    self._call_tf_sessionrun(None, {}, [], target_list, None)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py"", line 1420, in _call_tf_sessionrun
    status, run_metadata)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/errors_impl.py"", line 516, in __exit__
    c_api.TF_GetCode(self.status.status))
tensorflow.python.framework.errors_impl.InvalidArgumentError: Shape mismatch in tuple component 1. Expected [513,513,3], got [513,683,3]
         [[Node: batch/padding_fifo_queue_enqueue = QueueEnqueueV2[Tcomponents=[DT_INT64, DT_FLOAT, DT_STRING, DT_INT32, DT_UINT8, DT_INT64], timeout_ms=-1, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](batch/padding_fifo_queue, ParseSingleExample/ParseSingleExample:3, add_2/_4681, ParseSingleExample/ParseSingleExample:1, add_3/_4683, batch/packed, ParseSingleExample/ParseSingleExample:6)]]`
",pedropgusmao,b'stat:awaiting model gardener',2018-04-25T17:29:14Z,2018-11-03T00:52:52Z,,,,,,,
4086,ImageNet Data processing,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:

- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Redhat
- **TensorFlow installed from (source or binary)**:
binary
- **TensorFlow version (use command below)**:
1.7
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
9/6.6
- **GPU model and memory**:
K20 / 5.5 GB
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.
I am trying to prepare the imagenet data for the tf_cnn_benchmarks. I am using the""download_and_preprocess_imagenet.sh"" script . I worked but when it prepare for TFRECORD format I got processing errors with tf.



### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.

./download_and_preprocess_newimagenet.sh /home/amalik/NEWIMAGENETDATA/
Organizing the validation data into sub-directories.
Extracting bounding box information from XML.
Finished downloading and preprocessing the ImageNet data.
Saving results to /home/amalik/NEWIMAGENETDATA
Successfully read 615299 bounding boxes across 544546 images.
Determining list of input files and labels from /home/amalik/NEWIMAGENETDATA/raw-data/validation/.
Finished finding files in 100 of 1000 classes.
Finished finding files in 200 of 1000 classes.
Finished finding files in 300 of 1000 classes.
Finished finding files in 400 of 1000 classes.
Finished finding files in 500 of 1000 classes.
Finished finding files in 600 of 1000 classes.
Finished finding files in 700 of 1000 classes.
Finished finding files in 800 of 1000 classes.
Finished finding files in 900 of 1000 classes.
Finished finding files in 1000 of 1000 classes.
Found 50000 JPEG files across 1000 labels inside /home/amalik/NEWIMAGENETDATA/raw-data/validation/.
Found 0 images with bboxes out of 50000 images
Launching 8 threads for spacings: [[0, 6250], [6250, 12500], [12500, 18750], [18750, 25000], [25000, 31250], [31250, 37500], [37500, 43750], [43750, 50000]]
2018-04-25 11:32:43.064265: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1344] Found device 0 with properties: 
name: Tesla K20Xm major: 3 minor: 5 memoryClockRate(GHz): 0.732
pciBusID: 0000:08:00.0
totalMemory: 5.57GiB freeMemory: 5.49GiB
2018-04-25 11:32:43.064342: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1423] Adding visible gpu devices: 0
2018-04-25 11:32:45.273683: I tensorflow/core/common_runtime/gpu/gpu_device.cc:911] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-04-25 11:32:45.273756: I tensorflow/core/common_runtime/gpu/gpu_device.cc:917]      0 
2018-04-25 11:32:45.273775: I tensorflow/core/common_runtime/gpu/gpu_device.cc:930] 0:   N 
2018-04-25 11:32:45.274055: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 5285 MB memory) -> physical GPU (device: 0, name: Tesla K20Xm, pci bus id: 0000:08:00.0, compute capability: 3.5)
Exception in thread Thread-1:
Traceback (most recent call last):
  File ""/home/amalik/tenENV/lib/python2.7/threading.py"", line 801, in __bootstrap_inner
    self.run()
  File ""/home/amalik/tenENV/lib/python2.7/threading.py"", line 754, in run
    self.__target(*self.__args, **self.__kwargs)
  File ""/home/amalik/DATA/models/research/inception/inception/data/build_imagenet_data.py"", line 395, in _process_image_files_batch
    height, width)
  File ""/home/amalik/DATA/models/research/inception/inception/data/build_imagenet_data.py"", line 214, in _convert_to_example
    'image/colorspace': _bytes_feature(colorspace),
  File ""/home/amalik/DATA/models/research/inception/inception/data/build_imagenet_data.py"", line 175, in _bytes_feature
    value = six.binary_type(value, encoding='utf-8')
TypeError: str() takes at most 1 argument (2 given)

Exception in thread Thread-6:
Traceback (most recent call last):
  File ""/home/amalik/tenENV/lib/python2.7/threading.py"", line 801, in __bootstrap_inner
    self.run()
  File ""/home/amalik/tenENV/lib/python2.7/threading.py"", line 754, in run
    self.__target(*self.__args, **self.__kwargs)
  File ""/home/amalik/DATA/models/research/inception/inception/data/build_imagenet_data.py"", line 395, in _process_image_files_batch
    height, width)
  File ""/home/amalik/DATA/models/research/inception/inception/data/build_imagenet_data.py"", line 214, in _convert_to_example
    'image/colorspace': _bytes_feature(colorspace),
  File ""/home/amalik/DATA/models/research/inception/inception/data/build_imagenet_data.py"", line 175, in _bytes_feature
    value = six.binary_type(value, encoding='utf-8')
TypeError: str() takes at most 1 argument (2 given)
Exception in thread Thread-7:
Traceback (most recent call last):
  File ""/home/amalik/tenENV/lib/python2.7/threading.py"", line 801, in __bootstrap_inner
    self.run()
  File ""/home/amalik/tenENV/lib/python2.7/threading.py"", line 754, in run
    self.__target(*self.__args, **self.__kwargs)
  File ""/home/amalik/DATA/models/research/inception/inception/data/build_imagenet_data.py"", line 395, in _process_image_files_batch
    height, width)
  File ""/home/amalik/DATA/models/research/inception/inception/data/build_imagenet_data.py"", line 214, in _convert_to_example
    'image/colorspace': _bytes_feature(colorspace),
  File ""/home/amalik/DATA/models/research/inception/inception/data/build_imagenet_data.py"", line 175, in _bytes_feature
    value = six.binary_type(value, encoding='utf-8')
TypeError: str() takes at most 1 argument (2 given)

Exception in thread Thread-5:
Traceback (most recent call last):
  File ""/home/amalik/tenENV/lib/python2.7/threading.py"", line 801, in __bootstrap_inner
    self.run()
  File ""/home/amalik/tenENV/lib/python2.7/threading.py"", line 754, in run
    self.__target(*self.__args, **self.__kwargs)
  File ""/home/amalik/DATA/models/research/inception/inception/data/build_imagenet_data.py"", line 395, in _process_image_files_batch
    height, width)
  File ""/home/amalik/DATA/models/research/inception/inception/data/build_imagenet_data.py"", line 214, in _convert_to_example
    'image/colorspace': _bytes_feature(colorspace),
  File ""/home/amalik/DATA/models/research/inception/inception/data/build_imagenet_data.py"", line 175, in _bytes_feature
    value = six.binary_type(value, encoding='utf-8')
TypeError: str() takes at most 1 argument (2 given)


Exception in thread Thread-2:
Traceback (most recent call last):
  File ""/home/amalik/tenENV/lib/python2.7/threading.py"", line 801, in __bootstrap_inner
    self.run()
  File ""/home/amalik/tenENV/lib/python2.7/threading.py"", line 754, in run
    self.__target(*self.__args, **self.__kwargs)
  File ""/home/amalik/DATA/models/research/inception/inception/data/build_imagenet_data.py"", line 395, in _process_image_files_batch
    height, width)
  File ""/home/amalik/DATA/models/research/inception/inception/data/build_imagenet_data.py"", line 214, in _convert_to_example
    'image/colorspace': _bytes_feature(colorspace),
  File ""/home/amalik/DATA/models/research/inception/inception/data/build_imagenet_data.py"", line 175, in _bytes_feature
    value = six.binary_type(value, encoding='utf-8')
TypeError: str() takes at most 1 argument (2 given)
Exception in thread Thread-3:
Traceback (most recent call last):
  File ""/home/amalik/tenENV/lib/python2.7/threading.py"", line 801, in __bootstrap_inner
    self.run()
  File ""/home/amalik/tenENV/lib/python2.7/threading.py"", line 754, in run
    self.__target(*self.__args, **self.__kwargs)
  File ""/home/amalik/DATA/models/research/inception/inception/data/build_imagenet_data.py"", line 395, in _process_image_files_batch
    height, width)
  File ""/home/amalik/DATA/models/research/inception/inception/data/build_imagenet_data.py"", line 214, in _convert_to_example
    'image/colorspace': _bytes_feature(colorspace),
  File ""/home/amalik/DATA/models/research/inception/inception/data/build_imagenet_data.py"", line 175, in _bytes_feature
    value = six.binary_type(value, encoding='utf-8')
TypeError: str() takes at most 1 argument (2 given)

Exception in thread Thread-4:
Traceback (most recent call last):
  File ""/home/amalik/tenENV/lib/python2.7/threading.py"", line 801, in __bootstrap_inner
    self.run()
  File ""/home/amalik/tenENV/lib/python2.7/threading.py"", line 754, in run
    self.__target(*self.__args, **self.__kwargs)
  File ""/home/amalik/DATA/models/research/inception/inception/data/build_imagenet_data.py"", line 395, in _process_image_files_batch
    height, width)
  File ""/home/amalik/DATA/models/research/inception/inception/data/build_imagenet_data.py"", line 214, in _convert_to_example
    'image/colorspace': _bytes_feature(colorspace),
  File ""/home/amalik/DATA/models/research/inception/inception/data/build_imagenet_data.py"", line 175, in _bytes_feature
    value = six.binary_type(value, encoding='utf-8')
TypeError: str() takes at most 1 argument (2 given)


Exception in thread Thread-8:
Traceback (most recent call last):
  File ""/home/amalik/tenENV/lib/python2.7/threading.py"", line 801, in __bootstrap_inner
    self.run()
  File ""/home/amalik/tenENV/lib/python2.7/threading.py"", line 754, in run
    self.__target(*self.__args, **self.__kwargs)
  File ""/home/amalik/DATA/models/research/inception/inception/data/build_imagenet_data.py"", line 395, in _process_image_files_batch
    height, width)
  File ""/home/amalik/DATA/models/research/inception/inception/data/build_imagenet_data.py"", line 214, in _convert_to_example
    'image/colorspace': _bytes_feature(colorspace),
  File ""/home/amalik/DATA/models/research/inception/inception/data/build_imagenet_data.py"", line 175, in _bytes_feature
    value = six.binary_type(value, encoding='utf-8')
TypeError: str() takes at most 1 argument (2 given)

2018-04-25 11:32:46.426148: Finished writing all 50000 images in data set.
Determining list of input files and labels from /home/amalik/NEWIMAGENETDATA/raw-data/train/.
Finished finding files in 100 of 1000 classes.
Finished finding files in 200 of 1000 classes.
Finished finding files in 300 of 1000 classes.
Finished finding files in 400 of 1000 classes.
Finished finding files in 500 of 1000 classes.
Finished finding files in 600 of 1000 classes.
Finished finding files in 700 of 1000 classes.
Finished finding files in 800 of 1000 classes.
Finished finding files in 900 of 1000 classes.
Finished finding files in 1000 of 1000 classes.
Found 1281167 JPEG files across 1000 labels inside /home/amalik/NEWIMAGENETDATA/raw-data/train/.
Found 544546 images with bboxes out of 1281167 images
Launching 8 threads for spacings: [[0, 160145], [160145, 320291], [320291, 480437], [480437, 640583], [640583, 800729], [800729, 960875], [960875, 1121021], [1121021, 1281167]]
2018-04-25 11:34:48.594990: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1423] Adding visible gpu devices: 0
2018-04-25 11:34:48.595083: I tensorflow/core/common_runtime/gpu/gpu_device.cc:911] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-04-25 11:34:48.595103: I tensorflow/core/common_runtime/gpu/gpu_device.cc:917]      0 
2018-04-25 11:34:48.595116: I tensorflow/core/common_runtime/gpu/gpu_device.cc:930] 0:   N 
2018-04-25 11:34:48.595422: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 5285 MB memory) -> physical GPU (device: 0, name: Tesla K20Xm, pci bus id: 0000:08:00.0, compute capability: 3.5)
Exception in thread Thread-13:
Traceback (most recent call last):
  File ""/home/amalik/tenENV/lib/python2.7/threading.py"", line 801, in __bootstrap_inner
    self.run()
  File ""/home/amalik/tenENV/lib/python2.7/threading.py"", line 754, in run
    self.__target(*self.__args, **self.__kwargs)
  File ""/home/amalik/DATA/models/research/inception/inception/data/build_imagenet_data.py"", line 395, in _process_image_files_batch
    height, width)
  File ""/home/amalik/DATA/models/research/inception/inception/data/build_imagenet_data.py"", line 214, in _convert_to_example
    'image/colorspace': _bytes_feature(colorspace),
  File ""/home/amalik/DATA/models/research/inception/inception/data/build_imagenet_data.py"", line 175, in _bytes_feature
    value = six.binary_type(value, encoding='utf-8')
TypeError: str() takes at most 1 argument (2 given)
Exception in thread Thread-12:
Traceback (most recent call last):
  File ""/home/amalik/tenENV/lib/python2.7/threading.py"", line 801, in __bootstrap_inner
    self.run()
  File ""/home/amalik/tenENV/lib/python2.7/threading.py"", line 754, in run
    self.__target(*self.__args, **self.__kwargs)
  File ""/home/amalik/DATA/models/research/inception/inception/data/build_imagenet_data.py"", line 395, in _process_image_files_batch
    height, width)
  File ""/home/amalik/DATA/models/research/inception/inception/data/build_imagenet_data.py"", line 214, in _convert_to_example
    'image/colorspace': _bytes_feature(colorspace),
  File ""/home/amalik/DATA/models/research/inception/inception/data/build_imagenet_data.py"", line 175, in _bytes_feature
    value = six.binary_type(value, encoding='utf-8')
TypeError: str() takes at most 1 argument (2 given)


Exception in thread Thread-14:
Traceback (most recent call last):
  File ""/home/amalik/tenENV/lib/python2.7/threading.py"", line 801, in __bootstrap_inner
    self.run()
  File ""/home/amalik/tenENV/lib/python2.7/threading.py"", line 754, in run
    self.__target(*self.__args, **self.__kwargs)
  File ""/home/amalik/DATA/models/research/inception/inception/data/build_imagenet_data.py"", line 395, in _process_image_files_batch
    height, width)
  File ""/home/amalik/DATA/models/research/inception/inception/data/build_imagenet_data.py"", line 214, in _convert_to_example
    'image/colorspace': _bytes_feature(colorspace),
  File ""/home/amalik/DATA/models/research/inception/inception/data/build_imagenet_data.py"", line 175, in _bytes_feature
    value = six.binary_type(value, encoding='utf-8')
TypeError: str() takes at most 1 argument (2 given)

Exception in thread Thread-11:
Traceback (most recent call last):
  File ""/home/amalik/tenENV/lib/python2.7/threading.py"", line 801, in __bootstrap_inner
    self.run()
  File ""/home/amalik/tenENV/lib/python2.7/threading.py"", line 754, in run
    self.__target(*self.__args, **self.__kwargs)
  File ""/home/amalik/DATA/models/research/inception/inception/data/build_imagenet_data.py"", line 395, in _process_image_files_batch
    height, width)
  File ""/home/amalik/DATA/models/research/inception/inception/data/build_imagenet_data.py"", line 214, in _convert_to_example
    'image/colorspace': _bytes_feature(colorspace),
  File ""/home/amalik/DATA/models/research/inception/inception/data/build_imagenet_data.py"", line 175, in _bytes_feature
    value = six.binary_type(value, encoding='utf-8')
TypeError: str() takes at most 1 argument (2 given)
Exception in thread Thread-10:
Traceback (most recent call last):
  File ""/home/amalik/tenENV/lib/python2.7/threading.py"", line 801, in __bootstrap_inner
    self.run()
  File ""/home/amalik/tenENV/lib/python2.7/threading.py"", line 754, in run
    self.__target(*self.__args, **self.__kwargs)
  File ""/home/amalik/DATA/models/research/inception/inception/data/build_imagenet_data.py"", line 395, in _process_image_files_batch
    height, width)
  File ""/home/amalik/DATA/models/research/inception/inception/data/build_imagenet_data.py"", line 214, in _convert_to_example
    'image/colorspace': _bytes_feature(colorspace),
  File ""/home/amalik/DATA/models/research/inception/inception/data/build_imagenet_data.py"", line 175, in _bytes_feature
    value = six.binary_type(value, encoding='utf-8')
TypeError: str() takes at most 1 argument (2 given)


Exception in thread Thread-9:
Traceback (most recent call last):
  File ""/home/amalik/tenENV/lib/python2.7/threading.py"", line 801, in __bootstrap_inner
    self.run()
  File ""/home/amalik/tenENV/lib/python2.7/threading.py"", line 754, in run
    self.__target(*self.__args, **self.__kwargs)
  File ""/home/amalik/DATA/models/research/inception/inception/data/build_imagenet_data.py"", line 395, in _process_image_files_batch
    height, width)
  File ""/home/amalik/DATA/models/research/inception/inception/data/build_imagenet_data.py"", line 214, in _convert_to_example
    'image/colorspace': _bytes_feature(colorspace),
  File ""/home/amalik/DATA/models/research/inception/inception/data/build_imagenet_data.py"", line 175, in _bytes_feature
    value = six.binary_type(value, encoding='utf-8')
TypeError: str() takes at most 1 argument (2 given)

Exception in thread Thread-15:
Traceback (most recent call last):
  File ""/home/amalik/tenENV/lib/python2.7/threading.py"", line 801, in __bootstrap_inner
    self.run()
  File ""/home/amalik/tenENV/lib/python2.7/threading.py"", line 754, in run
    self.__target(*self.__args, **self.__kwargs)
  File ""/home/amalik/DATA/models/research/inception/inception/data/build_imagenet_data.py"", line 395, in _process_image_files_batch
    height, width)
  File ""/home/amalik/DATA/models/research/inception/inception/data/build_imagenet_data.py"", line 214, in _convert_to_example
    'image/colorspace': _bytes_feature(colorspace),
  File ""/home/amalik/DATA/models/research/inception/inception/data/build_imagenet_data.py"", line 175, in _bytes_feature
    value = six.binary_type(value, encoding='utf-8')
TypeError: str() takes at most 1 argument (2 given)

Exception in thread Thread-16:
Traceback (most recent call last):
  File ""/home/amalik/tenENV/lib/python2.7/threading.py"", line 801, in __bootstrap_inner
    self.run()
  File ""/home/amalik/tenENV/lib/python2.7/threading.py"", line 754, in run
    self.__target(*self.__args, **self.__kwargs)
  File ""/home/amalik/DATA/models/research/inception/inception/data/build_imagenet_data.py"", line 395, in _process_image_files_batch
    height, width)
  File ""/home/amalik/DATA/models/research/inception/inception/data/build_imagenet_data.py"", line 214, in _convert_to_example
    'image/colorspace': _bytes_feature(colorspace),
  File ""/home/amalik/DATA/models/research/inception/inception/data/build_imagenet_data.py"", line 175, in _bytes_feature
    value = six.binary_type(value, encoding='utf-8')
TypeError: str() takes at most 1 argument (2 given)

2018-04-25 11:34:49.610442: Finished writing all 1281167 images in data set.








",abidmalikwaterloo,b'stat:community support',2018-04-25T15:52:32Z,2020-01-29T23:22:50Z,,,,,,,
4078,"SSD,FASTER RCNN....: Eager execution example! Debug Tools","This project helps you debug object_detection(SSD,FASTER...) using tensorflow eager excution model!
https://github.com/bysowhat/object_detection_debug.git
If you have any question please contact me.

**The top-level directory of the project:**
models\research\object_detection
**OS Platform and Distribution:**
WIN10
**TensorFlow installed from:**
binary
**TensorFlow version：1.7.0**
Bazel version：
**CUDA/cuDNN version:**
CUDA: release 9.0
cuDNN: CUDNN_MAJOR 7
**GPU model and memory:**
GeForce GTX 1080 Ti, 11G memory
**Exact command to reproduce：**",bysowhat,None,2018-04-25T03:39:18Z,2020-02-07T18:45:13Z,,,,,,,
4075,ionary to object,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",dduarte-odoogap,None,2018-04-24T18:33:05Z,2018-04-25T18:14:03Z,,,,,,,
4069,Object Detection on Android is abnormally slow,"### System information
- **What is the top-level directory of the model you are using**:  
models\research\object_detection.
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:  
A little. Mostly edited existing files to match my needs.
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:  
Windows 10 version 1709.
- **TensorFlow installed from**:  
Source.
- **TensorFlow version**:  
1.6.0.
- **Bazel version (if compiling from source)**:  
n/a.
- **CUDA/cuDNN version**:  
CUDA v9.0 / cuDNN v64_7.
- **GPU model and memory**:  
Nvidia GeForce GTX 1050 4GB `6.1`.
- **Exact command to reproduce**:  
n/a.

### Describe the problem
After following [these](https://github.com/EdjeElectronics/TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10) [great](https://hackernoon.com/building-an-insanely-fast-image-classifier-on-android-with-mobilenets-in-tensorflow-dc3e0c4410d4) [tutorials](https://towardsdatascience.com/detecting-pikachu-on-android-using-tensorflow-object-detection-15464c7a60cd), I was able to train my own Object Detection models. For the training, I've used around 1600 images (1300 train + 300 test) in 6 categories and trained the models until the loss stabilized below the 0.05 mark on TensorBoard.    

The first model I used was the `faster_rcnn_inception_v2_coco` model, and _it works like a charm on my computer_, but not so great on my phone: after exporting it to the TF Detect demo app, I`ve noticed that it was only running the object detection every 30~60 seconds, or more. I would show imy phone an object, then only after a minute its boundaries were drawn.    

Things I tried:
* **Tried training with ""faster models""**: the `ssd_mobilenet_v2_coco` and `ssd_inception_v2_coco` models. They performed worse on the detection, but both also took the same time to process the images.
* **Tried lowering the ammount of predictions** made (from 300 to 30), both on the training .config files and the APIModel.java file, but no such luck.
* **Tried with both frozen and ""unfrozen"" models** (obtained with the freeze_graph.py script), but still no difference.  
* **Tried testing on multiple phones** besides my Moto X Play: tried on a Samsung Galaxy S8, on a Samsung Galaxy A7 and on a Amazon Fire 7. Neither of them did better than my phone.

I don't need ""real-time butter smooth 144 detections per second"" performance, but it would be great if I could get something faster than a detection every minute. Is there another step for optimizing object detection models for mobile that I couldn't find anywhere else?  Or is something wrong with the demo and I should make my own detection app from scratch?

### Source code / logs

**Android Studio debugger output** (Amazon Fire 7 + ssd_inception_v2_coco)
```I/tensorflow: CameraConnectionFragment: Desired size: 640x480, min size: 480x480
I/tensorflow: CameraConnectionFragment: Valid preview sizes: [480x480, 640x480, 720x480, 720x720, 800x480, 800x600, 800x800, 864x480, 960x540, 1280x720, 1600x912, 1600x1200]
              CameraConnectionFragment: Rejected preview sizes: [176x144, 320x240, 352x288, 480x320, 480x368]
              CameraConnectionFragment: Exact size match found.
I/art: Background partial concurrent mark sweep GC freed 4116(240KB) AllocSpace objects, 2(84MB) LOS objects, 36% free, 7MB/11MB, paused 935us total 127.001ms
W/tensorflow: TensorFlowObjectDetectionAPIModel: ???
W/tensorflow: TensorFlowObjectDetectionAPIModel: label1
W/tensorflow: TensorFlowObjectDetectionAPIModel: label2
              TensorFlowObjectDetectionAPIModel: label3
              TensorFlowObjectDetectionAPIModel: label4
              TensorFlowObjectDetectionAPIModel: label5
W/tensorflow: TensorFlowObjectDetectionAPIModel: label6
I/TensorFlowInferenceInterface: Checking to see if TensorFlow native methods are already loaded
I/TensorFlowInferenceInterface: TensorFlow native methods already loaded
I/TensorFlowInferenceInterface: Model load took 1438ms, TensorFlow version: 1.8.0-rc1
I/TensorFlowInferenceInterface: Successfully loaded model from 'file:///android_asset/ssd_inference_graph.pb'
I/tensorflow: DetectorActivity: Camera orientation relative to screen canvas: 90
              DetectorActivity: Initializing at size 640x480
E/tensorflow: ObjectTracker: libtensorflow_demo.so not found, tracking unavailable
I/tensorflow: MultiBoxTracker: Initializing ObjectTracker: 640x480
E/tensorflow: ObjectTracker: Native object tracking support not found. See tensorflow/examples/android/README.md for details.
W/ResourceType: Attempt to retrieve bag 0x0103003e which is invalid or in a cycle.
E/tensorflow: MultiBoxTracker: Object tracking support not found. See tensorflow/examples/android/README.md for details.
I/tensorflow: DetectorActivity: Preparing image 1 for detection in bg thread.
I/tensorflow: DetectorActivity: Running detection on image 1
I/MaliEGL: [Mali]window_type=1, is_framebuffer=0, errnum = 0
           [Mali]surface->num_buffers=4, surface->num_frames=3, win_min_undequeued=1
           [Mali]max_allowed_dequeued_buffers=3
I/Kernel: [ 5675.354224].(3)[19526:tensorflow.demo]lowmemorykiller: Killing '.amazon.venezia' (19801), adj 12, score_adj 705,
          [ 5675.354224]   to free 51316kB on behalf of 'tensorflow.demo' (19526) because
          [ 5675.354224]   cache 146736kB is below limit 147456kB for oom_score_adj 529
          [ 5675.354224]   Free memory is 0kB above reserved
I/Kernel: [ 5675.472659].(3)[19527:tensorflow.demo]lowmemorykiller: Killing 'azon.kindle.cms' (18630), adj 12, score_adj 705,
          [ 5675.472659]   to free 44224kB on behalf of 'tensorflow.demo' (19527) because
          [ 5675.472659]   cache 145512kB is below limit 147456kB for oom_score_adj 529
          [ 5675.472659]   Free memory is 0kB above reserved
I/Kernel: [ 5675.653276].(2)[19529:tensorflow.demo]lowmemorykiller: Killing 'om.amazon.tahoe' (19754), adj 12, score_adj 705,
I/Kernel: [ 5675.653276]   cache 138356kB is below limit 147456kB for oom_score_adj 529
          [ 5675.653276]   Free memory is 0kB above reserved
I/Kernel: [ 5675.751049].(0)[19526:tensorflow.demo]lowmemorykiller: Killing 'evice.messaging' (19734), adj 12, score_adj 705,
          [ 5675.751049]   to free 34896kB on behalf of 'tensorflow.demo' (19526) because
          [ 5675.751049]   cache 137348kB is below limit 147456kB for oom_score_adj 529
          [ 5675.751049]   Free memory is 0kB above reserved
I/Kernel: [ 5675.777268].(3)[19527:tensorflow.demo]lowmemorykiller: Killing 'on.sync.service' (19448), adj 12, score_adj 705,
          [ 5675.777268]   to free 29884kB on behalf of 'tensorflow.demo' (19527) because
          [ 5675.777268]   cache 137012kB is below limit 147456kB for oom_score_adj 529
          [ 5675.777268]   Free memory is 0kB above reserved
I/Kernel: [ 5675.895443].(2)[19528:tensorflow.demo]lowmemorykiller: Killing 'h2clientservice' (19482), adj 12, score_adj 705,
          [ 5675.895443]   to free 33808kB on behalf of 'tensorflow.demo' (19528) because
          [ 5675.895443]   cache 135308kB is below limit 147456kB for oom_score_adj 529
          [ 5675.895443]   Free memory is 0kB above reserved
I/Kernel: [ 5675.976866].(1)[19528:tensorflow.demo]lowmemorykiller: Killing 'VMetricsProcess' (18717), adj 12, score_adj 705,
          [ 5675.976866]   to free 21516kB on behalf of 'tensorflow.demo' (19528) because
          [ 5675.976866]   cache 132396kB is below limit 147456kB for oom_score_adj 529
          [ 5675.976866]   Free memory is 0kB above reserved
I/art: Explicit concurrent mark sweep GC freed 1683(130KB) AllocSpace objects, 1(49MB) LOS objects, 39% free, 5MB/8MB, paused 793us total 108.477ms
I/tensorflow: MultiBoxTracker: Processing 0 results from 1
I/tensorflow: DetectorActivity: Preparing image 418 for detection in bg thread.
I/tensorflow: DetectorActivity: Running detection on image 418
I/Choreographer: Skipped 42 frames!  The application may be doing too much work on its main thread.
I/tensorflow: MultiBoxTracker: Processing 1 results from 418
I/tensorflow: DetectorActivity: Preparing image 751 for detection in bg thread.
I/tensorflow: DetectorActivity: Running detection on image 751
I/Choreographer: Skipped 42 frames!  The application may be doing too much work on its main thread.
I/tensorflow: MultiBoxTracker: Processing 0 results from 751
I/tensorflow: DetectorActivity: Preparing image 1096 for detection in bg thread.
I/tensorflow: DetectorActivity: Running detection on image 1096
I/Choreographer: Skipped 47 frames!  The application may be doing too much work on its main thread.
I/Kernel: [ 5804.275921].(0)[19526:tensorflow.demo][STP-PSM] [I]_stp_psm_stp_is_idle: **IDLE is over 5000 msec, go to sleep!!!**
I/tensorflow: MultiBoxTracker: Processing 0 results from 1096
I/tensorflow: DetectorActivity: Preparing image 1386 for detection in bg thread.
I/tensorflow: DetectorActivity: Running detection on image 1386
I/tensorflow: MultiBoxTracker: Processing 0 results from 1386
I/tensorflow: DetectorActivity: Preparing image 2029 for detection in bg thread.
I/tensorflow: DetectorActivity: Running detection on image 2029
I/art: Explicit concurrent mark sweep GC freed 34323(1262KB) AllocSpace objects, 0(0B) LOS objects, 40% free, 5MB/8MB, paused 907us total 68.107ms
I/tensorflow: MultiBoxTracker: Processing 0 results from 2029
I/tensorflow: DetectorActivity: Preparing image 2351 for detection in bg thread.
I/tensorflow: DetectorActivity: Running detection on image 2351
I/tensorflow: MultiBoxTracker: Processing 1 results from 2351
I/tensorflow: DetectorActivity: Preparing image 2673 for detection in bg thread.
I/tensorflow: DetectorActivity: Running detection on image 2673
I/tensorflow: MultiBoxTracker: Processing 2 results from 2673
I/tensorflow: DetectorActivity: Preparing image 2996 for detection in bg thread.
I/tensorflow: DetectorActivity: Running detection on image 2996
I/art: Explicit concurrent mark sweep GC freed 24655(897KB) AllocSpace objects, 0(0B) LOS objects, 39% free, 5MB/8MB, paused 793us total 61.978ms

[... it keeps going on like that ...]```

_(Yeah the poor tablet keeps running out of memory, but even the mighty Galaxy S8 with double the ammount of RAM also took the same time to detect the objects.)_",giorigor,None,2018-04-24T13:37:25Z,2018-07-17T00:13:25Z,,,,,,,
4054,Testing: Either pylint or flake8 should be run on Python 3,"### System information
- **What is the top-level directory of the model you are using**: https://github.com/tensorflow/models
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Any Python 3
- **TensorFlow installed from (source or binary)**: Source
- **TensorFlow version (use command below)**: https://github.com/tensorflow/models -- Master
- **Bazel version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**: __python3 -m pylint --disable=all --enable=E0001 .__
    - __flake8 . --count --select=E901,E999,F821,F822,F823 --show-source --statistics__  # would also flag these syntax errors

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.
### Python 3 syntax errors are not fixed for months after being reported.  These should be caught when pull requests are submitted and before they are reviewed.  See #3883 for results.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",cclauss,None,2018-04-23T08:39:16Z,2018-04-25T16:21:20Z,,,,,,,
4030,"NotFoundError (see above for traceback): Key MobilenetV2/Conv/BatchNorm/beta not found in checkpoint 	 [[Node: save/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, ..., DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=""/job:localhost/replica:0/task:0/device:CPU:0""](_arg_save/Const_0_0, save/RestoreV2/tensor_names, save/RestoreV2/shape_and_slices)]]","Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",cuicuizhang1989,None,2018-04-19T11:13:02Z,2020-06-08T05:59:29Z,,,,,,,
4026,SSD ，who can tell me how to change 300*300 to 512*512！！！,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",ghost,None,2018-04-19T05:56:57Z,2018-06-08T06:34:28Z,,,,,,,
3995,"got an unexpected keyword argument ""serialized_options"",  centos 7","Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",InomjonRamatov,None,2018-04-17T08:15:46Z,2020-04-24T12:12:21Z,,,,,,,
3992,[deeplab] eval.py issue while evaluating on a custom dataset,"### System information
- **What is the top-level directory of the model you are using**: deeplab
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.7.0
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**: 9.0/7.0.4
- **GPU model and memory**: GTX980M, 8GB
- **Exact command to reproduce**:

### Problem description

## TL;DR
I am trying to fine-tune deeplabv3+ to work with my own dataset (5 classes, 862 training examples, 216 val examples). I have modified the code to do so, and I think I got all the main changes that are necessary to make it run. When I try to evaluate, however, the script breaks because my checkpoint is apparently missing a parameter (aspp1_depthwise/BatchNorm/beta):
```
NotFoundError: Key aspp1_depthwise/BatchNorm/beta not found in checkpoint
	 [[Node: save/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, ..., DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=""/job:localhost/replica:0/task:0/device:CPU:0""](_arg_save/Const_0_0, save/RestoreV2/tensor_names, save/RestoreV2/shape_and_slices)]]
	 [[Node: save/RestoreV2/_67 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device_incarnation=1, tensor_name=""edge_84_save/RestoreV2"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:GPU:0""]()]]
```

Anyone knows how to solve this?

## Full Description

I am trying to fine-tune deeplab on my own segmentation dataset, which has 5 classes, 862 train examples and 216 val examples. To do this, I have completed the following steps:

1. I have transformed my dataset to tfrecord format by generating a new .py file, 'build_gdi_data.py', closely following 'build_ade20k_data.py'. This file generated 4 .tfrecord files, `train-00000-of-00004.tfrecord` to `train-00003-of-00004.tfrecord` (around 12MB each), and they are sitting in the folders 'gd_train_tfrecord' and 'gd_val_tfrecord', respectively.

2. In segmentation_dataset.py, I have added information about my dataset as follows:
```
_GRAPHIC_DESIGNS_INFORMATION = DatasetDescriptor(
    splits_to_sizes={
        'train': 862,
        'val': 216,
    },
    num_classes=5,
    ignore_label=255,  
)
```

and

```
_DATASETS_INFORMATION = {
    'cityscapes': _CITYSCAPES_INFORMATION,
    'pascal_voc_seg': _PASCAL_VOC_SEG_INFORMATION,
    'ade20k': _ADE20K_INFORMATION,
    'graphic_designs':_GRAPHIC_DESIGNS_INFORMATION
}
```

3. In train.py, I have modified the flags to not initialize the last layer, use only logits as last layer, not fine tune batch norm and link to my dataset. Here is how I did it:
```
flags.DEFINE_boolean('initialize_last_layer', False,
                     'Initialize the last layer.')

flags.DEFINE_boolean('last_layers_contain_logits_only', True,
                     'Only consider logits as last layers or not.')

flags.DEFINE_boolean('fine_tune_batch_norm', False,
                     'Fine tune the batch norm parameters or not.')

flags.DEFINE_string('dataset', 'graphic_designs',
                    'Name of the segmentation dataset.')
```

4. In eval.py, I point to my custom dataset:
```
flags.DEFINE_string('dataset', 'graphic_designs',
                    'Name of the segmentation dataset.')
```

5. In train_utils.py, I modify the code so as to only exclude _LOGITS_SCOPE_NAME, that I import from deeplab.model:

```
from deeplab.model import _LOGITS_SCOPE_NAME
```

```  
# Variables that will not be restored.
  exclude_list = [_LOGITS_SCOPE_NAME]
  if not initialize_last_layer:
    exclude_list.extend(last_layers)
```

6. I downloaded the xception checkpoint 'deeplabv3_xception_pascal_trainval_2018_01_04.tar.gz' and I am calling the train script with the model.ckpt.index file inside that tar file.

7. I run the training script with the xception architecture, output_stride=16, and just 30 training steps to debug. This is my full call (from inside a jupyter notebook):

```
PATH_TO_INITIAL_CHECKPOINT = ""./deeplab_pretrained/deeplabv3_xception_pascal_trainval/model.ckpt.index""
PATH_TO_TRAIN_DIR = './train_logdir'
PATH_TO_DATASET = './gd_train_tfrecord'

%run ./models/research/deeplab/train.py \
    --tf_initial_checkpoint=${PATH_TO_INITIAL_CHECKPOINT} \
    --train_logdir=${PATH_TO_TRAIN_DIR} \
    --dataset_dir=${PATH_TO_DATASET} \
    --logtostderr \
    --training_number_of_steps=30 \
    --train_split=""train"" \
    --atrous_rates=6 \
    --atrous_rates=12 \
    --atrous_rates=18 \
    --output_stride=16 \
    --decoder_output_stride=4 \
    --train_crop_size=513 \
    --train_crop_size=513 \
    --train_batch_size=1 \
    --dataset=""graphic_designs"" \
    --model_variant=""xception_65"" 

```

The training seems to work, although I get an enormous amount of WARNING: Variable missing in checkpoint, like so:
```
WARNING:tensorflow:Variable decoder/decoder_conv1_pointwise/weights/Momentum missing in checkpoint ./deeplab_pretrained/deeplabv3_xception_pascal_trainval/model.ckpt.index
```

It seems like all the momentums, moving_mean and gammas are missing. This may be normal. After all those warnings, I finally get some training:

```
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Starting Session.
INFO:tensorflow:Saving checkpoint to path ./train_logdir\model.ckpt
INFO:tensorflow:Starting Queues.
INFO:tensorflow:global_step/sec: 0
INFO:tensorflow:Recording summary at step 0.
INFO:tensorflow:global step 10: loss = 4.7966 (0.860 sec/step)
INFO:tensorflow:global step 20: loss = 4.7966 (0.841 sec/step)
INFO:tensorflow:global step 30: loss = 4.7966 (0.870 sec/step)
INFO:tensorflow:Stopping Training.
INFO:tensorflow:Finished training! Saving model to disk.
```

No decrease in loss, but that's a problem for later I guess. After that, I try to run the eval.py script by doing:
```
PATH_TO_CHECKPOINT = ""./train_logdir"" 
PATH_TO_EVAL_DIR = './eval_logdir'
PATH_TO_DATASET = './gd_val_tfrecord'

%run ./models/research/deeplab/eval.py \
    --logtostderr \
    --eval_split=""val"" \
    --model_variant=""xception_65"" \
    --atrous_rates=6 \
    --atrous_rates=12 \
    --atrous_rates=18 \
    --output_stride=16 \
    --decoder_output_stride=4 \
    --eval_crop_size=609 \
    --eval_crop_size=609 \
    --dataset=""graphic_designs"" \
    --checkpoint_dir=${PATH_TO_CHECKPOINT} \
    --eval_logdir=${PATH_TO_EVAL_DIR} \
    --dataset_dir=${PATH_TO_DATASET}
```

Now this breaks because of a NotFoundError, and I don't understand why. Anyone has thoughts? Here is the error I get: 
```
NotFoundError: Key aspp1_depthwise/BatchNorm/beta not found in checkpoint
	 [[Node: save/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, ..., DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=""/job:localhost/replica:0/task:0/device:CPU:0""](_arg_save/Const_0_0, save/RestoreV2/tensor_names, save/RestoreV2/shape_and_slices)]]
	 [[Node: save/RestoreV2/_67 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device_incarnation=1, tensor_name=""edge_84_save/RestoreV2"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:GPU:0""]()]]
```

And below is the full error traceback:

### Error Traceback
```
WARNING:tensorflow:From C:\Users\Camilo\Anaconda3\lib\site-packages\tensorflow\contrib\learn\python\learn\datasets\base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.
Instructions for updating:
Use the retry module or similar alternatives.
WARNING:tensorflow:From C:\Users\Camilo\Anaconda3\lib\site-packages\tensorflow\contrib\learn\python\learn\datasets\base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.
Instructions for updating:
Use the retry module or similar alternatives.
INFO:tensorflow:Evaluating on val set
INFO:tensorflow:Evaluating on val set
Original_image, processed_image, label shapes: (?, ?, 3) (?, ?, 3) (?, ?, 1)
Label: Tensor(""case_1/cond/Merge:0"", shape=(?, ?, 1), dtype=uint8)
INPUT_PREPROCESS.py: original_image.shape, processed_image.shape, label.shape: (?, ?, 3) (609, 609, 3) (609, 609, 1)
INFO:tensorflow:Performing single-scale test.
INFO:tensorflow:Performing single-scale test.
INFO:tensorflow:Eval num images 216
INFO:tensorflow:Eval num images 216
INFO:tensorflow:Eval batch size 1 and num batch 216
INFO:tensorflow:Eval batch size 1 and num batch 216
INFO:tensorflow:Waiting for new checkpoint at ./train_logdir
INFO:tensorflow:Waiting for new checkpoint at ./train_logdir
INFO:tensorflow:Found new checkpoint at ./train_logdir\model.ckpt-50
INFO:tensorflow:Found new checkpoint at ./train_logdir\model.ckpt-50
WARNING:tensorflow:From C:\Users\Camilo\Anaconda3\lib\site-packages\tensorflow\contrib\training\python\training\evaluation.py:303: get_or_create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Please switch to tf.train.get_or_create_global_step
WARNING:tensorflow:From C:\Users\Camilo\Anaconda3\lib\site-packages\tensorflow\contrib\training\python\training\evaluation.py:303: get_or_create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Please switch to tf.train.get_or_create_global_step
INFO:tensorflow:Graph was finalized.
INFO:tensorflow:Graph was finalized.
INFO:tensorflow:Restoring parameters from ./train_logdir\model.ckpt-50
INFO:tensorflow:Restoring parameters from ./train_logdir\model.ckpt-50
---------------------------------------------------------------------------
NotFoundError                             Traceback (most recent call last)
C:\Users\Camilo\Anaconda3\lib\site-packages\tensorflow\python\client\session.py in _do_call(self, fn, *args)
   1326     try:
-> 1327       return fn(*args)
   1328     except errors.OpError as e:

C:\Users\Camilo\Anaconda3\lib\site-packages\tensorflow\python\client\session.py in _run_fn(feed_dict, fetch_list, target_list, options, run_metadata)
   1311       return self._call_tf_sessionrun(
-> 1312           options, feed_dict, fetch_list, target_list, run_metadata)
   1313 

C:\Users\Camilo\Anaconda3\lib\site-packages\tensorflow\python\client\session.py in _call_tf_sessionrun(self, options, feed_dict, fetch_list, target_list, run_metadata)
   1419             self._session, options, feed_dict, fetch_list, target_list,
-> 1420             status, run_metadata)
   1421 

C:\Users\Camilo\Anaconda3\lib\site-packages\tensorflow\python\framework\errors_impl.py in __exit__(self, type_arg, value_arg, traceback_arg)
    515             compat.as_text(c_api.TF_Message(self.status.status)),
--> 516             c_api.TF_GetCode(self.status.status))
    517     # Delete the underlying status object from memory otherwise it stays alive

NotFoundError: Key aspp1_depthwise/BatchNorm/beta not found in checkpoint
	 [[Node: save/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, ..., DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=""/job:localhost/replica:0/task:0/device:CPU:0""](_arg_save/Const_0_0, save/RestoreV2/tensor_names, save/RestoreV2/shape_and_slices)]]
	 [[Node: save/RestoreV2/_67 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device_incarnation=1, tensor_name=""edge_84_save/RestoreV2"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:GPU:0""]()]]

During handling of the above exception, another exception occurred:

NotFoundError                             Traceback (most recent call last)
C:\Users\Camilo\Dropbox\Graduate Studies\Harvard\AC299r Independent Research\deeplab_playground\models\research\deeplab\eval.py in <module>()
    178   flags.mark_flag_as_required('eval_logdir')
    179   flags.mark_flag_as_required('dataset_dir')
--> 180   tf.app.run()

C:\Users\Camilo\Anaconda3\lib\site-packages\tensorflow\python\platform\app.py in run(main, argv)
    124   # Call the main function, passing through any arguments
    125   # to the final program.
--> 126   _sys.exit(main(argv))
    127 
    128 

C:\Users\Camilo\Dropbox\Graduate Studies\Harvard\AC299r Independent Research\deeplab_playground\models\research\deeplab\eval.py in main(unused_argv)
    171         eval_op=list(metrics_to_updates.values()),
    172         max_number_of_evaluations=num_eval_iters,
--> 173         eval_interval_secs=FLAGS.eval_interval_secs)
    174 
    175 

C:\Users\Camilo\Anaconda3\lib\site-packages\tensorflow\contrib\slim\python\slim\evaluation.py in evaluation_loop(master, checkpoint_dir, logdir, num_evals, initial_op, initial_op_feed_dict, init_fn, eval_op, eval_op_feed_dict, final_op, final_op_feed_dict, summary_op, summary_op_feed_dict, variables_to_restore, eval_interval_secs, max_number_of_evaluations, session_config, timeout, hooks)
    299       config=session_config,
    300       max_number_of_evaluations=max_number_of_evaluations,
--> 301       timeout=timeout)

C:\Users\Camilo\Anaconda3\lib\site-packages\tensorflow\contrib\training\python\training\evaluation.py in evaluate_repeatedly(checkpoint_dir, master, scaffold, eval_ops, feed_dict, final_ops, final_ops_feed_dict, eval_interval_secs, hooks, config, max_number_of_evaluations, timeout, timeout_fn)
    445 
    446     with monitored_session.MonitoredSession(
--> 447         session_creator=session_creator, hooks=hooks) as session:
    448       logging.info('Starting evaluation at ' + time.strftime(
    449           '%Y-%m-%d-%H:%M:%S', time.gmtime()))

C:\Users\Camilo\Anaconda3\lib\site-packages\tensorflow\python\training\monitored_session.py in __init__(self, session_creator, hooks, stop_grace_period_secs)
    793     super(MonitoredSession, self).__init__(
    794         session_creator, hooks, should_recover=True,
--> 795         stop_grace_period_secs=stop_grace_period_secs)
    796 
    797 

C:\Users\Camilo\Anaconda3\lib\site-packages\tensorflow\python\training\monitored_session.py in __init__(self, session_creator, hooks, should_recover, stop_grace_period_secs)
    516         stop_grace_period_secs=stop_grace_period_secs)
    517     if should_recover:
--> 518       self._sess = _RecoverableSession(self._coordinated_creator)
    519     else:
    520       self._sess = self._coordinated_creator.create_session()

C:\Users\Camilo\Anaconda3\lib\site-packages\tensorflow\python\training\monitored_session.py in __init__(self, sess_creator)
    979     """"""
    980     self._sess_creator = sess_creator
--> 981     _WrappedSession.__init__(self, self._create_session())
    982 
    983   def _create_session(self):

C:\Users\Camilo\Anaconda3\lib\site-packages\tensorflow\python\training\monitored_session.py in _create_session(self)
    984     while True:
    985       try:
--> 986         return self._sess_creator.create_session()
    987       except _PREEMPTION_ERRORS as e:
    988         logging.info('An error was raised while a session was being created. '

C:\Users\Camilo\Anaconda3\lib\site-packages\tensorflow\python\training\monitored_session.py in create_session(self)
    673       """"""Creates a coordinated session.""""""
    674       # Keep the tf_sess for unit testing.
--> 675       self.tf_sess = self._session_creator.create_session()
    676       # We don't want coordinator to suppress any exception.
    677       self.coord = coordinator.Coordinator(clean_stop_exception_types=[])

C:\Users\Camilo\Anaconda3\lib\site-packages\tensorflow\python\training\monitored_session.py in create_session(self)
    444         init_op=self._scaffold.init_op,
    445         init_feed_dict=self._scaffold.init_feed_dict,
--> 446         init_fn=self._scaffold.init_fn)
    447 
    448 

C:\Users\Camilo\Anaconda3\lib\site-packages\tensorflow\python\training\session_manager.py in prepare_session(self, master, init_op, saver, checkpoint_dir, checkpoint_filename_with_path, wait_for_checkpoint, max_wait_secs, config, init_feed_dict, init_fn)
    273         wait_for_checkpoint=wait_for_checkpoint,
    274         max_wait_secs=max_wait_secs,
--> 275         config=config)
    276     if not is_loaded_from_checkpoint:
    277       if init_op is None and not init_fn and self._local_init_op is None:

C:\Users\Camilo\Anaconda3\lib\site-packages\tensorflow\python\training\session_manager.py in _restore_checkpoint(self, master, saver, checkpoint_dir, checkpoint_filename_with_path, wait_for_checkpoint, max_wait_secs, config)
    189 
    190     if checkpoint_filename_with_path:
--> 191       saver.restore(sess, checkpoint_filename_with_path)
    192       return sess, True
    193 

C:\Users\Camilo\Anaconda3\lib\site-packages\tensorflow\python\training\saver.py in restore(self, sess, save_path)
   1773     else:
   1774       sess.run(self.saver_def.restore_op_name,
-> 1775                {self.saver_def.filename_tensor_name: save_path})
   1776 
   1777   @staticmethod

C:\Users\Camilo\Anaconda3\lib\site-packages\tensorflow\python\client\session.py in run(self, fetches, feed_dict, options, run_metadata)
    903     try:
    904       result = self._run(None, fetches, feed_dict, options_ptr,
--> 905                          run_metadata_ptr)
    906       if run_metadata:
    907         proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)

C:\Users\Camilo\Anaconda3\lib\site-packages\tensorflow\python\client\session.py in _run(self, handle, fetches, feed_dict, options, run_metadata)
   1138     if final_fetches or final_targets or (handle and feed_dict_tensor):
   1139       results = self._do_run(handle, final_targets, final_fetches,
-> 1140                              feed_dict_tensor, options, run_metadata)
   1141     else:
   1142       results = []

C:\Users\Camilo\Anaconda3\lib\site-packages\tensorflow\python\client\session.py in _do_run(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)
   1319     if handle is None:
   1320       return self._do_call(_run_fn, feeds, fetches, targets, options,
-> 1321                            run_metadata)
   1322     else:
   1323       return self._do_call(_prun_fn, handle, feeds, fetches)

C:\Users\Camilo\Anaconda3\lib\site-packages\tensorflow\python\client\session.py in _do_call(self, fn, *args)
   1338         except KeyError:
   1339           pass
-> 1340       raise type(e)(node_def, op, message)
   1341 
   1342   def _extend_graph(self):

NotFoundError: Key aspp1_depthwise/BatchNorm/beta not found in checkpoint
	 [[Node: save/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, ..., DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=""/job:localhost/replica:0/task:0/device:CPU:0""](_arg_save/Const_0_0, save/RestoreV2/tensor_names, save/RestoreV2/shape_and_slices)]]
	 [[Node: save/RestoreV2/_67 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device_incarnation=1, tensor_name=""edge_84_save/RestoreV2"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:GPU:0""]()]]

Caused by op 'save/RestoreV2', defined at:
  File ""C:\Users\Camilo\Anaconda3\lib\runpy.py"", line 193, in _run_module_as_main
    ""__main__"", mod_spec)
  File ""C:\Users\Camilo\Anaconda3\lib\runpy.py"", line 85, in _run_code
    exec(code, run_globals)
  File ""C:\Users\Camilo\Anaconda3\lib\site-packages\ipykernel_launcher.py"", line 16, in <module>
    app.launch_new_instance()
  File ""C:\Users\Camilo\Anaconda3\lib\site-packages\traitlets\config\application.py"", line 658, in launch_instance
    app.start()
  File ""C:\Users\Camilo\Anaconda3\lib\site-packages\ipykernel\kernelapp.py"", line 477, in start
    ioloop.IOLoop.instance().start()
  File ""C:\Users\Camilo\Anaconda3\lib\site-packages\zmq\eventloop\ioloop.py"", line 177, in start
    super(ZMQIOLoop, self).start()
  File ""C:\Users\Camilo\Anaconda3\lib\site-packages\tornado\ioloop.py"", line 888, in start
    handler_func(fd_obj, events)
  File ""C:\Users\Camilo\Anaconda3\lib\site-packages\tornado\stack_context.py"", line 277, in null_wrapper
    return fn(*args, **kwargs)
  File ""C:\Users\Camilo\Anaconda3\lib\site-packages\zmq\eventloop\zmqstream.py"", line 440, in _handle_events
    self._handle_recv()
  File ""C:\Users\Camilo\Anaconda3\lib\site-packages\zmq\eventloop\zmqstream.py"", line 472, in _handle_recv
    self._run_callback(callback, msg)
  File ""C:\Users\Camilo\Anaconda3\lib\site-packages\zmq\eventloop\zmqstream.py"", line 414, in _run_callback
    callback(*args, **kwargs)
  File ""C:\Users\Camilo\Anaconda3\lib\site-packages\tornado\stack_context.py"", line 277, in null_wrapper
    return fn(*args, **kwargs)
  File ""C:\Users\Camilo\Anaconda3\lib\site-packages\ipykernel\kernelbase.py"", line 283, in dispatcher
    return self.dispatch_shell(stream, msg)
  File ""C:\Users\Camilo\Anaconda3\lib\site-packages\ipykernel\kernelbase.py"", line 235, in dispatch_shell
    handler(stream, idents, msg)
  File ""C:\Users\Camilo\Anaconda3\lib\site-packages\ipykernel\kernelbase.py"", line 399, in execute_request
    user_expressions, allow_stdin)
  File ""C:\Users\Camilo\Anaconda3\lib\site-packages\ipykernel\ipkernel.py"", line 196, in do_execute
    res = shell.run_cell(code, store_history=store_history, silent=silent)
  File ""C:\Users\Camilo\Anaconda3\lib\site-packages\ipykernel\zmqshell.py"", line 533, in run_cell
    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)
  File ""C:\Users\Camilo\Anaconda3\lib\site-packages\IPython\core\interactiveshell.py"", line 2717, in run_cell
    interactivity=interactivity, compiler=compiler, result=result)
  File ""C:\Users\Camilo\Anaconda3\lib\site-packages\IPython\core\interactiveshell.py"", line 2827, in run_ast_nodes
    if self.run_code(code, result):
  File ""C:\Users\Camilo\Anaconda3\lib\site-packages\IPython\core\interactiveshell.py"", line 2881, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File ""<ipython-input-3-17b437d1a5ce>"", line 8, in <module>
    get_ipython().magic('run {WORK_DIR}/eval.py     --logtostderr     --eval_split=""val""     --model_variant=""xception_65""     --atrous_rates=6     --atrous_rates=12     --atrous_rates=18     --output_stride=16     --decoder_output_stride=4     --eval_crop_size=609     --eval_crop_size=609     --dataset=""graphic_designs""     --fine_tune_batch_norm=False     --checkpoint_dir=${PATH_TO_CHECKPOINT}     --eval_logdir=${PATH_TO_EVAL_DIR}     --dataset_dir=${PATH_TO_DATASET}')
  File ""C:\Users\Camilo\Anaconda3\lib\site-packages\IPython\core\interactiveshell.py"", line 2158, in magic
    return self.run_line_magic(magic_name, magic_arg_s)
  File ""C:\Users\Camilo\Anaconda3\lib\site-packages\IPython\core\interactiveshell.py"", line 2079, in run_line_magic
    result = fn(*args,**kwargs)
  File ""<decorator-gen-58>"", line 2, in run
  File ""C:\Users\Camilo\Anaconda3\lib\site-packages\IPython\core\magic.py"", line 188, in <lambda>
    call = lambda f, *a, **k: f(*a, **k)
  File ""C:\Users\Camilo\Anaconda3\lib\site-packages\IPython\core\magics\execution.py"", line 742, in run
    run()
  File ""C:\Users\Camilo\Anaconda3\lib\site-packages\IPython\core\magics\execution.py"", line 728, in run
    exit_ignore=exit_ignore)
  File ""C:\Users\Camilo\Anaconda3\lib\site-packages\IPython\core\interactiveshell.py"", line 2481, in safe_execfile
    self.compile if kw['shell_futures'] else None)
  File ""C:\Users\Camilo\Anaconda3\lib\site-packages\IPython\utils\py3compat.py"", line 186, in execfile
    exec(compiler(f.read(), fname, 'exec'), glob, loc)
  File ""C:\Users\Camilo\Dropbox\Graduate Studies\Harvard\AC299r Independent Research\deeplab_playground\models\research\deeplab\eval.py"", line 180, in <module>
    tf.app.run()
  File ""C:\Users\Camilo\Anaconda3\lib\site-packages\tensorflow\python\platform\app.py"", line 126, in run
    _sys.exit(main(argv))
  File ""C:\Users\Camilo\Dropbox\Graduate Studies\Harvard\AC299r Independent Research\deeplab_playground\models\research\deeplab\eval.py"", line 173, in main
    eval_interval_secs=FLAGS.eval_interval_secs)
  File ""C:\Users\Camilo\Anaconda3\lib\site-packages\tensorflow\contrib\slim\python\slim\evaluation.py"", line 301, in evaluation_loop
    timeout=timeout)
  File ""C:\Users\Camilo\Anaconda3\lib\site-packages\tensorflow\contrib\training\python\training\evaluation.py"", line 447, in evaluate_repeatedly
    session_creator=session_creator, hooks=hooks) as session:
  File ""C:\Users\Camilo\Anaconda3\lib\site-packages\tensorflow\python\training\monitored_session.py"", line 795, in __init__
    stop_grace_period_secs=stop_grace_period_secs)
  File ""C:\Users\Camilo\Anaconda3\lib\site-packages\tensorflow\python\training\monitored_session.py"", line 518, in __init__
    self._sess = _RecoverableSession(self._coordinated_creator)
  File ""C:\Users\Camilo\Anaconda3\lib\site-packages\tensorflow\python\training\monitored_session.py"", line 981, in __init__
    _WrappedSession.__init__(self, self._create_session())
  File ""C:\Users\Camilo\Anaconda3\lib\site-packages\tensorflow\python\training\monitored_session.py"", line 986, in _create_session
    return self._sess_creator.create_session()
  File ""C:\Users\Camilo\Anaconda3\lib\site-packages\tensorflow\python\training\monitored_session.py"", line 675, in create_session
    self.tf_sess = self._session_creator.create_session()
  File ""C:\Users\Camilo\Anaconda3\lib\site-packages\tensorflow\python\training\monitored_session.py"", line 437, in create_session
    self._scaffold.finalize()
  File ""C:\Users\Camilo\Anaconda3\lib\site-packages\tensorflow\python\training\monitored_session.py"", line 212, in finalize
    self._saver = training_saver._get_saver_or_default()  # pylint: disable=protected-access
  File ""C:\Users\Camilo\Anaconda3\lib\site-packages\tensorflow\python\training\saver.py"", line 884, in _get_saver_or_default
    saver = Saver(sharded=True, allow_empty=True)
  File ""C:\Users\Camilo\Anaconda3\lib\site-packages\tensorflow\python\training\saver.py"", line 1311, in __init__
    self.build()
  File ""C:\Users\Camilo\Anaconda3\lib\site-packages\tensorflow\python\training\saver.py"", line 1320, in build
    self._build(self._filename, build_save=True, build_restore=True)
  File ""C:\Users\Camilo\Anaconda3\lib\site-packages\tensorflow\python\training\saver.py"", line 1357, in _build
    build_save=build_save, build_restore=build_restore)
  File ""C:\Users\Camilo\Anaconda3\lib\site-packages\tensorflow\python\training\saver.py"", line 803, in _build_internal
    restore_sequentially, reshape)
  File ""C:\Users\Camilo\Anaconda3\lib\site-packages\tensorflow\python\training\saver.py"", line 501, in _AddShardedRestoreOps
    name=""restore_shard""))
  File ""C:\Users\Camilo\Anaconda3\lib\site-packages\tensorflow\python\training\saver.py"", line 448, in _AddRestoreOps
    restore_sequentially)
  File ""C:\Users\Camilo\Anaconda3\lib\site-packages\tensorflow\python\training\saver.py"", line 860, in bulk_restore
    return io_ops.restore_v2(filename_tensor, names, slices, dtypes)
  File ""C:\Users\Camilo\Anaconda3\lib\site-packages\tensorflow\python\ops\gen_io_ops.py"", line 1541, in restore_v2
    shape_and_slices=shape_and_slices, dtypes=dtypes, name=name)
  File ""C:\Users\Camilo\Anaconda3\lib\site-packages\tensorflow\python\framework\op_def_library.py"", line 787, in _apply_op_helper
    op_def=op_def)
  File ""C:\Users\Camilo\Anaconda3\lib\site-packages\tensorflow\python\framework\ops.py"", line 3290, in create_op
    op_def=op_def)
  File ""C:\Users\Camilo\Anaconda3\lib\site-packages\tensorflow\python\framework\ops.py"", line 1654, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access

NotFoundError (see above for traceback): Key aspp1_depthwise/BatchNorm/beta not found in checkpoint
	 [[Node: save/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, ..., DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=""/job:localhost/replica:0/task:0/device:CPU:0""](_arg_save/Const_0_0, save/RestoreV2/tensor_names, save/RestoreV2/shape_and_slices)]]
	 [[Node: save/RestoreV2/_67 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device_incarnation=1, tensor_name=""edge_84_save/RestoreV2"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:GPU:0""]()]]
```
",cfosco,None,2018-04-16T18:28:01Z,2019-06-26T15:13:32Z,,,,,,,
3965,remove logging hook from wide_deep,Quick bug fix for #3959. It's probably best not to have graph-dependent logging in the model.,k-w-w,b'cla: yes',2018-04-13T01:18:41Z,2018-04-16T22:43:51Z,,,,,,,
3962,[Learned_optimizer] Error when running metarun.py,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**: ~/models/research/learned_optimizer
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: v1.4.0-19-ga52c8d9 1.4.1
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:6.0
- **GPU model and memory**: Titan xp
- **Exact command to reproduce**: python  metarun.py



### Describe the problem
I was trying to run the training script 'metarun.py' but encountered errors shown as below

### Source code / logs
Traceback (most recent call last):
  File ""metarun.py"", line 394, in <module>
    tf.app.run()
  File ""/home/rvl224/anaconda3/lib/python3.5/site-packages/tensorflow/python/platform/app.py"", line 48, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""metarun.py"", line 388, in main
    callbacks=[])
  File ""/home/rvl224/models/research/metaopt.py"", line 184, in train_optimizer
    train_output = opt.train(problem, dataset)
  File ""/home/rvl224/models/research/learned_optimizer/optimizer/trainable_optimizer.py"", line 347, in train
    swap_memory=True, shape_invariants=invariants)
  File ""/home/rvl224/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py"", line 2816, in while_loop
    result = loop_context.BuildLoop(cond, body, loop_vars, shape_invariants)
  File ""/home/rvl224/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py"", line 2640, in BuildLoop
    pred, body, original_loop_vars, loop_vars, shape_invariants)
  File ""/home/rvl224/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py"", line 2597, in _BuildLoop
    nest.assert_same_structure(list(packed_vars_for_body), list(body_result))
  File ""/home/rvl224/anaconda3/lib/python3.5/site-packages/tensorflow/python/util/nest.py"", line 222, in assert_same_structure
    % (len_nest1, nest1, len_nest2, nest2))
ValueError: The two structures don't have the same number of elements.

First structure (120 elements): [<tf.Tensor 'while/Identity:0' shape=() dtype=int32>, <tf.Tensor 'while/Identity_1:0' shape=() dtype=float32>, [<tf.Tensor 'while/Identity_2:0' shape=(11, 1) dtype=float32>, <tf.Tensor 'while/Identity_3:0' shape=(3, 1) dtype=float32>, <tf.Tensor 'while/Identity_4:0' shape=(9, 1) dtype=float32>, <tf.Tensor 'while/Identity_5:0' shape=(7, 1) dtype=float32>, <tf.Tensor 'while/Identity_6:0' shape=(5, 1) dtype=float32>, <tf.Tensor 'while/Identity_7:0' shape=(13, 1) dtype=float32>, <tf.Tensor 'while/Identity_8:0' shape=(12, 1) dtype=float32>], [<tf.Tensor 'while/Identity_9:0' shape=(11, 1) dtype=float32>, <tf.Tensor 'while/Identity_10:0' shape=(3, 1) dtype=float32>, <tf.Tensor 'while/Identity_11:0' shape=(9, 1) dtype=float32>, <tf.Tensor 'while/Identity_12:0' shape=(7, 1) dtype=float32>, <tf.Tensor 'while/Identity_13:0' shape=(5, 1) dtype=float32>, <tf.Tensor 'while/Identity_14:0' shape=(13, 1) dtype=float32>, <tf.Tensor 'while/Identity_15:0' shape=(12, 1) dtype=float32>], [[<tf.Tensor 'while/Identity_16:0' shape=(11, 1) dtype=float32>, <tf.Tensor 'while/Identity_17:0' shape=(11, 1) dtype=float32>, <tf.Tensor 'while/Identity_18:0' shape=(11, 1) dtype=float32>, <tf.Tensor 'while/Identity_19:0' shape=(11, 1) dtype=float32>, <tf.Tensor 'while/Identity_20:0' shape=(11, 1) dtype=float32>, <tf.Tensor 'while/Identity_21:0' shape=(1, 20) dtype=float32>, <tf.Tensor 'while/Identity_22:0' shape=(11, 1) dtype=float32>, <tf.Tensor 'while/Identity_23:0' shape=(11, 1) dtype=float32>, <tf.Tensor 'while/Identity_24:0' shape=(11, 1) dtype=float32>, <tf.Tensor 'while/Identity_25:0' shape=(11, 1) dtype=float32>, <tf.Tensor 'while/Identity_26:0' shape=(11, 1) dtype=float32>, <tf.Tensor 'while/Identity_27:0' shape=(11, 10) dtype=float32>, <tf.Tensor 'while/Identity_28:0' shape=(11, 1) dtype=float32>, <tf.Tensor 'while/Identity_29:0' shape=(11, 1) dtype=float32>], [<tf.Tensor 'while/Identity_30:0' shape=(3, 1) dtype=float32>, <tf.Tensor 'while/Identity_31:0' shape=(3, 1) dtype=float32>, <tf.Tensor 'while/Identity_32:0' shape=(3, 1) dtype=float32>, <tf.Tensor 'while/Identity_33:0' shape=(3, 1) dtype=float32>, <tf.Tensor 'while/Identity_34:0' shape=(3, 1) dtype=float32>, <tf.Tensor 'while/Identity_35:0' shape=(1, 20) dtype=float32>, <tf.Tensor 'while/Identity_36:0' shape=(3, 1) dtype=float32>, <tf.Tensor 'while/Identity_37:0' shape=(3, 1) dtype=float32>, <tf.Tensor 'while/Identity_38:0' shape=(3, 1) dtype=float32>, <tf.Tensor 'while/Identity_39:0' shape=(3, 1) dtype=float32>, <tf.Tensor 'while/Identity_40:0' shape=(3, 1) dtype=float32>, <tf.Tensor 'while/Identity_41:0' shape=(3, 10) dtype=float32>, <tf.Tensor 'while/Identity_42:0' shape=(3, 1) dtype=float32>, <tf.Tensor 'while/Identity_43:0' shape=(3, 1) dtype=float32>], [<tf.Tensor 'while/Identity_44:0' shape=(9, 1) dtype=float32>, <tf.Tensor 'while/Identity_45:0' shape=(9, 1) dtype=float32>, <tf.Tensor 'while/Identity_46:0' shape=(9, 1) dtype=float32>, <tf.Tensor 'while/Identity_47:0' shape=(9, 1) dtype=float32>, <tf.Tensor 'while/Identity_48:0' shape=(9, 1) dtype=float32>, <tf.Tensor 'while/Identity_49:0' shape=(1, 20) dtype=float32>, <tf.Tensor 'while/Identity_50:0' shape=(9, 1) dtype=float32>, <tf.Tensor 'while/Identity_51:0' shape=(9, 1) dtype=float32>, <tf.Tensor 'while/Identity_52:0' shape=(9, 1) dtype=float32>, <tf.Tensor 'while/Identity_53:0' shape=(9, 1) dtype=float32>, <tf.Tensor 'while/Identity_54:0' shape=(9, 1) dtype=float32>, <tf.Tensor 'while/Identity_55:0' shape=(9, 10) dtype=float32>, <tf.Tensor 'while/Identity_56:0' shape=(9, 1) dtype=float32>, <tf.Tensor 'while/Identity_57:0' shape=(9, 1) dtype=float32>], [<tf.Tensor 'while/Identity_58:0' shape=(7, 1) dtype=float32>, <tf.Tensor 'while/Identity_59:0' shape=(7, 1) dtype=float32>, <tf.Tensor 'while/Identity_60:0' shape=(7, 1) dtype=float32>, <tf.Tensor 'while/Identity_61:0' shape=(7, 1) dtype=float32>, <tf.Tensor 'while/Identity_62:0' shape=(7, 1) dtype=float32>, <tf.Tensor 'while/Identity_63:0' shape=(1, 20) dtype=float32>, <tf.Tensor 'while/Identity_64:0' shape=(7, 1) dtype=float32>, <tf.Tensor 'while/Identity_65:0' shape=(7, 1) dtype=float32>, <tf.Tensor 'while/Identity_66:0' shape=(7, 1) dtype=float32>, <tf.Tensor 'while/Identity_67:0' shape=(7, 1) dtype=float32>, <tf.Tensor 'while/Identity_68:0' shape=(7, 1) dtype=float32>, <tf.Tensor 'while/Identity_69:0' shape=(7, 10) dtype=float32>, <tf.Tensor 'while/Identity_70:0' shape=(7, 1) dtype=float32>, <tf.Tensor 'while/Identity_71:0' shape=(7, 1) dtype=float32>], [<tf.Tensor 'while/Identity_72:0' shape=(5, 1) dtype=float32>, <tf.Tensor 'while/Identity_73:0' shape=(5, 1) dtype=float32>, <tf.Tensor 'while/Identity_74:0' shape=(5, 1) dtype=float32>, <tf.Tensor 'while/Identity_75:0' shape=(5, 1) dtype=float32>, <tf.Tensor 'while/Identity_76:0' shape=(5, 1) dtype=float32>, <tf.Tensor 'while/Identity_77:0' shape=(1, 20) dtype=float32>, <tf.Tensor 'while/Identity_78:0' shape=(5, 1) dtype=float32>, <tf.Tensor 'while/Identity_79:0' shape=(5, 1) dtype=float32>, <tf.Tensor 'while/Identity_80:0' shape=(5, 1) dtype=float32>, <tf.Tensor 'while/Identity_81:0' shape=(5, 1) dtype=float32>, <tf.Tensor 'while/Identity_82:0' shape=(5, 1) dtype=float32>, <tf.Tensor 'while/Identity_83:0' shape=(5, 10) dtype=float32>, <tf.Tensor 'while/Identity_84:0' shape=(5, 1) dtype=float32>, <tf.Tensor 'while/Identity_85:0' shape=(5, 1) dtype=float32>], [<tf.Tensor 'while/Identity_86:0' shape=(13, 1) dtype=float32>, <tf.Tensor 'while/Identity_87:0' shape=(13, 1) dtype=float32>, <tf.Tensor 'while/Identity_88:0' shape=(13, 1) dtype=float32>, <tf.Tensor 'while/Identity_89:0' shape=(13, 1) dtype=float32>, <tf.Tensor 'while/Identity_90:0' shape=(13, 1) dtype=float32>, <tf.Tensor 'while/Identity_91:0' shape=(1, 20) dtype=float32>, <tf.Tensor 'while/Identity_92:0' shape=(13, 1) dtype=float32>, <tf.Tensor 'while/Identity_93:0' shape=(13, 1) dtype=float32>, <tf.Tensor 'while/Identity_94:0' shape=(13, 1) dtype=float32>, <tf.Tensor 'while/Identity_95:0' shape=(13, 1) dtype=float32>, <tf.Tensor 'while/Identity_96:0' shape=(13, 1) dtype=float32>, <tf.Tensor 'while/Identity_97:0' shape=(13, 10) dtype=float32>, <tf.Tensor 'while/Identity_98:0' shape=(13, 1) dtype=float32>, <tf.Tensor 'while/Identity_99:0' shape=(13, 1) dtype=float32>], [<tf.Tensor 'while/Identity_100:0' shape=(12, 1) dtype=float32>, <tf.Tensor 'while/Identity_101:0' shape=(12, 1) dtype=float32>, <tf.Tensor 'while/Identity_102:0' shape=(12, 1) dtype=float32>, <tf.Tensor 'while/Identity_103:0' shape=(12, 1) dtype=float32>, <tf.Tensor 'while/Identity_104:0' shape=(12, 1) dtype=float32>, <tf.Tensor 'while/Identity_105:0' shape=(1, 20) dtype=float32>, <tf.Tensor 'while/Identity_106:0' shape=(12, 1) dtype=float32>, <tf.Tensor 'while/Identity_107:0' shape=(12, 1) dtype=float32>, <tf.Tensor 'while/Identity_108:0' shape=(12, 1) dtype=float32>, <tf.Tensor 'while/Identity_109:0' shape=(12, 1) dtype=float32>, <tf.Tensor 'while/Identity_110:0' shape=(12, 1) dtype=float32>, <tf.Tensor 'while/Identity_111:0' shape=(12, 10) dtype=float32>, <tf.Tensor 'while/Identity_112:0' shape=(12, 1) dtype=float32>, <tf.Tensor 'while/Identity_113:0' shape=(12, 1) dtype=float32>]], [<tf.Tensor 'while/Identity_114:0' shape=(1, 20) dtype=float32>], <tf.Tensor 'while/Identity_115:0' shape=(?,) dtype=float32>, <tf.Tensor 'while/Identity_116:0' shape=() dtype=float32>, <tf.Tensor 'while/Identity_117:0' shape=<unknown> dtype=float32>, <tf.Tensor 'while/Identity_118:0' shape=<unknown> dtype=int32>, <tf.Tensor 'while/Identity_119:0' shape=<unknown> dtype=int32>]

Second structure (23 elements): [<tf.Tensor 'while/add_21:0' shape=() dtype=int32>, <tf.Tensor 'while/Add:0' shape=() dtype=float32>, [<tf.Tensor 'while/LOL/PerTensor/sub_15:0' shape=(11, 1) dtype=float32>, <tf.Tensor 'while/LOL/PerTensor_1/sub_15:0' shape=(3, 1) dtype=float32>, <tf.Tensor 'while/LOL/PerTensor_2/sub_15:0' shape=(9, 1) dtype=float32>, <tf.Tensor 'while/LOL/PerTensor_3/sub_15:0' shape=(7, 1) dtype=float32>, <tf.Tensor 'while/LOL/PerTensor_4/sub_15:0' shape=(5, 1) dtype=float32>, <tf.Tensor 'while/LOL/PerTensor_5/sub_15:0' shape=(13, 1) dtype=float32>, <tf.Tensor 'while/LOL/PerTensor_6/sub_15:0' shape=(12, 1) dtype=float32>], [<tf.Tensor 'while/LOL/PerTensor/sub_15:0' shape=(11, 1) dtype=float32>, <tf.Tensor 'while/LOL/PerTensor_1/sub_15:0' shape=(3, 1) dtype=float32>, <tf.Tensor 'while/LOL/PerTensor_2/sub_15:0' shape=(9, 1) dtype=float32>, <tf.Tensor 'while/LOL/PerTensor_3/sub_15:0' shape=(7, 1) dtype=float32>, <tf.Tensor 'while/LOL/PerTensor_4/sub_15:0' shape=(5, 1) dtype=float32>, <tf.Tensor 'while/LOL/PerTensor_5/sub_15:0' shape=(13, 1) dtype=float32>, <tf.Tensor 'while/LOL/PerTensor_6/sub_15:0' shape=(12, 1) dtype=float32>], <map object at 0x7f0a9b8f4be0>, [<tf.Tensor 'while/LOL/Layer2_RNN/BiasGRUCell/add:0' shape=(1, 20) dtype=float32>], <tf.Tensor 'while/concat:0' shape=(?,) dtype=float32>, <tf.Tensor 'while/Identity_116:0' shape=() dtype=float32>, <tf.Tensor 'while/Identity_117:0' shape=<unknown> dtype=float32>, <tf.Tensor 'while/Identity_118:0' shape=<unknown> dtype=int32>, <tf.Tensor 'while/Identity_119:0' shape=<unknown> dtype=int32>]
",imaxpayne,b'stat:awaiting model gardener',2018-04-12T11:02:08Z,2020-05-20T12:14:10Z,,,,,,,
3954,tensorflow.python.framework.errors_impl.NotFoundError: ; No such file or directory,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
/media/habeshageeks/DATA/auto_proj/lisa
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: 
Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: v1.7.0-3-g024aecf414 1.7.0
- **Bazel version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: Cuda 9.1 & Cudnn 7.1
- **GPU model and memory**: GTX1060 8 GB
- **Exact command to reproduce**: `python object_detection/train.py --logtostderr --pipeline lisa/lisa/experiments/training/faster_rcnn_lisa.config --train_dir lisa/lisa/experiments/training
`

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
When I run `python object_detection/train.py --logtostderr --pipeline lisa/lisa/experiments/training/faster_rcnn_lisa.config --train_dir lisa/lisa/experiments/training
` It shows me an error with `Traceback (most recent call last):
  File ""object_detection/train.py"", line 167, in <module>
    tf.app.run()
  File ""/home/habeshageeks/.virtualenvs/ml/lib/python3.5/site-packages/tensorflow/python/platform/app.py"", line 126, in run
    _sys.exit(main(argv))
  File ""object_detection/train.py"", line 107, in main
    overwrite=True)
  File ""/home/habeshageeks/.virtualenvs/ml/lib/python3.5/site-packages/tensorflow/python/lib/io/file_io.py"", line 392, in copy
    compat.as_bytes(oldpath), compat.as_bytes(newpath), overwrite, status)
  File ""/home/habeshageeks/.virtualenvs/ml/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py"", line 516, in __exit__
    c_api.TF_GetCode(self.status.status))
tensorflow.python.framework.errors_impl.NotFoundError: ; No such file or directory
`
The Path Lisa is Sim Linked with the Research Directory
### Source code / logs
`python object_detection/train.py --logtostderr --pipeline lisa/lisa/experiments/training/faster_rcnn_lisa.config --train_dir lisa/lisa/experiments/training
WARNING:tensorflow:From /home/habeshageeks/.virtualenvs/ml/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.
Instructions for updating:
Use the retry module or similar alternatives.
Traceback (most recent call last):
  File ""object_detection/train.py"", line 167, in <module>
    tf.app.run()
  File ""/home/habeshageeks/.virtualenvs/ml/lib/python3.5/site-packages/tensorflow/python/platform/app.py"", line 126, in run
    _sys.exit(main(argv))
  File ""object_detection/train.py"", line 107, in main
    overwrite=True)
  File ""/home/habeshageeks/.virtualenvs/ml/lib/python3.5/site-packages/tensorflow/python/lib/io/file_io.py"", line 392, in copy
    compat.as_bytes(oldpath), compat.as_bytes(newpath), overwrite, status)
  File ""/home/habeshageeks/.virtualenvs/ml/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py"", line 516, in __exit__
    c_api.TF_GetCode(self.status.status))
tensorflow.python.framework.errors_impl.NotFoundError: ; No such file or directory`
",isrugeek,b'stat:awaiting response',2018-04-11T15:39:18Z,2020-05-16T08:22:41Z,,,,,,,
3947,Fix bug exporting FasterRCNN with only one stage,Fixes issue #1916,dsuess,b'cla: yes',2018-04-11T04:55:28Z,2019-12-03T07:08:27Z,,,,,,,
3926," Shradhali Shinde 1 second ago File ""train.py"", line 167, in <module>     tf.app.run()   File ""C:\Users\hp\Anaconda3\lib\site-packages\tensorflow\python\platform\app.py"", line 126, in run     _sys.exit(main(argv))   File ""train.py"", line 163, in main     worker_job_name, is_chief, FLAGS.train_dir)   File ""C:\tensorflow1\models\research\object_detection\trainer.py"", line 211, in train     detection_model = create_model_fn()   File ""C:\tensorflow1\models\research\object_detection\builders\model_builder.py"", line 97, in build     raise ValueError('Unknown meta architecture: {}'.format(meta_architecture)) ValueError: Unknown meta architecture: None﻿","Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",mayur17mirashi,None,2018-04-10T05:35:14Z,2018-04-10T17:08:07Z,,,,,,,
3922,ssd_mobilenet_v2 pretrained model structure does not match,"### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
   Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**:
 Source
- **TensorFlow version (use command below)**:
  1.5
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
  Telsa V100
- **Exact command to reproduce**:
   python object_detection/train.py
       --logtostderr 
       --pipeline_config_path=scene_model/models/model-3-v2/ssd_mobilenet_v2.config  
       --train_dir=scene_model/models/model-3-v2/train


### Describe the problem
I am running the ssd_mobilenet_v2 version using the config file from:
https://github.com/tensorflow/models/tree/master/research/object_detection/samples/configs/ssd_mobilenet_v2_coco.config
pretrained model from:
https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md

I am an old user of ssd_mobilenet_v1. Everything works fine for my previous ssd_mobilenet_v1 model. I recently downloaded the ssd_mobilenet_v2 version model and using its COCO config. When I run the training, it reports the bug. The model can be still trained but most classes AP were close to 0. 

Besides, what is the PaxHeader folder inside the unzipped pretrained  ssd_mobilenet_v2_coco_2018_03_29 folder? Can anyone give a little explanation? 

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
INFO:tensorflow:depth of additional conv before box predictor: 0
INFO:tensorflow:depth of additional conv before box predictor: 0
INFO:tensorflow:depth of additional conv before box predictor: 0
INFO:tensorflow:depth of additional conv before box predictor: 0
INFO:tensorflow:depth of additional conv before box predictor: 0
INFO:tensorflow:depth of additional conv before box predictor: 0
WARNING:root:Variable [FeatureExtractor/MobilenetV2/Conv/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint
WARNING:root:Variable [FeatureExtractor/MobilenetV2/Conv/BatchNorm/beta/RMSProp] is not available in checkpoint
WARNING:root:Variable [FeatureExtractor/MobilenetV2/Conv/BatchNorm/beta/RMSProp_1] is not available in checkpoint
WARNING:root:Variable [FeatureExtractor/MobilenetV2/Conv/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint
WARNING:root:Variable [FeatureExtractor/MobilenetV2/Conv/BatchNorm/gamma/RMSProp] is not available in checkpoint
WARNING:root:Variable [FeatureExtractor/MobilenetV2/Conv/BatchNorm/gamma/RMSProp_1] is not available in checkpoint
WARNING:root:Variable [FeatureExtractor/MobilenetV2/Conv/weights/ExponentialMovingAverage] is not available in checkpoint
WARNING:root:Variable [FeatureExtractor/MobilenetV2/Conv/weights/RMSProp] is not available in checkpoint
WARNING:root:Variable [FeatureExtractor/MobilenetV2/Conv/weights/RMSProp_1] is not available in checkpoint
WARNING:root:Variable [FeatureExtractor/MobilenetV2/Conv_1/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint
WARNING:root:Variable [FeatureExtractor/MobilenetV2/Conv_1/BatchNorm/beta/RMSProp] is not available in checkpoint
WARNING:root:Variable [FeatureExtractor/MobilenetV2/Conv_1/BatchNorm/beta/RMSProp_1] is not available in checkpoint
WARNING:root:Variable [FeatureExtractor/MobilenetV2/Conv_1/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint
WARNING:root:Variable [FeatureExtractor/MobilenetV2/Conv_1/BatchNorm/gamma/RMSProp] is not available in checkpoint
WARNING:root:Variable [FeatureExtractor/MobilenetV2/Conv_1/BatchNorm/gamma/RMSProp_1] is not available in checkpoint
WARNING:root:Variable [FeatureExtractor/MobilenetV2/Conv_1/weights/ExponentialMovingAverage] is not available in checkpoint
WARNING:root:Variable [FeatureExtractor/MobilenetV2/Conv_1/weights/RMSProp] is not available in checkpoint
WARNING:root:Variable [FeatureExtractor/MobilenetV2/Conv_1/weights/RMSProp_1] is not available in checkpoint
WARNING:root:Variable [FeatureExtractor/MobilenetV2/expanded_conv/depthwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint
WARNING:root:Variable [FeatureExtractor/MobilenetV2/expanded_conv/depthwise/BatchNorm/beta/RMSProp] is not available in checkpoint
WARNING:root:Variable [FeatureExtractor/MobilenetV2/expanded_conv/depthwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint
WARNING:root:Variable [FeatureExtractor/MobilenetV2/expanded_conv/depthwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint
WARNING:root:Variable [FeatureExtractor/MobilenetV2/expanded_conv/depthwise/BatchNorm/gamma/RMSProp] is not available in checkpoint
WARNING:root:Variable [FeatureExtractor/MobilenetV2/expanded_conv/depthwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint
WARNING:root:Variable [FeatureExtractor/MobilenetV2/expanded_conv/depthwise/depthwise_weights/ExponentialMovingAverage] is not available in checkpoint
WARNING:root:Variable [FeatureExtractor/MobilenetV2/expanded_conv/depthwise/depthwise_weights/RMSProp] is not available in checkpoint
WARNING:root:Variable [FeatureExtractor/MobilenetV2/expanded_conv/depthwise/depthwise_weights/RMSProp_1] is not available in checkpoint
WARNING:root:Variable [FeatureExtractor/MobilenetV2/expanded_conv/project/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint
WARNING:root:Variable [FeatureExtractor/MobilenetV2/expanded_conv/project/BatchNorm/beta/RMSProp] is not available in checkpoint
WARNING:root:Variable [FeatureExtractor/MobilenetV2/expanded_conv/project/BatchNorm/beta/RMSProp_1] is not available in checkpoint
WARNING:root:Variable [FeatureExtractor/MobilenetV2/expanded_conv/project/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint
WARNING:root:Variable [FeatureExtractor/MobilenetV2/expanded_conv/project/BatchNorm/gamma/RMSProp] is not available in checkpoint
WARNING:root:Variable [FeatureExtractor/MobilenetV2/expanded_conv/project/BatchNorm/gamma/RMSProp_1] is not available in checkpoint
WARNING:root:Variable [FeatureExtractor/MobilenetV2/expanded_conv/project/weights/ExponentialMovingAverage] is not available in checkpoint
WARNING:root:Variable [FeatureExtractor/MobilenetV2/expanded_conv/project/weights/RMSProp] is not available in checkpoint
WARNING:root:Variable [FeatureExtractor/MobilenetV2/expanded_conv/project/weights/RMSProp_1] is not available in checkpoint
WARNING:root:Variable [FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint
WARNING:root:Variable [FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/BatchNorm/beta/RMSProp] is not available in checkpoint
WARNING:root:Variable [FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint
WARNING:root:Variable [FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint
WARNING:root:Variable [FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/BatchNorm/gamma/RMSProp] is not available in checkpoint
WARNING:root:Variable [FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint
WARNING:root:Variable [FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/depthwise_weights/ExponentialMovingAverage] is not available in checkpoint
WARNING:root:Variable [FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/depthwise_weights/RMSProp] is not available in checkpoint
WARNING:root:Variable [FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/depthwise_weights/RMSProp_1] is not available in checkpoint
WARNING:root:Variable [FeatureExtractor/MobilenetV2/expanded_conv_1/expand/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint
WARNING:root:Variable [FeatureExtractor/MobilenetV2/expanded_conv_1/expand/BatchNorm/beta/RMSProp] is not available in checkpoint
WARNING:root:Variable [FeatureExtractor/MobilenetV2/expanded_conv_1/expand/BatchNorm/beta/RMSProp_1] is not available in checkpoint
WARNING:root:Variable [FeatureExtractor/MobilenetV2/expanded_conv_1/expand/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint
WARNING:root:Variable [FeatureExtractor/MobilenetV2/expanded_conv_1/expand/BatchNorm/gamma/RMSProp] is not available in checkpoint
WARNING:root:Variable [FeatureExtractor/MobilenetV2/expanded_conv_1/expand/BatchNorm/gamma/RMSProp_1] is not available in checkpoint
WARNING:root:Variable [FeatureExtractor/MobilenetV2/expanded_conv_1/expand/weights/ExponentialMovingAverage] is not available in checkpoint
WARNING:root:Variable [FeatureExtractor/MobilenetV2/expanded_conv_1/expand/weights/RMSProp] is not available in checkpoint
WARNING:root:Variable [FeatureExtractor/MobilenetV2/expanded_conv_1/expand/weights/RMSProp_1] is not available in checkpoint
WARNING:root:Variable [FeatureExtractor/MobilenetV2/expanded_conv_1/project/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint
WARNING:root:Variable [FeatureExtractor/MobilenetV2/expanded_conv_1/project/BatchNorm/beta/RMSProp] is not available in checkpoint
WARNING:root:Variable [FeatureExtractor/MobilenetV2/expanded_conv_1/project/BatchNorm/beta/RMSProp_1] is not available in checkpoint
WARNING:root:Variable [FeatureExtractor/MobilenetV2/expanded_conv_1/project/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint
WARNING:root:Variable [FeatureExtractor/MobilenetV2/expanded_conv_1/project/BatchNorm/gamma/RMSProp] is not available in checkpoint
WARNING:root:Variable [FeatureExtractor/MobilenetV2/expanded_conv_1/project/BatchNorm/gamma/RMSProp_1] is not available in checkpoint
WARNING:root:Variable [FeatureExtractor/MobilenetV2/expanded_conv_1/project/weights/ExponentialMovingAverage] is not available in checkpoint
WARNING:root:Variable [FeatureExtractor/MobilenetV2/expanded_conv_1/project/weights/RMSProp] is not available in checkpoint
WARNING:root:Variable [FeatureExtractor/MobilenetV2/expanded_conv_1/project/weights/RMSProp_1] is not available in checkpoint
WARNING:root:Variable [FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint
WARNING:root:Variable [FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/BatchNorm/beta/RMSProp] is not available in checkpoint
WARNING:root:Variable [FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint
WARNING:root:Variable [FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint
WARNING:root:Variable [FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/BatchNorm/gamma/RMSProp] is not available in checkpoint
WARNING:root:Variable [FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint
WARNING:root:Variable [FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/depthwise_weights/ExponentialMovingAverage] is not available in checkpoint
WARNING:root:Variable [FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/depthwise_weights/RMSProp] is not available in checkpoint
WARNING:root:Variable [FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/depthwise_weights/RMSProp_1] is not available in checkpoint
WARNING:root:Variable [FeatureExtractor/MobilenetV2/expanded_conv_10/expand/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint
WARNING:root:Variable [FeatureExtractor/MobilenetV2/expanded_conv_10/expand/BatchNorm/beta/RMSProp] is not available in checkpoint
WARNING:root:Variable [FeatureExtractor/MobilenetV2/expanded_conv_10/expand/BatchNorm/beta/RMSProp_1] is not available in checkpoint
WARNING:root:Variable [FeatureExtractor/MobilenetV2/expanded_conv_10/expand/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint
WARNING:root:Variable [FeatureExtractor/MobilenetV2/expanded_conv_10/expand/BatchNorm/gamma/RMSProp] is not available in checkpoint
WARNING:root:Variable [FeatureExtractor/MobilenetV2/expanded_conv_10/expand/BatchNorm/gamma/RMSProp_1] is not available in checkpoint
WARNING:root:Variable [FeatureExtractor/MobilenetV2/expanded_conv_10/expand/weights/ExponentialMovingAverage] is not available in checkpoint
WARNING:root:Variable [FeatureExtractor/MobilenetV2/expanded_conv_10/expand/weights/RMSProp] is not available in checkpoint
WARNING:root:Variable [FeatureExtractor/MobilenetV2/expanded_conv_10/expand/weights/RMSProp_1] is not available in checkpoint
WARNING:root:Variable [FeatureExtractor/MobilenetV2/expanded_conv_10/project/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint
WARNING:root:Variable [FeatureExtractor/MobilenetV2/expanded_conv_10/project/BatchNorm/beta/RMSProp] is not available in checkpoint
WARNING:root:Variable [FeatureExtractor/MobilenetV2/expanded_conv_10/project/BatchNorm/beta/RMSProp_1] is not available in checkpoint
WARNING:root:Variable [FeatureExtractor/MobilenetV2/expanded_conv_10/project/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint
WARNING:root:Variable [FeatureExtractor/MobilenetV2/expanded_conv_10/project/BatchNorm/gamma/RMSProp] is not available in checkpoint
WARNING:root:Variable [FeatureExtractor/MobilenetV2/expanded_conv_10/project/BatchNorm/gamma/RMSProp_1] is not available in checkpoint
WARNING:root:Variable [FeatureExtractor/MobilenetV2/expanded_conv_10/project/weights/ExponentialMovingAverage] is not available in checkpoint
WARNING:root:Variable [FeatureExtractor/MobilenetV2/expanded_conv_10/project/weights/RMSProp] is not available in checkpoint
WARNING:root:Variable [FeatureExtractor/MobilenetV2/expanded_conv_10/project/weights/RMSProp_1] is not available in checkpoint
....
....
(I omittd many layers warning here)
....
....
WARNING:root:Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint
WARNING:root:Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/BatchNorm/gamma/RMSProp] is not available in checkpoint
WARNING:root:Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/BatchNorm/gamma/RMSProp_1] is not available in checkpoint
WARNING:root:Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/weights] is available in checkpoint, but has an incompatible shape with model variable.
WARNING:root:Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/weights/ExponentialMovingAverage] is not available in checkpoint
WARNING:root:Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/weights/RMSProp] is not available in checkpoint
WARNING:root:Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/weights/RMSProp_1] is not available in checkpoint
WARNING:root:Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint
WARNING:root:Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/BatchNorm/beta/RMSProp] is not available in checkpoint
WARNING:root:Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/BatchNorm/beta/RMSProp_1] is not available in checkpoint
WARNING:root:Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint
WARNING:root:Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/BatchNorm/gamma/RMSProp] is not available in checkpoint
WARNING:root:Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/BatchNorm/gamma/RMSProp_1] is not available in checkpoint
WARNING:root:Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/weights] is available in checkpoint, but has an incompatible shape with model variable.
WARNING:root:Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/weights/ExponentialMovingAverage] is not available in checkpoint
WARNING:root:Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/weights/RMSProp] is not available in checkpoint
WARNING:root:Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/weights/RMSProp_1] is not available in checkpoint
",tanndx17,None,2018-04-10T03:06:48Z,2020-03-05T08:06:37Z,,,,,,,
3920,[deeplab] is there a bug in refine_by_decoder?,"https://github.com/tensorflow/models/blob/aad56e4c428ce9ff5fbb1e9e1b0ef96f1e1fdfd2/research/deeplab/model.py#L560
Is this an indent error, or just on purpose. The second loop (line 560) should not be under the first one(L549)
The first loop (line 549) traverse all the branches in the feature_list.
And the second loop concatenates them together and do the decoder_conv0 and conv1",ruihou,None,2018-04-09T23:41:14Z,2018-04-10T19:47:46Z,,,,,,,
3908,prefetch_to_device does not work with Estimator API ,"### System information
- **What is the top-level directory of the model you are using**:
V:\kaggle\zalando\zaland
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
added one line of custom code
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Windows 10
- **TensorFlow installed from (source or binary)**:
binary
- **TensorFlow version (use command below)**:
b'unknown' 1.8.0-dev20180329
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
9.0/7
- **GPU model and memory**:
1080TI
- **Exact command to reproduce**:
I run model from 
https://github.com/tensorflow/models/blob/master/official/mnist/mnist.py
and just added at the end of the `train_input_fn()`
```
ds = ds.apply(tf.contrib.data.prefetch_to_device(""/gpu:0""))
```

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Is there a plan to enable `prefetch_to_device` in Estimator API?

### Source code / logs
```
PS V:\kaggle\zalando\zalando> cd 'v:\kaggle\zalando\zalando'; ${env:PYTHONIOENCODING}='UTF-8'; ${env:PYTHONUNBUFFERED}='1'; & 'C:\ProgramData\Anaconda3\python.exe' 'C:\Users\Marcin\.vscode\extensions\ms-python.python-2018.3.1\pythonFiles\PythonTools\visualstudio_py_launcher_nodebug.py' 'v:\kaggle\zalando\zalando' '53728' '34806ad9-833a-4524-8cd6-18ca4aa74f14' 'RedirectOutput,RedirectOutput' 'v:\kaggle\zalando\zalando\mnist_official.py'
C:\ProgramData\Anaconda3\lib\site-packages\h5py\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
INFO:tensorflow:Using default config.
INFO:tensorflow:Using config: {'_model_dir': '/tmp/mnist_model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000001F27714EA90>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
Downloading https://storage.googleapis.com/cvdf-datasets/mnist/train-images-idx3-ubyte.gz to /tmp/mnist_data\train-images-idx3-ubyte.gz
Downloading https://storage.googleapis.com/cvdf-datasets/mnist/train-labels-idx1-ubyte.gz to /tmp/mnist_data\train-labels-idx1-ubyte.gz
WARNING:tensorflow:From C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\contrib\learn\python\learn\datasets\base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.
Instructions for updating:
Use the retry module or similar alternatives.
Traceback (most recent call last):  File ""C:\Users\Marcin\.vscode\extensions\ms-python.python-2018.3.1\pythonFiles\PythonTools\visualstudio_py_launcher_nodebug.py"", line 74, in run
    _vspu.exec_file(file, globals_obj)
  File ""C:\Users\Marcin\.vscode\extensions\ms-python.python-2018.3.1\pythonFiles\PythonTools\visualstudio_py_util.py"", line 119, in exec_file
    exec_code(code, file, global_variables)
  File ""C:\Users\Marcin\.vscode\extensions\ms-python.python-2018.3.1\pythonFiles\PythonTools\visualstudio_py_util.py"", line 95, in exec_code
    exec(code_obj, global_variables)
  File ""v:\kaggle\zalando\zalando\mnist_official.py"", line 267, in <module>
    main(argv=sys.argv)
  File ""v:\kaggle\zalando\zalando\mnist_official.py"", line 235, in main
    mnist_classifier.train(input_fn=train_input_fn, hooks=train_hooks)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\estimator\estimator.py"", line 356, in train
    loss = self._train_model(input_fn, hooks, saving_listeners)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\estimator\estimator.py"", line 825, in _train_model
    input_fn, model_fn_lib.ModeKeys.TRAIN))
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\estimator\estimator.py"", line 687, in _get_features_and_labels_from_input_fn
    iterator = result.make_initializable_iterator()
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\contrib\data\python\ops\prefetching_ops.py"", line 145, in make_initializable_iterator
    raise NotImplementedError(""`prefetch_to_device()` is not currently ""
NotImplementedError: `prefetch_to_device()` is not currently compatible with initializable iterators. Use `make_one_shot_iterator()` instead.
```",mpekalski,b'stat:awaiting maintainer',2018-04-07T21:53:56Z,2018-04-09T14:21:31Z,,,,,,,
3893,I have installed the jupyter by using pip3 install jupyter. But jupyter notebook home page  is not opening while providing the  command       C:\Users\hp\Downloads\models\research\object_detection>jupyter notebook in my cmd .Can you please help me?,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",smartcap123,None,2018-04-06T12:40:09Z,2018-04-11T17:47:44Z,,,,,,,
3886,[DeepLab] Shape mismatch only for validation set with new dataset,"**System information**

- What is the top-level directory of the model you are using: /deeplab
- Have I written custom code: yes
- TensorFlow installed from: binary
- TensorFlow version: 1.6
- CUDA/cuDNN version: 9.1
- GPU model and memory: K80 12 GB

**Problem Description**

I' m trying to finetune deeplab3+ with a new dataset (with a different number of classes).
I converted the dataset to tfrecords (training and validation) and started to train the model without problems using train.py. 
Now I want to evaluate the new checkpoint, running the evaluation script eval.py, and I obtain a shape mismatch error.

```bash
tensorflow.python.framework.errors_impl.InvalidArgumentError: Shape mismatch in tuple component 1. Expected [513,513,3], got [2448,2448,3]
 [[Node: batch/padding_fifo_queue_enqueue = QueueEnqueueV2[Tcomponents=[DT_INT64, DT_FLOAT, DT_STRING, DT_INT32, DT_UINT8, DT_INT64], timeout_ms=-1, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](batch/padding_fifo_queue, Reshape_3/_4659, add_2/_4661, Reshape_1, add_3/_4663, case/cond/Merge/_4665, Reshape_6/_4667)]]
```

The problem seems to be inside the evaluation cycle in eval.py

```python
slim.evaluation.evaluation_loop(
    master=FLAGS.master,
    checkpoint_dir=FLAGS.checkpoint_dir,
    logdir=FLAGS.eval_logdir,
    num_evals=num_batches,
    eval_op=list(metrics_to_updates.values()),
    max_number_of_evaluations=num_eval_iters,
    eval_interval_secs=FLAGS.eval_interval_secs,
    hooks=[tf_debug.LocalCLIDebugHook()]))
```

I don't understand this error because the preprocessing seems the same (crop and resize).
I tried also to use the tensorflow debugger without success.

I'm running

```python
python ""${WORK_DIR}""/train.py \
  --logtostderr \
  --save_summaries_secs=100 \
  --train_split=""training"" \
  --model_variant=""xception_65"" \
  --atrous_rates=6 \
  --atrous_rates=12 \
  --atrous_rates=18 \
  --output_stride=16 \
  --decoder_output_stride=4 \
  --train_crop_size=513 \
  --train_crop_size=513 \
  --train_batch_size=4 \
  --training_number_of_steps=""${NUM_ITERATIONS}"" \
  --dataset=""mapillary"" \
  --fine_tune_batch_norm=false \
  --tf_initial_checkpoint=""${INIT_FOLDER}/deeplabv3_pascal_train_aug/model.ckpt"" \
  --initialize_last_layer=false \
  --train_logdir=""${TRAIN_LOGDIR}"" \
  --dataset_dir=""${NEW_DATASET}""
```

and 

```python
python ""${WORK_DIR}""/eval.py \
  --logtostderr \
  --eval_split=""validation"" \
  --model_variant=""xception_65"" \
  --atrous_rates=6 \
  --atrous_rates=12 \
  --atrous_rates=18 \
  --output_stride=16 \
  --decoder_output_stride=4 \
  --eval_crop_size=513 \
  --eval_crop_size=513 \
  --dataset=""mapillary"" \
  --checkpoint_dir=""${TRAIN_LOGDIR}"" \
  --eval_logdir=""${EVAL_LOGDIR}"" \
  --dataset_dir=""${NEW_DATASET}"" \
  --max_number_of_evaluations=1
```

I don't know if I' m doing something wrong with the data conversion or there is some problem with the code.",georgosgeorgos,None,2018-04-05T16:19:17Z,2020-04-25T15:07:14Z,,,,,,,
3884,cannot get the same mAP for SSD MobileNet as provided in official table,"### System information
- **What is the top-level directory of the model you are using**: models/research/object_detection
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No.
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.6
- **Bazel version (if compiling from source)**: /
- **CUDA/cuDNN version**: 9.0 / 7.0.5
- **GPU model and memory**: GTX 1080 Ti, 11GB
- **Exact command to reproduce**: 

python object_detection/eval.py \
        --logtostderr \
        --checkpoint_dir=ssd_mobilenet_v1_coco_2017_11_17 \
        --eval_dir=$eval_dir \
        --pipeline_config_path=object_detection/samples/configs/ssd_mobilenet_v1_coco.config

### Describe the problem
First bug, I cannot even evaluate model ssd_mobilenet_v1_coco_2017_11_17 without adding ""metrics_set: coco_detection_metrics"" in eval_config{} in object_detection/samples/configs/ssd_mobilenet_v1_coco.config

More important,  I got mAP: 26, not 21 as in the offical table. Also for ssd_mobilenet_v2_coco_2018_03_29 I got 25, not 22 as in the official table.
Evaluation was on: COCO  val_2017 (tfRecords are created by provided script ./object_detection/dataset_tools/download_and_preprocess_mscoco.sh )

Link on the official table: https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md

### Source code / logs
here is my output: 

INFO:tensorflow:depth of additional conv before box predictor: 0
INFO:tensorflow:depth of additional conv before box predictor: 0
INFO:tensorflow:depth of additional conv before box predictor: 0
INFO:tensorflow:depth of additional conv before box predictor: 0
INFO:tensorflow:depth of additional conv before box predictor: 0
INFO:tensorflow:depth of additional conv before box predictor: 0
INFO:tensorflow:Restoring parameters from tiris/ssd_mobilenet_v1_coco_2017_11_17/model.ckpt
INFO:tensorflow:Restoring parameters from tiris/ssd_mobilenet_v1_coco_2017_11_17/model.ckpt
creating index...
index created!
INFO:tensorflow:Loading and preparing annotation results...
INFO:tensorflow:Loading and preparing annotation results...
INFO:tensorflow:DONE (t=0.39s)
INFO:tensorflow:DONE (t=0.39s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=71.17s).
Accumulating evaluation results...
DONE (t=11.80s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.263
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.419
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.279
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.016
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.132
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.508
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.238
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.342
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.362
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.042
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.253
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.643



",dextroza,b'stat:awaiting model gardener',2018-04-05T14:28:46Z,2020-02-07T18:44:39Z,,,,,,,
3876,Training SSD Inception network with COCO-Text API,"
### System information
- **Top level directory: ~/models/research/object-detection**:
- **A custom code similar to found [here](https://github.com/offbye/tensorflow_object_detection_create_coco_tfrecord/blob/master/README.md)**
- **Linux Ubuntu 16.04**
- **TensorFlow install: From pip wheel**
- **1.5.0**
- **CUDA: 9.0 / CuDNN: 7.0**
- **GPU: Gtx1080(8GB)**
- **Python:3.5.4**

### Description of the problem
I created my tfrecords using the `coco-text` API and since I'm detecting only one class I just set the label to 1. When I run `python object_detection/train.py --logtostderr --pipeline_config_path object_detection/ssd_inception_v2_cocotxt.config --out_dir log_dir` I get the following error: 
```
shape[0] = [1,46] vs. shape[1] = [1,23]
	 [[Node: concat = ConcatV2[N=4, T=DT_FLOAT, Tidx=DT_INT32, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](ExpandDims, ExpandDims_1, ExpandDims_2, ExpandDims_3, Equal_4/y)]]
INFO:tensorflow:Caught OutOfRangeError. Stopping Training.

```

I have set my `batch_size` to 1 as well. The relevant portion of my code that's creating the tfrecord is: 
```
 bboxes = img_data['bboxes']
    xmins = []
    xmaxs = []
    ymins = []
    ymaxs = []
    
    # the coco format is [left,top,width,height]

    for bbox in bboxes:
        xmins.append(bbox[0])
        xmaxs.append(bbox[0] + bbox[2]) # 
        ymins.append(bbox[1])
        ymins.append(bbox[1] + bbox[3])

    example =  tf.train.Example(features=tf.train.Features(feature={
        'image/height':dataset_util.int64_feature(img_data['height']),
        'image/width':dataset_util.int64_feature(img_data['width']),
        'image/object/bbox/xmin':dataset_util.float_list_feature(xmins),
        'image/object/bbox/xmax':dataset_util.float_list_feature(xmaxs),
        'image/object/bbox/ymin':dataset_util.float_list_feature(ymins),
        'image/object/bbox/ymax':dataset_util.float_list_feature(ymaxs),
        'image/object/class/label':dataset_util.int64_list_feature(img_data['labels']),
        'image/object/class/text':dataset_util.bytes_list_feature(img_data['text']),
        'image/encoded':dataset_util.bytes_feature(img_data['data']),
        'image/format':dataset_util.bytes_feature('jpeg'.encode('utf-8')) 

    }))

    return example

```
Another interesting aspect is that `ConcatOp` fails with size mismatch of different sizes each time (size[0] and size[1]) are different each time. I am at a loss to where to localize this error to even begin debugging. So any help will be appreciated. ",aicaffeinelife,None,2018-04-04T17:50:28Z,2020-01-30T04:37:30Z,,,,,,,
3874,(locally trained) frozen_inference_graph.pb != (pre-trained) frozen_inference_graph.pb,"I am attempting to retrain mobilenet ssd v1 from my own training procedure. My goal is to deploy this on a qualcomm snapdragon chip. The original (pretrained) model that is available from the model zoo can be easily deployed. However, if I retrain the model locally, I have issues with the deployment. I've been analysing the computational graphs using Tensorboard, and I can see that they aren't identical. Is this a bug?

Here is the exported graph for the locally trained model:
https://ibb.co/hBB0ux

Here is the exported graph for the pretrained model:
https://ibb.co/eVv4Mc",dsimmoAnyVision,b'stat:awaiting response',2018-04-04T14:11:45Z,2018-04-05T15:54:05Z,,,,,,,
3777,Bug fix on flag name in wide_deep.py,PR #3650 renamed FLAGS.epochs_per_eval to flags.epochs_between_evals; it missed this one,nkconnor,b'cla: yes',2018-03-27T19:14:25Z,2018-03-27T22:03:48Z,,,,,,,
3748,TypeError: string indices must be integers,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",fera0013,None,2018-03-26T10:04:22Z,2018-11-30T22:20:38Z,,,,,,,
3747,Tensorboard Learning rate has disappeared after the update!,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------


### System information
- **What is the top-level directory of the model you are using**: **models/research**
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:no
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: Tensorflow-gpu source
- **TensorFlow version (use command below)**: 1.6.0
- **Bazel version (if compiling from source)**:not used
- **CUDA/cuDNN version**: 9.0.176 / 7.0
- **GPU model and memory**: Titan XP
- **Exact command to reproduce**: tensorboard --logdir=path/to/events.out.* --inspect

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.
Hello, my problem is that whenever I open up tensorboard, I couldn't find learning rate scalar value in my tensorboard after I updated the object detection api a month ago. (Feburary)




![image](https://user-images.githubusercontent.com/13467628/37894976-f150606e-311a-11e8-8231-c86f51ffa6df.png)

<before>


![image](https://user-images.githubusercontent.com/13467628/37894971-eaec77da-311a-11e8-99d0-1acd14429b4b.png)

<after>


as you can see in the pictures above, learning rate has been disappeared!! T.T
Can somebody tell me where should I change the code ??
I searched for models/research/object_detection/trainer.py part (specially, tf.add.summary and tf.scalar) but, there was no difference between after / before.

Thanks in advance!
### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",BloomBerry,None,2018-03-26T08:17:56Z,2019-02-20T21:47:13Z,,,,,,,
3743,I'm getting a permission error when i run the object_detection_tutorial. Not sure why. ,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",cmbowyer13,None,2018-03-25T17:42:34Z,2018-03-25T18:00:31Z,,,,,,,
3724,mnist_tpu.py errors,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
official/mnist

- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
No

- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Linux tpu-vm 4.9.0-6-amd64 #1 SMP Debian 4.9.82-1+deb9u3 (2018-03-02) x86_64 GNU/Linux
This is GCP vm and configured to use TPU

- **TensorFlow installed from (source or binary)**:
use ``` ml-images ``` while creating vm

- **TensorFlow version (use command below)**:
1.6.0 ('v1.6.0-0-gd2e24b6039')

- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

('v1.6.0-0-gd2e24b6039', '1.6.0')

### Describe the problem
While running mnist.py works, but ``` mnist_tpu.py --tpu_name '<tpu_name>' ``` gives error below,

### Source code / logs

$ python mnist_tpu.py  --tpu_name 'tpu-node-1'
/usr/local/lib/python2.7/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `n
p.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpPrbzhd
INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true
log_device_placement: true
, '_keep_checkpoint_max': 5, '_task_type': 'worker', '_global_id_in_cluster': 0, '_is_chief': True, '_cluster_spec': <tensorflow.python.train
ing.server_lib.ClusterSpec object at 0x7f0cd7de4810>, '_evaluation_master': u'grpc://10.240.1.2:8470', '_save_checkpoints_steps': None, '_kee
p_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tpu_config': TPUConfig(iterations_per_loop=50, num_shards=8, p
er_host_input_for_training=True, tpu_job_name=None, initial_infeed_sleep_secs=None), '_tf_random_seed': None, '_master': u'grpc://10.240.1.2:
8470', '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_model_dir': '/tmp/tmpPrbzhd', '_save_summary_steps': 100}
INFO:tensorflow:Calling model_fn.
Downloading https://storage.googleapis.com/cvdf-datasets/mnist/train-images-idx3-ubyte.gz to train-images-idx3-ubyte.gz
Downloading https://storage.googleapis.com/cvdf-datasets/mnist/train-labels-idx1-ubyte.gz to train-labels-idx1-ubyte.gz
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
INFO:tensorflow:TPU job name tpu_worker
INFO:tensorflow:Graph was finalized.
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Init TPU system
INFO:tensorflow:Start infeed thread controller
INFO:tensorflow:Starting infeed thread controller.
INFO:tensorflow:Start outfeed thread controller
INFO:tensorflow:Starting outfeed thread controller.
INFO:tensorflow:Enqueue next (50) batch(es) of data to infeed.
INFO:tensorflow:Dequeue next (50) batch(es) of data from outfeed.
WARNING:tensorflow:
Error occurred during infeed/outfeed.  This may be due to a compile error in the main session.  Waiting for a short time for the main session
 to come back.
File system scheme '[local]' not implemented (file: 'train-images-idx3-ubyte')
         [[Node: input_pipeline_task0/IteratorGetNext = IteratorGetNext[output_shapes=[[1024,784], [1024]], output_types=[DT_FLOAT, DT_INT32]
, _device=""/job:tpu_worker/replica:0/task:0/device:CPU:0""](input_pipeline_task0/OneShotIterator)]]
Caused by op u'input_pipeline_task0/IteratorGetNext', defined at:
  File ""mnist_tpu.py"", line 176, in <module>
    tf.app.run()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 126, in run
UnimplementedError (see above for traceback): File system scheme '[local]' not implemented (file: 'train-images-idx3-ubyte')
    _sys.exit(main(argv))
  File ""mnist_tpu.py"", line 166, in main
    estimator.train(input_fn=train_input_fn, max_steps=FLAGS.train_steps)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py"", line 352, in train
    loss = self._train_model(input_fn, hooks, saving_listeners)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py"", line 812, in _train_model
    features, labels, model_fn_lib.ModeKeys.TRAIN, self.config)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py"", line 793, in _call_model_fn
    model_fn_results = self._model_fn(features=features, **kwargs)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/tpu/python/tpu/tpu_estimator.py"", line 2065, in _model_fn
    input_holders.generate_infeed_enqueue_ops_and_dequeue_fn())
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/tpu/python/tpu/tpu_estimator.py"", line 1149, in generate_infeed_enqueue_ops_and_dequeue_fn
    self._invoke_input_fn_and_record_structure())
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/tpu/python/tpu/tpu_estimator.py"", line 1202, in _invoke_input_fn_and_record_structure
    self._batch_axis, host_device))
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/tpu/python/tpu/tpu_estimator.py"", line 918, in generate_per_host_enqueue_ops_fn_for_host
    inputs = _Inputs.from_input_fn(input_fn())
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/tpu/python/tpu/tpu_estimator.py"", line 2036, in _input_fn
    return input_fn(**kwargs)
  File ""mnist_tpu.py"", line 116, in train_input_fn
    images, labels = ds.make_one_shot_iterator().get_next()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/data/ops/iterator_ops.py"", line 330, in get_next
    name=name)), self._output_types,
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_dataset_ops.py"", line 866, in iterator_get_next
    output_shapes=output_shapes, name=name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py"", line 787, in _apply_op_helper
    op_def=op_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 3271, in create_op
    op_def=op_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 1650, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access

UnimplementedError (see above for traceback): File system scheme '[local]' not implemented (file: 'train-images-idx3-ubyte')
         [[Node: input_pipeline_task0/IteratorGetNext = IteratorGetNext[output_shapes=[[1024,784], [1024]], output_types=[DT_FLOAT, DT_INT32], _device=""/job:tpu_worker/replica:0/task:0/device:CPU:0""](input_pipeline_task0/OneShotIterator)]]

ERROR:tensorflow:Feed error: Traceback (most recent call last):
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/tpu/python/tpu/tpu_estimator.py"", line 666, in _run_infeed
    session.run(self._enqueue_ops)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 905, in run
    run_metadata_ptr)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1137, in _run
    feed_dict_tensor, options, run_metadata)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1355, in _do_run
    options, run_metadata)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1374, in _do_call
    raise type(e)(node_def, op, message)
UnimplementedError: File system scheme '[local]' not implemented (file: 'train-images-idx3-ubyte')
         [[Node: input_pipeline_task0/IteratorGetNext = IteratorGetNext[output_shapes=[[1024,784], [1024]], output_types=[DT_FLOAT, DT_INT32], _device=""/job:tpu_worker/replica:0/task:0/device:CPU:0""](input_pipeline_task0/OneShotIterator)]]

Caused by op u'input_pipeline_task0/IteratorGetNext', defined at:
  File ""mnist_tpu.py"", line 176, in <module>
    tf.app.run()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 126, in run
    _sys.exit(main(argv))
  File ""mnist_tpu.py"", line 166, in main
    estimator.train(input_fn=train_input_fn, max_steps=FLAGS.train_steps)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py"", line 352, in train
    loss = self._train_model(input_fn, hooks, saving_listeners)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py"", line 812, in _train_model
    features, labels, model_fn_lib.ModeKeys.TRAIN, self.config)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py"", line 793, in _call_model_fn
    model_fn_results = self._model_fn(features=features, **kwargs)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/tpu/python/tpu/tpu_estimator.py"", line 2065, in _model_fn
    input_holders.generate_infeed_enqueue_ops_and_dequeue_fn())
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/tpu/python/tpu/tpu_estimator.py"", line 1149, in generate_infeed_enqueue_ops_and_dequeue_fn
    self._invoke_input_fn_and_record_structure())
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/tpu/python/tpu/tpu_estimator.py"", line 1202, in _invoke_input_fn_and_record_structure
    self._batch_axis, host_device))
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/tpu/python/tpu/tpu_estimator.py"", line 918, in generate_per_host_enqueue_ops_fn_for_host
    inputs = _Inputs.from_input_fn(input_fn())
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/tpu/python/tpu/tpu_estimator.py"", line 2036, in _input_fn
    return input_fn(**kwargs)
  File ""mnist_tpu.py"", line 116, in train_input_fn
    images, labels = ds.make_one_shot_iterator().get_next()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/data/ops/iterator_ops.py"", line 330, in get_next
    name=name)), self._output_types,
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_dataset_ops.py"", line 866, in iterator_get_next
    output_shapes=output_shapes, name=name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py"", line 787, in _apply_op_helper
    op_def=op_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 3271, in create_op
    op_def=op_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 1650, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access

UnimplementedError (see above for traceback): File system scheme '[local]' not implemented (file: 'train-images-idx3-ubyte')
         [[Node: input_pipeline_task0/IteratorGetNext = IteratorGetNext[output_shapes=[[1024,784], [1024]], output_types=[DT_FLOAT, DT_INT32], _device=""/job:tpu_worker/replica:0/task:0/device:CPU:0""](input_pipeline_task0/OneShotIterator)]]",hyoo,None,2018-03-23T21:27:59Z,2019-03-02T14:21:18Z,,,,,,,
3718,load_image_into_numpy_array to handle png images,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
load_image_into_numpy_array(image) raises ValueError when the given image format is png. 
The workaround I found is to convert the image to 'RGB'.


### Source code / logs
Traceback (most recent call last):
  File ""object_detection_debug.py"", line 202, in <module>
    image_np = load_image_into_numpy_array(image)
  File ""object_detection_debug.py"", line 151, in load_image_into_numpy_array
    (im_height, im_width, 3)).astype(np.uint8)
ValueError: cannot reshape array of size 3418200 into shape (675,1266,3)

So I added below codes in the function and it handles the given png images.
if image.format == ""PNG"":
          image = image.convert('RGB')",pinkbunny1,None,2018-03-23T14:50:12Z,2018-03-23T15:20:03Z,,,,,,,
3717,Fail to build word2vec.so as  there does not exists tf.sysconfig.get_compile_flags() in tensorflow v1.4,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",lxcheng,None,2018-03-23T11:16:24Z,2018-11-21T21:52:45Z,,,,,,,
3716,INFO:tensorflow:Error reported to Coordinator: Nan in summary histogram for: image_pooling/BatchNorm/moving_variance_1,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**:binary
- **TensorFlow version (use command below)**:1.6-gpu
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:9.0/7.0
- **GPU model and memory**:11G
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

When I run local_test.sh,i only modify --***_crop_size to 1000,then the error comes out:

# ## **_INFO:tensorflow:Error reported to Coordinator: Nan in summary histogram for: image_pooling/BatchNorm/moving_variance_1
	 [[Node: image_pooling/BatchNorm/moving_variance_1 = HistogramSummary[T=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](image_pooling/BatchNorm/moving_variance_1/tag, image_pooling/BatchNorm/moving_variance/read)]]
	 [[Node: xception_65/middle_flow/block1/unit_13/xception_module/separable_conv3_pointwise/weights/read/_617 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device_incarnation=1, tensor_name=""edge_2728_...ights/read"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:GPU:0""]()]]

Caused by op u'image_pooling/BatchNorm/moving_variance_1', defined at:
  File ""/home/george/project/deeplabv3/models-master/research/deeplab/train.py"", line 347, in <module>
    tf.app.run()
  File ""/home/george/anaconda2/lib/python2.7/site-packages/tensorflow/python/platform/app.py"", line 126, in run
    _sys.exit(main(argv))
  File ""/home/george/project/deeplabv3/models-master/research/deeplab/train.py"", line 268, in main
    summaries.add(tf.summary.histogram(model_var.op.name, model_var))
  File ""/home/george/anaconda2/lib/python2.7/site-packages/tensorflow/python/summary/summary.py"", line 193, in histogram
    tag=tag, values=values, name=scope)
  File ""/home/george/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/gen_logging_ops.py"", line 189, in _histogram_summary
    ""HistogramSummary"", tag=tag, values=values, name=name)
  File ""/home/george/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py"", line 787, in _apply_op_helper
    op_def=op_def)
  File ""/home/george/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 3271, in create_op
    op_def=op_def)
  File ""/home/george/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 1650, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access_**

What is the reason? 1000 is too large?If I want to use the model to test 1920*1080 size image,how can I do?
I am looking forward to your response,thank you!

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",GeorgeBohw,None,2018-03-23T10:54:23Z,2019-04-28T09:45:45Z,,,,,,,
3715,bug？ImportError: No module named mobilenet,"When I try to test the installation of object detection API with commond:
python object_detection/builders/model_builder_test.py
It reports the error: 
    from nets.mobilenet import mobilenet
ImportError: No module named mobilenet

But If I use the same code like:
from nets.nasnet import nasnet
It never report any error.

In my opinion, the mobilenet and nasnet have the same role, can you explain this?

",liu09114,None,2018-03-23T09:06:08Z,2018-03-26T07:08:26Z,,,,,,,
3696,"deeplab.  hi, I want to reproduce deeplabv3+ result, but in the help document, I only get the pretrained model which trained on ImageNet, Could you please provide the pretrained model  which trianed on MS COCO and voc aug dataset?","Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",zuotianyoumeng,None,2018-03-22T07:55:49Z,2018-11-17T20:19:34Z,,,,,,,
3695,tensorflow.python.framework.errors_impl.InvalidArgumentError: padded_shape[1]=128 is not divisible by block_shape[1]=12,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:deeplabv3_pascal_trainval
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**:binary
- **TensorFlow version (use command below)**:1.6
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:9.0/7.0
- **GPU model and memory**:11G
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.
When I run ""Jupyter notebook for off-the-shelf inference."",Set the INPUT_SIZE=769 which tell the code to resie the input image.When run the code,error comeout:

Caused by op u'aspp1_depthwise/depthwise/SpaceToBatchND', defined at:
  File ""mytry.py"", line 130, in <module>
    model = DeepLabModel(download_path)
  File ""mytry.py"", line 98, in __init__
    tf.import_graph_def(graph_def, name='')
  File ""/home/george/anaconda2/lib/python2.7/site-packages/tensorflow/python/util/deprecation.py"", line 432, in new_func
    return func(*args, **kwargs)
  File ""/home/george/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/importer.py"", line 553, in import_graph_def
    op_def=op_def)
  File ""/home/george/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 3271, in create_op
    op_def=op_def)
  File ""/home/george/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 1650, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access

InvalidArgumentError (see above for traceback): padded_shape[1]=128 is not divisible by block_shape[1]=12
	 [[Node: aspp1_depthwise/depthwise/SpaceToBatchND = SpaceToBatchND[T=DT_FLOAT, Tblock_shape=DT_INT32, Tpaddings=DT_INT32, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](xception_65/exit_flow/block2/unit_1/xception_module/separable_conv3_pointwise/Relu, aspp1_depthwise/depthwise/SpaceToBatchND/block_shape, aspp1_depthwise/depthwise/SpaceToBatchND/paddings)]]
	 [[Node: ArgMax/_37 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device_incarnation=1, tensor_name=""edge_1637_ArgMax"", tensor_type=DT_INT64, _device=""/job:localhost/replica:0/task:0/device:CPU:0""]()]]

Can't I process arbitrary size of image?


### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",GeorgeBohw,None,2018-03-22T07:50:04Z,2020-04-30T18:57:00Z,,,,,,,
3692,fix bugs in Python 3.X,fix this issue https://github.com/tensorflow/models/issues/2948,ewanlee,b'cla: yes',2018-03-22T04:35:58Z,2018-03-22T04:48:29Z,,,,,,,
3681,deeplabv3+ deeplab_demo.ipynb why always download model every run,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:deeplabv3_pascal_trainval(is it v3+?)
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:ubuntu16.04
- **TensorFlow installed from (source or binary)**:binary
- **TensorFlow version (use command below)**:v1.5 gpu
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:9.0/7.0
- **GPU model and memory**:11G
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.
Everytime i run ""deeplab_demo.ipynb"",It always download model again which cost time when net speed is under bad condition,so why not just download once.

And i want to ask ---is ""deeplabv3_pascal_trainval "" deeplabv3+ model?why it cost me about 1.8s when i use NVIDAI GTX 1080Ti to run a image in 513*288 resolution?

Thanks for ur response. 


### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",GeorgeBohw,None,2018-03-21T09:58:36Z,2018-03-22T07:20:53Z,,,,,,,
3680,TypeError: Failed to convert object of type <type 'list'> to Tensor. ,"os:redhat7.3   cuda8.0  cudnn6.0  tensorflow_gpu1.3  p100*8
[root@tensorflow cifar10]# python cifar10_multi_gpu_train.py 
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
Traceback (most recent call last):
  File ""cifar10_multi_gpu_train.py"", line 277, in <module>
    tf.app.run()
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/platform/app.py"", line 48, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""cifar10_multi_gpu_train.py"", line 273, in main
    train()
  File ""cifar10_multi_gpu_train.py"", line 178, in train
    loss = tower_loss(scope, image_batch, label_batch)
  File ""cifar10_multi_gpu_train.py"", line 78, in tower_loss
    logits = cifar10.inference(images)
  File ""/home/tensorflow-models/models-master/tutorials/image/cifar10/cifar10.py"", line 243, in inference
    reshape = tf.reshape(pool2, [images.get_shape()[0], -1])
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/ops/gen_array_ops.py"", line 2619, in reshape
    name=name)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py"", line 493, in apply_op
    raise err
TypeError: Failed to convert object of type <type 'list'> to Tensor. Contents: [Dimension(128), -1]. Consider casting elements to a supported type.


------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",xshow-xs,None,2018-03-21T09:09:09Z,2018-11-30T22:23:19Z,,,,,,,
3655,tensorflow module not found error   ,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",chiran7,None,2018-03-19T23:04:48Z,2020-02-02T22:04:43Z,,,,,,,
3653,ResNet argparse fixes.,"As noted, imagenet can no longer just use the default number of train_epochs. This PR explicitly sets it back to 100, and also fixes a bug related to ""-h"" being inadvertently caught by tf.app.run().",robieta,b'cla: yes',2018-03-19T20:55:25Z,2018-03-20T20:32:17Z,,,,,,,
3631,[deeplab] POSTFIX wrong in cityscapes,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
deeplab
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.6.0
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**: 9.0 
- **GPU model and memory**: GTX 1060
- **Exact command to reproduce**: sh convert_cityscapes.sh

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
The _POSTFIX_MAP dictionary on build_cityscapes_data.py script is making the script look for files that do not exist, because the termination of the label's files is wrong from what can be downloaded form the cityscapes page:

```
_POSTFIX_MAP = {
    'image': '_leftImg8bit',
    'label': '_gtFine_labelTrainIds',
}
```

should be

```
_POSTFIX_MAP = {
    'image': '_leftImg8bit',
    'label': '_gtFine_labelIds',
}
```

### Source code / logs

",srcolinas,None,2018-03-17T01:15:01Z,2018-10-27T01:30:50Z,,,,,,,
3629,SSD Resnet50 FPN ValueError: Dimensions must be equal,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: custom .config file, see below
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: 1.7-rc0 and also tried on 1.6
- **Python version**: Tried 2.7 and 3.5
- **Bazel version (if compiling from source)**: 0.11.1
- **GCC/Compiler version (if compiling from source)**: gcc (Ubuntu 5.4.0-6ubuntu1~16.04.9) 5.4.0 20160609
- **CUDA/cuDNN version**: 8.0 / 6.0
- **GPU model and memory**: GeForce GTX 1060 6GB
- **Exact command to reproduce**: 
```
python3 object_detection/train.py \
    --pipeline_config_path=object_detection/samples/ssd_resnet_50_fpn_drone.config \
    --train_dir=object_detection/drone \
    --num_clones=1
```

When I'm trying to run test FPN config from model_builder_test.py (see attach), I'm getting error:
```
WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.
Instructions for updating:
Use the retry module or similar alternatives.
WARNING:tensorflow:From /home/undead/reps/tf_models/object_detection/trainer.py:228: create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Please switch to tf.train.create_global_step
Traceback (most recent call last):
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/common_shapes.py"", line 686, in _call_cpp_shape_fn_impl
    input_tensors_as_shapes, status)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/errors_impl.py"", line 516, in __exit__
    c_api.TF_GetCode(self.status.status))
tensorflow.python.framework.errors_impl.InvalidArgumentError: Dimensions must be equal, but are 6 and 5 for 'FeatureExtractor/fpn/top_down_features/add' (op: 'Add') with input shapes: [4,6,6,256], [4,5,5,256].

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""object_detection/train.py"", line 167, in <module>
    tf.app.run()
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/platform/app.py"", line 126, in run
    _sys.exit(main(argv))
  File ""object_detection/train.py"", line 163, in main
    worker_job_name, is_chief, FLAGS.train_dir)
  File ""/home/undead/reps/tf_models/object_detection/trainer.py"", line 246, in train
    clones = model_deploy.create_clones(deploy_config, model_fn, [input_queue])
  File ""/home/undead/reps/tf_models/slim/deployment/model_deploy.py"", line 193, in create_clones
    outputs = model_fn(*args, **kwargs)
  File ""/home/undead/reps/tf_models/object_detection/trainer.py"", line 179, in _create_losses
    prediction_dict = detection_model.predict(images, true_image_shapes)
  File ""/home/undead/reps/tf_models/object_detection/meta_architectures/ssd_meta_arch.py"", line 350, in predict
    preprocessed_inputs)
  File ""/home/undead/reps/tf_models/object_detection/models/ssd_resnet_v1_fpn_feature_extractor.py"", line 164, in extract_features
    scope='top_down_features')
  File ""/home/undead/reps/tf_models/object_detection/models/feature_map_generators.py"", line 217, in fpn_top_down_feature_maps
    top_down = 0.5 * top_down + 0.5 * residual
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py"", line 971, in binary_op_wrapper
    return func(x, y, name=name)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gen_math_ops.py"", line 296, in add
    ""Add"", x=x, y=y, name=name)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py"", line 787, in _apply_op_helper
    op_def=op_def)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py"", line 3292, in create_op
    compute_device=compute_device)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py"", line 3332, in _create_op_helper
    set_shapes_for_outputs(op)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py"", line 2496, in set_shapes_for_outputs
    return _set_shapes_for_outputs(op)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py"", line 2469, in _set_shapes_for_outputs
    shapes = shape_func(op)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py"", line 2399, in call_with_requiring
    return call_cpp_shape_fn(op, require_shape_fn=True)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/common_shapes.py"", line 627, in call_cpp_shape_fn
    require_shape_fn)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/common_shapes.py"", line 691, in _call_cpp_shape_fn_impl
    raise ValueError(err.message)
ValueError: Dimensions must be equal, but are 6 and 5 for 'FeatureExtractor/fpn/top_down_features/add' (op: 'Add') with input shapes: [4,6,6,256], [4,5,5,256].
```
model_builder_test.py and ssd_resnet_v1_fpn_feature_extractor_test.py passes on Python2.7.
Tried TF 1.6 and 1.7, Python 2.7 and 3.5, tried different input resolutions. All the same. Seems like a bug.

[ssd_resnet_50_fpn_drone.config.zip](https://github.com/tensorflow/tensorflow/files/1819317/ssd_resnet_50_fpn_drone.config.zip)",UndeadBlow,None,2018-03-16T14:30:11Z,2020-06-12T10:09:31Z,,,,,,,
3570,Build ImageNet TFRecord,"When building the TFRecord of ILSVRC, I get the following error:
```
file: research/inception/inception/data/build_imagenet_data.py
line: 175: six.binary_type TypeError: str() takes at most 1 argument
```
This probably due to the incompatible of python2 and python3 even if the author uses the six module.
In Python3: 
`class str(object='', encoding='utf-8', ...)
`
however, In Python2:
`class str(object='')`
i.e. It only take one argument.

I fix this bug by catching the exception and assign the string without encoding.",JoshuaPiinRueyPan,b'cla: yes',2018-03-12T11:45:47Z,2019-11-24T23:44:16Z,,,,,,,
3546,Unable to run Mask RCNN Resnet 101,"Hi,

I was trying to train 'mask_rcnn_resnet101', with the below command

python3 train.py --logtostderr --train_dir=training/ --pipeline_config_path=training/mask_rcnn_resnet101_atrous_coco.config

However i get bug which states

Message type ""object_detection.protos.FasterRcnn"" has no field named ""number_of_stages"".

Not sure how to go about, can anyone let me know how to go about?

Regards
Sekar
",chansekar,None,2018-03-08T10:56:47Z,2020-02-07T18:44:20Z,,,,,,,
3539,how to separate training data and evaluate data from Rerecord?,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",aqsasamreen,None,2018-03-07T10:39:41Z,2018-11-21T21:45:08Z,,,,,,,
3537,Smaple Request :Preparing data and TFRecords for Semantic Segmentation,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.
Instance Segmentation [workflow ](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/instance_segmentation.md)is unclear on preparing data . 
[Examples ](https://github.com/tensorflow/models/blob/master/research/object_detection/dataset_tools/)on creation of TFRecords either has Image-Lable or Image-Mask combination. 
AFAIK  TFRecords are generated with
 - Images in jpg or png format
 - Labels in PASCAL VOC XML format
 - Image Masks in png format 

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.

Is it alright to add 'image/object/mask'  to the TFRecord generation snippet?
Notice that [Convert raw PASCAL dataset to TFRecord for object_detection](https://github.com/tensorflow/models/blob/master/research/object_detection/dataset_tools/create_pascal_tf_record.py)  uses annotations directory. [Convert the Oxford pet dataset to TFRecord for object_detection](https://github.com/tensorflow/models/blob/master/research/object_detection/dataset_tools/create_pet_tf_record.py) does not use annotations but uses mask directory. Is there an example which combines both ?

example = tf.train.Example(features=tf.train.Features(feature={
      'image/height': dataset_util.int64_feature(height),
      'image/width': dataset_util.int64_feature(width),
      'image/filename': dataset_util.bytes_feature(
          data['filename'].encode('utf8')),
      'image/source_id': dataset_util.bytes_feature(
          data['filename'].encode('utf8')),
      'image/key/sha256': dataset_util.bytes_feature(key.encode('utf8')),
      'image/encoded': dataset_util.bytes_feature(encoded_jpg),
      'image/format': dataset_util.bytes_feature('jpeg'.encode('utf8')),
      'image/object/bbox/xmin': dataset_util.float_list_feature(xmin),
      'image/object/bbox/xmax': dataset_util.float_list_feature(xmax),
      'image/object/bbox/ymin': dataset_util.float_list_feature(ymin),
      'image/object/bbox/ymax': dataset_util.float_list_feature(ymax),
      'image/object/class/text': dataset_util.bytes_list_feature(classes_text),
      'image/object/class/label': dataset_util.int64_list_feature(classes),
      'image/object/difficult': dataset_util.int64_list_feature(difficult_obj),
      'image/object/truncated': dataset_util.int64_list_feature(truncated),
      'image/object/view': dataset_util.bytes_list_feature(poses),
  }))",ddurgaprasad,None,2018-03-07T04:57:56Z,2020-02-07T18:44:19Z,,,,,,,
3526,Box Error while running eval.py,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",somsukla,None,2018-03-06T10:20:42Z,2018-04-08T23:24:03Z,,,,,,,
3525,fix bug when user specifies input_shape,"* fix bug when user specifies input_shape, such as '-1,256,256,3', which program interprets -1 as parameter name not value
* update arg message of input_shape",gfphoenix78,b'cla: yes',2018-03-06T10:16:27Z,2019-11-24T23:44:15Z,,,,,,,
3524, fix bug when user specifies input_shape,"fix bug when user sets the batch_size of input_shape to -1,  such as '-1,128,128,3'. In this case the program interprets -1 as part of parameter name, not a parameter value.",gfphoenix,b'cla: no',2018-03-06T08:55:40Z,2018-03-06T10:06:13Z,,,,,,,
3508,retrained tfslim mobilenet_v1 model does not have input node?,"### System information
- **What is the top-level directory of the model you are using**:
/tensorflow/models/research/slim
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**:
Binary. It's a tensorflow docker image so all below questions are fixed
- **TensorFlow version (use command below)**:
3.5
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**: 9(? not sure, part of the standard docker image)
- **GPU model and memory**: nVidia 1080T
- **Exact command to reproduce**:

nvidia-docker run -v ~/DataSets:/DataSets -v ~/tensorflow:/tensorflow -it gcr.io/tensorflow/tensorflow:latest-gpu-py3 bash
Here DataSets are tfrecords formatted images, tensorflow is the tensorflow

Then within the docker image:
1. train:
DATASET_DIR=/DataSets/
mkdir /tmp/logs
TRAIN_DIR=/tmp/logs
cd /tensorflow/models/research/slim 
python train_image_classifier.py --train_dir=${TRAIN_DIR} --dataset_name=imagenet --dataset_split_name=train --dataset_dir=${DATASET_DIR} --model_name=mobilenet_v1
2. frozen pb:
cd /usr/local/lib/python3.5/dist-packages/tensorflow/python/tools
python freeze_graph.py --input_graph=/tmp/logs/graph.pbtxt --input_checkpoint=/tmp/logs/model.ckpt-102638  --output_graph=/tmp/mobilenet_v1_224_frozen_trained.pb --output_node_names=MobilenetV1/Predictions/Reshape_1

### Describe the problem
This frozen pb does not have input node.
I tried with summary_graph.py, it says ""No inputs spotted."" (the summary_graph.py is on another desktop with python 2.7, but I assume the model once frozen should be portable)
Also tried another tool, it complains the same thing.

",springishere,b'type:bug',2018-03-02T18:30:24Z,2018-11-17T20:10:26Z,,,,,,,
3507,Can we do something like raise an exception / display alert when an object is detected using the object_detection model of tensorflow?,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",sakethramanujam,None,2018-03-02T17:15:30Z,2018-11-21T21:54:58Z,,,,,,,
3506,Tensorflow Lite model load error about mobilenet_v1_1.0_224.tflite,"version info
tensorflow r1.5
ubuntu 14.04

the file mobilenet_v1_1.0_224.tflite included by the mobilenet_v1_1.0_224.tgz from the link:
http://download.tensorflow.org/models/mobilenet_v1_2018_02_22/mobilenet_v1_1.0_224.tgz
cannot be loaded.
but the file mobilenet_v1_1.0_224.tflite included by the mobilenet_v1_1.0_224_float_2017_11_08.zip from the link:
https://storage.googleapis.com/download.tensorflow.org/models/tflite/mobilenet_v1_224_android_quant_2017_11_08.zip
can be loaded.
the file size are same, but the first file is updated 2018.02.23, and the second one is 2017.11.09.
i am not sure whether or not this is a bug, or a compatibility problem.",BKZero,b'comp:lite stat:awaiting response type:build/install',2018-03-02T09:07:44Z,2018-08-02T22:15:54Z,,,,,,,
3489,Bug in Tensorflow object detection evaluation,"I want  evaluate my object detection model with mAP (mean average precision). In https://github.com/tensorflow/models/tree/master/research/object_detection/utils/ there is object_detection_evaluation.py that I want to use. 

The Bug is when i change the order of the prediction Boxes, I get a different result.

I am using the example in https://github.com/tensorflow/models/blob/master/research/object_detection/utils/object_detection_evaluation_test.py

I use following for the groundtruth boxes:

pascal_evaluator = object_detection_evaluation.PascalDetectionEvaluator( categories, matching_iou_threshold=0.1)
groundtruth_boxes = np.array([[10, 10, 11, 11]], dtype=float)
groundtruth_class_labels = np.array([1], dtype=int)

groundtruth_is_difficult_list = np.array([False], dtype=bool)
pascal_evaluator.add_single_ground_truth_image_info(
    'img2',
    {
        standard_fields.InputDataFields.groundtruth_boxes: groundtruth_boxes,
        standard_fields.InputDataFields.groundtruth_classes: groundtruth_class_labels,
        standard_fields.InputDataFields.groundtruth_difficult: groundtruth_is_difficult_list
    }
)

and this for the prediction Boxes:

image_key = 'img2'
detected_boxes = np.array(
    [ [100, 100, 220, 220], [10, 10, 11, 11]],
    dtype=float)
detected_class_labels = np.array([1,1], dtype=int)
detected_scores = np.array([0.8, 0.9], dtype=float)
pascal_evaluator.add_single_detected_image_info(image_key, {
    standard_fields.DetectionResultFields.detection_boxes:
        detected_boxes,
    standard_fields.DetectionResultFields.detection_scores:
        detected_scores,
    standard_fields.DetectionResultFields.detection_classes:
        detected_class_labels
})
I print the results with metrics = pascal_evaluator.evaluate() print(metrics)
if I use this prediction Boxes [100, 100, 220, 220], [10, 10, 11, 11] the result is:

{'PASCAL/Precision/mAP@0.1IOU': 1.0, 'PASCAL/PerformanceByCategory/AP@0.1IOU/face': 1.0}

If I use [10, 10, 11, 11], [100, 100, 220, 220] (other Box sequence)

I get following result:

{'PASCAL/Precision/mAP@0.1IOU': 0.5, 'PASCAL/PerformanceByCategory/AP@0.1IOU/face': 0.5}

The results are different, so in my view it is a bug. 

Cheers
Michael 

",mkrech,None,2018-02-28T07:43:12Z,2018-11-17T20:24:03Z,,,,,,,
3483,"Different training behavior using tfrecord produced by ""build_image_data.py"" and ""download_and_convert_cifar10.py""","### System information
- **What is the top-level directory of the model you are using**: slim and inception
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: 1.4.0
- **Bazel version (if compiling from source)**: 0.5.4
- **CUDA/cuDNN version**: 8.0.61
- **GPU model and memory**: NVIDIA Corporation Device 1b06
- **Exact command to reproduce**:

```
bazel build //inception:build_image_data
bazel-bin/inception/build_image_data \
--train_directory='.../cifar-10/train' \
--validation_directory='.../cifar-10/test' \
--labels_file='.../cifar-10/labels.txt' \
--train_shards=128 \
--validation_shards=8 \
--num_threads=8 \
--output_directory='.../cifar-10/tfrecord' 
```

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

I tried different types of labels.txt when it comes to build_image_data.py : 
```
0 airplane
1 automobile
...
```

```
0 ( empty line )
1 airplane
2 automobile
...
```
and both with python script or bazel.

On the other hand , I also produced tfrecord by download_and_convert_cifar10.py .
Under the same hyper-parameters , I kickoff cifar10 with the later one , but tfrecord produced by build_image_data.py always diverge in the very beginning of training.

I check the cifar10 manually extracted , it's nothing weird .

Is there anything I missed ?
Is this right way to produce tfrecord with build_image_data.py ?
thank you.

",ghost,None,2018-02-27T10:49:13Z,2018-03-09T02:32:17Z,,,,,,,
3477,autoencoder: bugfix in initialization,"Bugfix for initialization in autoencoder, thanks to @cclauss for raising the issue in #1052 
Verified it runs.",swaroopgj,b'cla: yes',2018-02-27T03:43:56Z,2018-04-17T16:11:46Z,,,,,,,
3466,resnet_v1_50() got an unexpected keyword argument 'store_non_strided_activations',"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**: models/research/object_detection
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Solus Linux 3
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.7.0-dev20180225 (nightly build)
- **Bazel version (if compiling from source)**: 9.0
- **CUDA/cuDNN version**:
- **GPU model and memory**: Nvidia Geforce 1080ti
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

When I try to train the retina net model (resnet50, SSD meta architecture, focal loss), I get the following error:

  File ""train.py"", line 167, in <module>
    tf.app.run()
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/platform/app.py"", line 126, in run
    _sys.exit(main(argv))
  File ""train.py"", line 163, in main
    worker_job_name, is_chief, FLAGS.train_dir)
  File ""/root/gv/models/research/object_detection/trainer.py"", line 246, in train
    clones = model_deploy.create_clones(deploy_config, model_fn, [input_queue])
  File ""/root/gv/models/research/slim/deployment/model_deploy.py"", line 193, in create_clones
    outputs = model_fn(*args, **kwargs)
  File ""/root/gv/models/research/object_detection/trainer.py"", line 179, in _create_losses
    prediction_dict = detection_model.predict(images, true_image_shapes)
  File ""/root/gv/models/research/object_detection/meta_architectures/ssd_meta_arch.py"", line 343, in predict
    preprocessed_inputs)
  File ""/root/gv/models/research/object_detection/models/ssd_resnet_v1_fpn_feature_extractor.py"", line 130, in extract_features
    scope=scope)
TypeError: resnet_v1_50() got an unexpected keyword argument 'store_non_strided_activations'

I did not change any code apart from the configuration file, where I set the feature extractor to be ssd_resnet_v1_fpn                                                                                                                                                 
",nguyeho7,None,2018-02-26T12:15:54Z,2020-02-07T18:44:08Z,,,,,,,
3462,Can't run an `Instance Segmentation` model example from docs (Object detection / TF 1.5),"### System information
- **What is the top-level directory of the model you are using**:
models/research/object_detection
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
no
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**:
pip install tensorflow-gpu
- **TensorFlow version (use command below)**:
1.5.0
- **CUDA/cuDNN version**:
9.0 / 7.0.5.15
- **GPU model and memory**:
GTX 1080
- **Exact command to reproduce**:
python train.py --logtostderr --pipeline_config_path=${HOME}/model/mask_rcnn_resnet101_atrous_coco_2018_01_28/pipeline.config --train_dir=${HOME}/model/mask_rcnn_resnet101_atrous_coco_2018_01_28

### Describe the problem
Trying to run `mask_rcnn_inception_resnet_v2_atrous_coco` with `Oxford-IIIT Pets Dataset`  new feature `Instance Segmentation`, but getting bug (see log). Created tf record with provided script `dataset_tools/create_pet_tf_record.py --faces_only=false --mask_type=png` . 
Pipeline config from docs [here](https://github.com/tensorflow/models/blob/master/research/object_detection/samples/configs/mask_rcnn_inception_resnet_v2_atrous_coco.config)
Then after run train and getting this error: `TypeError: Expected int32, got range(0, 3) of type 'range' instead.`

### Source code / logs
```
INFO:tensorflow:Scale of 0 disables regularizer.
INFO:tensorflow:Scale of 0 disables regularizer.
INFO:tensorflow:Scale of 0 disables regularizer.
WARNING:tensorflow:From /root/git/models/research/object_detection/trainer.py:228: create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Please switch to tf.train.create_global_step
INFO:tensorflow:Scale of 0 disables regularizer.
INFO:tensorflow:Scale of 0 disables regularizer.
INFO:tensorflow:Scale of 0 disables regularizer.
INFO:tensorflow:Scale of 0 disables regularizer.
INFO:tensorflow:depth of additional conv before box predictor: 0
INFO:tensorflow:Scale of 0 disables regularizer.
WARNING:tensorflow:From /root/git/models/research/object_detection/core/box_predictor.py:391: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.
Instructions for updating:
keep_dims is deprecated, use keepdims instead
WARNING:tensorflow:From /root/git/models/research/object_detection/core/losses.py:306: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.
Instructions for updating:

Future major versions of TensorFlow will allow gradients to flow
into the labels input on backprop by default.

See tf.nn.softmax_cross_entropy_with_logits_v2.

WARNING:tensorflow:From /root/git/models/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py:1851: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.
Instructions for updating:
keep_dims is deprecated, use keepdims instead
Traceback (most recent call last):
  File ""train.py"", line 167, in <module>
    tf.app.run()
  File ""/root/venv/lib/python3.5/site-packages/tensorflow/python/platform/app.py"", line 124, in run
    _sys.exit(main(argv))
  File ""train.py"", line 163, in main
    worker_job_name, is_chief, FLAGS.train_dir)
  File ""/root/git/models/research/object_detection/trainer.py"", line 255, in train
    train_config.optimizer)
  File ""/root/git/models/research/object_detection/builders/optimizer_builder.py"", line 50, in build
    learning_rate = _create_learning_rate(config.learning_rate)
  File ""/root/git/models/research/object_detection/builders/optimizer_builder.py"", line 108, in _create_learning_rate
    learning_rate_sequence)
  File ""/root/git/models/research/object_detection/utils/learning_schedules.py"", line 153, in manual_stepping
    tf.constant(range(num_boundaries), dtype=tf.int32),
  File ""/root/venv/lib/python3.5/site-packages/tensorflow/python/framework/constant_op.py"", line 212, in constant
    value, dtype=dtype, shape=shape, verify_shape=verify_shape))
  File ""/root/venv/lib/python3.5/site-packages/tensorflow/python/framework/tensor_util.py"", line 413, in make_tensor_proto
    _AssertCompatible(values, dtype)
  File ""/root/venv/lib/python3.5/site-packages/tensorflow/python/framework/tensor_util.py"", line 328, in _AssertCompatible
    (dtype.name, repr(mismatch), type(mismatch).__name__))
TypeError: Expected int32, got range(0, 3) of type 'range' instead.
```

",antlad,None,2018-02-26T09:01:40Z,2018-02-26T19:10:16Z,,,,,,,
3444,Error: cycle_length must be greater than zero.,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",NoamWhy,None,2018-02-23T19:47:29Z,2018-02-26T19:52:24Z,,,,,,,
3434,__init__() got an unexpected keyword argument 'dct_method',"### System information
- **What is the top-level directory of the model you are using**:
      C:\Users\Administrator\Documents\Projects\models
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
     Just changed the filename of 'train.py' to 'my_train.py'.
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: 
     Windows 10
- **TensorFlow installed from (source or binary)**:
      Binary
- **TensorFlow version (use command below)**:
      1.5
- **CUDA/cuDNN version**:
     CUDA v9.0
- **GPU model and memory**:
      NVDIA GeForce GT 730

### Describe the problem
Is the new version have some bugs or my installation is incorrect? because I saw the source code of the 'Image' class of tf.example_decoder, it is no an argument named 'dec_method' in the 'init' method. If my description or log is not clear enough, please tell me. Thanks in advance!

### Source code / logs
  File ""C:\Users\Administrator\AppData\Local\Programs\Python\Python35\lib\site-packages\object_detection-0.1-py3.5.egg\object_detection\trainer.py"", line 59, in create_input_queue
    tensor_dict = create_tensor_dict_fn()
  File ""C:/Users/Administrator/Documents/Projects/models/research/object_detection/my_train.py"", line 120, in get_next
    dataset_builder.build(config)).get_next()
  File ""C:\Users\Administrator\AppData\Local\Programs\Python\Python35\lib\site-packages\object_detection-0.1-py3.5.egg\object_detection\builders\dataset_builder.py"", line 138, in build
    label_map_proto_file=label_map_proto_file)
  File ""C:\Users\Administrator\AppData\Local\Programs\Python\Python35\lib\site-packages\object_detection-0.1-py3.5.egg\object_detection\data_decoders\tf_example_decoder.py"", line 110, in __init__
    dct_method=dct_method),
TypeError: __init__() got an unexpected keyword argument 'dct_method'",zeshaoaaa,b'stat:awaiting response',2018-02-23T04:25:01Z,2018-02-23T06:55:37Z,,,,,,,
3427,Tensorflow Object Detection API Detects Old Classes as My Custom Object,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**:1.3.0
- **Bazel version (if compiling from source)**:-
- **CUDA/cuDNN version**:8/6
- **GPU model and memory**:NVidia Quadro M4000

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
I am triying to create a custom object detector with Tensorflow Object Detection API. I followed the API documentation,[ raccoonn detector tutorial](https://towardsdatascience.com/how-to-train-your-own-object-detector-with-tensorflows-object-detector-api-bec72ecfe1d9), [macncheese tutorial](https://pythonprogramming.net/introduction-use-tensorflow-object-detection-api-tutorial/) and many others. I am using pre-trained faster rcnn model and default config file values (i edited ""PATH TO BE CONFİGURED"" areas correctly)(my label map has only one item and its id is 1). After training with 6660 training examples (tested at approximate 1500 and 5000 steps), results are not perfect but its okay for my test images. The main problem is when i test the model with different images that doesn't contain my custom object, it detects other objects as my custom object. Especially, if the object is in coco dataset (my model pre-trained on coco dataset) like car, knife, laptop etc. model detecting their location and tagging them as my custom object. I tried SSD mobilenet too and same issue. Is this a bug or am i missing something ? 


### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",mstferis,None,2018-02-22T14:05:03Z,2018-02-22T22:55:55Z,,,,,,,
3423,object_detection preprocessor.py random_image_scale TypeError and bug,"### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 14.04
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: 1.4.0
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**: Titan X
- **Exact command to reproduce**: use random_image_scale preprocessing with Mask R-CNN

### Describe the problem
When I tried to use 'random_image_scale' preprocess option with Mask R-CNN, I encountered type error and code errors.

1. TypeError
[preprocessor.py#L768](https://github.com/tensorflow/models/blob/master/research/object_detection/core/preprocessor.py#L768)
```
masks: (optional) rank 3 float32 tensor containing masks with
      size [height, width, num_masks]. The value is set to None if there are no masks.
```

mask tensor shape is `[num_instances, height, width]`, not `[height, width, num_masks]`

2. Code error (mask existence check, mask resize)
[preprocessor.py#L803](https://github.com/tensorflow/models/blob/master/research/object_detection/core/preprocessor.py#L803)
```
    if masks:
      masks = tf.image.resize_nearest_neighbor(
          masks, [image_newysize, image_newxsize], align_corners=True)
      result.append(masks)
```

2.1. Mask existence check
if we use masks which means it is tf.Tensor type rather than None type, `if masks:` raise error
```
raise TypeError(""Using a `tf.Tensor` as a Python `bool` is not allowed. ""
TypeError: Using a `tf.Tensor` as a Python `bool` is not allowed. Use `if t is not None:` instead of `if t:` to test if a tensor is defined, and use Tensorflow ops such as tf.cond to execute subgraphs conditioned on the value of a tensor.
```
This error can be fixed followed by: `if masks is not None:`

2.2. Mask resize
Also, resize function in code `tf.image.resize_nearest_neighbor(
          masks, [image_newysize, image_newxsize], align_corners=True)` is not working since the masks tensor shape is `[num_instances, height, width]`, but `tf.image.resize_nearest_neighbor` require the shape `[batch, height, width, channels]`. Therefore, error raises:
```
ValueError: Shape must be rank 4 but is rank 3 for 'RandomImageScale/ResizeNearestNeighbor' (op: 'ResizeNearestNeighbor') with input shapes: [?,?,?], [2].
```

My temporal fixed code is:
```
if masks is not None:
  masks = tf.image.resize_nearest_neighbor(tf.expand_dims(masks, -1), [image_newysize, image_newxsize], align_corners=True)
  masks = tf.squeeze(masks, -1)
  result.append(masks)
```
",byungjae89,b'stat:awaiting model gardener',2018-02-22T08:34:34Z,2020-02-07T18:44:06Z,,,,,,,
3412,object_detection trainer.py does not use train_config.load_all_detection_checkpoint_vars,"There might a be bug `trainer.py`. In

https://github.com/tensorflow/models/blob/af6527c975a65a834d71adfde1041333b6fb8dc2/research/object_detection/trainer.py#L270-L271

the parameter `load_all_detection_checkpoint_vars`, which is defined here

https://github.com/tensorflow/models/blob/af6527c975a65a834d71adfde1041333b6fb8dc2/research/object_detection/protos/train.proto#L41

is not honored.

What I did: finetune mobilenet_ssd based on weights from your website. Then, use the last checkpoint to experiment with quantization.  So, I created a new train config, then referenced the checkpoint as ""fine_tune_checkpoint"". The initial loss is quite high, without quantization enabled! It appears that all the BoxPredictor scopes are not restored. Indeed, after checking the code, this is expected. Only the FeatureExtractor scope gets restored. The additional flag mentioned above needs to be used, I believe. When I changed the aforementioned code line in trainer.py, it started working as expecting. From Step 1 on in the new training (in a different train dir btw.), training continued exactly from the last training state.",DominikAuras,b'stat:awaiting model gardener',2018-02-20T07:23:05Z,2020-02-07T18:44:05Z,,,,,,,
3411,Watch anchor boxes,"I executed object_detection_tutorial on pycharm using google-ssd-with inception v2. 
I wanna see code about making anchor boxes. 
I predicted that I can see variables value in /models/object_detection/anchor_generators/multiple_grid_generator.py if I apply break-point on multiple_grid_generator.py. But, When I executed debug, multiple_grid_generator.py was ignored (jump this section). 

When I wanna see the code of making anchor boxes, Where do I apply break-point? 
",89douner,b'stat:awaiting response',2018-02-20T05:33:37Z,2018-09-29T04:32:11Z,,,,,,,
3407,OOM when retian(resume) a model,"Hi ,
i fine-tuned a model , everything is ok , when i want to resume that model , i faced with error of OOM , so i must restart computer , and then resume that model , in this case my problem solved and the model retrains . why this problem these is ? i think this is a bug . ",PythonImageDeveloper,b'stat:awaiting response',2018-02-17T19:55:25Z,2018-09-29T04:32:00Z,,,,,,,
3393,"ResourceExhaustedError (see above for traceback): OOM when allocating tensor of shape [7744,512] ","Hi guys, I am a beginner with TF and I am trying to running some Atari Reinforcement Learning training on my laptop with GeForce GT 650M. I get the following error and I can't figure out what's wrong, I've tried to change my batch size multiple times but same again. Sometimes stop with this error and sometimes just quit after 300 steps without any error message.

```
ResourceExhaustedError (see above for traceback): OOM when allocating tensor of shape [7744,512] and type float
	 [[Node: q_estimator/q_estimator/fully_connected/weights/RMSProp_1/Initializer/zeros = Const[_class=[""loc:@q_estimator/fully_connected/weights""], dtype=DT_FLOAT, value=Tensor<type: float shape: [7744,512] values: [0 0 0]...>, _device=""/job:localhost/replica:0/task:0/device:GPU:0""]()]]
```

This is my code.. I am embedding all of it so it will be clear.

```
import gym
from gym.wrappers import Monitor
import itertools
import numpy as np
import os
import random
import sys
import psutil
import tensorflow as tf



if ""../"" not in sys.path:
  sys.path.append(""../"")

from lib import plotting
from collections import deque, namedtuple

env = gym.envs.make(""Breakout-v0"")

# atari actions: 0 [noop], 1 [fire], 2 [left] and 3 [right]
VALID_ACTIONS = [0, 1, 2, 3]

class StateProcessor():
  """"""
  Process a raw Atari image, resizes it and converts it to grayscale.
  """"""
  def __init__(self):
    # build the tensorflow graph
    with tf.variable_scope(""state_processor""):
      # obtain input image
      self.input_state = tf.placeholder(shape=[210,160,3], dtype=tf.uint8)
      # convert to greyscale
      self.output = tf.image.rgb_to_grayscale(self.input_state)
      # crop image
      self.output = tf.image.crop_to_bounding_box(self.output, 34, 0 , 160, 160)
      # resize image
      self.output = tf.image.resize_images(self.output, [84, 84], method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)
      # removes all dimensions of size 1
      self.output = tf.squeeze(self.output)


  def process(self, sess, state):
    """"""
    :param sess: tensorflow session object
    :param state: [210, 160, 3] atari RGB State
    :return: processed [84, 84, 1] state representing grayscale values
    """"""
    return sess.run(self.output, {self.input_state: state})


class Estimator():
  """"""
  Q-Value Estimator neural network

  This network is used for both the Q-Network and the Target Network
  """"""

  def __init__(self, scope=""estimator"", summaries_dir=None):
    self.scope = scope
    # writes Tensorboard summaries to disk
    self.summary_writer = None
    with tf.variable_scope(scope):
      # build the graph
      self.build_model()
      if summaries_dir:
        summary_dir = os.path.join(summaries_dir, ""summaries_{}"".format(scope))
        # create directory if does not exist
        if not os.path.exists(summary_dir):
          os.makedirs(summary_dir)
        self.summary_writer = tf.summary.FileWriter(summary_dir)

  def build_model(self):
    """"""
    Builds the Tensorflow graph
    :return:
    """"""

    # placeholders for input
    # input of 4 RGB frames of shape 160, 160 each
    self.X_pl = tf.placeholder(shape=[None, 84, 84, 4], dtype=tf.uint8, name=""X"")
    # the TD target value
    self.y_pl = tf.placeholder(shape=[None], dtype=tf.float32, name=""y"")
    # integer id of which action was selected
    self.actions_pl = tf.placeholder(shape=[None], dtype=tf.int32, name=""actions"")

    X = tf.to_float(self.X_pl) / 255.0
    batch_size = tf.shape(self.X_pl)[0]

    # three convolutional layer
    conv1 = tf.contrib.layers.conv2d(X, 32, 8, 4, activation_fn=tf.nn.relu)
    conv2 = tf.contrib.layers.conv2d(conv1, 64, 4, 2, activation_fn=tf.nn.relu)
    conv3 = tf.contrib.layers.conv2d(conv2, 64, 3, 1, activation_fn=tf.nn.relu)

    # flattened layer
    flattened = tf.contrib.layers.flatten(conv3)

    # fully connected layers
    fc1 = tf.contrib.layers.fully_connected(flattened, 512)
    self.predictions = tf.contrib.layers.fully_connected(fc1, len(VALID_ACTIONS))

    # get the predictions for the choses actions only
    gather_indices = tf.range(batch_size) * tf.shape(self.predictions)[1] + self.actions_pl
    
    # slices from predictions according to indices
    self.action_predictions = tf.gather(tf.reshape(self.predictions, [-1]), gather_indices)

    # calculate the losses using the square difference (x-y)(x-y)
    self.losses = tf.squared_difference(self.y_pl, self.action_predictions)
    # reduce input losses, return tensor with single element
    self.loss = tf.reduce_mean(self.losses)

    ### CAN BE MODIFIED ###

    # optimizer parameters from original paper
    self.optimizer = tf.train.RMSPropOptimizer(0.00025, 0.99, 0.0, 1e-6)
    self.train_op = self.optimizer.minimize(self.loss, global_step=tf.contrib.framework.get_global_step())

    # summaries for Tensorboard
    self.summaries = tf.summary.merge([
      tf.summary.scalar(""Loss"", self.loss),
      tf.summary.scalar(""Max_Q_Value"", tf.reduce_max(self.predictions)),
      tf.summary.histogram(""Loss_Hist"", self.losses),
      tf.summary.histogram(""Q_Value_Hist"", self.predictions)])

  def predict(self, sess, s):
    """"""
    Predicts action values.

    Args:
      sess: Tensorflow session
      s: State input of shape [batch_size, 4, 160, 160, 3]

    Returns:
      Tensor of shape [batch_size, NUM_VALID_ACTIONS] containing the estimated
      action values.
    """"""
    return sess.run(self.predictions, {self.X_pl: s})

  def update(self, sess, s, a, y):
    """"""
    Preidct action values
    :param self:
    :param sess: tensorflow session object
    :param s: state input of shape [batch_size, 4, 160, 160, 3]
    :param a: chosen actions of shape [batch_size]
    :param y: targets of shape [batch_size]
    :return: the calculated loss on the batch
    """"""
    feed_dict = {self.X_pl: s, self.y_pl: y, self.actions_pl: a}
    summaries, global_step, _, loss = sess.run([self.summaries, tf.contrib.framework.get_global_step(), self.train_op, self.loss],
                                               feed_dict)
    if self.summary_writer:
      self.summary_writer.add_summary(summaries, global_step)
    return loss


class ModelParametersCopier():
  """"""
  Copy model parameters of one estimator to another
  """"""

  def __init__(self, estimator1, estimator2):
    """"""
    Defines copy-work operation graph
    :param estimator1: estimator to copy params from
    :param estimator2: estimator to copy params to
    """"""

    e1_params = [t for t in tf.trainable_variables() if t.name.startswith(estimator1.scope)]
    e1_params = sorted(e1_params, key=lambda v: v.name)

    e2_params = [t for t in tf.trainable_variables() if t.name.startswith(estimator2.scope)]
    e2_params = sorted(e2_params, key=lambda v: v.name)

    self.update_ops = []
    for e1_v, e2_v in zip(e1_params, e2_params):
      op = e2_v.assign(e1_v)
      self.update_ops.append(op)

  def make(self, sess):
    """"""
    Makes copy
    :param self:
    :param sess: Tensorflow session instance
    :return:
    """"""
    sess.run(self.update_ops)

def make_epsilon_greedy_policy(estimator, nA):
  """"""
  Creates an epsilon-greedy policy based on a given Q-function approximator and epsilon
  :param estimator: an estimator that returns q values for a given state
  :param nA: number of actions in the environment
  :return: A function that takes the (sess, observation, epsilon) as an argument
           probabilities for each action in the form of a numpy array of lenght nA
  """"""

  def policy_fn(sess, observation, epsilon):
    A = np.ones(nA, dtype=float) * epsilon /nA
    q_values = estimator.predict(sess, np.expand_dims(observation, 0))[0]
    best_action = np.argmax(q_values)
    A[best_action] += (1.0 - epsilon)
    return A
  return policy_fn

def deep_q_learning(sess,
                    env,
                    q_estimator,
                    target_estimator,
                    state_processor,
                    num_episodes,
                    experiment_dir,
                    replay_memory_size=500000,
                    replay_memory_init_size=50000,
                    update_target_estimator_every=10000,
                    discount_factor=0.99,
                    epsilon_start=1.0,
                    epsilon_end=0.1,
                    epsilon_decay_steps=500000,
                    batch_size=32,
                    record_video_every=50):

  Transition = namedtuple(""Transition"", [""state"", ""action"", ""reward"", ""next_state"", ""done""])

  # the replay memory
  replay_memory = []

  # make model copier object
  estimator_copy = ModelParametersCopier(q_estimator, target_estimator)

  # keeps track of useful statistics
  stats = plotting.EpisodeStats(
    episode_lengths = np.zeros(num_episodes),
    episode_rewards = np.zeros(num_episodes))

  # for 'system/' summaries, usefull to check if current process looks healthy
  current_process = psutil.Process()

  # create directories for checkpoints and summaries
  checkpoint_dir = os.path.join(experiment_dir, ""checkpoints"")
  checkpoint_path = os.path.join(checkpoint_dir, ""model"")
  monitor_path = os.path.join(experiment_dir, ""monitor"")

  if not os.path.exists(checkpoint_dir):
    os.makedirs(checkpoint_dir)
  if not os.path.exists(monitor_path):
    os.makedirs(monitor_path)

  saver = tf.train.Saver()
  # load previous checkpoint if we found one
  latest_checkpoint = tf.train.latest_checkpoint(checkpoint_dir)
  if latest_checkpoint:
    print('Loading model checkpoint {}...\n'.format(latest_checkpoint))
    saver.restore(sess, latest_checkpoint)

  # get the current time step
  total_t = sess.run(tf.contrib.framework.get_global_step())

  # the epsilon decay schedule
  epsilons = np.linspace(epsilon_start, epsilon_end, epsilon_decay_steps)

  # the policy we're following
  policy = make_epsilon_greedy_policy(q_estimator, len(VALID_ACTIONS))

  # populate the replay memory with initial experience
  print('Populating replay memory..')
  state = env.reset()
  state = state_processor.process(sess, state)
  state = np.stack([state] * 4, axis=2)
  for i in range(replay_memory_init_size):
    action_probs = policy(sess, state, epsilons[min(total_t, epsilon_decay_steps-1)])
    action = np.random.choice(np.arange(len(action_probs)), p=action_probs)
    next_state, reward, done, _ = env.step(VALID_ACTIONS[action])
    next_state = state_processor.process(sess, next_state)
    next_state = np.append(state[:,:,1:], np.expand_dims(next_state, 2), axis=2)
    replay_memory.append(Transition(state, action, reward, next_state, done))
    if done:
      state = env.reset()
      state = state_processor.process(sess, state)
      state = np.stack([state]*4, axis=2)
    else:
      state = next_state

  # record videos, add env monitor wrapper
  env = Monitor(env, directory=monitor_path, video_callable=lambda count: count % record_video_every == 0, resume=True)

  for i_episode in range(num_episodes):
    # save the current checkpoint
    saver.save(tf.get_default_session(), checkpoint_path)
    # reset the environment
    state = env.reset()
    state = state_processor.process(sess, state)
    state = np.stack([state] * 4, axis=2)
    loss = None

    # one step in the environment
    for t in itertools.count():

      # epsilon for this time step
      epsilon = epsilons[min(total_t, epsilon_decay_steps-1)]

      # maybe update the target estimator
      if total_t % update_target_estimator_every == 0:
        estimator_copy.make(sess)
        print('\nCopied model parameters to target network')

      # print out which step we're on, useful for debugging
      print('\rStep {} ({}) @ Episode {}/{}, loss: {}'.format(t, total_t, i_episode+1, num_episodes, loss), end="""")
      sys.stdout.flush()

      # take a step
      action_probs = policy(sess, state, epsilon)
      action = np.random.choice(np.arange(len(action_probs)), p=action_probs)
      next_state, reward, done, _ = env.step(VALID_ACTIONS[action])
      next_state = state_processor.process(sess, next_state)
      next_state = np.append(state[:,:,1:], np.expand_dims(next_state, 2), axis=2)

      # if our replay memory is full, pop the first element
      if len(replay_memory) == replay_memory_size:
        replay_memory.pop(0)

      # save transition to replay memory
      replay_memory.append(Transition(state, action, reward, next_state, done))

      # update statistics
      stats.episode_rewards[i_episode] += reward
      stats.episode_lengths[i_episode] = t

      # sample a minibatch from the replay memory
      samples = random.sample(replay_memory, batch_size)
      states_batch, action_batch, reward_batch, next_states_batch, done_batch = map(np.array, zip(*samples))

      # calculate q values and targets
      q_values_next = target_estimator.predict(sess, next_states_batch)
      targets_batch = reward_batch + np.invert(done_batch).astype(np.float32) * discount_factor * np.amax(q_values_next, axis=1)

      # perform gradient descent update
      states_batch = np.array(states_batch)
      loss = q_estimator.update(sess, states_batch, action_batch, targets_batch)

      if done:
        break

      state = next_state
      total_t += 1

      # add summaries to tensorboard
      episode_summary = tf.Summary()
      episode_summary.value.add(simple_value=epsilon, tag=""episode/epsilon"")
      episode_summary.value.add(simple_value=stats.episode_rewards[i_episode], tag=""episode/reward"")
      episode_summary.value.add(simple_value=stats.episode_lengths[i_episode], tag=""episode/length"")
      episode_summary.value.add(simple_value=current_process.cpu_percent(), tag=""system/cpu_usage_percent"")
      episode_summary.value.add(simple_value=current_process.memory_percent(memtype=""vms""),tag=""system/v_memeory_usage_percent"")
      q_estimator.summary_writer.add_summary(episode_summary, i_episode)
      q_estimator.summary_writer.flush()

      yield total_t, plotting.EpisodeStats(
        episode_lengths=stats.episode_lengths[:i_episode + 1],
        episode_rewards=stats.episode_rewards[:i_episode + 1])

    return stats


tf.reset_default_graph()

# where to save checkpoint and graphs
experiment_dir = os.path.abspath(""./experiments/{}"".format(env.spec.id))

# create a global step variable
global_step = tf.Variable(0, name='global_step', trainable=False)

# create estimators
q_estimator = Estimator(scope='q_estimator', summaries_dir=experiment_dir)
target_estimator = Estimator(scope='target_q')

# state processor
state_processor = StateProcessor()

# run

config = tf.ConfigProto()
config.gpu_options.allocator_type = 'BFC'
with tf.Session(config = config) as sess:
  sess.run(tf.global_variables_initializer())
  for t, stats in deep_q_learning(sess,
                                    env,
                                    q_estimator=q_estimator,
                                    target_estimator=target_estimator,
                                    state_processor=state_processor,
                                    experiment_dir=experiment_dir,
                                    num_episodes=10000,
                                    replay_memory_size=500000,
                                    replay_memory_init_size=50000,
                                    update_target_estimator_every=10000,
                                    epsilon_start=1.0,
                                    epsilon_end=0.1,
                                    epsilon_decay_steps=500000,
                                    discount_factor=0.99,
                                    batch_size=32):

    print(""\nEpisode Reward: {}"".format(stats.episode_rewards[-1]))
```

Thank you in advance for your help.",digiamm,None,2018-02-16T12:24:49Z,2019-04-14T23:17:43Z,,,,,,,
3392,MASK RCNN 50 RELATED ISSUE ,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",sidvip,b'stat:awaiting response',2018-02-16T08:48:55Z,2019-06-17T08:22:12Z,,,,,,,
3389,bug correction for dataset import,The iterator to generate batches for imported dataset is missed. ,jind11,b'cla: no',2018-02-16T01:24:25Z,2018-02-16T17:12:53Z,,,,,,,
3384,Detection precision is worse after fine tune with pre-trained model,"### System information
- **What is the top-level directory of the model you are using**: object_detection
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes, but not much
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: UbuntuMATE 16.04
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.4.1
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**: V8.0.61
- **GPU model and memory**: GeForce GTX 1080 Ti / 10.91GiB
- **Exact command to reproduce**: 

### Describe the problem
I downloaded the pre-trained model of ssd-inception_v2_coco from detection model zoo, and set the ""fine_tune_checkpoint"" in ""ssd_inception_v2_coco.config"" to it. I use script ""train.py"" following the instruction in tutorial to train the network. After 200000 steps of training, ""export_inference_graph.py"" is used to export the model. However, the detection precision is getting worse (not just slightly different) with the re-trained model in the evaluation, comparing with directly using pre-trained model. May I know whether it is expected or a bug? If it is not a bug, how could we re-train a model to have better or at least similar detection precision as pre-trained model? Thanks in advance.",rogercw,b'stat:awaiting model gardener',2018-02-14T19:19:29Z,2020-02-07T18:44:05Z,,,,,,,
3372,Tensorflow slim validation accuracy is 0 for default models like mobilenet/inception trained on imagenet from scratch.,"Hi,

As title says, 
I trained tensorflow slim default models like mobilenetv1 and inceptionv2 on imagenet from scratch.
The loss is decreasing from ~7 to ~2, training seems to be good.
But the validation accuracy using eval_image_classifier.py shows around 0.
Checkpoints trained from scratch is used for validation accuracy check.

While I use tensorflow provided pretrained checkpoints of mobilenetv1 to check validation accuracy, Accuracy is about 70% as claimed in the site.

I also trained darknet-19 from scratch and the validation accuracy is around 60%, and I added batch normalization to vgg16 and trained on imagenet, the validation accuracy is also above 50%.

Could anyone tell me why default models on slim like mobilenetv1 and inceptionv2 trained from scratch shows around 0 accuracy on validation?

Any ideas? 

Thanks in advance.


Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
Tensorflow-slim
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Ubuntu 16.04
- **TensorFlow installed from (source or binary)**:
Binary
- **TensorFlow version (use command below)**:
1.4.1
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
CUDA 8.0 cuDNN 6.0
- **GPU model and memory**:
12G
- **Exact command to reproduce**:
Train mobilenetv1 on imagenet, and run eval_image_classifier.py for checkpoint trained from scratch

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",kakpple,None,2018-02-13T00:11:21Z,2018-02-13T20:15:44Z,,,,,,,
3368,mask_rcnn configs missing some values,"### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

In the instructions here for training with mask_rcnn - 
https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/instance_segmentation.md

There are instructions for updating a faster_rcnn config. In this instructions are two steps, load_instance_masks: true and mask_type: 1/2 (1 for numeric, 2 for png).

These configuration variables are not in the mask_rcnn configs provided in the instructions, and it would be nice if they were. ;-)
 
```

train_input_reader: {
  tf_record_input_reader {
    input_path: ""PATH_TO_BE_CONFIGURED/mscoco_train.record""
  }
  label_map_path: ""PATH_TO_BE_CONFIGURED/mscoco_label_map.pbtxt""
  load_instance_masks: true
  mask_type: 2
}
```
Edit again - for instance this one does not have the load_instance_masks field.

https://github.com/tensorflow/models/blob/master/research/object_detection/samples/configs/mask_rcnn_inception_resnet_v2_atrous_coco.config",jerowe,b'type:docs',2018-02-12T09:35:55Z,2020-02-07T18:44:05Z,,,,,,,
3356,bugs in faster_rcnn_meta_arch_test_lib.py,"When I was runing the module faster_rcnn_meta_arch_test_lib.py in ubuntu16.04:

#From object_detection/meta_architectures
$ python3 faster_rcnn_meta_arch_test_lib.py

I got 3 errors listed as following:

======================================================================
ERROR: test_loss_with_hard_mining (__main__.FasterRCNNMetaArchTestBase)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""faster_rcnn_meta_arch_test_lib.py"", line 1095, in test_loss_with_hard_mining
    hard_mining=True)
  File ""faster_rcnn_meta_arch_test_lib.py"", line 236, in _build_model
    num_classes=num_classes, is_training=is_training), **common_kwargs)
  File ""faster_rcnn_meta_arch_test_lib.py"", line 108, in _get_model
    **common_kwargs)
  File ""/home/shirhe-lyh/models/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py"", line 325, in __init__
    if is_training and second_stage_batch_size > first_stage_max_proposals:
TypeError: unorderable types: NoneType() > int()

======================================================================
ERROR: test_predict_correct_shapes_in_inference_mode_both_stages (__main__.FasterRCNNMetaArchTestBase)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""faster_rcnn_meta_arch_test_lib.py"", line 375, in test_predict_correct_shapes_in_inference_mode_both_stages
    self._get_box_classifier_features_shape(image_size,
AttributeError: 'FasterRCNNMetaArchTestBase' object has no attribute '_get_box_classifier_features_shape'

======================================================================
ERROR: test_predict_gives_correct_shapes_in_train_mode_both_stages (__main__.FasterRCNNMetaArchTestBase)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""faster_rcnn_meta_arch_test_lib.py"", line 438, in test_predict_gives_correct_shapes_in_train_mode_both_stages
    self._get_box_classifier_features_shape(image_size,
AttributeError: 'FasterRCNNMetaArchTestBase' object has no attribute '_get_box_classifier_features_shape'

----------------------------------------------------------------------
Ran 17 tests in 26.742s

FAILED (errors=3)
",Shirhe-Lyh,None,2018-02-10T02:50:15Z,2018-02-13T17:05:27Z,,,,,,,
3355,Bug in finding smallest side when preprocessing,"### System information
- **What is the top-level directory of the model you are using**: `models/research/slim/preprocessing`
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 14.04.5, Windows 10 x64
- **TensorFlow installed from (source or binary)**: Binary
- **TensorFlow version (use command below)**: `v1.4.0-19-ga52c8d9 1.4.1` (On Ubuntu), `unknown 1.4.0` (On Windows)
- **Bazel version (if compiling from source)**: NA
- **CUDA/cuDNN version**: 8.0.61/6.0.21 (On Ubuntu), No GPU on Windows
- **GPU model and memory**: Titan X (Pascal), 12GB
- **Exact command to reproduce**: 
```python
>>> sess.run(vgg_preprocessing._smallest_size_at_least(height, width, smallest_side),
             feed_dict={height: 1080, width: 1920, smallest_side: 224})
223, 398
```

### Describe the problem
When using the `vgg_preprocessing.preprocess_for_eval`, and by giving the image height value mentioned above, the given output is actually smaller than the `smallest_side` which happens due to precision loss when storing the result of dividing `smallest_side` by `height` in a `float32`.

This bug can also be easily reproduced using Numpy
```python
>>> a = np.float32(224.0 / 1080.0)
>>> (a * 1080.0).astype(np.int32)
223
```
I fixed this by changing [these lines](https://github.com/tensorflow/models/blob/master/research/slim/preprocessing/vgg_preprocessing.py#L249-L251) to all use `to_double`.",erfannoury,b'stat:awaiting model gardener',2018-02-09T22:05:14Z,2020-02-07T18:44:04Z,,,,,,,
3352,Simple line-line bug fixes for flags in synth data,,sussillo,b'cla: no',2018-02-09T20:04:37Z,2018-02-09T21:15:33Z,,,,,,,
3345,Bug in beginners tutorial using premade_estimator.py,"### System information
- **What is the top-level directory of the model you are using**:
 C:\Python3\Lib\site-packages\tensorflow\models\samples\core\get_started
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Windows 10
- **TensorFlow installed from (source or binary)**:
Binary
- **TensorFlow version (use command below)**:
1.5.0
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
V8.0.60
- **GPU model and memory**:
GT635m 4GB
- **Exact command to reproduce**:
python3 premade_estimator.py

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
When parsing the host variable in client.py the variable returned conatins a trailing semi-colon resulting in the port number reasiing an error since it's taken as a literal:
 "" ValueError: invalid literal for int() with base 10: '3128;' ""
### Source code / logs
```
   C:\Python3\Lib\site-packages\tensorflow\models\samples\core\get_started>py premade_estimator.py
    Downloading data from http://download.tensorflow.org/data/iris_training.csv
    Traceback (most recent call last):
      File ""C:\Python3\lib\http\client.py"", line 798, in _get_hostport
        port = int(host[i+1:])
    ValueError: invalid literal for int() with base 10: '3128;'
    
    During handling of the above exception, another exception occurred:
    
    Traceback (most recent call last):
      File ""premade_estimator.py"", line 88, in <module>
        tf.app.run(main)
      File ""C:\Python3\lib\site-packages\tensorflow\python\platform\app.py"", line 124, in run
        _sys.exit(main(argv))
      File ""premade_estimator.py"", line 34, in main
        (train_x, train_y), (test_x, test_y) = iris_data.load_data()
      File ""C:\Python3\Lib\site-packages\tensorflow\models\samples\core\get_started\iris_data.py"", line 19, in load_data
        train_path, test_path = maybe_download()
      File ""C:\Python3\Lib\site-packages\tensorflow\models\samples\core\get_started\iris_data.py"", line 12, in maybe_download
        train_path = tf.keras.utils.get_file(TRAIN_URL.split('/')[-1], TRAIN_URL)
      File ""C:\Python3\lib\site-packages\tensorflow\python\keras\_impl\keras\utils\data_utils.py"", line 238, in get_file
        urlretrieve(origin, fpath, dl_progress)
      File ""C:\Python3\lib\urllib\request.py"", line 188, in urlretrieve
        with contextlib.closing(urlopen(url, data)) as fp:
      File ""C:\Python3\lib\urllib\request.py"", line 163, in urlopen
        return opener.open(url, data, timeout)
      File ""C:\Python3\lib\urllib\request.py"", line 466, in open
        response = self._open(req, data)
      File ""C:\Python3\lib\urllib\request.py"", line 484, in _open
        '_open', req)
      File ""C:\Python3\lib\urllib\request.py"", line 444, in _call_chain
        result = func(*args)
      File ""C:\Python3\lib\urllib\request.py"", line 1282, in http_open
        return self.do_open(http.client.HTTPConnection, req)
      File ""C:\Python3\lib\urllib\request.py"", line 1223, in do_open
        h = http_class(host, timeout=req.timeout, **http_conn_args)
      File ""C:\Python3\lib\http\client.py"", line 762, in __init__
        (self.host, self.port) = self._get_hostport(host, port)
      File ""C:\Python3\lib\http\client.py"", line 803, in _get_hostport
        raise InvalidURL(""nonnumeric port: '%s'"" % host[i+1:])
    http.client.InvalidURL: nonnumeric port: '3128;'

```",muhammedchand,b'stat:awaiting model gardener',2018-02-08T17:22:38Z,2018-02-20T19:52:37Z,,,,,,,
3307,tensorflow model behaves differently in c++ and python,"I report a bug about SavedModel, which does not work good when load in c++, it concens two api, tf.gather_nd and tf.Print. Here are the details: 
https://stackoverflow.com/questions/48578706/tensorflow-model-behaves-differently-in-c-and-python",chengmengli06,None,2018-02-02T11:28:42Z,2020-02-07T18:44:03Z,,,,,,,
3302,bugs while decoding,"Description about the System

1. OS: Windows 10
2. Ram: 4GB DDR3
3. GPU: AMD Radeon 8 series(2GB)
4. Tensorflow Version :1.0.0
5. python version: 3.5


Description about the issue:

While decoding the files cloned from the tensorflow/models (eng-french) it get successfully cloned as well as the WMT files also gets downloaded.
After training when i am decoding the same it says..
![new](https://user-images.githubusercontent.com/29627340/35717129-451134b2-0803-11e8-94ef-1b2728128ed8.PNG)
Giving a wrong output with some bugs in it.
Please, Do describe me what actually the problem is and the solution to the same.",Sammyreus,b'stat:awaiting response',2018-02-02T04:56:18Z,2018-09-29T04:30:46Z,,,,,,,
3295,typo in tfgan mnist example launch script,"### Describe the problem
Hi,
I find a bug in the launch script of mnist example of tfgan (tensorflow/models/research/gan/mnist/launch_jobs.sh). 

The script run the evaluation with parameter ""--max_number_of_evaluation=1"". However, the correct parameter should be ""--max_number_of_evaluations=1"". This little bug results in the ""max_number_of_evaluations"" value to be ""None"" and the evaluation part to run forever, waiting for new checkpoints from training.

All three cases in the launch script (""unconditional"", ""conditional"" and ""infogan"") have the same problem (line 105, line 130 and line 155).
",DongCiLu,None,2018-02-01T15:55:05Z,2018-02-12T22:19:10Z,,,,,,,
3284,CUDA_ERROR_LAUNCH_FAILED when training my own model with ssd_mobilenet_v1_coco,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",szcdlsq,b'stat:awaiting response type:build/install',2018-01-31T15:41:26Z,2018-11-09T21:58:51Z,,,,,,,
3276,Too many logging when training with TensorFlow-Slim image classification model library,"### System information
- **What is the top-level directory of the model you are using**: slim
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: no
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows/Ubuntu
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.5
- **Bazel version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: 9
- **GPU model and memory**: Many...
- **Exact command to reproduce**: run script slim/train_image_classifier.py

### Describe the problem
When training using the mentioned script (train_image_classifier.py) there are log prints each time a new summary is written to the events file. 

For example:
INFO:tensorflow:Recording summary at step 16923

I think it makes the log very noisy. There should be a way to disable it or print it as debug.",ohadlights,None,2018-01-30T16:53:38Z,2018-01-30T22:24:48Z,,,,,,,
3270,Slow inference speed of object detection models and a hack as solution,"### System information
- **What is the top-level directory of the model you are using**:
models/research/object_detection/
- **Have I written custom code**:
No custom code for reproducing the bug. I have written custom code for diagnosing.
- **OS Platform and Distribution**:
Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**:
Anaconda conda-forge channel
- **TensorFlow version**:
b'unknown' 1.4.1 (output from `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`)
- **CUDA/cuDNN version**:
CUDA 8.0/cuDNN 6.0
- **GPU model and memory**:
1 TITAN X (Pascal)  12189MiB
- **Exact command to reproduce**:
Run the provided [object detection demo](https://github.com/tensorflow/models/blob/master/research/object_detection/object_detection_tutorial.ipynb) (ssd_mobilenet_v1_coco_2017_11_17 model) with a small modification in the last cell to record the inference speed:
```
    i = 0
    for _ in range(10):
      image_path = TEST_IMAGE_PATHS[1]
      i += 1
      image = Image.open(image_path)
      # the array based representation of the image will be used later in order to prepare the
      # result image with boxes and labels on it.
      image_np = load_image_into_numpy_array(image)
      # Expand dimensions since the model expects images to have shape: [1, None, None, 3]
      image_np_expanded = np.expand_dims(image_np, axis=0)
      # Actual detection.
      options = tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE)
      run_metadata = tf.RunMetadata()
      start_time = time.time()
      (boxes, scores, classes, num) = sess.run(
          [detection_boxes, detection_scores, detection_classes, num_detections],
          feed_dict={image_tensor: image_np_expanded})
      print('Iteration %d: %.3f sec'%(i, time.time()-start_time))
```
The results show that the inference speed is much shower than the reported inference speed, 30ms, in the [model zoo page](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md):
```
Iteration 1: 2.212 sec
Iteration 2: 0.069 sec
Iteration 3: 0.076 sec
Iteration 4: 0.068 sec
Iteration 5: 0.072 sec
Iteration 6: 0.072 sec
Iteration 7: 0.071 sec
Iteration 8: 0.079 sec
Iteration 9: 0.085 sec
Iteration 10: 0.071 sec
```

### Describe the problem
**Summary:**
By directly running the provided [object detection demo](https://github.com/tensorflow/models/blob/master/research/object_detection/object_detection_tutorial.ipynb), the observed inference speed of object detection models in the model zoo is much slower than the reported inference speed. With some hack, a higher inference speed than the reported speed can be achieved. After some diagnostics, it is highly likely that the slow inference speed is caused by:
* **tf.where and other post-processing operations are running anomaly slow on GPU; or**
* **The frozen inference graph is lack of the ability to optimize the GPU/CPU assignment.** 

**proof of the hypothesis: tf.where and other post-processing operations are running anomaly slow on GPU**

By outputting trace file, we can diagnose the running time of each node in details.
To output the trace file, modify the last cell of [object detection demo](https://github.com/tensorflow/models/blob/master/research/object_detection/object_detection_tutorial.ipynb) as:
```
from tensorflow.python.client import timeline
with detection_graph.as_default():
  with tf.Session(graph=detection_graph) as sess:
    # Definite input and output Tensors for detection_graph
    image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')
    # Each box represents a part of the image where a particular object was detected.
    detection_boxes = detection_graph.get_tensor_by_name('detection_boxes:0')
    # Each score represent how level of confidence for each of the objects.
    # Score is shown on the result image, together with the class label.
    detection_scores = detection_graph.get_tensor_by_name('detection_scores:0')
    detection_classes = detection_graph.get_tensor_by_name('detection_classes:0')
    num_detections = detection_graph.get_tensor_by_name('num_detections:0')
    i = 0
    for _ in range(10):
      image_path = TEST_IMAGE_PATHS[1]
      i += 1
      image = Image.open(image_path)
      # the array based representation of the image will be used later in order to prepare the
      # result image with boxes and labels on it.
      image_np = load_image_into_numpy_array(image)
      # Expand dimensions since the model expects images to have shape: [1, None, None, 3]
      image_np_expanded = np.expand_dims(image_np, axis=0)
      # Actual detection.
      options = tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE)
      run_metadata = tf.RunMetadata()
      start_time = time.time()   
      (boxes, scores, classes, num) = sess.run(\
      [detection_boxes, detection_scores, detection_classes, num_detections], \
      feed_dict={image_tensor: image_np_expanded}, \
      options=options, run_metadata=run_metadata)    
      print('Iteration %d: %.3f sec'%(i, time.time()-start_time))
      # Visualization of the results of a detection.
      vis_util.visualize_boxes_and_labels_on_image_array(
        image_np,
        np.squeeze(boxes),
        np.squeeze(classes).astype(np.int32),
        np.squeeze(scores),
        category_index,
        use_normalized_coordinates=True,
        line_thickness=8)
        
    plt.figure(figsize=IMAGE_SIZE)
    plt.imshow(image_np)
    
    fetched_timeline = timeline.Timeline(run_metadata.step_stats)
    chrome_trace = fetched_timeline.generate_chrome_trace_format()
    with open('Experiment_1.json' , 'w') as f:
      f.write(chrome_trace)
``` 
The output json file has been included in the .zip file in the **source code** section below.
Visualizing the json file in chrome://tracing/ gives:

![experiment1](https://user-images.githubusercontent.com/14045078/35551422-dae50440-0543-11e8-896f-62bc33bcf0af.png)

The CNN related operations end at ~13ms and the rest post-processing operations take about 133ms. We have noticed that adding the trace function will further slow down the inference speed. But it is shows clearly that the post-processing operations (post CNN) run very slowly on GPU.

As a comparison, one can run the [object detection demo](https://github.com/tensorflow/models/blob/master/research/object_detection/object_detection_tutorial.ipynb) with GPU disabled, and profile the running trace using the same method. To disable GPU, add `os.environ['CUDA_VISIBLE_DEVICES'] = ''` in the first row of the last cell.

The output json file has been included in the .zip file in the **source code** section below.
Visualizing this  json file in chrome://tracing/ gives: 

![experiment_2](https://user-images.githubusercontent.com/14045078/35581507-d329b978-05a0-11e8-808e-dc78232e284d.png)

By running everything on CPU, the CNN operations end at roughly 63ms and the rest post-processing operations only takes about 15ms on CPU which is significantly faster than the time they take when running on GPU.

**proof of the hypothesis: The frozen inference graph is lack of the ability to optimized the GPU/CPU assignment**

We add some hack trying to see can we achieve a higher inference speed. The hack is manually assigning the CNN related nodes on GPU and the rest nodes on CPU. The idea is using GPU to accelerate only CNN operations and leave the post-processing operations on CPU.

The source code has been included in the .zip file in the **source code** section below.

With this hack, we are able to observe a higher inference speed than the reported speed. 
```
Iteration 1: 1.021 sec
Iteration 2: 0.027 sec
Iteration 3: 0.026 sec
Iteration 4: 0.027 sec
Iteration 5: 0.026 sec
Iteration 6: 0.026 sec
Iteration 7: 0.026 sec
Iteration 8: 0.031 sec
Iteration 9: 0.031 sec
Iteration 10: 0.026 sec
```
**To verify the hypothesis, here are some questions we need from the tensorflow team:**

1. Are the numbers of inference speed reported on the detection model zoo page tested on the frozen inference graphs or original graphs?

2. Are the slow tf.where and other post-processing operations supposed to run on GPU or CPU? Is the slow running speed on GPU normal?

3. Is there a device assigning function to optimize the GPU/CPU use in the original tensorflow graphs? Is that function missing in the frozen inference graphs?

### Source code / logs

[tensorflowissue.zip](https://github.com/tensorflow/models/files/1678729/tensorflowissue.zip)

",wkelongws,None,2018-01-30T06:33:46Z,2020-02-07T18:42:44Z,,,,,,,
3269,Difference in predictions and loss in adversarial_text,"Here is a suspected bug:

**What is the top-level directory of the model you are using**: adversarial_text

In models/research/adversarial_text/layers.py, in classification_loss (line 220) we seem to be using sigmoid_cross_entropy, but in predictions (line 256) we compare with 0.5.
Shouldn't the logits be compared with 0, or the sigmoid of the logits compared with 0.5?
Otherwise this threshold of 0.5 for the logits seems arbitrary and I'm not sure why it should work well with every dataset.

Is there something I'm misunderstanding about the setup of the experiments?",ShantanuThakoor,None,2018-01-30T05:22:43Z,2018-02-22T19:42:51Z,,,,,,,
3267,small bug fix in exporter.py,Possible solution to problem described in https://github.com/tensorflow/models/issues/2861,frostell,b'cla: yes',2018-01-29T18:51:05Z,2018-02-03T15:34:49Z,,,,,,,
3254,Wide,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",John1231983,None,2018-01-26T14:51:02Z,2018-01-26T14:51:12Z,,,,,,,
3249,Chinese word compatible problem when I use the Object Detection API of reading the config file,"### System information
== cat /etc/issue ===============================================
Linux myName 4.13.0-31-generic #34~16.04.1-Ubuntu SMP Fri Jan 19 17:11:01 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux
VERSION=""16.04.3 LTS (Xenial Xerus)""
VERSION_ID=""16.04""
VERSION_CODENAME=xenial

== are we in docker =============================================
No

== compiler =====================================================
c++ (Ubuntu 5.4.0-6ubuntu1~16.04.5) 5.4.0 20160609
Copyright (C) 2015 Free Software Foundation, Inc.
This is free software; see the source for copying conditions. There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.

== uname -a =====================================================
Linux myName 4.13.0-31-generic #34~16.04.1-Ubuntu SMP Fri Jan 19 17:11:01 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux

== check pips ===================================================
numpy (1.14.0)
protobuf (3.5.1)
tensorflow-gpu (1.4.1)
tensorflow-tensorboard (0.4.0)

== check for virtualenv =========================================
False

== tensorflow import ============================================
tf.VERSION = 1.4.1
tf.GIT_VERSION = v1.4.0-19-ga52c8d9
tf.COMPILER_VERSION = v1.4.0-19-ga52c8d9

== env ==========================================================
LD_LIBRARY_PATH /usr/local/cuda-8.0/lib64:/usr/local/cuda-8.0/extras/CUPTI/lib64:/usr/local/cuda-8.0/lib64:/usr/local/cuda-8.0/extras/CUPTI/lib64
DYLD_LIBRARY_PATH is unset

### Describe the problem
**#Problem 1:**
In ""Object Detection API""--""train.py"":
`1) A single pipeline_pb2.TrainEvalPipelineConfig configuration file`
`can be specified by --pipeline_config_path.`

`Example usage:`
    `./train \`
        `--logtostderr \`
        `--train_dir=path/to/train_dir \`
        `--pipeline_config_path=pipeline_config.pbtxt`

config_path might end with "".config"".
At least,in ""Object Detection API"" doctument,the format should be consistent.

**#Problem 2:**
Some code in Tensorflow is not compatible with Chinese.

I run the following script,and get error message:
`python object_detection/train.py \`
`--logtostderr \`
`--pipeline_config_path=/home/myName/桌面/Work/Trained_Model/temp/faster_rcnn_resnet101_pets.config \`
`--train_dir=/home/myName/桌面/Work/Trained_Model/temp`


`Traceback (most recent call last):`
`File ""object_detection/train.py"", line 163, in <module>`
`tf.app.run()`
`File ""/home/myName/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/platform/app.py"", line 48, in run`
`_sys.exit(main(_sys.argv[:1] + flags_passthrough))`
`File ""object_detection/train.py"", line 91, in main
    FLAGS.pipeline_config_path)`
`File ""/home/myName/桌面/resources/Tensorflow/models/research/object_detection/utils/config_util.py"", line 43, in get_configs_from_pipeline_file
    text_format.Merge(proto_str, pipeline_config)`
`File ""/home/myName/anaconda3/envs/tensorflow/lib/python3.6/site-packages/google/protobuf/text_format.py"", line 533, in Merge
    descriptor_pool=descriptor_pool)`
`File ""/home/myName/anaconda3/envs/tensorflow/lib/python3.6/site-packages/google/protobuf/text_format.py"", line 587, in MergeLines
    return parser.MergeLines(lines, message)`
`File ""/home/myName/anaconda3/envs/tensorflow/lib/python3.6/site-packages/google/protobuf/text_format.py"", line 620, in MergeLines
    self._ParseOrMerge(lines, message)`
`File ""/home/myName/anaconda3/envs/tensorflow/lib/python3.6/site-packages/google/protobuf/text_format.py"", line 635, in _ParseOrMerge
    self._MergeField(tokenizer, message)`
`File ""/home/myName/anaconda3/envs/tensorflow/lib/python3.6/site-packages/google/protobuf/text_format.py"", line 735, in _MergeField
    merger(tokenizer, message, field)`
`File ""/home/myName/anaconda3/envs/tensorflow/lib/python3.6/site-packages/google/protobuf/text_format.py"", line 823, in _MergeMessageField
    self._MergeField(tokenizer, sub_message)`
`File ""/home/myName/anaconda3/envs/tensorflow/lib/python3.6/site-packages/google/protobuf/text_format.py"", line 735, in _MergeField
    merger(tokenizer, message, field)`
`File ""/home/myName/anaconda3/envs/tensorflow/lib/python3.6/site-packages/google/protobuf/text_format.py"", line 874, in _MergeScalarField
    value = tokenizer.ConsumeString()`
`File ""/home/myName/anaconda3/envs/tensorflow/lib/python3.6/site-packages/google/protobuf/text_format.py"", line 1237, in ConsumeString
    the_bytes = self.ConsumeByteString()`
`File ""/home/myName/anaconda3/envs/tensorflow/lib/python3.6/site-packages/google/protobuf/text_format.py"", line 1252, in ConsumeByteString
    the_list = [self._ConsumeSingleByteString()]`
`File ""/home/myName/anaconda3/envs/tensorflow/lib/python3.6/site-packages/google/protobuf/text_format.py"", line 1277, in _ConsumeSingleByteString
    result = text_encoding.CUnescape(text[1:-1])`
`File ""/home/myName/anaconda3/envs/tensorflow/lib/python3.6/site-packages/google/protobuf/text_encoding.py"", line 103, in CUnescape
    result = ''.join(_cescape_highbit_to_str[ord(c)] for c in result)`
`File ""/home/myName/anaconda3/envs/tensorflow/lib/python3.6/site-packages/google/protobuf/text_encoding.py"", line 103, in <genexpr>
    result = ''.join(_cescape_highbit_to_str[ord(c)] for c in result)`
`IndexError: list index out of range`

Some code in the file `faster_rcnn_resnet101_pets.config ` is like this:
`gradient_clipping_by_norm: 10.0`
`fine_tune_checkpoint: ""/home/myName/桌面/Work/Trained_Model/temp/model.ckpt""`

As I know,in UTF-8 encoding,a English letter is represented by one byte.
So,`ord(c)` may be right,but for Chinease word,the format parser code should change a little.

**According to my judgement,I create a symbolic link(whose path is all in English) pointed to the Desktop directory which is Chinese word.
For example,`/home/myName/DesktopLink` points to `/home/myName/桌面`**
And I use the new path in the config file instead.
I run the script again.
The training phase begins correctly.

So,I've got a bug or something could be improved?
**Although the problem might be in the `protobuf` code,does it need to do some preprocess to avoid this case?**",DaneSpiritGOD,b'stat:awaiting model gardener',2018-01-26T03:42:20Z,2020-02-07T18:43:52Z,,,,,,,
3242,Something error(No such file or directory) in running create_pet_tf_record.py,"### System information
== cat /etc/issue ===============================================
Linux myName 4.13.0-31-generic #34~16.04.1-Ubuntu SMP Fri Jan 19 17:11:01 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux
VERSION=""16.04.3 LTS (Xenial Xerus)""
VERSION_ID=""16.04""
VERSION_CODENAME=xenial

== are we in docker =============================================
No

== compiler =====================================================
c++ (Ubuntu 5.4.0-6ubuntu1~16.04.5) 5.4.0 20160609
Copyright (C) 2015 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.


== uname -a =====================================================
Linux myName 4.13.0-31-generic #34~16.04.1-Ubuntu SMP Fri Jan 19 17:11:01 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux

== check pips ===================================================
numpy (1.14.0)
protobuf (3.5.1)
tensorflow-gpu (1.4.1)
tensorflow-tensorboard (0.4.0)

== check for virtualenv =========================================
False

== tensorflow import ============================================
tf.VERSION = 1.4.1
tf.GIT_VERSION = v1.4.0-19-ga52c8d9
tf.COMPILER_VERSION = v1.4.0-19-ga52c8d9

== env ==========================================================
LD_LIBRARY_PATH /usr/local/cuda-8.0/lib64:/usr/local/cuda-8.0/extras/CUPTI/lib64:/usr/local/cuda-8.0/lib64:/usr/local/cuda-8.0/extras/CUPTI/lib64
DYLD_LIBRARY_PATH is unset

### Describe the problem
**I run below commandline:**

`python object_detection/dataset_tools/create_pet_tf_record.py \`
`--label_map_path=object_detection/data/pet_label_map.pbtxt \`
`--data_dir=~/桌面/Datasets/Oxford-IIIT-Pets \`
`--output_dir=~/桌面/Datasets/Oxford-IIIT-Pets/TfRecords`

**Then I got such error massage:**

`Traceback (most recent call last):
  File ""object_detection/dataset_tools/create_pet_tf_record.py"", line 272, in <module>
    tf.app.run()
  File ""/home/myName/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/platform/app.py"", line 48, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""object_detection/dataset_tools/create_pet_tf_record.py"", line 245, in main
    examples_list = dataset_util.read_examples_list(examples_path)
  File ""/home/myName/桌面/resources/Tensorflow/models/research/object_detection/utils/dataset_util.py"", line 59, in read_examples_list
    lines = fid.readlines()
  File ""/home/myName/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/lib/io/file_io.py"", line 182, in readlines
    self._preread_check()
  File ""/home/myName/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/lib/io/file_io.py"", line 79, in _preread_check
    compat.as_bytes(self.__name), 1024 * 512, status)
  File ""/home/myName/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py"", line 473, in __exit__
    c_api.TF_GetCode(self.status.status))
tensorflow.python.framework.errors_impl.NotFoundError: ~/桌面/Datasets/Oxford-IIIT-Pets/annotations/trainval.txt; No such file or directory`

_Finnally,I find following commandline which could be run correctly:_
`python object_detection/dataset_tools/create_pet_tf_record.py \`
`--label_map_path=object_detection/data/pet_label_map.pbtxt \`
`--data_dir=/home/myName/桌面/Datasets/Oxford-IIIT-Pets \`
`--output_dir=/home/myName/桌面/Datasets/Oxford-IIIT-Pets/TfRecords`

**I change the directory path with absolute path**
**So,it might be a bug...**

**Addtional,**
**""桌面"" in Chinese means ""Desktop"" in English.**
",DaneSpiritGOD,None,2018-01-25T01:45:46Z,2018-01-25T07:41:29Z,,,,,,,
3241,dragnn parsing error,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Exact command to reproduce**:
run official tensorflow/syntaxnet docker image:
docker run -it -p 8888:8888 tensorflow/syntaxnet

### Describe the problem
open ""http://localhost:8888/?token=xxxx"" in the browser
run dragnn/interactive_text_analyzer and input ""go to seattle for a movie"" in Interactive trace explorer
it tags ""seattle"" as ""VERB+VB""

It should be NOUN, how to fix it?
",robinqhuang,None,2018-01-24T23:51:28Z,2018-01-25T04:13:06Z,,,,,,,
3222,I trained the object detection API to detect a custom object using ssd_mobilenet_v1_coco_2017_11_17 model.,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",zuhain,None,2018-01-23T06:12:50Z,2018-01-23T06:13:58Z,,,,,,,
3219,[BUG] Mobilenet SSD Object Detection Defaults Cause Image Clipping,"Hi there,

When working with the object detection library, I noticed some clashes in the code.

In the MobileNet SSD model file in the models directory, the preprocessing function is scaled from 0 - 255 to -1 to 1. In the object detection core/preprocessing.py module, contrast/hue/pixel scaling ops have this line in them:

  image = tf.clip_by_value(image, clip_value_min=0.0, clip_value_max=1.0)

This clips the image unnaturally and may have side effects for people not staring at preprocessed images as they progress through the preprocessing pipeline in Tensorboard.",TylerBalsam,b'stat:awaiting model gardener',2018-01-22T20:39:48Z,2020-02-07T18:43:51Z,,,,,,,
3218,bugfix type mismatch tf.float32 != tf.int32 (fixes #2774),This fixes the bug described in https://github.com/tensorflow/models/issues/2774,davidenitti,b'cla: yes',2018-01-22T18:26:21Z,2019-11-24T23:44:10Z,,,,,,,
3217,bugfix type mismatch tf.float32 != tf.int32 (fixes #2774),"it fixes the bug discussed at https://github.com/tensorflow/models/issues/2774
TypeError: x and y must have the same dtype, got tf.float32 != tf.int32",davidenitti,b'cla: no',2018-01-22T17:23:16Z,2018-01-22T18:17:40Z,,,,,,,
3214,why the code doesn't log training accuracy ? how can I log accuracy if i want to ?,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",Bayesian4042,None,2018-01-22T11:40:46Z,2018-01-30T03:36:27Z,,,,,,,
3208,Fix minor bug in resnet_v2,In resnet_v2.py the bottleneck layer should subsample the input after it is passed through bn and relu and not before.,amlankar,b'cla: yes',2018-01-21T05:14:21Z,2018-01-21T05:30:24Z,,,,,,,
3186,Bugs in the usage of i ?,"https://github.com/tensorflow/models/blob/9325ea8feb5458d0ba2046a0134c305fd92e82a5/tutorials/rnn/ptb/reader.py#L124

i  in line 124 does not equal to i in line 120. 
Actually,  i(line 124) = i (line 120) + 1 , thus , i think,  it's not longer  "" a **word-level prediction** experiments "" with lstm.",morning-wind,None,2018-01-18T05:31:19Z,2018-01-21T23:11:07Z,,,,,,,
3182,Image links are broken in object_detection/README.md,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**: N/A
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: N/A
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: N/A
- **TensorFlow installed from (source or binary)**: N/A
- **TensorFlow version (use command below)**: N/A
- **Bazel version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**: N/A

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
The image links are bad in object detection README.md

### Source code / logs
https://github.com/tensorflow/models/commits/master/research/object_detection/README.md",aselle,b'stat:awaiting model gardener type:docs',2018-01-17T21:28:04Z,2018-03-22T01:28:52Z,,,,,,,
3179,KeyError for groundtruth_classes running eval.py,"### System information
- **What is the top-level directory of the model you are using**: ssd_mobilenet_v1 latest
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: ubuntu 16.04
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: 1.4.0
- **Bazel version (if compiling from source)**: 0.9.0
- **CUDA/cuDNN version**: 9.0 / 7
- **GPU model and memory**: NVIDIA GTX 1050 4GB (6.1 capability) 
- **Exact command to reproduce**:

i got a pascal-voc based dataset for hands. From that i  successfully created the csv and tfrecord files.
I got around 5000 training images with 10000 labels and around 800 testing images with 2000 labels.
The csv looks like this (so should be alright):
```
filename,width,height,class,xmin,ymin,xmax,ymax
VOC2007_518.jpg,375,500,hand,299,274,333,309
VOC2007_518.jpg,375,500,hand,337,198,376,236
```

My only class is ""hand"", therefore my label map looks like:
```
item {
  id: 1
  name: 'hand'
}
```
in eval.py i added:
`os.environ['CUDA_VISIBLE_DEVICES'] = '-1'`
to run it on CPU, but deleting this line does not solve the problem

parallel to training (which seems to run successful) i try to run the evaluation job like:
```
python object_detection/eval.py \
--logtostderr \
--pipeline_config_path= /home/gustav/workspace/training_hands/model/ssd_mobilehandsnet.config \
--checkpoint_dir=/home/gustav/workspace/training_hands/model/train \   
--eval_dir=/home/gustav/workspace/training_hands/model/eval
```

and got following error right in the beginning:
```
WARNING:root:image 0 does not have groundtruth difficult flag specified
Traceback (most recent call last):
  File ""object_detection/eval.py"", line 135, in <module>
    tf.app.run()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 48, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""object_detection/eval.py"", line 131, in main
    FLAGS.checkpoint_dir, FLAGS.eval_dir)
  File ""/home/gustav/workspace/tensorflow/models/research/object_detection/evaluator.py"", line 210, in evaluate
    save_graph_dir=(eval_dir if eval_config.save_graph else ''))
  File ""/home/gustav/workspace/tensorflow/models/research/object_detection/eval_util.py"", line 381, in repeated_checkpoint_run
    save_graph_dir)
  File ""/home/gustav/workspace/tensorflow/models/research/object_detection/eval_util.py"", line 269, in _run_checkpoint_once
    image_id=batch, groundtruth_dict=result_dict)
  File ""/home/gustav/workspace/tensorflow/models/research/object_detection/utils/object_detection_evaluation.py"", line 167, in add_single_ground_truth_image_info
    standard_fields.InputDataFields.groundtruth_classes]
KeyError: 'groundtruth_classes'
```

So i printed out the groundtruth_dict which causes the problem, and it looks like this:
```
('groundtruth_dict= ', {'original_image': array([[[[64, 68, 80],
         [66, 70, 82],
         [62, 66, 78],
         ...,
         [12, 16, 15],
         [12, 16, 15],
         [17, 21, 20]],

        [[63, 67, 79],
         [66, 70, 82],
         [61, 65, 77],
         ...,
         [13, 17, 16],
         [13, 17, 16],
         [17, 21, 20]],

        [[62, 66, 78],
         [66, 70, 82],
         [62, 66, 78],
         ...,
         [15, 19, 18],
         [14, 18, 17],
         [18, 22, 21]],

        ...,

        [[97, 83, 82],
         [85, 71, 70],
         [84, 70, 67],
         ...,
         [32, 36, 37],
         [26, 30, 31],
         [27, 31, 32]],

        [[94, 80, 79],
         [86, 72, 71],
         [90, 76, 73],
         ...,
         [30, 34, 35],
         [22, 26, 27],
         [27, 31, 32]],

        [[87, 73, 72],
         [85, 71, 70],
         [97, 83, 80],
         ...,
         [28, 32, 33],
         [18, 22, 23],
         [23, 27, 28]]]], dtype=uint8), 'groundtruth_is_crowd': array([], dtype=bool), 'groundtruth_area': array([], dtype=float32), 'detection_boxes': array([[  3.7222574, 243.85812  , 107.565025 , 424.56796  ],
       [ 11.711642 , 323.64343  , 105.015625 , 500.       ],
       [278.89868  , 458.30972  , 342.8926   , 497.58078  ],
       [  3.8873253,  29.537014 ,  97.22421  , 239.43376  ],
       [ 35.484375 , 428.64963  , 166.29593  , 499.3997   ],
       [252.70572  , 315.68005  , 361.17697  , 437.46945  ],
       [199.74017  , 268.7957   , 218.25183  , 287.99872  ],
       [ 27.835133 , 323.57385  ,  42.138878 , 341.12427  ],
       [262.94836  , 459.0676   , 324.5173   , 497.0951   ],
       [ 30.12121  , 352.18933  ,  42.691647 , 366.9404   ],
       [195.73451  , 346.0745   , 222.67781  , 369.47473  ],
       [182.75648  , 349.4227   , 203.51555  , 368.03787  ],
       [216.14795  , 268.55164  , 239.84476  , 289.22177  ],
       [213.16508  , 347.17734  , 239.56981  , 369.95773  ],
       [196.84222  , 321.86615  , 222.91957  , 343.78122  ],
       [198.60518  , 296.3402   , 221.77362  , 317.35907  ],
       [182.73792  , 323.54163  , 204.73431  , 343.42215  ],
       [212.7839   , 319.90427  , 240.82404  , 343.36578  ],
       [180.62373  , 296.06586  , 200.99411  , 315.83798  ],
       [338.9445   , 348.37943  , 359.15344  , 367.71082  ],
       [234.88895  , 349.16602  , 259.0071   , 370.33292  ],
       [303.46356  , 457.30545  , 364.08194  , 497.49954  ],
       [215.08684  , 240.73073  , 238.43745  , 261.50558  ],
       [145.5085   , 326.44092  , 157.93738  , 338.1567   ],
       [ 83.43828  , 271.63446  ,  98.896355 , 286.15344  ],
       [199.06071  , 241.57281  , 217.82936  , 260.41003  ],
       [140.45529  , 295.98352  , 157.77802  , 310.67267  ],
       [233.60094  , 320.17004  , 260.29773  , 343.26422  ],
       [182.35611  , 269.01178  , 198.91292  , 287.86884  ],
       [181.20068  , 372.96698  , 201.5161   , 393.46417  ],
       [300.68942  , 407.16644  , 359.04584  , 464.96985  ],
       [139.66115  , 444.37216  , 159.07675  , 479.99152  ],
       [ 23.430836 , 397.88272  ,  44.162247 , 422.06415  ],
       [ 21.100252 , 294.047    ,  42.38389  , 314.4236   ],
       [236.31688  , 243.0964   , 258.58383  , 261.66235  ],
       [280.3447   , 407.4605   , 292.8006   , 420.21317  ],
       [299.36264  , 378.95526  , 314.73883  , 393.8552   ],
       [215.91156  , 295.24384  , 241.68756  , 317.32587  ],
       [160.2216   , 293.39374  , 180.43195  , 310.80597  ],
       [104.38906  , 423.31558  , 119.70608  , 449.4095   ],
       [ 28.486263 , 373.89478  ,  45.667873 , 392.93118  ],
       [218.15582  , 216.69876  , 238.20929  , 235.54846  ],
       [ 83.59404  , 397.43365  ,  98.18858  , 419.92328  ],
       [234.9742   , 294.39795  , 259.99747  , 315.69208  ],
       [ 40.300983 , 420.2927   ,  60.01407  , 446.76932  ],
       [ 83.4634   , 300.71408  ,  98.52754  , 313.43674  ],
       [299.78403  , 351.60342  , 317.20264  , 366.65198  ],
       [338.4315   , 373.68985  , 359.32492  , 394.76834  ],
       [166.14731  , 325.57693  , 184.81743  , 340.32037  ],
       [ 44.711205 , 397.67593  ,  61.83229  , 420.33655  ],
       [257.01343  , 350.76517  , 278.36444  , 369.43997  ],
       [158.12172  , 445.21902  , 178.86504  , 480.0696   ],
       [262.4441   , 433.15714  , 275.50058  , 447.81937  ],
       [235.62439  , 269.40042  , 260.34317  , 289.5497   ],
       [216.74083  , 372.85437  , 239.18875  , 395.69507  ],
       [104.77659  , 272.44052  , 120.63016  , 287.7762   ],
       [320.54465  , 352.04922  , 339.21588  , 368.14398  ],
       [335.92252  , 398.19324  , 358.44922  , 421.3909   ],
       [ 58.603916 , 358.8482   ,  70.879425 , 371.98077  ],
       [141.1541   , 271.51678  , 160.22408  , 288.35416  ],
       [165.6901   , 377.2134   , 182.83548  , 393.69647  ],
       [297.67566  , 322.5592   , 319.34927  , 341.68277  ],
       [219.46007  , 191.31029  , 236.61574  , 210.29526  ],
       [261.85358  , 406.24994  , 275.86523  , 420.3969   ],
       [201.52548  , 218.10652  , 218.98857  , 235.7868   ],
       [ 61.601517 , 419.59647  ,  81.58215  , 449.02356  ],
       [259.13358  , 191.19864  , 275.70117  , 210.28836  ],
       [196.6504   , 370.98364  , 219.95567  , 395.11862  ],
       [ 37.326405 , 444.67273  ,  60.239902 , 478.10492  ],
       [ 64.34091  , 272.268    ,  81.0081   , 286.43555  ],
       [239.10269  , 190.63756  , 256.7139   , 209.62975  ],
       [ 84.614586 , 219.65251  , 100.4486   , 234.34676  ],
       [164.96635  , 400.28537  , 179.88608  , 420.6667   ],
       [236.52635  , 449.33408  , 259.5564   , 475.5281   ],
       [276.8998   , 356.08392  , 338.37222  , 413.64206  ],
       [104.9978   , 399.731    , 116.69384  , 418.34628  ],
       [320.3317   , 111.434006 , 338.71234  , 131.7356   ],
       [ 81.85569  , 420.5974   ,  99.61256  , 449.95294  ],
       [237.63846  , 217.76233  , 258.50333  , 235.64027  ],
       [150.84442  , 381.60397  , 163.33492  , 394.88397  ],
       [336.49493  , 293.7339   , 358.86316  , 315.8196   ],
       [316.99408  , 322.72513  , 339.50522  , 341.49857  ],
       [147.58536  , 403.13043  , 160.26057  , 421.39246  ],
       [ 59.55451  , 445.28403  ,  82.34845  , 480.91904  ],
       [124.00205  , 246.3231   , 143.39198  , 263.2262   ],
       [259.49414  , 163.86137  , 276.08868  , 184.64775  ],
       [338.4011   , 107.287674 , 356.83478  , 129.8463   ],
       [ 64.310234 , 398.55325  ,  81.488144 , 421.8755   ],
       [ 81.583664 , 444.8386   , 101.344795 , 482.3399   ],
       [105.01828  , 194.82852  , 119.77269  , 210.081    ],
       [ 36.95982  , 213.85706  ,  63.16913  , 236.14496  ],
       [337.48508  , 322.28442  , 359.05057  , 341.78952  ],
       [ 25.420755 , 164.07928  ,  40.073856 , 183.27313  ],
       [279.17184  , 379.42944  , 294.5789   , 393.39044  ],
       [316.2293   , 295.75665  , 341.90454  , 317.5249   ],
       [104.77272  , 167.66571  , 119.54046  , 183.84103  ],
       [254.92526  , 319.55164  , 280.5428   , 343.57095  ],
       [240.45943  , 163.13182  , 257.80908  , 185.5624   ],
       [ 86.57174  , 194.65358  , 101.57887  , 209.33946  ],
       [201.43233  , 191.00928  , 217.96552  , 209.88242  ]],
      dtype=float32), 'groundtruth_classes': array([1, 1]), 'groundtruth_group_of': array([], dtype=int64), 'detection_classes': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'groundtruth_boxes': array([[329.     , 185.     , 364.     , 222.     ],
       [228.00002, 142.     , 255.     , 169.     ]], dtype=float32), 'detection_scores': array([0.28857195, 0.27300978, 0.26126269, 0.26062793, 0.2579368 ,
       0.2562737 , 0.25593358, 0.25527725, 0.25475922, 0.25462022,
       0.25362423, 0.25343668, 0.25324154, 0.25309741, 0.25304952,
       0.2525339 , 0.25238705, 0.25216657, 0.25213185, 0.25187644,
       0.25182185, 0.25181577, 0.25178105, 0.25142857, 0.2514179 ,
       0.25129703, 0.2512553 , 0.25114852, 0.25109357, 0.25099254,
       0.25076938, 0.25071684, 0.25066367, 0.25060827, 0.2504932 ,
       0.25044683, 0.25038907, 0.2503281 , 0.25016046, 0.25004968,
       0.25001392, 0.24997473, 0.2499705 , 0.24986933, 0.24985579,
       0.24971655, 0.24966986, 0.24957949, 0.24955411, 0.2495341 ,
       0.24944127, 0.24943528, 0.24927019, 0.24923873, 0.24902871,
       0.24901138, 0.2489826 , 0.248974  , 0.24894503, 0.24888656,
       0.24886039, 0.24881014, 0.24875696, 0.2486437 , 0.248637  ,
       0.24848294, 0.24847926, 0.2484746 , 0.2484148 , 0.2483988 ,
       0.24838823, 0.24836443, 0.24826829, 0.2482202 , 0.24818836,
       0.24814872, 0.24807507, 0.24805978, 0.24801467, 0.24799332,
       0.24793899, 0.24792199, 0.24777597, 0.24773791, 0.2475662 ,
       0.24744678, 0.24743527, 0.24741969, 0.24732958, 0.24732772,
       0.24732672, 0.24732575, 0.24726531, 0.24718814, 0.24705447,
       0.24699058, 0.24694735, 0.24692817, 0.24681918, 0.24681872],
      dtype=float32), 'key': 'VOC2007_348.jpg', 'groundtruth_difficult': array([], dtype=int64)})
('standard_fields.InputDataFields.groundtruth_classes= ', 'groundtruth_classes')
WARNING:root:image 0 does not have groundtruth difficult flag specified
('groundtruth_dict= ', {})
```

Could it be that there is something wrong with the Int / Float formating of my data?",gustavz,b'stat:awaiting model gardener type:bug',2018-01-17T14:03:01Z,2019-09-03T15:33:15Z,,,,,,,
3170,The Object_detection  's visualize don't work,"when I am using the API of Object_detection,I followed the instruction ,everything is fine .However ,when I begin to test my picture , I met a problem , it seems that the function named 
"" visualize_boxes_and_labels_on_image_array ""  ( in the 57 line )   didn't work .  Here is my source codes 


 
`import cv2
import numpy as np
import tensorflow as tf
from object_detection.utils import label_map_util
from object_detection.utils import visualization_utils as vis_util


class TOD(object):
    def __init__(self):
        self.PATH_TO_CKPT = '/home/xiyou/Desktop/ssd_training/result/frozen_inference_graph.pb'
        self.PATH_TO_LABELS = '/home/xiyou/Desktop/ssd_training/detection_for_smoke.pbtxt'
        self.NUM_CLASSES = 1
        self.detection_graph = self._load_model()
        self.category_index = self._load_label_map()

    def _load_model(self):
        detection_graph = tf.Graph()
        with detection_graph.as_default():
            od_graph_def = tf.GraphDef()
            with tf.gfile.GFile(self.PATH_TO_CKPT, 'rb') as fid:
                serialized_graph = fid.read()
                od_graph_def.ParseFromString(serialized_graph)
                tf.import_graph_def(od_graph_def, name='')
        return detection_graph

    def _load_label_map(self):
        label_map = label_map_util.load_labelmap(self.PATH_TO_LABELS)
        categories = label_map_util.convert_label_map_to_categories(label_map,
                                                                    max_num_classes=self.NUM_CLASSES,
                                                                    use_display_name=True)
        category_index = label_map_util.create_category_index(categories)
        return category_index

    def detect(self, image):
        with self.detection_graph.as_default():
            with tf.Session(graph=self.detection_graph) as sess:
                 # Expand dimensions since the model expects images to have shape: [1, None, None, 3]
                image_np_expanded = np.expand_dims(image, axis=0)
                image_tensor = self.detection_graph.get_tensor_by_name('image_tensor:0')
                boxes = self.detection_graph.get_tensor_by_name('detection_boxes:0')
                scores = self.detection_graph.get_tensor_by_name('detection_scores:0')
                classes = self.detection_graph.get_tensor_by_name('detection_classes:0')

                num_detections = self.detection_graph.get_tensor_by_name('num_detections:0')
                # Actual detection.
                (boxes, scores, classes, num_detections) = sess.run(
                    [boxes, scores, classes, num_detections],
                    feed_dict={image_tensor: image_np_expanded})


                print(boxes, scores, classes, num_detections)
                #print(np.squeeze(boxes))

                # Visualization of the results of a detection.

                                                             #######Here is the problem  
               #  image1 = vis_util.visualize_boxes_and_labels_on_image_array(     
                    image,                              #######Here is the problem
                    np.squeeze(boxes),
                    np.squeeze(classes).astype(np.int32),
                    np.squeeze(scores),
                    self.category_index,
                    use_normalized_coordinates=True,
                    line_thickness=50,

                 )
                #print(np.squeeze(boxes),np.squeeze(classes))

        cv2.namedWindow(""detection"")
        cv2.imshow(""detection"", image1)
        cv2.waitKey(0)

if __name__ == '__main__':
    image = cv2.imread('/home/xiyou/Pictures/timg1.jpg')
    detecotr = TOD()
    detecotr.detect(image)`



when I run this code , the image did show ,but nothing changed , no  detected  area in the pic  and  no an other informations . the input pic is the same as the out image . But when I  was Debug  , I found the Varibles such as soucres , classes ,  boxes  do have values.  
Is anyone can help me ? Thanks!!!

And my Tensorflow version is  1.4.0  , CUDA 8.0  in Ubuntu 16.04
",yurunyang1998,None,2018-01-15T14:15:27Z,2018-01-23T07:57:22Z,,,,,,,
3168,inception v4,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",juzhitao,None,2018-01-15T11:22:23Z,2018-01-16T22:58:48Z,,,,,,,
3164,Tensorflow Object Detection API on Windows - error “ModuleNotFoundError: No module named 'utils'”,"### System information
- **What is the top-level directory of the model you are using**: 
models/research/object_detection

- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
No custom code, using stock example in models/research/object_detection

- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Windows 10

- **TensorFlow installed from (source or binary)**:
Binary via pip3, currently at Python 3.6

- **TensorFlow version (use command below)**:
1.4

- **Bazel version (if compiling from source)**:
N/A

- **CUDA/cuDNN version**:
Using CPU for the moment

- **GPU model and memory**:
Using CPU for the moment

- **Exact command to reproduce**:
See Stack Overflow link below

### Describe the problem
I'm not 100% sure at this point if this is a bug fix or a feature request.  For any Python script I write that uses the libraries in /models/research/object_detection/utils, I can only run a script from models/research/object_detection.  If I run from anywhere else I get the error:

ModuleNotFoundError: No module named 'utils'

I have a detailed Stack Overflow post where I've listed out the steps I've followed and the remedies I've tried to no avail:

https://stackoverflow.com/questions/48247921/tensorflow-object-detection-api-on-windows-error-modulenotfounderror-no-modu

For the sake of brevity I'd rather not repeat the entire post here, please see this link for the full details.  To make a long story short, I've tried adding the following paths:

C:\Users\cdahms\Documents\models
C:\Users\cdahms\Documents\models\research
C:\Users\cdahms\Documents\models\research\slim
C:\Users\cdahms\Documents\models\research\object_detection\utils

directly into a script via sys.path.append(), and also to PYTHONPATH (and then added PYTHONPATH to PATH)

I'm not sure if this is a bug or if there is some setting possible to make the /models/research/object_detection/utils content recognizable from a directory other than /models/research/object_detection, please advise.

--- Edit ---
Upon further consideration who knows what may happen to the Stack Overflow link above, so I'll repeat the error and full steps to reproduce here:

I'm attempting to get the TensorFlow Object Detection API:

https://github.com/tensorflow/models/tree/master/research/object_detection

working on Windows by following the install instructions:

https://github.com/tensorflow/models/tree/master/research/object_detection

Which seem to be for Linux/Mac. I can only get this to work if I put a script in the directory I cloned the above repo too. If I put the script in any other directory I get this error:

`ModuleNotFoundError: No module named 'utils'`

I suspect that the cause is not properly doing the Windows equivalent of this command listed on the install instructions above:

`export PYTHONPATH=$PYTHONPATH:`pwd`:`pwd`/slim`

I'm using Windows 10, Python 3.6, and TensorFlow 1.4.0 if that matters. Any suggestions on how to resolve this?

Here are the steps I've done so far specifically:

1) Installed TensorFlow and related tools via pip3

2) From an administrative command prompt, run the following:

```
pip3 install pillow
pip3 install lxml
pip3 install jupyter
pip3 install matplotlib
```

3) Clone the TensorFlow ""models"" repository to my documents folder, in my case

`C:\Users\cdahms\Documents\models`

4) Downloaded Google Protobuf https://github.com/google/protobuf Windows v3.4.0 release ""protoc-3.4.0-win32.zip"" (I tried the most current 3.5.1 and got errors on the subsequent steps, so I tried 3.4.0 per this vid https://www.youtube.com/watch?v=COlbP62-B-U&list=PLQVvvaa0QuDcNK5GeCQnxYnSSaar2tpku&index=1 and the protobuf compile worked)

5) Extracted the Protobuf download to Program Files, specifically:

`C:\Program Files\protoc-3.4.0-win32`

6) CD into the models\research directory, specifically:

`cd C:\Users\cdahms\Documents\models\research`

7) Executed the protobuf compile, specifically:

`“C:\Program Files\protoc-3.4.0-win32\bin\protoc.exe” object_detection/protos/*.proto --python_out=.`

The compile was successful (no errors), and also I went to:

`C:\Users\cdahms\Documents\models\research\object_detection\protos`

and verified the .py files were created successfully as a result of the compile

8) cd to the object_detection directory, ex:

`cd C:\Users\cdahms\Documents\models\research\object_detection`

then start the object_detection_tutorial.ipynb Jupyter Notebook:

`jupyter notebook`

9) In the Jupyter Notebook, choose ""object_detection_tutorial.ipynb"" -> Cell -> Run all, the example runs within the notebook

10) In the Jupyter Notebook, choose “File” -> “Download As” -> “Python”, and save the .py version of the notebook to the same directory, i.e.

`C:\Users\cdahms\Documents\models\research\object_detection\object_detection_tutorial.py`

The script runs as expected.

11) Move the script to any other directory, then I get the error:

`ModuleNotFoundError: No module named 'utils'`

Clearly, the lines where this error is occurring are the imports for utils:

```
from utils import label_map_util
from utils import visualization_utils as vis_util
```

Here are some things I've tried to resolve the concern, none of which have worked:

1) Add these lines to the script, just before the 2 above imports

```
sys.path.append(""C:\\Users\\cdahms\\Documents\\models"")
sys.path.append(""C:\\Users\\cdahms\\Documents\\models\\research"")
sys.path.append(""C:\\Users\\cdahms\\Documents\\models\\research\\slim"")
sys.path.append(""C:\\Users\\cdahms\\Documents\\models\\research\\object_detection\\utils"")
```

2) Go to System -> Advanced system settings -> Environment Variables . . . -> New, added a variable with the name PYTHONPATH and these values:

![untitled](https://user-images.githubusercontent.com/5672876/34916435-37e3f9ca-f8ed-11e7-8c8d-3530f983fb0a.png)

3) Also under Environment Variables, edited PATH and added PYTHONPATH

![untitled2](https://user-images.githubusercontent.com/5672876/34916437-4f7b79e6-f8ed-11e7-8d82-d491b1f87a72.png)

4) Pulled up a command prompt and ran the command ""set"", verified PYTHONPATH was there and PYTHONPATH and PATH contained the values from the previous steps:

![untitled3](https://user-images.githubusercontent.com/5672876/34916442-5a958f92-f8ed-11e7-9049-04fa8b25a94d.png)

5) Rebooted, then ran the script from any directory other than

`C:\Users\cdahms\Documents\models\research\object_detection`

again, still get the

`ModuleNotFoundError: No module named 'utils'`

Suggestions as to how to get

`C:\Users\cdahms\Documents\models\research\object_detection\utils`

to be recognized by Python when the script is run from any location ??",MicrocontrollersAndMore,None,2018-01-14T13:29:15Z,2019-03-12T05:19:40Z,,,,,,,
3161,"TypeError: x and y must have the same dtype, got tf.float32 != tf.int32","i am learning the tensorflow object detection api.i can train model normally using the train.py script,but when i use the eval.py script to evaluate it,some wrong happend.
python eval.py --logtostderr \
> --checkpoint_dir=train_log \
> --eval_dir=eval_log \
> --pipeline_config_path=ssd_mobilenet_v1_coco.config 
INFO:tensorflow:depth of additional conv before box predictor: 0
INFO:tensorflow:depth of additional conv before box predictor: 0
INFO:tensorflow:depth of additional conv before box predictor: 0
INFO:tensorflow:depth of additional conv before box predictor: 0
INFO:tensorflow:depth of additional conv before box predictor: 0
INFO:tensorflow:depth of additional conv before box predictor: 0
Traceback (most recent call last):
  File ""eval.py"", line 168, in <module>
    tf.app.run()
  File ""/usr/local/lib/python3.4/dist-packages/tensorflow/python/platform/app.py"", line 48, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""eval.py"", line 164, in main
    FLAGS.checkpoint_dir, FLAGS.eval_dir)
  File ""/home/yj/tensorflow3/models/research/object_detection/evaluator.py"", line 142, in evaluate
    ignore_groundtruth=eval_config.ignore_groundtruth)
  File ""/home/yj/tensorflow3/models/research/object_detection/evaluator.py"", line 61, in _extract_prediction_tensors
    detections = model.postprocess(prediction_dict)
  File ""/home/yj/tensorflow3/models/research/object_detection/meta_architectures/ssd_meta_arch.py"", line 405, in postprocess
    class_predictions_without_background)
  File ""/home/yj/tensorflow3/models/research/object_detection/builders/post_processing_builder.py"", line 94, in score_converter_fn
    scaled_logits = tf.divide(logits, logit_scale, name='scale_logits')
  File ""/usr/local/lib/python3.4/dist-packages/tensorflow/python/ops/math_ops.py"", line 309, in divide
    return DivideDelegateWithName(x, name) / y
  File ""/usr/local/lib/python3.4/dist-packages/tensorflow/python/ops/math_ops.py"", line 294, in __truediv__
    return _truediv_python3(self.x, y, self.name)
  File ""/usr/local/lib/python3.4/dist-packages/tensorflow/python/ops/math_ops.py"", line 981, in _truediv_python3
    (x_dtype, y_dtype))
TypeError: x and y must have the same dtype, got tf.float32 != tf.int32

my tf version is 1.4.0,python3.4,cpu,thanks",jimo123,b'type:bug',2018-01-14T02:04:28Z,2020-04-10T18:38:17Z,,,,,,,
3159,Incorrect imagenet classification result with pretrained mobilenet,"### System information
- **What is the top-level directory of the model you are using**:
mobilenet_v1
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**: Source
- **TensorFlow version (use command below)**: 1.4.0
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**: Titan X
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.
I want to run the mobilenet_v1 on imagenet classification. By using the pretrain weights  mobilenet_v1_1.0_224.ckpt, the result seems wrong. I used the similar code for the vgg model, the result seems correct. 

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.

The code:
[test_mobilenet.py.txt](https://github.com/tensorflow/models/files/1628616/test_mobilenet.py.txt)

The classification result (top k) is : 768, 651, 762,...

The test image:
![ilsvrc2012_val_00000003](https://user-images.githubusercontent.com/11369834/34908944-4e9d6ece-f85e-11e7-847d-64d2a8a50b20.JPEG)
",jjzhang10,None,2018-01-13T18:20:06Z,2018-01-26T05:49:02Z,,,,,,,
3155,"Performance issues : Speed is very slow, around .8 seconds per frame on pre-trained model","I am using the pre-trained model ""ssd_mobilenet_v1_coco_2017_11_17"" and the results for object detection for vehicles is pretty good. However, the performance is extremely slow and hence I am unable to use it for my purpose. I resized the image to a smaller one and even chopped the horizon from the image so that the detection is faster, but it doesnt seem to help. Is this a known issue? Any suggestions here",MeghaMaheshwari,b'type:bug',2018-01-12T19:22:46Z,2020-02-07T18:43:51Z,,,,,,,
3143,Feature Request: Freeze capability NasNet-A-Large Checkpoint on a CPU,"### System information
- **What is the top-level directory of the model you are using**:
https://storage.googleapis.com/download.tensorflow.org/models/nasnet-a_large_04_10_2017.tar.gz

- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
Yes (see below)

- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
== cat /etc/issue ===============================================
Linux steelers.steelersnet 4.14.11-200.fc26.x86_64 #1 SMP Wed Jan 3 13:58:53 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux
VERSION=""26 (Workstation Edition)""
VERSION_ID=26
REDHAT_BUGZILLA_PRODUCT_VERSION=26
REDHAT_SUPPORT_PRODUCT_VERSION=26
- **TensorFlow installed from (source or binary)**:
source
- **TensorFlow version (use command below)**:
== tensorflow import ============================================
tf.VERSION = 1.4.0
tf.GIT_VERSION = v1.3.0-rc1-5312-g8a4d849691
tf.COMPILER_VERSION = v1.3.0-rc1-5312-g8a4d849691
Sanity check: array([1], dtype=int32)

$ python3 -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""
2018-01-10 22:56:18.576633: I tensorflow/core/platform/s3/aws_logging.cc:53] Initializing Curl library
/usr/lib64/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
v1.3.0-rc1-6922-ga77096897f 1.5.0-rc0

- **Bazel version (if compiling from source)**:
$ bazel version
Build label: 0.8.1- (@non-git)
Build target: bazel-out/k8-opt/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Wed Dec 6 22:56:54 2017 (1512601014)
Build timestamp: 1512601014
Build timestamp as int: 1512601014

- **CUDA/cuDNN version**:
Not Applicable
- **GPU model and memory**:
Not Applicable
- **Exact command to reproduce**:
See below

### Describe the problem

The NasNet-A-Large trained checkpoint advertised [here](https://github.com/tensorflow/models/tree/master/research/slim#pre-trained-models) and downloadable from [here](https://storage.googleapis.com/download.tensorflow.org/models/nasnet-a_large_04_10_2017.tar.gz) appears to be only freezeable for a GPU.  Attempts to freeze it with a CPU generates errors.  There is an apparent incapatibility here between NHWC and NCHW data formats.

Using pretrained models on a CPU is expected and should be a usable feature.

### Source code / logs

```python
$ ipython3
Python 3.6.3 (default, Oct  9 2017, 12:11:29) 
Type 'copyright', 'credits' or 'license' for more information
IPython 6.2.1 -- An enhanced Interactive Python. Type '?' for help.

In [1]: import tensorflow as tf
   ...: import tensorflow.contrib.slim as slim
   ...: import numpy as np
   ...: 
   ...: import sys
   ...: sys.path.append(""/usr/local/src/tensorflow/models/research/slim"")
   ...: from nets.nasnet.nasnet import build_nasnet_large, nasnet_large_arg_scop
   ...: e
   ...: height = 299
   ...: width = 299
   ...: channels = 3
   ...: FREEZE_DIR = ""./models/build_freeze_graphs""
   ...: # Create graph
   ...: X = tf.placeholder(tf.float32, shape=[None, height, width, channels])
   ...: with slim.arg_scope(nasnet_large_arg_scope()):
   ...:     logits, end_points = build_nasnet_large(X, num_classes=1001,is_train
   ...: ing=False)
   ...: softmax = end_points[""Predictions""]
   ...: saver = tf.train.Saver()
   ...: X_test = np.ones((1,299,299,3))  # a fake image
   ...: 
   ...: # Execute graph
   ...: with tf.Session() as sess:
   ...:     saver.restore(sess, FREEZE_DIR + ""/nasnet-a_large_04_10_2017-model.c
   ...: kpt"")
   ...:     tf.train.write_graph(sess.graph_def, FREEZE_DIR, 'nasnet-a_large.pbt
   ...: xt')
   ...:     
2018-01-10 23:15:42.496988: I tensorflow/core/platform/s3/aws_logging.cc:53] Initializing Curl library
/usr/lib64/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
INFO:tensorflow:Restoring parameters from ./models/build_freeze_graphs/nasnet-a_large_04_10_2017-model.ckpt

In [2]: 

```

```bash
$ python3 /usr/local/src/tensorflow/tensorflow/tensorflow/python/tools/freeze_graph.py --input_graph ./nasnet-a_large.pbtxt --input_checkpoint ./nasnet-a_large_04_10_2017-model.ckpt --output_node_names final_layer/predictions --output_graph ./frozen_nasnet-a_large.pb
2018-01-11 03:48:11.933436: I tensorflow/core/platform/s3/aws_logging.cc:53] Initializing Curl library
/usr/lib64/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Converted 1546 variables to const ops.
```


```python

$ ipython3
Python 3.6.3 (default, Oct  9 2017, 12:11:29) 
Type 'copyright', 'credits' or 'license' for more information
IPython 6.2.1 -- An enhanced Interactive Python. Type '?' for help.

In [1]: TF_SRC_DIR = ""/usr/local/src/tensorflow""
   ...: TF_TF_SRC_DIR = TF_SRC_DIR + ""/tensorflow""
   ...: TF_MODELS_SRC_DIR = TF_SRC_DIR + ""/models""
   ...: TF_EXAMPLES_DIR = TF_TF_SRC_DIR + ""/tensorflow/examples""
   ...: 

In [2]: import importlib.util
   ...: import sys
   ...: 
   ...: # Load TF retrain module
   ...: spec = importlib.util.spec_from_file_location(""retrain"", TF_EXAMPLES_DIR
   ...:  + ""/image_retraining/retrain.py"")
   ...: retrain = importlib.util.module_from_spec(spec)
   ...: spec.loader.exec_module(retrain)
   ...: 
2018-01-11 04:11:22.152580: I tensorflow/core/platform/s3/aws_logging.cc:53] Initializing Curl library
/usr/lib64/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters

In [3]: DATA_DIR = ""./data/processed""
   ...: IMAGE_DIR = DATA_DIR + ""/JPG/Train""
   ...: ARCHITECTURE = ""nasnet-a_large""
   ...: 

In [4]: class C:
   ...:     pass
   ...: 
   ...: retrain.FLAGS = C()
   ...: 
   ...: retrain.FLAGS.architecture = ARCHITECTURE
   ...: retrain.FLAGS.bottleneck_dir = DATA_DIR + '/' + ARCHITECTURE + ""/bottlen
   ...: ecks""
   ...: retrain.FLAGS.eval_step_interval = 200
   ...: retrain.FLAGS.final_tensor_name = ""final_result""
   ...: retrain.FLAGS.flip_left_right = False
   ...: retrain.FLAGS.how_many_training_steps = 20000
   ...: retrain.FLAGS.image_dir = IMAGE_DIR
   ...: retrain.FLAGS.intermediate_output_graphs_dir = DATA_DIR + '/' + ARCHITEC
   ...: TURE + ""/intermed_output_graphs""
   ...: retrain.FLAGS.intermediate_store_frequency = 0
   ...: retrain.FLAGS.learning_rate = 0.005
   ...: retrain.FLAGS.model_dir = DATA_DIR + ""/models""
   ...: retrain.FLAGS.output_graph = DATA_DIR + '/' + ARCHITECTURE + ""/output_gr
   ...: aph.pb""
   ...: retrain.FLAGS.output_labels = DATA_DIR + '/' + ARCHITECTURE + ""/output_l
   ...: abels.txt""
   ...: retrain.FLAGS.print_misclassified_test_images = False
   ...: retrain.FLAGS.random_brightness = 0
   ...: retrain.FLAGS.random_crop = 0
   ...: retrain.FLAGS.random_scale = 0
   ...: retrain.FLAGS.summaries_dir = DATA_DIR + '/' + ARCHITECTURE + ""/retrain_
   ...: logs""
   ...: retrain.FLAGS.test_batch_size = -1
   ...: retrain.FLAGS.testing_percentage = 10
   ...: retrain.FLAGS.train_batch_size = 100
   ...: retrain.FLAGS.validation_batch_size = 100
   ...: retrain.FLAGS.validation_percentage = 10
   ...: 
   ...: 

In [5]: def create_model_info(architecture):
   ...:     return {
   ...:       'data_url': ""localhost:12345/fake/path/frozen_nasnet-a_large.pb"",
   ...:       'bottleneck_tensor_name': ""final_layer/dropout/Identity:0"",
   ...:       'bottleneck_tensor_size': 4032,
   ...:       'input_width': 299,
   ...:       'input_height': 299,
   ...:       'input_depth': 3,
   ...:       'resized_input_tensor_name': ""Placeholder:0"",
   ...:       'model_file_name': ""frozen_nasnet-a_large.pb"",
   ...:       'input_mean': 128,
   ...:       'input_std': 128,
   ...:       'quantize_layer': False,
   ...:   }
   ...: 
   ...: retrain.create_model_info = create_model_info
   ...: 

In [6]: retrain.main(None)
Not extracting or downloading files, model already present in disk
Model path:  ./data/processed/models/frozen_nasnet-a_large.pb
INFO:tensorflow:Looking for images in 'Iceberg'
INFO:tensorflow:Looking for images in 'NotIceberg'
INFO:tensorflow:Creating bottleneck at ./data/processed/nasnet-a_large/bottlenecks/Iceberg/1475-e8b76fb7.jpg_nasnet-a_large.txt
---------------------------------------------------------------------------
InvalidArgumentError                      Traceback (most recent call last)
~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py in _do_call(self, fn, *args)
   1349     try:
-> 1350       return fn(*args)
   1351     except errors.OpError as e:

~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py in _run_fn(session, feed_dict, fetch_list, target_list, options, run_metadata)
   1328                                    feed_dict, fetch_list, target_list,
-> 1329                                    status, run_metadata)
   1330 

~/.local/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py in __exit__(self, type_arg, value_arg, traceback_arg)
    472             compat.as_text(c_api.TF_Message(self.status.status)),
--> 473             c_api.TF_GetCode(self.status.status))
    474     # Delete the underlying status object from memory otherwise it stays alive

InvalidArgumentError: ConcatOp : Dimensions of inputs should match: shape[0] = [1,75,75,42] vs. shape[2] = [1,42,75,75]
	 [[Node: cell_stem_0/cell_output/concat = _MklConcatV2[N=4, T=DT_FLOAT, Tidx=DT_INT32, _kernel=""MklOp"", _device=""/job:localhost/replica:0/task:0/device:CPU:0""](cell_stem_0/comb_iter_1/combine/add, cell_stem_0/comb_iter_2/combine/add, cell_stem_0/comb_iter_3/combine/add, cell_stem_0/comb_iter_4/combine/add, cell_17/split/split_dim, DMT/_121, DMT/_122, cell_stem_0/comb_iter_3/combine/add:1, DMT/_123, DMT/_124)]]

During handling of the above exception, another exception occurred:

InvalidArgumentError                      Traceback (most recent call last)
/usr/local/src/tensorflow/tensorflow/tensorflow/examples/image_retraining/retrain.py in create_bottleneck_file(bottleneck_path, image_lists, label_name, index, image_dir, category, sess, jpeg_data_tensor, decoded_image_tensor, resized_input_tensor, bottleneck_tensor)
    381         sess, image_data, jpeg_data_tensor, decoded_image_tensor,
--> 382         resized_input_tensor, bottleneck_tensor)
    383   except Exception as e:

/usr/local/src/tensorflow/tensorflow/tensorflow/examples/image_retraining/retrain.py in run_bottleneck_on_image(sess, image_data, image_data_tensor, decoded_image_tensor, resized_input_tensor, bottleneck_tensor)
    316   bottleneck_values = sess.run(bottleneck_tensor,
--> 317                                {resized_input_tensor: resized_input_values})
    318   bottleneck_values = np.squeeze(bottleneck_values)

~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py in run(self, fetches, feed_dict, options, run_metadata)
    894       result = self._run(None, fetches, feed_dict, options_ptr,
--> 895                          run_metadata_ptr)
    896       if run_metadata:

~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py in _run(self, handle, fetches, feed_dict, options, run_metadata)
   1127       results = self._do_run(handle, final_targets, final_fetches,
-> 1128                              feed_dict_tensor, options, run_metadata)
   1129     else:

~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py in _do_run(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)
   1343       return self._do_call(_run_fn, self._session, feeds, fetches, targets,
-> 1344                            options, run_metadata)
   1345     else:

~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py in _do_call(self, fn, *args)
   1362           pass
-> 1363       raise type(e)(node_def, op, message)
   1364 

InvalidArgumentError: ConcatOp : Dimensions of inputs should match: shape[0] = [1,75,75,42] vs. shape[2] = [1,42,75,75]
	 [[Node: cell_stem_0/cell_output/concat = _MklConcatV2[N=4, T=DT_FLOAT, Tidx=DT_INT32, _kernel=""MklOp"", _device=""/job:localhost/replica:0/task:0/device:CPU:0""](cell_stem_0/comb_iter_1/combine/add, cell_stem_0/comb_iter_2/combine/add, cell_stem_0/comb_iter_3/combine/add, cell_stem_0/comb_iter_4/combine/add, cell_17/split/split_dim, DMT/_121, DMT/_122, cell_stem_0/comb_iter_3/combine/add:1, DMT/_123, DMT/_124)]]

Caused by op 'cell_stem_0/cell_output/concat', defined at:
  File ""/usr/bin/ipython3"", line 11, in <module>
    sys.exit(start_ipython())
  File ""/usr/lib/python3.6/site-packages/IPython/__init__.py"", line 125, in start_ipython
    return launch_new_instance(argv=argv, **kwargs)
  File ""/usr/lib/python3.6/site-packages/traitlets/config/application.py"", line 658, in launch_instance
    app.start()
  File ""/usr/lib/python3.6/site-packages/IPython/terminal/ipapp.py"", line 356, in start
    self.shell.mainloop()
  File ""/usr/lib/python3.6/site-packages/IPython/terminal/interactiveshell.py"", line 480, in mainloop
    self.interact()
  File ""/usr/lib/python3.6/site-packages/IPython/terminal/interactiveshell.py"", line 471, in interact
    self.run_cell(code, store_history=True)
  File ""/usr/lib/python3.6/site-packages/IPython/core/interactiveshell.py"", line 2728, in run_cell
    interactivity=interactivity, compiler=compiler, result=result)
  File ""/usr/lib/python3.6/site-packages/IPython/core/interactiveshell.py"", line 2856, in run_ast_nodes
    if self.run_code(code, result):
  File ""/usr/lib/python3.6/site-packages/IPython/core/interactiveshell.py"", line 2910, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File ""<ipython-input-6-c66df78b6d6a>"", line 1, in <module>
    retrain.main(None)
  File ""/usr/local/src/tensorflow/tensorflow/tensorflow/examples/image_retraining/retrain.py"", line 1024, in main
    create_model_graph(model_info))
  File ""/usr/local/src/tensorflow/tensorflow/tensorflow/examples/image_retraining/retrain.py"", line 291, in create_model_graph
    model_info['resized_input_tensor_name'],
  File ""/home/rick/.local/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py"", line 316, in new_func
    return func(*args, **kwargs)
  File ""/home/rick/.local/lib/python3.6/site-packages/tensorflow/python/framework/importer.py"", line 548, in import_graph_def
    op_def=op_def)
  File ""/home/rick/.local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 3160, in create_op
    op_def=op_def)
  File ""/home/rick/.local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 1617, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access

InvalidArgumentError (see above for traceback): ConcatOp : Dimensions of inputs should match: shape[0] = [1,75,75,42] vs. shape[2] = [1,42,75,75]
	 [[Node: cell_stem_0/cell_output/concat = _MklConcatV2[N=4, T=DT_FLOAT, Tidx=DT_INT32, _kernel=""MklOp"", _device=""/job:localhost/replica:0/task:0/device:CPU:0""](cell_stem_0/comb_iter_1/combine/add, cell_stem_0/comb_iter_2/combine/add, cell_stem_0/comb_iter_3/combine/add, cell_stem_0/comb_iter_4/combine/add, cell_17/split/split_dim, DMT/_121, DMT/_122, cell_stem_0/comb_iter_3/combine/add:1, DMT/_123, DMT/_124)]]


During handling of the above exception, another exception occurred:

RuntimeError                              Traceback (most recent call last)
<ipython-input-6-c66df78b6d6a> in <module>()
----> 1 retrain.main(None)

/usr/local/src/tensorflow/tensorflow/tensorflow/examples/image_retraining/retrain.py in main(_)
   1063                         FLAGS.bottleneck_dir, jpeg_data_tensor,
   1064                         decoded_image_tensor, resized_image_tensor,
-> 1065                         bottleneck_tensor, FLAGS.architecture)
   1066 
   1067     # Add the new layer that we'll be training.

/usr/local/src/tensorflow/tensorflow/tensorflow/examples/image_retraining/retrain.py in cache_bottlenecks(sess, image_lists, image_dir, bottleneck_dir, jpeg_data_tensor, decoded_image_tensor, resized_input_tensor, bottleneck_tensor, architecture)
    486             sess, image_lists, label_name, index, image_dir, category,
    487             bottleneck_dir, jpeg_data_tensor, decoded_image_tensor,
--> 488             resized_input_tensor, bottleneck_tensor, architecture)
    489 
    490         how_many_bottlenecks += 1

/usr/local/src/tensorflow/tensorflow/tensorflow/examples/image_retraining/retrain.py in get_or_create_bottleneck(sess, image_lists, label_name, index, image_dir, category, bottleneck_dir, jpeg_data_tensor, decoded_image_tensor, resized_input_tensor, bottleneck_tensor, architecture)
    428                            image_dir, category, sess, jpeg_data_tensor,
    429                            decoded_image_tensor, resized_input_tensor,
--> 430                            bottleneck_tensor)
    431   with open(bottleneck_path, 'r') as bottleneck_file:
    432     bottleneck_string = bottleneck_file.read()

/usr/local/src/tensorflow/tensorflow/tensorflow/examples/image_retraining/retrain.py in create_bottleneck_file(bottleneck_path, image_lists, label_name, index, image_dir, category, sess, jpeg_data_tensor, decoded_image_tensor, resized_input_tensor, bottleneck_tensor)
    383   except Exception as e:
    384     raise RuntimeError('Error during processing file %s (%s)' % (image_path,
--> 385                                                                  str(e)))
    386   bottleneck_string = ','.join(str(x) for x in bottleneck_values)
    387   with open(bottleneck_path, 'w') as bottleneck_file:

RuntimeError: Error during processing file ./data/processed/JPG/Train/Iceberg/1475-e8b76fb7.jpg (ConcatOp : Dimensions of inputs should match: shape[0] = [1,75,75,42] vs. shape[2] = [1,42,75,75]
	 [[Node: cell_stem_0/cell_output/concat = _MklConcatV2[N=4, T=DT_FLOAT, Tidx=DT_INT32, _kernel=""MklOp"", _device=""/job:localhost/replica:0/task:0/device:CPU:0""](cell_stem_0/comb_iter_1/combine/add, cell_stem_0/comb_iter_2/combine/add, cell_stem_0/comb_iter_3/combine/add, cell_stem_0/comb_iter_4/combine/add, cell_17/split/split_dim, DMT/_121, DMT/_122, cell_stem_0/comb_iter_3/combine/add:1, DMT/_123, DMT/_124)]]

Caused by op 'cell_stem_0/cell_output/concat', defined at:
  File ""/usr/bin/ipython3"", line 11, in <module>
    sys.exit(start_ipython())
  File ""/usr/lib/python3.6/site-packages/IPython/__init__.py"", line 125, in start_ipython
    return launch_new_instance(argv=argv, **kwargs)
  File ""/usr/lib/python3.6/site-packages/traitlets/config/application.py"", line 658, in launch_instance
    app.start()
  File ""/usr/lib/python3.6/site-packages/IPython/terminal/ipapp.py"", line 356, in start
    self.shell.mainloop()
  File ""/usr/lib/python3.6/site-packages/IPython/terminal/interactiveshell.py"", line 480, in mainloop
    self.interact()
  File ""/usr/lib/python3.6/site-packages/IPython/terminal/interactiveshell.py"", line 471, in interact
    self.run_cell(code, store_history=True)
  File ""/usr/lib/python3.6/site-packages/IPython/core/interactiveshell.py"", line 2728, in run_cell
    interactivity=interactivity, compiler=compiler, result=result)
  File ""/usr/lib/python3.6/site-packages/IPython/core/interactiveshell.py"", line 2856, in run_ast_nodes
    if self.run_code(code, result):
  File ""/usr/lib/python3.6/site-packages/IPython/core/interactiveshell.py"", line 2910, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File ""<ipython-input-6-c66df78b6d6a>"", line 1, in <module>
    retrain.main(None)
  File ""/usr/local/src/tensorflow/tensorflow/tensorflow/examples/image_retraining/retrain.py"", line 1024, in main
    create_model_graph(model_info))
  File ""/usr/local/src/tensorflow/tensorflow/tensorflow/examples/image_retraining/retrain.py"", line 291, in create_model_graph
    model_info['resized_input_tensor_name'],
  File ""/home/rick/.local/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py"", line 316, in new_func
    return func(*args, **kwargs)
  File ""/home/rick/.local/lib/python3.6/site-packages/tensorflow/python/framework/importer.py"", line 548, in import_graph_def
    op_def=op_def)
  File ""/home/rick/.local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 3160, in create_op
    op_def=op_def)
  File ""/home/rick/.local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 1617, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access

InvalidArgumentError (see above for traceback): ConcatOp : Dimensions of inputs should match: shape[0] = [1,75,75,42] vs. shape[2] = [1,42,75,75]
	 [[Node: cell_stem_0/cell_output/concat = _MklConcatV2[N=4, T=DT_FLOAT, Tidx=DT_INT32, _kernel=""MklOp"", _device=""/job:localhost/replica:0/task:0/device:CPU:0""](cell_stem_0/comb_iter_1/combine/add, cell_stem_0/comb_iter_2/combine/add, cell_stem_0/comb_iter_3/combine/add, cell_stem_0/comb_iter_4/combine/add, cell_17/split/split_dim, DMT/_121, DMT/_122, cell_stem_0/comb_iter_3/combine/add:1, DMT/_123, DMT/_124)]]
)

```
",rickhg12hs,b'stat:awaiting model gardener type:bug',2018-01-11T03:24:24Z,2020-06-12T02:41:45Z,,,,,,,
3140,Fix bug in gym_wrapper.,Added an 'env' parameter to env_step function since one an unreferenced one is used in the function.,ashaw596,b'cla: yes',2018-01-10T17:17:54Z,2018-01-16T18:15:46Z,,,,,,,
3138,Object detection API has very slow inference time with Tensorflow Serving,"I am unable to match the inference times reported for models released in object detection [model zoo](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md). Specifically I am trying out `faster_rcnn_resnet101_coco` model where the reported inference time is 106ms on a Titan X GPU.

My serving system is using TF 1.4 running in a container built from the [Dockerfile](https://github.com/tensorflow/serving/blob/master/tensorflow_serving/tools/docker/Dockerfile.devel-gpu) released by Google. My client is modeled after the [inception client](https://github.com/tensorflow/serving/blob/master/tensorflow_serving/example/inception_client.py) also released by Google.

My experiments are using 1 Titan X with TF 1.4. My total inference time `~330ms` is 3x worse than reported by Google - `106ms`. On further debugging I find that making the [tensor proto](https://github.com/tensorflow/serving/blob/master/tensorflow_serving/example/inception_client.py#L49-L50) is taking `~150ms` and [Predict](https://github.com/tensorflow/serving/blob/master/tensorflow_serving/example/inception_client.py#L51) is taking `~180ms`. My `saved_model.pb` is directly from the tar file downloaded from the model zoo. Is there something I am missing? What steps can I take to reduce the inference time?

Other details: 

### System information
- **What is the top-level directory of the model you are using**:
`https://github.com/tensorflow/models/tree/master/research/object_detection`
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
`no`
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
`Client is Linux Ubuntu 14.04.`
- **TensorFlow installed from (source or binary)**:
`binary`
- **TensorFlow version (use command below)**:
`1.4`
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
`CUDA 8, Cudnn v6`
- **GPU model and memory**:
`Titan X, 16GB`

I also created a stack overflow question [here](https://stackoverflow.com/questions/47896671/tensorflow-object-detection-api-has-slow-inference-time-with-tensorflow-serving).",siddharthm83,b'stat:awaiting model gardener',2018-01-10T15:06:55Z,2019-09-10T08:52:56Z,,,,,,,
3137,Double tensorflow INFO: when using a slim pretrained model,"### System information
- **What is the top-level directory of the model you are using**: object-detection
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: source and binary
- **TensorFlow version (use command below)**: 1.4.1
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**: 8.0
- **GPU model and memory**: gtx 980
- **Exact command to reproduce**:

### Describe the problem
When i restore a slim pretrained model ( like inception-v2) all the tensorflow mwssage info are duplicated.
Es:
INFO:tensorflow:Restoring parameters from /home/simone/Documents/inception_v2.ckpt
INFO:tensorflow:Restoring parameters from /home/simone/Documents/inception_v2.ckpt
INFO:tensorflow:Processed 0 images...
INFO:tensorflow:Processed 0 images...

The bug seems to be in the function `get_variables_available_in_checkpoint` in [https://github.com/tensorflow/models/blob/master/research/object_detection/utils/variables_helper.py](url)



### Source code / logs
i solved this issue commenting this part of the function :
```
       # else:
        #     logging.warning('Variable [%s] not available in checkpoint',
        #                     variable_name)

```
```
def get_variables_available_in_checkpoint(variables, checkpoint_path):
    """"""Returns the subset of variables available in the checkpoint.

    Inspects given checkpoint and returns the subset of variables that are
    available in it.

    TODO: force input and output to be a dictionary.

    Args:
      variables: a list or dictionary of variables to find in checkpoint.
      checkpoint_path: path to the checkpoint to restore variables from.

    Returns:
      A list or dictionary of variables.
    Raises:
      ValueError: if `variables` is not a list or dict.
    """"""
    if isinstance(variables, list):
        variable_names_map = {variable.op.name: variable for variable in variables}
    elif isinstance(variables, dict):
        variable_names_map = variables
    else:
        raise ValueError('`variables` is expected to be a list or dict.')
    ckpt_reader = tf.train.NewCheckpointReader(checkpoint_path)
    ckpt_vars = ckpt_reader.get_variable_to_shape_map().keys()
    vars_in_ckpt = {}
    for variable_name, variable in sorted(variable_names_map.items()):
        if variable_name in ckpt_vars:
            vars_in_ckpt[variable_name] = variable
        # else:
        #     logging.warning('Variable [%s] not available in checkpoint',
        #                     variable_name)
    if isinstance(variables, list):
        return vars_in_ckpt.values()
    return vars_in_ckpt

```",Lizzard93,None,2018-01-10T14:32:38Z,2018-11-02T02:26:51Z,,,,,,,
3132,object_detection A problem (bug?) when training a detection model in the multiclass setting,"### System information
- **What is the top-level directory of the model you are using**: research/object_detection
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: no
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Debian 4.9.65
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: ('v1.4.0-19-ga52c8d9', '1.4.1')
- **Bazel version (if compiling from source)**: 
- **CUDA/cuDNN version**:  8.0 / 6
- **GPU model and memory**: P100 16GB
- **Exact command to reproduce**: N/A

### Describe the problem
I use the object detection API to fine-tune the faster-rcnn detection model on
my custom dataset. The dataset often has multiple identical object boxes with
different labels. Thus, I use sigmoid score converter, sigmoid classification
loss and enable ""merge_multiple_label_boxes: true"" in the config file. Unfortunately,
I get very poor model in the end. The box labels are generally correct, but their locations
and confidences are poor.

I suspect that there is either something wrong with my configuration file or there is
a bug in how multiclass detection datasets are handled.

I can reliably reproduce the wrong behavior by enabling the option ""merge_multiple_label_boxes: true""
for multi-class datasets. In other words, the problem appears when a *k-hot label encoding* is used.

I verified that, when using the sigmoid score converter and the sigmoid
loss, a detection model works fine with 1-hot label encoding (i.e. unique labels per box).
Thus, I presume that k-hot encoding breaks the detection pipeline, but I am
not able to find the exact reason.

In the following I describe a minimal example for reproducing the error.

### Source code / logs
I've created a fork with minimal changes, which allows to reproduce the problem: https://github.com/kolesman/models

Specifically, I implement the following changes:

1. Modify the *create_pet_tf_record.py* to produce multiclass dataset.
    A box labeled by a class $c$ is populated by labels $c + 1$ and $c + 2$.

2. Modify the sample config file faster_rcnn_resnet101_pets.config by
      -> enabling sigmoid score converter
      -> enabling sigmoid loss
      -> enabling ""merge_multiple_label_boxes: true""

Otherwise, I closely follow the repository instructions, use mscoco pretrained model and
employ train.py and eval.py scripts:
```bash

# from research/
python object_detection/dataset_tools/create_pet_tf_record.py --label_map_path=object_detection/data/pet_label_map.pbtxt --data_dir=`pwd` --output_dir=`pwd`

# from research/object_detection
python train.py --logtostderr --pipeline_config_path=samples/configs/faster_rcnn_resnet101_pets.config --train_dir=train_dir

# from research/object_detection
python eval.py --logtostderr --pipeline_config_path=samples/configs/faster_rcnn_resnet101_pets.config --checkpoint_dir=train_dir/ --eval_dir=eval_dir

```

The resulting detection outputs after more then 10.000 iterations of training are attached here.
![multiclass](https://user-images.githubusercontent.com/460828/34731442-a28e50e2-f562-11e7-8838-15fb963ac735.png)

The labels are generally correct, but the boxes and their confidences are very poor.
Interestingly, quality of boxes degrades over the course of training.

",kolesman,b'stat:awaiting model gardener',2018-01-09T18:28:34Z,2020-02-07T18:43:51Z,,,,,,,
3122,[blog_estimators_dataset.py] bug fix for failing demo,"Here's the error I got before making this fix:

```
TensorFlow version: 1.5.0-rc0
Traceback (most recent call last):
  File ""/Users/timmolter/workspaces/workspace_tf/models/samples/outreach/blogs/blog_estimators_dataset.py"", line 86, in <module>
    next_batch = my_input_fn(FILE_TRAIN, True)  # Will return 32 random elements
  File ""/Users/timmolter/workspaces/workspace_tf/models/samples/outreach/blogs/blog_estimators_dataset.py"", line 76, in my_input_fn
    .map(decode_csv))  # Transform each elem by applying decode_csv fn
  File ""/usr/local/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py"", line 780, in map
    return MapDataset(self, map_func)
  File ""/usr/local/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py"", line 1583, in __init__
    self._map_func.add_to_graph(ops.get_default_graph())
  File ""/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/function.py"", line 486, in add_to_graph
    self._create_definition_if_needed()
  File ""/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/function.py"", line 321, in _create_definition_if_needed
    self._create_definition_if_needed_impl()
  File ""/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/function.py"", line 338, in _create_definition_if_needed_impl
    outputs = self._func(*inputs)
  File ""/usr/local/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py"", line 1571, in tf_map_func
    ret, [t.get_shape() for t in nest.flatten(ret)])
  File ""/usr/local/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py"", line 1571, in <listcomp>
    ret, [t.get_shape() for t in nest.flatten(ret)])
AttributeError: 'list' object has no attribute 'get_shape'
```",timmolter,b'cla: yes',2018-01-08T08:44:21Z,2018-01-09T17:39:59Z,,,,,,,
3117,Problem running my own model following the TensorFlow for Poets 2: Optimize for Mobile tutorial,"### System information
- **OS Platform and Distribution: 
     1) Windows 10 for Android Studio and Training Custom Model via Tensorflow-GPU;  
     2) Ubuntu 16.04 (via Oracle VM VirtualBox) to follow TensorFlow for Poets 2: Optimize for Mobile Tutorial 
- **TensorFlow installed from (source or binary)**: Binary
- **TensorFlow version (use command below)**: 1.4
- **CUDA/cuDNN version**:  Cuda Toolkit 8.0 and cuDNN v5.1
- **GPU model and memory**: NVIDIA GTX 1070. 8GB
- **Exact command to reproduce**: Please see ""TensorFlow for Poets 2: Optimize for Mobile"" tutorial.

### Describe the problem
I am following the ""TensorFlow for Poets 2: Optimize for Mobile"" tutorial and everything works just fine until I tried and run my own model on a virtual device (Nexus 5x API 27 x86). Please note that I have successfully ran the default app (setup classifies images into one of the 1000 ImageNet classes, using the standard MobileNet) before running into this problem. 
Furthermore, I have already followed the below instructions and modified my ClassifierActivity.java file accordinly. I suspect I need to deploy this apk on a real Android device instead of using a virtual device. I won't get my hand on a real device in 2-3 weeks so I appreciate any help to resolve this bug. Thank you for any help in advance!

Instructions to run custom model:
  // These are the settings for the original v1 Inception model. If you want to
  // use a model that's been produced from the TensorFlow for Poets codelab,
  // you'll need to set IMAGE_SIZE = 299, IMAGE_MEAN = 128, IMAGE_STD = 128,
  // INPUT_NAME = ""Mul"", and OUTPUT_NAME = ""final_result"".
  // You'll also need to update the MODEL_FILE and LABEL_FILE paths to point to
  // the ones you produced.


### Source code / logs
01/06 17:25:08: Launching tfmobile
$ adb install-multiple -r -t D:\tensorflow_skinlesion\android\tfmobile\gradleBuild\intermediates\split-apk\debug\dep\dependencies.apk D:\tensorflow\android\tfmobile\gradleBuild\intermediates\split-apk\debug\slices\slice_0.apk D:\tensorflow\android\tfmobile\gradleBuild\intermediates\split-apk\debug\slices\slice_1.apk D:\tensorflow\android\tfmobile\gradleBuild\intermediates\split-apk\debug\slices\slice_2.apk D:\tensorflow\android\tfmobile\gradleBuild\intermediates\split-apk\debug\slices\slice_3.apk D:\tensorflow\android\tfmobile\gradleBuild\intermediates\split-apk\debug\slices\slice_4.apk D:\tensorflow\android\tfmobile\gradleBuild\intermediates\split-apk\debug\slices\slice_5.apk D:\tensorflow\android\tfmobile\gradleBuild\intermediates\split-apk\debug\slices\slice_6.apk D:\tensorflow\android\tfmobile\gradleBuild\intermediates\split-apk\debug\slices\slice_7.apk D:\tensorflow\android\tfmobile\gradleBuild\intermediates\split-apk\debug\slices\slice_8.apk D:\tensorflow\android\tfmobile\gradleBuild\intermediates\split-apk\debug\slices\slice_9.apk D:\tensorflow\android\tfmobile\gradleBuild\outputs\apk\debug\tfmobile-debug.apk 
Split APKs installed
$ adb shell am start -n ""org.tensorflow.demo/org.tensorflow.demo.ClassifierActivity"" -a android.intent.action.MAIN -c android.intent.category.LAUNCHER
Client not ready yet..Waiting for process to come online
Connected to process 4543 on device emulator-5554
Capturing and displaying logcat messages from application. This behavior can be disabled in the ""Logcat output"" section of the ""Debugger"" settings page.
I/InstantRun: starting instant run server: is main process
D/tensorflow: CameraActivity: onCreate org.tensorflow.demo.ClassifierActivity@33c8742
D/tensorflow: CameraActivity: onStart org.tensorflow.demo.ClassifierActivity@33c8742
D/tensorflow: CameraActivity: onResume org.tensorflow.demo.ClassifierActivity@33c8742
D/OpenGLRenderer: HWUI GL Pipeline
I/zygote: android::hardware::configstore::V1_0::ISurfaceFlingerConfigs::hasWideColorDisplay retrieved: 0
I/OpenGLRenderer: Initialized EGL, version 1.4
D/OpenGLRenderer: Swap behavior 1
W/OpenGLRenderer: Failed to choose config with EGL_SWAP_BEHAVIOR_PRESERVED, retrying without...
D/OpenGLRenderer: Swap behavior 0
D/EGL_emulation: eglCreateContext: 0xa490c700: maj 3 min 1 rcv 4
D/EGL_emulation: eglMakeCurrent: 0xa490c700: ver 3 1 (tinfo 0x92f460a0)
E/eglCodecCommon: glUtilsParamSize: unknow param 0x000082da
E/eglCodecCommon: glUtilsParamSize: unknow param 0x000082da
E/eglCodecCommon: glUtilsParamSize: unknow param 0x00008cdf
E/eglCodecCommon: glUtilsParamSize: unknow param 0x00008cdf
E/eglCodecCommon: glUtilsParamSize: unknow param 0x00008824
E/eglCodecCommon: glUtilsParamSize: unknow param 0x00008824
I/CameraManagerGlobal: Connecting to camera service
I/tensorflow: CameraConnectionFragment: Desired size: 640x480, min size: 480x480
I/tensorflow: CameraConnectionFragment: Valid preview sizes: [640x480]
I/tensorflow: CameraConnectionFragment: Rejected preview sizes: [352x288, 320x240, 176x144]
I/tensorflow: CameraConnectionFragment: Exact size match found.
D/AndroidRuntime: Shutting down VM
E/AndroidRuntime: FATAL EXCEPTION: main
                  Process: org.tensorflow.demo, PID: 4543
                  java.lang.ArrayIndexOutOfBoundsException: length=1; index=1
                      at org.tensorflow.demo.TensorFlowImageClassifier.create(TensorFlowImageClassifier.java:89)
                      at org.tensorflow.demo.ClassifierActivity.onPreviewSizeChosen(ClassifierActivity.java:130)
                      at org.tensorflow.demo.CameraActivity$1.onPreviewSizeChosen(CameraActivity.java:159)
                      at org.tensorflow.demo.CameraConnectionFragment.setUpCameraOutputs(CameraConnectionFragment.java:421)
                      at org.tensorflow.demo.CameraConnectionFragment.openCamera(CameraConnectionFragment.java:428)
                      at org.tensorflow.demo.CameraConnectionFragment.access$000(CameraConnectionFragment.java:64)
                      at org.tensorflow.demo.CameraConnectionFragment$1.onSurfaceTextureAvailable(CameraConnectionFragment.java:95)
                      at android.view.TextureView.getHardwareLayer(TextureView.java:390)
                      at android.view.TextureView.draw(TextureView.java:339)
                      at android.view.View.updateDisplayListIfDirty(View.java:18142)
                      at android.view.View.draw(View.java:18920)
                      at android.view.ViewGroup.drawChild(ViewGroup.java:4236)
                      at android.view.ViewGroup.dispatchDraw(ViewGroup.java:4022)
                      at android.view.View.updateDisplayListIfDirty(View.java:18133)
                      at android.view.View.draw(View.java:18920)
                      at android.view.ViewGroup.drawChild(ViewGroup.java:4236)
                      at android.view.ViewGroup.dispatchDraw(ViewGroup.java:4022)
                      at android.view.View.draw(View.java:19195)
                      at android.view.View.updateDisplayListIfDirty(View.java:18142)
                      at android.view.View.draw(View.java:18920)
                      at android.view.ViewGroup.drawChild(ViewGroup.java:4236)
                      at android.view.ViewGroup.dispatchDraw(ViewGroup.java:4022)
                      at android.view.View.updateDisplayListIfDirty(View.java:18133)
                      at android.view.View.draw(View.java:18920)
                      at android.view.ViewGroup.drawChild(ViewGroup.java:4236)
                      at android.view.ViewGroup.dispatchDraw(ViewGroup.java:4022)
                      at android.view.View.updateDisplayListIfDirty(View.java:18133)
                      at android.view.View.draw(View.java:18920)
                      at android.view.ViewGroup.drawChild(ViewGroup.java:4236)
                      at android.view.ViewGroup.dispatchDraw(ViewGroup.java:4022)
                      at android.view.View.draw(View.java:19195)
                      at com.android.internal.policy.DecorView.draw(DecorView.java:788)
                      at android.view.View.updateDisplayListIfDirty(View.java:18142)
                      at android.view.ThreadedRenderer.updateViewTreeDisplayList(ThreadedRenderer.java:669)
                      at android.view.ThreadedRenderer.updateRootDisplayList(ThreadedRenderer.java:675)
                      at android.view.ThreadedRenderer.draw(ThreadedRenderer.java:783)
                      at android.view.ViewRootImpl.draw(ViewRootImpl.java:2992)
                      at android.view.ViewRootImpl.performDraw(ViewRootImpl.java:2806)
                      at android.view.ViewRootImpl.performTraversals(ViewRootImpl.java:2359)
                      at android.view.ViewRootImpl.doTraversal(ViewRootImpl.java:1392)
                      at android.view.ViewRootImpl$TraversalRunnable.run(ViewRootImpl.java:6752)
                      at android.view.Choreographer$CallbackRecord.run(Choreographer.java:911)
                      at android.view.Choreographer.doCallbacks(Choreographer.java:723)
                      at android.view.Choreographer.doFrame(Choreographer.java:658)
                      at android.view.Choreographer$FrameDisplayEventReceiver.run(Choreographer.java:897)
                      at android.os.Handler.handleCallback(Handler.java:790)
                      at android.os.Handler.dispatchMessage(Handler.java:99)
                      at android.os.Looper.loop(Looper.java:164)
                      at android.app.ActivityThread.main(ActivityThread.java:6494)
                      at java.lang.reflect.Method.invoke(Native Method)
                      at com.android.internal.os.RuntimeInit$MethodAndArgsCaller.run(RuntimeInit.java:438)
                      at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:807)
Application terminated.
  ",PhillipLy,None,2018-01-07T01:39:55Z,2018-03-04T21:26:30Z,,,,,,,
3103,from six.moves import xrange,"The following files are incompatible with Python 3 at least in part because they use xrange() yet they lack the import:
* __from six.moves import xrange__
```
./research/compression/entropy_coder/dataset/gen_synthetic_dataset.py
./research/compression/entropy_coder/dataset/synthetic_model.py
./research/compression/entropy_coder/lib/blocks_masked_conv2d.py
./research/compression/entropy_coder/lib/blocks_masked_conv2d_test.py
./research/compression/entropy_coder/lib/blocks_std_test.py
./research/delf/delf/python/feature_io.py
./research/differential_privacy/dp_sgd/dp_mnist/dp_mnist.py
./research/differential_privacy/dp_sgd/per_example_gradients/per_example_gradients.py
./research/differential_privacy/multiple_teachers/aggregation.py
./research/differential_privacy/multiple_teachers/deep_cnn.py
./research/differential_privacy/multiple_teachers/input.py
./research/differential_privacy/multiple_teachers/train_student.py
./research/domain_adaptation/domain_separation/dsn_eval.py
./research/gan/cifar/util.py
./research/gan/image_compression/networks_test.py
./research/gan/mnist/util.py
./research/gan/mnist_estimator/train.py
./research/im2txt/im2txt/data/build_mscoco_data.py
./research/learned_optimizer/metaopt.py
./research/learning_to_remember_rare_events/data_utils.py
./research/learning_to_remember_rare_events/memory.py
./research/learning_to_remember_rare_events/train.py
./research/lfads/synth_data/generate_itb_data.py
./research/lfads/synth_data/generate_labeled_rnn_data.py
./research/neural_gpu/data_utils.py
./research/next_frame_prediction/cross_conv/eval.py
./research/next_frame_prediction/cross_conv/example_gen.py
./research/next_frame_prediction/cross_conv/model.py
./research/next_frame_prediction/cross_conv/reader.py
./research/next_frame_prediction/cross_conv/sprites_gen.py
./research/object_detection/dataset_tools/oid_tfrecord_creation.py
./research/object_detection/utils/np_box_list_ops.py
./research/pcl_rl/baseline.py
./research/pcl_rl/controller.py
./research/pcl_rl/env_spec.py
./research/pcl_rl/expert_paths.py
./research/pcl_rl/gym_wrapper.py
./research/pcl_rl/optimizers.py
./research/pcl_rl/replay_buffer.py
./research/pcl_rl/trainer.py
./research/pcl_rl/trust_region.py
./research/ptn/metrics.py
./research/ptn/model_ptn.py
./research/ptn/model_rotator.py
./research/ptn/model_voxel_generation.py
./research/ptn/pretrain_rotator.py
./research/ptn/utils.py
./research/real_nvp/real_nvp_utils.py
./research/slim/datasets/build_imagenet_data.py
./research/slim/datasets/preprocess_imagenet_validation_data.py
./research/slim/datasets/process_bounding_boxes.py
./research/slim/nets/cyclegan.py
./research/slim/nets/dcgan.py
./research/slim/nets/dcgan_test.py
./research/street/python/decoder.py
./research/street/python/shapes.py
./research/street/python/vgslspecs.py
./research/syntaxnet/dragnn/python/graph_builder_test.py
./research/syntaxnet/dragnn/python/network_units.py
./research/syntaxnet/dragnn/python/spec_builder.py
./research/syntaxnet/dragnn/python/trainer_lib.py
./research/tcn/labeled_eval.py
```
  
  ",cclauss,b'help wanted type:bug',2018-01-04T10:55:43Z,2018-08-14T20:37:28Z,,,,,,,
3094,savedModel builder im2txt,"@cshallue
@jhseu 
@sukritiramesh 
Can we have a savedModel builder script for the im2txt model?
It would not only directly benefit the users of this model,
it would be another example of how saved model works and there are precious few.

Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**: research
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:no
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: fedora 27
- **TensorFlow installed from (source or binary)**:source
- **TensorFlow version (use command below)**:1.4
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:n/a
- **GPU model and memory**:n/a
- **Exact command to reproduce**:n/a

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""


### Describe the problem
@cshallue
@jhseu 
@sukritiramesh 
Can we have a savedModel builder script for the im2txt model?
It would not only directly benefit the users of this model,
it would be another example of how saved model works and there are precious few.

### Source code / logs
N/a
",DecentGradient,b'stat:awaiting model gardener type:feature',2018-01-02T23:32:32Z,2020-02-07T18:43:50Z,,,,,,,
3077,tensorflow.python.framework.errors_impl.NotFoundError:  /root/tensorflow/models/research/images/frame19_14; No such file or directory,"






Hi,

I am trying to create the TF Record files. However, when I run the following code I get the below error when I run 

> python object_detection/dataset_tools/create_pet_tf_record.py     --label_map_path=object_detection/data/shoecover_label_map.pbtxt     --data_dir=`pwd`     --output_dir=`pwd`python object_detection/dataset_tools/create_pet_tf_record.py     --label_map_path=object_detection/data/shoecover_label_map.pbtxt     --data_dir=`pwd`     --output_dir=`pwd`

:

```
/root/tensorflow/models/research/object_detection/utils/dataset_util.py:75: FutureWarning: The behavior of this method will change in future versions. Use specific 'len(elem)' or 'elem is not None' test instead.
  if not xml:
Traceback (most recent call last):
  File ""object_detection/dataset_tools/create_pet_tf_record.py"", line 282, in <module>
    tf.app.run()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 48, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""object_detection/dataset_tools/create_pet_tf_record.py"", line 276, in main
    image_dir, train_examples, faces_only=FLAGS.faces_only)
  File ""object_detection/dataset_tools/create_pet_tf_record.py"", line 228, in create_tf_record
    data, mask_path, label_map_dict, image_dir, faces_only=faces_only)
  File ""object_detection/dataset_tools/create_pet_tf_record.py"", line 101, in dict_to_tf_example
    encoded_jpg = fid.read()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/lib/io/file_io.py"", line 119, in read
    self._preread_check()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/lib/io/file_io.py"", line 79, in _preread_check
    compat.as_bytes(self.__name), 1024 * 512, status)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/errors_impl.py"", line 473, in __exit__
    c_api.TF_GetCode(self.status.status))
tensorflow.python.framework.errors_impl.NotFoundError: /root/tensorflow/models/research/images/frame19_14; No such file or directory
```

The file frame19_14.jpg does exist however for some reason the program does not append the '.jpg' string to the file names in the trainval.txt file.
I am using the same format as the trainval.txt files in the sample pets data with the filename (minus any '.jpg') in the first flag.




------------------------

### System information
- **What is the top-level directory of the model you are using**:  ../dataset_tools/create_pet_tf_record.py
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: ('v1.4.0-20-g438604f', '1.4.1')
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**: python object_detection/dataset_tools/create_pet_tf_record.py     --label_map_path=object_detection/data/shoecover_label_map.pbtxt     --data_dir=`pwd`     --output_dir=`pwd`

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",imrandatascientist,b'stat:awaiting response',2017-12-28T13:20:39Z,2018-10-31T21:13:25Z,,,,,,,
3074,Object-detection: Feature request- visualize layer activations and step by step visualization for Faster RCNN models,"### System information
- **What is the top-level directory of the model you are using**: object_detection
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: no
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: 1.4.0
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:


**This is a feature request !**

While training Faster RCNN it is worth while to look at the RPN's class agnostic proposals to know  whether correct ROIs go into the ROI pooling layers. This visualization can be made in a rather indirect way by exploiting the first stage only = True option in config (after training with first stage only = False ) and using the export_inference_graph.py  after fixing #1916 .
It would be beneficial if it can be done in an easier way. (or an easier way is already present and am missing it?)

One more visualization that will be useful for debugging is: visualizing **layer-activations** in tensorboard. 

Thanks",Abhijit-2592,b'help wanted',2017-12-28T08:01:15Z,2020-02-07T18:43:49Z,,,,,,,
3071,Get UnavailableError when running object detection training on CloudML,"I can train an Object Detection model just fine locally, but when I try to run the training on CloudML, it runs for a little bit (during the last run it ran for about 340 steps) and then terminates because of the following error:

UnavailableError: Endpoint read failed

The full stack trace is pasted at the end of this post.

### System information
- **What is the top-level directory of the model you are using**: N/A, training my own model
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No, but the Object Detection source code was modified for workaround of bugs #2739 and #2653 
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: CloudML default
- **TensorFlow installed from (source or binary)**: N/A
- **TensorFlow version (use command below)**: 1.4
- **Bazel version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: CloudML default
- **GPU model and memory**: CloudML default
- **Exact command to reproduce**: sudo gcloud ml-engine jobs submit training object_detection_171227 --job-dir=gs://my-sandbox/ml/train --packages /Users/user/object_detection/models/research/dist/object_detection-0.1.tar.gz,/Users/user/object_detection/models/research/slim/dist/slim-0.1.tar.gz --module-name object_detection.train --runtime-version 1.4 --region us-east1 --config /Users/user/cloud_yml/cloud.yml -- --train_dir=gs://my-sandbox/ml/train --pipeline_config_path=gs://my-sandbox/ml/data/pipeline.config

Full stack trace:

 severity:  ""ERROR""  
 textPayload:  ""The replica worker 0 exited with a non-zero status of 1. Termination reason: Error. 
Traceback (most recent call last):
  File ""/usr/lib/python2.7/runpy.py"", line 174, in _run_module_as_main
    ""__main__"", fname, loader, pkg_name)
  File ""/usr/lib/python2.7/runpy.py"", line 72, in _run_code
    exec code in run_globals
  File ""/root/.local/lib/python2.7/site-packages/object_detection/train.py"", line 163, in <module>
    tf.app.run()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 48, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""/root/.local/lib/python2.7/site-packages/object_detection/train.py"", line 159, in main
    worker_job_name, is_chief, FLAGS.train_dir)
  File ""/root/.local/lib/python2.7/site-packages/object_detection/trainer.py"", line 332, in train
    saver=saver)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/slim/python/slim/learning.py"", line 763, in train
    sess, train_op, global_step, train_step_kwargs)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/slim/python/slim/learning.py"", line 487, in train_step
    run_metadata=run_metadata)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 889, in run
    run_metadata_ptr)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1120, in _run
    feed_dict_tensor, options, run_metadata)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1317, in _do_run
    options, run_metadata)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1336, in _do_call
    raise type(e)(node_def, op, message)
UnavailableError: Endpoint read failed

",glarchev,None,2017-12-27T20:35:36Z,2018-12-28T21:43:29Z,,,,,,,
3068,Object detection. No cropping in evaluation config results in wrong validation,"### System information
- **What is the top-level directory of the model you are using**: object_detection
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: binary for anaconda python
- **TensorFlow version (use command below)**: v1.4.0-rc1-11-g130a514 1.4.0
- **Bazel version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: 6.0
- **GPU model and memory**: gtx1060 6gb
- **Exact command to reproduce**:

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

I train the ssd mobilenet v1 model on the kitti dataset.
I want the model input to be 640x360 (aspect ratio 16:9 ~ 1.7778)
```
    image_resizer {
      fixed_shape_resizer {
        height: 360
        width: 640
      }
    }
```
Kitti dataset image resolution is 1242x375 (aspect ratio 3.312)

I use a following preprocessing in train_config to use subimage with standard aspect ratio.
```
  data_augmentation_options {
    random_crop_to_aspect_ratio {
      aspect_ratio: 1.7778
      overlap_thresh: 0.8
    }
  }
```

So the training images are first cropped to 667x375 and are then resized to 640x360, resulting in normal training picture.

But there is no such preprocessing during the evaluation step, which means that validation images 1242x375 are just resized to 640x360, which results in images with squeezed road objects.

Because of that I get poor accuracy on the validation accuracy chart in tensorboard, but the model actually performs well during the manual testing, when I feed it with 16:9 aspect ratio images.

Is there a way to reproduce the same cropping during the validation step?",SergeyBykov1,b'stat:awaiting model gardener type:bug',2017-12-27T12:31:18Z,2020-02-07T18:43:48Z,,,,,,,
3051,How to train object detection model through jog format without tfrecord ?,"I really suggest you offer the way to train models with another method.Because tfrecord is so hard to debug,and it's not very friendly with new dataset.",shyanguan,None,2017-12-24T02:58:22Z,2017-12-28T19:03:45Z,,,,,,,
3045,error 'build' command is only supported from within a workplace,"I have installed bazel in win10. I tried to run 'bazel build tensorflow/examples/image_retraining:retrain' in the cmd command window. But I countered the error: error 'build' command is only supported from within a workplace. Could anyone help me how to overcome this problem, please? Thanks so much


Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",xhm1014,b'type:support',2017-12-21T19:56:17Z,2017-12-22T20:06:12Z,,,,,,,
3009,Fix a bug in create_pet_tf_record.py related to mask creation.,,derekjchow,b'cla: yes',2017-12-14T22:59:47Z,2017-12-14T23:53:39Z,,,,,,,
3007,fix eval_training_data bug,"`eval_training_data` flag seems no effect.
Since no code handles `eval_training_data` flag, `input_config = configs['eval_input_config']` will be always executed, even though ‘eval_training_data’ is set to `Ture`.
When ‘eval_training_data’ is set to `Ture`, `input_config` should be `configs['train_input_config']`.
I fix the bug in pull request.",jzhugithub,b'cla: yes',2017-12-14T14:40:29Z,2017-12-14T18:34:19Z,,,,,,,
2995,Invalid argument: assertion failed: [maximum box coordinate value is larger than 1.010000: ],"### System information
- **What is the top-level directory of the model you are using**: `object_detection`
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes (but using object_detection extensively)
- **OS Platform and Distribution**: Windows 10
- **TensorFlow installed from (source or binary)**: pip
- **TensorFlow version (use command below)**: tensorflow-gpu 1.4.0
- **Bazel version (if compiling from source)**: n/a
- **CUDA/cuDNN version**: Cuda 8.0 / cudnn64_6 
- **GPU model and memory**: GeForce GTX 1070
- **Exact command to reproduce**: `python models/research/object_detection/eval.py ...`

### Describe the problem
When evaluating on a trained ssd_inception_v2_coco model, I get this error: `W C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\framework\op_kernel.cc:1192] Invalid argument: assertion failed: [maximum box coordinate value is larger than 1.010000: ] [447]`

Digging deeper into it, I found the following:
* https://github.com/tensorflow/models/commit/8a72df2d8c62f7ffa2d58995fc5d484e47955546 sets `scale_to_absolute` to True unconditionally when calling `eval_util.result_dict_for_single_example` from the evaluator. 
* https://github.com/tensorflow/models/pull/2618/files sets a default for maximum_normalized_coordinate and other arguments of `to_absolute_coordinates`, thus making the check effective

Now, this creates an expectation that my data comes with normalized coordinates, but I do not think this reflects the paper or any documentation.

So I cannot fully determine whether it is a bug or expected behavior. If the latter is the case, perhaps a preprocessing step is required?

### Source code / logs

    2017-12-12 11:46:56.149089: W C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\framework\op_kernel.cc:1192] Invalid argument: assertion failed: [maximum box coordinate value is larger than 1.010000: ] [447]
    [[Node: ToAbsoluteCoordinates_1/Assert/AssertGuard/Assert = Assert[T=[DT_STRING, DT_FLOAT], summarize=3, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](ToAbsoluteCoordinates_1/Assert/AssertGuard/Assert/Switch/_1533, ToAbsoluteCoordinates_1/Assert/AssertGuard/Assert/data_0, ToAbsoluteCoordinates_1/Assert/AssertGuard/Assert/Switch_1/_1535)]]

https://github.com/tensorflow/models/issues/1754 has the same message, but the poster explicitly said they do not experience this with ssd_inception_v2_coco",monomon,b'stat:awaiting model gardener type:support',2017-12-12T09:57:32Z,2019-01-25T01:43:37Z,,,,,,,
2952,Got high loss after restoring parameters from ckpt,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**: research
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: customized for task of segmentation
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 14.04 (64bit)
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.20
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**: CUDA-8 CUDNN-6
- **GPU model and memory**: Tesla-P100
- **Exact command to reproduce**: 
```bash
TRAIN_DIR=object_detection/ckpt/ssd_inception
PIPELINE_CONFIG_PATH=object_detection/samples/configs/ssd_inception_v2_coco.config

python3 object_detection/train.py \
            --logtostderr \
            --pipeline_config_path=${PIPELINE_CONFIG_PATH} \
            --train_dir=${TRAIN_DIR}
```

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Hi everyone here:
    I have got a issue when training (fine-tuning) Tensorflow Object Detection API model.
I restored parameters from fine-tuning-ckpt (saved models to another directory, e.g., TRAIN_DIR), and after fine-tuning with big learning rate, the loss decreased as I expected. As it went lower and lower (e.g., 2.0), it is time to use smaller learning rate. So I moved the saved parameters from TRAIN_DIR to fine-tuning-ckpt, and removed all files under TRAIN_DIR. When I re-run the program, I expected the loss to be low (about 2.0), but got 300+. I tried several times and got the same results every time. So I guess the reason is that, the program I was running did not use the saved parameters (or did not restore from TRAIN_DIR), so I printed the variables_to_restore but found that all variable names. Does anybody have any idea or have the same problem ?

Best Regards


### Source code / logs
",xiaoxTM,None,2017-12-04T09:47:38Z,2018-11-03T00:30:57Z,,,,,,,
2937, export_inference_graph.py,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",Zhangxu0501,None,2017-12-01T05:54:02Z,2017-12-01T05:54:34Z,,,,,,,
2936,precision vs accuracy in cifar10_eval.py,"### System information
- **What is the top-level directory of the model you are using**: /tensorflow/models/tree/master/tutorials/image/cifar10
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:NO
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:Linux Ubuntu 16.04.3
- **TensorFlow installed from (source or binary)**:binary
- **TensorFlow version (use command below)**:1.1.0
- **Bazel version (if compiling from source)**:NA
- **CUDA/cuDNN version**:7
- **GPU model and memory**:nvidia geforce 1080Ti /11172 MiB
- **Exact command to reproduce**: python cifar10_eval.py

**error:**
The output of the script is ""precision"", however the correct term should be ""accuracy""
""2017-11-30 19:55:56.608454: precision @ 1 = 0.866""


**solution:**
change ""precision"" to ""accuracy"" in cifar10_eval.py also remove ""@1"" (whatever that means)
add epochs and time that went by  to calculate the accuracy.

**additional comments:**
the script itself talks about ""accuracy"" in the comment section, so the coder was aware about that fact,
later the term was confused with precision.
See: [accuracy vs precision](https://www.google.com/search?q=accuracy+vs+precision)




",tobigithub,b'stat:awaiting model gardener type:bug',2017-12-01T04:03:04Z,2017-12-02T03:05:16Z,,,,,,,
2930,object_detection/protos/*.proto: No such file or directory,"As mentioned above the error takes place in while executing the command in the windows cmd prompt.

>D:/BB/bin/protoc object_detection/protos/*.proto --python_out=.

as for the reference in the installation process of object detection in this model.

in protobuf compilation.",Hemanth2396,b'stat:awaiting response type:bug',2017-11-30T06:09:54Z,2020-09-27T13:32:30Z,,,,,,,
2926,The faster rcnn module does not support batch_size > 1 for each clone,"https://github.com/tensorflow/models/blob/b63a73df70656ecfcd2d50bfc98b09b3ce06f635/research/object_detection/trainer.py#L155

The above line has a concat operation which only works for single image or images with the same width/height ratio, i.e., the same size after resize. 

This seems to be a bug; because in 
https://github.com/tensorflow/models/blob/01aa7a4a6190bf021f448dee26fc649f4b47753e/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py#L101, the comments show ""When training with a relative large batch size (e.g. 8), it could be desirable to enable batch norm update."" This indicates the authors plan to support more batch sizes. Also, I believe that this comment is misleading. Set batch norm parameters not trainable is OK for fine tuning, but NOT acceptable for training from scratch. If training from scratch, even if the batch size is 1, the batch norm still need to be set trainable.",ybsave,b'stat:awaiting model gardener type:bug',2017-11-29T21:19:09Z,2020-02-07T18:43:28Z,,,,,,,
2917,resnet50 initialization in version 1.4 doesn't work,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**: slim
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: AWS p3.2xlarge with RedHat Linux
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**: 9
- **GPU model and memory**: V100
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Resnet50 constructor seem to not work with version 1.4. 

### Source code / logs

Following simple constructor snippet of resnet50 constructor is runnig into trouble. Any leads would be great. Thanks in advance.

```
import tensorflow as tf
import tensorflow.contrib.slim as slim
from tensorflow.contrib.slim.nets import resnet_v1
inputs = tf.placeholder(tf.float32, shape=[1, 224, 224, 3])
with slim.arg_scope(resnet_v1.resnet_arg_scope()):
    net, end_points = resnet_v1.resnet_v1_50(inputs, is_training=False)
```

This gives following error. Not sure why, this works before on v1.2
```
Traceback (most recent call last):
  File ""<stdin>"", line 2, in <module>
  File ""/usr/lib/python2.7/dist-packages/tensorflow/contrib/slim/python/slim/nets/resnet_v1.py"", line 274, in resnet_v1_50
    scope=scope)
  File ""/usr/lib/python2.7/dist-packages/tensorflow/contrib/slim/python/slim/nets/resnet_v1.py"", line 205, in resnet_v1
    net = resnet_utils.conv2d_same(net, 64, 7, stride=2, scope='conv1')
  File ""/usr/lib/python2.7/dist-packages/tensorflow/contrib/slim/python/slim/nets/resnet_utils.py"", line 146, in conv2d_same
    scope=scope)
  File ""/usr/lib/python2.7/dist-packages/tensorflow/contrib/framework/python/ops/arg_scope.py"", line 182, in func_with_args
    return func(*args, **current_args)
  File ""/usr/lib/python2.7/dist-packages/tensorflow/contrib/layers/python/layers/layers.py"", line 1042, in convolution
    outputs = normalizer_fn(outputs, **normalizer_params)
  File ""/usr/lib/python2.7/dist-packages/tensorflow/contrib/framework/python/ops/arg_scope.py"", line 182, in func_with_args
    return func(*args, **current_args)
  File ""/usr/lib/python2.7/dist-packages/tensorflow/contrib/layers/python/layers/layers.py"", line 642, in batch_norm
    fused=fused)
  File ""/usr/lib/python2.7/dist-packages/tensorflow/python/layers/normalization.py"", line 148, in __init__
    self.dtype = dtype
AttributeError: can't set attribute
```",parthg,b'stat:awaiting model gardener',2017-11-28T14:30:03Z,2018-10-27T01:15:47Z,,,,,,,
2906,"3D reconstruction using tensorflow implementation of ptn, error in  pretraining rotator ","
Hi,
When I tried to pretrain the rotator model with the dataset provided in the webpage, I'm getting the following Value error and I guess the problem is with the inp_dir path for the dataset on the system.

Tried providing both absolute and relative path but still the problem persist, any help would be great since I'm completely new to tensorflow .

ERROR:
INFO: Analysed target //:pretrain_rotator (0 packages loaded).
INFO: Found 1 target...
Target //:pretrain_rotator up-to-date:
  bazel-bin/pretrain_rotator
INFO: Elapsed time: 0.174s, Critical Path: 0.01s
INFO: Build completed successfully, 1 total action

INFO: Running command line: bazel-bin/pretrain_rotator '--step_size=1' '--init_model=/tmp/ptn_train/'
/.shapenet_tf
Traceback (most recent call last):
  File ""/home/sbasavaraju/.cache/bazel/_bazel_sbasavaraju/b31d182e049bda91baa4373c1dc1e3ce/execroot/__main__/bazel-out/local-opt/bin/pretrain_rotator.runfiles/__main__/pretrain_rotator.py"", line 236, in <module>
    app.run()
  File ""/home/sbasavaraju/anaconda3/lib/python3.6/site-packages/tensorflow/python/platform/app.py"", line 48, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""/home/sbasavaraju/.cache/bazel/_bazel_sbasavaraju/b31d182e049bda91baa4373c1dc1e3ce/execroot/__main__/bazel-out/local-opt/bin/pretrain_rotator.runfiles/__main__/pretrain_rotator.py"", line 119, in main
    ['encoder', 'rotator', 'decoder'], FLAGS)
  File ""/media/sbasavaraju/DATA/ptn/model_rotator.py"", line 151, in get_regularization_loss
    return losses.regularization_loss(scopes, params)
  File ""/media/sbasavaraju/DATA/ptn/losses.py"", line 173, in regularization_loss
    reg_loss += tf.add_n([tf.nn.l2_loss(var) for var in scope_vars])
  File ""/home/sbasavaraju/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py"", line 1942, in add_n
    raise ValueError(""inputs must be a list of at least one Tensor with the ""
ValueError: inputs must be a list of at least one Tensor with the same dtype and shape
ERROR: Non-zero return code '1' from command: Process exited with status 1


------------------------

System information
-  top-level directory of the model you are using: ptn
- OS Platform and Distribution : Ubuntu 16.04
- TensorFlow version : 1.3.0
- Bazel version: 0.70


",Santubasa,b'stat:awaiting model gardener type:bug',2017-11-27T10:45:24Z,2017-11-30T12:32:14Z,,,,,,,
2884,Tensorflow[attention_ocr] eval.py Freezes ,"when I run the example that is wrote in the [link](https://github.com/tensorflow/models/blob/master/research/attention_ocr/python/eval.py)
 which is: `A simple usage example:
python eval.py`

the server freezes with the outputs:
```
(tensorflow)ubuntu@ip-172-31-31-92:/nsfs/tensor_models/models/research/attention_ocr/python$ python eval.py
INFO 2017-11-23 14:53:36.000674: fsns.py: 130 Using FSNS dataset split_name=train dataset_dir=/nsfs/tensor_models/models/research/attention_ocr/python/datasets/data/fsns
DEBUG 2017-11-23 14:53:36.000805: model.py: 354 images: Tensor(""shuffle_batch:0"", shape=(32, 150, 600, 3), dtype=float32)
DEBUG 2017-11-23 14:53:36.000838: model.py: 359 Views=4 single view: Tensor(""AttentionOcr_v1/split:0"", shape=(32, 150, 150, 3), dtype=float32)
DEBUG 2017-11-23 14:53:36.000838: model.py: 200 Using final_endpoint=Mixed_5d
DEBUG 2017-11-23 14:53:37.000284: model.py: 200 Using final_endpoint=Mixed_5d
DEBUG 2017-11-23 14:53:37.000419: model.py: 200 Using final_endpoint=Mixed_5d
DEBUG 2017-11-23 14:53:37.000553: model.py: 200 Using final_endpoint=Mixed_5d
DEBUG 2017-11-23 14:53:37.000688: model.py: 365 Conv tower: Tensor(""AttentionOcr_v1/conv_tower_fn/INCE/InceptionV3/Mixed_5d/concat:0"", shape=(32, 16, 16, 288), dtype=float32)
DEBUG 2017-11-23 14:53:37.000688: model.py: 368 Conv tower w/ encoded coordinates: Tensor(""AttentionOcr_v1/conv_tower_fn/INCE/InceptionV3/Mixed_5d/concat:0"", shape=(32, 16, 16, 288), dtype=float32)
DEBUG 2017-11-23 14:53:37.000690: model.py: 371 Pooled views: Tensor(""AttentionOcr_v1/pool_views_fn/STCK/Reshape:0"", shape=(32, 1024, 288), dtype=float32)
DEBUG 2017-11-23 14:53:37.000690: sequence_layers.py: 421 Use AttentionWithAutoregression as a layer class
DEBUG 2017-11-23 14:53:39.000137: model.py: 374 chars_logit: Tensor(""AttentionOcr_v1/sequence_logit_fn/SQLR/concat:0"", shape=(32, 37, 134), dtype=float32)
WARNING:tensorflow:From /nsfs/tensor_models/models/research/attention_ocr/python/model.py:406: get_total_loss (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.
Instructions for updating:
Use tf.losses.get_total_loss instead.
WARNING 2017-11-23 14:53:39.000864: tf_logging.py: 90 From /nsfs/tensor_models/models/research/attention_ocr/python/model.py:406: get_total_loss (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.
Instructions for updating:
Use tf.losses.get_total_loss instead.
WARNING:tensorflow:From /home/ubuntu/tensorflow/local/lib/python2.7/site-packages/tensorflow/contrib/losses/python/losses/loss_ops.py:261: get_losses (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.
Instructions for updating:
Use tf.losses.get_losses instead.
WARNING 2017-11-23 14:53:39.000865: tf_logging.py: 90 From /home/ubuntu/tensorflow/local/lib/python2.7/site-packages/tensorflow/contrib/losses/python/losses/loss_ops.py:261: get_losses (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.
Instructions for updating:
Use tf.losses.get_losses instead.
WARNING:tensorflow:From /home/ubuntu/tensorflow/local/lib/python2.7/site-packages/tensorflow/contrib/losses/python/losses/loss_ops.py:263: get_regularization_losses (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.
Instructions for updating:
Use tf.losses.get_regularization_losses instead.
WARNING 2017-11-23 14:53:39.000865: tf_logging.py: 90 From /home/ubuntu/tensorflow/local/lib/python2.7/site-packages/tensorflow/contrib/losses/python/losses/loss_ops.py:263: get_regularization_losses (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.
Instructions for updating:
Use tf.losses.get_regularization_losses instead.
WARNING:tensorflow:From eval.py:64: get_or_create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Please switch to tf.train.get_or_create_global_step
WARNING 2017-11-23 14:53:39.000901: tf_logging.py: 90 From eval.py:64: get_or_create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Please switch to tf.train.get_or_create_global_step
INFO:tensorflow:Waiting for new checkpoint at /tmp/attention_ocr/train
INFO 2017-11-23 14:53:39.000907: tf_logging.py: 82 Waiting for new checkpoint at /tmp/attention_ocr/train
```",ibr123,b'stat:awaiting model gardener type:bug',2017-11-23T16:07:13Z,2019-11-13T11:46:16Z,,,,,,,
2882,Swivel: Force bufsz to be the square of shard_size? ,"Hey, I'm new to swivel and I tried it on my custom dataset. Since my vocabulary is quite large, I increased the shard_size and left everything unchanged. Then I found this will not throw any error during running prep.py, but will cause encoding error while running swivel.py. For example:

`UnicodeDecodeError: 'utf8' codec can't decode byte 0xc1 in position 40: invalid start byte`

Then I realized that I also need to change bufsz to be square of shard_size. After fixing this, everything is back on track. So I'm wondering if it would be better to force bufsz to be the square of shard_size instead of hard-coding it to be 16M? Please correct me if I'm wrong. Thanks. ",tomahawklin,b'type:bug',2017-11-23T15:21:38Z,2020-02-07T18:43:28Z,,,,,,,
2878,Fixes bug where unwrapped cells are shared between layers,"The bug is causing the weights to be shared shared between layers.

Without this patch, if you train the model (--size=small) and take a look at tf.trainable_variables() after each epoch, you'll see that there is only one set of weights, even though the model has two layers. Note that the default configuration of the model will not currently run (at least it doesn't for me), you have to add --rnn_mode=basic or --rnn_mode=block to the command line (that is an independent issue).

When the medium and large (--size=medium and --size=large) size models are trained, there *does* seem to be an independent set of weights per layer, at least in the training and validation models, and so the bug seems to be masked by the LSTM cells being wrapped with DropoutWrapper in those cases. However, I believe that there is only one set of weights in the test model (which doesn't apply DropoutWrapper), but I have not confirmed this. This bug-masking effect seems to be related to a difference between how DropoutWrapper and BasicLSTMCell (and the other LSTM cells) inherit from RNNCell -- DropoutWrapper overrides `__call__()` whereas the LSTM cells do not. I don't understand how wrapping with DropoutWrapper masks the bug. The way it currently is, the model should consistently, and incorrectly, share weights between layers. 

I believe that this patch makes the model use the LSTM cells and DropoutWrapper correctly, as they are used in other models, including tensorflow/models/translate/seq2seq_model.py and tensorflow/nmt, by instantiating an independent instance of the cell for each layer. *Therefore I think that this patch should be applied even though the bug is masked in model configurations that use dropout*.",duncanriach,b'cla: yes',2017-11-22T23:41:09Z,2017-12-16T00:27:10Z,,,,,,,
2875,Oxford-IIIT Pet TFRecord file generation,"### System information
- environment capture script output:
```
== cat /etc/issue ===============================================
Linux xico-dell-linux 4.10.0-38-generic #42~16.04.1-Ubuntu SMP Tue Oct 10 16:32:20 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux
VERSION=""16.04.3 LTS (Xenial Xerus)""
VERSION_ID=""16.04""
VERSION_CODENAME=xenial

== are we in docker =============================================
No

== compiler =====================================================
c++ (Ubuntu 5.4.0-6ubuntu1~16.04.5) 5.4.0 20160609
Copyright (C) 2015 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.


== uname -a =====================================================
Linux xico-dell-linux 4.10.0-38-generic #42~16.04.1-Ubuntu SMP Tue Oct 10 16:32:20 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux

== check pips ===================================================
numpy (1.13.3)
protobuf (3.4.0)
tensorflow (1.4.0)
tensorflow-tensorboard (0.4.0rc3)

== check for virtualenv =========================================
False

== tensorflow import ============================================
tf.VERSION = 1.4.0
tf.GIT_VERSION = v1.4.0-rc1-11-g130a514
tf.COMPILER_VERSION = v1.4.0-rc1-11-g130a514
Sanity check: array([1], dtype=int32)

== env ==========================================================
LD_LIBRARY_PATH is unset
DYLD_LIBRARY_PATH is unset

== nvidia-smi ===================================================
./tf_env_collect.sh: line 106: nvidia-smi: command not found

== cuda libs  ===================================================
/usr/local/MATLAB/R2017a/bin/glnxa64/libcudart.so.8.0.44
```

- tensorflow version: ('v1.4.0-rc1-11-g130a514', '1.4.0')
- command to reproduce: from the models/research directory run:
`python object_detection/create_pet_tf_record.py --label_map_path=object_detection/data/pet_label_map.pbtxt --data_dir=`pwd`  --output_dir=`pwd``
- not using any gpu
- tensorflow was installed through pip
- I am using linux ubuntu 16.04

### Describe the problem
Hello all,

I was trying to follow the quick start tutorial (https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/running_pets.md) when I faced what I think is a documentation bug.

The tutorial asks to run the command from the models/research directory:
python object_detection/create_pet_tf_record.py \
    --label_map_path=object_detection/data/pet_label_map.pbtxt \
    --data_dir=`pwd` \
    --output_dir=`pwd`

However, the script create_pet_tf_record.py is not in object_detection folder anymore, but in object_detection/dataset_tools. Furthermore, if I do not set the attribute ""--faces_only=False"", it will not generate the files pet_train.record and pet_val.record as suggested by the tutorial. Instead, it will create two empty files: pet_val_with_masks.record and pet_train_with_masks.record.

I inspected the code in create_pet_tf_record.py and there is no way the variable ""masks"" will arrive to the line 163 where ""mast_stack"" is set, without being empty if ""faces_only"" is not set to False. This leads to a deterministic fail to generate the record for all oxford images.

Thanks for the support. It is my first time using this tool, so I am not sure I configured something wrong.

Regards,
Francisco",frankist,b'stat:awaiting model gardener',2017-11-22T11:32:57Z,2020-01-30T10:51:35Z,,,,,,,
2872,pickle.load(),"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",ELI95,None,2017-11-22T05:59:05Z,2017-11-22T06:57:48Z,,,,,,,
2857,Error thrown when trying to run classify_image.py ,"I am beginning to think this is a bug. 

I have posted a question on SO but I don't think the answer is general. 

------------------------

### System information
- **What is the top-level directory of the model you are using**:

models/tutorials/image/imagenet ( https://github.com/tensorflow/models)

- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:

Not for this issue to be present

- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:

== uname -a =====================================================
Linux workstation01 4.10.0-38-generic #42~16.04.1-Ubuntu SMP Tue Oct 10 16:32:20 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux

- **TensorFlow installed from (source or binary)**:
Binary

== check pips ===================================================
numpy (1.13.3)
protobuf (3.4.0)
tensorflow-gpu (1.4.0)
tensorflow-tensorboard (0.4.0rc3)

== check for virtualenv =========================================
False
- **TensorFlow version (use command below)**:


== tensorflow import ============================================
tf.VERSION = 1.4.0
tf.GIT_VERSION = v1.4.0-rc1-11-g130a514
tf.COMPILER_VERSION = v1.4.0-rc1-11-g130a514
Sanity check: array([1], dtype=int32)

== env ==========================================================
LD_LIBRARY_PATH /usr/local/cuda-8.0/lib64:/usr/local/cuda/lib64:
DYLD_LIBRARY_PATH is unset

- **Bazel version (if compiling from source)**:

NA

- **CUDA/cuDNN version**:

== cuda libs  ===================================================
/usr/local/cuda-8.0/doc/man/man7/libcudart.7
/usr/local/cuda-8.0/doc/man/man7/libcudart.so.7
/usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudart_static.a
/usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudart.so.8.0.61

== env ==========================================================
LD_LIBRARY_PATH /usr/local/cuda-8.0/lib64:/usr/local/cuda/lib64:
DYLD_LIBRARY_PATH is unset

== cudnn ==========================================================
$ cat /usr/local/cuda/include/cudnn.h | grep CUDNN_MAJOR -A 2  AND $ cat /usr/local/cuda-8.0/include/cudnn.h | grep CUDNN_MAJOR -A 2
CUDNN_MAJOR 5 (It doesnt matter if this is 5.1 or 6 - I get the same error)

- **GPU model and memory**:

== nvidia-smi ===================================================
Tue Nov 21 09:49:03 2017       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 384.98                 Driver Version: 384.98                    |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  GeForce GTX 1070    Off  | 00000000:01:00.0  On |                  N/A |
|  0%   41C    P0    39W / 180W |    213MiB /  8110MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID   Type   Process name                             Usage      |
|=============================================================================|
|    0       993      G   /usr/lib/xorg/Xorg                           169MiB |
|    0      1657      G   compiz                                        41MiB |
+-----------------------------------------------------------------------------+


- **Exact command to reproduce**:

$ python classify_image.py 

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem

My system was working a month ago. I updated a couple things and now I am fighting to get it working again. I think this is a bug. All I am trying to do is run the examples so that I can get back to my program which is a convolutional neural net using keras. 
To reproduce this error I just have to run the standard model. 

### Source code / logs

~/TensorFlowExamples/models/tutorials/image/imag
enet$ python classify_image.py                                      
2017-11-21 09:43:09.913398: I tensorflow/core/platform/cpu_feature_gu
ard.cc:137] Your CPU supports instructions that this TensorFlow binar
y was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2017-11-21 09:43:10.016280: I tensorflow/stream_executor/cuda/cuda_gp
u_executor.cc:892] successful NUMA node read from SysFS had negative 
value (-1), but there must be at least one NUMA node, so returning NU
MA node zero
2017-11-21 09:43:10.016657: I tensorflow/core/common_runtime/gpu/gpu_
device.cc:1030] Found device 0 with properties: 
name: GeForce GTX 1070 major: 6 minor: 1 memoryClockRate(GHz): 1.7465
pciBusID: 0000:01:00.0
totalMemory: 7.92GiB freeMemory: 7.62GiB
2017-11-21 09:43:10.016670: I tensorflow/core/common_runtime/gpu/gpu$device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (devic$: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capab$lity: 6.1)
2017-11-21 09:43:10.316462: W tensorflow/core/framework/op_def_util.$c:334] Op BatchNormWithGlobalNormalization is deprecated. It will ce$se to work in GraphDef version 9. Use tf.nn.batch_normalization().
2017-11-21 09:43:10.552632: E tensorflow/stream_executor/cuda/cuda_b$as.cc:366] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIAL$ZED
2017-11-21 09:43:11.119849: E tensorflow/stream_executor/cuda/cuda_d$n.cc:385] could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR
2017-11-21 09:43:11.119875: E tensorflow/stream_executor/cuda/cuda_d$n.cc:352] could not destroy cudnn handle: CUDNN_STATUS_BAD_PARAM
2017-11-21 09:43:11.119915: F tensorflow/core/kernels/conv_ops.cc:66$] Check failed: stream->parent()->GetConvolveAlgorithms( conv_parame$ers.ShouldIncludeWinogradNonfusedAlgo<T>(), &algorithms) 
Aborted (core dumped)

== example showing tf imports correctly ===============================================
$ python
Python 2.7.12 (default, Nov 19 2016, 06:48:10) 
[GCC 5.4.0 20160609] on linux2
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
```
>>> import tensorflow as tf
>>> hello = tf.constant('Hello, TensorFlow!')                                 
>>> sess = tf.Session()
```
2017-11-21 10:07:35.756327: I tensorflow/core/platform/cpu_feature_guard.cc:13
7] Your CPU supports instructions that this TensorFlow binary was not compiled
 to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2017-11-21 10:07:35.886090: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:892] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2017-11-21 10:07:35.886473: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties: 
name: GeForce GTX 1070 major: 6 minor: 1 memoryClockRate(GHz): 1.7465
pciBusID: 0000:01:00.0
totalMemory: 7.92GiB freeMemory: 7.62GiB
2017-11-21 10:07:35.886487: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1)

`>>> print(sess.run(hello))`
Hello, TensorFlow!


UPD: This has not worked: https://github.com/fchollet/keras/issues/1538 




",ashleylid,None,2017-11-21T15:49:14Z,2017-11-23T04:15:24Z,,,,,,,
2844,when training will complete,"Hello,

When I tried to tune a inception model to identify the flowers, I found that the program never end. 

I read and follow the step posted in the link: https://github.com/tensorflow/models/tree/master/research/inception

The command I used to run the training is:
/usr/bin/python /share_folder/220Proj/flower_demo/bazel-bin/inception/flowers_train.runfiles/inception/inception/flowers_train.py \
--train_dir=/share_folder/220Proj/flower_demo/flowers_train \
--data_dir=/share_folder/220Proj/flower_demo/flowers_data \
--pretrained_model_checkpoint_path=/usr/local/lib/python3.5/dist-packages/inception-v3/model.ckpt-157585 \
--fine_tune=True \
--initial_learning=0.001 \
--input_queue_memory_factor=1

Here is part of the log:
2017-11-21 01:23:16.037863: step 250070, loss = 0.98 (77.4 examples/sec; 0.413 sec/batch)
2017-11-21 01:23:20.213151: step 250080, loss = 0.91 (76.4 examples/sec; 0.419 sec/batch)
2017-11-21 01:23:24.387518: step 250090, loss = 0.95 (77.1 examples/sec; 0.415 sec/batch)
2017-11-21 01:23:28.536253: step 250100, loss = 1.12 (76.9 examples/sec; 0.416 sec/batch)
2017-11-21 01:23:34.435414: step 250110, loss = 0.92 (76.5 examples/sec; 0.418 sec/batch)
2017-11-21 01:23:38.599515: step 250120, loss = 1.07 (77.5 examples/sec; 0.413 sec/batch)
2017-11-21 01:23:42.764535: step 250130, loss = 0.95 (77.0 examples/sec; 0.415 sec/batch)
2017-11-21 01:23:46.922841: step 250140, loss = 0.92 (78.0 examples/sec; 0.410 sec/batch)
2017-11-21 01:23:51.092711: step 250150, loss = 0.96 (77.4 examples/sec; 0.414 sec/batch)

You can see the loss is around 0.98 to 1.07, and never decrease. 

So could you tell if there is max steps in inception or not?

What should I do next? End the program manually?

Thanks,

Shuai Hua
",huahandsome,b'type:bug',2017-11-21T01:27:50Z,2017-11-29T23:05:43Z,,,,,,,
2833,ImportError: cannot import name preprocessor_pb2 when trying to run job on google cloud,"i'm trying run my own custom object detection training job by following 'pet training quickstart' and guideline on 'running on cloud' but has the following error

> The replica master 0 exited with a non-zero status of 1. Termination reason: Error. Traceback (most recent call last): File ""/usr/lib/python2.7/runpy.py"", line 162, in _run_module_as_main ""__main__"", fname, loader, pkg_name) File ""/usr/lib/python2.7/runpy.py"", line 72, in _run_code exec code in run_globals File ""/root/.local/lib/python2.7/site-packages/object_detection/train.py"", line 49, in <module> from object_detection import trainer File ""/root/.local/lib/python2.7/site-packages/object_detection/trainer.py"", line 27, in <module> from object_detection.builders import preprocessor_builder File ""/root/.local/lib/python2.7/site-packages/object_detection/builders/preprocessor_builder.py"", line 21, in <module> from object_detection.protos import preprocessor_pb2 **ImportError: cannot import name preprocessor_pb2** 

and a few more error for each worker with the same pattern

> The replica worker 0 .... **ImportError: cannot import name preprocessor_pb2** 
> The replica worker 1 .... **ImportError: cannot import name preprocessor_pb2** 
> The replica ps 0  .... **ImportError: cannot import name preprocessor_pb2** 
> The replica ps 1 .... **ImportError: cannot import name preprocessor_pb2** 

this is the input show in Google console

> {
>   ""scaleTier"": ""CUSTOM"",
>   ""masterType"": ""standard_gpu"",
>   ""workerType"": ""standard_gpu"",
>   ""parameterServerType"": ""standard"",
>   ""workerCount"": ""5"",
>   ""parameterServerCount"": ""3"",
>   ""packageUris"": [
>     ""gs://image-detection-kos/checkpoints/packages/885544b8b58fca05c7af7daec46b5a33a9f3cb4a598093eb59983e1c2485c597/object_detection-0.1.tar.gz"",
>     ""gs://image-detection-kos/checkpoints/packages/885544b8b58fca05c7af7daec46b5a33a9f3cb4a598093eb59983e1c2485c597/slim-0.1.tar.gz""
>   ],
>   ""pythonModule"": ""object_detection.train"",
>   ""args"": [
>     ""--train_dir=gs://image-detection-kos/checkpoints"",
>     ""--pipeline_config_path=gs://image-detection-kos/cloud.config""
>   ],
>   ""region"": ""us-east1"",
>   ""runtimeVersion"": ""1.0"",
>   ""jobDir"": ""gs://image-detection-kos/checkpoints""
> }

I'm not sure if this is a bug or if I do something wrong? Do i need to build proto files by myself? or did the script not building properly?",kosintop,None,2017-11-19T06:57:53Z,2019-05-19T19:05:07Z,,,,,,,
2832,lowproposals models are no faster than corresponding models with more proposals,"### System information
- **What is the top-level directory of the model you are using**:

research/object_detection

- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:

Yes, I've written a simple script that allows me to select the model, input video, frames, etc.

- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:

Ubuntu 17.04

- **TensorFlow installed from (source or binary)**:

pip install tensorflow or tensorflow-gpu (in a virtual environment)

- **TensorFlow version (use command below)**:

1.4

- **Bazel version (if compiling from source)**:

N/A

- **CUDA/cuDNN version**:

Whatever was installed with python 3.5 and pip install tensorflow-gpu.  I get the same behavior, however, independent of whether I'm running with tensorflow w/o CUDA or tensorflow-gpu w/ CUDA support.

- **GPU model and memory**:

The results are independent of whether I run on a GPU.

- **Exact command to reproduce**:

Run the object detection models using any strategy you want, then change just the model name.
My script is essentially the same steps as that in:

  research/object_detection/object_detection_tutorial.ipynb

### Describe the problem

I pretty sure there's a bug in the *lowproposals* models.  I have a script
that iterates over all models on the object model detection model zoo and
the results for the lowproposal models are essentailly the same for both
runtime and number of regions detected.  Based on the table describing the
models they should be several times faster.

The table below summarizes the results obtained for 10 frames of 4k video. In it:
- model = an abbreviation obtained by taking the first letter of each word
  in the model name and using 50 or 101 in the corresonding models to
  resolve abbreviations that would conflict with my naming convention.  I'm
  also pretty sure that my table is in the same order as the models are
  presented in the mode zoo page.
- dt = the per frame execution time in seconds (single GPU run)
- regions = the average number of objects detected per frame


| model    |    dt | regions |
|----------+-------+---------|
| sm1c     | 0.264 |    5.50 |
| si2c     | 0.342 |    6.20 |
| fri2c    | 0.616 |   10.30 |
| frr50c   | 0.713 |   14.20 |
| frr50lc  | 0.732 |   14.20 |
| rr101c   | 0.719 |    8.50 |
| frr101c  | 0.834 |   13.40 |
| frr101lc | 0.809 |   13.40 |
| frir2ac  | 2.229 |   12.70 |
| frir2alc | 2.220 |   12.70 |
| frnc     | 1.899 |   15.50 |
| frnlc    | 1.907 |   15.50 |

Note that *lc results are effectively identical to the coresponding *c
results.  I get the same results using GPU and non-GPU execution (only the
runtime changes).

For SSD I'm using the Nov 17th models and for the others I'm using the Nov
8th models.  The only difference in my code is the selection of a different
model file.  I'm running top-of-tree master as of Nov 18th 20:32 PST.

### Source code / logs

The table below summarizes the results obtained for 10 frames of 4k video. In it:
- model = an abbreviation obtained by taking the first letter of each word
  in the model name and using 50 or 101 in the corresonding models to
  resolve abbreviations that would conflict with my naming convention.  I'm
  also pretty sure that my table is in the same order as the models are
  presented in the mode zoo page.
- dt = the per frame execution time in seconds (single GPU run)
- regions = the average number of objects detected per frame


| model    |    dt | regions |
|----------+-------+---------|
| sm1c     | 0.264 |    5.50 |
| si2c     | 0.342 |    6.20 |
| fri2c    | 0.616 |   10.30 |
| frr50c   | 0.713 |   14.20 |
| frr50lc  | 0.732 |   14.20 |
| rr101c   | 0.719 |    8.50 |
| frr101c  | 0.834 |   13.40 |
| frr101lc | 0.809 |   13.40 |
| frir2ac  | 2.229 |   12.70 |
| frir2alc | 2.220 |   12.70 |
| frnc     | 1.899 |   15.50 |
| frnlc    | 1.907 |   15.50 |

Note that *lc results are effectively identical to the coresponding *c
results.  I get the same results using GPU and non-GPU execution (only the
runtime changes).

For SSD I'm using the Nov 17th models and for the others I'm using the Nov
8th models.  The only difference in my code is the selection of a different
model file.  I'm running top-of-tree master as of Nov 18th 20:32 PST.
",headdab,None,2017-11-19T04:44:35Z,2020-02-07T18:43:27Z,,,,,,,
2830,"Error from ""python object_detection/builders/model_builder_test.py"" command.","I have following error while doing the installation final step. 
I'm using tensorflow (1.4), cuda (8.0), cudnn (6.0), matplotlib (2.1.0) under anaconda virtual environment.

----------------------------------------------------------------------------------------------------------------------------
(tensorflow) chkim@chkim-PMTSB09D-Samsung-DeskTop:~/다운로드/models-master/research$ python object_detection/builders/model_builder_test.py

Traceback (most recent call last):
  File ""object_detection/builders/model_builder_test.py"", line 21, in <module>
    from object_detection.builders import model_builder
  File ""/home/chkim/다운로드/models-master/research/object_detection/builders/model_builder.py"", line 29, in <module>
    from object_detection.meta_architectures import ssd_meta_arch
  File ""/home/chkim/다운로드/models-master/research/object_detection/meta_architectures/ssd_meta_arch.py"", line 31, in <module>
    from object_detection.utils import visualization_utils
  File ""/home/chkim/다운로드/models-master/research/object_detection/utils/visualization_utils.py"", line 24, in <module>
    import matplotlib.pyplot as plt
  File ""/home/chkim/anaconda2/envs/tensorflow/lib/python2.7/site-packages/matplotlib/pyplot.py"", line 69, in <module>
    from matplotlib.backends import pylab_setup
  File ""/home/chkim/anaconda2/envs/tensorflow/lib/python2.7/site-packages/matplotlib/backends/__init__.py"", line 14, in <module>
    line for line in traceback.format_stack()
  File ""/home/chkim/anaconda2/envs/tensorflow/lib/python2.7/site-packages/matplotlib/backends/__init__.py"", line 16, in <genexpr>
    if not line.startswith('  File ""<frozen importlib._bootstrap'))
UnicodeDecodeError: 'ascii' codec can't decode byte 0xeb in position 20: ordinal not in range(128)
-------------------------------------------------------------------------------------------------------------------------


",flipflop98,b'stat:awaiting model gardener type:bug',2017-11-18T13:42:58Z,2020-02-07T18:43:26Z,,,,,,,
2818,Bug using 2 gpus,"### System information
- **What is the top-level directory of the model you are using**:
tensorflow/models/research/slim
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.4.0
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**: 8/6
- **GPU model and memory**: 1)GeForce GTX Titan, 2) GeForce GTX 1080
- **Exact command to reproduce**:
`python train_image_classifier.py \
  --train_dir=${TRAIN_DIR} \
  --dataset_name=DATASET_NAME \
  --dataset_split_name=train \
  --dataset_dir=${DATASET_DIR} \
  --clone_on_cpu=False \
  --num_clones=2 \
  --model_name=resnet_v2_101 \
  --max_number_of_steps=154526 \
  --batch_size=64 \
  --learning_rate=0.0001 \
  --learning_rate_decay_factor=0.1 \
  --end_learning_rate=0.00001 \
  --optimizer=momentum \
  --momentum=0.9 \
  --weight_decay=0.0001 \
  --train_image_size=180 \
  --save_interval_secs=60 \
  --save_summaries_secs=60 \
  --log_every_n_steps=100 \
  --checkpoint_path=${PRETRAINED_CHECKPOINT_DIR}/resnet_v2_101.ckpt \
  --checkpoint_exclude_scopes=resnet_v2_101/logits`



### Describe the problem
I am training resnet_v2_101 model on my custom data set. I composed the data set from the script for getting TFRecord shards, so the data are right and shuffled. The training process is really slow using 2 gpus and using the command **watch nvidia-smi** the gpus are not being utilized all the time. They can be at 80-100% both but suddenly they fall to 0% for a small amount of time. I think this is something that slows down the training. I spent a lot of time to check if the problem has to do with the reading process of the files but I cannot figure out the source.",chrisrn,b'type:support',2017-11-17T08:43:02Z,2020-05-08T21:05:56Z,,,,,,,
2816,script_test_pretrained_model.sh,"It seems that there is a bug when I run this command. It says that
scale cannot be an integer: False

ERROR:root:Checkpoint_dir: output/bl.v2.noclip.sbpd_d_r2r_h0_64_80
Traceback (most recent call last):
  File ""scripts/script_nav_agent_release.py"", line 253, in <module>
    app.run()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 48, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""scripts/script_nav_agent_release.py"", line 89, in main
    _launcher(FLAGS.config_name, FLAGS.logdir)
  File ""scripts/script_nav_agent_release.py"", line 100, in _launcher
    _test(args)
  File ""scripts/script_nav_agent_release.py"", line 195, in _test
    summary_mode=args.control.test_mode)
  File ""/~/programming/models/research/cognitive_mapping_and_planning/tfcode/vision_baseline_lstm.py"", line 260, in setup_to_run
    is_training)
  File ""/~/programming/models/research/cognitive_mapping_and_planning/tfcode/nav_utils.py"", line 101, in get_repr_from_image
    with slim.arg_scope(resnet_v2.resnet_utils.resnet_arg_scope(resnet_is_training)):
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/slim/python/slim/nets/resnet_utils.py"", line 257, in resnet_arg_scope
    weights_regularizer=regularizers.l2_regularizer(weight_decay),
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/layers/python/layers/regularizers.py"", line 92, in l2_regularizer
    raise ValueError('scale cannot be an integer: %s' % (scale,))

This is my error log",siavash-khodadadeh,None,2017-11-16T21:37:22Z,2019-12-09T02:30:17Z,,,,,,,
2807,Update eval_image_classifier.py default batch_size from 100 to 50 to avoid bug.,"Right now the large NASNet-A model, when evaluated with the default batch_size of 100, runs into a bug. This change will allow the NASNet-A model to work with the default values. See #2778 for details.",BarretZoph,b'cla: yes',2017-11-15T19:34:06Z,2017-11-20T19:07:33Z,,,,,,,
2796,GPU Out of memory and Where is the Net Structure,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:ssd_mobilenet_v1_coco_11_06_2017.tar
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:win7 and win10
- **TensorFlow installed from (source or binary)**:source python
- **TensorFlow version (use command below)**:1.3
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:1.8 5.5
- **GPU model and memory**:980m 4G
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
I have 2 questions:
1、I want to use my win10 gpu to retrain a new model. when it run about 2 minutes, it is failed and show error ""Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.9KiB"".
      It is run ok in my win7 cpu computer, but it is slow, about 10-20 sec per step.
      I want to know how can i make it not momery overflow. some code?
2、I want to see the detection net code, like your minist sample:
      ""conv --> pool --> conv --> pool ... --> full connect ... ...""
      I can see it clearly!
      But in this sample, you use pre-trained model to load net and params. I use break-point trace code  line by line, still can not find the net definition code. Can you tell me where it is?
Thank you!
### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",Dragonkingpan,None,2017-11-15T03:27:50Z,2017-11-18T07:29:26Z,,,,,,,
2784,Build issue for adversarial_text,"### System information
- **What is the top-level directory of the model you are using**:
/models/research/adversarial_text

- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
I do not have custom code and am trying to run the sequence of commands from adversarial_text's readme.

- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Linux Ubuntu 14.04

- **TensorFlow installed from (source or binary)**:
Installed using virtualenv for CPU as described here: https://www.tensorflow.org/install/install_linux .  I have the tensorflow/models source also and have run bazel build on adversarial_text and adversarial_text/data

- **TensorFlow version (use command below)**:
('v1.3.0-rc2-20-g0787eee', '1.3.0')

- **Bazel version (if compiling from source)**:
Build label: 0.7.0

- **CUDA/cuDNN version**:
Not installed

- **GPU model and memory**:
Installed TensorFlow for CPU only, not with GPU support

- **Exact command to reproduce**:
bazel run data:gen_vocab -- \
    --output_dir=$IMDB_DATA_DIR \
    --dataset=imdb \
    --imdb_input_dir=/tmp/aclImdb \
    --lowercase=False

Command is from the README here: https://github.com/tensorflow/models/tree/master/research/adversarial_text

I also ran the earlier commands in sequence listed in the README prior to running that command.


### Describe the problem
Bug:
I am trying to run the code of models/adversarial-text using the steps described in the README here https://github.com/tensorflow/models/tree/master/research/adversarial_text.  I have not made changes to any of the code or the dataset.  When I tried to run the first bazel command, I got this error:

ERROR: no such package 'data': BUILD file not found on package path.
____Elapsed time: 1.370s
ERROR: Build failed. Not running target.

I have searched Stack Overflow and tried suggested solutions to similar issues, but none have worked.  I found this question that was very similar to the one I am asking: https://stackoverflow.com/questions/45090345/bazel-build-package-not-found .  I contacted the person who had asked the Stack Overflow question, and he had not found a way to resolve the issue.  He told me that also he has had a few other people contact him about the same issue.

### Source code / logs
Running this command:
bazel run data:gen_vocab -- \
    --output_dir=$IMDB_DATA_DIR \
    --dataset=imdb \
    --imdb_input_dir=/tmp/aclImdb \
    --lowercase=False

Produced this error:
ERROR: no such package 'data': BUILD file not found on package path.
____Elapsed time: 1.370s
ERROR: Build failed. Not running target.
",abuhman,b'type:support',2017-11-13T22:50:44Z,2018-02-22T19:26:52Z,,,,,,,
2778,Odd batch_size specific behaviour with nasnet_large on ImageNet validation,"I've been trying to reproduce the ImageNet validation accuracies posted with the pretrained weights.

I cannot reproduce the results with an image size of 331 and the default batch size of 100 used in the eval_image_classifer script. With defaults I get roughly 64% top-1 and 74% top-5 using the command:

`python eval_image_classifier.py --dataset_dir ~/imagenet/ --dataset_split_name validation --model_name nasnet_large --checkpoint_path ~/nasnet_large/model.ckpt  --dataset_name imagenet --moving_average_decay=0.9999`

However, if I change the batch size down to 50, I hit the posted results dead on, 82.7% top-1 and 92.6% top-5. This seems rather odd to me. I've never experienced that significant of a performance drop by changing the batch size by a factor of two at eval. 

I noticed that with the batch size of 100, I could improve performance by dropping the eval image size down. There is an optimal value somewhere in the 280-290 range before it starts to fall off. My best result with batch size of 100 was at 288x288 with a 80.8% top-1 and 95.2% top-5, it falls off quickly as the image size increases from there. 

Is this possibly some sort of overflow in batch norm or another op in the network?

Note, I'm using latest released pip install of Tensorflow 1.4 for GPU. CUDA 8.0, cuDNN 6.",rwightman,b'type:bug',2017-11-13T04:04:52Z,2020-01-30T04:20:33Z,,,,,,,
2770,Apparent incorrect behavior from resize_to_range() in object_detection/core/preprocessor.py,"From the comments for resize_to_range():

  The output size can be described by two cases:
  1. If the image can be rescaled so its minimum dimension is equal to the
     provided value without the other dimension exceeding max_dimension,
     then do so.
  2. Otherwise, resize so the largest dimension is equal to max_dimension.

This logic would yield the wrong behavior for images with an aspect ratio near 1. For instance, if we had a 1200x1200 image, and we had settings min_dimension = 600 and max_dimension = 1024, it seems that the desired behavior would be to rescale the image to 1024x1024. Instead, following the logic above, the image would be rescaled to 600x600.

Am I missing something?

@jch1 @tombstone @derekjchow @jesu9 @dreamdragon
",MisterMorden,b'help wanted type:bug',2017-11-10T23:40:19Z,2020-02-07T18:43:24Z,,,,,,,
2769,"ptb fails on R1.4 built with cuda9, cudnn7","Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",David-Levinthal,None,2017-11-10T19:37:55Z,2017-11-11T01:58:24Z,,,,,,,
2763,Why is nasnet model so slow using one gpu?,"tensorflow 1.4 rc0,  on p40
I'm tring nasnet, it performs excellent but one thing is curious, I find using one gpu is much slower then using 2gpu(tower loss) I'm using p40, say if one gpu batch size is 16, for 2 gpu, each gpu with batch size 16 (so batch size total 16 * 2) But since we have communication cost I suppose using 2gpu will not speed up * 2, However experiment result is like below

1 gpu: train_step:92700 duration:37.092 elapsed:[405.920] batch_size:[16] batches/s:[0.25] insts/s:[3.94] 1epoch:[74.00h]

2 gpu: train_step:174600 duration:47.933 elapsed:[236.972] batch_size:[16] gpus:[2] batches/s:[0.42] insts/s:[13.50] 1epoch:[21.60h]

I have also try using inceptionV4, resnet152, inceptionResnetV2, they all behave as expected, 2gpu not speed up *2.

Sometimes I prefer to use one gpu, since when finetune image model, multiple gpu tower loss might hurt final accuracy though I still know why..

Not sure if this is a bug, I have also asked quesion on stackoverlow. 
https://stackoverflow.com/questions/47215223/why-is-nasnet-model-so-slow-using-one-gpu
Please help close if it is not proper to discuss here. ",chenghuige,b'help wanted',2017-11-10T03:35:17Z,2020-02-07T18:43:24Z,,,,,,,
2761,Problem with the new train and eval updates,"
### System information
- **What is the top-level directory of the model you are using**: object_detection
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: no
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Win7
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.4
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**: 8/6.1
- **GPU model and memory**: Titan X
- **Exact command to reproduce**:

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

I used to use object detection to fine tune the coco trained model on SSD_Mobilenet with only 3 classes on my data and it worked fine until this new updates of train.py, eval.py, and other dependent files.

the training log used to be like this:
##########################################
WARNING:tensorflow:From C:\TensorflowModels_v0\object_detection\trainer.py:178: create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Please switch to tf.train.create_global_step
WARNING:tensorflow:From C:\TensorFlowModels_v0\object_detection\builders\optimizer_builder.py:92: get_or_create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Please switch to tf.train.get_or_create_global_step
INFO:tensorflow:Summary name Learning Rate is illegal; using Learning_Rate instead.
WARNING:tensorflow:From C:\TensorFlowModels_v0\object_detection\meta_architectures\ssd_meta_arch.py:607: all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.
Instructions for updating:
Please use tf.global_variables instead.
INFO:tensorflow:Summary name /clone_loss is illegal; using clone_loss instead.
INFO:tensorflow:Restoring parameters from D:/object_detection/models/ssd_mobilenet_v1_coco_11_06_2017/model.ckpt
INFO:tensorflow:Starting Session.
INFO:tensorflow:Saving checkpoint to path D:/object_detection/models0/model.ckpt
INFO:tensorflow:Starting Queues.
INFO:tensorflow:global_step/sec: 0
INFO:tensorflow:Recording summary at step 0.
INFO:tensorflow:global step 1: loss = 22.9493 (30.222 sec/step)
INFO:tensorflow:global step 2: loss = 20.2359 (3.919 sec/step)
INFO:tensorflow:global step 3: loss = 18.7402 (3.793 sec/step)
INFO:tensorflow:global step 4: loss = 17.9404 (3.978 sec/step)
INFO:tensorflow:global step 5: loss = 17.1826 (3.588 sec/step)
INFO:tensorflow:global step 6: loss = 15.8118 (3.605 sec/step)
INFO:tensorflow:global step 7: loss = 15.1282 (3.416 sec/step)
INFO:tensorflow:global step 8: loss = 14.2844 (3.338 sec/step)
INFO:tensorflow:global step 9: loss = 13.7035 (3.416 sec/step)
INFO:tensorflow:global step 10: loss = 14.0352 (3.245 sec/step)
INFO:tensorflow:global step 11: loss = 13.6083 (3.279 sec/step)
INFO:tensorflow:global step 12: loss = 11.4007 (3.323 sec/step)
INFO:tensorflow:global step 13: loss = 11.8029 (3.354 sec/step)
INFO:tensorflow:global step 14: loss = 10.7637 (3.338 sec/step)
INFO:tensorflow:global step 15: loss = 10.5538 (3.370 sec/step)
INFO:tensorflow:global step 16: loss = 9.9638 (3.323 sec/step)
INFO:tensorflow:global step 17: loss = 10.5116 (3.276 sec/step)
INFO:tensorflow:global step 18: loss = 11.0982 (3.338 sec/step)
INFO:tensorflow:global step 19: loss = 9.9132 (3.307 sec/step)
INFO:tensorflow:global step 20: loss = 9.5878 (3.387 sec/step)

#############################
however when I use the version with recent updates I get this report:

################################
WARNING:tensorflow:From research\object_detection\trainer.py:210: create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Please switch to tf.train.create_global_step
INFO:tensorflow:depth of additional conv before box predictor: 0
INFO:tensorflow:depth of additional conv before box predictor: 0
INFO:tensorflow:depth of additional conv before box predictor: 0
INFO:tensorflow:depth of additional conv before box predictor: 0
INFO:tensorflow:depth of additional conv before box predictor: 0
INFO:tensorflow:depth of additional conv before box predictor: 0
INFO:tensorflow:Summary name /clone_loss is illegal; using clone_loss instead.
INFO:tensorflow:Restoring parameters from D:/object_detection/models/ssd_mobilenet_v1_coco_11_06_2017/model.ckpt
INFO:tensorflow:Starting Session.
INFO:tensorflow:Saving checkpoint to path G:/object_detection/models1/model.ckpt
INFO:tensorflow:Starting Queues.
INFO:tensorflow:global_step/sec: 0
INFO:tensorflow:Recording summary at step 0.
INFO:tensorflow:global step 1: loss = 88.5192 (29.360 sec/step)
INFO:tensorflow:global step 2: loss = 85.8423 (3.781 sec/step)
INFO:tensorflow:global step 3: loss = 74.9890 (3.584 sec/step)
INFO:tensorflow:global step 4: loss = 65.3577 (3.572 sec/step)
INFO:tensorflow:global step 5: loss = 46.6875 (3.479 sec/step)
INFO:tensorflow:global step 6: loss = 37.5350 (3.323 sec/step)
INFO:tensorflow:global step 7: loss = 39.2690 (3.402 sec/step)
INFO:tensorflow:global step 8: loss = 50.3077 (3.310 sec/step)
INFO:tensorflow:global step 9: loss = 28.0526 (3.324 sec/step)
INFO:tensorflow:global step 10: loss = 31.1548 (3.349 sec/step)
INFO:tensorflow:global step 11: loss = 32.1967 (3.335 sec/step)
INFO:tensorflow:global step 12: loss = 34.1146 (3.309 sec/step)
INFO:tensorflow:global step 13: loss = 22.3245 (3.358 sec/step)
INFO:tensorflow:global step 14: loss = 20.3864 (3.393 sec/step)
INFO:tensorflow:global step 15: loss = 21.3323 (3.311 sec/step)
INFO:tensorflow:global step 16: loss = 20.5359 (3.361 sec/step)
INFO:tensorflow:global step 17: loss = 19.8039 (3.393 sec/step)
INFO:tensorflow:global step 18: loss = 20.1648 (3.413 sec/step)
INFO:tensorflow:global step 19: loss = 18.7674 (3.424 sec/step)
INFO:tensorflow:global step 20: loss = 13.9156 (3.356 sec/step)
#############################################
this does not lead to good results. The initial loss seems to be 4 times the loss I used to get. So I had to go back using previous version of object detection.

",starwars110,b'models:research stat:awaiting model gardener type:support',2017-11-09T23:14:35Z,2020-07-11T11:35:31Z,,,,,,,
2753,Object Detection: error when using random_crop_pad_image data augmentation,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**: object_detection
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: no
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: 'v1.4.0-1-g7f646a6' 1.4.0
- **Bazel version (if compiling from source)**: 0.7.0
- **CUDA/cuDNN version**: 8.0/6.0
- **GPU model and memory**: 1080Ti 11 GB
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

When I add 
```
  data_augmentation_options {
    random_crop_pad_image {
    }
  }
```
in the train_config section of my pipeline config, and then run train.py, I get the following error:

```
Traceback (most recent call last):
  File ""../gpu-env/lib/python3.5/site-packages/object_detection/train.py"", line 163, in <module>
    tf.app.run()
  File ""/home/dan/gpu-env/lib/python3.5/site-packages/tensorflow/python/platform/app.py"", line 48, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""../gpu-env/lib/python3.5/site-packages/object_detection/train.py"", line 159, in main
    worker_job_name, is_chief, FLAGS.train_dir)
  File ""/home/dan/gpu-env/lib/python3.5/site-packages/object_detection/trainer.py"", line 217, in train
    train_config.prefetch_queue_capacity, data_augmentation_options)
  File ""/home/dan/gpu-env/lib/python3.5/site-packages/object_detection/trainer.py"", line 77, in create_input_queue
    include_keypoints=include_keypoints))
  File ""/home/dan/gpu-env/lib/python3.5/site-packages/object_detection/core/preprocessor.py"", line 2547, in preprocess
    results = func(*args, **params)
  File ""/home/dan/gpu-env/lib/python3.5/site-packages/object_detection/core/preprocessor.py"", line 1272, in random_crop_pad_image
    min_padded_size_ratio)
  File ""/home/dan/gpu-env/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py"", line 885, in binary_op_wrapper
    y = ops.convert_to_tensor(y, dtype=x.dtype.base_dtype, name=""y"")
  File ""/home/dan/gpu-env/lib/python3.5/site-packages/tensorflow/python/framework/ops.py"", line 836, in convert_to_tensor
    as_ref=False)
  File ""/home/dan/gpu-env/lib/python3.5/site-packages/tensorflow/python/framework/ops.py"", line 926, in internal_convert_to_tensor
    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
  File ""/home/dan/gpu-env/lib/python3.5/site-packages/tensorflow/python/framework/constant_op.py"", line 229, in _constant_tensor_conversion_function
    return constant(v, dtype=dtype, name=name)
  File ""/home/dan/gpu-env/lib/python3.5/site-packages/tensorflow/python/framework/constant_op.py"", line 208, in constant
    value, dtype=dtype, shape=shape, verify_shape=verify_shape))
  File ""/home/dan/gpu-env/lib/python3.5/site-packages/tensorflow/python/framework/tensor_util.py"", line 371, in make_tensor_proto
    raise ValueError(""None values not supported."")
ValueError: None values not supported.
```

This appears to be a bug relating to RandomCropPadImage.{min_padded_size_ratio,max_padded_size_ratio} not being specified. In addition, if I do specify them, e.g.:

```
  data_augmentation_options {
    random_crop_pad_image {
      min_padded_size_ratio: [0.5, 0.5]
      max_padded_size_ratio: [2.0, 2.0]
    }
  }
```

I get the following error:

```
Traceback (most recent call last):
  File ""../gpu-env/lib/python3.5/site-packages/object_detection/train.py"", line 163, in <module>
    tf.app.run()
  File ""/home/dan/gpu-env/lib/python3.5/site-packages/tensorflow/python/platform/app.py"", line 48, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""../gpu-env/lib/python3.5/site-packages/object_detection/train.py"", line 159, in main
    worker_job_name, is_chief, FLAGS.train_dir)
  File ""/home/dan/gpu-env/lib/python3.5/site-packages/object_detection/trainer.py"", line 217, in train
    train_config.prefetch_queue_capacity, data_augmentation_options)
  File ""/home/dan/gpu-env/lib/python3.5/site-packages/object_detection/trainer.py"", line 77, in create_input_queue
    include_keypoints=include_keypoints))
  File ""/home/dan/gpu-env/lib/python3.5/site-packages/object_detection/core/preprocessor.py"", line 2547, in preprocess
    results = func(*args, **params)
  File ""/home/dan/gpu-env/lib/python3.5/site-packages/object_detection/core/preprocessor.py"", line 1272, in random_crop_pad_image
    min_padded_size_ratio)
  File ""/home/dan/gpu-env/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py"", line 885, in binary_op_wrapper
    y = ops.convert_to_tensor(y, dtype=x.dtype.base_dtype, name=""y"")
  File ""/home/dan/gpu-env/lib/python3.5/site-packages/tensorflow/python/framework/ops.py"", line 836, in convert_to_tensor
    as_ref=False)
  File ""/home/dan/gpu-env/lib/python3.5/site-packages/tensorflow/python/framework/ops.py"", line 926, in internal_convert_to_tensor
    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
  File ""/home/dan/gpu-env/lib/python3.5/site-packages/tensorflow/python/framework/constant_op.py"", line 229, in _constant_tensor_conversion_function
    return constant(v, dtype=dtype, name=name)
  File ""/home/dan/gpu-env/lib/python3.5/site-packages/tensorflow/python/framework/constant_op.py"", line 208, in constant
    value, dtype=dtype, shape=shape, verify_shape=verify_shape))
  File ""/home/dan/gpu-env/lib/python3.5/site-packages/tensorflow/python/framework/tensor_util.py"", line 383, in make_tensor_proto
    _AssertCompatible(values, dtype)
  File ""/home/dan/gpu-env/lib/python3.5/site-packages/tensorflow/python/framework/tensor_util.py"", line 303, in _AssertCompatible
    (dtype.name, repr(mismatch), type(mismatch).__name__))
TypeError: Expected float32, got [0.5, 0.5] of type 'RepeatedScalarContainer' instead.
```

It appears that the code isn't properly converting from protobuf to a tensor.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",dnuffer,b'stat:awaiting model gardener type:bug',2017-11-09T17:10:52Z,2017-11-16T23:31:52Z,,,,,,,
2730,Nan in summary histogram for: SecondStageFeatureExtractor/resnet_v1_50/block4/unit_3/bottleneck_v1/conv3/BatchNorm/gamma_1,"I attemp to run   object_detection\samples\configs\faster_rcnn_resnet50_pets.config. After some global steps,my program meet a bug.

System information
•win7-64
•TensorFlow installed from binary
•TensorFlow 1.3
•Python version:3.5
•CUDA/cuDNN version: cuda8.0/cuDNN6.0
•GPU model and memory: gtx1060/6G


INFO:tensorflow:global step 186: loss = 4.5385 (1.394 sec/step)
INFO:tensorflow:global_step/sec: 1.55281
2017-11-08 08:05:39.363437: W C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\core\framework\op_kernel.cc:1192] Invalid argument: Nan in summary histogram for: SecondStageFeatureExtractor/resnet_v1_50/block4/unit_3/bottleneck_v1/conv3/BatchNorm/gamma_1

Caused by op 'SecondStageFeatureExtractor/resnet_v1_50/block4/unit_3/bottleneck_v1/conv3/BatchNorm/gamma_1', defined at:
  File ""D:/TF_Model/research/object_detection/train.py"", line 164, in <module>
    tf.app.run()",luyuesheng,b'stat:awaiting response',2017-11-08T00:25:44Z,2017-11-08T01:50:45Z,,,,,,,
2728,Testing issue projects,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",fakeneal,None,2017-11-07T19:59:10Z,2017-11-07T20:01:04Z,,,,,,,
2721,Invalid argument: Nan in summary histogram for: FirstStageFeatureExtractor/resnet_v1_50/conv1/weights_1,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",luyuesheng,None,2017-11-07T09:32:58Z,2017-11-07T19:15:05Z,,,,,,,
2713,"Object_Detection ValueError: operands could not be broadcast together with shapes (0,) (16,)","Dear all,
I am trying to train the API object detection model on my dataset with just one class. The training ended and i tried to run the evaluation (eval.py) but it gives me an error that I am not able to fully understand:

python eval.py
INFO:tensorflow:Scale of 0 disables regularizer.
INFO:tensorflow:Scale of 0 disables regularizer.
INFO:tensorflow:Scale of 0 disables regularizer.
INFO:tensorflow:depth of additional conv before box predictor: 0
INFO:tensorflow:Scale of 0 disables regularizer.
2017-11-06 11:24:50.514416: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2017-11-06 11:24:50.710928: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties:
name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.683
pciBusID: 0000:05:00.0
totalMemory: 10.91GiB freeMemory: 10.56GiB
2017-11-06 11:24:50.710953: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:05:00.0, compute capability: 6.1)
INFO:tensorflow:Restoring parameters from ./models/model/train/model.ckpt-200000
INFO:tensorflow:Restoring parameters from ./models/model/train/model.ckpt-200000
2017-11-06 11:24:57.255021: W tensorflow/core/framework/op_kernel.cc:1192] Out of range: FIFOQueue '_2_parallel_read/common_queue' is closed and has insufficient elements (requested 1, current size 0)
         [[Node: parallel_read/common_queue_Dequeue = QueueDequeueV2[component_types=[DT_STRING, DT_STRING], timeout_ms=-1, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](parallel_read/common_queue)]]
WARNING:root:The following classes have no ground truth examples: 1
/home/ucesfpa/ObjectDetection/TF_Models/models/research/object_detection/utils/metrics.py:144: RuntimeWarning: invalid value encountered in true_divide
  num_images_correctly_detected_per_class / num_gt_imgs_per_class)
/home/ucesfpa/ObjectDetection/TF_Models/models/research/object_detection/utils/object_detection_evaluation.py:585: RuntimeWarning: Mean of empty slice
  mean_ap = np.nanmean(self.average_precision_per_class)
/home/ucesfpa/ObjectDetection/TF_Models/models/research/object_detection/utils/object_detection_evaluation.py:586: RuntimeWarning: Mean of empty slice
  mean_corloc = np.nanmean(self.corloc_per_class)
Traceback (most recent call last):
  File ""eval.py"", line 130, in <module>
    tf.app.run()
  File ""/home/ucesfpa/ObjectDetection/lib/python3.5/site-packages/tensorflow/python/platform/app.py"", line 48, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""eval.py"", line 126, in main
    FLAGS.checkpoint_dir, FLAGS.eval_dir)
  File ""/home/ucesfpa/ObjectDetection/TF_Models/models/research/object_detection/evaluator.py"", line 210, in evaluate
    save_graph_dir=(eval_dir if eval_config.save_graph else ''))
  File ""/home/ucesfpa/ObjectDetection/TF_Models/models/research/object_detection/eval_util.py"", line 381, in repeated_checkpoint_run
    save_graph_dir)
  File ""/home/ucesfpa/ObjectDetection/TF_Models/models/research/object_detection/eval_util.py"", line 269, in _run_checkpoint_once
    image_id=batch, groundtruth_dict=result_dict)
  File ""/home/ucesfpa/ObjectDetection/TF_Models/models/research/object_detection/utils/object_detection_evaluation.py"", line 174, in add_single_ground_truth_image_info
    standard_fields.InputDataFields.groundtruth_difficult, None))
  File ""/home/ucesfpa/ObjectDetection/TF_Models/models/research/object_detection/utils/object_detection_evaluation.py"", line 447, in add_single_ground_truth_image_info
    groundtruth_is_group_of_list.astype(dtype=bool))
  File ""/home/ucesfpa/ObjectDetection/TF_Models/models/research/object_detection/utils/object_detection_evaluation.py"", line 527, in _update_ground_truth_statistics
    & ~groundtruth_is_group_of_list] == class_index)
ValueError: operands could not be broadcast together with shapes (0,) (16,)

Can anyone of you explain the problem?

Thank you,
Fabio",ucesfpa,b'stat:awaiting model gardener type:bug',2017-11-06T12:45:04Z,2018-07-04T11:58:52Z,,,,,,,
2702,Flaky official/wide_deep/wide_deep_test.py,"### System information
- **What is the top-level directory of the model you are using**:
NA
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
NA
- **TensorFlow installed from (source or binary)**:
NA
- **TensorFlow version (use command below)**:
NA
- **Bazel version (if compiling from source)**:
NA
- **CUDA/cuDNN version**:
NA
- **GPU model and memory**:
NA
- **Exact command to reproduce**:
submit any pull request to tensorflow/models and trigger a jenkins test.

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.
https://github.com/tensorflow/models/blob/master/official/wide_deep/wide_deep_test.py  is flaky. I have to rerun jenkins tests 3 times before being able to pass all tests for a unrelated PR.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.

https://ci.tensorflow.org/job/models-pull-requests/97/
",tombstone,None,2017-11-03T18:19:51Z,2017-11-07T19:34:42Z,,,,,,,
2662, C++ compilation of rule '@org_tensorflow//tensorflow/core/kernels:svd_op' failed (Exit 4),"**Issue**

As a follow up to issue #2588 I set up a new clean dockerfile with Bazel 0.5.4 and attempted to build syntaxnet triggering the build unleashes a deluge of warnings and the compiler ultimately issued a failure to complete build error.

**System information**

Followed very exactly [Syntaxnet installation](https://github.com/tensorflow/models/tree/master/research/syntaxnet) to build syntaxnet into a docker container except for Bazel which is 0.5.4 with a binary install using dpkg -i of the relevant debian archive, bazelrc file forcing --batch, build instruction for Bazel with --ignore_unsupported_sandboxing and --genrule_strategy=standalone --spawn_strategy=standalone.

- Windows 10 professional
- TensorFlow 1.3.0 installed as clean (functional) docker image from Ubuntu 16.04.3 LTS
- Docker 17.09.0-ce
- Python version 2.7
- Bazel version 0.7.0
- CUDA/cuDNN version not relevant (CPU install)
- GPU model and memory not relevant (CPU install)

**Command triggering issue**

`cd /models/research/syntaxnet && build ... --ignore_unsupported_sandboxing`

**Top-level directory of the model you are using**

> /models/research/syntaxnet

**Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**

Followed very exactly  [Syntaxnet installation](https://github.com/tensorflow/models/tree/master/research/syntaxnet) procedure.

Only variation I made was to clearly specify environment variables:

```
ENV PYTHON_BIN_PATH=/usr/bin/python
ENV PYTHON_LIB_PATH=/usr/lib/python2.7
```

In addition I also tried to attempt direct build instead of test and added sandboxing exception handling:

And downgraded to Bazel 0.5.4 instead.

**Describe the problem**

Whilst working to resolve issue #2588 I introspected the docker hub tensorflow/syntaxnet:latest docker image and figured out that it ran on Bazel 0.4.3.

I therefore tried to remake the image this time using Bazel 0.4.3 which made the ./config file issuing a warning that it required at least version 0.5.4. I therefore built yet another image using Bazel 0.5.4.

As for previous Bazel 0.7.0 attempts, triggering the build unleashes a deluge of warnings in addition to a very long wait numbering into hours to compile the following:

> [2,855 / 2,859] 2 actions running
> Compiling external/org_tensorflow/tensorflow/core/kernels/svd_op_complex128.cc; 563s local
> Compiling external/org_tensorflow/tensorflow/core/kernels/matmul_op.cc; 557s local

It also issued another error as described below in the error log.

**Error logs**

> ERROR: /root/.cache/bazel/_bazel_root/3b4c7ccb85580bc382ce4a52e9580003/external/org_tensorflow/tensorflow/core/kernels/BUILD:2354:1: C++ compilation of rule '@org_tensorflow//tensorflow/core/kernels:svd_op' failed (Exit 4)
> gcc: internal compiler error: Killed (program cc1plus)
> Please submit a full bug report,
> with preprocessed source if appropriate.
> See <file:///usr/share/doc/gcc-5/README.Bugs> for instructions.",SaintNazaire,None,2017-10-31T13:50:03Z,2017-11-01T13:54:24Z,,,,,,,
2661,[object_detection] Training Error: embedded_ssd_mobilenet_v1 ,"I was following the directions to train a embedded_ssd_mobilenet model that trains the detection network from the provided pre-trained model  on the COCO dataset .
pre-trained model : ssd_mobilenet_v1_coco.
https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md


However, I get the ValueError('Number of feature maps is expected to equal the length '
ValueError: Number of feature maps is expected to equal the length of `num_anchors_per_location`.
Has anyone else seen this issue or any pointers on how I can try to debug it?


Below I show my embedded_ssd_mobilenet_v1_pets.config to set up the experiment:

model {
  ssd {
    num_classes: 37
    box_coder {
      faster_rcnn_box_coder {
        y_scale: 10.0
        x_scale: 10.0
        height_scale: 5.0
        width_scale: 5.0
      }
    }
    matcher {
      argmax_matcher {
        matched_threshold: 0.5
        unmatched_threshold: 0.5
        ignore_thresholds: false
        negatives_lower_than_unmatched: true
        force_match_for_each_row: true
      }
    }
    similarity_calculator {
      iou_similarity {
      }
    }
    anchor_generator {
      ssd_anchor_generator {
        num_layers: 6
        min_scale: 0.2
        max_scale: 0.95
        aspect_ratios: 1.0
        aspect_ratios: 2.0
        aspect_ratios: 0.5
        aspect_ratios: 3.0
        aspect_ratios: 0.3333
      }
    }
    image_resizer {
      fixed_shape_resizer {
        height: 300
        width: 300
      }
    }
    box_predictor {
      convolutional_box_predictor {
        min_depth: 0
        max_depth: 0
        num_layers_before_predictor: 0
        use_dropout: false
        dropout_keep_probability: 0.8
        kernel_size: 1
        box_code_size: 4
        apply_sigmoid_to_scores: false
        conv_hyperparams {
          activation: RELU_6,
          regularizer {
            l2_regularizer {
              weight: 0.00004
            }
          }
          initializer {
            truncated_normal_initializer {
              stddev: 0.03
              mean: 0.0
            }
          }
          batch_norm {
            train: true,
            scale: true,
            center: true,
            decay: 0.9997,
            epsilon: 0.001,
          }
        }
      }
    }
    feature_extractor {
      type: 'embedded_ssd_mobilenet_v1'
      min_depth: 16
      depth_multiplier: 1.0
      conv_hyperparams {
        activation: RELU_6,
        regularizer {
          l2_regularizer {
            weight: 0.00004
          }
        }
        initializer {
          truncated_normal_initializer {
            stddev: 0.03
            mean: 0.0
          }
        }
        batch_norm {
          train: true,
          scale: true,
          center: true,
          decay: 0.9997,
          epsilon: 0.001,
        }
      }
    }
    loss {
      classification_loss {
        weighted_sigmoid {
          anchorwise_output: true
        }
      }
      localization_loss {
        weighted_smooth_l1 {
          anchorwise_output: true
        }
      }
      hard_example_miner {
        num_hard_examples: 3000
        iou_threshold: 0.99
        loss_type: CLASSIFICATION
        max_negatives_per_positive: 3
        min_negatives_per_image: 0
      }
      classification_weight: 1.0
      localization_weight: 1.0
    }
    normalize_loss_by_num_matches: true
    post_processing {
      batch_non_max_suppression {
        score_threshold: 1e-8
        iou_threshold: 0.6
        max_detections_per_class: 100
        max_total_detections: 100
      }
      score_converter: SIGMOID
    }
  }
}

train_config: {
  batch_size: 24
  optimizer {
    rms_prop_optimizer: {
      learning_rate: {
        exponential_decay_learning_rate {
          initial_learning_rate: 0.004
          decay_steps: 800720
          decay_factor: 0.95
        }
      }
      momentum_optimizer_value: 0.9
      decay: 0.9
      epsilon: 1.0
    }
  }
  fine_tune_checkpoint: ""object_detection/ssd_mobilenet_v1_coco_11_06_2017/model.ckpt""
  from_detection_checkpoint: true
  num_steps: 200000
  data_augmentation_options {
    random_horizontal_flip {
    }
  }
  data_augmentation_options {
    ssd_random_crop {
    }
  }
}

train_input_reader: {
  tf_record_input_reader {
    input_path: ""object_detection/data/pet_train.record""
  }
  label_map_path: ""object_detection/data/pet_label_map.pbtxt""
}

eval_config: {
  num_examples: 2000
  max_evals: 10
}

eval_input_reader: {
  tf_record_input_reader {
    input_path: ""object_detection/data/pet_val.record""
  }
  label_map_path: ""object_detection/data/pet_label_map.pbtxt""
  shuffle: false
  num_readers: 1
}






Traceback (most recent call last):
  File ""object_detection/train.py"", line 165, in <module>
    tf.app.run()
  File ""/autohome/user/chihyu/miniconda2/lib/python2.7/site-packages/tensorflow/python/platform/app.py"", line 48, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""object_detection/train.py"", line 161, in main
    worker_job_name, is_chief, FLAGS.train_dir)
  File ""/autohome/user/chihyu/tensorflow/models/research/object_detection/trainer.py"", line 228, in train
    clones = model_deploy.create_clones(deploy_config, model_fn, [input_queue])
  File ""/autohome/user/chihyu/tensorflow/models/research/slim/deployment/model_deploy.py"", line 193, in create_clones
    outputs = model_fn(*args, **kwargs)
  File ""/autohome/user/chihyu/tensorflow/models/research/object_detection/trainer.py"", line 165, in _create_losses
    prediction_dict = detection_model.predict(images)
  File ""/autohome/user/chihyu/tensorflow/models/research/object_detection/meta_architectures/ssd_meta_arch.py"", line 270, in predict
    im_width=image_shape[2])
  File ""/autohome/user/chihyu/tensorflow/models/research/object_detection/core/anchor_generator.py"", line 98, in generate
    raise ValueError('Number of feature maps is expected to equal the length '
ValueError: Number of feature maps is expected to equal the length of `num_anchors_per_location`.


System information

What is the top-level directory of the model you are using: object_detection
Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04
TensorFlow version (use command below):'1.3.0'
Bazel version (if compiling from source): 
CUDA/cuDNN version: CUDA 9.0, CUDNN 7.0

#define CUDNN_MAJOR 7
#define CUDNN_MINOR 0
#define CUDNN_PATCHLEVEL 3

GPU model and memory:  name: Tesla P100-PCIE-16GB
major: 6 minor: 0 memoryClockRate (GHz) 1.3285
pciBusID 0000:08:00.0
Total memory: 15.89GiB
Free memory: 15.60GiB


Exact command to reproduce: I am using the vanilla train.py command from the object detection README:
python object_detection/train.py 
--logtostderr 
--train_dir='object_detection/embedded_mobileNet/train' 
--pipeline_config_path='object_detection/embedded_mobileNet/embedded_ssd_mobilenet_v1_pets.config'",chihyuwang,None,2017-10-31T12:49:06Z,2018-02-26T03:25:42Z,,,,,,,
2652,object_detection model_builder_test.py fails with Python 3.x,"### System information
- Tensorflow version:  v1.3.0-rc2-20-g0787eee 1.3.0 (installed from package, i.e. binary)
== tensorflow import ============================================
tf.VERSION = 1.3.0
tf.GIT_VERSION = v1.3.0-rc2-20-g0787eee
tf.COMPILER_VERSION = v1.3.0-rc2-20-g0787eee
Sanity check: array([1], dtype=int32)

- Working directory: ~/tensorflow/models/research
- No custom code
- Linux Ubuntu 16.04
- Python version 3.6.3, using GCC 5.4.0 20160609
- **CUDA/cuDNN version**: CUDA 8.0, cudnn 6.0, nVidia driver: 384.90
- GPU: nVidia TitanXp 12GB memory
- CPU: Intel x86-64 Intel Core i7-7700K @ 4.20GHz x 8, 32GB memory
- Command to reproduce: python object_detection/builders/model_builder_test.py 
------------------------

### Describe the problem
object_detection model_builder_test.py fails with Python 3.x
This appears to be a bug in Python 3.x compatibility in the object_detection/model_builder_test.py file.
The code uses the following lines:
Line 334:  `for extractor_type, extractor_class in FEATURE_EXTRACTOR_MAPS.iteritems():`
Line 773:  `for extractor_type, extractor_class in FEATURE_EXTRACTOR_MAPS.iteritems():`
In Python 3.x, dicts no longer support the attribute `.iteritem()`. It needs to be changed to `.item()`.
When I changed the two lines as above, the code works fine in Python 3.6. However, for a complete solution, the code should check which Python version is being used and run the appropriate code for that version.

Here is the error log:
.....EE....
======================================================================
ERROR: test_create_faster_rcnn_resnet_v1_models_from_config (__main__.ModelBuilderTest)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""object_detection/builders/model_builder_test.py"", line 334, in test_create_faster_rcnn_resnet_v1_models_from_config
    for extractor_type, extractor_class in FEATURE_EXTRACTOR_MAPS.iteritems():
AttributeError: 'dict' object has no attribute 'iteritems'

======================================================================
ERROR: test_create_rfcn_resnet_v1_model_from_config (__main__.ModelBuilderTest)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""object_detection/builders/model_builder_test.py"", line 733, in test_create_rfcn_resnet_v1_model_from_config
    for extractor_type, extractor_class in FEATURE_EXTRACTOR_MAPS.iteritems():
AttributeError: 'dict' object has no attribute 'iteritems'

----------------------------------------------------------------------
Ran 11 tests in 0.040s

FAILED (errors=2)
",radzfoto,None,2017-10-30T21:38:31Z,2017-11-03T17:47:51Z,,,,,,,
2644,separable_convolution2d() got an unexpected keyword argument 'data_format',"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",sunset-clouds,b'stat:awaiting response',2017-10-30T14:29:39Z,2018-09-29T04:15:27Z,,,,,,,
2634,[object detection] input_reader_builder_test failed,"### System information
- **OS Platform and Distribution**: Linux Ubuntu 16.04
- **TensorFlow version (use command below)**: 1.3.0
- **CUDA/cuDNN version**: 8.0
- **Exact command to reproduce**: python object_detection/builders/input_reader_builder_test.py
- **protobuf**: protobuf(2.6.1)/protobuf (3.4.0)


### Describe the problem
input reader builder test failed. It seems TfExampleDecoder in input_reader_builder.py does not take load_instance_masks as argument?

### Source code / logs

ERROR: test_build_tf_record_input_reader (__main__.InputReaderBuilderTest)

TypeError: __init__() got an unexpected keyword argument 'load_instance_masks'TypeError: __init__() got an unexpected keyword argument 'load_instance_masks'
",yimintsai,b'type:bug',2017-10-29T03:37:31Z,2017-10-30T05:10:48Z,,,,,,,
2633,Protobuf error using object detection with python3.5?,"**System information**
    **What is the top-level directory of the model you are using:**
    ssd_mobilenet_v1_coco_11_06_2017
    **Have I written custom code (as opposed to using a stock example script provided in TensorFlow):**
    No
    **OS Platform and Distribution (e.g., Linux Ubuntu 16.04):**
    Ubuntu 16.04
    **TensorFlow installed from (source or binary):**
    Binary
    **TensorFlow version (use command below):**
    v1.0.0
    **Bazel version (if compiling from source):**
    NA
    **CUDA/cuDNN version:**
    8.0/5.1
    **GPU model and memory:**
    Ubuntu GTX960 2GB

**Describe the problem**
     I run demo successfully.After finishing model configure and converting training data to tfrecord, I run following command:
python object_detection/train.py --pipeline_config_path=/media/cuixiongwen/WORK/TensorFlow/tensorflow/tensorflow/models/object_detection/samples/configs/ssd_mobilenet_v1_pets.config --train_dir=/media/cuixiongwen/WORK/Code/raccoon_dataset
    Then following error occured:
File ""object_detection/train.py"", line 198, in <module>
    tf.app.run()
File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/platform/app.py"", line 44, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
File ""object_detection/train.py"", line 143, in main
    model_config, train_config, input_config = get_configs_from_pipeline_file()
File ""object_detection/train.py"", line 103, in get_configs_from_pipeline_file
    text_format.Merge(f.read(), pipeline_config)
File ""/usr/local/lib/python3.5/dist-packages/google/protobuf/text_format.py"", line 521, in Merge
    text.split('\n'),
TypeError: a bytes-like object is required, not 'str'
      
        It seemed this error is relative to python3.5, should I recompile protobuf to fix this bug?
",ghost,b'stat:awaiting model gardener',2017-10-29T01:14:13Z,2018-10-20T02:00:03Z,,,,,,,
2624,Updates to exporter modules.,"* Fix a bug that prevented model export with moving averages!
* Add a new input_size flag
* Mark some flags as required.
* Options to add additional intermediate nodes to the exported graph.",tombstone,b'cla: yes',2017-10-28T02:51:20Z,2017-10-28T05:48:44Z,,,,,,,
2612,python export_inference_graph.py --alsologtostderr --model_name=nasnet_mobile --output_file=/tmp/nasnet_mobile.pb,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",chl916185,b'stat:awaiting response',2017-10-27T07:50:25Z,2018-09-29T04:13:44Z,,,,,,,
2598,tensorflow.python.framework.errors_impl.NotFoundError: E:\TensorJupyter\word2vec_ops.so not found,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",Jacklin18244889844,None,2017-10-26T13:30:47Z,2017-10-27T18:42:59Z,,,,,,,
2596,Display the object ground truth box in tensorboard ,"Hi 
Is it possible to display the objects ground truth along with the detection in tensorboard ? 
I'm using the object detection models
Thnaks

Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",mbenami,None,2017-10-26T12:06:23Z,2017-10-27T18:42:35Z,,,,,,,
2578, python export_inference_graph.py --alsologtostderr --model_name=nasnet_large  --output_file=/tmp/nasnet.pb？,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",chl916185,b'stat:awaiting model gardener',2017-10-24T04:12:00Z,2017-10-30T17:45:47Z,,,,,,,
2576,"import google3？How to install google3？this is in ""models/research/slim/nets/nasnet/nasnet_utils.py"" ","Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",chl916185,None,2017-10-24T02:35:20Z,2018-08-20T14:08:00Z,,,,,,,
2562,Fix GRU cell bug,fix candidate activation expression,hamsungho,b'cla: yes',2017-10-20T08:46:38Z,2019-10-28T18:33:44Z,,,,,,,
2561,Having problems to correctly load Tensorflow Word2Vec Model,"I am not quite sure if this is a bug or the result of missing documentation/my unability to find the documentation. But I already posted the question on Stackoverflow a few days ago without getting any response (https://stackoverflow.com/questions/46785690/tensorflow-model-is-not-loading-correctly), so it seems to be no obvious mistake and I hope I do not waste your time. 

I currently try to train a word2vec model for my company.  For this I made use of the code https://github.com/tensorflow/models/blob/master/tutorials/embedding/word2vec.py.

I downloaded the german wikipedia dump and extracted the text information out of it. The task is to train a model with this data.

I work on a virtual Machine that has Ubuntu 16.04 and access to a Tesla M60. I have CUDA 8 and cuDNN 7.0.3 I installed Tensorflow-gpu via the ""pip install tensorflow-gpu"" command. For the weekend I trained the model and saved the checkpoints in a seperate folder. At the end of the weekend the model was able to answer 36% of the evaluation questions I gave to him (german questions similar to the example ""questions-word.txt""). After training I want to load the model and run the evaluation task again. For this I changed the code in following lines (except for path changes): I added

`with tf.Graph().as_default(), #tf.Session() as session:

       saver = tf.train.import_meta_graph(opts.save_path + ""/model.ckpt-288720426.meta"")

       saver.restore(session, tf.train.latest_checkpoint('./results'))

       print(""Model restored."")

       with tf.device(""/cpu:0""):

          model = Word2Vec(opts, session)

          model.read_analogies()  # Read analogy questions

       for _ in xrange(opts.epochs_to_train):

          #model.train()  # Process one epoch

          model.eval()  # Eval analogies.`

I added the two lines for loading the model (saver = ...) and commented out the training line. Looking at the meta and latest checkpoint files and tensorboard shows a trained model, but when I run the code, the evaluation results in 0.1% correct answers, which seems to me like the model restarts with an untrained model. I expected the result to be again 36%.

Can somebody tell me the error I made in the code, or maybe even in my thinking?
",Xsea,b'type:build/install',2017-10-20T06:40:53Z,2017-10-24T13:35:33Z,,,,,,,
2559,Object detection train.py yields a precondition error on google cloudml,"I hope this is genuinely a bug, i believe that i've done enough testing to submit an issue. I have an open stack overflow [question](
https://stackoverflow.com/questions/46800018/tensorflow-object-detection-train-py-fails-when-running-on-cloud-machine-learnin) as well. Thank you for your time.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
object_detection
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux. Google Cloud Machine Learning engine. Yaml 

```
trainingInput:
  runtimeVersion: ""1.0""
  scaleTier: CUSTOM
  masterType: standard_gpu
  workerCount: 2
  workerType: standard_gpu
  parameterServerCount: 3
  parameterServerType: standard
```  

- **TensorFlow installed from (source or binary)**: packaged from binary
- **TensorFlow version (use command below)**:
- **GPU model and memory**: Unknown within Google Cloud ML
- **Exact command to reproduce**:

```
gcloud ml-engine jobs submit training ""${JOB_ID}_train"" \
    --job-dir=${TRAIN_DIR} \
    --packages dist/object_detection-0.1.tar.gz,slim/dist/slim-0.1.tar.gz \
    --module-name object_detection.train \
    --region us-central1 \
    --config ${PIPELINE_YAML} \
    -- \
    --train_dir=${TRAIN_DIR} \
    --pipeline_config_path= gs://api-project-773889352370-ml/DeepMeerkatDetection/faster_rcnn_inception_resnet_v2_atrous_coco_cloud.config
```

I have made my pipeline config public such that it can be tested. the train_dir is not critical to the problem in question. The Yaml is included, above, again I don't think it is the crux of the issue.

### Describe the problem

I am running the object detection train.py script. I have a fully working local version that runs without error.

When I run

```
gcloud ml-engine jobs submit training ""${JOB_ID}_train"" \
    --job-dir=${TRAIN_DIR} \
    --packages dist/object_detection-0.1.tar.gz,slim/dist/slim-0.1.tar.gz \
    --module-name object_detection.train \
    --region us-central1 \
    --config ${PIPELINE_YAML} \
    -- \
    --train_dir=${TRAIN_DIR} \
    --pipeline_config_path= ${PIPELINE_CONFIG_PATH}
```

I get 

```
The replica ps 0 exited with a non-zero status of 1. Termination reason: Error. Traceback (most recent call last): File ""/usr/lib/python2.7/runpy.py"", line 162, in _run_module_as_main ""__main__"", fname, loader, pkg_name) File ""/usr/lib/python2.7/runpy.py"", line 72, in _run_code exec code in run_globals File ""/root/.local/lib/python2.7/site-packages/object_detection/train.py"", line 198, in <module> tf.app.run() File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 44, in run _sys.exit(main(_sys.argv[:1] + flags_passthrough)) File ""/root/.local/lib/python2.7/site-packages/object_detection/train.py"", line 145, in main model_config, train_config, input_config = get_configs_from_multiple_files() File ""/root/.local/lib/python2.7/site-packages/object_detection/train.py"", line 127, in get_configs_from_multiple_files text_format.Merge(f.read(), train_config) File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/lib/io/file_io.py"", line 112, in read return pywrap_tensorflow.ReadFromStream(self._read_buf, length, status) File ""/usr/lib/python2.7/contextlib.py"", line 24, in __exit__ self.gen.next() File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/errors_impl.py"", line 466, in raise_exception_on_not_ok_status pywrap_tensorflow.TF_GetCode(status)) FailedPreconditionError: . 
```

There doesn't seem to be anything wrong with my cloud machine learning environment. I can submit an eval.py job that runs without error (waits for a model to be generated).

What is particularly curious is that I can point to the cloud bucket from my local machine and run without an issue.

```
(detection) Bens-MacBook-Pro:Detection ben$ python object_detection/train.py     --logtostderr     --pipeline_config_path=/Users/ben/Documents/DeepMeerkat/training/Detection/faster_rcnn_inception_resnet_v2_atrous_coco_cloud.config     --train_dir=/Users/Ben/Dropbox/GoogleCloud/Detection/train/test/
INFO:tensorflow:Scale of 0 disables regularizer.
INFO:tensorflow:Scale of 0 disables regularizer.
INFO:tensorflow:Scale of 0 disables regularizer.
INFO:tensorflow:Scale of 0 disables regularizer.
INFO:tensorflow:Scale of 0 disables regularizer.
INFO:tensorflow:Scale of 0 disables regularizer.
INFO:tensorflow:Scale of 0 disables regularizer.
INFO:tensorflow:Scale of 0 disables regularizer.
INFO:tensorflow:Summary name Learning Rate is illegal; using Learning_Rate instead.
INFO:tensorflow:Summary name /clone_loss is illegal; using clone_loss instead.
/Users/ben/Documents/DeepMeerkat/training/Detection/detection/lib/python2.7/site-packages/tensorflow/python/ops/gradients_impl.py:95: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  ""Converting sparse IndexedSlices to a dense Tensor of unknown shape. ""
2017-10-19 11:18:28.417340: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2017-10-19 11:18:28.417360: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2017-10-19 11:18:28.417367: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2017-10-19 11:18:28.417373: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
2017-10-19 11:18:42.664975: I tensorflow/core/common_runtime/simple_placer.cc:697] Ignoring device specification /device:GPU:0 for node 'prefetch_queue_Dequeue' because the input edge from 'prefetch_queue' is a reference connection and already has a device field set to /device:CPU:0
INFO:tensorflow:Restoring parameters from gs://api-project-773889352370-ml/DeepMeerkatDetection/checkpoint/faster_rcnn_inception_resnet_v2_atrous_coco_11_06_2017/model.ckpt
```

The entirety of the config is the same as the local version, except changing the paths to gs:// bucket. 


```
# Faster R-CNN with Inception Resnet v2, Atrous version;
# Configured for MSCOCO Dataset.
# Users should configure the fine_tune_checkpoint field in the train config as
# well as the label_map_path and input_path fields in the train_input_reader and
# eval_input_reader. Search for ""PATH_TO_BE_CONFIGURED"" to find the fields that
# should be configured.

model {
  faster_rcnn {
    num_classes: 90
    image_resizer {
      keep_aspect_ratio_resizer {
        min_dimension: 600
        max_dimension: 1024
      }
    }
    feature_extractor {
      type: 'faster_rcnn_inception_resnet_v2'
      first_stage_features_stride: 8
    }
    first_stage_anchor_generator {
      grid_anchor_generator {
        scales: [0.25, 0.5, 1.0, 2.0]
        aspect_ratios: [0.5, 1.0, 2.0]
        height_stride: 8
        width_stride: 8
      }
    }
    first_stage_atrous_rate: 2
    first_stage_box_predictor_conv_hyperparams {
      op: CONV
      regularizer {
        l2_regularizer {
          weight: 0.0
        }
      }
      initializer {
        truncated_normal_initializer {
          stddev: 0.01
        }
      }
    }
    first_stage_nms_score_threshold: 0.0
    first_stage_nms_iou_threshold: 0.7
    first_stage_max_proposals: 300
    first_stage_localization_loss_weight: 2.0
    first_stage_objectness_loss_weight: 1.0
    initial_crop_size: 17
    maxpool_kernel_size: 1
    maxpool_stride: 1
    second_stage_box_predictor {
      mask_rcnn_box_predictor {
        use_dropout: false
        dropout_keep_probability: 1.0
        fc_hyperparams {
          op: FC
          regularizer {
            l2_regularizer {
              weight: 0.0
            }
          }
          initializer {
            variance_scaling_initializer {
              factor: 1.0
              uniform: true
              mode: FAN_AVG
            }
          }
        }
      }
    }
    second_stage_post_processing {
      batch_non_max_suppression {
        score_threshold: 0.0
        iou_threshold: 0.6
        max_detections_per_class: 100
        max_total_detections: 100
      }
      score_converter: SOFTMAX
    }
    second_stage_localization_loss_weight: 2.0
    second_stage_classification_loss_weight: 1.0
  }
}

train_config: {
  batch_size: 1
  optimizer {
    momentum_optimizer: {
      learning_rate: {
        manual_step_learning_rate {
          initial_learning_rate: 0.0003
          schedule {
            step: 0
            learning_rate: .0003
          }
          schedule {
            step: 900000
            learning_rate: .00003
          }
          schedule {
            step: 1200000
            learning_rate: .000003
          }
        }
      }
      momentum_optimizer_value: 0.9
    }
    use_moving_average: false
  }
  gradient_clipping_by_norm: 10.0
  fine_tune_checkpoint: ""gs://api-project-773889352370-ml/DeepMeerkatDetection/checkpoint/faster_rcnn_inception_resnet_v2_atrous_coco_11_06_2017/model.ckpt""
  from_detection_checkpoint: true
  # Note: The below line limits the training process to 200K steps, which we
  # empirically found to be sufficient enough to train the pets dataset. This
  # effectively bypasses the learning rate schedule (the learning rate will
  # never decay). Remove the below line to train indefinitely.
  num_steps: 200000
  data_augmentation_options {
    random_horizontal_flip {
    }
  }
}

train_input_reader: {
  tf_record_input_reader {
    input_path: ""gs://api-project-773889352370-ml/DeepMeerkatDetection/tfrecords/train.record""
  }
  label_map_path: ""gs://api-project-773889352370-ml/DeepMeerkatDetection/label.pbtxt""
}

eval_config: {
  num_examples: 150
  # Note: The below line limits the evaluation process to 10 evaluations.
  # Remove the below line to evaluate indefinitely.
  max_evals: 10
}

eval_input_reader: {
  tf_record_input_reader {
    input_path: ""gs://api-project-773889352370-ml/DeepMeerkatDetection/tfrecords/eval.record""
  }
  label_map_path: ""gs://api-project-773889352370-ml/DeepMeerkatDetection/label.pbtxt""
  shuffle: false
  num_readers: 1
  num_epochs: 1
}
```
---
Just as a further test, I can open up a new cloud engine, install everything, check the model test

```
benweinstein2010@instance-2:~/models/research$ python object_detection/builders/model_builder_test.py
.......
----------------------------------------------------------------------
Ran 7 tests in 0.035s
OK
```

and grab that local config file which points to objects in the bucket

```
benweinstein2010@instance-2:~/models/research$ gsutil cp gs://api-project-773889352370-ml/DeepMeerkatDetection/fast
er_rcnn_inception_resnet_v2_atrous_coco_cloud.config .
```

Then run train.py, which hasn't yet generated any errors (still running).

```
benweinstein2010@instance-2:~/models/research$ python object_detection/train.py \
>     --logtostderr \
>     --pipeline_config_path=faster_rcnn_inception_resnet_v2_atrous_coco_cloud.config \
>     --train_dir=../test/ 
```

```
INFO:tensorflow:Scale of 0 disables regularizer.
INFO:tensorflow:Scale of 0 disables regularizer.
INFO:tensorflow:Scale of 0 disables regularizer.
INFO:tensorflow:Scale of 0 disables regularizer.
INFO:tensorflow:Scale of 0 disables regularizer.
INFO:tensorflow:Scale of 0 disables regularizer.
INFO:tensorflow:Scale of 0 disables regularizer.
INFO:tensorflow:Scale of 0 disables regularizer.
INFO:tensorflow:Summary name Learning Rate is illegal; using Learning_Rate instead.
INFO:tensorflow:Summary name /clone_loss is illegal; using clone_loss instead.
/home/benweinstein2010/.local/lib/python2.7/site-packages/tensorflow/python/ops/gradients_impl.py:95: UserWarning: 
Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  ""Converting sparse IndexedSlices to a dense Tensor of unknown shape. ""
2017-10-19 18:54:02.322985: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow librar
y wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed
 up CPU computations.
2017-10-19 18:54:02.323139: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow librar
y wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed
 up CPU computations.
2017-10-19 18:54:02.323204: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow librar
y wasn't compiled to use AVX instructions, but these are available on your machine and could speed up
 CPU computations.
2017-10-19 18:54:02.323242: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow librar
y wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed u
p CPU computations.
2017-10-19 18:54:02.323278: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow librar
y wasn't compiled to use FMA instructions, but these are available on your machine and could speed up
 CPU computations.
2017-10-19 18:54:04.677595: I tensorflow/core/common_runtime/simple_placer.cc:697] Ignoring device specification /device:G
PU:0 for node 'prefetch_queue_Dequeue' because the input edge from 'prefetch_queue' is a reference connection and already 
has a device field set to /device:CPU:0
INFO:tensorflow:Restoring parameters from gs://api-project-773889352370-ml/DeepMeerkatDetection/checkpoint/faster_rcnn_inc
eption_resnet_v2_atrous_coco_11_06_2017/model.ckpt
```

So its something about the interaction either with the GPU or cloud machine learning engine's environment.

---
Another idea might be that the checkpoint is somehow been corrupted during upload. We can test this bypassing and training from scratch.

In .config
```
  from_detection_checkpoint: false
```

that yields the the same precondition error, so it can't be the model.",bw4sz,None,2017-10-19T18:42:21Z,2017-10-20T23:19:37Z,,,,,,,
2550,SVM for classification for object detection ,"Hi everyone 
I'll would like to change the last layer in the object detection Faster Rcnn from softmax to svm 
Has anyone done something like that and can give me some hint on how to do that? 
I'm new little bit in the core flow of tensor-flow (just using the normal API and i'll would like to dig in little bit) 

Thanks for the help!



Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",mbenami,b'stat:awaiting model gardener',2017-10-18T12:31:57Z,2017-10-27T18:33:16Z,,,,,,,
2548,Out of memory when training SSD mobilenet on google cloud ml,"### System information
- **What is the top-level directory of the model you are using**:
ssd_mobilenet_v1_coco_11_06_2017
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
Yes, modified dataset and config
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**:
Binary 
- **TensorFlow version (use command below)**:
1.3.0
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
standard_gpu as described in [here](https://cloud.google.com/ml-engine/pricing#machine_types_for_custom_cluster_configurations)
- **Exact command to reproduce**:

gcloud ml-engine jobs submit training wound_object_detection_`date +%s` \
    --job-dir=gs://my-bucket-name/train \
    --packages dist/object_detection-0.1.tar.gz,slim/dist/slim-0.1.tar.gz \
    --module-name object_detection.train \
    --region us-central1 \
    --config object_detection/samples/cloud/cloud.yml \
    -- \
    --train_dir=gs://my-bucket-name/train \
    --pipeline_config_path=gs://my-bucket-name/data/ssd_mobilenet_v1_my_own.config


### Describe the problem
Attempting to fine tune ssd mobilenet on cloud ml engine results in out of memory after running ~7000 steps.  I am getting the following message:
> The replica worker 9 ran out-of-memory and exited with a non-zero status of 247

I am using a custom dataset which consists of roughly 2000 images. I have also changed the number of classes to one. These are the only two changes from the standard example on pet dataset.  
I have already successfully managed to fine tune _faster_rcnn_resnet101_, so the dataset is not the issue. It happens randomly after around 15 minutes of runtime. 
It does not make sense, since ssd_mobilenet should be a much smaller net than faster_resnet, that is why I suspect a bug. I am using the original cloud.yml configuration with 10 gpu workers
The same also happens when I try to train locally (though the local GPU is quite weak, so it makes sense)
Any suggestion or workaround will be very welcome.

### Source code / logs
",AndreyRub,None,2017-10-18T07:50:21Z,2017-10-27T18:32:48Z,,,,,,,
2531,Does syntaxnet supports Simplified Chinese?,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",CyrusLiu158,None,2017-10-12T15:30:46Z,2017-10-12T17:05:45Z,,,,,,,
2530,Reduce number of support issues,"I see a lot of people are asking for support in these issues. 
I think this is because the Readme for `object_detection` has a section ""Getting help"" where literally the first thing is ""the issue tracker"". 

I suggest to change the readme so as to direct support to StackOverflow and completely remove the link to the issue tracker from the Readme. People who have bugs know how to report them 😃 .

Sorry, didn't feel like signing the CLA just for such a small PR. The queue is already long ",cipri-tom,None,2017-10-12T15:18:10Z,2017-10-13T05:15:16Z,,,,,,,
2503,Error reshaping image in load_image_into_numpy_array,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
models/research/object_detection

- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Ubuntu 16.04
- **TensorFlow installed from (source or binary)**:
conda
- **TensorFlow version (use command below)**:
```
python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""
b'unknown' 1.3.0
```
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

I get this error while running the object_detection_tutorial, but I will just put the relevant code
```
import numpy as np
import os
import six.moves.urllib as urllib
import sys
import tarfile
import tensorflow as tf
import zipfile
import glob

from collections import defaultdict
from io import StringIO
from matplotlib import pyplot as plt
from PIL import Image

def load_image_into_numpy_array(image):
  (im_width, im_height) = image.size
  return np.array(image.getdata()).reshape(
      (im_height, im_width, 3)).astype(np.uint8)

 image  = Image.open('small_images/RNAi.1.N2.E.D_A01-autolevel-300x300.jpeg')
image_np  = load_image_into_numpy_array(image)

## Output
ValueError                                Traceback (most recent call last)
<ipython-input-4-e1507f4b23ae> in <module>()
----> 1 image_np  = load_image_into_numpy_array(image)

<ipython-input-2-f35cf9e400b7> in load_image_into_numpy_array(image)
      2   (im_width, im_height) = image.size
      3   return np.array(image.getdata()).reshape(
----> 4       (im_height, im_width, 3)).astype(np.uint8)
      5 

ValueError: cannot reshape array of size 90000 into shape (300,300,3)
```

I have tried images with different sizes.


You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

In the object_detection_tutorial the load_image_into_numpy_array gets an error.

I'm not sure if its a bug or something wrong on my end.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",jerowe,None,2017-10-06T04:29:56Z,2019-11-29T09:47:06Z,,,,,,,
2489,Problems with official examples,"I'm playing with Tensorflow for a week now and I was able to hook up another database to the models in the official folder (https://github.com/tensorflow/models/blob/master/official/resnet/imagenet_main.py). I like this high-level API much and everything seems to work fine apart the following issues:

- when using a large database containing millions of images, the workstation just explodes. High RAM usage, events.out.tfevent on the order of several gigabytes. I realized that this problem is related to the fact that each time a checkpoint is saved or a summary, the entire list of images is saved to disk:) I could circumvent this problem by using placeholders for filenames and variables, feeding them using a hook on the train function. I don't know if this the recommended way. I've read somewhere that one might want to transfer the database into TFRecords. However, what's best there: a single file or multiple files?

- I had to add something like logits += tf.constant(1e-8) to avoid NaN at some point

- training proceeds nicely apart that something is destroyed each time a checkpoint is restored (after stop and restart or when the train function finishes in the cycle while loop).

![screenshot_2017-10-04_09-40-25](https://user-images.githubusercontent.com/2109115/31165885-04564040-a8ed-11e7-88e8-a9cf58070942.png)

Is this something expected? I suspect that some parameters are not well restored (batch norm moving mean or moving variance?). If I run the example on a smaller database with fewer classes, this does not seem that dramatic. But I guess it is because I haven't run it for long. Maybe the moving mean/variance is really well estimated, then destroyed, causing those curves.

I've posted this question at several places. Also, I've seen people having the same issue in different places. However, I found no convincing answer. Thanks for your help.


",jmaye,b'type:bug',2017-10-04T08:20:59Z,2018-07-13T07:35:45Z,,,,,,,
2476,fix #2470 : Create imagenet sub-dir only if does not exist,"The imagenet download and preprocess script failed due to some bug in bazel file path parsing system. If I re-run the imagenet download and preprocess script, it throws an error saying-

OSError: [Errno 17] File exists:
because some of the dataset was previously extracted.

Ideally the script should only try to create a directory if it does not exist.

My commit fixes just this problem and has just one line of code added.",pankajkgupta,b'cla: yes',2017-09-28T15:47:09Z,2019-10-28T18:33:43Z,,,,,,,
2475,"why  [123, 117, 104] is considered the mean of the three channels of images?","Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",Amyhii,None,2017-09-28T11:49:40Z,2017-10-03T08:36:58Z,,,,,,,
2474,Object Detection ssd mobilenet Training not reading in batch norm parameters,"I was following the directions to train a ssd_mobilenet model that trains the detection network from scratch after initializing the backbone with the weights of a model trained on Imagenet. I downloaded the pre-trained mobilenet checkpoint for this experiment. 
MobileNet_v1_0.25_128
mobilenet_v1_0.25_128_2017_06_14.tar.gz
https://github.com/tensorflow/models/tree/master/research/slim

However, I get warning messages complaining that the batch norm parameters could not be loaded (see below for the messages). Has anyone else seen this issue or any pointers on how I can try to debug it?

Below I show my train_config to set up the experiment from the stock one given in the detection library and the warning messages I see about not reading in

train_config: {
  batch_size: 24
  optimizer {
    rms_prop_optimizer: {
      learning_rate: {
        exponential_decay_learning_rate {
          initial_learning_rate: 0.004
          decay_steps: 800720
          decay_factor: 0.95
        }
      }
      momentum_optimizer_value: 0.9
      decay: 0.9
      epsilon: 1.0
    }
  }
  fine_tune_checkpoint: ""object_detection/mobilenet_v1_025/mobilenet_v1_0.25_128.ckpt""
  from_detection_checkpoint: false
  data_augmentation_options {
    random_horizontal_flip {
    }
  }
  data_augmentation_options {
    ssd_random_crop {
    }
  }
}

INFO:tensorflow:Summary name Learning Rate is illegal; using Learning_Rate instead.
WARNING:root:Variable [MobilenetV1/Conv2d_13_pointwise_1_Conv2d_2_1x1_128/BatchNorm/beta] not available in checkpoint
WARNING:root:Variable [MobilenetV1/Conv2d_13_pointwise_1_Conv2d_2_1x1_128/BatchNorm/gamma] not available in checkpoint
WARNING:root:Variable [MobilenetV1/Conv2d_13_pointwise_1_Conv2d_2_1x1_128/BatchNorm/moving_mean] not available in checkpoint
WARNING:root:Variable [MobilenetV1/Conv2d_13_pointwise_1_Conv2d_2_1x1_128/BatchNorm/moving_variance] not available in checkpoint
WARNING:root:Variable [MobilenetV1/Conv2d_13_pointwise_1_Conv2d_2_1x1_128/weights] not available in checkpoint
WARNING:root:Variable [MobilenetV1/Conv2d_13_pointwise_1_Conv2d_3_1x1_64/BatchNorm/beta] not available in checkpoint
WARNING:root:Variable [MobilenetV1/Conv2d_13_pointwise_1_Conv2d_3_1x1_64/BatchNorm/gamma] not available in checkpoint
WARNING:root:Variable [MobilenetV1/Conv2d_13_pointwise_1_Conv2d_3_1x1_64/BatchNorm/moving_mean] not available in checkpoint
WARNING:root:Variable [MobilenetV1/Conv2d_13_pointwise_1_Conv2d_3_1x1_64/BatchNorm/moving_variance] not available in checkpoint
WARNING:root:Variable [MobilenetV1/Conv2d_13_pointwise_1_Conv2d_3_1x1_64/weights] not available in checkpoint
WARNING:root:Variable [MobilenetV1/Conv2d_13_pointwise_1_Conv2d_4_1x1_64/BatchNorm/beta] not available in checkpoint
WARNING:root:Variable [MobilenetV1/Conv2d_13_pointwise_1_Conv2d_4_1x1_64/BatchNorm/gamma] not available in checkpoint
WARNING:root:Variable [MobilenetV1/Conv2d_13_pointwise_1_Conv2d_4_1x1_64/BatchNorm/moving_mean] not available in checkpoint
WARNING:root:Variable [MobilenetV1/Conv2d_13_pointwise_1_Conv2d_4_1x1_64/BatchNorm/moving_variance] not available in checkpoint
WARNING:root:Variable [MobilenetV1/Conv2d_13_pointwise_1_Conv2d_4_1x1_64/weights] not available in checkpoint
WARNING:root:Variable [MobilenetV1/Conv2d_13_pointwise_1_Conv2d_5_1x1_32/BatchNorm/beta] not available in checkpoint
WARNING:root:Variable [MobilenetV1/Conv2d_13_pointwise_1_Conv2d_5_1x1_32/BatchNorm/gamma] not available in checkpoint
WARNING:root:Variable [MobilenetV1/Conv2d_13_pointwise_1_Conv2d_5_1x1_32/BatchNorm/moving_mean] not available in checkpoint
WARNING:root:Variable [MobilenetV1/Conv2d_13_pointwise_1_Conv2d_5_1x1_32/BatchNorm/moving_variance] not available in checkpoint
WARNING:root:Variable [MobilenetV1/Conv2d_13_pointwise_1_Conv2d_5_1x1_32/weights] not available in checkpoint
WARNING:root:Variable [MobilenetV1/Conv2d_13_pointwise_2_Conv2d_2_3x3_s2_256/BatchNorm/beta] not available in checkpoint
WARNING:root:Variable [MobilenetV1/Conv2d_13_pointwise_2_Conv2d_2_3x3_s2_256/BatchNorm/gamma] not available in checkpoint
WARNING:root:Variable [MobilenetV1/Conv2d_13_pointwise_2_Conv2d_2_3x3_s2_256/BatchNorm/moving_mean] not available in checkpoint
WARNING:root:Variable [MobilenetV1/Conv2d_13_pointwise_2_Conv2d_2_3x3_s2_256/BatchNorm/moving_variance] not available in checkpoint
WARNING:root:Variable [MobilenetV1/Conv2d_13_pointwise_2_Conv2d_2_3x3_s2_256/weights] not available in checkpoint
WARNING:root:Variable [MobilenetV1/Conv2d_13_pointwise_2_Conv2d_3_3x3_s2_128/BatchNorm/beta] not available in checkpoint
WARNING:root:Variable [MobilenetV1/Conv2d_13_pointwise_2_Conv2d_3_3x3_s2_128/BatchNorm/gamma] not available in checkpoint
WARNING:root:Variable [MobilenetV1/Conv2d_13_pointwise_2_Conv2d_3_3x3_s2_128/BatchNorm/moving_mean] not available in checkpoint
WARNING:root:Variable [MobilenetV1/Conv2d_13_pointwise_2_Conv2d_3_3x3_s2_128/BatchNorm/moving_variance] not available in checkpoint
WARNING:root:Variable [MobilenetV1/Conv2d_13_pointwise_2_Conv2d_3_3x3_s2_128/weights] not available in checkpoint
WARNING:root:Variable [MobilenetV1/Conv2d_13_pointwise_2_Conv2d_4_3x3_s2_128/BatchNorm/beta] not available in checkpoint
WARNING:root:Variable [MobilenetV1/Conv2d_13_pointwise_2_Conv2d_4_3x3_s2_128/BatchNorm/gamma] not available in checkpoint
WARNING:root:Variable [MobilenetV1/Conv2d_13_pointwise_2_Conv2d_4_3x3_s2_128/BatchNorm/moving_mean] not available in checkpoint
WARNING:root:Variable [MobilenetV1/Conv2d_13_pointwise_2_Conv2d_4_3x3_s2_128/BatchNorm/moving_variance] not available in checkpoint
WARNING:root:Variable [MobilenetV1/Conv2d_13_pointwise_2_Conv2d_4_3x3_s2_128/weights] not available in checkpoint
WARNING:root:Variable [MobilenetV1/Conv2d_13_pointwise_2_Conv2d_5_3x3_s2_64/BatchNorm/beta] not available in checkpoint
WARNING:root:Variable [MobilenetV1/Conv2d_13_pointwise_2_Conv2d_5_3x3_s2_64/BatchNorm/gamma] not available in checkpoint
WARNING:root:Variable [MobilenetV1/Conv2d_13_pointwise_2_Conv2d_5_3x3_s2_64/BatchNorm/moving_mean] not available in checkpoint
WARNING:root:Variable [MobilenetV1/Conv2d_13_pointwise_2_Conv2d_5_3x3_s2_64/BatchNorm/moving_variance] not available in checkpoint
WARNING:root:Variable [MobilenetV1/Conv2d_13_pointwise_2_Conv2d_5_3x3_s2_64/weights] not available in checkpoint
INFO:tensorflow:Summary name /clone_loss is illegal; using clone_loss instead.
INFO:tensorflow:Summary name /clone_loss is illegal; using clone_loss instead.
2017-09-28 12:54:07.684949: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2017-09-28 12:54:07.684970: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2017-09-28 12:54:07.684974: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2017-09-28 12:54:07.684977: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2017-09-28 12:54:07.684980: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
2017-09-28 12:54:07.783602: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:893] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2017-09-28 12:54:07.783851: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 0 with properties:
name: GeForce GTX 1080
major: 6 minor: 1 memoryClockRate (GHz) 1.759
pciBusID 0000:02:00.0
Total memory: 7.92GiB
Free memory: 7.81GiB
2017-09-28 12:54:07.783862: I tensorflow/core/common_runtime/gpu/gpu_device.cc:976] DMA: 0
2017-09-28 12:54:07.783866: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 0:   Y
2017-09-28 12:54:07.783871: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1080, pci bus id: 0000:02:00.0)
2017-09-28 12:54:08.774752: I tensorflow/core/common_runtime/simple_placer.cc:697] Ignoring device specification /device:GPU:0 for node 'prefetch_queue_Dequeue' because the input edge from 'prefetch_queue' is a reference connection and already has a device field set to /device:CPU:0
INFO:tensorflow:Restoring parameters from object_detection/mobilenet_v1_025/mobilenet_v1_0.25_128.ckpt
INFO:tensorflow:Restoring parameters from object_detection/mobilenet_v1_025/mobilenet_v1_0.25_128.ckpt
INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.InvalidArgumentError'>, Assign requires shapes of both tensors to match. lhs shape= [16] rhs shape= [8]
         [[Node: save/Assign_1 = Assign[T=DT_FLOAT, _class=[""loc:@FeatureExtractor/MobilenetV1/Conv2d_0/BatchNorm/gamma""], use_locking=true, validate_shape=true, _device=""/job:localhost/replica:0/task:0/cpu:0""](FeatureExtractor/MobilenetV1/Conv2d_0/BatchNorm/gamma, save/RestoreV2_1)]]

Caused by op u'save/Assign_1', defined at:
  File ""object_detection/train.py"", line 200, in <module>
    tf.app.run()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 48, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""object_detection/train.py"", line 196, in main
    worker_job_name, is_chief, FLAGS.train_dir)
  File ""/home/chiuyu/code2/tensorflow/models/research/object_detection/trainer.py"", line 219, in train
    init_saver = tf.train.Saver(available_var_map)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1140, in __init__
    self.build()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1172, in build
    filename=self._filename)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 688, in build
    restore_sequentially, reshape)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 419, in _AddRestoreOps
    assign_ops.append(saveable.restore(tensors, shapes))
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 155, in restore
    self.op.get_shape().is_fully_defined())
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/state_ops.py"", line 274, in assign
    validate_shape=validate_shape)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_state_ops.py"", line 43, in assign
    use_locking=use_locking, name=name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py"", line 767, in apply_op
    op_def=op_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 2630, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 1204, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access

InvalidArgumentError (see above for traceback): Assign requires shapes of both tensors to match. lhs shape= [16] rhs shape= [8]
         [[Node: save/Assign_1 = Assign[T=DT_FLOAT, _class=[""loc:@FeatureExtractor/MobilenetV1/Conv2d_0/BatchNorm/gamma""], use_locking=true, validate_shape=true, _device=""/job:localhost/replica:0/task:0/cpu:0""](FeatureExtractor/MobilenetV1/Conv2d_0/BatchNorm/gamma, save/RestoreV2_1)]]

INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.InvalidArgumentError'>, Assign requires shapes of both tensors to match. lhs shape= [16] rhs shape= [8]
         [[Node: save/Assign_1 = Assign[T=DT_FLOAT, _class=[""loc:@FeatureExtractor/MobilenetV1/Conv2d_0/BatchNorm/gamma""], use_locking=true, validate_shape=true, _device=""/job:localhost/replica:0/task:0/cpu:0""](FeatureExtractor/MobilenetV1/Conv2d_0/BatchNorm/gamma, save/RestoreV2_1)]]

Caused by op u'save/Assign_1', defined at:
  File ""object_detection/train.py"", line 200, in <module>
    tf.app.run()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 48, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""object_detection/train.py"", line 196, in main
    worker_job_name, is_chief, FLAGS.train_dir)
  File ""/home/chiuyu/code2/tensorflow/models/research/object_detection/trainer.py"", line 219, in train
    init_saver = tf.train.Saver(available_var_map)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1140, in __init__
    self.build()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1172, in build
    filename=self._filename)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 688, in build
    restore_sequentially, reshape)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 419, in _AddRestoreOps
    assign_ops.append(saveable.restore(tensors, shapes))
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 155, in restore
    self.op.get_shape().is_fully_defined())
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/state_ops.py"", line 274, in assign
    validate_shape=validate_shape)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_state_ops.py"", line 43, in assign
    use_locking=use_locking, name=name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py"", line 767, in apply_op
    op_def=op_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 2630, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 1204, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access

InvalidArgumentError (see above for traceback): Assign requires shapes of both tensors to match. lhs shape= [16] rhs shape= [8]
         [[Node: save/Assign_1 = Assign[T=DT_FLOAT, _class=[""loc:@FeatureExtractor/MobilenetV1/Conv2d_0/BatchNorm/gamma""], use_locking=true, validate_shape=true, _device=""/job:localhost/replica:0/task:0/cpu:0""](FeatureExtractor/MobilenetV1/Conv2d_0/BatchNorm/gamma, save/RestoreV2_1)]]

Traceback (most recent call last):
  File ""object_detection/train.py"", line 200, in <module>
    tf.app.run()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 48, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""object_detection/train.py"", line 196, in main
    worker_job_name, is_chief, FLAGS.train_dir)
  File ""/home/chiuyu/code2/tensorflow/models/research/object_detection/trainer.py"", line 296, in train
    saver=saver)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/slim/python/slim/learning.py"", line 738, in train
    master, start_standard_services=False, config=session_config) as sess:
  File ""/usr/lib/python2.7/contextlib.py"", line 17, in __enter__
    return self.gen.next()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/supervisor.py"", line 964, in managed_session
    self.stop(close_summary_writer=close_summary_writer)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/supervisor.py"", line 792, in stop
    stop_grace_period_secs=self._stop_grace_secs)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/coordinator.py"", line 389, in join
    six.reraise(*self._exc_info_to_raise)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/supervisor.py"", line 953, in managed_session
    start_standard_services=start_standard_services)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/supervisor.py"", line 708, in prepare_or_wait_for_session
    init_feed_dict=self._init_feed_dict, init_fn=self._init_fn)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/session_manager.py"", line 281, in prepare_session
    init_fn(sess)
  File ""/home/chiuyu/code2/tensorflow/models/research/object_detection/trainer.py"", line 221, in initializer_fn
    init_saver.restore(sess, train_config.fine_tune_checkpoint)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1560, in restore
    {self.saver_def.filename_tensor_name: save_path})
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 895, in run
    run_metadata_ptr)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1124, in _run
    feed_dict_tensor, options, run_metadata)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1321, in _do_run
    options, run_metadata)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1340, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.InvalidArgumentError: Assign requires shapes of both tensors to match. lhs shape= [16] rhs shape= [8]
         [[Node: save/Assign_1 = Assign[T=DT_FLOAT, _class=[""loc:@FeatureExtractor/MobilenetV1/Conv2d_0/BatchNorm/gamma""], use_locking=true, validate_shape=true, _device=""/job:localhost/replica:0/task:0/cpu:0""](FeatureExtractor/MobilenetV1/Conv2d_0/BatchNorm/gamma, save/RestoreV2_1)]]

Caused by op u'save/Assign_1', defined at:
  File ""object_detection/train.py"", line 200, in <module>
    tf.app.run()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 48, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""object_detection/train.py"", line 196, in main
    worker_job_name, is_chief, FLAGS.train_dir)
  File ""/home/chiuyu/code2/tensorflow/models/research/object_detection/trainer.py"", line 219, in train
    init_saver = tf.train.Saver(available_var_map)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1140, in __init__
    self.build()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1172, in build
    filename=self._filename)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 688, in build
    restore_sequentially, reshape)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 419, in _AddRestoreOps
    assign_ops.append(saveable.restore(tensors, shapes))
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 155, in restore
    self.op.get_shape().is_fully_defined())
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/state_ops.py"", line 274, in assign
    validate_shape=validate_shape)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_state_ops.py"", line 43, in assign
    use_locking=use_locking, name=name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py"", line 767, in apply_op
    op_def=op_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 2630, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 1204, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access

InvalidArgumentError (see above for traceback): Assign requires shapes of both tensors to match. lhs shape= [16] rhs shape= [8]
         [[Node: save/Assign_1 = Assign[T=DT_FLOAT, _class=[""loc:@FeatureExtractor/MobilenetV1/Conv2d_0/BatchNorm/gamma""], use_locking=true, validate_shape=true, _device=""/job:localhost/replica:0/task:0/cpu:0""](FeatureExtractor/MobilenetV1/Conv2d_0/BatchNorm/gamma, save/RestoreV2_1)]]

ERROR:tensorflow:==================================
Object was never used (type <class 'tensorflow.python.framework.ops.Tensor'>):
<tf.Tensor 'init_ops/report_uninitialized_variables/boolean_mask/Gather:0' shape=(?,) dtype=string>
If you want to mark it as used call its ""mark_used()"" method.
It was originally created here:
['File ""object_detection/train.py"", line 200, in <module>\n    tf.app.run()', 'File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 48, in run\n    _sys.exit(main(_sys.argv[:1] + flags_passthrough))', 'File ""object_detection/train.py"", line 196, in main\n    worker_job_name, is_chief, FLAGS.train_dir)', 'File ""/home/chiuyu/code2/tensorflow/models/research/object_detection/trainer.py"", line 296, in train\n    saver=saver)', 'File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/slim/python/slim/learning.py"", line 663, in train\n    ready_op = tf_variables.report_uninitialized_variables()', 'File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/util/tf_should_use.py"", line 175, in wrapped\n    return _add_should_use_warning(fn(*args, **kwargs))', 'File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/util/tf_should_use.py"", line 144, in _add_should_use_warning\n    wrapped = TFShouldUseWarningWrapper(x)', 'File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/util/tf_should_use.py"", line 101, in __init__\n    stack = [s.strip() for s in traceback.format_stack()]']
==================================
ERROR:tensorflow:==================================
Object was never used (type <class 'tensorflow.python.framework.ops.Tensor'>):
<tf.Tensor 'init_ops/report_uninitialized_variables/boolean_mask/Gather:0' shape=(?,) dtype=string>
If you want to mark it as used call its ""mark_used()"" method.
It was originally created here:
['File ""object_detection/train.py"", line 200, in <module>\n    tf.app.run()', 'File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 48, in run\n    _sys.exit(main(_sys.argv[:1] + flags_passthrough))', 'File ""object_detection/train.py"", line 196, in main\n    worker_job_name, is_chief, FLAGS.train_dir)', 'File ""/home/chiuyu/code2/tensorflow/models/research/object_detection/trainer.py"", line 296, in train\n    saver=saver)', 'File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/slim/python/slim/learning.py"", line 663, in train\n    ready_op = tf_variables.report_uninitialized_variables()', 'File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/util/tf_should_use.py"", line 175, in wrapped\n    return _add_should_use_warning(fn(*args, **kwargs))', 'File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/util/tf_should_use.py"", line 144, in _add_should_use_warning\n    wrapped = TFShouldUseWarningWrapper(x)', 'File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/util/tf_should_use.py"", line 101, in __init__\n    stack = [s.strip() for s in traceback.format_stack()]']
==================================








System information

What is the top-level directory of the model you are using: object_detection
Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04
TensorFlow installed from (source or binary): Source
TensorFlow version (use command below):
>>> tf.__version__
'1.3.0'

Bazel version (if compiling from source): 0.5.1
CUDA/cuDNN version:  CUDA 8.0, CUDNN 6.0
nvcc --version
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2016 NVIDIA Corporation
Built on Tue_Jan_10_13:22:03_CST_2017
Cuda compilation tools, release 8.0, V8.0.61

cat /usr/local/cuda/include/cudnn.h | grep CUDNN_MAJOR -A 2
#define CUDNN_MAJOR      6
#define CUDNN_MINOR      0
#define CUDNN_PATCHLEVEL 21
--



GPU model and memory: GeForce GTX 1080, with Total memory: 7.92GiB , Free memory: 7.81GiB
Exact command to reproduce: I am using the vanilla train.py command from the object detection README: 
python2 object_detection/train.py \
    --logtostderr \
    --train_dir='object_detection/data_mobile025/train' \
 --pipeline_config_path='object_detection/data_mobile025/ssd_mobilenet_v1_025.config'


",chihyuwang,b'stat:awaiting model gardener',2017-09-28T05:12:34Z,2020-02-07T18:43:12Z,,,,,,,
2470,"""File exists"" error in preprocess_imagenet_validation_data.py","### System information
- **What is the top-level directory of the model you are using**: research/inception
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 14.04
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**:1.3.0
- **Bazel version (if compiling from source)**:0.5.4
- **CUDA/cuDNN version**:7.5/6.0
- **GPU model and memory**:GeForce GTX TITAN X 12GB
- **Exact command to reproduce**:bazel-bin/inception/download_and_preprocess_imagenet ""${DATA_DIR}""

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
The imagenet download and preprocess script failed due to some bug in bazel file path parsing system. If I re-run the imagenet download and preprocess script, it throws an error saying-

>OSError: [Errno 17] File exists:

because some of the dataset was previously extracted.

Ideally the script should only try to create a directory if it does not exist.

### Source code / logs

> .
.
.
Processing: n15075141
Finished processing: n15075141
Organizing the validation data into sub-directories.
Traceback (most recent call last):
  File ""bazel-bin/inception/download_and_preprocess_imagenet.runfiles/inception/inception/data/preprocess_imagenet_validation_data.py"", line 72, in <module>
    os.makedirs(labeled_data_dir)
  File ""/usr/lib/python2.7/os.py"", line 157, in makedirs
    mkdir(name, mode)
OSError: [Errno 17] File exists: '<base_path>/imagenet-data/raw-data/validation/n03544143'

",pankajkgupta,None,2017-09-27T22:26:57Z,2017-10-12T04:40:47Z,,,,,,,
2462,Bug in models/official/resnet/cifar10_main.py when re-starting training,"In file models/official/resnet/cifar10_main.py, there is the running cycle defined as:

    for cycle in range(FLAGS.train_steps // FLAGS.steps_per_eval):

This cycle is not correct when training from an existing checkpoint but is only correct when training from scratch. I think the original intention for ""FLAGS.train_steps"" is the total number of training steps but not the steps needed for extra training; therefore, I believe that this is a bug.",ybsave,None,2017-09-26T18:17:06Z,2017-09-27T15:24:34Z,,,,,,,
2426,[attention_ocr] error on new dataset,"I want to train attention_ocr on new dataset, each example has 1 image, size of image is (800,600,3). The max_sequence_length is 18, size of charset is 37(10 digits + 26 uppercase + 1 null), config as follow:

```python
DEFAULT_CONFIG = {
    'name': 'trade',
    'splits': {
        'train': {
            'size': 5000,
            'pattern': 'train/train*'
        },
        'test': {
            'size': 234,
            'pattern': 'test/test*'
        }
    },
    'charset_filename': 'charset37.txt',
    'image_shape': (800, 600, 3),  # height, width, channel
    'num_of_views': 1,
    'max_sequence_length': 18,
    'null_code': 36,
    'items_to_descriptions': {
        'image': 'color image',
        'label': 'characters codes',
        'text': 'unicode string',
        'length': 'length of the encoded text',
        'num_of_view': '1'
    }
}
```

Code to generate tfrecord as follow:

```python
ext = 'RAW'

img = Image.open(img_path)
width, height = img.size
img = img.resize((600, 800))
img_raw = img.tobytes()

text = item.split('_')[0].upper()  # 01442000MA4WG2LJ4N_e5dcd8a67e6bf1a89a8ef794d6449f03.jpeg
ids_unpadded = [_map_rev[k] for k in text]
ids_padded = ids_unpadded + [nul] * (18 - len(ids_unpadded))

feature={
    'image/format': _bytes_feature([ext]),
    'image/encoded': _bytes_feature([img_raw]),
    'image/class': _int64_feature(ids_padded),
    'image/unpadded_class': _int64_feature(ids_unpadded),
    'height': _int64_feature([800]),
    'width': _int64_feature([600]),
    'orig_width': _int64_feature([600]),
    'image/text': _bytes_feature([text])
}
```

Command to train:
```
python train.py --dataset_name trade --dataset_dir /root/data/trade --use_augment_input false --train_log_dir /tmp/trade/train
```

Error log:

```
INFO 2017-09-21 18:12:57.000118: train.py: 167 Use already existing training directory /tmp/trade/train
INFO 2017-09-21 18:12:57.000118: fsns.py: 131 Using trade dataset split_name=train dataset_dir=/root/data/trade
DEBUG 2017-09-21 18:12:57.000301: model.py: 352 images: Tensor(""shuffle_batch:0"", shape=(32, 800, 600, 3), dtype=float32)
DEBUG 2017-09-21 18:12:57.000304: model.py: 357 Views=1 single view: Tensor(""AttentionOcr_v1/split:0"", shape=(32, 800, 600, 3), dtype=float32)
DEBUG 2017-09-21 18:12:57.000304: model.py: 200 Using final_endpoint=Mixed_5d
DEBUG 2017-09-21 18:12:58.000429: model.py: 364 Conv tower: Tensor(""AttentionOcr_v1/conv_tower_fn/INCE/InceptionV3/Mixed_5d/concat:0"", shape=(32, 97, 72, 288), dtype=float32)
DEBUG 2017-09-21 18:12:58.000429: model.py: 368 Conv tower w/ encoded coordinates: Tensor(""AttentionOcr_v1/conv_tower_fn/INCE/InceptionV3/Mixed_5d/concat:0"", shape=(32, 97, 72, 288), dtype=float32)
DEBUG 2017-09-21 18:12:58.000432: model.py: 372 Pooled views: Tensor(""AttentionOcr_v1/pool_views_fn/STCK/Reshape:0"", shape=(32, 6984, 288), dtype=float32)
DEBUG 2017-09-21 18:12:58.000433: sequence_layers.py: 421 Use AttentionWithAutoregression as a layer class
DEBUG 2017-09-21 18:12:59.000535: model.py: 375 chars_logit: Tensor(""AttentionOcr_v1/sequence_logit_fn/SQLR/concat:0"", shape=(32, 18, 37), dtype=float32)
WARNING:tensorflow:From /root/everhu/tensorflowapp/ocr/model.py:407: get_total_loss (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.
Instructions for updating:
Use tf.losses.get_total_loss instead.
WARNING 2017-09-21 18:12:59.000973: tf_logging.py: 90 From /root/everhu/tensorflowapp/ocr/model.py:407: get_total_loss (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.
Instructions for updating:
Use tf.losses.get_total_loss instead.
WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/losses/python/losses/loss_ops.py:261: get_losses (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.
Instructions for updating:
Use tf.losses.get_losses instead.
WARNING 2017-09-21 18:12:59.000974: tf_logging.py: 90 From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/losses/python/losses/loss_ops.py:261: get_losses (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.
Instructions for updating:
Use tf.losses.get_losses instead.
WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/losses/python/losses/loss_ops.py:263: get_regularization_losses (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.
Instructions for updating:
Use tf.losses.get_regularization_losses instead.
WARNING 2017-09-21 18:12:59.000974: tf_logging.py: 90 From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/losses/python/losses/loss_ops.py:263: get_regularization_losses (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.
Instructions for updating:
Use tf.losses.get_regularization_losses instead.
2017-09-21 18:13:11.757058: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2017-09-21 18:13:11.757121: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
INFO:tensorflow:Restoring parameters from /tmp/trade/train/model.ckpt-0
INFO 2017-09-21 18:13:11.000764: tf_logging.py: 82 Restoring parameters from /tmp/trade/train/model.ckpt-0
INFO:tensorflow:Starting Session.
INFO 2017-09-21 18:13:17.000928: tf_logging.py: 82 Starting Session.
INFO:tensorflow:Saving checkpoint to path /tmp/trade/train/model.ckpt
INFO 2017-09-21 18:13:18.000008: tf_logging.py: 82 Saving checkpoint to path /tmp/trade/train/model.ckpt
INFO:tensorflow:Starting Queues.
INFO 2017-09-21 18:13:18.000013: tf_logging.py: 82 Starting Queues.
INFO:tensorflow:global_step/sec: 0
INFO 2017-09-21 18:13:19.000014: tf_logging.py: 121 global_step/sec: 0
INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.InvalidArgumentError'>, Input to reshape is a tensor with 1920000 values, but the requested shape has 1440000
     [[Node: Reshape_6 = Reshape[T=DT_UINT8, Tshape=DT_INT32, _device=""/job:localhost/replica:0/task:0/cpu:0""](case/If_1/Merge, Reshape_6/shape)]]
INFO 2017-09-21 18:13:27.000583: tf_logging.py: 82 Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.InvalidArgumentError'>, Input to reshape is a tensor with 1920000 values, but the requested shape has 1440000
     [[Node: Reshape_6 = Reshape[T=DT_UINT8, Tshape=DT_INT32, _device=""/job:localhost/replica:0/task:0/cpu:0""](case/If_1/Merge, Reshape_6/shape)]]
terminate called after throwing an instance of 'std::bad_alloc'
  what():  std::bad_alloc
Aborted
```
",everhu,None,2017-09-21T10:23:38Z,2017-09-25T07:07:47Z,,,,,,,
2423,[Attention OCR] demo_inference needs the same image preprocess as train phase,"Found a bug maybe... I think the inference phase should pre-process the images first, as same as the training phase",buaaliyi,b'cla: yes',2017-09-21T03:36:21Z,2019-10-28T18:30:04Z,,,,,,,
2418,Bug in models/learning_to_remember_rare_events/,"
It seems like the per-shot accuracy calculation in `models/learning_to_remember_rare_events/train.py` is wrong: 
```correct_by_shot = dict((k, []) for k in xrange(self.episode_width + 1))```

Instead of `self.episode_width` , it should be something like `int(self.episode_length/self.episode_width*1.0)-1` since per shot means how many samples have been seen so far. 

The original code does not make sense when `episode_length` is 60 and `episode_width` is 10 in which case we should be seeing accuracies for 0-shot,1-shot,2-shot,3-shot,4-shot,5-shot. With the fix above, this seems to work fine. ",himani-arora,b'stat:awaiting model gardener type:bug',2017-09-19T18:39:47Z,2018-02-28T04:40:32Z,,,,,,,
2404,cifar10_estimator hangs under `gpu` variable_strategy locally with multigpu,"### System information

ubuntu 14.04, tf 1.3 (installed from `tensorflow-gpu` pip package). CUDA 8.0 + cuDNN 6. Two Titan X GPUs

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\

Under https://github.com/tensorflow/models/commit/dd9a81c03bf924db8d461a3e696ba1bd4bb193fc, 
the training hangs after the first evaluation step with the following command (unchanged from the Readme). I could verify it works when using CPU as PS or without `--sync` flag. Is there any other step needed in this mode?

```bash
python cifar10_main.py --data-dir=${PWD}/cifar-10-data --job-dir=./models/cifar10 --variable-strategy GPU  --num-gpus=2 --sync
```
Logs [here](https://gist.github.com/chenliu0831/40358bed6196134ca4a86c3d7b67c52e)
",chenliu0831,None,2017-09-17T20:32:03Z,2017-09-27T20:23:47Z,,,,,,,
2394,Help,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",NikaSerti,None,2017-09-14T22:55:23Z,2017-09-14T23:52:46Z,,,,,,,
2385,Have issue training the model from scratch.,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",25b3nk,None,2017-09-14T05:46:17Z,2017-09-14T17:38:55Z,,,,,,,
2383,models/slim/datasets/imagenet.py has strange _NUM_CLASS 1001,"
### System information
- **What is the top-level directory of the model you are using**: 
tensorflow/models/
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: 
No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: 
Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**:
binary
- **TensorFlow version (use command below)**:
1.3
- **Bazel version (if compiling from source)**:
no use
- **CUDA/cuDNN version**:
8.0/6.0
- **GPU model and memory**:
GTX 1080, 8GB
- **Exact command to reproduce**:
python3 eval_image_classifier.py \                                                                                                 
        --alsologtostderr \                                                                                                        
        --checkpoint_path=/path/to/inception_v3.ckpt \                                                                   
        --dataset_dir=/path/to/imagenet_dataset \                                                                                      
        --dataset_name=imagenet \                                                                                                  
        --dataset_split_name=validation \                                                                                          
        --model_name=inception_v3 \ 

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.
There is a strange figure assigned in codes of ""models/slim/datasets/imagenet.py"". It's weird we have 1001 as number of imagenet 2012 classes.

### Source code / logs

_NUM_CLASSES = 1001
",wonsekim,None,2017-09-14T04:44:20Z,2017-09-14T07:37:33Z,,,,,,,
2378,Error installing: AttributeError: module 'pandas' has no attribute 'computation',"### System information
- **What is the top-level directory of the model you are using**: models/object_detection
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Just following the installation instructions
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: binary (provided in AWS Deep Learning AMI)
- **TensorFlow version (use command below)**: v1.2.0-0-g12f033d 1.2.0
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**: `python object_detection/builders/model_builder_test.py`

### Describe the problem
There seems to be a bug in the installation process. I have followed the instructions [here](https://github.com/tensorflow/models/blob/master/object_detection/g3doc/installation.md).
With the final step I run:
```
python object_detection/builders/model_builder_test.py
```
And it fails with error message: AttributeError: module 'pandas' has no attribute 'computation'.

I am applying this to the standard AWS Deep Learning AMI which has anaconda installed. I've used `source src/anaconda3/bin/activate root` to activate the Python 3.5 environment then followed the install instructions.
Could there be missing dependencies that are not listed in the installation instructions?

### Source code / logs
Full error stack trace:

```
(root) ubuntu@ip-172-31-37-243:~/models$ python object_detection/builders/model_builder_test.py
Traceback (most recent call last):
  File ""object_detection/builders/model_builder_test.py"", line 21, in <module>
    from object_detection.builders import model_builder
  File ""/home/ubuntu/models/object_detection/builders/model_builder.py"", line 19, in <module>
    from object_detection.builders import box_predictor_builder
  File ""/home/ubuntu/models/object_detection/builders/box_predictor_builder.py"", line 18, in <module>
    from object_detection.core import box_predictor
  File ""/home/ubuntu/models/object_detection/core/box_predictor.py"", line 35, in <module>
    slim = tf.contrib.slim
  File ""/home/ubuntu/src/anaconda3/lib/python3.5/site-packages/tensorflow/python/util/lazy_loader.py"", line 53, in __getattr__
    module = self._load()
  File ""/home/ubuntu/src/anaconda3/lib/python3.5/site-packages/tensorflow/python/util/lazy_loader.py"", line 42, in _load
    module = importlib.import_module(self.__name__)
  File ""/home/ubuntu/src/anaconda3/lib/python3.5/importlib/__init__.py"", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""/home/ubuntu/src/anaconda3/lib/python3.5/site-packages/tensorflow/contrib/__init__.py"", line 31, in <module>
    from tensorflow.contrib import factorization
  File ""/home/ubuntu/src/anaconda3/lib/python3.5/site-packages/tensorflow/contrib/factorization/__init__.py"", line 24, in <module>
    from tensorflow.contrib.factorization.python.ops.gmm import *
  File ""/home/ubuntu/src/anaconda3/lib/python3.5/site-packages/tensorflow/contrib/factorization/python/ops/gmm.py"", line 27, in <module>
    from tensorflow.contrib.learn.python.learn.estimators import estimator
  File ""/home/ubuntu/src/anaconda3/lib/python3.5/site-packages/tensorflow/contrib/learn/__init__.py"", line 88, in <module>
    from tensorflow.contrib.learn.python.learn import *
  File ""/home/ubuntu/src/anaconda3/lib/python3.5/site-packages/tensorflow/contrib/learn/python/__init__.py"", line 23, in <module>
    from tensorflow.contrib.learn.python.learn import *
  File ""/home/ubuntu/src/anaconda3/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/__init__.py"", line 25, in <module>
    from tensorflow.contrib.learn.python.learn import estimators
  File ""/home/ubuntu/src/anaconda3/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/estimators/__init__.py"", line 297, in <module>
    from tensorflow.contrib.learn.python.learn.estimators.dnn import DNNClassifier
  File ""/home/ubuntu/src/anaconda3/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/estimators/dnn.py"", line 30, in <module>
    from tensorflow.contrib.learn.python.learn.estimators import dnn_linear_combined
  File ""/home/ubuntu/src/anaconda3/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/estimators/dnn_linear_combined.py"", line 31, in <module>
    from tensorflow.contrib.learn.python.learn.estimators import estimator
  File ""/home/ubuntu/src/anaconda3/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py"", line 49, in <module>
    from tensorflow.contrib.learn.python.learn.learn_io import data_feeder
  File ""/home/ubuntu/src/anaconda3/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/learn_io/__init__.py"", line 21, in <module>
    from tensorflow.contrib.learn.python.learn.learn_io.dask_io import extract_dask_data
  File ""/home/ubuntu/src/anaconda3/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/learn_io/dask_io.py"", line 26, in <module>
    import dask.dataframe as dd
  File ""/home/ubuntu/src/anaconda3/lib/python3.5/site-packages/dask/dataframe/__init__.py"", line 3, in <module>
    from .core import (DataFrame, Series, Index, _Frame, map_partitions,
  File ""/home/ubuntu/src/anaconda3/lib/python3.5/site-packages/dask/dataframe/core.py"", line 36, in <module>
    pd.computation.expressions.set_use_numexpr(False)
AttributeError: module 'pandas' has no attribute 'computation'
```",js1972,b'stat:awaiting response',2017-09-13T08:31:57Z,2017-09-15T00:26:13Z,,,,,,,
2374,Frozen pretrained Faster RCNN/RFCN networks from model zoo yielding different outputs on different GPUs and runs,"### System information
- **What is the top-level directory of the model you are using**:
Using unmodified pretrained coco models: faster_rcnn_inception_resnet_v2_atrous_coco_11_06_2017, faster_rcnn_resnet101_coco_11_06_2017, rfcn_resnet101_coco_11_06_2017

- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
No

- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
UPDATE: tested on two machines now, both reproduce it:
Machine 1: Linux Ubuntu 14.04.4 LTS
Machine 2: Linux Ubuntu 16.04.2 LTS

- **TensorFlow installed from (source or binary)**:
official docker container, with last commit 58fb6d7e257f28cd7934316d6ae7a81ec42a533a
docker version from 2017-08-24T02:37:57.51182742Z

- **TensorFlow version (use command below)**:
('v1.2.0-5-g435cdfc', '1.2.1')

- **Bazel version (if compiling from source)**:
N/A

- **CUDA/cuDNN version**:
From official docker: CUDA 8., cuDNN 5.1.10

- **GPU model and memory**:
Machine 1: Three nVIDIA GeForce GTX 1080, 12 GB
Machine 2: Two nVIDIA GeForce GTX 1080, 12 GB

- **Exact command to reproduce**:
Running object_detection_tutorial.ipynb with different GPUs, either with export CUDA_VISIBLE_DEVICES=, or by setting it in the session config.  Version that runs through 3 GPUs several times and compares output is included.

### Describe the problem
Running on different GPUs yields different results, and GPUs 1 and 2 are not deterministic.  This is accomplished by making devices 1,2 invisible, and tensorflow runs on 0, and so forth.  This is using frozen pretrained networks from this repository's linked [model zoo](https://github.com/tensorflow/models/blob/master/object_detection/g3doc/detection_model_zoo.md) and the supplied object_detection_tutorial.ipynb with no modifications other than setting the cuda visible_device_list.  The SSD frozen models, however, give identical outputs on the 3 GPUs from what I have seen.

I have also run [cuda_memtest](https://sourceforge.net/projects/cudagpumemtest/) on all 3 GPUs, logs attached

UPDATE: I just tested on a second machine with 2 GPUs, and reproduced the issue.  GPU 0 is deterministic, GPU 1 is not (and often produces bad results).

### Source code / logs
I've attached the diff of the modified object_detection_tutorial.ipynb which loops over 3 GPUs 3 times and prints out the top box scores, which change depending on the run.  Also attached is a PDF of that ipynb with detections drawn on it.  Text output:

> Evaluating image 0
> 
> 	Running on GPU 0
> 		Top 4 box scores: 
> 		Iter 1: [ 0.99978215  0.99857557  0.95300484  0.91580492]
> 		Iter 2: [ 0.99978215  0.99857557  0.95300484  0.91580492]
> 		Iter 3: [ 0.99978215  0.99857557  0.95300484  0.91580492]
> 
> 	Running on GPU 1
> 		Top 4 box scores: 
> 		Iter 1: [ 0.68702352  0.16781448  0.13143283  0.12993629]
> 		Iter 2: [ 0.18502565  0.16854601  0.08074528  0.07859289]
> 		Iter 3: [ 0.18502565  0.16854601  0.05546702  0.05111229]
> 
> 	Running on GPU 2
> 		Top 4 box scores: 
> 		Iter 1: [ 0.68702352  0.16781448  0.13143283  0.12993629]
> 		Iter 2: [ 0.18941374  0.18502565  0.16854601  0.16230994]
> 		Iter 3: [ 0.18502565  0.16854601  0.05546702  0.05482833]
> 
> 
> Evaluating image 1
> 
> 	Running on GPU 0
> 		Top 4 box scores: 
> 		Iter 1: [ 0.99755412  0.99750346  0.99380219  0.99067008]
> 		Iter 2: [ 0.99755412  0.99750346  0.99380219  0.99067008]
> 		Iter 3: [ 0.99755412  0.99750346  0.99380219  0.99067008]
> 
> 	Running on GPU 1
> 		Top 4 box scores: 
> 		Iter 1: [ 0.96881998  0.96441168  0.96164131  0.96006596]
> 		Iter 2: [ 0.9377929   0.91686022  0.80374646  0.79758978]
> 		Iter 3: [ 0.90396696  0.89217037  0.85456908  0.85334581]
> 
> 	Running on GPU 2
> 		Top 4 box scores: 
> 		Iter 1: [ 0.9377929   0.91686022  0.80374646  0.79758978]
> 		Iter 2: [ 0.9377929   0.91686022  0.80374646  0.79758978]
> 		Iter 3: [ 0.9377929   0.91686022  0.80374646  0.79758978]

[object_detection_tutorial.diff.txt](https://github.com/tensorflow/models/files/1313430/object_detection_tutorial.diff.txt)

[gpu_output_differences.pdf](https://github.com/tensorflow/models/files/1313428/gpu_output_differences.pdf)

Updated with longer run:
[cuda_memtest.log.txt](https://github.com/tensorflow/models/files/1315285/cuda_memtest.log.txt)


",EpochalEngineer,b'type:bug',2017-09-13T01:39:20Z,2020-02-07T18:42:43Z,,,,,,,
2372,A bug in object detection?,"In [argmax_matcher.py](https://github.com/tensorflow/models/blob/master/object_detection/matchers/argmax_matcher.py#L158), the algorithm of `_force_match_for_each_row` is wrong?

It seems that use the maximum of row to force_match_for_each_row, but many rows can have  maximum  with the same column.

For example,  to use similarity
```
similarity = np.array([[0,1,2],
                        [1,2,3],
                        [2,3,4]], dtype=np.int32)
```
instead of similarity in [test_return_correct_matches_unmatched_row_while_using_force_match](https://github.com/tensorflow/models/blob/master/object_detection/matchers/argmax_matcher_test.py#L167). You will get matched_rows with length of 2.

Another question is [assertEmpty](https://github.com/tensorflow/models/blob/master/object_detection/matchers/argmax_matcher_test.py#L47), it will raise a error, because I can't find it is a member function of `tf.test.TestCase`.

",gauss-clb,b'stat:awaiting model gardener type:bug',2017-09-12T11:40:00Z,2020-02-07T18:42:43Z,,,,,,,
2357," python train.py --checkpoint=model.ckpt-399731 Traceback (most recent call last):   File ""train.py"", line 30, in <module>     import common_flags   File ""E:\Workplace\tensorflow\result\models-master\attention_ocr\python\common_flags.py"", line 22, in <module>     import datasets   File ""E:\Workplace\tensorflow\result\models-master\attention_ocr\python\datasets\__init__.py"", line 16, in <module>     import fsns ImportError: No module named 'fsns'","Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",fistix,None,2017-09-08T08:19:29Z,2017-09-11T18:42:57Z,,,,,,,
2348,Training goes back ~200k steps during training using faster_rcnn model,"### System information
- **What is the top-level directory of the model you are using**: object_detection/models
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux #87-Ubuntu SMP Fri Mar 3 15:29:05 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux 
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: ('v1.2.0-rc0-24-g94484aa', '1.2.0-rc1')
- **Bazel version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: 8.0
- **GPU model and memory**: Tesla K80, 11439MiB
- **Exact command to reproduce**: python train.py --pipeline_config_path=object_detection/faster_rcnn_resnet101_points.config --train_dir=object_detection/train
You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
I am training using the `faster_rcnn_resnet101_points.config` and noticed that after 350k steps, it goes back about 200k steps with noticeably worse performance. Please see ![tensorboard_steps_reverse](https://user-images.githubusercontent.com/1262052/30117798-4a553254-92ef-11e7-98f9-0c0ea4c8fb5a.PNG). 
Is this a known bug in this model?

### Source code / logs
I am using the stock example script and model provided.",cmyee,None,2017-09-06T14:43:12Z,2017-09-14T23:51:00Z,,,,,,,
2345,Run Cifar10_train in debug mode (Higher Level APIs),"I am trying to run the [Cifar10_train.py code](https://github.com/tensorflow/models/blob/master/tutorials/image/cifar10/cifar10_train.py) in debug mode but I am getting errors and I don't know how to get around them.

Here are the changes I made:

In Cifar10_train.py, I added:
from tensorflow.python import debug as tf_debug

also made the following changes in defining the train() function:

.
.
.

with tf.train.MonitoredTrainingSession(checkpoint_dir=FLAGS.train_dir, hooks=[tf.train.StopAtStepHook(last_step=FLAGS.max_steps),tf.train.NanTensorHook(loss),_LoggerHook()],
				config=tf.ConfigProto(log_device_placement=FLAGS.log_device_placement)) as mon_sess:
			while not mon_sess.should_stop():
				**mon_sess = tf_debug.LocalCLIDebugWrapperSession(mon_sess)
				mon_sess.add_tensor_filter(""has_inf_or_nan"", tf_debug.has_inf_or_nan)**
				mon_sess.run(train_op)

But I am getting the error:

TypeError: Expected type <class 'tensorflow.python.client.session.BaseSession'>; got type <class 'tensorflow.python.training.monitored_session.MonitoredSession'>

Could someone please help, how to run this types of code in debug mode?
Thanks",aziabari,None,2017-09-06T03:35:17Z,2018-10-08T00:42:55Z,,,,,,,
2331,maybe a bug in models/slim/deployment/model_deploy.py,"def _sum_clones_gradients(clone_grads):
  """"""Calculate the sum gradient for each shared variable across all clones.
  This function assumes that the clone_grads has been scaled appropriately by
  1 / num_clones.

howerver,  in ""def _optimize_clone(optimizer, clone, num_clones, regularization_losses, **kwargs):""
there is :
if sum_loss is not None:
    with tf.device(clone.device):
      clone_grad = optimizer.compute_gradients(sum_loss, **kwargs)

i think ' clone_grad ' is not scaled appropriately by 1 / num_clones.

",bjmajic,None,2017-09-04T03:14:14Z,2020-02-07T18:42:42Z,,,,,,,
2328,tfdbg on slim not compatible with Object Detection API,"### System information
- **What is the top-level directory of the model you are using**: 
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Linux Ubuntu 14.04
- **TensorFlow installed from (source or binary)**: Source
- **TensorFlow version (use command below)**: r1.3 with latest checkout of tensorflow/tensorflow/contrib/slim/python/slim/learning.py
- **Bazel version (if compiling from source)**: 0.5.2
- **CUDA/cuDNN version**: 8.0, 5.1
- **GPU model and memory**: 1080 Ti 12GB
- **Exact command to reproduce**:

### Describe the problem
I want to debug a NaN error with tfdbg on the Object Detection API rfcn network. I checkout latest version of 'tensorflow/tensorflow/contrib/slim/python/slim/learning.py' to include the tfdbg support. After hitting 'run' twice in tfdbg, I encountered the following error. This can be reproduced with the pets example by adding 'session_wrapper=tf_debug.LocalCLIDebugWrapperSession' to the 'slim.learning.train' in 'models/object_detection/trainer.py'. 

### Source code / logs
2017-09-03 13:04:11.473343: I tensorflow/core/debug/debug_graph_utils.cc:229] For debugging, tfdbg is changing the parallel_iterations attribute of the Enter/RefEnter node ""gradients/map/while/TensorArrayReadV3/Enter_1_grad/b_acc_1"" on device ""/job:localhost/replica:0/task:0/gpu:0"" from 16 to 1. (This does not affect subsequent non-debug runs.)
INFO:tensorflow:Error reported to Coordinator: <type 'exceptions.ValueError'>, Node name 'parallel_read/filenames/Assert/Assert/data_0' is not found in partition graphs of device /job:localhost/replica:0/task:0/cpu:0.
Traceback (most recent call last):
  File ""object_detection/train.py"", line 202, in <module>
    tf.app.run()
  File ""/local/mnt/workspace/chris/anaconda2/lib/python2.7/site-packages/tensorflow/python/platform/app.py"", line 48, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""object_detection/train.py"", line 198, in main
    worker_job_name, is_chief, FLAGS.train_dir)
  File ""/local/mnt/workspace/chris/projects/models/object_detection/trainer.py"", line 310, in train
    session_wrapper=tf_debug.LocalCLIDebugWrapperSession)
  File ""/local/mnt/workspace/chris/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/slim/python/slim/learning.py"", line 777, in train
    sv.stop(threads, close_summary_writer=True)
  File ""/local/mnt/workspace/chris/anaconda2/lib/python2.7/contextlib.py"", line 35, in __exit__
    self.gen.throw(type, value, traceback)
  File ""/local/mnt/workspace/chris/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/supervisor.py"", line 964, in managed_session
    self.stop(close_summary_writer=close_summary_writer)
  File ""/local/mnt/workspace/chris/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/supervisor.py"", line 792, in stop
    stop_grace_period_secs=self._stop_grace_secs)
  File ""/local/mnt/workspace/chris/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/coordinator.py"", line 389, in join
    six.reraise(*self._exc_info_to_raise)
  File ""/local/mnt/workspace/chris/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/queue_runner_impl.py"", line 238, in _run
    enqueue_callable()
  File ""/local/mnt/workspace/chris/anaconda2/lib/python2.7/site-packages/tensorflow/python/debug/wrappers/framework.py"", line 570, in wrapped_runner
    callable_runner_args=runner_args)
  File ""/local/mnt/workspace/chris/anaconda2/lib/python2.7/site-packages/tensorflow/python/debug/wrappers/framework.py"", line 532, in run
    run_end_resp = self.on_run_end(run_end_req)
  File ""/local/mnt/workspace/chris/anaconda2/lib/python2.7/site-packages/tensorflow/python/debug/wrappers/local_cli_wrapper.py"", line 319, in on_run_end
    self._dump_root, partition_graphs=partition_graphs)
  File ""/local/mnt/workspace/chris/anaconda2/lib/python2.7/site-packages/tensorflow/python/debug/lib/debug_data.py"", line 690, in __init__
    self._load_all_device_dumps(partition_graphs, validate)
  File ""/local/mnt/workspace/chris/anaconda2/lib/python2.7/site-packages/tensorflow/python/debug/lib/debug_data.py"", line 712, in _load_all_device_dumps
    self._load_partition_graphs(partition_graphs, validate)
  File ""/local/mnt/workspace/chris/anaconda2/lib/python2.7/site-packages/tensorflow/python/debug/lib/debug_data.py"", line 1009, in _load_partition_graphs
    self._validate_dump_with_graphs(device_name)
  File ""/local/mnt/workspace/chris/anaconda2/lib/python2.7/site-packages/tensorflow/python/debug/lib/debug_data.py"", line 1208, in _validate_dump_with_graphs
    ""device %s."" % (datum.node_name, device_name))
ValueError: Node name 'parallel_read/filenames/Assert/Assert/data_0' is not found in partition graphs of device /job:localhost/replica:0/task:0/cpu:0.

",bwuzhang,b'stat:awaiting model gardener',2017-09-03T17:05:46Z,2020-02-04T16:25:05Z,,,,,,,
2324,ar,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",ghost,None,2017-09-01T14:44:19Z,2017-09-01T18:36:01Z,,,,,,,
2316,Can I get the offical train-finished model of im2txt model for a test？,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",dmxj,None,2017-08-31T07:58:13Z,2017-09-01T18:33:06Z,,,,,,,
2299,BUG: Fix inception imagenet download script,"In [`download_imagenet.sh`](inception/inception/data/download_imagenet.sh), the path to the `$SYNSETS_FILE` resource (`imagenet_2012_validation_synset_labels.txt`) was not working due to a `cd` earlier in the script.

This is fixed by prepending the initial directory path to the path to the resource file (`$SYNSETS_FILE`) when we try to access it.

Fixes #682.",scottclowe,b'cla: yes',2017-08-28T12:17:10Z,2018-03-03T18:45:13Z,,,,,,,
2277,ImportError: cannot import name 'label_map_util',"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.


ImportError: cannot import name 'label_map_util'
",mthd98,b'stat:awaiting response',2017-08-23T21:55:11Z,2018-09-29T04:08:57Z,,,,,,,
2259,bugfix for rnn tutorial on Python3,"`str` object doesn't have `decode` method and so `tutorials/rnn/ptb/reader.py` doesn't work on Python3.

Actually we don't have to call `decode` method even if we use Python2 because the data used in the tutorial only include ascii characters.
I wrote the code which have `if` condition for `Py3` to apply this code to some texts include non-ascii characters.",skwbc,b'cla: yes',2017-08-19T12:35:17Z,2017-09-09T02:27:46Z,,,,,,,
2255,Huge RAM usage with LFADS model,"We observed that when we tried to run LFADS on continuous data (hence using gaussian cost function of LFADS) with 300 trials where the data dimensionality was 40 and the length of each trial was 900 time samples ( 300x40x900 matrix), LFADS takes a huge amount of RAM (CPU RAM) about 30+GB.
The RAM usage gradually ramps up to 30+GB, and most of the RAM growth occurs during the initial part of the training (or even before the training starts) and it becomes steady after that. The GPU RAM usage would be around 1GB.

We also observed that the length of the trials (time samples - in our case 900) is the critical variable that sets the RAM usage, the number of trials and data dimensionality do not lead to this huge memory usage. If we decrease the time samples for e.g. to 300, the RAM usage significantly decreases (to e.g. 2-4GB range). 

We are using LFADS model:
https://github.com/tensorflow/models/tree/master/lfads
Tensorflow ver: 1.2
Cuda Ver: 8.0
OS: Linux CentOS

This issue limits us from being able to use LFADS on data with a hundreds of time sample long due to this memory issue. 
",mrezak,b'stat:awaiting model gardener type:bug',2017-08-19T05:19:38Z,2020-02-07T18:42:41Z,,,,,,,
2251,Bugfix for missing function rotator_metrics in models/ptn,"This PR fixes the known bug when evaluating the rotator model in models/ptn. #2240 

Please check this out @arkanath @mees ",xcyan,b'cla: yes',2017-08-18T10:31:21Z,2017-08-18T18:06:53Z,,,,,,,
2243,Cost calculation in Variational Autoencoder model is wrong,"### System information
- **What is the top-level directory of the model you are using**: autoencoder
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: no
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 14.04
- **TensorFlow installed from (source or binary)**: not relevant
- **TensorFlow version (use command below)**: not relevant
- **Bazel version (if compiling from source)**:not relevant
- **CUDA/cuDNN version**: not relevant
- **GPU model and memory**: not relevant
- **Exact command to reproduce**: not relevant

### Describe the problem
The [reconstruction error](https://github.com/tensorflow/models/blob/master/autoencoder/autoencoder_models/VariationalAutoencoder.py#L24) in variational autoencoder is calculated without specifying the ""axis"" argument, resulting in calculating the sum of reconstruction error across the whole batch. However, the [latent error](https://github.com/tensorflow/models/blob/master/autoencoder/autoencoder_models/VariationalAutoencoder.py#L25) is calculated with axis=1, resulting in a 1D vector representing the latent error for each sample in the batch. When we add them up and take the average to get the [cost](https://github.com/tensorflow/models/blob/master/autoencoder/autoencoder_models/VariationalAutoencoder.py#L26), the 0-d reconstruction error will get broadcast to each element of the latent error, resulting in a larger cost than it should be. The right way should be either mean + mean, or mean(vector + vector).

### Source code / logs
N/A
",haoyangz,b'help wanted type:bug',2017-08-17T23:37:57Z,2020-02-07T18:42:40Z,,,,,,,
2241,[Slim] Scripts for Training ResNet From Scratch,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 14.04
- **TensorFlow installed from (source or binary)**: Source
- **TensorFlow version (use command below)**: 1.0.0
- **CUDA/cuDNN version**: 8.0
- **GPU model and memory**: 6xK80 
- **Exact command to reproduce**: See below

### Describe the problem
Although it is stated in the slim model that train_image_classifier.py can be used to train models from scratch, I found it really hard in practice without any working example. In my case, I am trying to train ResNet from scratch on a local machine with 6xK80s. After spending much time figuring out the difference between replica and clone arguments and how effective batch size is computed, I came up with this script:
```
DATASET_DIR=/nv/hmart1/ashaban6/scratch/data/imagenet_RF_record
TRAIN_DIR=/nv/hmart1/ashaban6/scratch/train_dir
DEPTH=50
NUM_CLONES=8

CUDA_VISIBLE_DEVICES=""0,1,2,3,4,5,6,7,8"" python train_image_classifier.py --train_dir=${TRAIN_DIR} --dataset_name=imagenet --model_name=resnet_v1_${DEPTH} --max_number_of_steps=100000000 --batch_size=32 --learning_rate=0.1 --learning_rate_decay_type=exponential --dataset_split_name=train --dataset_dir=${DATASET_DIR} --optimizer=momentum --momentum=0.9 --learning_rate_decay_factor=0.1 --num_epochs_per_decay=30 --weight_decay=0.0001 --num_readers=12 --num_clones=$NUM_CLONES
``` 
I followed the same settings as is suggested in the paper. I am using 8 GPUs on a local machine with batch_size 32 so the effective batch size is 32x8=256. Learning rate is initially set to 0.1 and will be decayed by 10 every 30 epochs. After 70K steps (70000x256/1.2e6 ~ 15 epochs), the top-1 performance on the validation set is as low as ~14% while it should be around 50% after that many iterations. I used this command to get the top-1 performance:
```
DATASET_DIR=/nv/hmart1/ashaban6/scratch/data/imagenet_RF_record
CHECKPOINT_FILE=/nv/hmart1/ashaban6/scratch/train_dir/
DEPTH=50

CUDA_VISIBLE_DEVICES=""10"" python eval_image_classifier.py --alsologtostderr --checkpoint_path=${CHECKPOINT_FILE} --dataset_dir=${DATASET_DIR} --dataset_name=imagenet --dataset_split_name=validation --model_name=resnet_v1_${DEPTH}
```
With the lack of working examples it is hard to say if there is a bug in the slim training code or a problem in my script. Providing a working script would be really helpful.


",haamoon,None,2017-08-17T19:54:27Z,2020-02-07T18:42:40Z,,,,,,,
2227,ImportError: cannot import name 'label_map_util',"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",ahelou2,None,2017-08-16T20:43:03Z,2017-08-16T21:42:27Z,,,,,,,
2218,"Fixes bug #2140, that prevents running the perspective transformer net","Fixes bug #2140. Adds bazel workspace file to enable running perspective transformer networks.

",mees,b'cla: yes',2017-08-15T14:17:36Z,2017-08-18T03:12:09Z,,,,,,,
2214,Object Detection API anchorwise_output config,"'anchorwise_output' config in example configs is true, I don't know why. When I try to change 'true' to 'false', the program throws error:
```
Traceback (most recent call last):
  File ""../libs/object_detection/train.py"", line 202, in <module>
    tf.app.run()
  File ""py3-tensorflow/lib/python3.4/site-packages/tensorflow/python/platform/app.py"", line 48, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""libs/object_detection/train.py"", line 198, in main
    worker_job_name, is_chief, FLAGS.train_dir)
  File ""detection-workspace/libs/object_detection/trainer.py"", line 192, in train
    clones = model_deploy.create_clones(deploy_config, model_fn, [input_queue])
  File ""detection-workspace/libs/slim/deployment/model_deploy.py"", line 193, in create_clones
    outputs = model_fn(*args, **kwargs)
  File ""detection-workspace/libs/object_detection/trainer.py"", line 133, in _create_losses
    losses_dict = detection_model.loss(prediction_dict)
  File ""detection-workspace/libs/object_detection/meta_architectures/ssd_meta_arch.py"", line 428, in loss
    location_losses, cls_losses, prediction_dict, match_list)
  File ""detection-workspace/libs/object_detection/meta_architectures/ssd_meta_arch.py"", line 563, in _apply_hard_mining
    match_list=match_list)
  File ""libs/object_detection/core/losses.py"", line 529, in __call__
    location_losses = tf.unstack(location_losses)
  File ""py3-tensorflow/lib/python3.4/site-packages/tensorflow/python/ops/array_ops.py"", line 971, in unstack
    (axis, -value_shape.ndims, value_shape.ndims))
ValueError: axis = 0 not in [0, 0)
```
It seems a bug and not been tested.",irmowan,b'stat:awaiting model gardener',2017-08-15T05:48:09Z,2018-11-03T00:28:41Z,,,,,,,
2209,I have annotated some sentences of bangla  using universal dependency rules now how can i create model using   Parsey McParseface parser,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",shaficse,None,2017-08-14T13:21:02Z,2017-08-14T21:39:29Z,,,,,,,
2206,Is it a bug of inception?,"Fellow me,  inception_train wants to use multi-gpu to train,  gpu should reuse the variables defined on cpu.
Look the [code](https://github.com/tensorflow/models/blob/master/inception/inception/inception_train.py#L244). But I find the gpu don't reuse  the variables defined on cpu. Step into `_tower_loss`,  there is [outer variable scope](https://github.com/tensorflow/models/blob/master/inception/inception/inception_train.py#L106), step into `inception.inference` and reach at [line 81](https://github.com/tensorflow/models/blob/master/inception/inception/inception_model.py#L81), step into `slim.inception.inception_v3` and you will find [name_scope](https://github.com/tensorflow/models/blob/master/inception/inception/slim/inception_model.py#L80) of '',  see line 86 and step into `ops.conv2d`, you will find [inner variable scope](https://github.com/tensorflow/models/blob/master/inception/inception/slim/ops.py#L213) and the variable is defined here, but you can see the reuse is None default and  the [line 86](https://github.com/tensorflow/models/blob/master/inception/inception/slim/inception_model.py#L86) of `slim.inception.inception_v3`  don't pass the reuse into `ops.conv2d`, which means reuse=None, and all of gpu don't reuse variable on cpu,  but define a new version for themselves. 

Do you agree with me?  Is it a bug?",gauss-clb,None,2017-08-14T07:43:43Z,2017-08-14T08:03:47Z,,,,,,,
2198,"Fixes broken visualization in Perspective Transformer Nets, #2197","Fixes broken visualization in Perspective Transformer Nets, bug #2197.",mees,b'cla: yes',2017-08-11T13:02:13Z,2017-09-07T04:49:51Z,,,,,,,
2175,"cannot find ""tf.contrib.training.HParams"" when using ""pixel_domain_adaptation""","Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",cassiePython,None,2017-08-10T02:48:28Z,2017-08-14T21:21:16Z,,,,,,,
2169,Computation of quantized graph is slower than unquantized graph [Galaxy S8],"The performance result of the benchmark tool on S8 and also S7 shows that quantized computation is much slower than unquantized 32float computation! I saw previous issues on this but those are regarding mainly on intel CPU platform and I know that gemmlowp is not optimized for x86 CPU. Though gemmlowp is highly optimized for ARM NEON SIMD, it still lacks performance compared to 32float!

Platform: S8, compiled from source for arm64-v8a, Tensorflow  v1.0.1
Inception-v3 (optimized for inference, 32float) has 1.17x higher performance than Inception-v3 (optimized for inference & quantized, 8bit)

Inception-v1 (optimized for inference, 32float) has 3.65x higher performance than Inception-v1 (optimized for inference & quantized, 8bit)




",atrah22,b'type:bug',2017-08-09T08:30:16Z,2018-08-01T20:07:48Z,,,,,,,
2159,"fixes bug #2157, loads the pretrained encoder to finetune the decoder", bug #2157 didn't load the pretrained decoder when training  the volumetric decoder. This patch loads the latest checkpoint model from the given folder.,mees,b'cla: yes',2017-08-08T13:27:02Z,2019-10-28T18:29:27Z,,,,,,,
2158,Fixes#2157,"Fixes bug #2157, where the pretrained encoder model isn't loaded to train the decoder. ",mees,b'cla: yes',2017-08-08T13:19:20Z,2017-08-08T13:20:48Z,,,,,,,
2156,"Fixes bug  #2140, that prevents running the perspective transformer net",Fixes issue #2140.,mees,b'cla: yes',2017-08-08T10:08:01Z,2017-08-09T14:13:28Z,,,,,,,
2155,Fixing some bugs and adding ptn directory info in root README,,arkanath,b'cla: yes',2017-08-08T10:00:34Z,2019-10-28T18:29:27Z,,,,,,,
2150,imagenet_distributed_train using inception v3 stuck on saving check points forever.,"### System information
```bash
== cat /etc/issue ===============================================
Linux ip-172-30-4-87 3.10.0-514.16.1.el7.x86_64 #1 SMP Wed Apr 12 15:04:24 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux
VERSION=""7 (Core)""
VERSION_ID=""7""
CENTOS_MANTISBT_PROJECT_VERSION=""7""
REDHAT_SUPPORT_PRODUCT_VERSION=""7""

== are we in docker =============================================
No

== compiler =====================================================
c++ (GCC) 4.8.5 20150623 (Red Hat 4.8.5-11)
Copyright (C) 2015 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.


== uname -a =====================================================
Linux ip-172-30-4-87 3.10.0-514.16.1.el7.x86_64 #1 SMP Wed Apr 12 15:04:24 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux

== check pips ===================================================
numpy (1.13.0)
protobuf (3.3.0)
tensorflow-gpu (1.2.0)

== check for virtualenv =========================================
False

== tensorflow import ============================================
tf.VERSION = 1.2.0
tf.GIT_VERSION = v1.2.0-rc2-21-g12f033d
tf.COMPILER_VERSION = v1.2.0-rc2-21-g12f033d
Sanity check: array([1], dtype=int32)

== env ==========================================================
LD_LIBRARY_PATH is unset
DYLD_LIBRARY_PATH is unset

== nvidia-smi ===================================================
Mon Aug  7 21:00:40 2017
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 375.51                 Driver Version: 375.51                    |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  Tesla K80           On   | 0000:00:1E.0     Off |                    0 |
| N/A   51C    P0    72W / 149W |  10944MiB / 11439MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+

+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID  Type  Process name                               Usage      |
|=============================================================================|
|    0      2886    C   /bin/python                                  10938MiB |
+-----------------------------------------------------------------------------+

== cuda libs  ===================================================
/usr/local/cuda-8.0/doc/man/man7/libcudart.7
/usr/local/cuda-8.0/doc/man/man7/libcudart.so.7
/usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudart.so.8.0.61
/usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudart_static.a
```

I am running the imagenet_distributed_train.py of inception: https://github.com/tensorflow/models/tree/master/inception, with 16 AWS p2x2 machines. I didn't change any code of inception and follow the guidance to run imagenet_distributed_train using parallel-ssh.

The script I use to run parallel-ssh:
```python
from pssh.pssh_client import ParallelSSHClient
import datetime
from pprint import pprint
from pssh.utils import load_private_key

output_ps = []
output_worker = []
some host ip here
ps = [host1,host2,host3]
worker = [host0,host1,host2,host3,host4,host5,host6,host7,host8,host9,host10,host11,host12,host13,host14,host15]
client_ps = ParallelSSHClient(ps, user='centos')
client_worker = ParallelSSHClient(worker, user='centos')

output_ps = client_ps.run_command('%s', host_args=(
    ('/imagenet/run_ps.sh --job_name ps --task_id 0 --batch_size 32 --num_ps 3 --num_workers 16 --ps_hosts ******* --worker_hosts *******'),
    ('/imagenet/run_ps.sh --job_name ps --task_id 1 --batch_size 32 --num_ps 3 --num_workers 16 --ps_hosts ******* --worker_hosts *******'),
    ('/imagenet/run_ps.sh --job_name ps --task_id 2 --batch_size 32 --num_ps 3 --num_workers 16 --ps_hosts ******* --worker_hosts *******'),
    ))

output_worker = client_worker.run_command( '%s', host_args=(
    ('/imagenet/run_worker.sh --job_name worker --task_id 0 --batch_size 32 --num_ps 3 --num_workers 16 --ps_hosts ******* --worker_hosts *******'),
    ('/imagenet/run_worker.sh --job_name worker --task_id 1 --batch_size 32 --num_ps 3 --num_workers 16 --ps_hosts ******* --worker_hosts *******'),
    ('/imagenet/run_worker.sh --job_name worker --task_id 2 --batch_size 32 --num_ps 3 --num_workers 16 --ps_hosts ******* --worker_hosts *******'),
    ('/imagenet/run_worker.sh --job_name worker --task_id 3 --batch_size 32 --num_ps 3 --num_workers 16 --ps_hosts ******* --worker_hosts *******'),
    ('/imagenet/run_worker.sh --job_name worker --task_id 4 --batch_size 32 --num_ps 3 --num_workers 16 --ps_hosts ******* --worker_hosts *******'),
    ('/imagenet/run_worker.sh --job_name worker --task_id 5 --batch_size 32 --num_ps 3 --num_workers 16 --ps_hosts ******* --worker_hosts *******'),
    ('/imagenet/run_worker.sh --job_name worker --task_id 6 --batch_size 32 --num_ps 3 --num_workers 16 --ps_hosts ******* --worker_hosts *******'),
    ('/imagenet/run_worker.sh --job_name worker --task_id 7 --batch_size 32 --num_ps 3 --num_workers 16 --ps_hosts ******* --worker_hosts *******'),
    ('/imagenet/run_worker.sh --job_name worker --task_id 8 --batch_size 32 --num_ps 3 --num_workers 16 --ps_hosts ******* --worker_hosts *******'),
    ('/imagenet/run_worker.sh --job_name worker --task_id 9 --batch_size 32 --num_ps 3 --num_workers 16 --ps_hosts ******* --worker_hosts *******'),
    ('/imagenet/run_worker.sh --job_name worker --task_id 10 --batch_size 32 --num_ps 3 --num_workers 16 --ps_hosts ******* --worker_hosts *******'),
    ('/imagenet/run_worker.sh --job_name worker --task_id 11 --batch_size 32 --num_ps 3 --num_workers 16 --ps_hosts ******* --worker_hosts *******'),
    ('/imagenet/run_worker.sh --job_name worker --task_id 12 --batch_size 32 --num_ps 3 --num_workers 16 --ps_hosts ******* --worker_hosts *******'),
    ('/imagenet/run_worker.sh --job_name worker --task_id 13 --batch_size 32 --num_ps 3 --num_workers 16 --ps_hosts ******* --worker_hosts *******'),
    ('/imagenet/run_worker.sh --job_name worker --task_id 14 --batch_size 32 --num_ps 3 --num_workers 16 --ps_hosts ******* --worker_hosts *******'),
    ('/imagenet/run_worker.sh --job_name worker --task_id 15 --batch_size 32 --num_ps 3 --num_workers 16 --ps_hosts ******* --worker_hosts *******'),
       ))

client_ps.join(output_ps)
#client_worker.join(output_worker)
pprint(output_ps.values()[0].exit_code)
#pprint(output_worker.values()[0].exit_code)

for host, host_output in output_ps.items():
    for line in host_output.stdout:
        print(""Host [%s] - %s"" % (host, line))
```
I think this script worked fine because I logged in every machine and checked with ps command and ensured the program was running with correct parameters. Then the program just worked fine but to some point, it started to save checkpoints forever(here is the output of worker0):

```bash
INFO:tensorflow:Worker 0: 2017-08-04 06:46:08.510727: step 2340, loss = 11.22(2.0 examples/sec; 15.788  sec/batch)
INFO:tensorflow:Running Summary operation on the chief.
INFO:tensorflow:Finished running Summary operation.
INFO:tensorflow:Running Summary operation on the chief.
INFO:tensorflow:Finished running Summary operation.
INFO:tensorflow:Saving checkpoint to path /home/centos/experiment_16W_2P_32BS_2017-08-03_IMAGENET_W0/model.ckpt
INFO:tensorflow:Running Summary operation on the chief.
INFO:tensorflow:Finished running Summary operation.
INFO:tensorflow:Worker 0: 2017-08-04 06:53:55.553703: step 2370, loss = 10.30(2.1 examples/sec; 15.573  sec/batch)
INFO:tensorflow:Running Summary operation on the chief.
INFO:tensorflow:Finished running Summary operation.
INFO:tensorflow:Running Summary operation on the chief.
INFO:tensorflow:Finished running Summary operation.
INFO:tensorflow:Worker 0: 2017-08-04 07:01:44.226068: step 2400, loss = 10.84(2.1 examples/sec; 15.421  sec/batch)
INFO:tensorflow:Saving checkpoint to path /home/centos/experiment_16W_2P_32BS_2017-08-03_IMAGENET_W0/model.ckpt
INFO:tensorflow:Running Summary operation on the chief.
INFO:tensorflow:Finished running Summary operation.
INFO:tensorflow:Saving checkpoint to path /home/centos/experiment_16W_2P_32BS_2017-08-03_IMAGENET_W0/model.ckpt
INFO:tensorflow:Saving checkpoint to path /home/centos/experiment_16W_2P_32BS_2017-08-03_IMAGENET_W0/model.ckpt
INFO:tensorflow:Saving checkpoint to path /home/centos/experiment_16W_2P_32BS_2017-08-03_IMAGENET_W0/model.ckpt
INFO:tensorflow:Saving checkpoint to path /home/centos/experiment_16W_2P_32BS_2017-08-03_IMAGENET_W0/model.ckpt
INFO:tensorflow:Saving checkpoint to path /home/centos/experiment_16W_2P_32BS_2017-08-03_IMAGENET_W0/model.ckpt
INFO:tensorflow:Saving checkpoint to path /home/centos/experiment_16W_2P_32BS_2017-08-03_IMAGENET_W0/model.ckpt
INFO:tensorflow:Saving checkpoint to path /home/centos/experiment_16W_2P_32BS_2017-08-03_IMAGENET_W0/model.ckpt
INFO:tensorflow:Saving checkpoint to path /home/centos/experiment_16W_2P_32BS_2017-08-03_IMAGENET_W0/model.ckpt
(same saving checkpoint output forever)
```
I ran nvidia-smi and found the GPU wasn't working and same with other nodes. The output of worker 1-15 just stucked on step 2400 and didn't do any progress.  I tried this several time on new set of 16 machines but it all stucked on saving checkpoint forever problem at some time.  I guess it might be a bug in tensorflow? Or does this caused network failure? but it didn't retrun any network failure error.
",YuxinxinChen,b'stat:awaiting model gardener',2017-08-07T22:28:36Z,2020-02-07T18:42:38Z,,,,,,,
2145,Bug: Change protobuf to list in Object Detection API,"
there is a 'subtract_channel_mean' preprocess op in Object Detection API.
https://github.com/tensorflow/models/blob/master/object_detection/core/preprocessor.py#L1462

Problem 1:
When I add this preprocessing op in the pipeline.config, and begin to train, it raises error:

    TypeError: Expected float32, got <google.protobuf.pyext._message.RepeatedScalarContainer object at 0x7f17df4fde30> of type 'RepeatedScalarContainer' instead.

Add 'means = list(means)' before Line 1474, and the problem solved(but this way is not elegant).

You need to fix it.

Problem 2:
This config is in the model config as a preprocessing config. However, it seems that if this operation be done in the training procedure, it also need to be done in the eval & test. But it seems not.
",irmowan,b'stat:awaiting model gardener',2017-08-07T09:59:53Z,2020-02-07T18:42:37Z,,,,,,,
2139,Broken bazel build of //object_detection:all,"Please go to Stack Overflow for help and support:

### System information
- **What is the top-level directory of the model you are using**:
None
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
Nope
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Mac OS 10.12.6
- **TensorFlow installed from (source or binary)**:
source (but should not matter)
- **TensorFlow version (use command below)**:
v1.2.0-5-g435cdfc 1.2.1
- **Bazel version (if compiling from source)**:
0.5.2-homebrew
- **CUDA/cuDNN version**:
None
- **GPU model and memory**:
None
- **Exact command to reproduce**:
```bash
git clone https://github.com/tensorflow/models.git
cd models
bazel build //object_detection:train
```

### Describe the problem
 //object_detection targets don't build. 

I want to use tensorflow/models as an external dependency of my project (I use bazel as a build system). On the other hand one also expects the BUILD files to be correct in this repository.

For my use case (external dependency) you can reproduce it using: 
```bash
mkdir my_workspace
cd my_workspace
echo 'http_archive(
    name = ""tf_models"",
    sha256 = ""96f6bdc2a9044f0ce8daa0f20f8e227d3c47409a1df12293ea9eaa6816cde328"",
    urls = [""https://github.com/tensorflow/models/archive/3d792f9.tar.gz""],
    strip_prefix =""models-3d792f935d652b2c7793b95aa3351a5551dc2401"",
)' > WORKSPACE
bazel build --verbose_failures @tf_models//object_detection:train
```

Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
For  `bazel build //object_detection:train`:
```
ERROR: /Users/vertix/Documents/models/object_detection/BUILD:11:1: no such package 'tensorflow': BUILD file not found on package path and referenced by '//object_detection:train'.
ERROR: Analysis of target '//object_detection:train' failed; build aborted.
INFO: Elapsed time: 11,901s
```

For  `bazel build @tf_models//object_detection:train`:
```
ERROR: /private/var/tmp/_bazel_vertix/0bd4347ec154918ae178683310d45d71/external/tf_models/object_detection/BUILD:28:1: no such package '@tf_models//tensorflow_models/object_detection/core': BUILD file not found on package path and referenced by '@tf_models//object_detection:trainer'.
ERROR: /private/var/tmp/_bazel_vertix/0bd4347ec154918ae178683310d45d71/external/tf_models/object_detection/BUILD:28:1: no such package '@tf_models//tensorflow_models/object_detection/core': BUILD file not found on package path and referenced by '@tf_models//object_detection:trainer'.
ERROR: Analysis of target '@tf_models//object_detection:train' failed; build aborted.
INFO: Elapsed time: 100,886s
```",vertix,None,2017-08-06T14:01:45Z,2020-02-07T18:42:28Z,,,,,,,
2137,Couldn't restore attention_ocr variables from .index and .data checkpoints,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
MacOS Sierra 10.12.5
- **TensorFlow installed from (source or binary)**:
created environment in conda, then installed tf via pip
- **TensorFlow version (use command below)**:
('v1.2.0-rc2-21-g12f033d', '1.2.0')
- **Python version**: 
2.7
- **Bazel version (if compiling from source)**:
Not installed
- **CUDA/cuDNN version**:
No GPU supported
- **GPU model and memory**:
No
- **Exact command to reproduce**:
python test.py
You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

Hi, I am trying to use attention_ocr in my own data, a simple test is firstly implemented.
according to the instructions from [How to use a pre-trained model](https://github.com/tensorflow/models/tree/master/attention_ocr#how-to-use-a-pre-trained-model) but somehow failed in restoring the checkpoints without explicit error info.

The following condition has been checked:
1. checkpoint files are complete
2. right path to the checkpoint
3. graphs have been imported from .meta
4. Nothing changes after run saver.train.restore() (predictions remained the same)
5. No error or hints provided

The checkpoint was downloaded as suggested:
```
wget http://download.tensorflow.org/models/attention_ocr_2017_05_17.tar.gz
tar xf attention_ocr_2017_05_17.tar.gz
cd attention_ocr_2017_05_17
ls -lh
```
```
total 64216
-rw-r-----  1 liuhuichuan  staff    14M  5 18 04:07 model.ckpt-399731.data-00000-of-00001
-rw-r-----  1 liuhuichuan  staff   8.2K  5 18 04:07 model.ckpt-399731.index
-rw-r-----  1 liuhuichuan  staff    17M  5 18 04:07 model.ckpt-399731.meta
```

The graphs were successfully imported from .meta, but somehow saver couldn't recognize .index and .data files: 
```
print os.path.exists('../attention_ocr_2017_05_17/model.ckpt-399731.data-00000-of-00001')
print os.path.exists('../attention_ocr_2017_05_17/model.ckpt-399731.index')
print tf.train.get_checkpoint_state('../attention_ocr_2017_05_17/model.ckpt-399731')
```
returns:
```
Ture
Ture
None
```
A very simple test is attempted:
```
saver = tf.train.import_meta_graph('../attention_ocr_2017_05_17/model.ckpt-399731.meta')
with tf.Session() as sess:
    print os.path.exists('./attention_ocr_2017_05_17/model.ckpt-399731.meta')
    print tf.train.get_checkpoint_state('../attention_ocr_2017_05_17/model.ckpt-399731')
    saver.restore(sess,'../attention_ocr_2017_05_17/model.ckpt-399731')
```
returns no error, but still not restored:
```
2017-08-06 16:24:41.346086: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
True
2017-08-06 16:24:41.346124: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2017-08-06 16:24:41.346129: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2017-08-06 16:24:41.346133: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
None
INFO:tensorflow:Restoring parameters from ../attention_ocr_2017_05_17/model.ckpt-399731
INFO 2017-08-06 16:24:41.000354: tf_logging.py: 82 Restoring parameters from ../attention_ocr_2017_05_17/model.ckpt-399731

Process finished with exit code 0
```

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.

```
import tensorflow as tf
import os
from tensorflow.python.platform import flags
import matplotlib.image as mpimg
import common_flags

FLAGS = flags.FLAGS
common_flags.define()

# yapf: disable
flags.DEFINE_integer('num_batches', 100,
                     'Number of batches to run eval for.')

flags.DEFINE_string('eval_log_dir', '/tmp/attention_ocr/eval',
                    'Directory where the evaluation results are saved to.')

flags.DEFINE_integer('eval_interval_secs', 60,
                     'Frequency in seconds to run evaluations.')

flags.DEFINE_integer('number_of_steps', None,
                     'Number of times to run evaluation.')


# fake a simple test image

raw_image_data = mpimg.imread('A4A8A5910A355-cvt.jpg').reshape((1,150,600,3))
images_placeholder = tf.placeholder(tf.float32,shape = (1,150, 600, 3),name='img_data')

if not tf.gfile.Exists(FLAGS.eval_log_dir):
    tf.gfile.MakeDirs(FLAGS.eval_log_dir)
dataset = common_flags.create_dataset(split_name=FLAGS.split_name)
model = common_flags.create_model(dataset.num_char_classes,
                                    dataset.max_sequence_length,
                                    dataset.num_of_views, dataset.null_code)
endpoints = model.create_base(images_placeholder, labels_one_hot=None)

# start loading attention_ocr model

saver = tf.train.import_meta_graph('../attention_ocr_2017_05_17/model.ckpt-399731.meta')

with tf.Session() as sess:
    # init without checkpoint variables and predict
    init = tf.global_variables_initializer()
    sess.run(init)
    predictions = sess.run(endpoints.predicted_chars, feed_dict={images_placeholder: raw_image_data})
    print predictions

    # restore from checkpoint then predict
    print os.path.exists('./attention_ocr_2017_05_17/model.ckpt-399731.meta')
    print tf.train.get_checkpoint_state('../attention_ocr_2017_05_17/model.ckpt-399731')
    saver.restore(sess,'../attention_ocr_2017_05_17/model.ckpt-399731')
    predictions = sess.run(endpoints.predicted_chars, feed_dict={images_placeholder: raw_image_data})
    print predictions
```

```
INFO 2017-08-06 16:48:44.000554: fsns.py: 130 Using FSNS dataset split_name=train dataset_dir=/Users/liuhuichuan/PycharmProjects/models/attention_ocr/python/datasets/data/fsns
DEBUG 2017-08-06 16:48:44.000556: model.py: 343 images: Tensor(""img_data:0"", shape=(1, 150, 600, 3), dtype=float32)
DEBUG 2017-08-06 16:48:44.000561: model.py: 348 Views=4 single view: Tensor(""AttentionOcr_v1/split:0"", shape=(1, 150, 150, 3), dtype=float32)
DEBUG 2017-08-06 16:48:44.000561: model.py: 191 Using final_endpoint=Mixed_5d
DEBUG 2017-08-06 16:48:46.000492: model.py: 191 Using final_endpoint=Mixed_5d
DEBUG 2017-08-06 16:48:47.000546: model.py: 191 Using final_endpoint=Mixed_5d
DEBUG 2017-08-06 16:48:48.000684: model.py: 191 Using final_endpoint=Mixed_5d
DEBUG 2017-08-06 16:48:49.000862: model.py: 354 Conv tower: Tensor(""AttentionOcr_v1/conv_tower_fn/INCE/InceptionV3/Mixed_5d/concat:0"", shape=(1, 16, 16, 288), dtype=float32)
DEBUG 2017-08-06 16:48:49.000862: model.py: 357 Conv tower w/ encoded coordinates: Tensor(""AttentionOcr_v1/conv_tower_fn/INCE/InceptionV3/Mixed_5d/concat:0"", shape=(1, 16, 16, 288), dtype=float32)
DEBUG 2017-08-06 16:48:49.000869: model.py: 360 Pooled views: Tensor(""AttentionOcr_v1/pool_views_fn/STCK/Reshape:0"", shape=(1, 1024, 288), dtype=float32)
DEBUG 2017-08-06 16:48:49.000869: sequence_layers.py: 421 Use AttentionWithAutoregression as a layer class
DEBUG 2017-08-06 16:48:53.000099: model.py: 363 chars_logit: Tensor(""AttentionOcr_v1/sequence_logit_fn/SQLR/concat:0"", shape=(1, 37, 134), dtype=float32)
2017-08-06 16:50:05.943512: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2017-08-06 16:50:05.943528: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2017-08-06 16:50:05.943532: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2017-08-06 16:50:05.943537: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
INFO:tensorflow:Restoring parameters from ../attention_ocr_2017_05_17/model.ckpt-399731
INFO 2017-08-06 16:50:29.000024: tf_logging.py: 82 Restoring parameters from ../attention_ocr_2017_05_17/model.ckpt-399731
[[  0   0   0 123 123 123 123 123 123 123 123 123 123 123 123 123 123 123
  123 123 123 123 123 123 123 123 123 123 123 123 123 123 123 123 123 123
  123]]
True
None
[[  0   0   0 123 123 123 123 123 123 123 123 123 123 123 123 123 123 123
  123 123 123 123 123 123 123 123 123 123 123 123 123 123 123 123 123 123
  123]]

Process finished with exit code 0
```
",HuichuanLiu,b'stat:awaiting model gardener type:bug',2017-08-06T09:43:55Z,2017-11-30T06:33:37Z,,,,,,,
2133,Object Detection: Errors with Export/Import for inference,"## System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.2.1
- **Bazel version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: 6.0
- **GPU model and memory**: Tesla P100 16276 MiB
- **Exact command to reproduce**: See description

## Describe the problem
### Overview
Loading a frozen model created with export_inference_graph.py results in ""truncated message: errors.  As a result, I am unable to use the model for inference.  Model was generated at 10,820 iterations training the pet detector example locally.

### Details:
The tutorial given at https://github.com/tensorflow/models/blob/master/object_detection/g3doc/exporting_models.md has some incorrect input option names, however, a few minor changes to the suggested inputs gets export_inference_graph.py to run via:
`python object_detection/export_inference_graph.py --input_type image_tensor --pipeline_config_path /home/qzhrlc/models/object_detection/samples/configs/faster_rcnn_resnet101_pets.config --trained_checkpoint_prefix /path/to/checkpoint/model.ckpt-10820 --output_directory .`

This produces a .pb file, however, some log messages appear which may indicate some issue.  Then, when loading into python via 
`PATH_TO_CKPT = '/home/qzhrlc/models/saved_model/saved_model.pb'`
`detection_graph = tf.Graph()`
`with detection_graph.as_default():`
`  od_graph_def = tf.GraphDef()`
`  with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:`
`    serialized_graph = fid.read()`
`    od_graph_def.ParseFromString(serialized_graph)`
`    tf.import_graph_def(od_graph_def, name='')`
An error is generated on `od_graph_def.ParseFromString(serialized_graph)`  of DecodeError: Truncated message.  Output of export_inference_graph and error message included below.

## Source code / logs
### export_inference_graph output:
2017-08-04 12:00:13.624623: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2017-08-04 12:00:13.624652: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2017-08-04 12:00:13.624656: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2017-08-04 12:00:13.624678: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2017-08-04 12:00:13.624683: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
2017-08-04 12:00:14.054272: I tensorflow/core/common_runtime/gpu/gpu_device.cc:940] Found device 0 with properties: 
name: Tesla P100-SXM2-16GB
major: 6 minor: 0 memoryClockRate (GHz) 1.4805
pciBusID 0000:05:00.0
Total memory: 15.89GiB
Free memory: 514.25MiB
2017-08-04 12:00:14.452981: W tensorflow/stream_executor/cuda/cuda_driver.cc:523] A non-primary context 0x714e4f0 exists before initializing the StreamExecutor. We haven't verified StreamExecutor works with that.
2017-08-04 12:00:14.453690: I tensorflow/core/common_runtime/gpu/gpu_device.cc:940] Found device 1 with properties: 
name: Tesla P100-SXM2-16GB
major: 6 minor: 0 memoryClockRate (GHz) 1.4805
pciBusID 0000:06:00.0
Total memory: 15.89GiB
Free memory: 514.25MiB
2017-08-04 12:00:14.885142: W tensorflow/stream_executor/cuda/cuda_driver.cc:523] A non-primary context 0x7151e80 exists before initializing the StreamExecutor. We haven't verified StreamExecutor works with that.
2017-08-04 12:00:14.885995: I tensorflow/core/common_runtime/gpu/gpu_device.cc:940] Found device 2 with properties: 
name: Tesla P100-SXM2-16GB
major: 6 minor: 0 memoryClockRate (GHz) 1.4805
pciBusID 0000:84:00.0
Total memory: 15.89GiB
Free memory: 514.25MiB
2017-08-04 12:00:15.310494: W tensorflow/stream_executor/cuda/cuda_driver.cc:523] A non-primary context 0x7155810 exists before initializing the StreamExecutor. We haven't verified StreamExecutor works with that.
2017-08-04 12:00:15.311252: I tensorflow/core/common_runtime/gpu/gpu_device.cc:940] Found device 3 with properties: 
name: Tesla P100-SXM2-16GB
major: 6 minor: 0 memoryClockRate (GHz) 1.4805
pciBusID 0000:85:00.0
Total memory: 15.89GiB
Free memory: 514.25MiB
2017-08-04 12:00:15.312769: I tensorflow/core/common_runtime/gpu/gpu_device.cc:961] DMA: 0 1 2 3 
2017-08-04 12:00:15.312779: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   Y Y Y Y 
2017-08-04 12:00:15.312783: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 1:   Y Y Y Y 
2017-08-04 12:00:15.312786: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 2:   Y Y Y Y 
2017-08-04 12:00:15.312790: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 3:   Y Y Y Y 
2017-08-04 12:00:15.312798: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla P100-SXM2-16GB, pci bus id: 0000:05:00.0)
2017-08-04 12:00:15.312805: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:1) -> (device: 1, name: Tesla P100-SXM2-16GB, pci bus id: 0000:06:00.0)
2017-08-04 12:00:15.312810: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:2) -> (device: 2, name: Tesla P100-SXM2-16GB, pci bus id: 0000:84:00.0)
2017-08-04 12:00:15.312832: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:3) -> (device: 3, name: Tesla P100-SXM2-16GB, pci bus id: 0000:85:00.0)
2017-08-04 12:01:02.982605: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla P100-SXM2-16GB, pci bus id: 0000:05:00.0)
2017-08-04 12:01:02.982634: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:1) -> (device: 1, name: Tesla P100-SXM2-16GB, pci bus id: 0000:06:00.0)
2017-08-04 12:01:02.982656: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:2) -> (device: 2, name: Tesla P100-SXM2-16GB, pci bus id: 0000:84:00.0)
2017-08-04 12:01:02.982661: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:3) -> (device: 3, name: Tesla P100-SXM2-16GB, pci bus id: 0000:85:00.0)
Converted 530 variables to const ops.
2017-08-04 12:01:12.496242: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla P100-SXM2-16GB, pci bus id: 0000:05:00.0)
2017-08-04 12:01:12.496283: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:1) -> (device: 1, name: Tesla P100-SXM2-16GB, pci bus id: 0000:06:00.0)
2017-08-04 12:01:12.496288: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:2) -> (device: 2, name: Tesla P100-SXM2-16GB, pci bus id: 0000:84:00.0)
2017-08-04 12:01:12.496292: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:3) -> (device: 3, name: Tesla P100-SXM2-16GB, pci bus id: 0000:85:00.0)


### Import error message:
---------------------------------------------------------------------------
DecodeError                               Traceback (most recent call last)
<ipython-input-7-0e97fbc26e6d> in <module>()
      4   with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:
      5     serialized_graph = fid.read()
----> 6     od_graph_def.ParseFromString(serialized_graph)
      7     tf.import_graph_def(od_graph_def, name='')

/home/qzhrlc/miniconda2/envs/ajlBaseCaffe/lib/python2.7/site-packages/google/protobuf/message.pyc in ParseFromString(self, serialized)
    183     """"""
    184     self.Clear()
--> 185     self.MergeFromString(serialized)
    186 
    187   def SerializeToString(self):

/home/qzhrlc/miniconda2/envs/ajlBaseCaffe/lib/python2.7/site-packages/google/protobuf/internal/python_message.pyc in MergeFromString(self, serialized)
   1060     length = len(serialized)
   1061     try:
-> 1062       if self._InternalParse(serialized, 0, length) != length:
   1063         # The only reason _InternalParse would return early is if it
   1064         # encountered an end-group tag.

/home/qzhrlc/miniconda2/envs/ajlBaseCaffe/lib/python2.7/site-packages/google/protobuf/internal/python_message.pyc in InternalParse(self, buffer, pos, end)
   1096         pos = new_pos
   1097       else:
-> 1098         pos = field_decoder(buffer, new_pos, end, self, field_dict)
   1099         if field_desc:
   1100           self._UpdateOneofState(field_desc)

/home/qzhrlc/miniconda2/envs/ajlBaseCaffe/lib/python2.7/site-packages/google/protobuf/internal/decoder.pyc in DecodeField(buffer, pos, end, message, field_dict)
    631         raise _DecodeError('Truncated message.')
    632       # Read sub-message.
--> 633       if value._InternalParse(buffer, pos, new_pos) != new_pos:
    634         # The only reason _InternalParse would return early is if it encountered
    635         # an end-group tag.

/home/qzhrlc/miniconda2/envs/ajlBaseCaffe/lib/python2.7/site-packages/google/protobuf/internal/python_message.pyc in InternalParse(self, buffer, pos, end)
   1096         pos = new_pos
   1097       else:
-> 1098         pos = field_decoder(buffer, new_pos, end, self, field_dict)
   1099         if field_desc:
   1100           self._UpdateOneofState(field_desc)

/home/qzhrlc/miniconda2/envs/ajlBaseCaffe/lib/python2.7/site-packages/google/protobuf/internal/decoder.pyc in DecodeRepeatedField(buffer, pos, end, message, field_dict)
    610           raise _DecodeError('Truncated message.')
    611         # Read sub-message.
--> 612         if value.add()._InternalParse(buffer, pos, new_pos) != new_pos:
    613           # The only reason _InternalParse would return early is if it
    614           # encountered an end-group tag.

/home/qzhrlc/miniconda2/envs/ajlBaseCaffe/lib/python2.7/site-packages/google/protobuf/internal/python_message.pyc in InternalParse(self, buffer, pos, end)
   1096         pos = new_pos
   1097       else:
-> 1098         pos = field_decoder(buffer, new_pos, end, self, field_dict)
   1099         if field_desc:
   1100           self._UpdateOneofState(field_desc)

/home/qzhrlc/miniconda2/envs/ajlBaseCaffe/lib/python2.7/site-packages/google/protobuf/internal/decoder.pyc in DecodeMap(buffer, pos, end, message, field_dict)
    741       # Read sub-message.
    742       submsg.Clear()
--> 743       if submsg._InternalParse(buffer, pos, new_pos) != new_pos:
    744         # The only reason _InternalParse would return early is if it
    745         # encountered an end-group tag.

/home/qzhrlc/miniconda2/envs/ajlBaseCaffe/lib/python2.7/site-packages/google/protobuf/internal/python_message.pyc in InternalParse(self, buffer, pos, end)
   1086       if field_decoder is None:
   1087         value_start_pos = new_pos
-> 1088         new_pos = local_SkipField(buffer, new_pos, end, tag_bytes)
   1089         if new_pos == -1:
   1090           return pos

/home/qzhrlc/miniconda2/envs/ajlBaseCaffe/lib/python2.7/site-packages/google/protobuf/internal/decoder.pyc in SkipField(buffer, pos, end, tag_bytes)
    848     # The wire type is always in the first byte since varints are little-endian.
    849     wire_type = ord(tag_bytes[0:1]) & wiretype_mask
--> 850     return WIRETYPE_TO_SKIPPER[wire_type](buffer, pos, end)
    851 
    852   return SkipField

/home/qzhrlc/miniconda2/envs/ajlBaseCaffe/lib/python2.7/site-packages/google/protobuf/internal/decoder.pyc in _SkipGroup(buffer, pos, end)
    797   while 1:
    798     (tag_bytes, pos) = ReadTag(buffer, pos)
--> 799     new_pos = SkipField(buffer, pos, end, tag_bytes)
    800     if new_pos == -1:
    801       return pos

/home/qzhrlc/miniconda2/envs/ajlBaseCaffe/lib/python2.7/site-packages/google/protobuf/internal/decoder.pyc in SkipField(buffer, pos, end, tag_bytes)
    848     # The wire type is always in the first byte since varints are little-endian.
    849     wire_type = ord(tag_bytes[0:1]) & wiretype_mask
--> 850     return WIRETYPE_TO_SKIPPER[wire_type](buffer, pos, end)
    851 
    852   return SkipField

/home/qzhrlc/miniconda2/envs/ajlBaseCaffe/lib/python2.7/site-packages/google/protobuf/internal/decoder.pyc in _SkipFixed32(buffer, pos, end)
    812   pos += 4
    813   if pos > end:
--> 814     raise _DecodeError('Truncated message.')
    815   return pos
    816 

DecodeError: Truncated message.
",matlabninja,b'type:bug',2017-08-04T16:20:58Z,2018-04-09T14:39:22Z,,,,,,,
2120,About python train.py this step,"when I follow author's step to  train my database ,Input this order  python train.py
In my screen show on this bug 

tensorflow.python.framework.errors_impl.NotFoundError: /home/wanpengfei/tensorflow_models/models/attention_ocr/python/datasets/data/fsns/train

But when I trace this route and check  models/attention_ocr/python/datasets/testdata/fsns/, I didn't find this file 'train' .I dont know why this issue happend or if my version of tensorflow is incorrect? I hope someone can help me solve or discuss this issue.",philipwan,b'type:support',2017-08-04T02:21:08Z,2017-08-04T17:54:23Z,,,,,,,
2091,Spatial Transformer cannot adapt to different Train and Test image dimension and batch size,"### System information
- **What is the top-level directory of the model you are using**: models/transformer
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
I am trying to use the transformer layer as part of a CNN.
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.2.1


### Describe the problem
As I understand it, the implementation of the transformer layer requires its arguments' dimensions to be preset (and these arguments -- U, theta, output_size -- are all dependent on input_size/batch_size)
The examples provided in models/transformer only have training -- and do not show how to use the transformer layer when testing differently-sized images.
I feel that original ST-CNN implementations must have not been reliant on expressly passed in input sizes and batch sizes. 
I have been trying various designs for the functions, processing of inputs and outputs, attempts to allow inference of input_size and batch_size, and extensive debugging for 10+ hours with little result. For example, attempting to find shape of input_size returns NoneTypes.
[snippet_of_transformer_function.txt](https://github.com/tensorflow/models/files/1192395/snippet_of_transformer_function.txt)


### Source code / logs
Train inputs are 200x200, batches of 8
Validation/test inputs are 800x800, individual images,
```
inputs.shape (8, 200, 200, 3)
labels.shape (8, 200, 200, 3)
test inputs (7, 800, 800, 3)    <-- 7 test files
labels inputs (7, 800, 800, 3)
```




[tracebacksssss.txt](https://github.com/tensorflow/models/files/1192384/tracebacksssss.txt)

Appreciate any help as this has been consuming my last few days.
",JeffreyYun,None,2017-08-02T01:31:19Z,2017-08-04T19:24:04Z,,,,,,,
2077,"resnet_v2_101/block1/unit_1/bottleneck_v2/conv1/biases does not exist, or was not created with tf.get_variable()","Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",islamtashfiq,None,2017-07-31T12:17:39Z,2017-07-31T13:22:32Z,,,,,,,
2066,"Maybe a big bug in object_detection API, when I add data augmentation options on config files, then the model quickly divergences, mAP  on testset would be 0. ","I am training with ""ssd_inception_v2"" on coco datasets, when I use the default data augmentation options in config file, which is 
```
  data_augmentation_options {
    random_horizontal_flip {
    }
  }
  data_augmentation_options {
    ssd_random_crop {
    }
  }
```
the model convergences rightly. It works very well. However, when I add one data augmentation options which is defined in `objection_detection/coco/preprocessor`, only add one `random_adjust_hue` option or  
`random_adjust_saturation` et.al. The model would  divergence quickly, even in a pretrained model， and mAP on testset would decline to 0 quickly. I add data augmentation options on config files, which looks like this format
```
  data_augmentation_options {
    random_horizontal_flip {
    }
  }
  data_augmentation_options {
    ssd_random_crop {
    }
  }

  data_augmentation_options {
    random_adjust_saturation {
    }
  }
```
![image](https://user-images.githubusercontent.com/25903017/28741973-5c8b0358-7455-11e7-9e1e-7a2ad0a221e2.png)
**I tried `ssd_inception_v2`  on pascal data with the all scripts in Tensorflow Object Detection API, I met the same  problem. Without `random_adjust_brightness` or any of hue, contrast. et.al, the model works quite well, when add `random_adjust_brightness` or any of hue, contrast. et.al. It's mAP on validation set quickly decline to 0. I wonder whether those methods on `core/preporcessor.py` loss the bboxes or labels when they are applied?**",MetaPeak,None,2017-07-29T03:59:36Z,2018-07-05T09:14:07Z,,,,,,,
2063,tensorflow.python.framework.errors_impl.AlreadyExistsError,"### System information
- **What is the top-level directory of the model you are using**:
object_detection
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
no
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Red Hat 4.8.5-4
- **TensorFlow installed from (source or binary)**:
binary
- **TensorFlow version (use command below)**:
('v1.0.0-65-g4763edf-dirty', '1.0.1')
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
CUDA 8.0/cuDNN 5.1
- **GPU model and memory**:
Tesla P40
- **Exact command to reproduce**:

python object_detection/train.py --logtostderr --pipeline_config_path=object_detection/models/model/rfcn_resnet101_pedestrain.config --train_dir=object_detection/models/model/train

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

In the training process, after about 270000 iterations, the error occured. And I could restart the training from the checkpoints. However it happened again at 290000 iteration and again at 310000 iteration. It seems it happens about every 20k iterations. However, I didn't have this kind of errors before when I was training other models using object_detection or in the previous 270000 iterations.
   ```
 pywrap_tensorflow.TF_GetCode(status))
tensorflow.python.framework.errors_impl.AlreadyExistsError: object_detection/models/model/train/checkpoint.tmp34ad7bc3cd2a4711ad0092ab5b599a50
```
Update:
Now , it fails to continue training, throwing another error. I don't know if this is related to the first error.
 ```
   self._prewrite_check()
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/lib/io/file_io.py"", line 82, in _prewrite_check
    compat.as_bytes(self.__name), compat.as_bytes(self.__mode), status)
  File ""/usr/lib64/python2.7/contextlib.py"", line 24, in __exit__
    self.gen.next()
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/framework/errors_impl.py"", line 466, in raise_exception_on_not_ok_status
    pywrap_tensorflow.TF_GetCode(status))
tensorflow.python.framework.errors_impl.FailedPreconditionError: object_detection/models/model_pedes_new/train/checkpoint.tmp9a60b55633944de6ad4f1fbeceba829a

```",lionel92,None,2017-07-28T11:33:26Z,2018-10-31T20:55:39Z,,,,,,,
2050,LFADS: Fixing alignment bias bug,"For the /lfads model, this fixes an issue when using the ""stitching"" feature (involving the alignment bias vectors across recording sessions). Attn @sussillo ",djoshea,b'cla: yes',2017-07-27T21:00:17Z,2017-07-28T16:31:07Z,,,,,,,
2045,"[object_detection] Empty ""variables"" folder after I tried to set ""export_as_saved_model True"" when calling ""export_inference_graph.py""","### System information
- **What is the top-level directory of the model you are using**:
~/workspace/models

- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
I am using config files written by myself

- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Linux Ubuntu 16.04
And another Linux server

- **TensorFlow installed from (source or binary)**:
pip install

- **TensorFlow version (use command below)**:
1.2.1

- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
8.0/5.1
- **GPU model and memory**:
GTX 1060 6GB
- **Exact command to reproduce**:
 CUDA_VISIBLE_DEVICES=2 python export_inference_graph.py \
             --input_type image_tensor \
                 --pipeline_config_path /scratch2/wangxiny2/workspace/models/object_detection/configs/rfcn_resnet50_car_Jul_20.config \
                     --checkpoint_path /scratch2/wangxiny2/workspace/models/object_detection/train_car_Jul_20_3/model.ckpt-17586 \
                         --inference_graph_path serving_model/1 \
                           --export_as_saved_model True


### Describe the problem
I trained some models on my own dataset, both training and evaluation process went well without any problems. I also expoted the model with option ""--export_as_saved_model"" to be ""False"" and tried to run in my python script to inference new images, also without any problems. However, I was planing to server the model with tensorflow serving, which means I need to switch ""--export_as_saved_model"" to be ""True"" to get model exported as a servable model. It seems the converting process went fine:
```python
2017-07-26 17:13:26.931536: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2017-07-26 17:13:26.931593: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2017-07-26 17:13:26.931607: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2017-07-26 17:13:26.931618: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2017-07-26 17:13:26.931629: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
2017-07-26 17:13:27.337890: I tensorflow/core/common_runtime/gpu/gpu_device.cc:940] Found device 0 with properties: 
name: Tesla K80
major: 3 minor: 7 memoryClockRate (GHz) 0.8235
pciBusID 0000:84:00.0
Total memory: 11.17GiB
Free memory: 11.11GiB
2017-07-26 17:13:27.337993: I tensorflow/core/common_runtime/gpu/gpu_device.cc:961] DMA: 0 
2017-07-26 17:13:27.338017: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   Y 
2017-07-26 17:13:27.338230: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:84:00.0)
Converted 277 variables to const ops.
2017-07-26 17:13:30.349176: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:84:00.0)
```

And I also got the .pb file with reasonable size. However, the ""variables"" folder was empty. According to the example provided by tensorflow serving, it should contain files like ""variables.data-00000-of-00001"" and ""variables.index"". When I tried to serve the model, tensorflow serving returned the information below:

```python
2017-07-26 16:42:51.545132: I tensorflow_serving/model_servers/main.cc:149] Building single TensorFlow model file config:  model_name: detection model_base_path: /home/xinyao/workspace/models/object_detection/serving_model
2017-07-26 16:42:51.545337: I tensorflow_serving/model_servers/server_core.cc:375] Adding/updating models.
2017-07-26 16:42:51.545346: I tensorflow_serving/model_servers/server_core.cc:421]  (Re-)adding model: detection
2017-07-26 16:42:51.646110: I tensorflow_serving/core/basic_manager.cc:705] Successfully reserved resources to load servable {name: detection version: 1}
2017-07-26 16:42:51.646148: I tensorflow_serving/core/loader_harness.cc:66] Approving load for servable version {name: detection version: 1}
2017-07-26 16:42:51.646168: I tensorflow_serving/core/loader_harness.cc:74] Loading servable version {name: detection version: 1}
2017-07-26 16:42:51.646246: I external/org_tensorflow/tensorflow/contrib/session_bundle/bundle_shim.cc:360] Attempting to load native SavedModelBundle in bundle-shim from: /home/xinyao/workspace/models/object_detection/serving_model/1
2017-07-26 16:42:51.646272: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:236] Loading SavedModel from: /home/xinyao/workspace/models/object_detection/serving_model/1
2017-07-26 16:42:51.711957: W external/org_tensorflow/tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2017-07-26 16:42:51.711974: W external/org_tensorflow/tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2017-07-26 16:42:51.711992: W external/org_tensorflow/tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2017-07-26 16:42:51.711996: W external/org_tensorflow/tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2017-07-26 16:42:51.711999: W external/org_tensorflow/tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
2017-07-26 16:42:51.815773: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:155] Restoring SavedModel bundle.
2017-07-26 16:42:51.815817: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:165] The specified SavedModel has no variables; no checkpoints were restored.
2017-07-26 16:42:51.815824: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:190] Running LegacyInitOp on SavedModel bundle.
2017-07-26 16:42:51.819608: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:284] Loading SavedModel: success. Took 173340 microseconds.
2017-07-26 16:42:51.819631: I tensorflow_serving/core/loader_harness.cc:86] Successfully loaded servable version {name: detection version: 1}
2017-07-26 16:42:51.834766: I tensorflow_serving/model_servers/main.cc:290] Running ModelServer at 0.0.0.0:9000 ...
```

It seems like the model was not properly served, since ""The specified SavedModel has no variables; no checkpoints were restored.""

I tried different checkpoint files with different architectures(rfcn-resnet50 and ssd_mobilenet_v1). It seems all have the same problems. I am not sure if I did something wrong or it is a bug.

### Source code / logs
One of the config files I am using:

model {
  faster_rcnn {
    num_classes: 1
    image_resizer {
      keep_aspect_ratio_resizer {
        min_dimension: 961
        max_dimension: 1199
      }
    }
    feature_extractor {
      type: 'faster_rcnn_resnet50'
      first_stage_features_stride: 8
    }
    first_stage_anchor_generator {
      grid_anchor_generator {
        scales: [0.25, 0.5, 1.0, 2.0]
        aspect_ratios: [0.5, 1.0, 2.0]
        height_stride: 8
        width_stride: 8
      }
    }
    first_stage_box_predictor_conv_hyperparams {
      op: CONV
      regularizer {
        l2_regularizer {
          weight: 0.0
        }
      }
      initializer {
        truncated_normal_initializer {
          stddev: 0.01
        }
      }
    }
    first_stage_nms_score_threshold: 0.0
    first_stage_nms_iou_threshold: 0.8
    first_stage_max_proposals: 300
    first_stage_localization_loss_weight: 1.0
    first_stage_objectness_loss_weight: 1.0
    second_stage_box_predictor {
      rfcn_box_predictor {
        conv_hyperparams {
          op: CONV
          regularizer {
            l2_regularizer {
              weight: 0.0
            }
          }
          initializer {
            truncated_normal_initializer {
              stddev: 0.01
            }
          }
        }
        crop_height: 10
        crop_width: 10
        num_spatial_bins_height: 2
        num_spatial_bins_width: 2
      }
    }
    second_stage_post_processing {
      batch_non_max_suppression {
        score_threshold: 0.0
        iou_threshold: 0.6
        max_detections_per_class: 300
        max_total_detections: 300
      }
      score_converter: SOFTMAX
    }
    second_stage_localization_loss_weight: 1.0
    second_stage_classification_loss_weight: 1.0
  }
}

train_config: {
  batch_size: 1
  num_steps: 45000
  keep_checkpoint_every_n_hours: 1
  optimizer {
    momentum_optimizer: {
      learning_rate: {
        manual_step_learning_rate {
          initial_learning_rate: 0.0003
          schedule {
            step: 0
            learning_rate: .0003
          }
          schedule {
            step: 15000
            learning_rate: .00003
          }
          schedule {
            step: 20000
            learning_rate: .000003
          }
        }
      }
      momentum_optimizer_value: 0.9
    }
    use_moving_average: false
  }
  gradient_clipping_by_norm: 10.0
  fine_tune_checkpoint: ""/scratch2/wangxiny2/workspace/models/object_detection/resnet_v1_50.ckpt""
  from_detection_checkpoint: false
  data_augmentation_options {
    random_horizontal_flip {
    }
  }
}

train_input_reader: {
  tf_record_input_reader {
    input_path: ""/scratch2/wangxiny2/workspace/models/object_detection/car_train.record""
  }
  label_map_path: ""/scratch2/wangxiny2/workspace/models/object_detection/data/car_label_map.pbtxt""
}

eval_config: {
  num_visualizations: 33
  num_examples: 33
  max_evals: 1
  visualization_export_dir: ""/scratch2/wangxiny2/workspace/models/object_detection/eval_car_Jul_20_3""
}

eval_input_reader: {
  tf_record_input_reader {
    input_path: ""/scratch2/wangxiny2/workspace/models/object_detection/car_val.record""
  }
  label_map_path: ""/scratch2/wangxiny2/workspace/models/object_detection/data/car_label_map.pbtxt""
  shuffle: false
  num_readers: 1
}
",protossw512,None,2017-07-27T01:01:11Z,2019-11-13T18:55:35Z,,,,,,,
2041,Fixing bug #2040,https://github.com/tensorflow/models/issues/2040,mari-linhares,b'cla: yes',2017-07-25T19:06:34Z,2017-07-25T20:33:14Z,,,,,,,
2038,[object detection] Dequeue placement issue,"### System information
- **What is the top-level directory of the model you are using**:
object_detection
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Windows Server 2012 R2
- **TensorFlow installed from (source or binary)**:
Binary
- **TensorFlow version (use command below)**:
1.3.0rc0
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
8.0 / 5.1.10
- **GPU model and memory**:
GTX 1080 Ti 11GB
- **Exact command to reproduce**:
```
python C:\Users\name\git-repos\models\object_detection\train.py --logtostderr --pipe
line_config_path=ssd_inception_v2.config --train_dir=.
```
### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

The output of the object_detection `train.py` file includes this line:

```
2017-07-25 12:39:37.289202: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\core\common_runtime\simple_placer.cc:697] Ignoring device specification /device:GPU:0 for node 'prefetch_queue_Dequeue' because the input edge from 'prefetch_queue' is a reference connection and already has a device field set to /device:CPU:0
```

This is related to issue #1390. Is this a performance problem? This problem existed in 1.2.x as well.
",MaxBareiss,b'models:research stat:awaiting response type:bug',2017-07-25T16:54:26Z,2020-02-07T18:42:26Z,,,,,,,
2020,Unable to run translate.py with tensorflow version 1.0 on windows  an Invalid argument error is thrown,"I get this error when trying to run seq-seq model in tensorflow version 1.0

Windows 10 (CPU)
Python 3.5


when i run the following command : python translate.py --decode, the following error is displayed:

"" InvalidArgumentError (see above for traceback): Assign requires shapes of both tensors to match. lhs shape= [1024] rhs shape= [256]
         [[Node: save/Assign_2 = Assign[T=DT_FLOAT, _class=[""loc:@embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/biases""], use_locking=true, validate_shape=true, _device=""/job:localhost/replica:0/task:0/cpu:0""](embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/biases, save/RestoreV2_2)]]"" ",soukira,b'stat:awaiting model gardener type:bug',2017-07-24T16:21:48Z,2018-10-20T02:09:36Z,,,,,,,
2016,Spatial Transformer Networks cuts off last row and column off input,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
models/transformer
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
Only the script attached below to reproduce the issue
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Tested on both MacOS Sierra and Linux Ubuntu 16.04.2 LTS
- **TensorFlow installed from (source or binary)**:
binary
- **TensorFlow version (use command below)**:
1.2.1
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
n/a
- **GPU model and memory**:
n/a
- **Exact command to reproduce**:

```python
import tensorflow as tf
import numpy as np
from spatial_transformer import transformer

def identity():

    original_theta = np.array([[1., 0., 0.],
                               [0., 1., 0.]])

    theta = tf.Variable(initial_value=np.expand_dims(original_theta.flatten(), 0))
    
    original_U = np.reshape(np.arange(25, dtype=""float32""), [5,5])
    reshaped_U = np.expand_dims(np.expand_dims(original_U, 2), 0)
    U = tf.Variable(initial_value=reshaped_U)

    assert(U.shape == (1,5,5,1))
    assert(theta.shape == (1,6))

    raw_output = transformer(U, theta, (5,5))
    
    sess = tf.Session()
    sess.run(tf.global_variables_initializer())
    output = np.array(sess.run(raw_output))
   
    assert(reshaped_U.shape == (1,5,5,1))
    assert(output.shape == (1,5,5,1))

    print(output)
    print(reshaped_U)

    assert((output == reshaped_U).all())
```

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

I cloned the models/transformer directory to generalize 2D spatial transformers to 3D. In the process, I found a few bugs that caused spatial transformers to not output the exact transformation specified. After investigating, I found that there are some indexing errors which cause the problem shown above. I'd be happy to make a PR for any or all of the following if it would be helpful:
1) The fixed 2D spatial transformer
2) Newly implemented 3D spatial transformer
3) Basic test cases for both of the above

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",hughbzhang,b'stat:community support type:bug',2017-07-24T03:18:20Z,2020-02-07T18:42:25Z,,,,,,,
2014,error with loading new layer weights when fine-tuning from existing checkpoint using slim,"Hello TensorFlow slim community,

I am in a bit of a rut here. 
First, let me  explain the task I am trying to perform:

# Background
I am writing a new vgg_16 model  within slim's[ vgg.py.](https://github.com/tensorflow/models/blob/master/slim/nets/vgg.py) The difference between the original vgg_16 and my version, named `modified_vgg_16`, is that all the fully-connected layers are removed and replaced with one convolutional layer -- this is added in the model below with a scope of `conv6`. The reason for this is that I am not performing a classification task. I am predicting arrays in the very end. I am also using a pre-trained vgg_16 model that loads parameters up until the last layer, that is, the convolutional layer with scope `conv6`. This layer is where I want to start training on my dataset.

That said,

I have written it as such:

(Again, this is with the fully-connected layers removed)

```
def modified_vgg_16(inputs,
           num_classes=1000,
           is_training=True,
           dropout_keep_prob=0.5,
           spatial_squeeze=True,
           scope='vgg_16',
           fc_conv_padding='VALID'):
  """"""Oxford Net VGG 16-Layers version D Example.

  Note: All the fully_connected layers have been transformed to conv2d layers.
        To use in classification mode, resize input to 224x224.

  Args:
    inputs: a tensor of size [batch_size, height, width, channels].
    num_classes: number of predicted classes.
    is_training: whether or not the model is being trained.
    dropout_keep_prob: the probability that activations are kept in the dropout
      layers during training.
    spatial_squeeze: whether or not should squeeze the spatial dimensions of the
      outputs. Useful to remove unnecessary dimensions for classification.
    scope: Optional scope for the variables.
    fc_conv_padding: the type of padding to use for the fully connected layer
      that is implemented as a convolutional layer. Use 'SAME' padding if you
      are applying the network in a fully convolutional manner and want to
      get a prediction map downsampled by a factor of 32 as an output. Otherwise,
      the output prediction map will be (input / 32) - 6 in case of 'VALID' padding.

  Returns:
    the last op containing the log predictions and end_points dict.
  """"""
  with tf.variable_scope(scope, 'vgg_16', [inputs]) as sc:
    end_points_collection = sc.name + '_end_points'
    
    # Collect outputs for conv2d, fully_connected and max_pool2d.
    with slim.arg_scope([slim.conv2d, slim.fully_connected, slim.max_pool2d],
                        outputs_collections=end_points_collection):
      net = slim.repeat(inputs, 2, slim.conv2d, 64, [3, 3], scope='conv1')
      net = slim.max_pool2d(net, [2, 2], scope='pool1')
      net = slim.repeat(net, 2, slim.conv2d, 128, [3, 3], scope='conv2')
      net = slim.max_pool2d(net, [2, 2], scope='pool2')
      net = slim.repeat(net, 3, slim.conv2d, 256, [3, 3], scope='conv3')
      net = slim.max_pool2d(net, [2, 2], scope='pool3')
      net = slim.repeat(net, 3, slim.conv2d, 512, [3, 3], scope='conv4')
      net = slim.max_pool2d(net, [2, 2], scope='pool4')
      net = slim.repeat(net, 3, slim.conv2d, 512, [3, 3], scope='conv5')
      net = slim.max_pool2d(net, [2, 2], scope='pool5')
      net = slim.conv2d(net, 1, num_classes, [1, 1], scope='conv6')

      # Convert end_points_collection into a end_point dict.
      end_points = slim.utils.convert_collection_to_dict(end_points_collection)
      if spatial_squeeze:
        #net = tf.squeeze(net, [1, 1], name='conv6/squeezed')
        end_points[sc.name + '/conv6'] = net
      return net, end_points

```

Now, to load the vgg_16 checkpoint, vgg_16.ckpt, I have written a bash script, very similar to the bash [scripts identified in slim](https://github.com/tensorflow/models/tree/master/slim/scripts), that I believe is loading the pre-trained model up until `conv6`, the layer where I want to start training on my dataset.

```
# Where the pre-trained vgg_16 checkpoint is saved to.
PRETRAINED_CHECKPOINT_DIR=checkpoints

# Where the training (fine-tuned) checkpoint and logs will be saved to.
TRAIN_DIR=trainLogs

# Where the dataset is saved to.
DATASET_DIR=all_train_TF_records

# Download the pre-trained checkpoint.
if [ ! -d ""$PRETRAINED_CHECKPOINT_DIR"" ]; then
  mkdir ${PRETRAINED_CHECKPOINT_DIR}
fi
if [ ! -f ${PRETRAINED_CHECKPOINT_DIR}/vgg_16.ckpt ]; then
  wget http://download.tensorflow.org/models/vgg_16_2016_08_28.tar.gz
  tar -xvf vgg_16_2016_08_28.tar.gz
  mv vgg_16.ckpt ${PRETRAINED_CHECKPOINT_DIR}/vgg_16.ckpt
  rm vgg_16_2016_08_28.tar.gz
fi

# Download the dataset
python download_and_convert_data.py \
  --dataset_name=mydataset\
  --dataset_dir=${DATASET_DIR}

### Fine-tune only the new layers for 3000 steps.
python train_image_classifier.py \
  --train_dir=${TRAIN_DIR} \
  --dataset_name=mydataset\
  --dataset_split_name=train \
  --dataset_dir=${DATASET_DIR} \
  --model_name=modified_vgg_16\
  --checkpoint_path=${TRAIN_DIR} \
  --trainable_scopes=vgg_16/conv6 \
  --checkpoint_exclude_scopes=vgg_16/conv6 \
  --max_number_of_steps=3000 \
  --learning_rate=0.00005 \
  --learning_rate_decay_type=fixed \
  --save_interval_secs=60 \
  --save_summaries_secs=60 \
  --log_every_n_steps=100 \
  --optimizer=rmsprop \
  --weight_decay=0.00004
```

# The Problem

I now get the error below:

`NotFoundError (see above for traceback): Key vgg_16/conv6/weights not found in checkpoint
	 [[Node: save/RestoreV2_40 = RestoreV2[dtypes=[DT_FLOAT], _device=""/job:localhost/replica:0/task:0/cpu:0""](_recv_save/Const_0, save/RestoreV2_40/tensor_names, save/RestoreV2_40/shape_and_slices)]]
	 [[Node: save/RestoreV2_35/_1 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device_incarnation=1, tensor_name=""edge_163_save/RestoreV2_35"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/gpu:0""]()]]
`

Why are the `conv6 `weights not being loaded? Am I misusing `checkpoint_exclude_scopes` and `trainable_scopes`? If I want to load the checkpoint of the pre-trained vgg_16 model, should I first train it on the original vgg_16 model and set `check_point_exclude_scopes` to equal all the fully-connected layers' scopes, then retrain the modified_vgg_16 from where that left off?  Or is it that I should have not written a modified version of vgg_16.? I am unsure if it is my approach or if it is a bug.

**[(See Slim documentation here)](https://github.com/tensorflow/models/tree/master/slim/)**

(Also, I apologize if this is not a question meant for the issues section. I wasn't getting any feedback on StackOverflow for a couple of days, and this is urgent.) 

Thank you!",haxtar,b'type:support',2017-07-23T08:15:16Z,2017-07-28T16:27:43Z,,,,,,,
2009,"inception: Fix issue #1976, merge mac script","This commit fixes the bug described in issue #1976; it also makes the download_and_preprocess_flowers_mac.sh script redundant by checking whether shuf or gshuf are available. 

Would 2 different PRs be preferred? I could do that, too.",Pibborn,b'cla: yes',2017-07-21T16:32:59Z,2019-10-28T18:29:22Z,,,,,,,
1993,"Resource exhausted: OOM when allocating tensor with shape[2304,384] Traceback (most recent call last):","Please go to Stack Overflow for help and support:

I tried to run models/tutorials/image/cifar10/train.py 
I let it run  about a day on my pc :
(windows10 , tensorflow-gpu 1.2 ,) after 
`2017-07-20 13:58:20.441224: step 941580, loss = 0.14 (3076.2 examples/sec; 0.042 sec/batch)`

`I got this error : 
```
2017-07-20 13:58:20.791379: W c:\tf_jenkins\home\workspace\release-win\m\windows-gpu\py\35\tensorflow\core\framework\op_kernel.cc:1158] Resource exhausted: OOM when allocating tensor with shape[2304,384]
Traceback (most recent call last):
  File ""D:\Anaconda3\lib\site-packages\tensorflow\python\client\session.py"", line 1139, in _do_call
    return fn(*args)
  File ""D:\Anaconda3\lib\site-packages\tensorflow\python\client\session.py"", line 1121, in _run_fn
    status, run_metadata)
  File ""D:\Anaconda3\lib\contextlib.py"", line 66, in __exit__
    next(self.gen)
  File ""D:\Anaconda3\lib\site-packages\tensorflow\python\framework\errors_impl.py"", line 466, in raise_exception_on_not_ok_status
    pywrap_tensorflow.TF_GetCode(status))
tensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[2304,384]
	 [[Node: ExponentialMovingAverage/AssignMovingAvg_4/sub_1 = Sub[T=DT_FLOAT, _class=[""loc:@local3/weights""], _device=""/job:localhost/replica:0/task:0/cpu:0""](local3/weights/ExponentialMovingAverage/read, local3/weights/read)]]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:/Users/Hoda/Documents/GitHub/models/tutorials/image/cifar10/cifar10_train.py"", line 127, in <module>
    tf.app.run()
  File ""D:\Anaconda3\lib\site-packages\tensorflow\python\platform\app.py"", line 48, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""C:/Users/Hoda/Documents/GitHub/models/tutorials/image/cifar10/cifar10_train.py"", line 123, in main
    train()
  File ""C:/Users/Hoda/Documents/GitHub/models/tutorials/image/cifar10/cifar10_train.py"", line 115, in train
    mon_sess.run(train_op)
  File ""D:\Anaconda3\lib\site-packages\tensorflow\python\training\monitored_session.py"", line 505, in run
    run_metadata=run_metadata)
  File ""D:\Anaconda3\lib\site-packages\tensorflow\python\training\monitored_session.py"", line 842, in run
    run_metadata=run_metadata)
  File ""D:\Anaconda3\lib\site-packages\tensorflow\python\training\monitored_session.py"", line 798, in run
    return self._sess.run(*args, **kwargs)
  File ""D:\Anaconda3\lib\site-packages\tensorflow\python\training\monitored_session.py"", line 952, in run
    run_metadata=run_metadata)
  File ""D:\Anaconda3\lib\site-packages\tensorflow\python\training\monitored_session.py"", line 798, in run
    return self._sess.run(*args, **kwargs)
  File ""D:\Anaconda3\lib\site-packages\tensorflow\python\client\session.py"", line 789, in run
    run_metadata_ptr)
  File ""D:\Anaconda3\lib\site-packages\tensorflow\python\client\session.py"", line 997, in _run
    feed_dict_string, options, run_metadata)
  File ""D:\Anaconda3\lib\site-packages\tensorflow\python\client\session.py"", line 1132, in _do_run
    target_list, options, run_metadata)
  File ""D:\Anaconda3\lib\site-packages\tensorflow\python\client\session.py"", line 1152, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[2304,384]
	 [[Node: ExponentialMovingAverage/AssignMovingAvg_4/sub_1 = Sub[T=DT_FLOAT, _class=[""loc:@local3/weights""], _device=""/job:localhost/replica:0/task:0/cpu:0""](local3/weights/ExponentialMovingAverage/read, local3/weights/read)]]

Caused by op 'ExponentialMovingAverage/AssignMovingAvg_4/sub_1', defined at:
  File ""C:/Users/Hoda/Documents/GitHub/models/tutorials/image/cifar10/cifar10_train.py"", line 127, in <module>
    tf.app.run()
  File ""D:\Anaconda3\lib\site-packages\tensorflow\python\platform\app.py"", line 48, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""C:/Users/Hoda/Documents/GitHub/models/tutorials/image/cifar10/cifar10_train.py"", line 123, in main
    train()
  File ""C:/Users/Hoda/Documents/GitHub/models/tutorials/image/cifar10/cifar10_train.py"", line 79, in train
    train_op = cifar10.train(loss, global_step)
  File ""C:\Users\Hoda\Documents\GitHub\models\tutorials\image\cifar10\cifar10.py"", line 373, in train
    variables_averages_op = variable_averages.apply(tf.trainable_variables())
  File ""D:\Anaconda3\lib\site-packages\tensorflow\python\training\moving_averages.py"", line 392, in apply
    self._averages[var], var, decay, zero_debias=zero_debias))
  File ""D:\Anaconda3\lib\site-packages\tensorflow\python\training\moving_averages.py"", line 72, in assign_moving_average
    update_delta = (variable - value) * decay
  File ""D:\Anaconda3\lib\site-packages\tensorflow\python\ops\variables.py"", line 694, in _run_op
    return getattr(ops.Tensor, operator)(a._AsTensor(), *args)
  File ""D:\Anaconda3\lib\site-packages\tensorflow\python\ops\math_ops.py"", line 838, in binary_op_wrapper
    return func(x, y, name=name)
  File ""D:\Anaconda3\lib\site-packages\tensorflow\python\ops\gen_math_ops.py"", line 2501, in _sub
    result = _op_def_lib.apply_op(""Sub"", x=x, y=y, name=name)
  File ""D:\Anaconda3\lib\site-packages\tensorflow\python\framework\op_def_library.py"", line 767, in apply_op
    op_def=op_def)
  File ""D:\Anaconda3\lib\site-packages\tensorflow\python\framework\ops.py"", line 2510, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""D:\Anaconda3\lib\site-packages\tensorflow\python\framework\ops.py"", line 1273, in __init__
    self._traceback = _extract_stack()

ResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[2304,384]
	 [[Node: ExponentialMovingAverage/AssignMovingAvg_4/sub_1 = Sub[T=DT_FLOAT, _class=[""loc:@local3/weights""], _device=""/job:localhost/replica:0/task:0/cpu:0""](local3/weights/ExponentialMovingAverage/read, local3/weights/read)]]
```

`how can I fix it? and do I have to run it again from or the previous result is saved? 
ibe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

",ehfo0,None,2017-07-20T09:56:01Z,2020-09-20T09:39:43Z,,,,,,,
1936,eval.py stuck: The following classes have no ground truth examples,"I got the follow result after running:

# modify the config file for the right path
PATH_TO_YOUR_PIPELINE_CONFIG=""object_detection/samples/configs/faster_rcnn_resnet101_voc07.config""
PATH_TO_TRAIN_DIR=""out""
PATH_TO_EVAL_DIR=""out""

# From the tensorflow/models/ directory
GPU_ID=1
CUDA_VISIBLE_DEVICES=${GPU_ID} python object_detection/eval.py --debug\
    --logtostderr \
    --pipeline_config_path=${PATH_TO_YOUR_PIPELINE_CONFIG} \
    --checkpoint_dir=${PATH_TO_TRAIN_DIR} \
    --eval_dir=${PATH_TO_EVAL_DIR}




**WARNING:root:The following classes have no ground truth examples: [ 0  2  3  8  9 11 13 14 16 17 18]**
/local/home/cpchung/software/models/object_detection/utils/metrics.py:145: RuntimeWarning: invalid value encountered in true_divide
  num_images_correctly_detected_per_class / num_gt_imgs_per_class)



Where can I find the result of this evalution?
",chakpongchung,None,2017-07-12T20:54:04Z,2020-02-07T18:42:24Z,,,,,,,
1916,object detection export inference graph error when RPN_only ,"When I set first_stage_only = true in my config file, it trains well. However, when I try to use export_inference_graph.py to export the trained model for inference, there is a bug:
> Traceback (most recent call last):
>   File ""export_inference_graph.py"", line 101, in <module>
>     tf.app.run()
>   File ""/home/linhb/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/platform/app.py"", line 48, in run
>     _sys.exit(main(_sys.argv[:1] + flags_passthrough))
>   File ""export_inference_graph.py"", line 97, in main
>     FLAGS.export_as_saved_model)
>   File ""/home/linhb/horse/models/object_detection/exporter.py"", line 339, in export_inference_graph
>     export_as_saved_model)
>   File ""/home/linhb/horse/models/object_detection/exporter.py"", line 310, in _export_inference_graph
>     outputs = _add_output_tensor_nodes(postprocessed_tensors)
>   File ""/home/linhb/horse/models/object_detection/exporter.py"", line 184, in _add_output_tensor_nodes
>     classes = postprocessed_tensors.get('detection_classes') + label_id_offset
> TypeError: unsupported operand type(s) for +: 'NoneType' and 'int'

That's due to the output detection_classes is None when using first_stage_only. I change the code in `exporter.py`, line184, from,
`classes = postprocessed_tensors.get('detection_classes')+label_id_offset`
to,
```
classes = postprocessed_tensors.get('detection_classes') 
if classes: 
    classes += label_id_offset 
else:
    classes = tf.constant(1, tf.int32, scores.shape)
```
then the program can run correctly.",YuxianMeng,b'stat:awaiting response',2017-07-11T03:11:25Z,2019-04-10T12:56:37Z,,,,,,,
1906,object detection label map,"default label map config in object_detection.data label_map.pbtxts starts from index0, however, the program results in 'Label map ids should be >= 1'.
Change the label map id start from 1 could fix the bug.
For example,  the id in pet_label_map.pbtxt are from 0 to 37. Change the id of class 'none_of_the_above' to 38, then the bug should be fixed
",YuxianMeng,None,2017-07-10T10:33:01Z,2017-07-11T17:11:28Z,,,,,,,
1876,API ObjectDetection size of  input images issues ,"**GPU  : GeForce GTX 1080 Ti/PCIe/SSE2 (11 GB)**
**Tensorflow version: 1.1.0**
**Python version: 2.7.12**
**Model checkpoint : ssd_mobilenet_v1_coco_11_06_2017**

**Context** :After read the tutorial of ObjectDetection, I converted my own image data sets to tfRecord files by create the *.xml file to each image. As the sizes of images of my own data sets are very large : about **width=4000pixels** and **height=2000pixels** for each , the train.tfRecord is about **55G**.

**Issues**: When I began to train with **train.py** by using the lightest model  **ssd_mobilenet_v1_coco_11_06_2017**, after 4-5 steps, it crashed by error OOM.
The error message is below:
![125](https://user-images.githubusercontent.com/29950360/27914310-08056dd6-6263-11e7-83ca-8249a3ff0c9a.png)
Il seems like that the OOM error happened when allocating tensor with shape[1,2969,3546,3],
As the capacity of my GPU is 11GB, I didn't understand why it causes this problem..





",chenyuZha,b'stat:awaiting model gardener type:bug',2017-07-06T14:06:43Z,2020-07-07T14:37:25Z,,,,,,,
1873,Fix preprocessing bugs,1. tf.constant could not accept a proto field correctly. 2. height/width should be int32 instead of float,hjp709394,b'cla: yes stat:awaiting review',2017-07-06T09:23:41Z,2019-10-28T18:28:42Z,,,,,,,
1872,Fix augmentation bugs,"1. For random_resize_method, float height / width would cause errors becuase tf.image.resize_images require a int32 Tensor for parameter size. 
2. For subtract_channel_mean, tf.constant could not accept a protobuf field. ",hjp709394,b'cla: no',2017-07-06T08:55:24Z,2017-07-06T09:00:51Z,,,,,,,
1863,Unable to train on custom dataset (Object Detection),"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: Source
- **TensorFlow version (use command below)**: 1.0.1
- **Python version**:  2.7.12
- **Bazel version (if compiling from source)**: 0.4.2
- **CUDA/cuDNN version**: CUDA 8.0, not sure cuDNN version
- **GPU model and memory**: TITAN X (Pascal), 12188MiB
- **Exact command to reproduce**: N/A

### Describe the problem
I am unable to train any of the pre-trained models on my own dataset. For testing purposes, i constructed a training dataset with only 1 image, so the model should simply learn to memorize that image's objects. This image is also used for the ""test"" set. Also, to make things simpler, I'm using only one class (cars) for detection.

I trained on this image with the SSD mobilenet and inception networks (and then tried again with Faster R-CNN, to the same results). Each model converged, or at least the loss went to 0. See below for training logs. However, when I ran `eval.py` on the latest saved model checkpoint, every single time it returns a `mAP` of 0.0. I froze the models using the `export_inference_graph.py` script, and output their detections using the iPython notebook and there are 25+ boxes, none of which are near any of the 9 cars in the image. 

I modified `trainer.py` so that it saves my model's checkpoint every minute of training, this way I don't have to wait until the saver decides to save the checkpoint. This was the only modification I made to `trainer` or any of the training scripts.

To construct my dataset, I used a custom script that took our annotations/labels and output them into TFRecords, the same way the examples did it. In my script, to be sure nothing weird was going on, I printed out the TFExample I wrote to file right before writing it. Below is the TFExample with the bytes_list omitted due to its size.

I've been debugging this issue for days.. Strangely, I _am_ able to successfully train on the PETS dataset and the model appears to learn something when training on it. I'm really confused what I did wrong and what is making the model's loss go to 0 when it clearly isn't learning anything. Thanks for any help!

### Source code / logs

```features {
feature {
  key: ""image/encoded""
  value {
    bytes_list {
      value: ""<BYTES_LIST>""
    }
  }
}
feature {
  key: ""image/filename""
  value {
    bytes_list {
      value: ""582ff3acfb29d4001bba1d92.jpg""
    }
  }
}
feature {
  key: ""image/format""ue: 0
      value: 0
      value: 0
      value: 0
      value: 0
      value: 0
      value: 0
      value: 0
      value: 
  value {
    bytes_list {
      value: ""jpeg""
    }
  }
}
feature {
  key: ""image/height""
  value {
    int64_list {
      value: 504
    }
  }
}
feature {
  key: ""image/key/sha256""
  value {
    bytes_list {
      value: ""bde189df7bd931838ded79f2b52054d94c39b8b76e3b105363bed87ff4231c64""
    }
  }
}
feature {
  key: ""image/object/bbox/xmax""
  value {
    float_list {
      value: 0.991781949997
      value: 0.98629707098
      value: 0.783108830452
      value: 0.73282623291
      value: 0.560007512569
      value: 0.530334770679
      value: 0.35382014513
      value: 0.574932456017
      value: 0.275806516409
    }
  }
}
feature {
  key: ""image/object/bbox/xmin""
  value {
    float_list {
      value: 0.732768774033
      value: 0.871232867241
      value: 0.709041059017
      value: 0.565873265266
      value: 0.524092078209
      value: 0.449410796165
      value: 0.282586842775
      value: 0.555617213249
      value: 0.259866952896
    }
  }
}
feature {
  key: ""image/object/bbox/ymax""
  value {
    float_list {
      value: 0.818147242069
      value: 0.642841875553
      value: 0.698197245598
      value: 0.788145005703
      value: 0.680336654186
      value: 0.729095876217
      value: 0.676592707634
      value: 0.680128872395
      value: 0.676128447056
    }
  }
}
feature {
  key: ""image/object/bbox/ymin""
  value {
    float_list {
      value: 0.589852809906
      value: 0.573962926865
      value: 0.596921443939
      value: 0.579189062119
      value: 0.625779926777
      value: 0.605418324471
      value: 0.624974191189
      value: 0.642448067665
      value: 0.634556055069
    }
  }
}
feature {
  key: ""image/object/class/label""
  value {
    int64_list {
      value: 0
      value: 0
      value: 0
      value: 0
      value: 0
      value: 0
      value: 0
      value: 0
      value: 0
    }
  }
}
feature {
  key: ""image/object/class/text""
  value {
    bytes_list {
      value: ""car""
      value: ""car""
      value: ""car""
      value: ""car""
      value: ""car""
      value: ""car""
      value: ""car""
      value: ""car""
      value: ""car""
    }
  }
}
feature {
  key: ""image/object/difficult""
  value {
    int64_list {
      value: 0
      value: 0
      value: 0
      value: 0
      value: 0
      value: 0
      value: 0
      value: 0
      value: 0
    }
  }
}
feature {
  key: ""image/object/truncated""
  value {
    int64_list {
      value: 0
      value: 0
      value: 0
      value: 0
      value: 0
      value: 0
      value: 0
      value: 0
      value: 0
    }
  }
}
feature {
  key: ""image/object/view""
  value {
    bytes_list {
      value: ""Unspecified""
      value: ""Unspecified""
      value: ""Unspecified""
      value: ""Unspecified""
      value: ""Unspecified""
      value: ""Unspecified""
      value: ""Unspecified""
      value: ""Unspecified""
      value: ""Unspecified""
    }
  }
}
feature {
  key: ""image/source_id""
  value {
    bytes_list {
      value: ""582ff3acfb29d4001bba1d92.jpg""
    }
  }
}
feature {
  key: ""image/width""
  value {
    int64_list {
      value: 960
    }
  }
}
}
```


Train logs
```tplump@tplump:/usr/local/lib/python2.7/dist-packages/tensorflow/models$ python object_detection/train.py --logtostdout --pipeline_config_path=<MY_CONFIG_PATH> --train_dir=<MY_TRAIN_DIR>
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcudnn.so.6 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.so.8.0 locally
INFO:tensorflow:Scale of 0 disables regularizer.
INFO:tensorflow:Scale of 0 disables regularizer.
INFO:tensorflow:Scale of 0 disables regularizer.
INFO:tensorflow:Scale of 0 disables regularizer.
INFO:tensorflow:Summary name Learning Rate is illegal; using Learning_Rate instead.
WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/models/object_detection/meta_architectures/ssd_meta_arch.py:579: all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.
Instructions for updating:
Please use tf.global_variables instead.
INFO:tensorflow:Summary name /clone_loss is illegal; using clone_loss instead.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE3 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
I tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with properties: 
name: TITAN X (Pascal)
major: 6 minor: 1 memoryClockRate (GHz) 1.531
pciBusID 0000:01:00.0
Total memory: 11.90GiB
Free memory: 11.26GiB
I tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0:   Y 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: TITAN X (Pascal), pci bus id: 0000:01:00.0)
I tensorflow/core/common_runtime/simple_placer.cc:669] Ignoring device specification /GPU:0 for node 'prefetch_queue_Dequeue' because the input edge from 'prefetch_queue' is a reference connection and already has a device field set to /CPU:0
I tensorflow/compiler/xla/service/platform_util.cc:58] platform CUDA present with 1 visible devices
I tensorflow/compiler/xla/service/platform_util.cc:58] platform Host present with 12 visible devices
I tensorflow/compiler/xla/service/service.cc:180] XLA service executing computations on platform Host. Devices:
I tensorflow/compiler/xla/service/service.cc:187]   StreamExecutor device (0): <undefined>, <undefined>
I tensorflow/compiler/xla/service/platform_util.cc:58] platform CUDA present with 1 visible devices
I tensorflow/compiler/xla/service/platform_util.cc:58] platform Host present with 12 visible devices
I tensorflow/compiler/xla/service/service.cc:180] XLA service executing computations on platform CUDA. Devices:
I tensorflow/compiler/xla/service/service.cc:187]   StreamExecutor device (0): TITAN X (Pascal), Compute Capability 6.1
INFO:tensorflow:Starting Session.
INFO:tensorflow:Starting Queues.
INFO:tensorflow:global_step/sec: 0
INFO:tensorflow:global step 1: loss = 5.8670 (8.34 sec/step)
INFO:tensorflow:global step 2: loss = 5.7140 (1.68 sec/step)
INFO:tensorflow:global step 3: loss = 3.9298 (1.92 sec/step)
INFO:tensorflow:global step 4: loss = 3.0551 (1.89 sec/step)
INFO:tensorflow:global step 5: loss = 1.4610 (1.90 sec/step)
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 10618 get requests, put_count=10614 evicted_count=1000 eviction_rate=0.0942152 and unsatisfied allocation rate=0.103974
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:259] Raising pool_size_limit_ from 100 to 110
INFO:tensorflow:global step 6: loss = 0.0000 (1.93 sec/step)
INFO:tensorflow:global step 7: loss = 0.0000 (1.84 sec/step)
INFO:tensorflow:global step 8: loss = 0.0000 (1.87 sec/step)
INFO:tensorflow:global step 9: loss = 0.0000 (1.89 sec/step)
INFO:tensorflow:global step 10: loss = 0.0000 (1.89 sec/step)
INFO:tensorflow:global step 11: loss = 0.0000 (1.81 sec/step)
INFO:tensorflow:global step 12: loss = 0.0000 (1.94 sec/step)
INFO:tensorflow:global step 13: loss = 0.0000 (1.78 sec/step)
INFO:tensorflow:global step 14: loss = 0.0000 (1.85 sec/step)
INFO:tensorflow:global step 15: loss = 0.0000 (1.71 sec/step)
INFO:tensorflow:global step 16: loss = 0.0000 (1.69 sec/step)
INFO:tensorflow:global step 17: loss = 0.0000 (1.93 sec/step)
INFO:tensorflow:global step 18: loss = 0.0000 (1.78 sec/step)
INFO:tensorflow:global step 19: loss = 0.0000 (1.90 sec/step)
INFO:tensorflow:global step 20: loss = 0.0000 (1.89 sec/step)
INFO:tensorflow:global step 21: loss = 0.0000 (1.90 sec/step)
INFO:tensorflow:global step 22: loss = 0.0000 (1.92 sec/step)
INFO:tensorflow:global step 23: loss = 0.0000 (1.85 sec/step)
INFO:tensorflow:global step 24: loss = 0.0000 (1.90 sec/step)
INFO:tensorflow:global step 25: loss = 0.0000 (1.93 sec/step)
INFO:tensorflow:global step 26: loss = 0.0000 (1.93 sec/step)
INFO:tensorflow:global step 27: loss = 0.0000 (1.80 sec/step)
INFO:tensorflow:global step 28: loss = 0.0000 (1.78 sec/step)
INFO:tensorflow:global step 29: loss = 0.0000 (1.74 sec/step)
INFO:tensorflow:global step 30: loss = 0.0000 (1.82 sec/step)
INFO:tensorflow:global step 31: loss = 0.0000 (1.89 sec/step)
INFO:tensorflow:global step 32: loss = 0.0000 (1.90 sec/step)
INFO:tensorflow:global step 33: loss = 0.0000 (1.79 sec/step)
INFO:tensorflow:global step 34: loss = 0.0000 (1.77 sec/step)
INFO:tensorflow:global step 35: loss = 0.0000 (1.94 sec/step)
INFO:tensorflow:global step 36: loss = 0.0000 (1.76 sec/step)
INFO:tensorflow:global step 37: loss = 0.0000 (1.86 sec/step)
```

SSD_mobilenet config:
```# SSD with Mobilenet v1, configured for Oxford-IIT Pets Dataset.
# Users should configure the fine_tune_checkpoint field in the train config as
# well as the label_map_path and input_path fields in the train_input_reader and
# eval_input_reader. Search for ""PATH_TO_BE_CONFIGURED"" to find the fields that
# should be configured.

model {
  ssd {
    num_classes: 1
    box_coder {
      faster_rcnn_box_coder {
        y_scale: 10.0
        x_scale: 10.0
        height_scale: 5.0
        width_scale: 5.0
      }
    }
    matcher {
      argmax_matcher {
        matched_threshold: 0.5
        unmatched_threshold: 0.5
        ignore_thresholds: false
        negatives_lower_than_unmatched: true
        force_match_for_each_row: true
      }
    }
    similarity_calculator {
      iou_similarity {
      }
    }
    anchor_generator {
      ssd_anchor_generator {
        num_layers: 6
        min_scale: 0.2
        max_scale: 0.95
        aspect_ratios: 1.0
        aspect_ratios: 2.0
        aspect_ratios: 0.5
        aspect_ratios: 3.0
        aspect_ratios: 0.3333
      }
    }
    image_resizer {
      fixed_shape_resizer {
        height: 504
        width: 960
      }
    }
    box_predictor {
      convolutional_box_predictor {
        min_depth: 0
        max_depth: 0
        num_layers_before_predictor: 0
        use_dropout: false
        dropout_keep_probability: 0.8
        kernel_size: 1
        box_code_size: 4
        apply_sigmoid_to_scores: false
        conv_hyperparams {
          activation: RELU_6,
          regularizer {
            l2_regularizer {
              weight: 0.00000
            }
          }
          initializer {
            truncated_normal_initializer {
              stddev: 0.03
              mean: 0.0
            }
          }
          batch_norm {
            train: true,
            scale: true,
            center: true,
            decay: 0.9997,
            epsilon: 0.001,
          }
        }
      }
    }
    feature_extractor {
      type: 'ssd_mobilenet_v1'
      min_depth: 16
      depth_multiplier: 1.0
      conv_hyperparams {
        activation: RELU_6,
        regularizer {
          l2_regularizer {
            weight: 0.0000
          }
        }
        initializer {
          truncated_normal_initializer {
            stddev: 0.03
            mean: 0.0
          }
        }
        batch_norm {
          train: true,
          scale: true,
          center: true,
          decay: 0.9997,
          epsilon: 0.001,
        }
      }
    }
    loss {
      classification_loss {
        weighted_sigmoid {
          anchorwise_output: true
        }
      }
      localization_loss {
        weighted_smooth_l1 {
          anchorwise_output: true
        }
      }
      hard_example_miner {
        num_hard_examples: 3000
        iou_threshold: 0.99
        loss_type: CLASSIFICATION
        max_negatives_per_positive: 3
        min_negatives_per_image: 0
      }
      classification_weight: 1.0
      localization_weight: 1.0
    }
    normalize_loss_by_num_matches: true
    post_processing {
      batch_non_max_suppression {
        score_threshold: 1e-8
        iou_threshold: 0.6
        max_detections_per_class: 100
        max_total_detections: 100
      }
      score_converter: SIGMOID
    }
  }
}

train_config: {
  batch_size: 1
  optimizer {
    rms_prop_optimizer: {
      learning_rate: {
        exponential_decay_learning_rate {
          initial_learning_rate: 0.0004
          decay_steps: 800720
          decay_factor: 0.95
        }
      }
      momentum_optimizer_value: 0.9
      decay: 0.9
      epsilon: 1.0
    }
  }
  fine_tune_checkpoint: ""PATH_TO_PRETRAINED_MODEL""
  from_detection_checkpoint: true
}

train_input_reader: {
  tf_record_input_reader {
    input_path: ""INSERT_PATH_HERE""
  }
  label_map_path: ""INSERT_PATH_HERE""
}

eval_config: {
  num_examples: 200
}

eval_input_reader: {
  tf_record_input_reader {
    input_path: ""INSERT_PATH_HERE""
  }
  label_map_path: ""INSERT_PATH_HERE""
}
```",timisplump,None,2017-07-05T17:52:11Z,2018-02-22T13:30:04Z,,,,,,,
1858,rnn/ptb TypeError: bytes-like object is required,"Good morning !

I am working using Windows and I use python 3.5, and Tensorflow 1.0.1 and I only use a CPU.
I am trying to run the latest version of the rnn/ptb tutorial code.

When I run the command : python ptb_word_lm.py --data_path=./simple-examples/data --model=small
I always have a TypeError : a bytes-like object is required, not 'str'

```
C:\Users\efbarrier\AppData\Local\Continuum\Anaconda3\envs\tensorflow\models\tuto
rials\rnn\ptb>python ptb_word_lm.py --data_path=./simple-examples/data --model=s
mall
Traceback (most recent call last):
  File ""ptb_word_lm.py"", line 395, in <module>
    tf.app.run()
  File ""C:\Users\efbarrier\AppData\Local\Continuum\Anaconda3\lib\site-packages\t
ensorflow\python\platform\app.py"", line 44, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""ptb_word_lm.py"", line 342, in main
    raw_data = reader.ptb_raw_data(FLAGS.data_path)
  File ""C:\Users\efbarrier\AppData\Local\Continuum\Anaconda3\envs\tensorflow\mod
els\tutorials\rnn\ptb\reader.py"", line 77, in ptb_raw_data
    word_to_id = _build_vocab(train_path)
  File ""C:\Users\efbarrier\AppData\Local\Continuum\Anaconda3\envs\tensorflow\mod
els\tutorials\rnn\ptb\reader.py"", line 38, in _build_vocab
    data = _read_words(filename)
  File ""C:\Users\efbarrier\AppData\Local\Continuum\Anaconda3\envs\tensorflow\mod
els\tutorials\rnn\ptb\reader.py"", line 32, in _read_words
    return f.read().replace(""\n"", ""<eos>"").split()
TypeError: a bytes-like object is required, not 'str'
```
I think that there is a bug in the code, but I don't find where because I don't have enough experience using Tensorflow.
Could you help me ? Thank you very much.

Regards, Emeric",EmericELninja,b'stat:awaiting model gardener',2017-07-05T08:13:39Z,2017-09-01T23:48:47Z,,,,,,,
1834,"How to fix the bug “Expected ""required"", ""optional"", or ""repeated"".”？","When I use the commond "" protoc object_detection/protos/*.proto --python_out=."",
The output:
object_detection/protos/anchor_generator.proto:11:3: Expected ""required"", ""optio                                                                                      nal"", or ""repeated"".
object_detection/protos/anchor_generator.proto:11:32: Missing field number.

",amazingzby,b'type:build/install',2017-07-02T07:01:09Z,2018-04-18T19:53:26Z,,,,,,,
1826,SyntaxNet: free(): invalid pointer: 0x0000000002a27078,"System information:
tensorflow version: 1.2.1
tf.GIT_VERSION = v1.2.0-5-g435cdfc
tf.COMPILER_VERSION = v1.2.0-5-g435cdfc
protobuf version: 3.3.0
numpy version: 1.13.0
My own machine OS: Ubuntu 16.04.2 LTS
bazel version: 0.5.2
Python version: 2.7.12

I got the error while trying to run first cell of [the SyntaxNet example notebook](https://github.com/tensorflow/models/blob/master/syntaxnet/examples/dragnn/interactive_text_analyzer.ipynb).

I has also tried to fix the bug by installing libtcmalloc-minimal4 (follow [this issues](https://github.com/tensorflow/tensorflow/issues/9328)). But the bug is still present.

For installing SyntaxNet, I successfully followed the [manual installation](https://github.com/tensorflow/models/tree/master/syntaxnet). 

*** Error in `/usr/bin/python2': free(): invalid pointer: 0x0000000002347d38 ***
======= Backtrace: =========
/lib/x86_64-linux-gnu/libc.so.6(+0x777e5)[0x7f2e9aed47e5]
/lib/x86_64-linux-gnu/libc.so.6(+0x8037a)[0x7f2e9aedd37a]
/lib/x86_64-linux-gnu/libc.so.6(cfree+0x4c)[0x7f2e9aee153c]
/usr/local/lib/python2.7/dist-packages/syntaxnet/parser_ops.so(+0x338ad8)[0x7f2e668faad8]
/lib64/ld-linux-x86-64.so.2(+0x106ba)[0x7f2e9b4546ba]
....

Thanks",thanhlct,b'stat:awaiting model gardener type:build/install',2017-06-30T10:01:06Z,2018-10-31T20:59:24Z,,,,,,,
1823,Tf slim run error,"Systeme Information

OS Platform and Distribution: Linux Ubuntu 14.04 LTS
TensorFlow installed from: pip tensorflow-gpu
TensorFlow version: ('v1.2.0-rc2-21-g12f033d', '1.2.0')
CUDA/cuDNN version: Cuda 8.0, Cudnn 5.1
GPU model and memory: titan x pascal 12gb
------------------------



### Describe the problem

I'm trying to run Tf slim image classifier with following URL
https://github.com/tensorflow/models/tree/master/slim


python train_image_classifier.py 
    --train_dir= /home/sk/workspace/slim/datasets/log
    --dataset_name=flowers
    --dataset_split_name=train 
    --dataset_dir=/home/sk/workspace/slim/datasets/flowers 
    --model_name=inception_v3

below is error, i think is about gpu hardware problem but it works perfectly fine with TFlearn of tensorflow example code, only tf slim doesn't work
i reinstalled tensorflow and cudnn but I can't fix it
what is cause of this problem?

### Source code / logs
Caused by op u'InceptionV3/Logits/Conv2d_1c_1x1/biases/RMSProp_1', defined at:
  File ""/home/sk/workspace/slim/train_image_classifier.py"", line 573, in <module>
    tf.app.run()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 48, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""/home/sk/workspace/slim/train_image_classifier.py"", line 539, in main
    global_step=global_step)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/optimizer.py"", line 446, in apply_gradients
    self._create_slots([_get_variable_for(v) for v in var_list])
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/rmsprop.py"", line 103, in _create_slots
    self._zeros_slot(v, ""momentum"", self._name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/optimizer.py"", line 766, in _zeros_slot
    named_slots[_var_key(var)] = slot_creator.create_zeros_slot(var, op_name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/slot_creator.py"", line 174, in create_zeros_slot
    colocate_with_primary=colocate_with_primary)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/slot_creator.py"", line 146, in create_slot_with_initializer
    dtype)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/slot_creator.py"", line 66, in _create_slot_var
    validate_shape=validate_shape)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variable_scope.py"", line 1049, in get_variable
    use_resource=use_resource, custom_getter=custom_getter)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variable_scope.py"", line 948, in get_variable
    use_resource=use_resource, custom_getter=custom_getter)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variable_scope.py"", line 356, in get_variable
    validate_shape=validate_shape, use_resource=use_resource)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variable_scope.py"", line 341, in _true_getter
    use_resource=use_resource)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variable_scope.py"", line 714, in _get_single_variable
    validate_shape=validate_shape)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variables.py"", line 197, in __init__
    expected_shape=expected_shape)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variables.py"", line 281, in _init_from_args
    name=name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/state_ops.py"", line 128, in variable_op_v2
    shared_name=shared_name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_state_ops.py"", line 708, in _variable_v2
    name=name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py"", line 768, in apply_op
    op_def=op_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 2336, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 1228, in __init__
    self._traceback = _extract_stack()

InvalidArgumentError (see above for traceback): Cannot assign a device to node 'InceptionV3/Logits/Conv2d_1c_1x1/biases/RMSProp_1': Could not satisfy explicit device specification '/device:GPU:0' because no devices matching that specification are registered in this process; available devices: /job:localhost/replica:0/task:0/cpu:0
Colocation Debug Info:
Colocation group had the following types and devices: 
ApplyRMSProp: CPU 
Const: CPU 
Assign: CPU 
IsVariableInitialized: CPU 
Identity: CPU 
VariableV2: CPU 
     [[Node: InceptionV3/Logits/Conv2d_1c_1x1/biases/RMSProp_1 = VariableV2[_class=[""loc:@InceptionV3/Logits/Conv2d_1c_1x1/biases""], container="""", dtype=DT_FLOAT, shape=[3], shared_name="""", _device=""/device:GPU:0""]()]]

nvidia-smi  status

-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  TITAN X (Pascal)    Off  | 0000:01:00.0      On |                  N/A |
| 23%   30C    P8    10W / 250W |    313MiB / 12181MiB |      5%      Default |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID  Type  Process name                               Usage      |
|=============================================================================|
|    0      1056    G   /usr/lib/xorg/Xorg                             212MiB |
|    0      1655    G   compiz                                          98MiB |
+-----------------------------------------------------------------------------+

nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2016 NVIDIA Corporation
Built on Tue_Jan_10_13:22:03_CST_2017
Cuda compilation tools, release 8.0, V8.0.61

",sukkyusun,b'stat:community support type:support',2017-06-30T06:22:46Z,2018-11-22T03:16:49Z,,,,,,,
1822,Fix CDNA transformation bug and speed up its implementation.,"- Fix CDNA transformation bug where transformed channels of color and masks were combined incorrectly.
- Remove for loop over batch size in implementation of CDNA transformation. This speeds up the building of the graph.

@cbfinn ",alexlee-gk,b'cla: yes',2017-06-30T01:14:50Z,2017-06-30T23:45:35Z,,,,,,,
1817,Out Of Memory when training on Big Images,"# Out Of Memory when training on Big Images

### Systeme Information
- **OS Platform and Distribution**: Linux Ubuntu 16.04 LTS
- **TensorFlow installed from**: pip tensorflow-gpu
- **TensorFlow version**: ('v1.2.0-rc2-21-g12f033d', '1.2.0')
- **CUDA/cuDNN version**: Cuda 8.0, Cudnn 5.1
- **GPU model and memory**: 8 Tesla K-80, Cores 2, Memory 7.5 G


### Describe the Problem
I have successfully run the pets tutorial on this Google Compute Instance
When I train a fasterrcnn resnet 101 on my dataset (VOC format, 47 classes, image_size: 1000/2000) with:
```sh
python object_detection/train.py --train_dir=data_xxxx --pipeline_config_path=data_xxxx/faster_rcnn_resnet101_pets.config
```
I get the following error at the beginning of the training:
```
2017-06-29 17:24:13.193833: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:7) -> (device: 7, name: Tesla K80, pci bus id: 0000:00:0b.0)
2017-06-29 17:24:15.414228: I tensorflow/core/common_runtime/simple_placer.cc:675] Ignoring device specification /device:GPU:0 for node 'prefetch_queue_Dequeue' because the input edge from 'prefetch_queue' is a reference connection and already has a device field set to /device:CPU:0
INFO:tensorflow:Restoring parameters from /home/ubuntu/models/data_xxxx/model.ckpt
INFO:tensorflow:Starting Session.
INFO:tensorflow:Saving checkpoint to path data_doliprane/model.ckpt
INFO:tensorflow:Starting Queues.
INFO:tensorflow:global_step/sec: 0
[1]    4359 killed     python object_detection/train.py --train_dir=data_xxxx 
``` 

__I managed to avoid the oom on this dataset by resizing all the images and annotation files (divided the dimensions by 4).__

__I didn't modify the config file(just the number of class and the paths), therefore they should be resized at 600 1024, and the bug should not occur with the big images__

Is there a way I can train on my images without having to shrink them? Are there some parameters I can tune to avoid this problem? 




",pjeambrun,None,2017-06-29T18:29:39Z,2020-06-12T16:04:16Z,,,,,,,
1795,Object Detection Training not reading in batch norm parameters,"I was following the directions to train a ssd_mobilenet model that trains the detection network from scratch after initializing the backbone with the weights of a model trained on Imagenet. I downloaded the pre-trained mobilenet checkpoint for this experiment. However, I get warning messages complaining that the batch norm parameters could not be loaded (see below for the messages). Has anyone else seen this issue or any pointers on how I can try to debug it?  

Below I show my train_config to set up the experiment from the stock one given in the detection library and the warning messages I see about not reading in 

train_config: {
  batch_size: 24
  optimizer {
    rms_prop_optimizer: {
      learning_rate: {
        exponential_decay_learning_rate {
          initial_learning_rate: 0.001
          decay_steps: 800720
          decay_factor: 0.95
        }
      }
      momentum_optimizer_value: 0.9
      decay: 0.9
      epsilon: 1.0
    }
  }
  fine_tune_checkpoint: ""/raid/gavenkatesh/Networks/tensorflowModels/models/object_detection/modelImagenet/mobilenet_v1_1.0_224.ckpt""
  from_detection_checkpoint: false
  data_augmentation_options {
    random_horizontal_flip {
    }
  }
  data_augmentation_options {
    ssd_random_crop {
    }
  }
}

**Warning messages:**
WARNING:root:Variable [MobilenetV1/Conv2d_13_pointwise_1_Conv2d_2_1x1_256/BatchNorm/beta] not available in checkpoint
WARNING:root:Variable [MobilenetV1/Conv2d_13_pointwise_1_Conv2d_2_1x1_256/BatchNorm/gamma] not available in checkpoint
WARNING:root:Variable [MobilenetV1/Conv2d_13_pointwise_1_Conv2d_2_1x1_256/BatchNorm/moving_mean] not available in checkpoint
WARNING:root:Variable [MobilenetV1/Conv2d_13_pointwise_1_Conv2d_2_1x1_256/BatchNorm/moving_variance] not available in checkpoint
WARNING:root:Variable [MobilenetV1/Conv2d_13_pointwise_1_Conv2d_2_1x1_256/weights] not available in checkpoint
WARNING:root:Variable [MobilenetV1/Conv2d_13_pointwise_1_Conv2d_3_1x1_128/BatchNorm/beta] not available in checkpoint
WARNING:root:Variable [MobilenetV1/Conv2d_13_pointwise_1_Conv2d_3_1x1_128/BatchNorm/gamma] not available in checkpoint
WARNING:root:Variable [MobilenetV1/Conv2d_13_pointwise_1_Conv2d_3_1x1_128/BatchNorm/moving_mean] not available in checkpoint
WARNING:root:Variable [MobilenetV1/Conv2d_13_pointwise_1_Conv2d_3_1x1_128/BatchNorm/moving_variance] not available in checkpoint
WARNING:root:Variable [MobilenetV1/Conv2d_13_pointwise_1_Conv2d_3_1x1_128/weights] not available in checkpoint
WARNING:root:Variable [MobilenetV1/Conv2d_13_pointwise_1_Conv2d_4_1x1_128/BatchNorm/beta] not available in checkpoint
WARNING:root:Variable [MobilenetV1/Conv2d_13_pointwise_1_Conv2d_4_1x1_128/BatchNorm/gamma] not available in checkpoint
WARNING:root:Variable [MobilenetV1/Conv2d_13_pointwise_1_Conv2d_4_1x1_128/BatchNorm/moving_mean] not available in checkpoint
WARNING:root:Variable [MobilenetV1/Conv2d_13_pointwise_1_Conv2d_4_1x1_128/BatchNorm/moving_variance] not available in checkpoint
WARNING:root:Variable [MobilenetV1/Conv2d_13_pointwise_1_Conv2d_4_1x1_128/weights] not available in checkpoint
 



### System information
- **What is the top-level directory of the model you are using**: object_detection
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: Source
- **TensorFlow version (use command below)**:1.2
- **Bazel version (if compiling from source)**: 0.5.1
- **CUDA/cuDNN version**: CUDA 8.0, CUDNN 6.0
- **GPU model and memory**: GP100 with 16 GB memory
- **Exact command to reproduce**: I am using the vanilla train.py command from the object detection README: python object_detection/train.py --logtostderr --pipeline_config_path=object_detection/samples/configs/ssd_mobilenet_v1_voc07.config --train_dir=object_detection/modelCheckpoints/pascal/

### Describe the problem
I was following the directions to train a ssd_mobilenet model that trains the detection network from scratch after initializing the backbone with the weights of a model trained on Imagenet. I downloaded the pre-trained mobilenet checkpoint for this experiment. However, I get warning messages complaining that the batch norm parameters could not be loaded (see below for the messages). Has anyone else seen this issue or any pointers on how I can try to debug it? 
### Source code / logs

train_config: {
  batch_size: 24
  optimizer {
    rms_prop_optimizer: {
      learning_rate: {
        exponential_decay_learning_rate {
          initial_learning_rate: 0.001
          decay_steps: 800720
          decay_factor: 0.95
        }
      }
      momentum_optimizer_value: 0.9
      decay: 0.9
      epsilon: 1.0
    }
  }
  fine_tune_checkpoint: ""/raid/gavenkatesh/Networks/tensorflowModels/models/object_detection/modelImagenet/mobilenet_v1_1.0_224.ckpt""
  from_detection_checkpoint: false
  data_augmentation_options {
    random_horizontal_flip {
    }
  }
  data_augmentation_options {
    ssd_random_crop {
    }
  }
}

**Warning messages:**
WARNING:root:Variable [MobilenetV1/Conv2d_13_pointwise_1_Conv2d_2_1x1_256/BatchNorm/beta] not available in checkpoint
WARNING:root:Variable [MobilenetV1/Conv2d_13_pointwise_1_Conv2d_2_1x1_256/BatchNorm/gamma] not available in checkpoint
WARNING:root:Variable [MobilenetV1/Conv2d_13_pointwise_1_Conv2d_2_1x1_256/BatchNorm/moving_mean] not available in checkpoint
WARNING:root:Variable [MobilenetV1/Conv2d_13_pointwise_1_Conv2d_2_1x1_256/BatchNorm/moving_variance] not available in checkpoint
WARNING:root:Variable [MobilenetV1/Conv2d_13_pointwise_1_Conv2d_2_1x1_256/weights] not available in checkpoint
WARNING:root:Variable [MobilenetV1/Conv2d_13_pointwise_1_Conv2d_3_1x1_128/BatchNorm/beta] not available in checkpoint
WARNING:root:Variable [MobilenetV1/Conv2d_13_pointwise_1_Conv2d_3_1x1_128/BatchNorm/gamma] not available in checkpoint
WARNING:root:Variable [MobilenetV1/Conv2d_13_pointwise_1_Conv2d_3_1x1_128/BatchNorm/moving_mean] not available in checkpoint
WARNING:root:Variable [MobilenetV1/Conv2d_13_pointwise_1_Conv2d_3_1x1_128/BatchNorm/moving_variance] not available in checkpoint
WARNING:root:Variable [MobilenetV1/Conv2d_13_pointwise_1_Conv2d_3_1x1_128/weights] not available in checkpoint
WARNING:root:Variable [MobilenetV1/Conv2d_13_pointwise_1_Conv2d_4_1x1_128/BatchNorm/beta] not available in checkpoint
WARNING:root:Variable [MobilenetV1/Conv2d_13_pointwise_1_Conv2d_4_1x1_128/BatchNorm/gamma] not available in checkpoint
WARNING:root:Variable [MobilenetV1/Conv2d_13_pointwise_1_Conv2d_4_1x1_128/BatchNorm/moving_mean] not available in checkpoint
WARNING:root:Variable [MobilenetV1/Conv2d_13_pointwise_1_Conv2d_4_1x1_128/BatchNorm/moving_variance] not available in checkpoint
WARNING:root:Variable [MobilenetV1/Conv2d_13_pointwise_1_Conv2d_4_1x1_128/weights] not available in checkpoint",livenletdie,None,2017-06-28T18:16:19Z,2017-06-28T18:47:45Z,,,,,,,
1783,Running SyntaxNet in any sort of IDE," Hi,
I post my question week ago in stack-overflow but nobody answered so I decide to ask it here , maybe finally somebody can help me  
I am working on SyntaxNet and syntactic parsing in English language with NN, I installed SyntaxNet on two different Ubuntu servers, one with GPU  and the other one without GPU, I successfully run SyntaxNet on both  machine and compared the performance also I changed the system in a way  that it is processing my data with my desire parameters and desired output format. (I wrote a program around the SytaxNet to control its parameters and etc). also I can fully control the pipeline of the SyntaxNet by using scriptfile that people suggest in other posts as well.

Now I need to change some part of the code of SyntaxNet and I need to  trace it step by step (having a program in debugging mode) so is there anyway that I can load a SytaxNet in any IDE like pycharm (and it is working) so I can trace it.

It is highly appreciated any sort of help that you can offer.

@calberti @andorardo ",k1trd,b'stat:community support type:support',2017-06-27T19:05:20Z,2018-10-31T20:58:02Z,,,,,,,
1735,Only 0.5 MAP on ssd_mobilnet_v1 object detection for pascal dataset.,"### System information
- **What is the top-level directory of the model you are using**:
object_detection
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
False
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Ubuntu 14.04
- **TensorFlow installed from (source or binary)**:
binary
- **TensorFlow version (use command below)**:
1.2
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
8.0/5.1
- **GPU model and memory**:
4 x Titan X Pascal
- **Exact command to reproduce**:

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

I successfully trained an ssd_mobilenet_v1 detection model locally using the oxford pet dataset and the file ```samples/configs/ssd_mobilenet_v1_pets.config``` and the initialized weights ```/ssd_mobilenet_v1_coco_11_06_2017/model.ckpt```
I achieved ~.9 test MAP score.

I attempted to replicate this process with the pascal voc12 dataset.  To do this, I followed the instructions for downloading the dataset and converting it to a tensorflow train/val record.

I copied the file ```samples/configs/ssd_mobilenet_v1_pets.config``` and pointed the datasets and labels file to the train/val tensorflow recrods.  I have attached this config.

I then ran the training and testing configuration locally.  Even after 120k iterations, the test MAP seemed to plateau around 0.5-0.6.  Are there different recommended parameters for the pascal dataset?  

I understand this may be more a stack overflow question, however, because the dataset exists in repo documentation and is mentioned in the paper, I would hope the code in the repository is set up to replicate the results of the paper.

I have attached photos of the tensorboard.  Orange is train and teal is test.


[ssd_mobilenet_v1_voc12.config.txt](https://github.com/tensorflow/models/files/1095760/ssd_mobilenet_v1_voc12.config.txt)
![screen shot 2017-06-22 at 9 57 34 am](https://user-images.githubusercontent.com/22623388/27446210-9d3b414c-5731-11e7-98a5-f44b422b5348.png)
![screen shot 2017-06-22 at 9 57 46 am](https://user-images.githubusercontent.com/22623388/27446211-9d3bbe42-5731-11e7-9db7-8513427edf24.png)
![screen shot 2017-06-22 at 9 58 14 am](https://user-images.githubusercontent.com/22623388/27446212-9d3f3b08-5731-11e7-8c07-51086eb1a613.png)

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",blake-varden,b'stat:awaiting response',2017-06-22T17:03:28Z,2019-12-13T01:58:34Z,,,,,,,
1720,RFE: include DenseNet,"> 1. It must be a bug or a feature request.

this is a request for a feature, which is to implement DenseNet

* [paper](https://arxiv.org/pdf/1608.06993.pdf)
* [karas code](https://github.com/flyyufelix/cnn_finetune/blob/master/densenet121.py)
* [pretrained weights](https://drive.google.com/open?id=0Byy2AcGyEVxfSTA4SHJVOHNuTXc)

",muayyad-alsadi,b'help wanted type:feature',2017-06-21T18:31:08Z,2018-10-12T01:41:49Z,,,,,,,
1707,Cast regularization parameters to float.,"This works around a bug in earlier proto versions
that automatically infer these values to be integer
instead of float.",jch1,b'cla: yes',2017-06-20T21:14:00Z,2017-06-20T21:16:52Z,,,,,,,
1706,Cast regularization parameters to float.,"This works around a bug in earlier proto versions
that automatically infer these values to be integer
instead of float.",jch1,b'cla: no',2017-06-20T21:06:50Z,2017-06-20T21:07:38Z,,,,,,,
1705,Cast regularization parameters to float.,"This works around a bug in earlier proto versions
that automatically infer these values to be integer
instead of float.",jch1,b'cla: no',2017-06-20T21:03:48Z,2017-06-20T21:04:29Z,,,,,,,
1697,how to input our own new dataset and what should be done for it???,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",anish9,None,2017-06-20T12:50:10Z,2017-06-20T20:39:28Z,,,,,,,
1620,"testing attention_ocr model on test set: getting ""TypeError: The value of a feed cannot be a tf.Tensor object. Acceptable feed values include Python scalars, strings, lists, numpy ndarrays, or TensorHandles""","
### System information
- **What is the top-level directory of the model you are using**: attention_ocr
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 14.04
- **TensorFlow installed from (source or binary)**: Binary
- **TensorFlow version (use command below)**: ('v1.0.0-2378-g2259213', '1.1.0-rc0')
- **Bazel version (if compiling from source)**: 
- **CUDA/cuDNN version**: CUDA 8.0/cuDNN : 5.1
- **GPU model and memory**: GeForce GTX 1080/ 8112MiB
- **Exact command to reproduce**: ""python <test.py> --checkpoint=model.ckpt-399731""


### Describe the problem

I was trying to use the pretrained model of attention_ocr (model.ckpt-399731) on test data (fsn data). My idea was once I'm able to run it successfully, I can try it on my own images.

But when I followed the provided instructions to use pretrained model, I'm getting the following error:
`Traceback (most recent call last):
  File ""test.py"", line 60, in <module>
    app.run()
  File ""/home/sudheer/Flipkart/Research/maneesh/tensorflow_1.1/local/lib/python2.7/site-packages/tensorflow/python/platform/app.py"", line 48, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""test.py"", line 54, in main
    predictions = sess.run(endpoints.predicted_chars, feed_dict={img_data:data.images})
  File ""/home/sudheer/Flipkart/Research/maneesh/tensorflow_1.1/local/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 778, in run
    run_metadata_ptr)
  File ""/home/sudheer/Flipkart/Research/maneesh/tensorflow_1.1/local/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 936, in _run
    raise TypeError('The value of a feed cannot be a tf.Tensor object. '
TypeError: The value of a feed cannot be a tf.Tensor object. Acceptable feed values include Python scalars, strings, lists, numpy ndarrays, or TensorHandles.`

Here are the steps I followed:
* Created a placeholders for the images 
`img_data = tf.placeholder(tf.float32, shape=(32, 150, 600, 3), name='img_data')`
* Created a graph using `endpoints = model.create_base(img_data, labels_one_hot=None)`
* Loaded the pretrained model `init_fn = model.create_init_fn_to_restore(FLAGS.checkpoint, FLAGS.checkpoint_inception)`
* Finally running the predictions tensor using 'predictions = sess.run(endpoints.predicted_chars, feed_dict={img_data:data.images})'

I'm getting the error in the last line when running predictions.

### Source code
Please find the complete source code
`def main(_):
   
    img_data = tf.placeholder(tf.float32, shape=(32, 150, 600, 3), name='img_data')
    dataset = common_flags.create_dataset(split_name='test')
    data = data_provider.get_data(dataset, FLAGS.batch_size, augment=False, central_crop_size=common_flags.get_crop_size())

    with tf.Session() as sess:
        
        model = common_flags.create_model(dataset.num_char_classes,
                                    dataset.max_sequence_length,
                                    dataset.num_of_views, dataset.null_code)
        endpoints = model.create_base(img_data, labels_one_hot=None)
        total_loss = model.create_loss(data, endpoints)
        summaries = model.create_summaries(data, endpoints, dataset.charset, is_training=False)
        init_fn = model.create_init_fn_to_restore(FLAGS.checkpoint, FLAGS.checkpoint_inception)
        #sess.run(tf.global_variables_initializer())
        #print init_fn
        predictions = sess.run(endpoints.predicted_chars, feed_dict={img_data:data.images})
`

### Logs

Please find the complete stack trace:
`INFO 2017-06-20 02:49:57.000398: fsns.py: 130 Using FSNS dataset split_name=test dataset_dir=/home/sudheer/Flipkart/Research/maneesh/tensor_flow/models/models/attention_ocr/python/datasets/data/fsns
2017-06-20 02:49:57.519862: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2017-06-20 02:49:57.519882: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2017-06-20 02:49:57.519889: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2017-06-20 02:49:57.519894: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2017-06-20 02:49:57.519898: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
2017-06-20 02:49:57.798192: I tensorflow/core/common_runtime/gpu/gpu_device.cc:887] Found device 0 with properties: 
name: GeForce GTX 1080
major: 6 minor: 1 memoryClockRate (GHz) 1.8095
pciBusID 0000:01:00.0
Total memory: 7.92GiB
Free memory: 7.64GiB
2017-06-20 02:49:57.798225: I tensorflow/core/common_runtime/gpu/gpu_device.cc:908] DMA: 0 
2017-06-20 02:49:57.798232: I tensorflow/core/common_runtime/gpu/gpu_device.cc:918] 0:   Y 
2017-06-20 02:49:57.798241: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0)
DEBUG 2017-06-20 02:49:57.000835: model.py: 314 images: Tensor(""img_data:0"", shape=(32, 150, 600, 3), dtype=float32)
DEBUG 2017-06-20 02:49:57.000837: model.py: 319 Views=4 single view: Tensor(""AttentionOcr_v1/split:0"", shape=(32, 150, 150, 3), dtype=float32)
DEBUG 2017-06-20 02:49:57.000837: model.py: 186 Using final_endpoint=Mixed_5d
DEBUG 2017-06-20 02:49:58.000554: model.py: 186 Using final_endpoint=Mixed_5d
DEBUG 2017-06-20 02:49:58.000940: model.py: 186 Using final_endpoint=Mixed_5d
DEBUG 2017-06-20 02:49:59.000301: model.py: 186 Using final_endpoint=Mixed_5d
DEBUG 2017-06-20 02:49:59.000722: model.py: 325 Conv tower: Tensor(""AttentionOcr_v1/conv_tower_fn/INCE/InceptionV3/Mixed_5d/concat:0"", shape=(32, 16, 16, 288), dtype=float32)
DEBUG 2017-06-20 02:49:59.000724: model.py: 328 Pooled views: Tensor(""AttentionOcr_v1/pool_views_fn/STCK/Reshape:0"", shape=(32, 1024, 288), dtype=float32)
DEBUG 2017-06-20 02:49:59.000724: sequence_layers.py: 421 Use AttentionWithAutoregression as a layer class
DEBUG 2017-06-20 02:50:00.000818: model.py: 331 chars_logit: Tensor(""AttentionOcr_v1/sequence_logit_fn/SQLR/concat:0"", shape=(32, 37, 134), dtype=float32)
WARNING:tensorflow:From /home/sudheer/Flipkart/Research/maneesh/tensorflow_1.1/models/attention_ocr/python/model.py:358: get_total_loss (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.
Instructions for updating:
Use tf.losses.get_total_loss instead.
WARNING 2017-06-20 02:50:01.000253: deprecation.py: 117 From /home/sudheer/Flipkart/Research/maneesh/tensorflow_1.1/models/attention_ocr/python/model.py:358: get_total_loss (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.
Instructions for updating:
Use tf.losses.get_total_loss instead.
WARNING:tensorflow:From /home/sudheer/Flipkart/Research/maneesh/tensorflow_1.1/local/lib/python2.7/site-packages/tensorflow/contrib/losses/python/losses/loss_ops.py:261: get_losses (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.
Instructions for updating:
Use tf.losses.get_losses instead.
WARNING 2017-06-20 02:50:01.000253: deprecation.py: 117 From /home/sudheer/Flipkart/Research/maneesh/tensorflow_1.1/local/lib/python2.7/site-packages/tensorflow/contrib/losses/python/losses/loss_ops.py:261: get_losses (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.
Instructions for updating:
Use tf.losses.get_losses instead.
WARNING:tensorflow:From /home/sudheer/Flipkart/Research/maneesh/tensorflow_1.1/local/lib/python2.7/site-packages/tensorflow/contrib/losses/python/losses/loss_ops.py:263: get_regularization_losses (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.
Instructions for updating:
Use tf.losses.get_regularization_losses instead.
WARNING 2017-06-20 02:50:01.000253: deprecation.py: 117 From /home/sudheer/Flipkart/Research/maneesh/tensorflow_1.1/local/lib/python2.7/site-packages/tensorflow/contrib/losses/python/losses/loss_ops.py:263: get_regularization_losses (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.
Instructions for updating:
Use tf.losses.get_regularization_losses instead.
INFO 2017-06-20 02:50:01.000279: model.py: 511 Request to re-store 116 weights from model.ckpt-399731
INFO 2017-06-20 02:50:01.000462: model.py: 511 Request to re-store 104 weights from /home/sudheer/Flipkart/Research/maneesh/tensor_flow/models/models/attention_ocr/python/pretrained_models/inception_v3.ckpt
Traceback (most recent call last):
  File ""test.py"", line 60, in <module>
    app.run()
  File ""/home/sudheer/Flipkart/Research/maneesh/tensorflow_1.1/local/lib/python2.7/site-packages/tensorflow/python/platform/app.py"", line 48, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""test.py"", line 54, in main
    predictions = sess.run(endpoints.predicted_chars, feed_dict={img_data:data.images})
  File ""/home/sudheer/Flipkart/Research/maneesh/tensorflow_1.1/local/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 778, in run
    run_metadata_ptr)
  File ""/home/sudheer/Flipkart/Research/maneesh/tensorflow_1.1/local/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 936, in _run
    raise TypeError('The value of a feed cannot be a tf.Tensor object. '
TypeError: The value of a feed cannot be a tf.Tensor object. Acceptable feed values include Python scalars, strings, lists, numpy ndarrays, or TensorHandles.
`

Please let me know if I'm doing something wrong and how should I fix my code. If anyone has successfully used pretrained attention_ocr model to test on their images, I really appreciate if you can provide me the python script you used or series of steps I need to follow to do the same. 
",tumusudheer,b'type:support',2017-06-20T02:04:02Z,2017-06-30T17:58:49Z,,,,,,,
1598,Follow TF performance guide in models available here,"### System information
N/A

### Describe the problem
Currently, none of the models available here generally follow the TF performance guidelines. None of the models here support running in NCHW, and only the newest object detection models use the fused batch norm op.

As such, this makes the [published TF benchmarks](https://www.tensorflow.org/performance/benchmarks) somewhat misleading – while those benchmarks run at competitive speeds, the actual reference model code published here does not, and instead takes a very large performance hit.

Ideally the first-party example code here should all support NCHW and use fused batch norm where relevant, such that the performance obtained here is actually comparable with the claims made via the posted benchmarks.",taion,b'stat:awaiting response type:bug',2017-06-17T23:21:11Z,2017-06-20T20:12:21Z,,,,,,,
1587,"Mention of Python 3: AttributeError: 'dict' object has no attribute 'iteritems' for ""python ./object_detection/builders/model_builder_test.py""","When you meet this:

```
File ""./object_detection/builders/model_builder_test.py"", line 258, in test_create_faster_rcnn_resnet_v1_models_from_config

File ""./object_detection/builders/model_builder_test.py"", line 448, in test_create_rfcn_resnet_v1_model_from_config

```
This is a Python 2 to Python 3 of dict change.

Solution:
_change iteritems() to items()_

`for extractor_type, extractor_class in FEATURE_EXTRACTOR_MAPS.items():`

Then,
`python ./object_detection/builders/model_builder_test.py`

.......
----------------------------------------------------------------------
Ran 7 tests in 0.055s

OK

",zhouphd,b'help wanted type:bug',2017-06-16T21:28:50Z,2019-11-09T16:48:56Z,,,,,,,
1585,object_detection/models/faster_rcnn_resnet_v1_feature_extractor_test.py Broken !,"Looks like resnet_v1 feature extractors are broken. Here is the log of running the test - ` python models/faster_rcnn_resnet_v1_feature_extractor_test.py`

```======================================================================
ERROR: test_extract_proposal_features_stride_eight (__main__.FasterRcnnResnetV1FeatureExtractorTest)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""models/faster_rcnn_resnet_v1_feature_extractor_test.py"", line 65, in test_extract_proposal_features_stride_eight
    preprocessed_inputs, scope='TestScope')
  File ""/models/object_detection/meta_architectures/faster_rcnn_meta_arch.py"", line 131, in extract_proposal_features
    return self._extract_proposal_features(preprocessed_inputs, scope)
  File ""/models/object_detection/models/faster_rcnn_resnet_v1_feature_extractor.py"", line 125, in _extract_proposal_features
    scope=var_scope)
  File ""/models/slim/nets/resnet_v1.py"", line 280, in resnet_v1_101
    reuse=reuse, scope=scope)
  File ""/models/slim/nets/resnet_v1.py"", line 204, in resnet_v1
    logits = tf.squeeze(net, [1, 2], name='SpatialSqueeze')
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/array_ops.py"", line 2281, in squeeze
    return gen_array_ops._squeeze(input, axis, name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_array_ops.py"", line 3329, in _squeeze
    squeeze_dims=squeeze_dims, name=name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py"", line 767, in apply_op
    op_def=op_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 2508, in create_op
    set_shapes_for_outputs(ret)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 1873, in set_shapes_for_outputs
    shapes = shape_func(op)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 1823, in call_with_requiring
    return call_cpp_shape_fn(op, require_shape_fn=True)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/common_shapes.py"", line 610, in call_cpp_shape_fn
    debug_python_shape_fn, require_shape_fn)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/common_shapes.py"", line 676, in _call_cpp_shape_fn_impl
    raise ValueError(err.message)
ValueError: Can not squeeze dim[1], expected a dimension of 1, got 28 for 'TestScope/resnet_v1_101/resnet_v1_101/SpatialSqueeze' (op: 'Squeeze') with input shapes: [4,28,28,2048].

----------------------------------------------------------------------
```",darshanhegde,b'stat:awaiting response type:bug',2017-06-16T20:58:51Z,2017-06-16T21:51:09Z,,,,,,,
1579,"How to use the model/slim, Resnet152 ckpt and .graph files to do an inference in a C++ or Python inference using tensorflow?","Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",mayuresh51,None,2017-06-16T16:52:56Z,2017-06-16T20:22:27Z,,,,,,,
1576,no test_ckpt/ssd_inception_v2.pb file for /models/object_detection/object_detection_tutorial.ipynb,"Thanks for your new Great object detection model.

I'm trying to test  /models/object_detection/object_detection_tutorial.ipynb with jupyter notebook.

but there missing file , ""test_ckpt/ssd_inception_v2.pb""

this is sample code.

PATH_TO_CKPT = os.path.join('test_ckpt', 'ssd_inception_v2.pb')

and,

with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:
        serialized_graph = fid.read()
        od_graph_def.ParseFromString(serialized_graph)
        tf.import_graph_def(od_graph_def, name='')

So , PATH_TO_CKPT( = test_ckpt/ssd_inception_v2.pb) is need to run test code.

please check it and let me know how to down load this file please. :-)

Thanks for reading!",Jun-13,b'stat:awaiting response type:bug',2017-06-16T11:30:44Z,2017-10-27T07:48:58Z,,,,,,,
1573,tensorflow.Supervisor cannot save global variable correctly,"    tensorflow       1.1.0
    Python 3.6.1

I train `LSTM` model with code in `tutorials/rnn/ptb/ptb_word_lm.py`, it runs ok. But when I tried to restore model from file like this:

    import tensorflow as tf

    def main(_):
        initializer = tf.constant_initializer(0.9)
        with tf.Session() as sess:

            saver = tf.train.import_meta_graph(""/data/ptb_out/model.ckpt-0.meta"")
            saver.restore(sess, tf.train.latest_checkpoint(""/data/ptb_out""))

            for v in tf.global_variables():
                print(v)
                print(sess.run(v))

    if __name__ == ""__main__"":
      tf.app.run()

its result is absolutely wrong. Here is some output:

    <tf.Variable 'Model/RNN/multi_rnn_cell/cell_1/basic_lstm_cell/biases:0' shape=(800,) dtype=float32_ref>
    [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.                   
      0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
      0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
      0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.     
      0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
      0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
    ......

And Here is some output I print when training:

    <tf.Variable 'Model/RNN/multi_rnn_cell/cell_1/basic_lstm_cell/biases:0' shape=(800,) dtype=float32_ref>
    [ -1.17101513e-01  -2.15225220e-02  -1.28542287e-02  -3.51899974e-02
       5.21844253e-04   1.20898355e-02  -3.93793173e-02  -7.61226267e-02
      -9.99010429e-02  -6.64486885e-02   8.51375982e-04  -2.59024128e-02
      -2.68366076e-02  -7.81635195e-02   3.87813337e-02  -3.07088848e-02
      -3.90137807e-02  -1.77433752e-02  -8.50182846e-02  -5.49090877e-02
       2.65573729e-02  -1.36946924e-02  -9.55018103e-02  -8.94337296e-02
     ......

I suspect it is a bug of `Supervisor`.",rogerdehe,None,2017-06-16T10:36:14Z,2017-06-16T22:29:37Z,,,,,,,
1558,Fixing the initialization/loading bug.,"The code currently loads the checkpoint and then initializes the variables resulting to random weights. 
Swapping the order fixes the loading checkpoint issue.",mbz,b'cla: yes',2017-06-14T23:02:01Z,2017-06-15T21:52:54Z,,,,,,,
1548,Fix a small bug of Python3 compatibility in tutorial example /rnn/ptb,"This PR is for Issue #1541
Done basic tests with Python3 without GPU, and python2 (in virtualenv). ",ngovanmao,b'cla: yes',2017-06-13T15:39:29Z,2017-06-13T15:59:13Z,,,,,,,
1541,rnn/ptb/ptb_word_lm.py cannot run with Python3 due to str.decode,"The example rnn/ptg/ptb_word_lm.py  cannot run with Python3. 
~/models/tutorials/rnn/ptb$ python3 ptb_word_lm.py --data_path=/tmp/simple-examples/data --model=small
Traceback (most recent call last):
  File ""ptb_word_lm.py"", line 385, in <module>
    tf.app.run()
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/platform/app.py"", line 48, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""ptb_word_lm.py"", line 332, in main
    raw_data = reader.ptb_raw_data(FLAGS.data_path)
  File ""/home/vanmao_ngo/models/tutorials/rnn/ptb/reader.py"", line 73, in ptb_raw_data
    word_to_id = _build_vocab(train_path)
  File ""/home/vanmao_ngo/models/tutorials/rnn/ptb/reader.py"", line 34, in _build_vocab
    data = _read_words(filename)
  File ""/home/vanmao_ngo/models/tutorials/rnn/ptb/reader.py"", line 30, in _read_words
    return f.read().decode(""utf-8"").replace(""\n"", ""<eos>"").split()
AttributeError: 'str' object has no attribute 'decode'

The problem is as clear as the message: str.decode is not necessary in Python3. 

# Solution: Change in the reader.py file, just remove decode(""utf-8""). 
The full solution should handle both Python 2 and Python 3. 
if sys.version_info[0] >= 3:
  return f.read().replace(""\n"", ""<eos>"").split()
else:
 return f.read().decode(""utf-8"").replace(""\n"", ""<eos>"").split()",ngovanmao,b'type:bug',2017-06-09T13:18:38Z,2017-06-13T15:59:30Z,,,,,,,
1514,能否添加一个R-FCN(resnet-101)做目标检测的model？,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",crazyyanchao,None,2017-05-29T14:08:32Z,2017-05-29T23:38:47Z,,,,,,,
1498,resnet_v2_test: 8 tests Failed,"Majority of the tests are failing in [resnet_v2_test.py](https://github.com/tensorflow/models/blob/master/slim/nets/resnet_v2_test.py )

11 of 17 Tests done. **8 failed**
Failed:
1. testAtrousFullyConvolutionalUnknownHeightWidth

> Failure
> Traceback (most recent call last):
>   File ""nets/resnet_v2_test.py"", line 444, in testAtrousFullyConvolutionalUnknownHeightWidth
>     [batch, None, None, 32])
> AssertionError: Lists differ: [2, 32] != [2, None, None, 32]
> 
> First differing element 1:
> 32
> None
> 
> Second list contains 2 additional elements.
> First extra element 2:
> None
> 
> - [2, 32]
> + [2, None, None, 32]

2. testAtrousFullyConvolutionalEndpointShapes

> Error
> Traceback (most recent call last):
>   File ""/home/asanakoy/workspace/kaggle/noaa/scripts/nets/resnet_v2_test.py"", line 358, in testAtrousFullyConvolutionalEndpointShapes
>     scope='resnet')
>   File ""/home/asanakoy/workspace/kaggle/noaa/scripts/nets/resnet_v2_test.py"", line 280, in _resnet_small
>     scope=scope)
>   File ""/home/asanakoy/workspace/kaggle/noaa/scripts/nets/resnet_v2.py"", line 211, in resnet_v2
>     logits = tf.squeeze(net, [1, 2], name='SpatialSqueeze')
>   File ""/home/asanakoy/.venvs/tf_r1/lib/python2.7/site-packages/tensorflow/python/ops/array_ops.py"", line 2259, in squeeze
>     return gen_array_ops._squeeze(input, axis, name)
>   File ""/home/asanakoy/.venvs/tf_r1/lib/python2.7/site-packages/tensorflow/python/ops/gen_array_ops.py"", line 3378, in _squeeze
>     squeeze_dims=squeeze_dims, name=name)
>   File ""/home/asanakoy/.venvs/tf_r1/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py"", line 768, in apply_op
>     op_def=op_def)
>   File ""/home/asanakoy/.venvs/tf_r1/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 2338, in create_op
>     set_shapes_for_outputs(ret)
>   File ""/home/asanakoy/.venvs/tf_r1/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 1719, in set_shapes_for_outputs
>     shapes = shape_func(op)
>   File ""/home/asanakoy/.venvs/tf_r1/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 1669, in call_with_requiring
>     return call_cpp_shape_fn(op, require_shape_fn=True)
>   File ""/home/asanakoy/.venvs/tf_r1/lib/python2.7/site-packages/tensorflow/python/framework/common_shapes.py"", line 610, in call_cpp_shape_fn
>     debug_python_shape_fn, require_shape_fn)
>   File ""/home/asanakoy/.venvs/tf_r1/lib/python2.7/site-packages/tensorflow/python/framework/common_shapes.py"", line 676, in _call_cpp_shape_fn_impl
>     raise ValueError(err.message)
> ValueError: Can not squeeze dim[1], expected a dimension of 1, got 41 for 'resnet/SpatialSqueeze' (op: 'Squeeze') with input shapes: [2,41,41,10].

3. testAtrousFullyConvolutionalValues
> Error
> Traceback (most recent call last):
>   File ""/home/asanakoy/workspace/kaggle/noaa/scripts/nets/resnet_v2_test.py"", line 381, in testAtrousFullyConvolutionalValues
>     output_stride=output_stride)
>   File ""/home/asanakoy/workspace/kaggle/noaa/scripts/nets/resnet_v2_test.py"", line 280, in _resnet_small
>     scope=scope)
>   File ""/home/asanakoy/workspace/kaggle/noaa/scripts/nets/resnet_v2.py"", line 211, in resnet_v2
>     logits = tf.squeeze(net, [1, 2], name='SpatialSqueeze')
>   File ""/home/asanakoy/.venvs/tf_r1/lib/python2.7/site-packages/tensorflow/python/ops/array_ops.py"", line 2259, in squeeze
>     return gen_array_ops._squeeze(input, axis, name)
>   File ""/home/asanakoy/.venvs/tf_r1/lib/python2.7/site-packages/tensorflow/python/ops/gen_array_ops.py"", line 3378, in _squeeze
>     squeeze_dims=squeeze_dims, name=name)
>   File ""/home/asanakoy/.venvs/tf_r1/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py"", line 768, in apply_op
>     op_def=op_def)
>   File ""/home/asanakoy/.venvs/tf_r1/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 2338, in create_op
>     set_shapes_for_outputs(ret)
>   File ""/home/asanakoy/.venvs/tf_r1/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 1719, in set_shapes_for_outputs
>     shapes = shape_func(op)
>   File ""/home/asanakoy/.venvs/tf_r1/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 1669, in call_with_requiring
>     return call_cpp_shape_fn(op, require_shape_fn=True)
>   File ""/home/asanakoy/.venvs/tf_r1/lib/python2.7/site-packages/tensorflow/python/framework/common_shapes.py"", line 610, in call_cpp_shape_fn
>     debug_python_shape_fn, require_shape_fn)
>   File ""/home/asanakoy/.venvs/tf_r1/lib/python2.7/site-packages/tensorflow/python/framework/common_shapes.py"", line 676, in _call_cpp_shape_fn_impl
>     raise ValueError(err.message)
> ValueError: Can not squeeze dim[1], expected a dimension of 1, got 21 for 'resnet_v2_small/SpatialSqueeze' (op: 'Squeeze') with input shapes: [2,21,21,32].

4.testClassificationEndPoints
> Failure
> Traceback (most recent call last):
>   File ""/home/asanakoy/workspace/kaggle/noaa/scripts/nets/resnet_v2_test.py"", line 290, in testClassificationEndPoints
>     self.assertTrue(logits.op.name.startswith('resnet/logits'))
> AssertionError: False is not true

5. testFullyConvolutionalEndpointShapes
> Error
> Traceback (most recent call last):
>   File ""/home/asanakoy/workspace/kaggle/noaa/scripts/nets/resnet_v2_test.py"", line 320, in testFullyConvolutionalEndpointShapes
>     scope='resnet')
>   File ""/home/asanakoy/workspace/kaggle/noaa/scripts/nets/resnet_v2_test.py"", line 280, in _resnet_small
>     scope=scope)
>   File ""/home/asanakoy/workspace/kaggle/noaa/scripts/nets/resnet_v2.py"", line 211, in resnet_v2
>     logits = tf.squeeze(net, [1, 2], name='SpatialSqueeze')
>   File ""/home/asanakoy/.venvs/tf_r1/lib/python2.7/site-packages/tensorflow/python/ops/array_ops.py"", line 2259, in squeeze
>     return gen_array_ops._squeeze(input, axis, name)
>   File ""/home/asanakoy/.venvs/tf_r1/lib/python2.7/site-packages/tensorflow/python/ops/gen_array_ops.py"", line 3378, in _squeeze
>     squeeze_dims=squeeze_dims, name=name)
>   File ""/home/asanakoy/.venvs/tf_r1/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py"", line 768, in apply_op
>     op_def=op_def)
>   File ""/home/asanakoy/.venvs/tf_r1/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 2338, in create_op
>     set_shapes_for_outputs(ret)
>   File ""/home/asanakoy/.venvs/tf_r1/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 1719, in set_shapes_for_outputs
>     shapes = shape_func(op)
>   File ""/home/asanakoy/.venvs/tf_r1/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 1669, in call_with_requiring
>     return call_cpp_shape_fn(op, require_shape_fn=True)
>   File ""/home/asanakoy/.venvs/tf_r1/lib/python2.7/site-packages/tensorflow/python/framework/common_shapes.py"", line 610, in call_cpp_shape_fn
>     debug_python_shape_fn, require_shape_fn)
>   File ""/home/asanakoy/.venvs/tf_r1/lib/python2.7/site-packages/tensorflow/python/framework/common_shapes.py"", line 676, in _call_cpp_shape_fn_impl
>     raise ValueError(err.message)
> ValueError: Can not squeeze dim[1], expected a dimension of 1, got 11 for 'resnet/SpatialSqueeze' (op: 'Squeeze') with input shapes: [2,11,11,10].
> 

6. testFullyConvolutionalUnknownHeightWidth

> Failure
> Traceback (most recent call last):
>   File ""/home/asanakoy/workspace/kaggle/noaa/scripts/nets/resnet_v2_test.py"", line 425, in testFullyConvolutionalUnknownHeightWidth
>     [batch, None, None, 32])
> AssertionError: Lists differ: [2, 32] != [2, None, None, 32]
> 
> First differing element 1:
> 32
> None
> 
> Second list contains 2 additional elements.
> First extra element 2:
> None
> 
> - [2, 32]
> + [2, None, None, 32]

7. testRootlessFullyConvolutionalEndpointShapes

> Error
> Traceback (most recent call last):
>   File ""/home/asanakoy/workspace/kaggle/noaa/scripts/nets/resnet_v2_test.py"", line 338, in testRootlessFullyConvolutionalEndpointShapes
>     scope='resnet')
>   File ""/home/asanakoy/workspace/kaggle/noaa/scripts/nets/resnet_v2_test.py"", line 280, in _resnet_small
>     scope=scope)
>   File ""/home/asanakoy/workspace/kaggle/noaa/scripts/nets/resnet_v2.py"", line 211, in resnet_v2
>     logits = tf.squeeze(net, [1, 2], name='SpatialSqueeze')
>   File ""/home/asanakoy/.venvs/tf_r1/lib/python2.7/site-packages/tensorflow/python/ops/array_ops.py"", line 2259, in squeeze
>     return gen_array_ops._squeeze(input, axis, name)
>   File ""/home/asanakoy/.venvs/tf_r1/lib/python2.7/site-packages/tensorflow/python/ops/gen_array_ops.py"", line 3378, in _squeeze
>     squeeze_dims=squeeze_dims, name=name)
>   File ""/home/asanakoy/.venvs/tf_r1/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py"", line 768, in apply_op
>     op_def=op_def)
>   File ""/home/asanakoy/.venvs/tf_r1/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 2338, in create_op
>     set_shapes_for_outputs(ret)
>   File ""/home/asanakoy/.venvs/tf_r1/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 1719, in set_shapes_for_outputs
>     shapes = shape_func(op)
>   File ""/home/asanakoy/.venvs/tf_r1/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 1669, in call_with_requiring
>     return call_cpp_shape_fn(op, require_shape_fn=True)
>   File ""/home/asanakoy/.venvs/tf_r1/lib/python2.7/site-packages/tensorflow/python/framework/common_shapes.py"", line 610, in call_cpp_shape_fn
>     debug_python_shape_fn, require_shape_fn)
>   File ""/home/asanakoy/.venvs/tf_r1/lib/python2.7/site-packages/tensorflow/python/framework/common_shapes.py"", line 676, in _call_cpp_shape_fn_impl
>     raise ValueError(err.message)
> ValueError: Can not squeeze dim[1], expected a dimension of 1, got 16 for 'resnet/SpatialSqueeze' (op: 'Squeeze') with input shapes: [2,16,16,10].
> 

8. testUnknownBatchSize

> Failure
> Traceback (most recent call last):
>   File ""/home/asanakoy/workspace/kaggle/noaa/scripts/nets/resnet_v2_test.py"", line 407, in testUnknownBatchSize
>     self.assertTrue(logits.op.name.startswith('resnet/logits'))
> AssertionError: False is not true


Similar situation is with `resnet_v1_test.py`  (8 tests failed as well).

CentOS Linux release 7.2.1511, python 2.7.3, 
I have the latest tensorflow (installed from pip), and master branch of `tensorflow/models`.",asanakoy,None,2017-05-22T01:27:58Z,2017-06-15T02:37:56Z,,,,,,,
1484,resnet_v1_test.py Failing,"### System information
- **What is the top-level directory of the model you are using**:
models/slim/
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**:
Anaconda
- **TensorFlow version (use command below)**:
1.1
- **Bazel version (if compiling from source)**:
N/A
- **CUDA/cuDNN version**:
N/A
- **GPU model and memory**:
N/A
- **Exact command to reproduce**:
python nets/resnet_v1_test.py

### Describe the problem
I am trying to run the script to test the resnet_v1 network i.e. resnet_v1_test.py 
However, this fails.  I have not modified this file in anyway.

### Source code / logs
======================================================================
ERROR: testRootlessFullyConvolutionalEndpointShapes (__main__.ResnetCompleteNetworkTest)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""/home/richard/gitFiles/TensorFlow/slim/nets/resnet_v1_test.py"", line 338, in testRootlessFullyConvolutionalEndpointShapes
    scope='resnet')
  File ""/home/richard/gitFiles/TensorFlow/slim/nets/resnet_v1_test.py"", line 280, in _resnet_small
    scope=scope)
  File ""nets/resnet_v1.py"", line 204, in resnet_v1
    logits = tf.squeeze(net, [1, 2], name='SpatialSqueeze')
  File ""/home/richard/.anaconda3/envs/py27/lib/python2.7/site-packages/tensorflow/python/ops/array_ops.py"", line 2259, in squeeze
    return gen_array_ops._squeeze(input, axis, name)
  File ""/home/richard/.anaconda3/envs/py27/lib/python2.7/site-packages/tensorflow/python/ops/gen_array_ops.py"", line 3378, in _squeeze
    squeeze_dims=squeeze_dims, name=name)
  File ""/home/richard/.anaconda3/envs/py27/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py"", line 768, in apply_op
    op_def=op_def)
  File ""/home/richard/.anaconda3/envs/py27/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 2338, in create_op
    set_shapes_for_outputs(ret)
  File ""/home/richard/.anaconda3/envs/py27/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 1719, in set_shapes_for_outputs
    shapes = shape_func(op)
  File ""/home/richard/.anaconda3/envs/py27/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 1669, in call_with_requiring
    return call_cpp_shape_fn(op, require_shape_fn=True)
  File ""/home/richard/.anaconda3/envs/py27/lib/python2.7/site-packages/tensorflow/python/framework/common_shapes.py"", line 610, in call_cpp_shape_fn
    debug_python_shape_fn, require_shape_fn)
  File ""/home/richard/.anaconda3/envs/py27/lib/python2.7/site-packages/tensorflow/python/framework/common_shapes.py"", line 676, in _call_cpp_shape_fn_impl
    raise ValueError(err.message)
ValueError: Can not squeeze dim[1], expected a dimension of 1, got 16 for 'resnet/SpatialSqueeze' (op: 'Squeeze') with input shapes: [2,16,16,10].

======================================================================
ERROR: testEndPointsV1 (__main__.ResnetUtilsTest)
Test the end points of a tiny v1 bottleneck network.
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""/home/richard/gitFiles/TensorFlow/slim/nets/resnet_v1_test.py"", line 169, in testEndPointsV1
    _, end_points = self._resnet_plain(inputs, blocks, scope='tiny')
  File ""/home/richard/gitFiles/TensorFlow/slim/nets/resnet_v1_test.py"", line 159, in _resnet_plain
    end_points = dict(tf.get_collection('end_points'))
TypeError: cannot convert dictionary update sequence element #0 to a sequence

======================================================================
FAIL: testAtrousFullyConvolutionalUnknownHeightWidth (__main__.ResnetCompleteNetworkTest)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""/home/richard/gitFiles/TensorFlow/slim/nets/resnet_v1_test.py"", line 441, in testAtrousFullyConvolutionalUnknownHeightWidth
    [batch, None, None, 32])
AssertionError: Lists differ: [2, 32] != [2, None, None, 32]

First differing element 1:
32
None

Second list contains 2 additional elements.
First extra element 2:
None

- [2, 32]
+ [2, None, None, 32]

======================================================================
FAIL: testClassificationEndPoints (__main__.ResnetCompleteNetworkTest)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""/home/richard/gitFiles/TensorFlow/slim/nets/resnet_v1_test.py"", line 290, in testClassificationEndPoints
    self.assertTrue(logits.op.name.startswith('resnet/logits'))
AssertionError: False is not true

======================================================================
FAIL: testFullyConvolutionalUnknownHeightWidth (__main__.ResnetCompleteNetworkTest)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""/home/richard/gitFiles/TensorFlow/slim/nets/resnet_v1_test.py"", line 422, in testFullyConvolutionalUnknownHeightWidth
    [batch, None, None, 32])
AssertionError: Lists differ: [2, 32] != [2, None, None, 32]

First differing element 1:
32
None

Second list contains 2 additional elements.
First extra element 2:
None

- [2, 32]
+ [2, None, None, 32]

======================================================================
FAIL: testUnknownBatchSize (__main__.ResnetCompleteNetworkTest)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""/home/richard/gitFiles/TensorFlow/slim/nets/resnet_v1_test.py"", line 405, in testUnknownBatchSize
    self.assertTrue(logits.op.name.startswith('resnet/logits'))
AssertionError: False is not true

----------------------------------------------------------------------
Ran 17 tests in 31.426s

FAILED (failures=4, errors=5)
",richardmarcum,None,2017-05-18T17:40:28Z,2017-06-20T17:41:53Z,,,,,,,
1481,Start fixing Neural GPU's RNN baseline,"Running `python neural_gpu_trainer.py --problem bmul --rnn_baseline=True` fails with:

`ValueError: Attempt to reuse RNNCell <tensorflow.contrib.rnn.python.ops.core_rnn_cell_impl.BasicLSTMCell object at 0x7f5ae993d190> with a different variable scope than its first use.  First use of cell was with scope 'encoder/rnn/multi_rnn_cell/cell_0/basic_lstm_cell', this attempt is with scope 'encoder/rnn/multi_rnn_cell/cell_1/basic_lstm_cell'.  Please create a new instance of the cell if you would like it to use a different set of weights.  If before you were using: MultiRNNCell([BasicLSTMCell(...)] * num_layers), change to: MultiRNNCell([BasicLSTMCell(...) for _ in range(num_layers)]).  If before you were using the same cell instance as both the forward and reverse cell of a bidirectional RNN, simply create two instances (one for forward, one for reverse).  In May 2017, we will start transitioning this cell's behavior to use existing stored weights, if any, when it is called with scope=None (which can lead to silent model degradation, so this error will remain until then.)`

This is the first part of a fix for this, fixing the MultiRNNCell parameters.

However, there's a second bug which I don't fix here - the same instances are still used in the forward and reverse cells, so this error goes, but is replaced by:

`ValueError: Attempt to reuse RNNCell <tensorflow.contrib.rnn.python.ops.core_rnn_cell_impl.BasicLSTMCell object at 0x7f7584639050> with a different variable scope than its first use.  First use of cell was with scope 'encoder/rnn/multi_rnn_cell/cell_0/basic_lstm_cell', this attempt is with scope 'decoder/multi_rnn_cell/cell_0/basic_lstm_cell'.  Please create a new instance of the cell if you would like it to use a different set of weights.  If before you were using: MultiRNNCell([BasicLSTMCell(...)] * num_layers), change to: MultiRNNCell([BasicLSTMCell(...) for _ in range(num_layers)]).  If before you were using the same cell instance as both the forward and reverse cell of a bidirectional RNN, simply create two instances (one for forward, one for reverse).  In May 2017, we will start transitioning this cell's behavior to use existing stored weights, if any, when it is called with scope=None (which can lead to silent model degradation, so this error will remain until then.)`

Someone who knows the code better will need to fix that second part too to get it actually working again.",richardjdavies,b'cla: yes',2017-05-17T16:16:35Z,2017-05-18T00:37:43Z,,,,,,,
1476,Attention_OCR Model,"### System information
- What is the top-level directory of the model you are using: attention_ocr
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): stock code
- OS Platform and Distribution: Linux Ubuntu 16.04
- TensorFlow installed from (source or binary): installed via pip
- TensorFlow version (use command below): 1.0.1 [also tried it in 1.1.0]
- Bazel version (if compiling from source): N/A
- CUDA/cuDNN version: I'm using CPU

### Describe the problem
I'm trying to execute the code posted in the readme file:

> wget http://download.tensorflow.org/models/attention_ocr_2017_05_01.tar.gz
> tar xf attention_ocr_2017_05_01.tar.gz
> python train.py --checkpoint=model.ckpt-232572

1. I noticed the checkpoint number (232672) written in the readme is not the same as the one found in the tar.gz file (230849). 
2. I also placed the three files (model.ckpt-230849.data-00000-of-00001, model.ckpt-230849.index, model.ckpt-230849.meta) found in attention_ocr_2017_05_01.tar.gz in the same directory as the train.py and the script can't seem to find the model file. I also tried changing the checkpoint parameter to  --checkpoint=model.ckpt-230849 and the script can't still find it.
3. Also, is there a way for me to use my own images instead of the FSNS?

### Log
  File ""/opt/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/framework/python/ops/variables.py"", line 512, in assign_from_checkpoint
    reader = pywrap_tensorflow.NewCheckpointReader(model_path)
  File ""/opt/anaconda2/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 110, in NewCheckpointReader
    return CheckpointReader(compat.as_bytes(filepattern), status)
  File ""/opt/anaconda2/lib/python2.7/contextlib.py"", line 24, in __exit__
    self.gen.next()
  File ""/opt/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/errors_impl.py"", line 466, in raise_exception_on_not_ok_status
    pywrap_tensorflow.TF_GetCode(status))
tensorflow.python.framework.errors_impl.NotFoundError: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for model.ckpt-232572
",leifsyliongka,b'stat:awaiting response type:bug',2017-05-17T03:24:38Z,2017-05-31T03:17:27Z,,,,,,,
1460,"How can i recognize age and gender, is there any model for that?","Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",roysG,None,2017-05-11T14:05:36Z,2017-05-11T23:11:12Z,,,,,,,
1453,vidia-smi,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",ghost,None,2017-05-08T06:30:13Z,2017-05-08T06:40:11Z,,,,,,,
1452,Non-trainable layers are updated during fine-tuning,"### System information
- **What is the top-level directory of the model you are using**: models-master\slim
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: I haven't written my code. I've only applied  https://github.com/tensorflow/models/pull/1422 and https://github.com/tensorflow/models/pull/1346 fixes which are related to reading of the datasets
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows Server 2016 (Google Cloud Platform)
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.1.0
- **Bazel version (if compiling from source)**: I didn't use bazel
- **CUDA/cuDNN version**: 8.0.61/5.1
- **GPU model and memory**: 1 x NVIDIA Tesla K80, 15GB RAM
- **Exact command to reproduce**: 

Checkpoint is downloaded and unzipped manually.

**set work_dir=C:\Dev\work_dir
set train_dir=%work_dir%\train_dir
set datasets=%work_dir%\datasets
set checkoints=%work_dir%\checkpoints
set curr_model=inception_resnet_v2
set curr_ckpt_date=2016_08_30
python train_image_classifier.py ^
--train_dir=%train_dir%\%curr_model% ^
--dataset_dir=%datasets%\%curr_dataset% ^
--dataset_name=%curr_dataset% ^
--dataset_split_name=train ^
--model_name=%curr_model% ^
--checkpoint_path=%checkpoints%\%curr_model%\%curr_model%_%curr_ckpt_date%.ckpt ^
--checkpoint_exclude_scopes=InceptionResnetV2/Logits,InceptionResnetV2/AuxLogits ^
--trainable_scopes=InceptionResnetV2/Logits,InceptionResnetV2/AuxLogits**

So the resolved command looks like:

**python train_image_classifier.py ^
--train_dir=C:\Dev\work_dir\train_dir\inception_resnet_v2 ^
--dataset_dir=C:\Dev\work_dir\datasets\flowers ^
--dataset_name=flowers ^
--dataset_split_name=train ^
--model_name=inception_resnet_v2 ^
--checkpoint_path=C:\Dev\work_dir\checkpoints\inception_resnet_v2\inception_resnet_v2_2016_08_30.ckpt ^
--checkpoint_exclude_scopes=InceptionResnetV2/Logits,InceptionResnetV2/AuxLogits ^
--trainable_scopes=InceptionResnetV2/Logits,InceptionResnetV2/AuxLogits**

### Describe the problem
I fine-tuned inception-resent-v2 model on flowers dataset. I applied appropriate flags:
--checkpoint_exclude_scopes=InceptionResnetV2/Logits,InceptionResnetV2/AuxLogits ^
--trainable_scopes=InceptionResnetV2/Logits,InceptionResnetV2/AuxLogits
I expected that only Logits and AuxLogits blocks will be trained and all other layers will not be changed during the fine-tuning. However after training I have found that Tensorboard displays changes for BatchNormalization and Convolutional weights (histograms ->InceptionResnetV2 section) for such blocks as Repeat, Repeat2, Block8 etc. From my point of view it is a bug because those layers should be untouched during the fine-tuning but they are.
Could you please review this issue?

### Source code / logs
Sources:
https://drive.google.com/open?id=0B71CmqrSAIWWNGhVUG43Ulc5UFk

Original checkpoint:
https://drive.google.com/open?id=0B71CmqrSAIWWNGhVUG43Ulc5UFk

Training directory:
https://drive.google.com/open?id=0B71CmqrSAIWWSndmSnVzaUptcGM

Screenshot of changed non-trainable layers weights:
![screen shot 2017-05-07 at 1 56 39 pm](https://cloud.githubusercontent.com/assets/17811772/25780326/a7e5503c-332e-11e7-8681-684fb310a3ae.jpg)",dubchek,b'stat:awaiting model gardener',2017-05-07T11:14:07Z,2020-02-07T18:40:58Z,,,,,,,
1447,resnet_v1 and v2 segmentation bugs from 7e2435e resolved,"7e2435e added a squeeze option, which introduced a bug in which logits would never be assigned if squeeze is False. This pull request fixes the bug in resnet_v1 and resnet_v2",ahundt,b'cla: yes',2017-05-05T23:14:37Z,2017-05-06T00:06:52Z,,,,,,,
1436,[slim] Python 3 support,"### System information
- **What is the top-level directory of the model you are using**: slim
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: no
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: MacOS 10.12.3 (16D32)
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.1.0
- **Bazel version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**: `cd slim && python download_and_convert_data.py --dataset_name=flowers --dataset_dir=data`

Here's the output from the environment capture script:

```

== cat /etc/issue ===============================================
Darwin Brandons-MBP.connect 16.4.0 Darwin Kernel Version 16.4.0: Thu Dec 22 22:53:21 PST 2016; root:xnu-3789.41.3~3/RELEASE_X86_64 x86_64
Mac OS X 10.12.3

== are we in docker =============================================
No

== compiler =====================================================
Apple LLVM version 8.0.0 (clang-800.0.42.1)
Target: x86_64-apple-darwin16.4.0
Thread model: posix
InstalledDir: /Library/Developer/CommandLineTools/usr/bin

== uname -a =====================================================
Darwin Brandons-MBP.connect 16.4.0 Darwin Kernel Version 16.4.0: Thu Dec 22 22:53:21 PST 2016; root:xnu-3789.41.3~3/RELEASE_X86_64 x86_64

== check pips ===================================================
numpy (1.12.1)
protobuf (3.2.0)
tensorflow (1.1.0)

== check for virtualenv =========================================
False

== tensorflow import ============================================
tf.VERSION = 1.1.0
tf.GIT_VERSION = v1.1.0-rc0-61-g1ec6ed5
tf.COMPILER_VERSION = v1.1.0-rc0-61-g1ec6ed5
Sanity check: array([1], dtype=int32)

== env ==========================================================
LD_LIBRARY_PATH is unset
DYLD_LIBRARY_PATH is unset

== nvidia-smi ===================================================

== cuda libs  ===================================================
```

### Describe the problem
The slim/download_and_convert_data.py script doesn't work with Python 3.6.0.  It gives the following output:

```Python traceback
Traceback (most recent call last):
  File ""download_and_convert_data.py"", line 39, in <module>
    from datasets import download_and_convert_cifar10
  File ""/Users/pokey/src/deep-stats/models/slim/datasets/download_and_convert_cifar10.py"", line 29, in <module>
    import cPickle
ModuleNotFoundError: No module named 'cPickle'
```

To fix this, I patched as follows:

```diff
diff --git a/slim/datasets/download_and_convert_cifar10.py b/slim/datasets/download_and_convert_cifar10.py
index 2cb787d..ee8928b 100644
--- a/slim/datasets/download_and_convert_cifar10.py
+++ b/slim/datasets/download_and_convert_cifar10.py
@@ -26,7 +26,7 @@ from __future__ import absolute_import
 from __future__ import division
 from __future__ import print_function
 
-import cPickle
+import pickle
 import os
 import sys
 import tarfile
@@ -73,7 +73,7 @@ def _add_to_tfrecord(filename, tfrecord_writer, offset=0):
     The new offset.
   """"""
   with tf.gfile.Open(filename, 'r') as f:
-    data = cPickle.load(f)
+    data = pickle.load(f)
 
   images = data['data']
   num_images = images.shape[0]
```

However, I then get the following:

```Python traceback
>> Downloading flower_photos.tgz 100.0%
Successfully downloaded flower_photos.tgz 228813984 bytes.
>> Converting image 1/3320 shard 0Traceback (most recent call last):
  File ""download_and_convert_data.py"", line 73, in <module>
    tf.app.run()
  File ""/Users/pokey/.pyenv/versions/deep-stats/lib/python3.6/site-packages/tensorflow/python/platform/app.py"", line 48, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""download_and_convert_data.py"", line 65, in main
    download_and_convert_flowers.run(FLAGS.dataset_dir)
  File ""/Users/pokey/src/deep-stats/models/slim/datasets/download_and_convert_flowers.py"", line 202, in run
    dataset_dir)
  File ""/Users/pokey/src/deep-stats/models/slim/datasets/download_and_convert_flowers.py"", line 139, in _convert_dataset
    image_data = tf.gfile.FastGFile(filenames[i], 'r').read()
  File ""/Users/pokey/.pyenv/versions/deep-stats/lib/python3.6/site-packages/tensorflow/python/lib/io/file_io.py"", line 122, in read
    pywrap_tensorflow.ReadFromStream(self._read_buf, length, status))
  File ""/Users/pokey/.pyenv/versions/deep-stats/lib/python3.6/site-packages/tensorflow/python/lib/io/file_io.py"", line 90, in _prepare_value
    return compat.as_str_any(val)
  File ""/Users/pokey/.pyenv/versions/deep-stats/lib/python3.6/site-packages/tensorflow/python/util/compat.py"", line 106, in as_str_any
    return as_str(value)
  File ""/Users/pokey/.pyenv/versions/deep-stats/lib/python3.6/site-packages/tensorflow/python/util/compat.py"", line 84, in as_text
    return bytes_or_text.decode(encoding)
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte
```",pokey,b'type:bug',2017-05-03T11:42:01Z,2018-11-17T19:56:30Z,,,,,,,
1429,Im2Txt not working for other languages like hindi,"
------------------------

### System information
- **What is the top-level directory of the model you are using** models/Im2Txt:
- **OS Platform and Distribution : Linux CentOS 7**:
- **TensorFlow installed from Binary**:
- **TensorFlow version:('v1.0.0-rc1-102-g1536a84-dirty', '1.0.0-rc2')**:

I am trying to use im2txt model with MSCOCO dataset modified to use hindi caption. When I tried to pre-process dataset using bazel-bin/im2txt/download_and_preprocess_mscoco ""${MSCOCO_DIR}"" command, it will work until generating word_count file. In step of generating TFrecord it throws following error:

Exception in thread Thread-14:
Traceback (most recent call last):
  File ""/usr/lib64/python2.7/threading.py"", line 811, in __bootstrap_inner
    self.run()
  File ""/usr/lib64/python2.7/threading.py"", line 764, in run
    self.__target(*self.__args, **self.__kwargs)
  File ""/root/.cache/bazel/_bazel_root/5d96493270bd616258f6b3292edd375b/execroot/im2txt/bazel-out/local-fastbuild/bin/im2txt/build_mscoco_data.runfiles/im2txt/im2txt/data/build_mscoco_data.py"", line 281, in _process_image_files
    sequence_example = _to_sequence_example(image, decoder, vocab)
  File ""/root/.cache/bazel/_bazel_root/5d96493270bd616258f6b3292edd375b/execroot/im2txt/bazel-out/local-fastbuild/bin/im2txt/build_mscoco_data.runfiles/im2txt/im2txt/data/build_mscoco_data.py"", line 234, in _to_sequence_example
    ""image/caption"": _bytes_feature_list(caption),
  File ""/root/.cache/bazel/_bazel_root/5d96493270bd616258f6b3292edd375b/execroot/im2txt/bazel-out/local-fastbuild/bin/im2txt/build_mscoco_data.runfiles/im2txt/im2txt/data/build_mscoco_data.py"", line 202, in _bytes_feature_list
    return tf.train.FeatureList(feature=[_bytes_feature(v) for v in values])
  File ""/root/.cache/bazel/_bazel_root/5d96493270bd616258f6b3292edd375b/execroot/im2txt/bazel-out/local-fastbuild/bin/im2txt/build_mscoco_data.runfiles/im2txt/im2txt/data/build_mscoco_data.py"", line 192, in _bytes_feature
    return tf.train.Feature(bytes_list=tf.train.BytesList(value=str(value)))
UnicodeEncodeError: 'ascii' codec can't encode characters in position 0-2: ordinal not in range(128)


It seems error in encoding data to tfrecord. I have also tried to modify str(value) using unicode encode  function. 
Sample caption file is available at: https://drive.google.com/file/d/0B8Rng3ofk0uAbDBJekpPR3BXVzA/view?usp=sharing
",shahparth123,b'type:bug',2017-05-01T13:32:37Z,2018-10-08T00:17:18Z,,,,,,,
1428,[Slim] Imagenet training not utilizing multiple GPUs efficiently,"Hi,

I am running some tests on Slim's imagenet training using Inception Resnet V2. The training is done on AWS ec2 instances (p2.xlarge and p2.8xlarge): Here are the specs for both:

1) p2.xlarge: GPUs (1), vCPUs (4), Ram (61GB)
2) p2.8xlarge: GPUs (8), vCPUs (32), Ram (488GB)

The GPUs are all Nvidia Tesla K80

Tensorflow seems to detect and loads the training on all GPUs according to both the training output and nvidia-smi. However there does not seem to be much difference in execution times.


On the **p2.xlarge** instance, TF/Slim reported an average of **3.05 sec/step**. 
On the **p2.8xlarge**  instance it reported an average of **2.96 sec/step**

I was expecting the time to drop significantly but given the above results I do not see a huge benefit running the training on multiple GPUs. 

Both instances have a copy of the same exact training datasets and scripts. I am running the training using this command:

```
DATASET_DIR=/imagenet2
TRAIN_DIR=/imagenet2/train_logs
python train_image_classifier.py \
	--train_dir=${TRAIN_DIR} \
	--dataset_name=imagenet \
	--dataset_split_name=train \
	--dataset_dir=${DATASET_DIR} \
	--max_number_of_steps=20000 \
	--model_name=inception_resnet_v2
```

Both instances running Tensorflow 1.0.1 running from binary as VM
Both instances are running Ubuntu 14.04 x64


Regards

",redserpent7,b'type:bug',2017-05-01T11:46:42Z,2018-02-08T18:22:15Z,,,,,,,
1417,GPU out of memory when using Tensorflow Slim,"I have used Tensorflow / Slim to implement ResNext 50 framework. When I run the program with a cardinality (the number of groups used in ResNext, see detailed explanations below) of 32, the GPU is always out of memory, even if I set the batch size to 1. When I use cardinality of 4, I can successfully run the program with a batch size of 16.

------------Update----------------
I find the reason is due to the update of start_dim (see labeled below) does not work. I change the codes locations and the program now works. It's somewhat weird to me.
------------Update End-----------

My system information:
Tensorflow: 1.10rc1
OS: Windows 10
Cuda: 8.0
Cudnn: 5.1
Python: 3.5
GPU: one Quadro M4000 with 8GB memory
CPU: 16 cores
Memory: 64GB

When running Resnet_v1 50, there is no problem on my machine. Therefore, I guess the crash comes from the cardinality which make the framework wider. My codes are copied below. 

(For people not familiar with ResNext bottleneck, here is the simple explanation. If input depth is 256, then it first use 1x1 conv to convert it to depth of 128. Then the 128 depths were divided into ""cardinality"" (32 here) groups, and 3x3 convs were performed within each group with same output depth as input (4 here). All results from the 32 groups are concatenated to form a 128 depth tensor again. Finally a 1x1 conv is performed to get the 256 depth output)

Take input = 256 dim and cardinality = 32 as an example. In my opinion, the division of each sub tensor only has a depth of 4. Even all of them are allocated in the GPU, the union of these tensors only cost two times of the original memory (WxHx128 instead of WxHx64 as in Resnet). All other tensors share the same size. Therefore, the maximum memory should be no more than 2 times of ResNet, which should be simply achieved by setting half of the original batch size (32-->16). However, even if I set batch size to 1, the program still crashes. Could this be a bug in Tensorflow/Slim or some issues in my codes? Thank you


My bottleneck function is defined as:

	@slim.add_arg_scope
	def bottleneck(inputs, depth, depth_bottleneck, cardinality, stride, rate=1,
				   outputs_collections=None, scope=None):
	  with tf.variable_scope(scope, 'bottleneck_vc', [inputs]) as sc:
		depth_in = slim.utils.last_dimension(inputs.get_shape(), min_rank=4)
		if depth == depth_in:
		  shortcut = resnext_utils.subsample(inputs, stride, 'shortcut')
		else:
		  shortcut = slim.conv2d(inputs, depth, [1, 1], stride=stride,
								 activation_fn=None, scope='shortcut')

		residual = slim.conv2d(inputs, depth_bottleneck, [1, 1], stride=1,
							   scope='conv1')

		residual_merge = []
		step = depth_bottleneck / cardinality
		start_dim = 0
		for i in range(cardinality):
		  with tf.variable_scope('conv2_%d' % (i + 1)) as local_sc:
			end_dim = round(step * (i + 1))
			dim_num = end_dim - start_dim
			part_residual = tf.slice(residual,
				[0,0,0,start_dim], [-1,-1,-1,dim_num])
			part_out = resnext_utils.conv2d_same(part_residual, dim_num, 3, stride, rate=rate, scope=local_sc)       
			if i == 0:
			  residual_merge = part_out
			else:
			  residual_merge = tf.concat([residual_merge, part_out], 3)
        
			star_dim = end_dim  #------------Update: this line does not work-------------
    
		residual = slim.conv2d(residual_merge, depth, [1, 1], stride=1,
							   activation_fn=None, scope='conv3')
		output = tf.nn.relu(shortcut + residual)

		return slim.utils.collect_named_outputs(outputs_collections, sc.original_name_scope, output)

The net definition is exact the same as ResNext-50 mentioned in the paper. Therefore, theoretically, the number of parameters is even smaller than ResNet-50. However, ResNet-50 can run without problem with batch size 32, while ResNext-50 cannot run even with batch size 1.

My network definition is as below, where the ""32"" is the cardinality.

	def resnext_vc_50(inputs,
					 num_classes=None,
					 is_training=True,
					 global_pool=True,
					 output_stride=None,
					 reuse=None,
					 scope='resnext_vc_50'):

	  blocks = [
		  resnext_utils.Block(
			  'block1', bottleneck, [(256, 128, 32, 1)] * 2 + [(256, 128, 32, 2)]),
		  resnext_utils.Block(
			  'block2', bottleneck, [(512, 256, 32, 1)] * 3 + [(512, 256, 32, 2)]),
		  resnext_utils.Block(
			  'block3', bottleneck, [(1024, 512, 32, 1)] * 5 + [(1024, 512, 32, 2)]),
		  resnext_utils.Block(
			  'block4', bottleneck, [(2048, 1024, 32, 1)] * 3)
	  ]

	  return resnext_vc(inputs, blocks, num_classes, is_training,
					   global_pool=global_pool, output_stride=output_stride,
					   include_root_block=True, reuse=reuse, scope=scope)
",ybsave,None,2017-04-26T21:04:48Z,2017-04-26T23:54:15Z,,,,,,,
1407,Out of bound error on Swivel.py model,"I was running swivel.py, and the only thing I changed was CPU instead of GPU, but still got an error message as below:

> InvalidArgumentError (see above for traceback): indices[3926] = [0,4096] is out of bounds: need 0 <= index < [4096,4096]
	 [[Node: SparseToDense = SparseToDense[T=DT_FLOAT, Tindices=DT_INT64, validate_indices=true, _device=""/job:localhost/replica:0/task:0/cpu:0""](concat, SparseToDense/output_shape, ParseSingleExample/ParseExample/ParseExample:5, SparseToDense/default_value)]]

How can I fix this? Also, why is index < [4096,4096]? shouldn't it be <= [4096,4096], since the number of shard was set to be 4096??

Below is the link to swivel.py
https://github.com/tensorflow/models/blob/dc135d79b8e5ec725e14a5fef050859ec57e83bb/swivel/swivel.py
",gahu1125,b'stat:awaiting model gardener type:bug',2017-04-25T17:35:55Z,2017-10-22T21:17:11Z,,,,,,,
1406,DOC: document bash use for resnet,I ran into a bug under zsh with `--train_data=cifar10/data_batch*`.,stsievert,b'cla: yes stat:awaiting response',2017-04-25T15:20:20Z,2017-04-26T20:19:58Z,,,,,,,
1400,Neural_programmer bug,"Hi, 

I keep getting this error trying to run `python neural_programmer.py`,

```
(tf_py2_tf_1_0) ajay@ajay-h8-1170uk:~/PythonProjects/TF_models_v1/neural_programmer$ python neural_programmer.py
Annotated examples loaded  14152
Annotated examples loaded  4344
entry match token:  9133 9133
entry match token:  9134 9134
# train examples  10178
# dev examples  2546
# test examples  3913
running open source
forget gate bias
Traceback (most recent call last):
  File ""neural_programmer.py"", line 237, in <module>
    tf.app.run()
  File ""/home/ajay/anaconda3/envs/tf_py2_tf_1_0/lib/python2.7/site-packages/tensorflow/python/platform/app.py"", line 48, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""neural_programmer.py"", line 233, in main
    master(train_data, dev_data, utility)
  File ""neural_programmer.py"", line 160, in master
    graph.create_graph(params, global_step)
  File ""/home/ajay/PythonProjects/TF_models_v1/neural_programmer/model.py"", line 636, in create_graph
    self.total_cost = self.compute_error() 
  File ""/home/ajay/PythonProjects/TF_models_v1/neural_programmer/model.py"", line 582, in compute_error
    1, [self.batch_number_column_mask, self.batch_word_column_mask])
  File ""/home/ajay/anaconda3/envs/tf_py2_tf_1_0/lib/python2.7/site-packages/tensorflow/python/ops/array_ops.py"", line 1029, in concat
    dtype=dtypes.int32).get_shape(
  File ""/home/ajay/anaconda3/envs/tf_py2_tf_1_0/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 639, in convert_to_tensor
    as_ref=False)
  File ""/home/ajay/anaconda3/envs/tf_py2_tf_1_0/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 704, in internal_convert_to_tensor
    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
  File ""/home/ajay/anaconda3/envs/tf_py2_tf_1_0/lib/python2.7/site-packages/tensorflow/python/framework/constant_op.py"", line 113, in _constant_tensor_conversion_function
    return constant(v, dtype=dtype, name=name)
  File ""/home/ajay/anaconda3/envs/tf_py2_tf_1_0/lib/python2.7/site-packages/tensorflow/python/framework/constant_op.py"", line 102, in constant
    tensor_util.make_tensor_proto(value, dtype=dtype, shape=shape, verify_shape=verify_shape))
  File ""/home/ajay/anaconda3/envs/tf_py2_tf_1_0/lib/python2.7/site-packages/tensorflow/python/framework/tensor_util.py"", line 370, in make_tensor_proto
    _AssertCompatible(values, dtype)
  File ""/home/ajay/anaconda3/envs/tf_py2_tf_1_0/lib/python2.7/site-packages/tensorflow/python/framework/tensor_util.py"", line 302, in _AssertCompatible
    (dtype.name, repr(mismatch), type(mismatch).__name__))
TypeError: Expected int32, got list containing Tensors of type '_Message' instead.
```

- **What is the top-level directory of the model you are using**:
https://github.com/tensorflow/models/tree/master/neural_programmer

- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
No

- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Ubuntu 14.04

- **TensorFlow installed from (source or binary)**:
binary

- **TensorFlow version (use command below)**:

('v1.1.0-rc0-61-g1ec6ed5', '1.1.0')

- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:

CPU mode

- **Exact command to reproduce**:

python neural_programmer.py


You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",AjayTalati,b'help wanted type:bug',2017-04-25T10:12:20Z,2018-11-12T08:43:00Z,,,,,,,
1395,"""Found input thread dead"" and ""No attribute next""","When running 

     bazel-bin/textsum/seq2seq_attention \
     --mode=train \
     --article_key=article \
     --abstract_key=abstract \
     --data_path=data/bin_data_train\
     --vocab_path=data/vocab \
     --log_root=textsum/log_root \
     --train_dir=textsum/log_root/train

I get this error:

    ERROR:tensorflow:Found input thread dead.
    Exception in thread Thread-377:
    Traceback (most recent call last):
      File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/threading.py"", line 916,     in _bootstrap_inner
        self.run()
      File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/threading.py"", line 864,    in run
        self._target(*self._args, **self._kwargs)
      File ""/Users/johnjosephhiggins/PycharmProjects/prometheadj/models/textsum/batch_reader.py"",     line 136, in _FillInputQueue
        (article, abstract) = input_gen.next()
     AttributeError: 'generator' object has no attribute 'next'


I've done everything correctly, as far as I know. I'm running on CPU-- no CUDA. I have a pretty new Mac, OS Yosemite with 8GB free. Python 3.6.

I think the first error ""Input thread dead"" might be tied to the second ""no attribute next."" I opened a pull request changing 

    .next( )

to

    .__next__( )

in 'batch_reader.py'. That removes the ""no attribute 'next'"" and ""found thread dead"" errors, but causes training to stop after the first global step. I waited for ~3 hours and received no new messages from either tensorboard or terminal.

Any thoughts? Is my pull request worth a shot?
",Higgins2718,b'stat:awaiting model gardener type:bug',2017-04-24T22:35:20Z,2017-05-11T22:14:57Z,,,,,,,
1392,some debug about seq2seq_attention_model.py,"I have found some debug in seq2seq_attention_model.py, the seq2seq_lib.sampled_sequence_loss function 's fourth parameters is a boolean variable. so the right coding is sampled_sequence_loss(
              decoder_outputs, targets, loss_weights, True, sampled_loss_func) not sampled_sequence_loss(decoder_outputs, targets, loss_weights, sampled_loss_func) ",zhangluoyang,b'stat:awaiting response',2017-04-24T14:58:08Z,2018-02-24T18:55:02Z,,,,,,,
1390,Slim multi-gpu performance problems,"I was using slim models with flower dataset in Ubuntu 16.04.

Tensorflow version:1.1.0rc2 from src

git version:
34c738cc6d3badcb22e3f72482536ada29bd0e65

Bazel version:
Build label: 0.4.5
Build target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Thu Mar 16 12:19:38 2017 (1489666778)
Build timestamp: 1489666778
Build timestamp as int: 1489666778

CUDA version: 8.0.44
cuDNN version:5.1.5
GPU: 3GPUs. All of them are GeForce GTX 1080Ti 11GB
Memory: 32GB

I didn't change source code.
with 1 GPU:

TRAIN_DIR=/tmp/train_logs
DATASET_DIR=/home/l/data/flowers
python train_image_classifier.py     --train_dir=${TRAIN_DIR}     --dataset_name=flowers     --dataset_split_name=train     --dataset_dir=${DATASET_DIR}     --model_name=inception_resnet_v2
…
(log here is same as running with 3 gpus)
…
INFO:tensorflow:global_step/sec: 0
INFO:tensorflow:Recording summary at step 0.
INFO:tensorflow:global step 10: loss = 3.2313 (0.96 sec/step)
INFO:tensorflow:global step 20: loss = 3.7792 (0.97 sec/step)
INFO:tensorflow:global step 30: loss = 2.9681 (0.96 sec/step)
INFO:tensorflow:global step 40: loss = 3.8321 (0.97 sec/step)
INFO:tensorflow:global step 50: loss = 3.2210 (0.96 sec/step)
...

when I use 3 gpus:
python train_image_classifier.py     --train_dir=${TRAIN_DIR}     --dataset_name=flowers     --dataset_split_name=train     --dataset_dir=${DATASET_DIR}     --model_name=inception_resnet_v2 --num_clones=3
2017-04-24 14:26:11.885411: I tensorflow/core/common_runtime/gpu/gpu_device.cc:887] Found device 0 with properties: 
name: Graphics Device
major: 6 minor: 1 memoryClockRate (GHz) 1.582
pciBusID 0000:05:00.0
Total memory: 10.91GiB
Free memory: 10.53GiB
2017-04-24 14:26:11.885472: W tensorflow/stream_executor/cuda/cuda_driver.cc:485] creating context when one is currently active; existing: 0x5b62c2c0
2017-04-24 14:26:12.131777: I tensorflow/core/common_runtime/gpu/gpu_device.cc:887] Found device 1 with properties: 
name: Graphics Device
major: 6 minor: 1 memoryClockRate (GHz) 1.582
pciBusID 0000:06:00.0
Total memory: 10.91GiB
Free memory: 10.75GiB
2017-04-24 14:26:12.131848: W tensorflow/stream_executor/cuda/cuda_driver.cc:485] creating context when one is currently active; existing: 0x5945f2d0
2017-04-24 14:26:12.369331: I tensorflow/core/common_runtime/gpu/gpu_device.cc:887] Found device 2 with properties: 
name: Graphics Device
major: 6 minor: 1 memoryClockRate (GHz) 1.582
pciBusID 0000:09:00.0
Total memory: 10.91GiB
Free memory: 10.75GiB
2017-04-24 14:26:12.371583: I tensorflow/core/common_runtime/gpu/gpu_device.cc:908] DMA: 0 1 2 
2017-04-24 14:26:12.371596: I tensorflow/core/common_runtime/gpu/gpu_device.cc:918] 0:   Y Y Y 
2017-04-24 14:26:12.371601: I tensorflow/core/common_runtime/gpu/gpu_device.cc:918] 1:   Y Y Y 
2017-04-24 14:26:12.371606: I tensorflow/core/common_runtime/gpu/gpu_device.cc:918] 2:   Y Y Y 
2017-04-24 14:26:12.371615: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Graphics Device, pci bus id: 0000:05:00.0)
2017-04-24 14:26:12.371622: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977] Creating TensorFlow device (/gpu:1) -> (device: 1, name: Graphics Device, pci bus id: 0000:06:00.0)
2017-04-24 14:26:12.371625: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977] Creating TensorFlow device (/gpu:2) -> (device: 2, name: Graphics Device, pci bus id: 0000:09:00.0)
INFO:tensorflow:Restoring parameters from /tmp/train_logs/model.ckpt-0
**2017-04-24 14:26:17.426353: I tensorflow/core/common_runtime/simple_placer.cc:669] Ignoring device specification /device:GPU:2 for node 'clone_2/fifo_queue_Dequeue' because the input edge from 'prefetch_queue/fifo_queue' is a reference connection and already has a device field set to /device:CPU:0
2017-04-24 14:26:17.427748: I tensorflow/core/common_runtime/simple_placer.cc:669] Ignoring device specification /device:GPU:1 for node 'clone_1/fifo_queue_Dequeue' because the input edge from 'prefetch_queue/fifo_queue' is a reference connection and already has a device field set to /device:CPU:0
2017-04-24 14:26:17.429099: I tensorflow/core/common_runtime/simple_placer.cc:669] Ignoring device specification /device:GPU:0 for node 'clone_0/fifo_queue_Dequeue' because the input edge from 'prefetch_queue/fifo_queue' is a reference connection and already has a device field set to /device:CPU:0**
INFO:tensorflow:Starting Session.
INFO:tensorflow:Saving checkpoint to path /tmp/train_logs/model.ckpt
INFO:tensorflow:Starting Queues.
INFO:tensorflow:global_step/sec: 0
INFO:tensorflow:Recording summary at step 0.
INFO:tensorflow:global step 10: loss = 2.9670 (0.98 sec/step)
INFO:tensorflow:global step 20: loss = 2.9945 (0.99 sec/step)
INFO:tensorflow:global step 30: loss = 3.0432 (0.99 sec/step)
INFO:tensorflow:global step 40: loss = 3.0007 (1.04 sec/step)
INFO:tensorflow:global step 50: loss = 2.8072 (1.03 sec/step)
...

I saw ""Ignoring device specification"" and the training speed didn't change.
This is nvidia-smi output with 3 gpus.

+-----------------------------------------------------------------------------+
| NVIDIA-SMI 378.13                 Driver Version: 378.13                    |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  Graphics Device     Off  | 0000:05:00.0      On |                  N/A |
| 49%   83C    P2   140W / 250W |  10754MiB / 11171MiB |     98%      Default |
+-------------------------------+----------------------+----------------------+
|   1  Graphics Device     Off  | 0000:06:00.0     Off |                  N/A |
| 47%   81C    P2   137W / 250W |  10744MiB / 11172MiB |     98%      Default |
+-------------------------------+----------------------+----------------------+
|   2  Graphics Device     Off  | 0000:09:00.0     Off |                  N/A |
| 43%   74C    P2   130W / 250W |  10744MiB / 11172MiB |     98%      Default |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID  Type  Process name                               Usage      |
|=============================================================================|
|    0      1065    G   /usr/lib/xorg/Xorg                             160MiB |
|    0      1757    G   compiz                                          81MiB |
|    0     14407    C   python                                       10497MiB |
|    1     14407    C   python                                       10729MiB |
|    2     14407    C   python                                       10729MiB |
+-----------------------------------------------------------------------------+

Something Else
  I tried inception model with 3 gpus and it worked well with speed boost. There was no ""Ignoring device specification"" in inception model logs. I'm not sure whether it is the problem.

  similar problem: 
  #1338 
  https://github.com/tensorflow/tensorflow/issues/8061 (I tried the script in TF1.1.0 and ""Ignoring device specification"" appeared too. If someone needs details,I will post logs.)
 

 I changed model to inception_v3. It seems nothing changed.
 I'm also considering if I can output batch content that may be helpful.",Ettard,b'stat:awaiting model gardener type:bug',2017-04-24T07:36:08Z,2018-01-19T06:15:03Z,,,,,,,
1389,python vgslspecs_test.py,"I get the following error while executing python vgslspecs_test.py
kindly help me to resolve the bug
Traceback (most recent call last):
  File ""vgslspecs_test.py"", line 19, in <module>
    import vgslspecs
  File ""/home/sarfraaz/Downloads/tensorflow-models-master/street/python/vgslspecs.py"", line 24, in <module>
    import nn_ops
  File ""/home/sarfraaz/Downloads/tensorflow-models-master/street/python/nn_ops.py"", line 22, in <module>
    rnn = tf.load_op_library(""../cc/rnn_ops.so"")
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/load_library.py"", line 64, in load_op_library
    None, None, error_msg, error_code)
tensorflow.python.framework.errors_impl.NotFoundError: ../cc/rnn_ops.so: undefined symbol: _ZN10tensorflow7strings8internal9CatPiecesB5cxx11ESt16initializer_listINS_11StringPieceEE



",SarfraazMsa,b'stat:awaiting maintainer type:bug',2017-04-24T06:35:58Z,2018-07-17T14:10:10Z,,,,,,,
1378,cannot convert dictionary update sequence element #0 to a sequence,"My system is windows 10, python 3.5, tensorflow 1.0,
the path is E:\PycharmProjects\models\slim\nets\resnet_v2_test.py

Here is the error:
Error
Traceback (most recent call last):
  File ""E:\PycharmProjects\models\slim\nets\resnet_v2_test.py"", line 172, in testEndPointsV2
    _, end_points = self._resnet_plain(inputs, blocks, scope='tiny')
  File ""E:\PycharmProjects\models\slim\nets\resnet_v2_test.py"", line 162, in _resnet_plain
    end_points = dict(tf.get_collection('end_points'))
TypeError: cannot convert dictionary update sequence element #0 to a sequence

And by the way , my file nets have the resnet_v2.py , why I just use ""import resnet_v2"" in resnet_v2_test.py , it show no module named resnet_v2 ? And I use ""from nets import resnet_v2"" , it
still show no module named nets and no module named resnet_v2 ?",paulzhhong,b'stat:awaiting model gardener type:bug',2017-04-21T09:03:34Z,2018-02-24T18:39:58Z,,,,,,,
1376,wrapped_units.LayerNormBasicLSTMNetwork,"No1.
http://stackoverflow.com/questions/43509103/typeerror-init-got-an-unexpected-keyword-argument-reuse

for No1,i modify the file dragnn/python/wrapped_units.py by del del the "", reuse=True"" in 
""return tf.contrib.rnn.LayerNormBasicLSTMCell(
          num_units, layer_norm=self._attrs['layer_norm'], reuse=True)""  to slove the problem.

No2. using in dragnn model as blow:
 tagger.set_network_unit(name='wrapped_units.LayerNormBasicLSTMNetwork', hidden_layer_sizes='256)
when i run 
""text = '他們 是 親朋 好友 .'
tokens = [sentence_pb2.Token(word=word, start=-1, end=-1) for word in text.split()]
sentence = sentence_pb2.Sentence()
sentence.token.extend(tokens)
with tf.Session(graph=graph) as sess:
    # Restore the model we just trained.
    builder.saver.restore(sess, CHECKPOINT_FILENAME
)
    annotations, traces = sess.run([annotator['annotations'], annotator['traces']],
                      feed_dict={annotator['input_batch']: [sentence.SerializeToString()]})
HTML(visualization.trace_html(traces[0]))""

jupyter notebook show log as blow
[W 11:51:42.335 NotebookApp] Saving untrusted notebook trainer_tutorial.ipynb
I dragnn/core/compute_session_pool.cc:55] Destroying pool: total number of sessions created = 1
*** Error in `/usr/bin/python2.7': double free or corruption (!prev): 0x000000000109e160 ***
[I 11:52:25.327 NotebookApp] KernelRestarter: restarting kernel (1/5)
WARNING:root:kernel ad3ac582-fb41-4ffe-9a4f-e7b41ca1eabf restarted
 
source:
IN[1]: 
import os.path
import time
import random
import tensorflow as tf
from IPython.display import HTML
from tensorflow.python.platform import gfile
from tensorflow.python.platform import tf_logging as logging
from google.protobuf import text_format
from syntaxnet.ops import gen_parser_ops
from syntaxnet import load_parser_ops
from syntaxnet import task_spec_pb2
from syntaxnet import sentence_pb2
from dragnn.protos import spec_pb2 
from dragnn.python.sentence_io import ConllSentenceReader
from dragnn.python import evaluation
from dragnn.python import graph_builder
from dragnn.python import lexicon
from dragnn.python import load_dragnn_cc_impl
from dragnn.python import render_parse_tree_graphviz
from dragnn.python import render_spec_with_graphviz
from dragnn.python import spec_builder
from dragnn.python import trainer_lib
from dragnn.python import visualization

DATA_DIR = '/usr/cep/nlp/np/data/zht'
TENSORBOARD_DIR = '/usr/local/models/syntaxnet/tensorflow/tensorflow/tensorboard'
CHECKPOINT_FILENAME = '{}/zht.checkpoint'.format(DATA_DIR)
TRAINING_CORPUS_PATH = '{}/zh-ud-train.conllu'.format(DATA_DIR)
DEV_CORPUS_PATH = '{}/zh-ud-dev.conllu'.format(DATA_DIR)

assert os.path.isfile(TRAINING_CORPUS_PATH), '训练语料库不存在'

logging.set_verbosity(logging.WARN)

lexicon.build_lexicon(DATA_DIR, TRAINING_CORPUS_PATH)

lookahead = spec_builder.ComponentSpecBuilder('lookahead')
lookahead.set_network_unit(
    name='FeedForwardNetwork', hidden_layer_sizes='256')
lookahead.set_transition_system(name='shift-only', left_to_right='true')
lookahead.add_fixed_feature(name='words', fml='input.word', embedding_dim=32)
lookahead.add_rnn_link(embedding_dim=-1)
lookahead.fill_from_resources(DATA_DIR)

tagger = spec_builder.ComponentSpecBuilder('tagger')
tagger.set_network_unit(name='wrapped_units.LayerNormBasicLSTMNetwork', hidden_layer_sizes='256')
tagger.set_transition_system(name='tagger')
tagger.add_rnn_link(embedding_dim=-1)
tagger.add_token_link(source=lookahead, fml='input.focus', embedding_dim=32)
tagger.fill_from_resources(DATA_DIR)

parser = spec_builder.ComponentSpecBuilder('parser')
parser.set_network_unit(name='FeedForwardNetwork', hidden_layer_sizes='256',
                        layer_norm_hidden='true')
parser.set_transition_system(name='arc-standard')
parser.add_token_link(source=lookahead, fml='input.focus', embedding_dim=32)
parser.add_token_link(
    source=tagger, fml='input.focus stack.focus stack(1).focus',
    embedding_dim=32)

parser.add_fixed_feature(name='labels', embedding_dim=16,
                         fml=' '.join([
                             'stack.child(1).label',
                             'stack.child(1).sibling(-1).label',
                             'stack.child(-1).label',
                             'stack.child(-1).sibling(1).label',
                             'stack(1).child(1).label',
                             'stack(1).child(1).sibling(-1).label',
                             'stack(1).child(-1).label',
                             'stack(1).child(-1).sibling(1).label',
                             'stack.child(2).label',
                             'stack.child(-2).label',
                             'stack(1).child(2).label',
                             'stack(1).child(-2).label']))

parser.add_link(
        source=parser,  # recurrent connection
        name='rnn-stack',  # unique identifier
        fml='stack.focus stack(1).focus',  # look for both stack tokens
        source_translator='shift-reduce-step',  # maps token indices -> step
        embedding_dim=32)  # project down to 64 dims

parser.fill_from_resources(DATA_DIR)

master_spec = spec_pb2.MasterSpec()
master_spec.component.extend([lookahead.spec, tagger.spec, parser.spec])
HTML(render_spec_with_graphviz.master_spec_graph(master_spec))

IN[2]:
graph = tf.Graph()
with graph.as_default():
    hyperparam_config = spec_pb2.GridPoint(
        learning_method='adam',
        learning_rate=0.0005, 
        adam_beta1=0.9, adam_beta2=0.9, adam_eps=0.001,
        decay_steps=128000,
        dropout_rate=0.8, gradient_clip_norm=1,
        use_moving_average=True,
        seed=1)    
    builder = graph_builder.MasterBuilder(master_spec, hyperparam_config)
    target = spec_pb2.TrainTarget(
        name='all',
        unroll_using_oracle=[False, True, True], # train tagger & parser on gold unrolling, skip lookahead
        component_weights=[0, 0.5, 0.5]) # tagger and parser losses have equal weights
    trainer = builder.add_training_from_config(target)
    annotator = builder.add_annotation(enable_tracing=True)
    builder.add_saver()

N_STEPS = 20
BATCH_SIZE = 64
with tf.Session(graph=graph) as sess:
    sess.run(tf.global_variables_initializer())
    training_corpus = ConllSentenceReader(
        TRAINING_CORPUS_PATH, projectivize=True).corpus()
    dev_corpus = ConllSentenceReader(DEV_CORPUS_PATH).corpus()[:200]
    for step in xrange(N_STEPS):
        trainer_lib.run_training_step(sess, trainer, training_corpus, batch_size=BATCH_SIZE)
        tf.logging.warning('Step %d/%d', step + 1, N_STEPS)
    parsed_dev_corpus = trainer_lib.annotate_dataset(sess, annotator, dev_corpus)
    pos, uas, las = evaluation.calculate_parse_metrics(dev_corpus, parsed_dev_corpus)
    tf.logging.warning('POS %.2f UAS %.2f LAS %.2f', pos, uas, las)
    builder.saver.save(sess, CHECKPOINT_FILENAME)

IN[3]:
text = '他們 是 親朋 好友 .'
tokens = [sentence_pb2.Token(word=word, start=-1, end=-1) for word in text.split()]
sentence = sentence_pb2.Sentence()
sentence.token.extend(tokens)

with tf.Session(graph=graph) as sess:
    builder.saver.restore(sess, CHECKPOINT_FILENAME)
    annotations, traces = sess.run([annotator['annotations'], annotator['traces']],
                      feed_dict={annotator['input_batch']: [sentence.SerializeToString()]})
HTML(visualization.trace_html(traces[0]))

",haoran8899,b'stat:awaiting model gardener type:bug',2017-04-21T05:42:35Z,2020-02-07T18:40:57Z,,,,,,,
1374,It this a bug in distributed version ?,"I am trying the distributed tensorflow, and my code is shown as follow. The problem is that the chief worker can run as expected. However, non-chief worker will blocked at :
> sess = sv.prepare_or_wait_for_session(target, config=sess_config)

Is this a bug or just I made a mistake by myself ?  Could anybody help me solve this problem ?
```
  # Copyright 2016 Google Inc. All Rights Reserved.
  #
  # Licensed under the Apache License, Version 2.0 (the ""License"");
  # you may not use this file except in compliance with the License.
  # You may obtain a copy of the License at
  #
  #     http://www.apache.org/licenses/LICENSE-2.0
  #
  # Unless required by applicable law or agreed to in writing, software
  # distributed under the License is distributed on an ""AS IS"" BASIS,
  # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  # See the License for the specific language governing permissions and
  # limitations under the License.
  # ==============================================================================
  """"""A library to train Inception using multiple replicas with synchronous update.

  Please see accompanying README.md for details and instructions.
  """"""
  from __future__ import absolute_import
  from __future__ import division
  from __future__ import print_function

  from datetime import datetime
  import os.path
  import time

  import numpy as np
  import tensorflow as tf

  from inception.slim.datasets import dataset_factory
  from inception.slim.nets import nets_factory
  from inception.slim.preprocessing import preprocessing_factory
  from inception import inception_model as inception
  from inception.slim import slim
  #from inception import image_processing
  sslim = tf.contrib.slim
  FLAGS = tf.app.flags.FLAGS

  tf.app.flags.DEFINE_string(
  'dataset_name', 'imagenet', 'The name of the dataset to load.')
  tf.app.flags.DEFINE_string(
  'dataset_split_name', 'train', 'The name of the train/test split.')
  tf.app.flags.DEFINE_integer(
  'train_image_size', None, 'Train image size')
  tf.app.flags.DEFINE_string(
  'dataset_dir', None, 'The directory where the dataset files are stored.')
  tf.app.flags.DEFINE_string('job_name', '', 'One of ""ps"", ""worker""')
  tf.app.flags.DEFINE_string('ps_hosts', '',
                         """"""Comma-separated list of hostname:port for the """"""
                         """"""parameter server jobs. e.g. """"""
                         """"""'machine1:2222,machine2:1111,machine2:2222'"""""")
  tf.app.flags.DEFINE_string('worker_hosts', '',
                         """"""Comma-separated list of hostname:port for the """"""
                         """"""worker jobs. e.g. """"""
                         """"""'machine1:2222,machine2:1111,machine2:2222'"""""")
  tf.app.flags.DEFINE_float(
  'weight_decay', 0.00004, 'The weight decay on the model weights.')
  tf.app.flags.DEFINE_string('train_dir', '/tmp/imagenet_train',
                         """"""Directory where to write event logs """"""
                         """"""and checkpoint."""""")
  tf.app.flags.DEFINE_integer('max_steps', 100, 'Number of batches to run.')
  tf.app.flags.DEFINE_string('subset', 'train', 'Either ""train"" or ""validation"".')
  tf.app.flags.DEFINE_boolean('log_device_placement', False,
                          'Whether to log device placement.')
  tf.app.flags.DEFINE_string(
  'model_name', 'inception_v3', 'The name of the architecture to train.')
  tf.app.flags.DEFINE_integer(
  'batch_size', 32, 'The number of samples in each batch.')
  tf.app.flags.DEFINE_string(
  'preprocessing_name', None, 'The name of the preprocessing to use. If left '
  'as `None`, then the model_name flag is used.')
  # Task ID is used to select the chief and also to access the local_step for
  # each replica to check staleness of the gradients in sync_replicas_optimizer.
  tf.app.flags.DEFINE_integer(
  'task_id', 0, 'Task ID of the worker/replica running the training.')

  # More details can be found in the sync_replicas_optimizer class:
  # tensorflow/python/training/sync_replicas_optimizer.py
  tf.app.flags.DEFINE_integer('num_replicas_to_aggregate', -1,
                          """"""Number of gradients to collect before """"""
                          """"""updating the parameters."""""")
  tf.app.flags.DEFINE_integer('save_interval_secs', 10 * 60,
                          'Save interval seconds.')
  tf.app.flags.DEFINE_integer('save_summaries_secs', 10 * 60,
                          'Save summaries interval seconds.')

  # **IMPORTANT**
  # Please note that this learning rate schedule is heavily dependent on the
  # hardware architecture, batch size and any changes to the model architecture
  # specification. Selecting a finely tuned learning rate schedule is an
  # empirical process that requires some experimentation. Please see README.md
  # more guidance and discussion.
  #
  # Learning rate decay factor selected from https://arxiv.org/abs/1604.00981
  tf.app.flags.DEFINE_float('initial_learning_rate', 0.045,
                        'Initial learning rate.')
  tf.app.flags.DEFINE_float('num_epochs_per_decay', 2.0,
                        'Epochs after which learning rate decays.')
  tf.app.flags.DEFINE_float('learning_rate_decay_factor', 0.94,
                        'Learning rate decay factor.')

  # Constants dictating the learning rate schedule.
  RMSPROP_DECAY = 0.9                # Decay term for RMSProp.
  RMSPROP_MOMENTUM = 0.9             # Momentum in RMSProp.
  RMSPROP_EPSILON = 1.0              # Epsilon term for RMSProp.


  def train(target, dataset, cluster_spec):
  """"""Train Inception on a dataset for a number of steps.""""""
  # Number of workers and parameter servers are infered from the workers and ps
  # hosts string.
  num_workers = len(cluster_spec.as_dict()['worker'])
  num_parameter_servers = len(cluster_spec.as_dict()['ps'])
  # If no value is given, num_replicas_to_aggregate defaults to be the number of
  # workers.
  if FLAGS.num_replicas_to_aggregate == -1:
  num_replicas_to_aggregate = num_workers
  else:
  num_replicas_to_aggregate = FLAGS.num_replicas_to_aggregate

  # Both should be greater than 0 in a distributed training.
  assert num_workers > 0 and num_parameter_servers > 0, (' num_workers and '
                                                       'num_parameter_servers'
                                                       ' must be > 0.')

  # Choose worker 0 as the chief. Note that any worker could be the chief
  # but there should be only one chief.
  is_chief = (FLAGS.task_id == 0)
  # Ops are assigned to worker by default.
  with tf.device('/job:worker/task:%d' % FLAGS.task_id):
  # Variables and its related init/assign ops are assigned to ps.
  with slim.scopes.arg_scope(
      [slim.variables.variable, slim.variables.global_step],
      device=slim.variables.VariableDeviceChooser(num_parameter_servers)):
    # Create a variable to count the number of train() calls. This equals the
    # number of updates applied to the variables.
    global_step = slim.variables.global_step()

    # Calculate the learning rate schedule.
    num_batches_per_epoch = (dataset.num_examples_per_epoch() /
                             FLAGS.batch_size)
    # Decay steps need to be divided by the number of replicas to aggregate.
    decay_steps = int(num_batches_per_epoch * FLAGS.num_epochs_per_decay /
                      num_replicas_to_aggregate)

    # Decay the learning rate exponentially based on the number of steps.
    lr = tf.train.exponential_decay(FLAGS.initial_learning_rate,
                                    global_step,
                                    decay_steps,
                                    FLAGS.learning_rate_decay_factor,
                                    staircase=True)
    # Add a summary to track the learning rate.
    tf.summary.scalar('learning_rate', lr)

    # Create an optimizer that performs gradient descent.
    opt = tf.train.RMSPropOptimizer(lr,
                                    RMSPROP_DECAY,
                                    momentum=RMSPROP_MOMENTUM,
                                    epsilon=RMSPROP_EPSILON)

    dataset = dataset_factory.get_dataset(
      FLAGS.dataset_name, FLAGS.dataset_split_name, FLAGS.dataset_dir)
    network_fn = nets_factory.get_network_fn(
      FLAGS.model_name,
      num_classes=(dataset.num_classes),
      weight_decay=FLAGS.weight_decay,
      is_training=True)
    preprocessing_name = FLAGS.preprocessing_name or FLAGS.model_name
    image_preprocessing_fn = preprocessing_factory.get_preprocessing(
      preprocessing_name,
      is_training=True)
    provider = sslim.dataset_data_provider.DatasetDataProvider(
        dataset,
        num_readers=4,
        common_queue_capacity=20 * FLAGS.batch_size,
        common_queue_min=10 * FLAGS.batch_size)
    [image, label] = provider.get(['image', 'label'])
    train_image_size = FLAGS.train_image_size or network_fn.default_image_size

    image = image_preprocessing_fn(image, train_image_size, train_image_size)

    images, labels = tf.train.batch(
        [image, label],
        batch_size=FLAGS.batch_size,
        num_threads=4,
        capacity=5 * FLAGS.batch_size)
    # Number of classes in the Dataset label set plus 1.
    # Label 0 is reserved for an (unused) background class.
    num_classes = 1001

    logits, end_points = network_fn(images)
    batch_size=FLAGS.batch_size
    # Add classification loss.
    sparse_labels = tf.reshape(labels, [batch_size, 1])
    indices = tf.reshape(tf.range(batch_size), [batch_size, 1])
    #concated = tf.concat(1, [indices, sparse_labels])
    sparse_labels = tf.cast(sparse_labels, tf.int32)
    concated = tf.concat([indices, sparse_labels], 1)
    dense_labels = tf.sparse_to_dense(concated,
                                  [batch_size, 1001],
                                  1.0, 0.0) 
    slim.losses.cross_entropy_loss(
        logits, dense_labels, label_smoothing=0.01, weight=1.0)
    # Gather all of the losses including regularization losses.
    losses = tf.get_collection(slim.losses.LOSSES_COLLECTION)
    losses += tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)

    total_loss = tf.add_n(losses, name='total_loss')

    if is_chief:
      # Compute the moving average of all individual losses and the
      # total loss.
      loss_averages = tf.train.ExponentialMovingAverage(0.9, name='avg')
      loss_averages_op = loss_averages.apply(losses + [total_loss])

      # Attach a scalar summmary to all individual losses and the total loss;
      # do the same for the averaged version of the losses.
      for l in losses + [total_loss]:
        loss_name = l.op.name
        # Name each loss as '(raw)' and name the moving average version of the
        # loss as the original loss name.
        tf.summary.scalar(loss_name + '_raw', l)
        tf.summary.scalar(loss_name, loss_averages.average(l))

      # Add dependency to compute loss_averages.
      with tf.control_dependencies([loss_averages_op]):
        total_loss = tf.identity(total_loss)

    # Track the moving averages of all trainable variables.
    # Note that we maintain a 'double-average' of the BatchNormalization
    # global statistics.
    # This is not needed when the number of replicas are small but important
    # for synchronous distributed training with tens of workers/replicas.
    exp_moving_averager = tf.train.ExponentialMovingAverage(
        inception.MOVING_AVERAGE_DECAY, global_step)

    variables_to_average = (
        tf.trainable_variables() + tf.moving_average_variables())

    # Add histograms for model variables.
    for var in variables_to_average:
      tf.summary.histogram(var.op.name, var)

    # Create synchronous replica optimizer.
    opt = tf.train.SyncReplicasOptimizer(
        opt,
        replicas_to_aggregate=num_replicas_to_aggregate,
        total_num_replicas=num_workers,
        variable_averages=exp_moving_averager,
        variables_to_average=variables_to_average)

    # Compute gradients with respect to the loss.
    grads = opt.compute_gradients(total_loss)

    # Add histograms for gradients.
    for grad, var in grads:
      if grad is not None:
        tf.summary.histogram(var.op.name + '/gradients', grad)

    apply_gradients_op = opt.apply_gradients(grads, global_step=global_step)

    with tf.control_dependencies([apply_gradients_op]):
      train_op = tf.identity(total_loss, name='train_op')

    # Get chief queue_runners, init_tokens and clean_up_op, which is used to
    # synchronize replicas.
    # More details can be found in sync_replicas_optimizer.
    chief_queue_runners = [opt.get_chief_queue_runner()]
    init_tokens_op = opt.get_init_tokens_op()

    # Build the summary operation based on the TF collection of Summaries.
    summary_op = tf.summary.merge_all()

    # Build an initialization operation to run below.
    #init_op = tf.global_variables_initializer()

    # We run the summaries in the same thread as the training operations by
    # passing in None for summary_op to avoid a summary_thread being started.
    # Running summaries and training operations in parallel could run out of
    # GPU memory.

    sv = tf.train.Supervisor(is_chief=is_chief,
                             logdir=FLAGS.train_dir,
                             init_op=init_op,
                             summary_op=None,
                             global_step=global_step,
                             #saver=saver,
                             saver=None,
                             save_model_secs=FLAGS.save_interval_secs)

    tf.logging.info('%s Supervisor' % datetime.now())

    sess_config = tf.ConfigProto(
        allow_soft_placement=True,
        log_device_placement=FLAGS.log_device_placement)
    # Get a session.
    sess = sv.prepare_or_wait_for_session(target, config=sess_config)
    # Start the queue runners.
    queue_runners = tf.get_collection(tf.GraphKeys.QUEUE_RUNNERS)
    sv.start_queue_runners(sess, queue_runners)
    tf.logging.info('Started %d queues for processing input data.',
                  len(queue_runners))
    if is_chief:
      sv.start_queue_runners(sess, chief_queue_runners)
      sess.run(init_tokens_op)

    # Train, checking for Nans. Concurrently run the summary operation at a
    # specified interval. Note that the summary_op and train_op never run
    # simultaneously in order to prevent running out of GPU memory.
    #sess = sv.managed_session(target)
    next_summary_time = time.time() + FLAGS.save_summaries_secs
    while not sv.should_stop():
      try:
        start_time = time.time()
        loss_value, step = sess.run([train_op, global_step])
        assert not np.isnan(loss_value), 'Model diverged with loss = NaN'
        if step > FLAGS.max_steps: 
          break
        duration = time.time() - start_time
        if step % 10 == 0:
          examples_per_sec = FLAGS.batch_size / float(duration)
          format_str = ('Worker %d: %s: step %d, loss = %.2f'
                        '(%.1f examples/sec; %.3f  sec/batch)')
          tf.logging.info(format_str %
                          (FLAGS.task_id, datetime.now(), step, loss_value,
                           examples_per_sec, duration))

        # Determine if the summary_op should be run on the chief worker.
        if is_chief and next_summary_time < time.time():
          tf.logging.info('Running Summary operation on the chief.')
          summary_str = sess.run(summary_op)
          sv.summary_computed(sess, summary_str)
          tf.logging.info('Finished running Summary operation.')

          # Determine the next time for running the summary.
          next_summary_time += FLAGS.save_summaries_secs 
      except:
        if is_chief:
          tf.logging.info('About to execute sync_clean_up_op!')
          #sess.run(clean_up_op)
        raise

    # Stop the supervisor.  This also waits for service threads to finish.
    sv.stop()
```",LiZhelong,b'stat:awaiting response',2017-04-21T04:09:43Z,2018-02-24T18:37:43Z,,,,,,,
1358,Pretrained Inception V1 model not predicting proper labels,"Please go to Stack Overflow for help and support: http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **What is the top-level directory of the model you are using**:
models/slim/nets/
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Linux Ubuntu 14.04
- **TensorFlow installed from (source or binary)**:
binary
- **TensorFlow version (use command below)**:
1.1.0-rc1
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
CUDA 8/cuDNN 5.1
- **GPU model and memory**:
Titan X Pascal
- **Exact command to reproduce**:

```
import tensorflow as tf
from tensorflow.contrib.slim.nets import inception
import numpy as np
slim = tf.contrib.slim

num_classes = 1001
tf_image = tf.placeholder(tf.float32, [None, 224,224,3])
tf_labels = tf.placeholder(tf.int32, [None, num_classes])
with slim.arg_scope(inception.inception_v1_arg_scope()):
    logits, end_points = inception.inception_v1(tf_image,
                                                num_classes=num_classes,
                                                is_training=False)
predictions = end_points['Predictions']


variables_to_restore = slim.get_variables_to_restore()
# path to my downloaded models
init_assign_fn = slim.assign_from_checkpoint_fn('/nas/weights/inception_v1.ckpt',
                                                variables_to_restore)

session=tf.Session()
init_assign_fn(session)
# http://www.4x4expedition.se/Image/expedition/baboon.jpg
import cv2
image = cv2.imread('../baboon.jpg')
image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

with session.as_default():
    pred = session.run(end_points['Predictions'], feed_dict={tf_image:[image]})
# prints 916
print np.argmax(pred)    

# https://s-media-cache-ak0.pinimg.com/736x/96/3d/56/963d562a02e0a4a49633b1e1026071fb.jpg
image = cv2.imread('../husky.jpg')
image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

with session.as_default():
    pred = session.run(end_points['Predictions'], feed_dict={tf_image:[image]})
# prints 916    
print np.argmax(pred)    
```
You can collect some of this information using our environment capture script: https://github.com/tensorflow/tensorflow/tree/master/tools

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem

Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

I instantiate the inception v1 model with the pretrained weights and pass a baboon image through and a husky image through (both 224x224).  The argmax of the predictions for both images is 916.  It is also unclear with the inception models what label->human label mapping should be used.  Regardless it doesnt appear as though the pretrained weights are successfully working with the net to create an accurate prediction.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",blake-varden,b'stat:community support',2017-04-17T18:10:03Z,2018-02-08T10:39:34Z,,,,,,,
1349,retrain with InceptionNet V3 but not converge with low learning rate,"My enviroment is ubuntu 16.04 x64 tensorflow 1.0.0 by pip
with  python2.7
only one GPU 1070 RAM 8G CPU.
Cuda compilation tools, release 8.0, V8.0.61
bazelBuild label: 0.4.5
cuDNN v5.1 
i7 RAM8G
the top folder is /home/lunasdejavu/Downloads/Inception/
I read the tutorial already, then I tried to train a dataset which is consist of 10382 images for training , 1154 images for validation and only 2 class.
I am very new to python so after I turned the dataset to 1 shards `TFRecords` because the tutorial said 1024 for 1 shard.
the I changed  `enum_classes()` and `num_examples_per_epoch()` in `flowers_data.py`
,`FLOWERS_DATA_DIR=/tmp/my-custom-data/`
the question is that the loss  never converges even after 100000
i tried 0.1 0.05 would be  too big that the loss could be bigger than the  loss of the first step
then after that 0.01 0.001 is always look like this
[http://imgur.com/a/kD4Fi](url)
the learnig rate seemed to drop too fast ,and the loss looked the same after many steps
and I read  a few papers said that the change of the loss between N step and N+1 step should be less than 0.01. 
the learning rate is 0.0005 now
so should I make it lower like 0.0001 now?

------------------------

### System information
- **What is the top-level directory of the model you are using**:
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script: https://github.com/tensorflow/tensorflow/tree/master/tools

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem

Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
",lunasdejavu,b'type:support',2017-04-15T00:44:37Z,2017-04-15T07:00:00Z,,,,,,,
1320,[spatial_transformer bug] what happens if the coordinates fall out of the sampling region,"# models/transformer/spatial_transformer.py
Seems that it simply takes the boundary value for sampling rather than dropping it.
However, in the torch implementation, there is such sanity check (L76-L80).
Reference: https://github.com/qassemoquab/stnbhwd/blob/master/generic/BilinearSamplerBHWD.c
",xcyan,b'stat:community support type:support',2017-04-09T08:54:21Z,2020-06-21T01:07:37Z,,,,,,,
1280,Unable to load bi skip thought model under Encoding Sentences ,"## Please let us know which model this issue is about (specify the top-level directory)
This is regarding the skip thoughts model. The uni model loads fine, the following error is thrown when loading the bi model:

```
VOCAB_FILE_BI = ""/home/icarus/skip_thoughts/pretrained/skip_thoughts_bi_2017_02_16/vocab.txt""
EMBEDDING_MATRIX_FILE_BI = ""/home/icarus/skip_thoughts/pretrained/skip_thoughts_bi_2017_02_16/embeddings.npy""
CHECKPOINT_PATH_BI = ""/home/icarus/skip_thoughts/pretrained/skip_thoughts_bi_2017_02_16/model.ckpt-500008""

```


```
---------------------------------------------------------------------------
NotFoundError                             Traceback (most recent call last)
<ipython-input-4-debbde01a7e3> in <module>()
      3                    vocabulary_file=VOCAB_FILE_BI,
      4                    embedding_matrix_file=EMBEDDING_MATRIX_FILE_BI,
----> 5                    checkpoint_path=CHECKPOINT_PATH_BI)

/home/icarus/skip_thoughts/skip_thoughts/encoder_manager.pyc in load_model(self, model_config, vocabulary_file, embedding_matrix_file, checkpoint_path)
     85 
     86     sess = tf.Session(graph=g)
---> 87     restore_model(sess)
     88 
     89     self.encoders.append(encoder)

/home/icarus/skip_thoughts/skip_thoughts/skip_thoughts_encoder.pyc in _restore_fn(sess)
    128     def _restore_fn(sess):
    129       tf.logging.info(""Loading model from checkpoint: %s"", checkpoint_path)
--> 130       saver.restore(sess, checkpoint_path)
    131       tf.logging.info(""Successfully loaded checkpoint: %s"",
    132                       os.path.basename(checkpoint_path))

/home/icarus/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/saver.pyc in restore(self, sess, save_path)
   1426       return
   1427     sess.run(self.saver_def.restore_op_name,
-> 1428              {self.saver_def.filename_tensor_name: save_path})
   1429 
   1430   @staticmethod

/home/icarus/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc in run(self, fetches, feed_dict, options, run_metadata)
    765     try:
    766       result = self._run(None, fetches, feed_dict, options_ptr,
--> 767                          run_metadata_ptr)
    768       if run_metadata:
    769         proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)

/home/icarus/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc in _run(self, handle, fetches, feed_dict, options, run_metadata)
    963     if final_fetches or final_targets:
    964       results = self._do_run(handle, final_targets, final_fetches,
--> 965                              feed_dict_string, options, run_metadata)
    966     else:
    967       results = []

/home/icarus/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc in _do_run(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)
   1013     if handle is None:
   1014       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,
-> 1015                            target_list, options, run_metadata)
   1016     else:
   1017       return self._do_call(_prun_fn, self._session, handle, feed_dict,

/home/icarus/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc in _do_call(self, fn, *args)
   1033         except KeyError:
   1034           pass
-> 1035       raise type(e)(node_def, op, message)
   1036 
   1037   def _extend_graph(self):

NotFoundError: Key encoder/gru_cell/candidate/layer_norm/w/beta not found in checkpoint
	 [[Node: save/RestoreV2_2 = RestoreV2[dtypes=[DT_FLOAT], _device=""/job:localhost/replica:0/task:0/cpu:0""](_recv_save/Const_0, save/RestoreV2_2/tensor_names, save/RestoreV2_2/shape_and_slices)]]

Caused by op u'save/RestoreV2_2', defined at:
  File ""/home/icarus/anaconda2/lib/python2.7/runpy.py"", line 174, in _run_module_as_main
    ""__main__"", fname, loader, pkg_name)
  File ""/home/icarus/anaconda2/lib/python2.7/runpy.py"", line 72, in _run_code
    exec code in run_globals
  File ""/home/icarus/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py"", line 3, in <module>
    app.launch_new_instance()
  File ""/home/icarus/anaconda2/lib/python2.7/site-packages/traitlets/config/application.py"", line 653, in launch_instance
    app.start()
  File ""/home/icarus/anaconda2/lib/python2.7/site-packages/ipykernel/kernelapp.py"", line 474, in start
    ioloop.IOLoop.instance().start()
  File ""/home/icarus/anaconda2/lib/python2.7/site-packages/zmq/eventloop/ioloop.py"", line 162, in start
    super(ZMQIOLoop, self).start()
  File ""/home/icarus/anaconda2/lib/python2.7/site-packages/tornado/ioloop.py"", line 887, in start
    handler_func(fd_obj, events)
  File ""/home/icarus/anaconda2/lib/python2.7/site-packages/tornado/stack_context.py"", line 275, in null_wrapper
    return fn(*args, **kwargs)
  File ""/home/icarus/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py"", line 440, in _handle_events
    self._handle_recv()
  File ""/home/icarus/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py"", line 472, in _handle_recv
    self._run_callback(callback, msg)
  File ""/home/icarus/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py"", line 414, in _run_callback
    callback(*args, **kwargs)
  File ""/home/icarus/anaconda2/lib/python2.7/site-packages/tornado/stack_context.py"", line 275, in null_wrapper
    return fn(*args, **kwargs)
  File ""/home/icarus/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py"", line 276, in dispatcher
    return self.dispatch_shell(stream, msg)
  File ""/home/icarus/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py"", line 228, in dispatch_shell
    handler(stream, idents, msg)
  File ""/home/icarus/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py"", line 390, in execute_request
    user_expressions, allow_stdin)
  File ""/home/icarus/anaconda2/lib/python2.7/site-packages/ipykernel/ipkernel.py"", line 196, in do_execute
    res = shell.run_cell(code, store_history=store_history, silent=silent)
  File ""/home/icarus/anaconda2/lib/python2.7/site-packages/ipykernel/zmqshell.py"", line 501, in run_cell
    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)
  File ""/home/icarus/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py"", line 2717, in run_cell
    interactivity=interactivity, compiler=compiler, result=result)
  File ""/home/icarus/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py"", line 2827, in run_ast_nodes
    if self.run_code(code, result):
  File ""/home/icarus/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py"", line 2881, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File ""<ipython-input-4-debbde01a7e3>"", line 5, in <module>
    checkpoint_path=CHECKPOINT_PATH_BI)
  File ""/home/icarus/skip_thoughts/skip_thoughts/encoder_manager.py"", line 84, in load_model
    checkpoint_path)
  File ""/home/icarus/skip_thoughts/skip_thoughts/skip_thoughts_encoder.py"", line 151, in build_graph_from_config
    saver = tf.train.Saver()
  File ""/home/icarus/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/saver.py"", line 1040, in __init__
    self.build()
  File ""/home/icarus/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/saver.py"", line 1070, in build
    restore_sequentially=self._restore_sequentially)
  File ""/home/icarus/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/saver.py"", line 675, in build
    restore_sequentially, reshape)
  File ""/home/icarus/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/saver.py"", line 402, in _AddRestoreOps
    tensors = self.restore_op(filename_tensor, saveable, preferred_shard)
  File ""/home/icarus/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/saver.py"", line 242, in restore_op
    [spec.tensor.dtype])[0])
  File ""/home/icarus/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/gen_io_ops.py"", line 668, in restore_v2
    dtypes=dtypes, name=name)
  File ""/home/icarus/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py"", line 763, in apply_op
    op_def=op_def)
  File ""/home/icarus/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 2327, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""/home/icarus/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 1226, in __init__
    self._traceback = _extract_stack()

NotFoundError (see above for traceback): Key encoder/gru_cell/candidate/layer_norm/w/beta not found in checkpoint
	 [[Node: save/RestoreV2_2 = RestoreV2[dtypes=[DT_FLOAT], _device=""/job:localhost/replica:0/task:0/cpu:0""](_recv_save/Const_0, save/RestoreV2_2/tensor_names, save/RestoreV2_2/shape_and_slices)]]

```",ankitarya10,b'stat:awaiting model gardener stat:awaiting response type:bug',2017-03-30T22:54:06Z,2017-04-03T17:04:39Z,,,,,,,
1275,tf.concat BUG,"tf.concat() to be compatible with new TF

while use  inception_resnet_v2.py ,raise Error, use tf.__version__ =='0.12.0:

  File ""/ssd/lidenghui/jt/models_crop/slim/nets/inception_resnet_v2.py"", line 169, in inception_resnet_v2
  net = tf.concat(axis=3, values=[tower_conv, tower_conv1_1,
            tower_conv2_2, tower_pool_1])
TypeError: concat() got an unexpected keyword argument 'axis'
 
that because tf.concat api has been updated ,according https://www.tensorflow.org/api_docs/python/tf/concat

so  all tf.concat in inception_resnet_v2.py should been changed to：
  net = tf.concat( concat_dim=3,values=[tower_conv, tower_conv1_1,
            tower_conv2_2, tower_pool_1])
",Google1234,None,2017-03-30T09:07:52Z,2017-03-30T20:15:26Z,,,,,,,
1264,Cifar10 underutilizing GPUs?,"I am running on four GPUs on a cloud server.

I am fairly certain I am underutiliing GPUs since I am running `watch nvidia-smi` and seeing lots of zeroes with periodic breif upticks to about 20-30% in one or two gpus. I sent `--num-gpus=4` as an argument.

Here is some detail:

`W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE3 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:910] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
I tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with properties:
name: Tesla K80
major: 3 minor: 7 memoryClockRate (GHz) 0.8235
pciBusID 0000:00:04.0
Total memory: 11.17GiB
Free memory: 11.11GiB
W tensorflow/stream_executor/cuda/cuda_driver.cc:590] creating context when one is currently active; existing: 0x2c26cc0
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:910] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
I tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 1 with properties:
name: Tesla K80
major: 3 minor: 7 memoryClockRate (GHz) 0.8235
pciBusID 0000:00:05.0
Total memory: 11.17GiB
Free memory: 11.11GiB
W tensorflow/stream_executor/cuda/cuda_driver.cc:590] creating context when one is currently active; existing: 0x2c2ab00
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:910] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
I tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 2 with properties:
name: Tesla K80
major: 3 minor: 7 memoryClockRate (GHz) 0.8235
pciBusID 0000:00:06.0
Total memory: 11.17GiB
Free memory: 11.11GiB
W tensorflow/stream_executor/cuda/cuda_driver.cc:590] creating context when one is currently active; existing: 0x2c4e9c0
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:910] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
I tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 3 with properties:
name: Tesla K80
major: 3 minor: 7 memoryClockRate (GHz) 0.8235
pciBusID 0000:00:07.0
Total memory: 11.17GiB
Free memory: 11.11GiB
I tensorflow/core/common_runtime/gpu/gpu_device.cc:777] Peer access not supported between device ordinals 0 and 1
I tensorflow/core/common_runtime/gpu/gpu_device.cc:777] Peer access not supported between device ordinals 0 and 2
I tensorflow/core/common_runtime/gpu/gpu_device.cc:777] Peer access not supported between device ordinals 0 and 3
I tensorflow/core/common_runtime/gpu/gpu_device.cc:777] Peer access not supported between device ordinals 1 and 0
I tensorflow/core/common_runtime/gpu/gpu_device.cc:777] Peer access not supported between device ordinals 1 and 2
I tensorflow/core/common_runtime/gpu/gpu_device.cc:777] Peer access not supported between device ordinals 1 and 3
I tensorflow/core/common_runtime/gpu/gpu_device.cc:777] Peer access not supported between device ordinals 2 and 0
I tensorflow/core/common_runtime/gpu/gpu_device.cc:777] Peer access not supported between device ordinals 2 and 1
I tensorflow/core/common_runtime/gpu/gpu_device.cc:777] Peer access not supported between device ordinals 2 and 3
I tensorflow/core/common_runtime/gpu/gpu_device.cc:777] Peer access not supported between device ordinals 3 and 0
I tensorflow/core/common_runtime/gpu/gpu_device.cc:777] Peer access not supported between device ordinals 3 and 1
I tensorflow/core/common_runtime/gpu/gpu_device.cc:777] Peer access not supported between device ordinals 3 and 2
I tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0 1 2 3
I tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0:   Y N N N
I tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 1:   N Y N N
I tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 2:   N N Y N
I tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 3:   N N N Y
I tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0)
I tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:1) -> (device: 1, name: Tesla K80, pci bus id: 0000:00:05.0)
I tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:2) -> (device: 2, name: Tesla K80, pci bus id: 0000:00:06.0)
I tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:3) -> (device: 3, name: Tesla K80, pci bus id: 0000:00:07.0)`


and then my steps are slower than the file claims should be... since I am running 4 K80s I would expect much faster. I have been running about 2 hours now...


`2017-03-27 19:26:46.990922: step 0, loss = 4.67 (1.3 examples/sec; 100.494 sec/batch)
2017-03-27 19:27:15.323066: step 10, loss = 4.63 (212.7 examples/sec; 0.602 sec/batch)
2017-03-27 19:27:42.953002: step 20, loss = 4.61 (194.4 examples/sec; 0.659 sec/batch)
2017-03-27 19:28:08.125142: step 30, loss = 4.39 (202.5 examples/sec; 0.632 sec/batch)
2017-03-27 19:28:34.616396: step 40, loss = 4.32 (197.4 examples/sec; 0.649 sec/batch)
2017-03-27 19:29:00.785607: step 50, loss = 4.33 (221.3 examples/sec; 0.578 sec/batch)
2017-03-27 19:29:28.233038: step 60, loss = 4.31 (205.7 examples/sec; 0.622 sec/batch)
2017-03-27 19:29:54.034672: step 70, loss = 4.07 (232.7 examples/sec; 0.550 sec/batch)
2017-03-27 19:30:20.986209: step 80, loss = 4.13 (216.5 examples/sec; 0.591 sec/batch)
2017-03-27 19:30:46.936150: step 90, loss = 4.02 (182.9 examples/sec; 0.700 sec/batch)
2017-03-27 19:31:10.537182: step 100, loss = 4.03 (208.4 examples/sec; 0.614 sec/batch)
2017-03-27 19:31:40.003347: step 110, loss = 3.93 (187.7 examples/sec; 0.682 sec/batch)
2017-03-27 19:32:06.837135: step 120, loss = 3.86 (225.1 examples/sec; 0.569 sec/batch)
2017-03-27 19:32:33.440906: step 130, loss = 4.01 (165.4 examples/sec; 0.774 sec/batch)
2017-03-27 19:32:59.915578: step 140, loss = 3.98 (176.0 examples/sec; 0.727 sec/batch)
2017-03-27 19:33:25.993545: step 150, loss = 3.96 (195.5 examples/sec; 0.655 sec/batch)
2017-03-27 19:33:53.430149: step 160, loss = 3.78 (170.8 examples/sec; 0.749 sec/batch)
2017-03-27 19:34:18.521821: step 170, loss = 3.75 (212.1 examples/sec; 0.604 sec/batch)
2017-03-27 19:34:43.483902: step 180, loss = 3.88 (220.9 examples/sec; 0.580 sec/batch)
2017-03-27 19:35:10.340536: step 190, loss = 3.65 (182.9 examples/sec; 0.700 sec/batch)
2017-03-27 19:35:37.155107: step 200, loss = 3.90 (181.9 examples/sec; 0.704 sec/batch)
2017-03-27 19:36:07.403705: step 210, loss = 3.80 (192.3 examples/sec; 0.666 sec/batch)
2017-03-27 19:36:33.683254: step 220, loss = 3.91 (201.4 examples/sec; 0.635 sec/batch)
2017-03-27 19:36:59.653552: step 230, loss = 3.57 (176.6 examples/sec; 0.725 sec/batch)
2017-03-27 19:37:26.459334: step 240, loss = 3.66 (195.9 examples/sec; 0.653 sec/batch)
2017-03-27 19:37:54.057299: step 250, loss = 3.50 (212.2 examples/sec; 0.603 sec/batch)
2017-03-27 19:38:20.363680: step 260, loss = 3.54 (169.5 examples/sec; 0.755 sec/batch)
2017-03-27 19:38:46.152019: step 270, loss = 3.65 (211.0 examples/sec; 0.607 sec/batch)
2017-03-27 19:39:13.269074: step 280, loss = 3.77 (164.5 examples/sec; 0.778 sec/batch)
2017-03-27 19:39:38.569408: step 290, loss = 3.52 (197.6 examples/sec; 0.648 sec/batch)
2017-03-27 19:40:06.769787: step 300, loss = 3.52 (234.1 examples/sec; 0.547 sec/batch)
2017-03-27 19:40:37.029889: step 310, loss = 3.47 (192.5 examples/sec; 0.665 sec/batch)
2017-03-27 19:41:03.169604: step 320, loss = 3.52 (204.1 examples/sec; 0.627 sec/batch)
2017-03-27 19:41:31.389978: step 330, loss = 3.44 (180.9 examples/sec; 0.708 sec/batch)
2017-03-27 19:41:57.252489: step 340, loss = 3.68 (215.6 examples/sec; 0.594 sec/batch)
2017-03-27 19:42:23.678016: step 350, loss = 3.31 (196.3 examples/sec; 0.652 sec/batch)
2017-03-27 19:42:51.908805: step 360, loss = 3.24 (218.5 examples/sec; 0.586 sec/batch)
2017-03-27 19:43:19.394081: step 370, loss = 3.25 (170.1 examples/sec; 0.752 sec/batch)
2017-03-27 19:43:44.038110: step 380, loss = 3.20 (208.9 examples/sec; 0.613 sec/batch)
2017-03-27 19:44:11.626015: step 390, loss = 3.25 (163.5 examples/sec; 0.783 sec/batch)
2017-03-27 19:44:38.404796: step 400, loss = 3.29 (203.4 examples/sec; 0.629 sec/batch)
2017-03-27 19:45:07.275305: step 410, loss = 3.36 (169.9 examples/sec; 0.753 sec/batch)
2017-03-27 19:45:34.380476: step 420, loss = 3.28 (194.0 examples/sec; 0.660 sec/batch)
2017-03-27 19:46:00.917443: step 430, loss = 3.09 (189.5 examples/sec; 0.676 sec/batch)
2017-03-27 19:46:28.402162: step 440, loss = 3.16 (170.2 examples/sec; 0.752 sec/batch)
2017-03-27 19:46:54.475613: step 450, loss = 3.23 (214.7 examples/sec; 0.596 sec/batch)
2017-03-27 19:47:20.203394: step 460, loss = 3.14 (197.6 examples/sec; 0.648 sec/batch)
2017-03-27 19:47:46.100768: step 470, loss = 3.15 (205.0 examples/sec; 0.624 sec/batch)
2017-03-27 19:48:12.108813: step 480, loss = 3.16 (182.7 examples/sec; 0.700 sec/batch)
2017-03-27 19:48:38.917580: step 490, loss = 3.03 (189.9 examples/sec; 0.674 sec/batch)
2017-03-27 19:49:06.275778: step 500, loss = 3.33 (217.0 examples/sec; 0.590 sec/batch)
2017-03-27 19:49:37.939371: step 510, loss = 3.00 (168.8 examples/sec; 0.758 sec/batch)
2017-03-27 19:50:05.918202: step 520, loss = 3.17 (203.2 examples/sec; 0.630 sec/batch)
2017-03-27 19:50:33.384825: step 530, loss = 3.06 (188.6 examples/sec; 0.679 sec/batch)
2017-03-27 19:50:58.220123: step 540, loss = 3.04 (189.3 examples/sec; 0.676 sec/batch)
2017-03-27 19:51:24.429506: step 550, loss = 3.10 (214.1 examples/sec; 0.598 sec/batch)
2017-03-27 19:51:50.033498: step 560, loss = 3.17 (197.8 examples/sec; 0.647 sec/batch)
2017-03-27 19:52:15.544901: step 570, loss = 2.89 (213.4 examples/sec; 0.600 sec/batch)
2017-03-27 19:52:41.645112: step 580, loss = 2.88 (182.8 examples/sec; 0.700 sec/batch)
2017-03-27 19:53:08.246384: step 590, loss = 2.85 (184.3 examples/sec; 0.695 sec/batch)
2017-03-27 19:53:34.648499: step 600, loss = 3.23 (159.7 examples/sec; 0.802 sec/batch)
2017-03-27 19:54:05.155759: step 610, loss = 2.97 (154.4 examples/sec; 0.829 sec/batch)
2017-03-27 19:54:32.427825: step 620, loss = 2.93 (191.4 examples/sec; 0.669 sec/batch)
2017-03-27 19:54:58.939925: step 630, loss = 2.85 (171.5 examples/sec; 0.746 sec/batch)
2017-03-27 19:55:25.750831: step 640, loss = 2.75 (177.0 examples/sec; 0.723 sec/batch)
2017-03-27 19:55:54.483247: step 650, loss = 3.01 (174.2 examples/sec; 0.735 sec/batch)
2017-03-27 19:56:20.648869: step 660, loss = 2.79 (198.0 examples/sec; 0.646 sec/batch)
2017-03-27 19:56:48.254483: step 670, loss = 2.94 (177.0 examples/sec; 0.723 sec/batch)
2017-03-27 19:57:14.791461: step 680, loss = 2.86 (220.6 examples/sec; 0.580 sec/batch)
2017-03-27 19:57:41.755795: step 690, loss = 2.60 (176.1 examples/sec; 0.727 sec/batch)
2017-03-27 19:58:07.782214: step 700, loss = 2.84 (181.8 examples/sec; 0.704 sec/batch)
2017-03-27 19:58:37.283130: step 710, loss = 2.72 (174.5 examples/sec; 0.733 sec/batch)
2017-03-27 19:59:02.973874: step 720, loss = 2.72 (212.3 examples/sec; 0.603 sec/batch)
2017-03-27 19:59:30.256519: step 730, loss = 2.58 (186.9 examples/sec; 0.685 sec/batch)
2017-03-27 19:59:58.869470: step 740, loss = 2.66 (199.2 examples/sec; 0.642 sec/batch)
2017-03-27 20:00:24.191095: step 750, loss = 2.60 (254.0 examples/sec; 0.504 sec/batch)
2017-03-27 20:00:49.456903: step 760, loss = 2.66 (183.1 examples/sec; 0.699 sec/batch)
2017-03-27 20:01:15.948954: step 770, loss = 2.75 (169.9 examples/sec; 0.753 sec/batch)
2017-03-27 20:01:43.432525: step 780, loss = 2.68 (185.4 examples/sec; 0.690 sec/batch)
2017-03-27 20:02:09.862770: step 790, loss = 2.52 (160.3 examples/sec; 0.798 sec/batch)
2017-03-27 20:02:37.205679: step 800, loss = 2.55 (221.0 examples/sec; 0.579 sec/batch)
2017-03-27 20:03:06.496276: step 810, loss = 2.84 (242.3 examples/sec; 0.528 sec/batch)
2017-03-27 20:03:33.060909: step 820, loss = 2.41 (203.1 examples/sec; 0.630 sec/batch)
2017-03-27 20:03:59.760558: step 830, loss = 2.65 (177.4 examples/sec; 0.722 sec/batch)
2017-03-27 20:04:25.873692: step 840, loss = 2.57 (196.4 examples/sec; 0.652 sec/batch)
2017-03-27 20:04:51.278986: step 850, loss = 2.40 (254.7 examples/sec; 0.503 sec/batch)
2017-03-27 20:05:18.219390: step 860, loss = 2.45 (231.0 examples/sec; 0.554 sec/batch)
2017-03-27 20:05:43.783941: step 870, loss = 2.54 (231.2 examples/sec; 0.554 sec/batch)
2017-03-27 20:06:10.881609: step 880, loss = 2.49 (194.2 examples/sec; 0.659 sec/batch)
2017-03-27 20:06:37.334819: step 890, loss = 2.57 (179.2 examples/sec; 0.714 sec/batch)
2017-03-27 20:07:04.405804: step 900, loss = 2.66 (194.2 examples/sec; 0.659 sec/batch)
2017-03-27 20:07:33.789852: step 910, loss = 2.41 (169.8 examples/sec; 0.754 sec/batch)
2017-03-27 20:08:00.781905: step 920, loss = 2.39 (188.1 examples/sec; 0.681 sec/batch)
2017-03-27 20:08:27.574612: step 930, loss = 2.47 (204.2 examples/sec; 0.627 sec/batch)
2017-03-27 20:08:53.584209: step 940, loss = 2.33 (203.6 examples/sec; 0.629 sec/batch)
2017-03-27 20:09:20.882582: step 950, loss = 2.74 (170.6 examples/sec; 0.750 sec/batch)
2017-03-27 20:09:46.787176: step 960, loss = 2.35 (226.8 examples/sec; 0.564 sec/batch)
2017-03-27 20:10:13.693611: step 970, loss = 2.23 (221.3 examples/sec; 0.578 sec/batch)
2017-03-27 20:10:39.787442: step 980, loss = 2.30 (189.5 examples/sec; 0.675 sec/batch)
2017-03-27 20:11:05.435047: step 990, loss = 2.46 (222.1 examples/sec; 0.576 sec/batch)
2017-03-27 20:11:31.995699: step 1000, loss = 2.42 (189.5 examples/sec; 0.676 sec/batch)
2017-03-27 20:12:02.392635: step 1010, loss = 2.41 (176.0 examples/sec; 0.727 sec/batch)
2017-03-27 20:12:28.601123: step 1020, loss = 2.28 (189.5 examples/sec; 0.675 sec/batch)
2017-03-27 20:12:57.962129: step 1030, loss = 2.07 (166.6 examples/sec; 0.768 sec/batch)
2017-03-27 20:13:23.711667: step 1040, loss = 2.40 (150.0 examples/sec; 0.853 sec/batch)
2017-03-27 20:13:50.391482: step 1050, loss = 2.16 (163.3 examples/sec; 0.784 sec/batch)
2017-03-27 20:14:17.150539: step 1060, loss = 2.18 (176.4 examples/sec; 0.725 sec/batch)
2017-03-27 20:14:43.821420: step 1070, loss = 2.23 (231.7 examples/sec; 0.552 sec/batch)
2017-03-27 20:15:11.304181: step 1080, loss = 2.38 (194.1 examples/sec; 0.659 sec/batch)
2017-03-27 20:15:37.173430: step 1090, loss = 2.05 (203.5 examples/sec; 0.629 sec/batch)
2017-03-27 20:16:04.255046: step 1100, loss = 2.23 (194.7 examples/sec; 0.657 sec/batch)
2017-03-27 20:16:34.813689: step 1110, loss = 2.28 (165.6 examples/sec; 0.773 sec/batch)
2017-03-27 20:17:01.100678: step 1120, loss = 2.14 (178.2 examples/sec; 0.718 sec/batch)
2017-03-27 20:17:28.586044: step 1130, loss = 2.11 (195.2 examples/sec; 0.656 sec/batch)
2017-03-27 20:17:55.360578: step 1140, loss = 2.04 (150.1 examples/sec; 0.853 sec/batch)
2017-03-27 20:18:22.455943: step 1150, loss = 2.24 (186.1 examples/sec; 0.688 sec/batch)
2017-03-27 20:18:50.903029: step 1160, loss = 1.96 (185.7 examples/sec; 0.689 sec/batch)
2017-03-27 20:19:18.376409: step 1170, loss = 2.09 (170.0 examples/sec; 0.753 sec/batch)
2017-03-27 20:19:45.204791: step 1180, loss = 2.04 (213.4 examples/sec; 0.600 sec/batch)
2017-03-27 20:20:11.020790: step 1190, loss = 2.19 (189.2 examples/sec; 0.676 sec/batch)
2017-03-27 20:20:37.598919: step 1200, loss = 2.10 (198.9 examples/sec; 0.644 sec/batch)
2017-03-27 20:21:08.177342: step 1210, loss = 2.31 (182.7 examples/sec; 0.701 sec/batch)
2017-03-27 20:21:35.569058: step 1220, loss = 2.14 (153.8 examples/sec; 0.832 sec/batch)
2017-03-27 20:22:02.416500: step 1230, loss = 2.10 (186.6 examples/sec; 0.686 sec/batch)
2017-03-27 20:22:30.671925: step 1240, loss = 1.93 (176.6 examples/sec; 0.725 sec/batch)
2017-03-27 20:22:56.999680: step 1250, loss = 2.17 (183.7 examples/sec; 0.697 sec/batch)
2017-03-27 20:23:25.414515: step 1260, loss = 2.00 (189.4 examples/sec; 0.676 sec/batch)
2017-03-27 20:23:52.737623: step 1270, loss = 2.07 (181.8 examples/sec; 0.704 sec/batch)
2017-03-27 20:24:20.142201: step 1280, loss = 1.95 (174.4 examples/sec; 0.734 sec/batch)
2017-03-27 20:24:47.854200: step 1290, loss = 1.81 (184.2 examples/sec; 0.695 sec/batch)
2017-03-27 20:25:14.885685: step 1300, loss = 1.94 (175.9 examples/sec; 0.728 sec/batch)
2017-03-27 20:25:43.580519: step 1310, loss = 2.08 (244.6 examples/sec; 0.523 sec/batch)
2017-03-27 20:26:10.291048: step 1320, loss = 2.09 (154.9 examples/sec; 0.826 sec/batch)
2017-03-27 20:26:36.991663: step 1330, loss = 2.06 (180.9 examples/sec; 0.708 sec/batch)
2017-03-27 20:27:04.117405: step 1340, loss = 2.12 (188.9 examples/sec; 0.678 sec/batch)
2017-03-27 20:27:30.031492: step 1350, loss = 1.96 (213.5 examples/sec; 0.600 sec/batch)
2017-03-27 20:27:56.745065: step 1360, loss = 1.83 (199.8 examples/sec; 0.641 sec/batch)
2017-03-27 20:28:23.977106: step 1370, loss = 1.98 (220.1 examples/sec; 0.581 sec/batch)
2017-03-27 20:28:51.653204: step 1380, loss = 1.90 (189.6 examples/sec; 0.675 sec/batch)
2017-03-27 20:29:18.689594: step 1390, loss = 2.08 (190.3 examples/sec; 0.673 sec/batch)
2017-03-27 20:29:46.789295: step 1400, loss = 2.07 (141.3 examples/sec; 0.906 sec/batch)
2017-03-27 20:30:15.382193: step 1410, loss = 1.87 (203.6 examples/sec; 0.629 sec/batch)
2017-03-27 20:30:40.716611: step 1420, loss = 2.02 (214.1 examples/sec; 0.598 sec/batch)
2017-03-27 20:31:07.416061: step 1430, loss = 1.73 (185.0 examples/sec; 0.692 sec/batch)
2017-03-27 20:31:35.051818: step 1440, loss = 1.89 (191.9 examples/sec; 0.667 sec/batch)
2017-03-27 20:32:01.469996: step 1450, loss = 2.10 (231.1 examples/sec; 0.554 sec/batch)
2017-03-27 20:32:28.600844: step 1460, loss = 1.70 (197.7 examples/sec; 0.647 sec/batch)
2017-03-27 20:32:56.324405: step 1470, loss = 1.76 (203.2 examples/sec; 0.630 sec/batch)
2017-03-27 20:33:23.486288: step 1480, loss = 2.25 (202.5 examples/sec; 0.632 sec/batch)
2017-03-27 20:33:49.776652: step 1490, loss = 1.77 (211.4 examples/sec; 0.606 sec/batch)
2017-03-27 20:34:16.973078: step 1500, loss = 1.75 (162.7 examples/sec; 0.786 sec/batch)
2017-03-27 20:34:47.797704: step 1510, loss = 1.78 (176.4 examples/sec; 0.726 sec/batch)
2017-03-27 20:35:14.206160: step 1520, loss = 1.79 (202.8 examples/sec; 0.631 sec/batch)
2017-03-27 20:35:40.812538: step 1530, loss = 1.95 (185.6 examples/sec; 0.689 sec/batch)
2017-03-27 20:36:08.044138: step 1540, loss = 1.83 (189.3 examples/sec; 0.676 sec/batch)
2017-03-27 20:36:35.161508: step 1550, loss = 1.78 (208.4 examples/sec; 0.614 sec/batch)
2017-03-27 20:37:01.680550: step 1560, loss = 1.81 (189.5 examples/sec; 0.676 sec/batch)
2017-03-27 20:37:29.050672: step 1570, loss = 1.78 (189.7 examples/sec; 0.675 sec/batch)
2017-03-27 20:37:56.332387: step 1580, loss = 1.73 (174.9 examples/sec; 0.732 sec/batch)
2017-03-27 20:38:22.492058: step 1590, loss = 1.62 (207.6 examples/sec; 0.617 sec/batch)
2017-03-27 20:36:35.161508: step 1550, loss = 1.78 (208.4 examples/sec; 0.614 sec/batch)
2017-03-27 20:37:01.680550: step 1560, loss = 1.81 (189.5 examples/sec; 0.676 sec/batch)
2017-03-27 20:37:29.050672: step 1570, loss = 1.78 (189.7 examples/sec; 0.675 sec/batch)
2017-03-27 20:37:56.332387: step 1580, loss = 1.73 (174.9 examples/sec; 0.732 sec/batch)
2017-03-27 20:38:22.492058: step 1590, loss = 1.62 (207.6 examples/sec; 0.617 sec/batch)
` 

Is this abnormal? Is something stopping the GPUs from running correctly?

Mon Mar 27 20:38:08 2017
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 375.39                 Driver Version: 375.39                    |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  Tesla K80           Off  | 0000:00:04.0     Off |                    0 |
| N/A   56C    P0    58W / 149W |  10943MiB / 11439MiB |      1%      Default |
+-------------------------------+----------------------+----------------------+
|   1  Tesla K80           Off  | 0000:00:05.0     Off |                    0 |
| N/A   72C    P0    71W / 149W |  10943MiB / 11439MiB |      1%      Default |
+-------------------------------+----------------------+----------------------+
|   2  Tesla K80           Off  | 0000:00:06.0     Off |                    0 |
| N/A   73C    P0    72W / 149W |  10943MiB / 11439MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   3  Tesla K80           Off  | 0000:00:07.0     Off |                    0 |
| N/A   56C    P0    63W / 149W |  10941MiB / 11439MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+

+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID  Type  Process name                               Usage      |",MikeTam1021,b'stat:awaiting model gardener type:bug',2017-03-27T20:39:00Z,2019-12-13T17:39:14Z,,,,,,,
1262,Loading Skip Thoughts Model in Python 3,"Model: skip_thoughts
Issue type: Update for Python 3.5+ support
Excellent job with the implementation of Skip-Thoughts in TF.
Just want to bring to your attention about loading the embedding matrix .npy file in Python 3.5.3.
These lines in encoder_manager.py:
```
with open(embedding_matrix_file, ""r"") as f:
      embedding_matrix = np.load(f)
```
need to be changed to the following:
`embedding_matrix = np.load(embedding_matrix_file)`
as Python 3 seems to have issues loading the file object but seems fine loading directly.
The original code raises an error as: _startswith first arg must be str or a tuple of str, not bytes_
when npyio.py file reads the file object at line 393: `magic.startswith(_ZIP_PREFIX)`

Thanks",karthikmswamy,b'stat:awaiting maintainer type:bug',2017-03-27T06:44:27Z,2018-02-28T03:33:24Z,,,,,,,
1261,Tensorflow Bazel Build Failure - GCC failing ," /tensorflow/tensorflow/core/kernels/BUILD:2122:1
C++ compilation of rule '//tensorflow/core/kernels:argmax_op' failed: gcc failed: error executing command /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -B/usr/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG ... (remaining 130 argument(s) skipped): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 4.
gcc: internal compiler error: Killed (program cc1plus)
",alfydavy,b'stat:awaiting response type:build/install',2017-03-27T05:37:59Z,2019-02-15T22:47:03Z,,,,,,,
1257,[im2txt] Unable to preprocess mscoco dataset for show and tell,"I'm trying to preprocess mscoco dataset for use in im2txt model. 
I'm using tensorflow 1.0 for GPU on a GTX 1070 with 16 GB RAM.
Python version: 3.5.3
```
(tensorflow) timberners@galileo:/media/timberners/magicae/models/im2txt$ bazel-bin/im2txt/download_and_preprocess_mscoco ""${MSCOCO_DIR}""
/media/timberners/magicae/models/im2txt
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcudnn.so.5 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.so.8.0 locally
Loaded caption metadata for 82783 images from /media/timberners/magicae/models/im2txt/data/mscoco/raw-data/annotations/captions_train2014.json
Processing captions.
Finished processing 414113 captions for 82783 images in /media/timberners/magicae/models/im2txt/data/mscoco/raw-data/annotations/captions_train2014.json
Loaded caption metadata for 40504 images from /media/timberners/magicae/models/im2txt/data/mscoco/raw-data/annotations/captions_val2014.json
Processing captions.
Finished processing 202654 captions for 40504 images in /media/timberners/magicae/models/im2txt/data/mscoco/raw-data/annotations/captions_val2014.json
Creating vocabulary.
Total words: 29415
Words in vocabulary: 11519
Wrote vocabulary file: /media/timberners/magicae/models/im2txt/data/mscoco/word_counts.txt
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE3 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:910] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
I tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with properties: 
name: GeForce GTX 1070
major: 6 minor: 1 memoryClockRate (GHz) 1.7465
pciBusID 0000:01:00.0
Total memory: 7.92GiB
Free memory: 7.47GiB
I tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0:   Y 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0)
Launching 8 threads for spacings: [[0, 73296], [73296, 146592], [146592, 219888], [219888, 293184], [293184, 366480], [366480, 439776], [439776, 513072], [513072, 586368]]
Exception in thread Thread-3:
Traceback (most recent call last):
  File ""/home/timberners/anaconda3/envs/tensorflow/lib/python3.5/threading.py"", line 914, in _bootstrap_inner
    self.run()
  File ""/home/timberners/anaconda3/envs/tensorflow/lib/python3.5/threading.py"", line 862, in run
    self._target(*self._args, **self._kwargs)
  File ""/media/timberners/magicae/models/im2txt/bazel-bin/im2txt/download_and_preprocess_mscoco.runfiles/im2txt/im2txt/data/build_mscoco_data.py"", line 281, in _process_image_files
    sequence_example = _to_sequence_example(image, decoder, vocab)
  File ""/media/timberners/magicae/models/im2txt/bazel-bin/im2txt/download_and_preprocess_mscoco.runfiles/im2txt/im2txt/data/build_mscoco_data.py"", line 227, in _to_sequence_example
    ""image/data"": _bytes_feature(encoded_image),
  File ""/media/timberners/magicae/models/im2txt/bazel-bin/im2txt/download_and_preprocess_mscoco.runfiles/im2txt/im2txt/data/build_mscoco_data.py"", line 192, in _bytes_feature
    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[str(value)]))
TypeError: 'b\'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x01\\x00\\xb4\\x00\\xb4\\x00\\x00\\xff\\xe2\\ has type str, but expected one of: bytes

Exception in thread Thread-1:
Traceback (most recent call last):
  File ""/home/timberners/anaconda3/envs/tensorflow/lib/python3.5/threading.py"", line 914, in _bootstrap_inner
    self.run()
  File ""/home/timberners/anaconda3/envs/tensorflow/lib/python3.5/threading.py"", line 862, in run
    self._target(*self._args, **self._kwargs)
  File ""/media/timberners/magicae/models/im2txt/bazel-bin/im2txt/download_and_preprocess_mscoco.runfiles/im2txt/im2txt/data/build_mscoco_data.py"", line 281, in _process_image_files
    sequence_example = _to_sequence_example(image, decoder, vocab)
  File ""/media/timberners/magicae/models/im2txt/bazel-bin/im2txt/download_and_preprocess_mscoco.runfiles/im2txt/im2txt/data/build_mscoco_data.py"", line 227, in _to_sequence_example
    ""image/data"": _bytes_feature(encoded_image),
  File ""/media/timberners/magicae/models/im2txt/bazel-bin/im2txt/download_and_preprocess_mscoco.runfiles/im2txt/im2txt/data/build_mscoco_data.py"", line 192, in _bytes_feature
    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[str(value)]))
TypeError: 'b\'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x01\\x00H\\x00H\\x00\\x00\\xff\\xe2\\x0cXICC_ has type str, but expected one of: bytes

Exception in thread Thread-2:
Traceback (most recent call last):
  File ""/home/timberners/anaconda3/envs/tensorflow/lib/python3.5/threading.py"", line 914, in _bootstrap_inner
    self.run()
  File ""/home/timberners/anaconda3/envs/tensorflow/lib/python3.5/threading.py"", line 862, in run
    self._target(*self._args, **self._kwargs)
  File ""/media/timberners/magicae/models/im2txt/bazel-bin/im2txt/download_and_preprocess_mscoco.runfiles/im2txt/im2txt/data/build_mscoco_data.py"", line 281, in _process_image_files
    sequence_example = _to_sequence_example(image, decoder, vocab)
  File ""/media/timberners/magicae/models/im2txt/bazel-bin/im2txt/download_and_preprocess_mscoco.runfiles/im2txt/im2txt/data/build_mscoco_data.py"", line 227, in _to_sequence_example
    ""image/data"": _bytes_feature(encoded_image),
  File ""/media/timberners/magicae/models/im2txt/bazel-bin/im2txt/download_and_preprocess_mscoco.runfiles/im2txt/im2txt/data/build_mscoco_data.py"", line 192, in _bytes_feature
    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[str(value)]))
TypeError: 'b\'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x01\\x00H\\x00H\\x00\\x00\\xff\\xdb\\x00C\\x0 has type str, but expected one of: bytes

Exception in thread Thread-7:
Traceback (most recent call last):
  File ""/home/timberners/anaconda3/envs/tensorflow/lib/python3.5/threading.py"", line 914, in _bootstrap_inner
    self.run()
  File ""/home/timberners/anaconda3/envs/tensorflow/lib/python3.5/threading.py"", line 862, in run
    self._target(*self._args, **self._kwargs)
  File ""/media/timberners/magicae/models/im2txt/bazel-bin/im2txt/download_and_preprocess_mscoco.runfiles/im2txt/im2txt/data/build_mscoco_data.py"", line 281, in _process_image_files
    sequence_example = _to_sequence_example(image, decoder, vocab)
  File ""/media/timberners/magicae/models/im2txt/bazel-bin/im2txt/download_and_preprocess_mscoco.runfiles/im2txt/im2txt/data/build_mscoco_data.py"", line 227, in _to_sequence_example
    ""image/data"": _bytes_feature(encoded_image),
  File ""/media/timberners/magicae/models/im2txt/bazel-bin/im2txt/download_and_preprocess_mscoco.runfiles/im2txt/im2txt/data/build_mscoco_data.py"", line 192, in _bytes_feature
    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[str(value)]))
TypeError: 'b\'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x01\\x00H\\x00H\\x00\\x00\\xff\\xdb\\x00C\\x0 has type str, but expected one of: bytes
Exception in thread Thread-6:
Traceback (most recent call last):
  File ""/home/timberners/anaconda3/envs/tensorflow/lib/python3.5/threading.py"", line 914, in _bootstrap_inner
    self.run()
  File ""/home/timberners/anaconda3/envs/tensorflow/lib/python3.5/threading.py"", line 862, in run
    self._target(*self._args, **self._kwargs)
  File ""/media/timberners/magicae/models/im2txt/bazel-bin/im2txt/download_and_preprocess_mscoco.runfiles/im2txt/im2txt/data/build_mscoco_data.py"", line 281, in _process_image_files
    sequence_example = _to_sequence_example(image, decoder, vocab)
  File ""/media/timberners/magicae/models/im2txt/bazel-bin/im2txt/download_and_preprocess_mscoco.runfiles/im2txt/im2txt/data/build_mscoco_data.py"", line 227, in _to_sequence_example
    ""image/data"": _bytes_feature(encoded_image),
  File ""/media/timberners/magicae/models/im2txt/bazel-bin/im2txt/download_and_preprocess_mscoco.runfiles/im2txt/im2txt/data/build_mscoco_data.py"", line 192, in _bytes_feature
    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[str(value)]))
TypeError: 'b\'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x01\\x00H\\x00H\\x00\\x00\\xff\\xe2\\x0cXICC_ has type str, but expected one of: bytes
Exception in thread Thread-4:
Traceback (most recent call last):
  File ""/home/timberners/anaconda3/envs/tensorflow/lib/python3.5/threading.py"", line 914, in _bootstrap_inner
    self.run()
  File ""/home/timberners/anaconda3/envs/tensorflow/lib/python3.5/threading.py"", line 862, in run
    self._target(*self._args, **self._kwargs)
  File ""/media/timberners/magicae/models/im2txt/bazel-bin/im2txt/download_and_preprocess_mscoco.runfiles/im2txt/im2txt/data/build_mscoco_data.py"", line 281, in _process_image_files
    sequence_example = _to_sequence_example(image, decoder, vocab)
  File ""/media/timberners/magicae/models/im2txt/bazel-bin/im2txt/download_and_preprocess_mscoco.runfiles/im2txt/im2txt/data/build_mscoco_data.py"", line 227, in _to_sequence_example
    ""image/data"": _bytes_feature(encoded_image),
  File ""/media/timberners/magicae/models/im2txt/bazel-bin/im2txt/download_and_preprocess_mscoco.runfiles/im2txt/im2txt/data/build_mscoco_data.py"", line 192, in _bytes_feature
    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[str(value)]))
TypeError: 'b\'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x01\\x00H\\x00H\\x00\\x00\\xff\\xe2\\x0cTICC_ has type str, but expected one of: bytes


Exception in thread Thread-5:
Traceback (most recent call last):
  File ""/home/timberners/anaconda3/envs/tensorflow/lib/python3.5/threading.py"", line 914, in _bootstrap_inner
    self.run()
  File ""/home/timberners/anaconda3/envs/tensorflow/lib/python3.5/threading.py"", line 862, in run
    self._target(*self._args, **self._kwargs)
  File ""/media/timberners/magicae/models/im2txt/bazel-bin/im2txt/download_and_preprocess_mscoco.runfiles/im2txt/im2txt/data/build_mscoco_data.py"", line 281, in _process_image_files
    sequence_example = _to_sequence_example(image, decoder, vocab)
  File ""/media/timberners/magicae/models/im2txt/bazel-bin/im2txt/download_and_preprocess_mscoco.runfiles/im2txt/im2txt/data/build_mscoco_data.py"", line 227, in _to_sequence_example
    ""image/data"": _bytes_feature(encoded_image),
  File ""/media/timberners/magicae/models/im2txt/bazel-bin/im2txt/download_and_preprocess_mscoco.runfiles/im2txt/im2txt/data/build_mscoco_data.py"", line 192, in _bytes_feature
    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[str(value)]))
TypeError: 'b\'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x01\\x00H\\x00H\\x00\\x00\\xff\\xe1\\x0b\\x0e has type str, but expected one of: bytes


Exception in thread Thread-8:
Traceback (most recent call last):
  File ""/home/timberners/anaconda3/envs/tensorflow/lib/python3.5/threading.py"", line 914, in _bootstrap_inner
    self.run()
  File ""/home/timberners/anaconda3/envs/tensorflow/lib/python3.5/threading.py"", line 862, in run
    self._target(*self._args, **self._kwargs)
  File ""/media/timberners/magicae/models/im2txt/bazel-bin/im2txt/download_and_preprocess_mscoco.runfiles/im2txt/im2txt/data/build_mscoco_data.py"", line 281, in _process_image_files
    sequence_example = _to_sequence_example(image, decoder, vocab)
  File ""/media/timberners/magicae/models/im2txt/bazel-bin/im2txt/download_and_preprocess_mscoco.runfiles/im2txt/im2txt/data/build_mscoco_data.py"", line 227, in _to_sequence_example
    ""image/data"": _bytes_feature(encoded_image),
  File ""/media/timberners/magicae/models/im2txt/bazel-bin/im2txt/download_and_preprocess_mscoco.runfiles/im2txt/im2txt/data/build_mscoco_data.py"", line 192, in _bytes_feature
    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[str(value)]))
TypeError: 'b\'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x01\\x01\\xce\\x01\\xce\\x00\\x00\\xff\\xe2\\ has type str, but expected one of: bytes

2017-03-26 01:57:03.430551: Finished processing all 586368 image-caption pairs in data set 'train'.
I tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0)
Launching 4 threads for spacings: [[0, 2533], [2533, 5066], [5066, 7599], [7599, 10132]]
Exception in thread Thread-10:
Traceback (most recent call last):
  File ""/home/timberners/anaconda3/envs/tensorflow/lib/python3.5/threading.py"", line 914, in _bootstrap_inner
    self.run()
  File ""/home/timberners/anaconda3/envs/tensorflow/lib/python3.5/threading.py"", line 862, in run
    self._target(*self._args, **self._kwargs)
  File ""/media/timberners/magicae/models/im2txt/bazel-bin/im2txt/download_and_preprocess_mscoco.runfiles/im2txt/im2txt/data/build_mscoco_data.py"", line 281, in _process_image_files
    sequence_example = _to_sequence_example(image, decoder, vocab)
  File ""/media/timberners/magicae/models/im2txt/bazel-bin/im2txt/download_and_preprocess_mscoco.runfiles/im2txt/im2txt/data/build_mscoco_data.py"", line 227, in _to_sequence_example
    ""image/data"": _bytes_feature(encoded_image),
  File ""/media/timberners/magicae/models/im2txt/bazel-bin/im2txt/download_and_preprocess_mscoco.runfiles/im2txt/im2txt/data/build_mscoco_data.py"", line 192, in _bytes_feature
    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[str(value)]))
TypeError: 'b\'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x01\\x00H\\x00H\\x00\\x00\\xff\\xdb\\x00C\\x0 has type str, but expected one of: bytes

Exception in thread Thread-11:
Traceback (most recent call last):
  File ""/home/timberners/anaconda3/envs/tensorflow/lib/python3.5/threading.py"", line 914, in _bootstrap_inner
    self.run()
  File ""/home/timberners/anaconda3/envs/tensorflow/lib/python3.5/threading.py"", line 862, in run
    self._target(*self._args, **self._kwargs)
  File ""/media/timberners/magicae/models/im2txt/bazel-bin/im2txt/download_and_preprocess_mscoco.runfiles/im2txt/im2txt/data/build_mscoco_data.py"", line 281, in _process_image_files
    sequence_example = _to_sequence_example(image, decoder, vocab)
  File ""/media/timberners/magicae/models/im2txt/bazel-bin/im2txt/download_and_preprocess_mscoco.runfiles/im2txt/im2txt/data/build_mscoco_data.py"", line 227, in _to_sequence_example
    ""image/data"": _bytes_feature(encoded_image),
  File ""/media/timberners/magicae/models/im2txt/bazel-bin/im2txt/download_and_preprocess_mscoco.runfiles/im2txt/im2txt/data/build_mscoco_data.py"", line 192, in _bytes_feature
    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[str(value)]))
TypeError: 'b\'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x01\\x00H\\x00H\\x00\\x00\\xff\\xdb\\x00C\\x0 has type str, but expected one of: bytes

Exception in thread Thread-9:
Traceback (most recent call last):
  File ""/home/timberners/anaconda3/envs/tensorflow/lib/python3.5/threading.py"", line 914, in _bootstrap_inner
    self.run()
  File ""/home/timberners/anaconda3/envs/tensorflow/lib/python3.5/threading.py"", line 862, in run
    self._target(*self._args, **self._kwargs)
  File ""/media/timberners/magicae/models/im2txt/bazel-bin/im2txt/download_and_preprocess_mscoco.runfiles/im2txt/im2txt/data/build_mscoco_data.py"", line 281, in _process_image_files
    sequence_example = _to_sequence_example(image, decoder, vocab)
  File ""/media/timberners/magicae/models/im2txt/bazel-bin/im2txt/download_and_preprocess_mscoco.runfiles/im2txt/im2txt/data/build_mscoco_data.py"", line 227, in _to_sequence_example
    ""image/data"": _bytes_feature(encoded_image),
  File ""/media/timberners/magicae/models/im2txt/bazel-bin/im2txt/download_and_preprocess_mscoco.runfiles/im2txt/im2txt/data/build_mscoco_data.py"", line 192, in _bytes_feature
    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[str(value)]))
TypeError: 'b\'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x01\\x00H\\x00H\\x00\\x00\\xff\\xe2\\x0cXICC_ has type str, but expected one of: bytes

Exception in thread Thread-12:
Traceback (most recent call last):
  File ""/home/timberners/anaconda3/envs/tensorflow/lib/python3.5/threading.py"", line 914, in _bootstrap_inner
    self.run()
  File ""/home/timberners/anaconda3/envs/tensorflow/lib/python3.5/threading.py"", line 862, in run
    self._target(*self._args, **self._kwargs)
  File ""/media/timberners/magicae/models/im2txt/bazel-bin/im2txt/download_and_preprocess_mscoco.runfiles/im2txt/im2txt/data/build_mscoco_data.py"", line 281, in _process_image_files
    sequence_example = _to_sequence_example(image, decoder, vocab)
  File ""/media/timberners/magicae/models/im2txt/bazel-bin/im2txt/download_and_preprocess_mscoco.runfiles/im2txt/im2txt/data/build_mscoco_data.py"", line 227, in _to_sequence_example
    ""image/data"": _bytes_feature(encoded_image),
  File ""/media/timberners/magicae/models/im2txt/bazel-bin/im2txt/download_and_preprocess_mscoco.runfiles/im2txt/im2txt/data/build_mscoco_data.py"", line 192, in _bytes_feature
    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[str(value)]))
TypeError: 'b\'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x01\\x01,\\x01,\\x00\\x00\\xff\\xdb\\x00C\\x0 has type str, but expected one of: bytes

2017-03-26 01:57:04.812453: Finished processing all 10132 image-caption pairs in data set 'val'.
I tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0)
Launching 8 threads for spacings: [[0, 2533], [2533, 5066], [5066, 7600], [7600, 10133], [10133, 12666], [12666, 15200], [15200, 17733], [17733, 20267]]
Exception in thread Thread-16:
Traceback (most recent call last):
  File ""/home/timberners/anaconda3/envs/tensorflow/lib/python3.5/threading.py"", line 914, in _bootstrap_inner
    self.run()
  File ""/home/timberners/anaconda3/envs/tensorflow/lib/python3.5/threading.py"", line 862, in run
    self._target(*self._args, **self._kwargs)
  File ""/media/timberners/magicae/models/im2txt/bazel-bin/im2txt/download_and_preprocess_mscoco.runfiles/im2txt/im2txt/data/build_mscoco_data.py"", line 281, in _process_image_files
    sequence_example = _to_sequence_example(image, decoder, vocab)
  File ""/media/timberners/magicae/models/im2txt/bazel-bin/im2txt/download_and_preprocess_mscoco.runfiles/im2txt/im2txt/data/build_mscoco_data.py"", line 227, in _to_sequence_example
    ""image/data"": _bytes_feature(encoded_image),
  File ""/media/timberners/magicae/models/im2txt/bazel-bin/im2txt/download_and_preprocess_mscoco.runfiles/im2txt/im2txt/data/build_mscoco_data.py"", line 192, in _bytes_feature
    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[str(value)]))
TypeError: 'b\'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x01\\x00H\\x00H\\x00\\x00\\xff\\xfe\\x00\\x0c has type str, but expected one of: bytes

Exception in thread Thread-19:
Traceback (most recent call last):
  File ""/home/timberners/anaconda3/envs/tensorflow/lib/python3.5/threading.py"", line 914, in _bootstrap_inner
    self.run()
  File ""/home/timberners/anaconda3/envs/tensorflow/lib/python3.5/threading.py"", line 862, in run
    self._target(*self._args, **self._kwargs)
  File ""/media/timberners/magicae/models/im2txt/bazel-bin/im2txt/download_and_preprocess_mscoco.runfiles/im2txt/im2txt/data/build_mscoco_data.py"", line 281, in _process_image_files
    sequence_example = _to_sequence_example(image, decoder, vocab)
  File ""/media/timberners/magicae/models/im2txt/bazel-bin/im2txt/download_and_preprocess_mscoco.runfiles/im2txt/im2txt/data/build_mscoco_data.py"", line 227, in _to_sequence_example
    ""image/data"": _bytes_feature(encoded_image),
  File ""/media/timberners/magicae/models/im2txt/bazel-bin/im2txt/download_and_preprocess_mscoco.runfiles/im2txt/im2txt/data/build_mscoco_data.py"", line 192, in _bytes_feature
    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[str(value)]))
TypeError: 'b\'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x01\\x00H\\x00H\\x00\\x00\\xff\\xdb\\x00C\\x0 has type str, but expected one of: bytes

Exception in thread Thread-13:
Traceback (most recent call last):
  File ""/home/timberners/anaconda3/envs/tensorflow/lib/python3.5/threading.py"", line 914, in _bootstrap_inner
    self.run()
  File ""/home/timberners/anaconda3/envs/tensorflow/lib/python3.5/threading.py"", line 862, in run
    self._target(*self._args, **self._kwargs)
  File ""/media/timberners/magicae/models/im2txt/bazel-bin/im2txt/download_and_preprocess_mscoco.runfiles/im2txt/im2txt/data/build_mscoco_data.py"", line 281, in _process_image_files
    sequence_example = _to_sequence_example(image, decoder, vocab)
  File ""/media/timberners/magicae/models/im2txt/bazel-bin/im2txt/download_and_preprocess_mscoco.runfiles/im2txt/im2txt/data/build_mscoco_data.py"", line 227, in _to_sequence_example
    ""image/data"": _bytes_feature(encoded_image),
  File ""/media/timberners/magicae/models/im2txt/bazel-bin/im2txt/download_and_preprocess_mscoco.runfiles/im2txt/im2txt/data/build_mscoco_data.py"", line 192, in _bytes_feature
    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[str(value)]))
TypeError: 'b\'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x01\\x00H\\x00H\\x00\\x00\\xff\\xdb\\x00C\\x0 has type str, but expected one of: bytes

Exception in thread Thread-15:
Traceback (most recent call last):
  File ""/home/timberners/anaconda3/envs/tensorflow/lib/python3.5/threading.py"", line 914, in _bootstrap_inner
    self.run()
  File ""/home/timberners/anaconda3/envs/tensorflow/lib/python3.5/threading.py"", line 862, in run
    self._target(*self._args, **self._kwargs)
  File ""/media/timberners/magicae/models/im2txt/bazel-bin/im2txt/download_and_preprocess_mscoco.runfiles/im2txt/im2txt/data/build_mscoco_data.py"", line 281, in _process_image_files
    sequence_example = _to_sequence_example(image, decoder, vocab)
  File ""/media/timberners/magicae/models/im2txt/bazel-bin/im2txt/download_and_preprocess_mscoco.runfiles/im2txt/im2txt/data/build_mscoco_data.py"", line 227, in _to_sequence_example
    ""image/data"": _bytes_feature(encoded_image),
  File ""/media/timberners/magicae/models/im2txt/bazel-bin/im2txt/download_and_preprocess_mscoco.runfiles/im2txt/im2txt/data/build_mscoco_data.py"", line 192, in _bytes_feature
    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[str(value)]))
TypeError: 'b\'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x01\\x00`\\x00`\\x00\\x00\\xff\\xdb\\x00C\\x0 has type str, but expected one of: bytes

Exception in thread Thread-20:
Traceback (most recent call last):
  File ""/home/timberners/anaconda3/envs/tensorflow/lib/python3.5/threading.py"", line 914, in _bootstrap_inner
    self.run()
  File ""/home/timberners/anaconda3/envs/tensorflow/lib/python3.5/threading.py"", line 862, in run
    self._target(*self._args, **self._kwargs)
  File ""/media/timberners/magicae/models/im2txt/bazel-bin/im2txt/download_and_preprocess_mscoco.runfiles/im2txt/im2txt/data/build_mscoco_data.py"", line 281, in _process_image_files
    sequence_example = _to_sequence_example(image, decoder, vocab)
  File ""/media/timberners/magicae/models/im2txt/bazel-bin/im2txt/download_and_preprocess_mscoco.runfiles/im2txt/im2txt/data/build_mscoco_data.py"", line 227, in _to_sequence_example
    ""image/data"": _bytes_feature(encoded_image),
  File ""/media/timberners/magicae/models/im2txt/bazel-bin/im2txt/download_and_preprocess_mscoco.runfiles/im2txt/im2txt/data/build_mscoco_data.py"", line 192, in _bytes_feature
    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[str(value)]))
TypeError: 'b\'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x01\\x00H\\x00H\\x00\\x00\\xff\\xe1\\n\\x00XM has type str, but expected one of: bytes
Exception in thread Thread-18:
Traceback (most recent call last):
  File ""/home/timberners/anaconda3/envs/tensorflow/lib/python3.5/threading.py"", line 914, in _bootstrap_inner
    self.run()
  File ""/home/timberners/anaconda3/envs/tensorflow/lib/python3.5/threading.py"", line 862, in run
    self._target(*self._args, **self._kwargs)
  File ""/media/timberners/magicae/models/im2txt/bazel-bin/im2txt/download_and_preprocess_mscoco.runfiles/im2txt/im2txt/data/build_mscoco_data.py"", line 281, in _process_image_files
    sequence_example = _to_sequence_example(image, decoder, vocab)
  File ""/media/timberners/magicae/models/im2txt/bazel-bin/im2txt/download_and_preprocess_mscoco.runfiles/im2txt/im2txt/data/build_mscoco_data.py"", line 227, in _to_sequence_example
    ""image/data"": _bytes_feature(encoded_image),
  File ""/media/timberners/magicae/models/im2txt/bazel-bin/im2txt/download_and_preprocess_mscoco.runfiles/im2txt/im2txt/data/build_mscoco_data.py"", line 192, in _bytes_feature
    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[str(value)]))
TypeError: 'b\'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x01\\x00H\\x00H\\x00\\x00\\xff\\xe1\\x01\\xc7 has type str, but expected one of: bytes

Exception in thread Thread-14:
Traceback (most recent call last):
  File ""/home/timberners/anaconda3/envs/tensorflow/lib/python3.5/threading.py"", line 914, in _bootstrap_inner
    self.run()
  File ""/home/timberners/anaconda3/envs/tensorflow/lib/python3.5/threading.py"", line 862, in run
    self._target(*self._args, **self._kwargs)
  File ""/media/timberners/magicae/models/im2txt/bazel-bin/im2txt/download_and_preprocess_mscoco.runfiles/im2txt/im2txt/data/build_mscoco_data.py"", line 281, in _process_image_files
    sequence_example = _to_sequence_example(image, decoder, vocab)
  File ""/media/timberners/magicae/models/im2txt/bazel-bin/im2txt/download_and_preprocess_mscoco.runfiles/im2txt/im2txt/data/build_mscoco_data.py"", line 227, in _to_sequence_example
    ""image/data"": _bytes_feature(encoded_image),
  File ""/media/timberners/magicae/models/im2txt/bazel-bin/im2txt/download_and_preprocess_mscoco.runfiles/im2txt/im2txt/data/build_mscoco_data.py"", line 192, in _bytes_feature
    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[str(value)]))
TypeError: 'b\'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x01\\x01,\\x01,\\x00\\x00\\xff\\xdb\\x00C\\x0 has type str, but expected one of: bytes

Exception in thread Thread-17:
Traceback (most recent call last):
  File ""/home/timberners/anaconda3/envs/tensorflow/lib/python3.5/threading.py"", line 914, in _bootstrap_inner
    self.run()
  File ""/home/timberners/anaconda3/envs/tensorflow/lib/python3.5/threading.py"", line 862, in run
    self._target(*self._args, **self._kwargs)
  File ""/media/timberners/magicae/models/im2txt/bazel-bin/im2txt/download_and_preprocess_mscoco.runfiles/im2txt/im2txt/data/build_mscoco_data.py"", line 281, in _process_image_files
    sequence_example = _to_sequence_example(image, decoder, vocab)
  File ""/media/timberners/magicae/models/im2txt/bazel-bin/im2txt/download_and_preprocess_mscoco.runfiles/im2txt/im2txt/data/build_mscoco_data.py"", line 227, in _to_sequence_example
    ""image/data"": _bytes_feature(encoded_image),
  File ""/media/timberners/magicae/models/im2txt/bazel-bin/im2txt/download_and_preprocess_mscoco.runfiles/im2txt/im2txt/data/build_mscoco_data.py"", line 192, in _bytes_feature
    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[str(value)]))
TypeError: 'b\'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x01\\x00H\\x00H\\x00\\x00\\xff\\xe2\\x0cXICC_ has type str, but expected one of: bytes


2017-03-26 01:57:05.852854: Finished processing all 20267 image-caption pairs in data set 'test'.

```",KranthiGV,b'help wanted type:bug',2017-03-25T20:52:28Z,2020-05-02T05:25:51Z,,,,,,,
1247,README.md warning on extra background class added by build_image_data.py,"This cost me many hours of debugging when my network failed to converge when applying `build_image_data.py` to a new dataset. Turns out I didn't read the `build_image_data.py` comments carefully and missed the part about the background class being labeled 0. The [one_hot_encoding](https://github.com/tensorflow/models/blob/master/slim/train_image_classifier.py#L455) in train_image_classifier does not take into account of out-of-range inputs. Therefore in my 3 classes dataset, my labels of `[3 2 2 1]` are converted to these one hot labels:
```
[[0 0 0]
 [0 0 1]
 [0 0 1]
 [0 1 0]]
```
The NN will always classify class 3 as 'wrong'. I fixed this by changing [label_index](https://github.com/tensorflow/models/blob/master/inception/inception/data/build_image_data.py#L375) to 0 so my classes will now numerate `[0,2]`. (alternatively can add `tf.subtract(labels, 1)`). 

Additionally, I think that the background class is unnecessary since the script is referred to quite often in the README as a general data converter to TFRecords. The background class seems to be a relic of the ImageNet dataset that does not generalize well to other types of data. In any case, I hope this addition will emphasize this nuance to future README readers.

Fix shell script to match example.",jimmyyentran,b'cla: yes stat:awaiting response',2017-03-23T11:31:12Z,2017-03-24T00:06:27Z,,,,,,,
1232,"[Syntaxnet,dragnn] bazel test ... not passed all on Ubuntu 16.04 ","## [Syntaxnet,dragnn] bazel test ... not passed all on Ubuntu 16.04

Hi all,
I'm new to tensorflow and syntaxnet. I followed several Issues' responses but didn't solve the problems.

- Environment:
```
Linux kernel: Linux usar 4.4.0-66-generic #87-Ubuntu SMP Fri Mar 3 15:29:05 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux
GCC:   gcc (Ubuntu 5.4.0-6ubuntu1~16.04.4) 5.4.0 20160609
G++:    g++ (Ubuntu 5.4.0-6ubuntu1~16.04.4) 5.4.0 20160609
Cuda: Cuda compilation tools, release 8.0, V8.0.44
$LD_LIBRARY_PATH :/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64: No such file or directory
$CUDA_HOME /usr/local/cuda
python: Python 2.7.13 :: Anaconda custom (64-bit)
tensorflow/models: commit 0bd8e24d82c2f330b91767397da52072d477ab17

Tensorflow configure: 
All default except yes with CUDA option
```



 `bazel test ...`

```
INFO: Elapsed time: 3.855s, Critical Path: 3.52s
//dragnn/python:visualization_test                              (cached) PASSED in 2.9s
//syntaxnet:arc_standard_transitions_test                       (cached) PASSED in 0.1s
//syntaxnet:beam_reader_ops_test                                (cached) PASSED in 15.0s
//syntaxnet:binary_segment_state_test                           (cached) PASSED in 0.1s
//syntaxnet:binary_segment_transitions_test                     (cached) PASSED in 0.1s
//syntaxnet:char_ngram_string_extractor_test                    (cached) PASSED in 0.0s
//syntaxnet:char_properties_test                                (cached) PASSED in 0.1s
//syntaxnet:char_shift_transitions_test                         (cached) PASSED in 0.1s
//syntaxnet:graph_builder_test                                  (cached) PASSED in 7.5s
//syntaxnet:head_transitions_test                               (cached) PASSED in 0.2s
//syntaxnet:label_transitions_test                              (cached) PASSED in 0.1s
//syntaxnet:lexicon_builder_test                                (cached) PASSED in 1.6s
//syntaxnet:morphology_label_set_test                           (cached) PASSED in 0.0s
//syntaxnet:once_transitions_test                               (cached) PASSED in 0.1s
//syntaxnet:parser_features_test                                (cached) PASSED in 0.1s
//syntaxnet:parser_trainer_test                                 (cached) PASSED in 23.0s
//syntaxnet:reader_ops_test                                     (cached) PASSED in 3.2s
//syntaxnet:segmenter_utils_test                                (cached) PASSED in 0.0s
//syntaxnet:sentence_features_test                              (cached) PASSED in 0.1s
//syntaxnet:shared_store_test                                   (cached) PASSED in 0.3s
//syntaxnet:tagger_transitions_test                             (cached) PASSED in 0.1s
//syntaxnet:text_formats_test                                   (cached) PASSED in 1.8s
//syntaxnet/util:check_test                                     (cached) PASSED in 1.7s
//syntaxnet/util:registry_test                                  (cached) PASSED in 1.8s
//syntaxnet:whole_sentence_features_test                        (cached) PASSED in 0.1s
//util/utf8:unicodetext_unittest                                (cached) PASSED in 0.0s
//dragnn/components/syntaxnet:syntaxnet_component_test                NO STATUS
//dragnn/components/syntaxnet:syntaxnet_link_feature_extractor_test   NO STATUS
//dragnn/components/syntaxnet:syntaxnet_transition_state_test         NO STATUS
//dragnn/core:compute_session_impl_test                               NO STATUS
//dragnn/core:compute_session_pool_test                               NO STATUS
//dragnn/core:dragnn_bulk_op_kernels_test                             NO STATUS
//dragnn/core:dragnn_op_kernels_test                                  NO STATUS
//dragnn/core:index_translator_test                                   NO STATUS
//dragnn/core:input_batch_cache_test                                  NO STATUS
//dragnn/core:resource_container_test                                 NO STATUS
//dragnn/io:sentence_input_batch_test                                 NO STATUS
//dragnn/python:bulk_component_test                                   NO STATUS
//dragnn/python:composite_optimizer_test                              NO STATUS
//dragnn/python:digraph_ops_test                                      NO STATUS
//dragnn/python:evaluation_test                                       NO STATUS
//dragnn/python:graph_builder_test                                    NO STATUS
//dragnn/python:lexicon_test                                          NO STATUS
//dragnn/python:network_units_test                                    NO STATUS
//dragnn/python:render_parse_tree_graphviz_test                       NO STATUS
//dragnn/python:render_spec_with_graphviz_test                        NO STATUS
//dragnn/python:sentence_io_test                                      NO STATUS
//dragnn/python:spec_builder_test                                     NO STATUS
//examples/dragnn:test_run_all_tutorials                              NO STATUS

Executed 0 out of 50 tests: 26 tests pass, 1 fails to build and 23 were skipped.
There were tests whose specified size is too big. Use the --test_verbose_timeout_warnings command line option to see which ones these are.
```


```
INFO: Found 162 targets and 50 test targets...
ERROR: /home/usar/ws/pretrained/models/syntaxnet/dragnn/core/BUILD:102:1: C++ compilation of rule '//dragnn/core:beam_test' failed: gcc failed: error executing command /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -B/usr/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG ... (remaining 125 argument(s) skipped): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.
In file included from external/org_tensorflow/tensorflow/core/platform/default/logging.h:24:0,
                 from external/org_tensorflow/tensorflow/core/platform/logging.h:25,
                 from external/org_tensorflow/tensorflow/core/lib/core/status.h:24,
                 from ./syntaxnet/base.h:24,
                 from ./dragnn/core/interfaces/transition_state.h:7,
                 from ./dragnn/core/interfaces/cloneable_transition_state.h:7,
                 from ./dragnn/core/beam.h:8,
                 from dragnn/core/beam_test.cc:1:
./dragnn/core/beam.h: In member function 'void syntaxnet::dragnn::Beam<T>::AdvanceFromPrediction(const float*, int, int)':
./dragnn/core/beam.h:115:37: error: there are no arguments to 'isnan' that depend on a template parameter, so a declaration of 'isnan' must be available [-fpermissive]
             CHECK(!isnan(score_delta));
                                     ^
external/org_tensorflow/tensorflow/core/platform/macros.h:64:30: note: in definition of macro 'TF_PREDICT_FALSE'
 #define TF_PREDICT_FALSE(x) (x)
                              ^
./dragnn/core/beam.h:115:13: note: in expansion of macro 'CHECK'
             CHECK(!isnan(score_delta));
             ^
./dragnn/core/beam.h:115:37: note: (if you use '-fpermissive', G++ will accept your code, but allowing the use of an undeclared name is deprecated)
             CHECK(!isnan(score_delta));
                                     ^
external/org_tensorflow/tensorflow/core/platform/macros.h:64:30: note: in definition of macro 'TF_PREDICT_FALSE'
 #define TF_PREDICT_FALSE(x) (x)
                              ^
./dragnn/core/beam.h:115:13: note: in expansion of macro 'CHECK'
             CHECK(!isnan(score_delta));
             ^
dragnn/core/beam_test.cc: In member function 'virtual void syntaxnet::dragnn::BeamTest_AdvancingCreatesNewTransitions_Test::TestBody()':
dragnn/core/beam_test.cc:177:21: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]
   for (int i = 0; i < beam.beam().size(); ++i) {
                     ^
dragnn/core/beam_test.cc: In member function 'virtual void syntaxnet::dragnn::BeamTest_MultipleElementBeamsAdvanceAllElements_Test::TestBody()':
dragnn/core/beam_test.cc:245:21: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]
   for (int i = 0; i < beam.beam().size(); ++i) {
                     ^
dragnn/core/beam_test.cc: In member function 'virtual void syntaxnet::dragnn::BeamTest_AdvancingDropsLowValuePredictions_Test::TestBody()':
dragnn/core/beam_test.cc:328:21: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]
   for (int i = 0; i < beam.beam().size(); ++i) {
                     ^
dragnn/core/beam_test.cc: In member function 'virtual void syntaxnet::dragnn::BeamTest_AdvancesFromOracleWithMultipleStates_Test::TestBody()':
dragnn/core/beam_test.cc:406:21: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]
   for (int i = 0; i < beam.beam().size(); ++i) {
                     ^
dragnn/core/beam_test.cc:413:21: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]
   for (int i = 0; i < beam.beam().size(); ++i) {
                     ^
dragnn/core/beam_test.cc: In member function 'virtual void syntaxnet::dragnn::BeamTest_IgnoresForbiddenTransitionActions_Test::TestBody()':
dragnn/core/beam_test.cc:522:21: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]
   for (int i = 0; i < beam.beam().size(); ++i) {
                     ^
dragnn/core/beam_test.cc: In member function 'virtual void syntaxnet::dragnn::BeamTest_FindPreviousIndexTracesHistory_Test::TestBody()':
dragnn/core/beam_test.cc:648:21: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]
   for (int i = 0; i < beam.beam().size(); ++i) {
                     ^
In file included from dragnn/core/beam_test.cc:1:0:
./dragnn/core/beam.h: In instantiation of 'void syntaxnet::dragnn::Beam<T>::Init(std::vector<std::unique_ptr<T> >) [with T = syntaxnet::dragnn::{anonymous}::TestTransitionState]':
dragnn/core/beam_test.cc:117:30:   required from here
./dragnn/core/beam.h:58:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]
     for (int i = 0; i < beam_.size(); ++i) {
                       ^
./dragnn/core/beam.h: In instantiation of 'void syntaxnet::dragnn::Beam<T>::AdvanceFromPrediction(const float*, int, int) [with T = syntaxnet::dragnn::{anonymous}::TestTransitionState]':
dragnn/core/beam_test.cc:118:66:   required from here
./dragnn/core/beam.h:100:39: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]
       for (int beam_idx = 0; beam_idx < beam_.size(); ++beam_idx) {
                                       ^
In file included from external/org_tensorflow/tensorflow/core/platform/default/logging.h:24:0,
                 from external/org_tensorflow/tensorflow/core/platform/logging.h:25,
                 from external/org_tensorflow/tensorflow/core/lib/core/status.h:24,
                 from ./syntaxnet/base.h:24,
                 from ./dragnn/core/interfaces/transition_state.h:7,
                 from ./dragnn/core/interfaces/cloneable_transition_state.h:7,
                 from ./dragnn/core/beam.h:8,
                 from dragnn/core/beam_test.cc:1:
./dragnn/core/beam.h:115:25: error: 'isnan' was not declared in this scope
             CHECK(!isnan(score_delta));
                         ^
external/org_tensorflow/tensorflow/core/platform/macros.h:64:30: note: in definition of macro 'TF_PREDICT_FALSE'
 #define TF_PREDICT_FALSE(x) (x)
                              ^
./dragnn/core/beam.h:115:13: note: in expansion of macro 'CHECK'
             CHECK(!isnan(score_delta));
             ^
./dragnn/core/beam.h:115:25: note: suggested alternatives:
             CHECK(!isnan(score_delta));
                         ^
external/org_tensorflow/tensorflow/core/platform/macros.h:64:30: note: in definition of macro 'TF_PREDICT_FALSE'
 #define TF_PREDICT_FALSE(x) (x)
                              ^
./dragnn/core/beam.h:115:13: note: in expansion of macro 'CHECK'
             CHECK(!isnan(score_delta));
             ^
In file included from /usr/include/c++/5/random:38:0,
                 from /usr/include/c++/5/bits/stl_algo.h:66,
                 from /usr/include/c++/5/algorithm:62,
                 from ./dragnn/core/beam.h:4,
                 from dragnn/core/beam_test.cc:1:
/usr/include/c++/5/cmath:641:5: note:   'std::isnan'
     isnan(_Tp __x)
     ^
/usr/include/c++/5/cmath:641:5: note:   'std::isnan'
In file included from dragnn/core/beam_test.cc:1:0:
./dragnn/core/beam.h: In instantiation of 'void syntaxnet::dragnn::Beam<T>::AdvanceFromOracle() [with T = syntaxnet::dragnn::{anonymous}::TestTransitionState]':
dragnn/core/beam_test.cc:356:26:   required from here
./dragnn/core/beam.h:166:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]
     for (int i = 0; i < beam_.size(); ++i) {
                       ^
In file included from external/org_tensorflow/tensorflow/core/platform/default/logging.h:24:0,
                 from external/org_tensorflow/tensorflow/core/platform/logging.h:25,
                 from external/org_tensorflow/tensorflow/core/lib/core/status.h:24,
                 from ./syntaxnet/base.h:24,
                 from ./dragnn/core/interfaces/transition_state.h:7,
                 from ./dragnn/core/interfaces/cloneable_transition_state.h:7,
                 from ./dragnn/core/beam.h:8,
                 from dragnn/core/beam_test.cc:1:
./dragnn/core/beam.h: In instantiation of 'int syntaxnet::dragnn::Beam<T>::FindPreviousIndex(int, int) const [with T = syntaxnet::dragnn::{anonymous}::TestTransitionState]':
dragnn/core/beam_test.cc:676:3:   required from here
./dragnn/core/beam.h:225:24: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]
       CHECK(num_steps_ == beam_index_history_.size() - 1);
                        ^
external/org_tensorflow/tensorflow/core/platform/macros.h:64:30: note: in definition of macro 'TF_PREDICT_FALSE'
 #define TF_PREDICT_FALSE(x) (x)
                              ^
./dragnn/core/beam.h:225:7: note: in expansion of macro 'CHECK'
       CHECK(num_steps_ == beam_index_history_.size() - 1);
       ^
In file included from /usr/include/c++/5/algorithm:62:0,
                 from ./dragnn/core/beam.h:4,
                 from dragnn/core/beam_test.cc:1:
/usr/include/c++/5/bits/stl_algo.h: At global scope:
/usr/include/c++/5/bits/stl_algo.h:4718:5: error: 'void std::sort(_RAIter, _RAIter, _Compare) [with _RAIter = __gnu_cxx::__normal_iterator<syntaxnet::dragnn::Beam<syntaxnet::dragnn::{anonymous}::TestTransitionState>::Transition*, std::vector<syntaxnet::dragnn::Beam<syntaxnet::dragnn::{anonymous}::TestTransitionState>::Transition, std::allocator<syntaxnet::dragnn::Beam<syntaxnet::dragnn::{anonymous}::TestTransitionState>::Transition> > >; _Compare = syntaxnet::dragnn::Beam<T>::AdvanceFromPrediction(const float*, int, int) [with T = syntaxnet::dragnn::{anonymous}::TestTransitionState]::<lambda(const syntaxnet::dragnn::Beam<syntaxnet::dragnn::{anonymous}::TestTransitionState>::Transition&, const syntaxnet::dragnn::Beam<syntaxnet::dragnn::{anonymous}::TestTransitionState>::Transition&)>]', declared using local type 'syntaxnet::dragnn::Beam<T>::AdvanceFromPrediction(const float*, int, int) [with T = syntaxnet::dragnn::{anonymous}::TestTransitionState]::<lambda(const syntaxnet::dragnn::Beam<syntaxnet::dragnn::{anonymous}::TestTransitionState>::Transition&, const syntaxnet::dragnn::Beam<syntaxnet::dragnn::{anonymous}::TestTransitionState>::Transition&)>', is used but never defined [-fpermissive]
     sort(_RandomAccessIterator __first, _RandomAccessIterator __last,
     ^

```

",10ap,None,2017-03-21T16:06:00Z,2017-03-21T21:03:14Z,,,,,,,
1226,"Revert ""fixed a bug in sampled_loss(), made compatible for 0.12.0""","Reverts tensorflow/models#982
See discussions in https://github.com/tensorflow/models/issues/1221, https://github.com/tensorflow/models/issues/836, https://github.com/tensorflow/tensorflow/issues/8505, and https://github.com/tensorflow/models/issues/1220",nealwu,b'cla: yes',2017-03-20T22:18:35Z,2017-03-20T22:24:08Z,,,,,,,
1222,[Inception] Resource Exhausted exception when generating TF-Records,"Hi,

I started generating TF records to start training Imagenet data from scratch. I keep getting this error and the process terminates:

````2017-03-20 08:51:14.244444 [thread 0]: Processed 19000 of 1077584 images in thread batch.
Exception in thread Thread-7:
Traceback (most recent call last):
  File ""/usr/lib/python2.7/threading.py"", line 810, in __bootstrap_inner
    self.run()
  File ""/usr/lib/python2.7/threading.py"", line 763, in run
    self.__target(*self.__args, **self.__kwargs)
  File ""/home/ubuntu/tensorflow_models/models-master/inception/bazel-bin/inception/download_and_preprocess_imagenet.runfiles/inception/inception/data/build_imagenet_data.py"", line 389, in _process_image_files_batch
    image_buffer, height, width = _process_image(filename, coder)
  File ""/home/ubuntu/tensorflow_models/models-master/inception/bazel-bin/inception/download_and_preprocess_imagenet.runfiles/inception/inception/data/build_imagenet_data.py"", line 317, in _process_image
    image_data = f.read()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/lib/io/file_io.py"", line 102, in read
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/lib/io/file_io.py"", line 72, in _preread_check
  File ""/usr/lib/python2.7/contextlib.py"", line 24, in __exit__
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/errors.py"", line 463, in raise_exception_on_not_ok_status
ResourceExhaustedError: /imagenet2/raw-data/train/n02055803/n02055803_8301.jpg

Exception in thread Thread-8:
Traceback (most recent call last):
  File ""/usr/lib/python2.7/threading.py"", line 810, in __bootstrap_inner
    self.run()
  File ""/usr/lib/python2.7/threading.py"", line 763, in run
    self.__target(*self.__args, **self.__kwargs)
  File ""/home/ubuntu/tensorflow_models/models-master/inception/bazel-bin/inception/download_and_preprocess_imagenet.runfiles/inception/inception/data/build_imagenet_data.py"", line 389, in _process_image_files_batch
    image_buffer, height, width = _process_image(filename, coder)
  File ""/home/ubuntu/tensorflow_models/models-master/inception/bazel-bin/inception/download_and_preprocess_imagenet.runfiles/inception/inception/data/build_imagenet_data.py"", line 317, in _process_image
    image_data = f.read()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/lib/io/file_io.py"", line 102, in read
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/lib/io/file_io.py"", line 72, in _preread_check
  File ""/usr/lib/python2.7/contextlib.py"", line 24, in __exit__
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/errors.py"", line 463, in raise_exception_on_not_ok_status
ResourceExhaustedError: /imagenet2/raw-data/train/n02382948/n02382948_22355.jpg

Exception in thread Thread-3:
Traceback (most recent call last):
  File ""/usr/lib/python2.7/threading.py"", line 810, in __bootstrap_inner
    self.run()
  File ""/usr/lib/python2.7/threading.py"", line 763, in run
    self.__target(*self.__args, **self.__kwargs)
  File ""/home/ubuntu/tensorflow_models/models-master/inception/bazel-bin/inception/download_and_preprocess_imagenet.runfiles/inception/inception/data/build_imagenet_data.py"", line 389, in _process_image_files_batch
    image_buffer, height, width = _process_image(filename, coder)
  File ""/home/ubuntu/tensorflow_models/models-master/inception/bazel-bin/inception/download_and_preprocess_imagenet.runfiles/inception/inception/data/build_imagenet_data.py"", line 317, in _process_image
    image_data = f.read()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/lib/io/file_io.py"", line 102, in read
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/lib/io/file_io.py"", line 72, in _preread_check
  File ""/usr/lib/python2.7/contextlib.py"", line 24, in __exit__
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/errors.py"", line 463, in raise_exception_on_not_ok_status
ResourceExhaustedError: /imagenet2/raw-data/train/n12409470/n12409470_12184.jpg

Exception in thread Thread-1:
Traceback (most recent call last):
  File ""/usr/lib/python2.7/threading.py"", line 810, in __bootstrap_inner
    self.run()
  File ""/usr/lib/python2.7/threading.py"", line 763, in run
    self.__target(*self.__args, **self.__kwargs)
  File ""/home/ubuntu/tensorflow_models/models-master/inception/bazel-bin/inception/download_and_preprocess_imagenet.runfiles/inception/inception/data/build_imagenet_data.py"", line 389, in _process_image_files_batch
    image_buffer, height, width = _process_image(filename, coder)
  File ""/home/ubuntu/tensorflow_models/models-master/inception/bazel-bin/inception/download_and_preprocess_imagenet.runfiles/inception/inception/data/build_imagenet_data.py"", line 317, in _process_image
    image_data = f.read()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/lib/io/file_io.py"", line 102, in read
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/lib/io/file_io.py"", line 72, in _preread_check
  File ""/usr/lib/python2.7/contextlib.py"", line 24, in __exit__
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/errors.py"", line 463, in raise_exception_on_not_ok_status
ResourceExhaustedError: /imagenet2/raw-data/train/n03978966/n03978966_12697.jpg

2017-03-20 08:51:17.086050: Finished writing all 8620676 images in data set.
Determining list of input files and labels from /imagenet2/raw-data/train/.
Traceback (most recent call last):
  File ""/home/ubuntu/tensorflow_models/models-master/inception/bazel-bin/inception/download_and_preprocess_imagenet.runfiles/inception/inception/data/build_imagenet_data.py"", line 704, in <module>
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 30, in run
  File ""/home/ubuntu/tensorflow_models/models-master/inception/bazel-bin/inception/download_and_preprocess_imagenet.runfiles/inception/inception/data/build_imagenet_data.py"", line 700, in main
  File ""/home/ubuntu/tensorflow_models/models-master/inception/bazel-bin/inception/download_and_preprocess_imagenet.runfiles/inception/inception/data/build_imagenet_data.py"", line 597, in _process_dataset
  File ""/home/ubuntu/tensorflow_models/models-master/inception/bazel-bin/inception/download_and_preprocess_imagenet.runfiles/inception/inception/data/build_imagenet_data.py"", line 513, in _find_image_files
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/lib/io/file_io.py"", line 251, in get_matching_files
  File ""/usr/lib/python2.7/contextlib.py"", line 24, in __exit__
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/errors.py"", line 463, in raise_exception_on_not_ok_status
tensorflow.python.framework.errors.ResourceExhaustedError: /imagenet2/raw-data/train/n00006484
````

I am not sure what resource its exhausting. I am running it on CPU with 8 cores and 30GB of RAM. I kept monitoring the process using top and both memory and CPU levels were low during the process until the crash.

Does generating TF-Records require GPU?

Regards
",redserpent7,b'type:bug',2017-03-20T11:57:32Z,2017-05-09T23:28:09Z,,,,,,,
1221,Error in models/tutorials/rnn/translate/seq2seq_model.py,"I just use the[ Sequence-to-Sequence Models](https://github.com/tensorflow/models/blob/master/tutorials/rnn/translate/translate.py) to test the function Neural machine translation with tensorflow 1.0, but I alway get the following error 

> ValueError: Shape must be rank 2 but is rank 1 for 'translate_model/model_with_buckets/translate_model/sequence_loss/sequence_loss_by_example/sampled_softmax_loss/MatMul_1' (op: 'MatMul') with input shapes: [?], [?,500].

After exploring the code, I found there is a bug in the line 103 for [seq2seq_model.py](https://github.com/tensorflow/models/blob/master/tutorials/rnn/translate/seq2seq_model.py#L103), which define a customized loss function `sampled_loss`, and will be passed to the function [tf.contrib.legacy_seq2seq.model_with_buckets ](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/legacy_seq2seq/python/ops/seq2seq.py#L1139) in line [163](https://github.com/tensorflow/models/blob/master/tutorials/rnn/translate/seq2seq_model.py#L163) 
```
def sampled_loss(inputs, labels):
        labels = tf.reshape(labels, [-1, 1])
        # We need to compute the sampled_softmax_loss using 32bit floats to
        # avoid numerical instabilities.
        local_w_t = tf.cast(w_t, tf.float32)
        local_b = tf.cast(b, tf.float32)
        local_inputs = tf.cast(inputs, tf.float32)
        return tf.cast(
            tf.nn.sampled_softmax_loss(
                weights=local_w_t,
                biases=local_b,
                labels=labels,
                inputs=local_inputs,
                num_sampled=num_samples,
                num_classes=self.target_vocab_size),
            dtype)

....
self.outputs, self.losses = tf.contrib.legacy_seq2seq.model_with_buckets(
          self.encoder_inputs, self.decoder_inputs, targets,
          self.target_weights, buckets, lambda x, y: seq2seq_f(x, y, True),
          softmax_loss_function=softmax_loss_function)
...
```

The `sampled_loss` function will be called in [sequence_loss_by_example](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/legacy_seq2seq/python/ops/seq2seq.py#L1088)
```
  ...
   else:
        crossent = softmax_loss_function(target, logit)
      log_perp_list.append(crossent * weight)
  ....
```


But the the order of the parameters is not consistent with the definition of the function `sampled_loss` , which will cause the error that I mentioned before.

and If i change the order of the parameters in the definition `sampled_loss`,  the program will be ok

```
...
def sampled_loss(labels, inputs):
...
```
",david-liu,None,2017-03-20T11:44:34Z,2018-08-12T13:36:05Z,,,,,,,
1213,[Inception] 0-byte TF_Record files,"Hi,

I am trying to train imagenet from scratch. I have all original images available and I followed the documentation step-by-step. However, when I run download_and_preprocess_imagenet I get this output:

````
2017-03-19 14:47:32.641057 [thread 0]: Wrote 0 images to /imagenet2/train-00127-of-01024
2017-03-19 14:47:32.641226 [thread 6]: Wrote 0 images to /imagenet2/train-00892-of-01024
2017-03-19 14:47:32.641296 [thread 7]: Wrote 0 images to /imagenet2/train-00994-of-01024
2017-03-19 14:47:32.641428 [thread 5]: Wrote 0 images to /imagenet2/train-00766-of-01024
2017-03-19 14:47:32.641474 [thread 0]: Wrote 0 images to 0 shards.
2017-03-19 14:47:32.641542 [thread 4]: Wrote 0 images to /imagenet2/train-00634-of-01024
2017-03-19 14:47:32.641797 [thread 6]: Wrote 0 images to /imagenet2/train-00893-of-01024
2017-03-19 14:47:32.641883 [thread 4]: Wrote 0 images to /imagenet2/train-00635-of-01024
2017-03-19 14:47:32.641969 [thread 7]: Wrote 0 images to /imagenet2/train-00995-of-01024
2017-03-19 14:47:32.642150 [thread 5]: Wrote 0 images to /imagenet2/train-00767-of-01024
2017-03-19 14:47:32.642309 [thread 6]: Wrote 0 images to /imagenet2/train-00894-of-01024
2017-03-19 14:47:32.642365 [thread 4]: Wrote 0 images to /imagenet2/train-00636-of-01024
2017-03-19 14:47:32.642472 [thread 7]: Wrote 0 images to /imagenet2/train-00996-of-01024
2017-03-19 14:47:32.642543 [thread 5]: Wrote 0 images to 0 shards.
2017-03-19 14:47:32.642614 [thread 4]: Wrote 0 images to /imagenet2/train-00637-of-01024
2017-03-19 14:47:32.642821 [thread 4]: Wrote 0 images to /imagenet2/train-00638-of-01024
2017-03-19 14:47:32.642962 [thread 4]: Wrote 0 images to /imagenet2/train-00639-of-01024
2017-03-19 14:47:32.643050 [thread 6]: Wrote 0 images to /imagenet2/train-00895-of-01024
2017-03-19 14:47:32.643123 [thread 4]: Wrote 0 images to 0 shards.
2017-03-19 14:47:32.643188 [thread 7]: Wrote 0 images to /imagenet2/train-00997-of-01024
2017-03-19 14:47:32.643224 [thread 6]: Wrote 0 images to 0 shards.
2017-03-19 14:47:32.643409 [thread 7]: Wrote 0 images to /imagenet2/train-00998-of-01024
2017-03-19 14:47:32.643509 [thread 7]: Wrote 0 images to /imagenet2/train-00999-of-01024
2017-03-19 14:47:32.643602 [thread 7]: Wrote 0 images to /imagenet2/train-01000-of-01024
2017-03-19 14:47:32.643694 [thread 7]: Wrote 0 images to /imagenet2/train-01001-of-01024
2017-03-19 14:47:32.643788 [thread 7]: Wrote 0 images to /imagenet2/train-01002-of-01024
2017-03-19 14:47:32.643879 [thread 7]: Wrote 0 images to /imagenet2/train-01003-of-01024
2017-03-19 14:47:32.643969 [thread 7]: Wrote 0 images to /imagenet2/train-01004-of-01024
2017-03-19 14:47:32.644059 [thread 7]: Wrote 0 images to /imagenet2/train-01005-of-01024
2017-03-19 14:47:32.644148 [thread 7]: Wrote 0 images to /imagenet2/train-01006-of-01024
2017-03-19 14:47:32.644238 [thread 7]: Wrote 0 images to /imagenet2/train-01007-of-01024
2017-03-19 14:47:32.644338 [thread 7]: Wrote 0 images to /imagenet2/train-01008-of-01024
2017-03-19 14:47:32.644430 [thread 7]: Wrote 0 images to /imagenet2/train-01009-of-01024
2017-03-19 14:47:32.644519 [thread 7]: Wrote 0 images to /imagenet2/train-01010-of-01024
2017-03-19 14:47:32.644607 [thread 7]: Wrote 0 images to /imagenet2/train-01011-of-01024
2017-03-19 14:47:32.644694 [thread 7]: Wrote 0 images to /imagenet2/train-01012-of-01024
2017-03-19 14:47:32.644783 [thread 7]: Wrote 0 images to /imagenet2/train-01013-of-01024
2017-03-19 14:47:32.644871 [thread 7]: Wrote 0 images to /imagenet2/train-01014-of-01024
2017-03-19 14:47:32.644959 [thread 7]: Wrote 0 images to /imagenet2/train-01015-of-01024
2017-03-19 14:47:32.645049 [thread 7]: Wrote 0 images to /imagenet2/train-01016-of-01024
2017-03-19 14:47:32.645136 [thread 7]: Wrote 0 images to /imagenet2/train-01017-of-01024
2017-03-19 14:47:32.645225 [thread 7]: Wrote 0 images to /imagenet2/train-01018-of-01024
2017-03-19 14:47:32.645312 [thread 7]: Wrote 0 images to /imagenet2/train-01019-of-01024
2017-03-19 14:47:32.645402 [thread 7]: Wrote 0 images to /imagenet2/train-01020-of-01024
2017-03-19 14:47:32.645490 [thread 7]: Wrote 0 images to /imagenet2/train-01021-of-01024
2017-03-19 14:47:32.645578 [thread 7]: Wrote 0 images to /imagenet2/train-01022-of-01024
2017-03-19 14:47:32.645670 [thread 7]: Wrote 0 images to /imagenet2/train-01023-of-01024
````

And when I go and check my data directory I see all TF-Record files are 0-bytes.

No exceptions are thrown and no warnings. not sure what is wrong here.

I checked all classes folders and they all contain the jpg images.",redserpent7,b'stat:awaiting response type:bug type:build/install type:support',2017-03-19T14:51:10Z,2018-02-22T20:01:26Z,,,,,,,
1201,"[syntaxnet, dragnn] bazel test ... failed in OS X","- environment
```
OS X : 10.11.3(15D21) EL Capitan
syntaxnet : e8464d33d363c6f8e90a29c08e5af11ef01be7a1 ( 2017. 3. 17 )
python : 2.7.10
bazel : 0.4.3
swig : 3.0.7
protobuf==3.2.0
numpy==1.12.0
mock==2.0.0
asciitree==0.3.3
pygraphviz==1.3.1

tensorflow
./configure
  : default setting
  : no OpenGL, no GPU, no Clould, no JIT
  : python site-packages == /Users/username/Library/Python/2.7/lib/python/site-packages
```

- i followed the instructions described in https://github.com/tensorflow/models/tree/master/syntaxnet
and got errors. 
```
$ bazel test ...
....
//syntaxnet:tagger_transitions_test                                      PASSED in 0.0s
//syntaxnet/util:check_test                                              PASSED in 3.1s
//syntaxnet/util:registry_test                                           PASSED in 3.4s
//syntaxnet:whole_sentence_features_test                                 PASSED in 0.0s
//util/utf8:unicodetext_unittest                                         PASSED in 0.0s
//dragnn/components/syntaxnet:syntaxnet_component_test                   FAILED in 1.1s
  /private/var/tmp/_bazel_donghwon/b775d9ba23a609707f1d52289dfe1bde/execroot/syntaxnet/bazel-out/local-opt/testlogs/dragnn/components/syntaxnet/syntaxnet_component_test/test.log
//dragnn/python:bulk_component_test                                      FAILED in 4.1s
  /private/var/tmp/_bazel_donghwon/b775d9ba23a609707f1d52289dfe1bde/execroot/syntaxnet/bazel-out/local-opt/testlogs/dragnn/python/bulk_component_test/test.log
//dragnn/python:graph_builder_test                                       FAILED in 9.5s
  /private/var/tmp/_bazel_donghwon/b775d9ba23a609707f1d52289dfe1bde/execroot/syntaxnet/bazel-out/local-opt/testlogs/dragnn/python/graph_builder_test/test.log
//dragnn/python:lexicon_test                                             FAILED in 3.7s
  /private/var/tmp/_bazel_donghwon/b775d9ba23a609707f1d52289dfe1bde/execroot/syntaxnet/bazel-out/local-opt/testlogs/dragnn/python/lexicon_test/test.log
//dragnn/python:sentence_io_test                                         FAILED in 3.6s
  /private/var/tmp/_bazel_donghwon/b775d9ba23a609707f1d52289dfe1bde/execroot/syntaxnet/bazel-out/local-opt/testlogs/dragnn/python/sentence_io_test/test.log
//dragnn/python:spec_builder_test                                        FAILED in 3.4s
  /private/var/tmp/_bazel_donghwon/b775d9ba23a609707f1d52289dfe1bde/execroot/syntaxnet/bazel-out/local-opt/testlogs/dragnn/python/spec_builder_test/test.log
//examples/dragnn:test_run_all_tutorials                                 FAILED in 0.0s
  /private/var/tmp/_bazel_donghwon/b775d9ba23a609707f1d52289dfe1bde/execroot/syntaxnet/bazel-out/local-opt/testlogs/examples/dragnn/test_run_all_tutorials/test.log
//syntaxnet:beam_reader_ops_test                                         FAILED in 4.2s
  /private/var/tmp/_bazel_donghwon/b775d9ba23a609707f1d52289dfe1bde/execroot/syntaxnet/bazel-out/local-opt/testlogs/syntaxnet/beam_reader_ops_test/test.log
//syntaxnet:graph_builder_test                                           FAILED in 3.8s
  /private/var/tmp/_bazel_donghwon/b775d9ba23a609707f1d52289dfe1bde/execroot/syntaxnet/bazel-out/local-opt/testlogs/syntaxnet/graph_builder_test/test.log
//syntaxnet:lexicon_builder_test                                         FAILED in 3.8s
  /private/var/tmp/_bazel_donghwon/b775d9ba23a609707f1d52289dfe1bde/execroot/syntaxnet/bazel-out/local-opt/testlogs/syntaxnet/lexicon_builder_test/test.log
//syntaxnet:parser_trainer_test                                          FAILED in 4.0s
  /private/var/tmp/_bazel_donghwon/b775d9ba23a609707f1d52289dfe1bde/execroot/syntaxnet/bazel-out/local-opt/testlogs/syntaxnet/parser_trainer_test/test.log
//syntaxnet:reader_ops_test                                              FAILED in 4.3s
  /private/var/tmp/_bazel_donghwon/b775d9ba23a609707f1d52289dfe1bde/execroot/syntaxnet/bazel-out/local-opt/testlogs/syntaxnet/reader_ops_test/test.log
//syntaxnet:text_formats_test                                            FAILED in 4.3s
  /private/var/tmp/_bazel_donghwon/b775d9ba23a609707f1d52289dfe1bde/execroot/syntaxnet/bazel-out/local-opt/testlogs/syntaxnet/text_formats_test/test.log

Executed 50 out of 50 tests: 37 tests pass and 13 fail locally.
There were tests whose specified size is too big. Use the --test_verbose_timeout_warnings command line option to see which ones these are.
```

- for example
```
$ vi /private/var/tmp/_bazel_donghwon/b775d9ba23a609707f1d52289dfe1bde/execroot/syntaxnet/bazel-out/local-opt/testlogs/dragnn/components/syntaxnet/syntaxnet_component_test/test.log
...
dragnn/components/syntaxnet/syntaxnet_component_test.cc:849: Failure
      Expected: expected_ids
      Which is: { 12, 7, 12, 7, 12, 7, 12, 7, 12, 7, 12, 7 }
To be equal to: ids
      Which is: { 7, 50, 12, 7, 12, 7, 7, 50, 12, 7, 12, 7 }
[  FAILED  ] SyntaxNetComponentTest.ExportsFixedFeatures (2 ms)
...
dragnn/components/syntaxnet/syntaxnet_component_test.cc:1027: Failure
      Expected: link_features.at(0).feature_value()
      Which is: 1
To be equal to: -1
dragnn/components/syntaxnet/syntaxnet_component_test.cc:1031: Failure
      Expected: link_features.at(1).feature_value()
      Which is: 0
To be equal to: -2
dragnn/components/syntaxnet/syntaxnet_component_test.cc:1052: Failure
      Expected: link_features.at(6).feature_value()
      Which is: 1
To be equal to: -1
dragnn/components/syntaxnet/syntaxnet_component_test.cc:1056: Failure
      Expected: link_features.at(7).feature_value()
      Which is: 0
To be equal to: -2
[  FAILED  ] SyntaxNetComponentTest.ExportsRawLinkFeatures (2 ms)
...

$ vi /private/var/tmp/_bazel_donghwon/b775d9ba23a609707f1d52289dfe1bde/execroot/syntaxnet/bazel-out/local-opt/testlogs/dragnn/python/lexicon_test/test.log
...
ERROR: testBuildLexicon (__main__.LexiconTest)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""/private/var/tmp/_bazel_donghwon/b775d9ba23a609707f1d52289dfe1bde/execroot/syntaxnet/bazel-out/local-opt/bin/dragnn/python/lexicon_test.runfiles/__main__/dragnn/python/lexicon_test.py"", line 75, in testBuildLexicon
    lexicon.build_lexicon(lexicon_output_path, empty_input_path)
  File ""/private/var/tmp/_bazel_donghwon/b775d9ba23a609707f1d52289dfe1bde/execroot/syntaxnet/bazel-out/local-opt/bin/dragnn/python/lexicon_test.runfiles/__main__/dragnn/python/lexicon.py"", line 73, in build_lexicon
    task_context_str=str(context), corpus_name='corpus', **kwargs))
  File ""/private/var/tmp/_bazel_donghwon/b775d9ba23a609707f1d52289dfe1bde/execroot/syntaxnet/bazel-out/local-opt/bin/dragnn/python/lexicon_test.runfiles/__main__/syntaxnet/ops/gen_parser_ops.py"", line 444, in lexicon_builder
    name=name)
  File ""/private/var/tmp/_bazel_donghwon/b775d9ba23a609707f1d52289dfe1bde/execroot/syntaxnet/bazel-out/local-opt/bin/dragnn/python/lexicon_test.runfiles/org_tensorflow/tensorflow/python/framework/op_def_library.py"", line 768, in apply_op
    op_def=op_def)
  File ""/private/var/tmp/_bazel_donghwon/b775d9ba23a609707f1d52289dfe1bde/execroot/syntaxnet/bazel-out/local-opt/bin/dragnn/python/lexicon_test.runfiles/org_tensorflow/tensorflow/python/framework/ops.py"", line 2338, in create_op
    set_shapes_for_outputs(ret)
  File ""/private/var/tmp/_bazel_donghwon/b775d9ba23a609707f1d52289dfe1bde/execroot/syntaxnet/bazel-out/local-opt/bin/dragnn/python/lexicon_test.runfiles/org_tensorflow/tensorflow/python/framework/ops.py"", line 1719, in set_shapes_for_outputs
    shapes = shape_func(op)
  File ""/private/var/tmp/_bazel_donghwon/b775d9ba23a609707f1d52289dfe1bde/execroot/syntaxnet/bazel-out/local-opt/bin/dragnn/python/lexicon_test.runfiles/org_tensorflow/tensorflow/python/framework/ops.py"", line 1664, in call_without_requiring
    return call_cpp_shape_fn(op, require_shape_fn=False)
  File ""/private/var/tmp/_bazel_donghwon/b775d9ba23a609707f1d52289dfe1bde/execroot/syntaxnet/bazel-out/local-opt/bin/dragnn/python/lexicon_test.runfiles/org_tensorflow/tensorflow/python/framework/common_shapes.py"", line 610, in call_cpp_shape_fn
    debug_python_shape_fn, require_shape_fn)
  File ""/private/var/tmp/_bazel_donghwon/b775d9ba23a609707f1d52289dfe1bde/execroot/syntaxnet/bazel-out/local-opt/bin/dragnn/python/lexicon_test.runfiles/org_tensorflow/tensorflow/python/framework/common_shapes.py"", line 671, in _call_cpp_shape_fn_impl
    input_tensors_as_shapes, status)
  File ""/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/contextlib.py"", line 24, in __exit__
    self.gen.next()
  File ""/private/var/tmp/_bazel_donghwon/b775d9ba23a609707f1d52289dfe1bde/execroot/syntaxnet/bazel-out/local-opt/bin/dragnn/python/lexicon_test.runfiles/org_tensorflow/tensorflow/python/framework/errors_impl.py"", line 466, in raise_exception_on_not_ok_status
    pywrap_tensorflow.TF_GetCode(status))
NotFoundError: Op type not registered 'LexiconBuilder'
...
```

- any suggestion to fix ?
",dsindex,b'stat:awaiting model gardener',2017-03-18T05:59:31Z,2017-03-27T01:39:12Z,,,,,,,
1176,SyntaxNet and Bazel Tests Error [Ubuntu] fatal error: Python.h,"Looks like variation of the another issue https://github.com/tensorflow/models/issues/80
but with other output.
After installing the correct deps (protobuf, swig, bazel, asciitree), tried running bazel test syntaxnet/... util/utf8/..., but after a lot of notes and warnings, the final output I got this:
```

root@engine:/var/lib/postgresql/models/syntaxnet# bazel test syntaxnet/... util/utf8/...
WARNING: /root/.cache/bazel/_bazel_root/1553b8a3c109a70f0eed3dac69444e1d/external/org_tensorflow/tensorflow/workspace.bzl:63:5: tf_repo_name was specified to tf_workspace but is no longer used and will be removed in the future.
INFO: Found 68 targets and 17 test targets...
ERROR: /root/.cache/bazel/_bazel_root/1553b8a3c109a70f0eed3dac69444e1d/external/protobuf/BUILD:579:1: C++ compilation of rule '@protobuf//:internal/_api_implementation.so' failed: gcc failed: error executing command /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -B/usr/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG ... (remaining 43 argument(s) skipped): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.
external/protobuf/python/google/protobuf/internal/api_implementation.cc:31:20: fatal error: Python.h: No such file or directory
 #include <Python.h>
                    ^
compilation terminated.
INFO: Elapsed time: 8.619s, Critical Path: 4.28s
//syntaxnet:arc_standard_transitions_test                             NO STATUS
//syntaxnet:beam_reader_ops_test                                      NO STATUS
//syntaxnet:binary_segment_state_test                                 NO STATUS
//syntaxnet:binary_segment_transitions_test                           NO STATUS
//syntaxnet:char_properties_test                                      NO STATUS
//syntaxnet:graph_builder_test                                        NO STATUS
//syntaxnet:lexicon_builder_test                                      NO STATUS
//syntaxnet:morphology_label_set_test                                 NO STATUS
//syntaxnet:parser_features_test                                      NO STATUS
//syntaxnet:parser_trainer_test                                       NO STATUS
//syntaxnet:reader_ops_test                                           NO STATUS
//syntaxnet:segmenter_utils_test                                      NO STATUS
//syntaxnet:sentence_features_test                                    NO STATUS
//syntaxnet:shared_store_test                                         NO STATUS
//syntaxnet:tagger_transitions_test                                   NO STATUS
//syntaxnet:text_formats_test                                         NO STATUS
//util/utf8:unicodetext_unittest                                      NO STATUS

Executed 0 out of 17 tests: 17 were skipped.

```

Versions:
OS: Ubuntu 14.04
swig: latest
protobuf: 3.2.0 (tried also 3.0.0b2 - no luck)
numpy: 1.12.0
python: 2.7.6
asciitree: latest
bazel: 0.4.4

Also i am not sure should i install via `pip` tensorflow or not? Note when installing TF version 1 (new 2017) it upgrades protobuf to 3.2.0 ",GraphGrailAi,None,2017-03-15T12:47:47Z,2017-03-15T19:19:40Z,,,,,,,
1126,when i use tensorboard in tf1.0 there are SyntaxError: invalid syntax,"when i fine this inception3 model and use tensorboard in tf1.0 all have syntaxerror invalid syntax .

DATASET_DIR=/home/cy/data/flowers
TRAIN_DIR=./flowers-models/inception_v3
CHECKPOINT_PATH=./pretrainmodel/inception_v3.ckpt
python3 train_image_classifier.py \
    --train_dir=${TRAIN_DIR} \
    --dataset_dir=${DATASET_DIR} \
    --dataset_name=flowers \
    --dataset_split_name=train \
    --model_name=inception_v3 \
    --checkpoint_path=${CHECKPOINT_PATH} \
    --checkpoint_exclude_scopes=InceptionV3/Logits,InceptionV3/AuxLogits/Logits \
    --trainable_scopes=InceptionV3/Logits,InceptionV3/AuxLogits/Logits

cy@cy:~/PycharmProjects/models-master/slim/flowers-models$ tensorboard --logdir=./inception_v3
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcudnn.so.5 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.so.8.0 locally
Traceback (most recent call last):
  File ""/usr/local/bin/tensorboard"", line 7, in <module>
    from tensorflow.tensorboard.tensorboard import main
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/tensorboard/tensorboard.py"", line 34, in <module>
    from tensorflow.tensorboard.backend import server
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/tensorboard/backend/server.py"", line 38, in <module>
    from tensorflow.tensorboard.plugins.projector import plugin as projector_plugin
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/tensorboard/plugins/projector/plugin.py"", line 27, in <module>
    from tensorflow.contrib.tensorboard.plugins.projector import PROJECTOR_FILENAME
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/__init__.py"", line 29, in <module>
    from tensorflow.contrib import factorization
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/factorization/__init__.py"", line 24, in <module>
    from tensorflow.contrib.factorization.python.ops.gmm import *
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/factorization/python/ops/gmm.py"", line 32, in <module>
    from tensorflow.contrib.learn.python.learn import graph_actions
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/__init__.py"", line 83, in <module>
    from tensorflow.contrib.learn.python.learn import *
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/__init__.py"", line 23, in <module>
    from tensorflow.contrib.learn.python.learn import *
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/__init__.py"", line 25, in <module>
    from tensorflow.contrib.learn.python.learn import estimators
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/estimators/__init__.py"", line 310, in <module>
    from tensorflow.contrib.learn.python.learn.estimators.dnn import DNNClassifier
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/estimators/dnn.py"", line 29, in <module>
    from tensorflow.contrib.learn.python.learn.estimators import dnn_linear_combined
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/estimators/dnn_linear_combined.py"", line 33, in <module>
    from tensorflow.contrib.learn.python.learn.estimators import estimator
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py"", line 51, in <module>
    from tensorflow.contrib.learn.python.learn.learn_io import data_feeder
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/learn_io/__init__.py"", line 21, in <module>
    from tensorflow.contrib.learn.python.learn.learn_io.dask_io import extract_dask_data
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/learn_io/dask_io.py"", line 26, in <module>
    import dask.dataframe as dd
  File ""/home/cy/.local/lib/python3.5/site-packages/dask/dataframe/__init__.py"", line 3, in <module>
    from .core import (DataFrame, Series, Index, _Frame, map_partitions,
  File ""/home/cy/.local/lib/python3.5/site-packages/dask/dataframe/core.py"", line 11, in <module>
    import pandas as pd
  File ""/home/cy/.local/lib/python3.5/site-packages/pandas/__init__.py"", line 22, in <module>
    from pandas.compat.numpy import *
  File ""/home/cy/.local/lib/python3.5/site-packages/pandas/compat/__init__.py"", line 357, in <module>
    from dateutil import parser as _date_parser
  File ""/home/cy/.local/lib/python3.5/site-packages/dateutil/parser.py"", line 158
    l.append(""%s=%s"" % (attr, `value`))
                              ^
SyntaxError: invalid syntax
",andongchen,b'type:bug',2017-03-08T06:33:32Z,2017-07-18T03:20:03Z,,,,,,,
1116,Build fail with error 'google/protobuf/stubs/common.h' file not found,"https://github.com/tensorflow/models/tree/master/syntaxnet
 
The following command threw an error on Mac OS X during build. 

bazel test --linkopt=-headerpad_max_install_names 
syntaxnet/... util/utf8/...

ERROR: /private/var/tmp/_bazel_coreychong/12e1cac900a5b57469553695a912bfcb/external/org_tensorflow/tensorflow/contrib/ffmpeg/BUILD:36:1: C++ compilation of rule '@org_tensorflow//tensorflow/contrib/ffmpeg:encode_audio_op_cc' failed: cc_wrapper.sh failed: error executing command external/local_config_cc/cc_wrapper.sh -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -Wall -Wthread-safety -Wself-assign -fcolor-diagnostics -fno-omit-frame-pointer -g0 -O2 -DNDEBUG ... (remaining 47 argument(s) skipped): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.
In file included from external/org_tensorflow/tensorflow/contrib/ffmpeg/encode_audio_op.cc:18:
In file included from external/org_tensorflow/tensorflow/contrib/ffmpeg/ffmpeg_lib.h:22:
In file included from external/org_tensorflow/tensorflow/core/lib/core/status.h:22:
bazel-out/host/genfiles/external/org_tensorflow/tensorflow/core/lib/core/error_codes.pb.h:9:10: fatal error: 'google/protobuf/stubs/common.h' file not found
#include <google/protobuf/stubs/common.h>
         ^
1 error generated.
INFO: Elapsed time: 7.281s, Critical Path: 4.35s
//syntaxnet:arc_standard_transitions_test                             NO STATUS
//syntaxnet:binary_segment_state_test                                 NO STATUS
//syntaxnet:binary_segment_transitions_test                           NO STATUS
//syntaxnet:char_properties_test                                      NO STATUS
//syntaxnet:graph_builder_test                                        NO STATUS
//syntaxnet:lexicon_builder_test                                      NO STATUS
//syntaxnet:morphology_label_set_test                                 NO STATUS
//syntaxnet:parser_features_test                                      NO STATUS
//syntaxnet:parser_trainer_test                                       NO STATUS
//syntaxnet:reader_ops_test                                           NO STATUS
//syntaxnet:segmenter_utils_test                                      NO STATUS
//syntaxnet:sentence_features_test                                    NO STATUS
//syntaxnet:shared_store_test                                         NO STATUS
//syntaxnet:tagger_transitions_test                                   NO STATUS
//syntaxnet:text_formats_test                                         NO STATUS
//util/utf8:unicodetext_unittest                                      NO STATUS

Executed 0 out of 17 tests: 1 fails to build and 16 were skipped.

Protobuf version ==3.0.0b2 followed setup instructions and Bazel version 0.4.3.
Anyone encountered this error before?  ",coreych,None,2017-03-05T15:12:27Z,2018-05-30T15:17:12Z,,,,,,,
1084,cifar10 example fails with asegmentation fault,"cifar10 example fails with a segmentation fault as below.

    ubuntu@ubuntu:~/work/tensorflow/models2/tutorials/image/cifar10$ python cifar10_train.py --max_steps=10 --batch_size=4
    I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.8.0 locally
    I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcudnn.so.5 locally
    I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.8.0 locally
    I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcuda.so.1 locally
    I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.so.8.0 locally
    Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
    W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE3 instructions, but these are available on your machine and could speed up CPU computations.
    W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
    W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
    W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
    W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
    W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
    I tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with properties:
    name: GeForce GTX TITAN X
    major: 5 minor: 2 memoryClockRate (GHz) 1.076
    pciBusID 0000:03:00.0
    Total memory: 11.92GiB
    Free memory: 11.81GiB
    I tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0
    I tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0:   Y
    I tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:03:00.0)
    2017-03-01 10:40:00.056918: step 0, loss = 4.68 (0.4 examples/sec; 10.139 sec/batch)
    Segmentation fault (core dumped)

system info:
ubuntu 14.04.2
tensorflow-gpu 1.0.0 installed using pip
cuda 8.0
cudnn 5.1.5

I am pretty new to tensorflow and python. Can you advise me how to fix or debug this?
",namhyungk,None,2017-03-01T01:49:32Z,2017-03-01T05:08:21Z,,,,,,,
1072,Shape mismatch between predictions and labels in ResNet_v1_50,"## slim

I am trying to run the pretrained model for resnet_v1_50. 

It throws an error while defining metrics. Says there is shape mismatch between predictions and labels.

Here is the stack trace

INFO:tensorflow:Scale of 0 disables regularizer.
Traceback (most recent call last):
  File ""eval_image_classifier.py"", line 191, in <module>
    tf.app.run()
  File ""/home/sk6829/Work/TensorFlowCuda1/lib/python2.7/site-packages/tensorflow/python/platform/app.py"", line 44, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""eval_image_classifier.py"", line 155, in main
    'Accuracy': slim.metrics.streaming_accuracy(predictions, labels),
  File ""/home/sk6829/Work/TensorFlowCuda1/lib/python2.7/site-packages/tensorflow/contrib/metrics/python/ops/metric_ops.py"", line 490, in streaming_accuracy
    updates_collections=updates_collections, name=name)
  File ""/home/sk6829/Work/TensorFlowCuda1/lib/python2.7/site-packages/tensorflow/python/ops/metrics_impl.py"", line 326, in accuracy
    labels, predictions, weights=weights)
  File ""/home/sk6829/Work/TensorFlowCuda1/lib/python2.7/site-packages/tensorflow/python/ops/metrics_impl.py"", line 75, in _remove_squeezable_dimensions
    predictions.get_shape().assert_is_compatible_with(labels.get_shape())
  File ""/home/sk6829/Work/TensorFlowCuda1/lib/python2.7/site-packages/tensorflow/python/framework/tensor_shape.py"", line 756, in assert_is_compatible_with
    raise ValueError(""Shapes %s and %s are incompatible"" % (self, other))
ValueError: Shapes (100, 1, 10) and (100,) are incompatible


",salilkapur,b'type:bug',2017-02-25T23:07:04Z,2017-03-23T22:51:34Z,,,,,,,
1039,ptb example not working,"## models/tutorials/rnn/ptb/

When attempting to run the tut, there is the following error:

line 117, in ptb_producer
    [batch_size, (i + 1) * num_steps])
TypeError: strided_slice() missing 1 required positional argument: 'strides'

I'm running with python3, and adding strides=None does not help. Looks like this function cannot work without a stride specified.",nebgru,b'stat:awaiting response type:bug',2017-02-19T21:22:44Z,2017-02-20T11:54:48Z,,,,,,,
1038,inception_resnet_v2 fails to instantiate under Tensorflow 1.0,"The tf-slim implementation of inception-resnet-v2 (https://github.com/tensorflow/models/blob/master/slim/nets/inception_resnet_v2.py) fails to instantiate for me under TF 1.0.   I was able to fix this by installing TF 0.12.  I'm running tensorflow-gpu (both versions) under Ubuntu Server 16.04, using python3.

Apologies, since at the time I didn't think to save off the error message when I encountered it, and I've long since closed the SSH window and lost the buffer.  However, the last line of the error messages was identical to [this recent post](https://github.com/tensorflow/models/issues/987):

`TypeError: Expected int32, got list containing Tensors of type '_Message' instead.`

...which occurred in response to the following call:

`self.logits, self.end_points = inception_resnet_v2(scaled_input_tensor, is_training=False)`

If it can't be reproduced, I can install TF-1.0 again to catch the error trace.
",admcl,b'stat:awaiting response type:bug',2017-02-19T15:38:18Z,2017-02-21T17:07:36Z,,,,,,,
1037,im2txt: Why is the initial learning rate so high (2.0)?,Is it a bug or is it expected that high? https://github.com/tensorflow/models/blob/master/im2txt/im2txt/configuration.py#L93,danieljl,b'stat:awaiting model gardener type:bug',2017-02-19T03:56:24Z,2017-07-06T03:03:29Z,,,,,,,
1036,when i train resnet the program stuck,"python3.5 tf version 1.0 the program is stuck here
=========================Options=============================
-max_depth                  10000
-min_bytes                  0
-min_micros                 0
-min_params                 0
-min_float_ops              1
-device_regexes             .*
-order_by                   float_ops
-account_type_regexes       .*
-start_name_regexes         .*
-trim_name_regexes          
-show_name_regexes          .*
-hide_name_regexes          
-account_displayed_op_only  true
-select                     float_ops
-viz                        false
-dump_to_file               

==================Model Analysis Report======================
_TFProfRoot (0/17.63b flops)
  unit_2_1/sub2/conv2/Conv2D (603.98m/603.98m flops)
  unit_3_4/sub2/conv2/Conv2D (603.98m/603.98m flops)
  unit_3_4/sub1/conv1/Conv2D (603.98m/603.98m flops)
  unit_3_3/sub2/conv2/Conv2D (603.98m/603.98m flops)
  unit_3_3/sub1/conv1/Conv2D (603.98m/603.98m flops)
  unit_3_2/sub2/conv2/Conv2D (603.98m/603.98m flops)
  unit_3_2/sub1/conv1/Conv2D (603.98m/603.98m flops)
  unit_3_1/sub2/conv2/Conv2D (603.98m/603.98m flops)
  unit_3_1/sub1/conv1/Conv2D (603.98m/603.98m flops)
  unit_3_0/sub2/conv2/Conv2D (603.98m/603.98m flops)
  unit_2_4/sub2/conv2/Conv2D (603.98m/603.98m flops)
  unit_2_4/sub1/conv1/Conv2D (603.98m/603.98m flops)
  unit_2_3/sub2/conv2/Conv2D (603.98m/603.98m flops)
  unit_2_3/sub1/conv1/Conv2D (603.98m/603.98m flops)
  unit_2_2/sub2/conv2/Conv2D (603.98m/603.98m flops)
  unit_2_2/sub1/conv1/Conv2D (603.98m/603.98m flops)
  unit_2_1/sub1/conv1/Conv2D (603.98m/603.98m flops)
  unit_2_0/sub2/conv2/Conv2D (603.98m/603.98m flops)
  unit_1_0/sub1/conv1/Conv2D (603.98m/603.98m flops)
  unit_1_4/sub2/conv2/Conv2D (603.98m/603.98m flops)
  unit_1_4/sub1/conv1/Conv2D (603.98m/603.98m flops)
  unit_1_3/sub2/conv2/Conv2D (603.98m/603.98m flops)
  unit_1_3/sub1/conv1/Conv2D (603.98m/603.98m flops)
  unit_1_0/sub2/conv2/Conv2D (603.98m/603.98m flops)
  unit_1_2/sub2/conv2/Conv2D (603.98m/603.98m flops)
  unit_1_2/sub1/conv1/Conv2D (603.98m/603.98m flops)
  unit_1_1/sub2/conv2/Conv2D (603.98m/603.98m flops)
  unit_1_1/sub1/conv1/Conv2D (603.98m/603.98m flops)
  unit_3_0/sub1/conv1/Conv2D (301.99m/301.99m flops)
  unit_2_0/sub1/conv1/Conv2D (301.99m/301.99m flops)
  init/init_conv/Conv2D (113.25m/113.25m flops)
  logit/xw_plus_b (1.28k/165.12k flops)
    logit/xw_plus_b/MatMul (163.84k/163.84k flops)
  gradients/logit/xw_plus_b/MatMul_grad/MatMul_1 (163.84k/163.84k flops)
  gradients/logit/xw_plus_b/MatMul_grad/MatMul (163.84k/163.84k flops)

======================End of Report==========================
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE3 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:910] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
I tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with properties: 
name: GeForce GTX 1060 6GB
major: 6 minor: 1 memoryClockRate (GHz) 1.7845
pciBusID 0000:01:00.0
Total memory: 5.93GiB
Free memory: 5.12GiB
I tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0:   Y 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 6GB, pci bus id: 0000:01:00.0)


",andongchen,b'stat:awaiting response type:bug',2017-02-19T02:55:29Z,2017-03-11T02:43:56Z,,,,,,,
1030,No biases in inception_v4 checkpoint file,"Hi I'm trying to use the inception_v4 code and checkpoint file as a starting point for my model. I'm not using the slim scripts directly but am importing the inception network and using 

slim.assign_from_checkpoint_fn(
      model_path + ""inception_v4.ckpt"",
      weights,
      ignore_missing_vars=True)

Where weights are the network weights minus all the meta weights needed for adam optimizer. I'm getting a lot of:

WARNING:tensorflow:Variable InceptionV4/Mixed_6f/Branch_1/Conv2d_0a_1x1/biases missing in checkpoint

It's only for the biases. After inspecting the checkpoint file manually with tf.train.NewCheckpointReader I see that there aren't in fact any bias variables saved in the checkpoint file. Is this on purpose or am I missing something? Why would nets.inception_v4.inception_v4 create a network with biases that aren't saved in the checkpoint file. Any help appreciated!",lucaswiser,b'stat:community support type:bug',2017-02-17T23:04:07Z,2017-07-21T07:54:39Z,,,,,,,
1024,Computer Vision sample and tutorials don't work. These are official samples and need more attention.,"I'm trying to run tutorial sample and I get tons of errors

imagenet doesn't work, classify sample that uses pretrained imagenet doesn't work. 
mnist doesn't work

A lot of code outdated and not usable on current version of Tensorflow without adjustments.
The official samples are important for new users that are trying to learn Tensorflow It's bad that most of the code cannot be executed",AndreaFar,b'stat:awaiting response type:bug',2017-02-16T15:32:35Z,2017-03-03T23:41:05Z,,,,,,,
1022,TypeError: zeros_initializer() missing 1 required positional argument: 'shape' ,"inception model

What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?

None yet

Environment info

Operating System: ubuntu 14.04
python 3.4.3

If installed from binary pip package, provide:

A link to the pip package you installed: pip 7.1.2

The output from python -c ""import tensorflow; print(tensorflow.__version__)"".
0.12.1
If installed from source, provide

The commit hash (git rev-parse HEAD)

The output of bazel version
Build label: 0.4.3

If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)

What other attempted solutions have you tried?

Logs or other output that would be helpful

(If logs are large, please upload as attachment or provide link).


`Traceback (most recent call last): File ""/home/raj/FYP/FP4/models/inception/bazel-bin/inception/crops_train.runfiles/inception/inception/crops_train.py"", line 41, in <module> tf.app.run() File ""/home/raj/FYP/FP4/lib/python3.4/site-packages/tensorflow/python/platform/app.py"", line 43, in run sys.exit(main(sys.argv[:1] + flags_passthrough)) File ""/home/raj/FYP/FP4/models/inception/bazel-bin/inception/crops_train.runfiles/inception/inception/crops_train.py"", line 37, in main inception_train.train(dataset) File ""/home/raj/FYP/FP4/models/inception/bazel-bin/inception/crops_train.runfiles/inception/inception/inception_train.py"", line 241, in train scope, reuse_variables) File ""/home/raj/FYP/FP4/models/inception/bazel-bin/inception/crops_train.runfiles/inception/inception/inception_train.py"", line 109, in _tower_loss scope=scope) File ""/home/raj/FYP/FP4/models/inception/bazel-bin/inception/crops_train.runfiles/inception/inception/inception_model.py"", line 87, in inference scope=scope) File ""/home/raj/FYP/FP4/models/inception/bazel-bin/inception/crops_train.runfiles/inception/inception/slim/inception_model.py"", line 87, in inception_v3 scope='conv0') File ""/home/raj/FYP/FP4/models/inception/bazel-bin/inception/crops_train.runfiles/inception/inception/slim/scopes.py"", line 155, in func_with_args return func(*args, **current_args) File ""/home/raj/FYP/FP4/models/inception/bazel-bin/inception/crops_train.runfiles/inception/inception/slim/ops.py"", line 234, in conv2d outputs = batch_norm(conv, **batch_norm_params) File ""/home/raj/FYP/FP4/models/inception/bazel-bin/inception/crops_train.runfiles/inception/inception/slim/scopes.py"", line 155, in func_with_args return func(*args, **current_args) File ""/home/raj/FYP/FP4/models/inception/bazel-bin/inception/crops_train.runfiles/inception/inception/slim/ops.py"", line 88, in batch_norm initializer=tf.zeros_initializer(), TypeError: zeros_initializer() missing 1 required positional argument: 'shape'`

Working upon crops dataset with 38 classes , created tfrecords as asked of training and validation data. jpg files resized to 299x299. using flowers_train and flowers_data with edited num_examples and num_classes.Even the flowes dataset gave same error upon training.",rajmiglani,b'stat:awaiting response type:bug',2017-02-16T08:07:37Z,2017-03-19T06:16:08Z,,,,,,,
1021,Issue during debug of tensorflow,"
Hello,
I'm pretty new to tensorflow and python. If I try to run syntaxnet by command line it works well, but I have an issue when I try to debug it step by step with Eclipse or Spyder. I had same error: an issue on load a library (parser_ops.so). Someone should help me to understand what is the issue? 
I attach here the error log (generated by Spyder)

  File ""<ipython-input-2-c92123615836>"", line 1, in <module>
    debugfile('/home/erber/models/syntaxnet/bazel-bin/syntaxnet/parser_eval.runfiles/__main__/syntaxnet/parser_eval.py', wdir='/home/erber/models/syntaxnet/bazel-bin/syntaxnet/parser_eval.runfiles/__main__/syntaxnet')

  File ""/usr/lib/python2.7/dist-packages/spyderlib/widgets/externalshell/sitecustomize.py"", line 719, in debugfile
    debugger.run(""runfile(%r, args=%r, wdir=%r)"" % (filename, args, wdir))

  File ""/usr/lib/python2.7/bdb.py"", line 400, in run
    exec cmd in globals, locals

  File ""<string>"", line 1, in <module>

  File ""/usr/lib/python2.7/dist-packages/spyderlib/widgets/externalshell/sitecustomize.py"", line 699, in runfile
    execfile(filename, namespace)

  File ""/usr/lib/python2.7/dist-packages/spyderlib/widgets/externalshell/sitecustomize.py"", line 81, in execfile
    builtins.execfile(filename, *where)

  File ""/home/erber/models/syntaxnet/bazel-bin/syntaxnet/parser_eval.runfiles/__main__/syntaxnet/parser_eval.py"", line 31, in <module>
    import graph_builder

  File ""graph_builder.py"", line 22, in <module>
    import load_parser_ops

  File ""load_parser_ops.py"", line 25, in <module>
    'parser_ops.so'))

  File ""/home/erber/.local/lib/python2.7/site-packages/tensorflow/python/framework/load_library.py"", line 64, in load_op_library
    None, None, error_msg, error_code)

NotFoundError: parser_ops.so: cannot open shared object file: No such file or directory

thank you very much for any help!
",EnricoBeltramo,b'stat:awaiting model gardener type:bug',2017-02-15T23:29:26Z,2018-02-08T00:24:52Z,,,,,,,
1020,Slim.learning.train  error when model train too fast,"I follow step in slim_walkthoungh.ipynb and get error. I gess when train model too fast then elapsed_time equal zero

`Layers
name = deep_regression/fc2/Relu:0, shape = (?, 16)
name = deep_regression/fc1/Relu:0, shape = (?, 32)
name = deep_regression/prediction/BiasAdd:0, shape = (?, 1)


Parameters
name = deep_regression/fc1/weights:0, shape = (1, 32)
name = deep_regression/fc1/biases:0, shape = (32,)
name = deep_regression/fc2/weights:0, shape = (32, 16)
name = deep_regression/fc2/biases:0, shape = (16,)
name = deep_regression/prediction/weights:0, shape = (16, 1)
name = deep_regression/prediction/biases:0, shape = (1,)
WARNING:tensorflow:From D:\ML Learning\python_env\lib\site-packages\tensorflow\python\training\supervisor.py:344 in __init__.: SummaryWriter.__init__ (from tensorflow.python.training.summary_io) is deprecated and will be removed after 2016-11-30.
Instructions for updating:
Please switch to tf.summary.FileWriter. The interface and behavior is the same; this is just a rename.
INFO:tensorflow:Starting Session.
INFO:tensorflow:Starting Queues.
INFO:tensorflow:Error reported to Coordinator: <class 'ZeroDivisionError'>, float division by zero
INFO:tensorflow:Stopping Training.
INFO:tensorflow:Finished training! Saving model to disk.
Traceback (most recent call last):
  File ""D:/ML Learning/workspace/mnistclass/model.py"", line 117, in <module>
    log_every_n_steps=50)
  File ""D:\ML Learning\python_env\lib\site-packages\tensorflow\contrib\slim\python\slim\learning.py"", line 793, in train
    raise
  File ""D:\ML Learning\python_env\lib\contextlib.py"", line 66, in __exit__
    next(self.gen)
  File ""D:\ML Learning\python_env\lib\site-packages\tensorflow\python\training\supervisor.py"", line 974, in managed_session
    self.stop(close_summary_writer=close_summary_writer)
  File ""D:\ML Learning\python_env\lib\site-packages\tensorflow\python\training\supervisor.py"", line 802, in stop
    stop_grace_period_secs=self._stop_grace_secs)
  File ""D:\ML Learning\python_env\lib\site-packages\tensorflow\python\training\coordinator.py"", line 386, in join
    six.reraise(*self._exc_info_to_raise)
  File ""D:\ML Learning\python_env\lib\site-packages\six.py"", line 686, in reraise
    raise value
  File ""D:\ML Learning\python_env\lib\site-packages\tensorflow\python\training\coordinator.py"", line 296, in stop_on_exception
    yield
  File ""D:\ML Learning\python_env\lib\site-packages\tensorflow\python\training\coordinator.py"", line 487, in run
    self.run_loop()
  File ""D:\ML Learning\python_env\lib\site-packages\tensorflow\python\training\supervisor.py"", line 1044, in run_loop
    steps_per_sec = added_steps / elapsed_time
ZeroDivisionError: float division by zero`",nguyenvulebinh,b'type:bug',2017-02-15T08:11:20Z,2017-02-15T18:23:16Z,,,,,,,
1005,Suggestions for autoencoder,"## Please let us know which model this issue is about (specify the top-level directory) autoencoder

In _models/autoencoder/AdditiveGaussianNoiseAutoencoderRunner.py_ 
Changing 
```
    # Display logs per epoch step
    if epoch % display_step == 0:
        print ""Epoch:"", '%04d' % (epoch + 1), \
            ""cost="", ""{:.9f}"".format(avg_cost)

print ""Total cost: "" + str(autoencoder.calc_total_cost(X_test))
```
to 
```
    # Display logs per epoch step
    if epoch % display_step == 0:
        print(""Epoch:"", '%04d' % (epoch + 1), \
            ""cost="", ""{:.9f}"".format(avg_cost))

print(""Total cost: "" + str(autoencoder.calc_total_cost(X_test)))
```
Also for _models/autoencoder/AutoencoderRunner.py_ ,  _MaskingNoiseAutoencoderRunner.py_ and  _VariationalAutoencoderRunner.py_",linrio,b'help wanted type:bug',2017-02-10T13:44:57Z,2018-02-22T19:34:06Z,,,,,,,
987,"inception: ""TypeError: Expected int32, got list containing Tensors of type '_Message' instead.""","Steps to reproduce: follow the inception tutorial with TensorFlow 0.12.head installed.

When running training from scratch, I get:

```
$ bazel-bin/inception/imagenet_train --num_gpus=1 --batch_size=32 --train_dir=/tmp/imagenet_train --data_dir=/work/user/data/imagenet
I tensorflow/stream_executor/dso_loader.cc:125] successfully opened CUDA library libcublas.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:125] successfully opened CUDA library libcudnn.so.5 locally
I tensorflow/stream_executor/dso_loader.cc:125] successfully opened CUDA library libcufft.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:125] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:125] successfully opened CUDA library libcurand.so.8.0 locally
Traceback (most recent call last):
  File ""/usr/wiss/user/libs/tfmodels/inception/bazel-bin/inception/imagenet_train.runfiles/inception/inception/imagenet_train.py"", line 41, in <module>
    tf.app.run()
  File ""/usr/wiss/user/.local/lib/python2.7/site-packages/tensorflow/python/platform/app.py"", line 44, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""/usr/wiss/user/libs/tfmodels/inception/bazel-bin/inception/imagenet_train.runfiles/inception/inception/imagenet_train.py"", line 37, in main
    inception_train.train(dataset)
  File ""/usr/wiss/user/libs/tfmodels/inception/bazel-bin/inception/imagenet_train.runfiles/inception/inception/inception_train.py"", line 217, in train
    num_preprocess_threads=num_preprocess_threads)
  File ""/usr/wiss/user/libs/tfmodels/inception/bazel-bin/inception/imagenet_train.runfiles/inception/inception/image_processing.py"", line 136, in distorted_inputs
    num_readers=FLAGS.num_readers)
  File ""/usr/wiss/user/libs/tfmodels/inception/bazel-bin/inception/imagenet_train.runfiles/inception/inception/image_processing.py"", line 490, in batch_inputs
    example_serialized)
  File ""/usr/wiss/user/libs/tfmodels/inception/bazel-bin/inception/imagenet_train.runfiles/inception/inception/image_processing.py"", line 397, in parse_example_proto
    bbox = tf.concat(0, [ymin, xmin, ymax, xmax])
  File ""/usr/wiss/user/.local/lib/python2.7/site-packages/tensorflow/python/ops/array_ops.py"", line 1248, in concat
    dtype=dtypes.int32).get_shape(
  File ""/usr/wiss/user/.local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 651, in convert_to_tensor
    as_ref=False)
  File ""/usr/wiss/user/.local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 716, in internal_convert_to_tensor
    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
  File ""/usr/wiss/user/.local/lib/python2.7/site-packages/tensorflow/python/framework/constant_op.py"", line 176, in _constant_tensor_conversion_function
    return constant(v, dtype=dtype, name=name)
  File ""/usr/wiss/user/.local/lib/python2.7/site-packages/tensorflow/python/framework/constant_op.py"", line 165, in constant
    tensor_util.make_tensor_proto(value, dtype=dtype, shape=shape, verify_shape=verify_shape))
  File ""/usr/wiss/user/.local/lib/python2.7/site-packages/tensorflow/python/framework/tensor_util.py"", line 367, in make_tensor_proto
    _AssertCompatible(values, dtype)
  File ""/usr/wiss/user/.local/lib/python2.7/site-packages/tensorflow/python/framework/tensor_util.py"", line 302, in _AssertCompatible
    (dtype.name, repr(mismatch), type(mismatch).__name__))
TypeError: Expected int32, got list containing Tensors of type '_Message' instead.

```

The problem is that some examples don't provide bounding boxes. In that case, xmin etc are all `[]` in which case concat fails.",haeusser,b'type:bug',2017-02-06T15:13:01Z,2017-03-23T22:49:57Z,,,,,,,
982,"fixed a bug in sampled_loss(), made compatible for 0.12.0","One of the main changes is swapping the arguments of the function sampled_loss(). Also made appropriate changes to package reference so it is able to run with the tensorflow's version available in the repo.

Thanks
Arvind",arvind385801,b'cla: yes',2017-02-05T15:05:57Z,2017-03-16T00:13:44Z,,,,,,,
964,fix the  bug running cifar10 example on tensorflow 1.0 or master branch,"for the master branch tensorflow, there is no `tf.image_summary` and will cause a bug,
so this need to be change to `tf.summary.image`, since tensorflow 1.0 use this and will be a stable api, update all these kind of api changes (also a tf.mul -> tf.multiply)",fayeshine,b'cla: yes',2017-01-28T12:30:44Z,2017-02-06T06:26:53Z,,,,,,,
960,Corrections and explanations for the updated Neural GPU model.,Small corrections to bug spotted in the updated Neural GPU code and some README updates.,lukaszkaiser,b'cla: yes',2017-01-27T09:44:26Z,2017-01-27T09:44:53Z,,,,,,,
952,Incpetion flowers fine-tune taking too long,"I know this is probably not the place to ask this but since I need the but I hope someone here has already tried fine-tuning the inception model.

I am running the inception fine-tuning flowers example. Its been well over 5 days now and I'm just went past the 150,000 step.

How many steps does it take to fine-tune the flowers model?",redserpent7,b'stat:community support type:bug type:support',2017-01-25T14:01:30Z,2018-02-08T00:19:56Z,,,,,,,
950,Fine-tune Inception V3 with Tensorflow 0.12.1 failed,"Fine-tune Inception V3 with Tensorflow 0.12.1 failed.
```
Traceback (most recent call last):
  File ""train_image_classifier.py"", line 585, in <module>
    tf.app.run()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 44, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""train_image_classifier.py"", line 448, in main
    image = image_preprocessing_fn(image, train_image_size, train_image_size)
  File ""/home/ylzhao/project/tensorflow-models/slim/preprocessing/preprocessing_factory.py"", line 70, in preprocessing_fn
    image, output_height, output_width, is_training=is_training, **kwargs)
  File ""/home/ylzhao/project/tensorflow-models/slim/preprocessing/inception_preprocessing.py"", line 302, in preprocess_image
    return preprocess_for_train(image, height, width, bbox, fast_mode)
  File ""/home/ylzhao/project/tensorflow-models/slim/preprocessing/inception_preprocessing.py"", line 195, in preprocess_for_train
    tf.image_summary('image_with_bounding_boxes', image_with_box)
AttributeError: 'module' object has no attribute 'image_summary'
```
```
Traceback (most recent call last):
  File ""eval_image_classifier.py"", line 191, in <module>
    tf.app.run()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 44, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""eval_image_classifier.py"", line 128, in main
    image = image_preprocessing_fn(image, eval_image_size, eval_image_size)
  File ""/home/ylzhao/project/tensorflow-models/slim/preprocessing/preprocessing_factory.py"", line 70, in preprocessing_fn
    image, output_height, output_width, is_training=is_training, **kwargs)
  File ""/home/ylzhao/project/tensorflow-models/slim/preprocessing/inception_preprocessing.py"", line 304, in preprocess_image
    return preprocess_for_eval(image, height, width)
  File ""/home/ylzhao/project/tensorflow-models/slim/preprocessing/inception_preprocessing.py"", line 273, in preprocess_for_eval
    image = tf.sub(image, 0.5)
AttributeError: 'module' object has no attribute 'sub'
```
```
Traceback (most recent call last):
  File ""eval_image_classifier.py"", line 191, in <module>
    tf.app.run()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 44, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""eval_image_classifier.py"", line 128, in main
    image = image_preprocessing_fn(image, eval_image_size, eval_image_size)
  File ""/home/ylzhao/project/tensorflow-models/slim/preprocessing/preprocessing_factory.py"", line 70, in preprocessing_fn
    image, output_height, output_width, is_training=is_training, **kwargs)
  File ""/home/ylzhao/project/tensorflow-models/slim/preprocessing/inception_preprocessing.py"", line 304, in preprocess_image
    return preprocess_for_eval(image, height, width)
  File ""/home/ylzhao/project/tensorflow-models/slim/preprocessing/inception_preprocessing.py"", line 274, in preprocess_for_eval
    image = tf.mul(image, 2.0)
AttributeError: 'module' object has no attribute 'mul'
```
```
Traceback (most recent call last):
  File ""eval_image_classifier.py"", line 191, in <module>
    tf.app.run()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 44, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""eval_image_classifier.py"", line 139, in main
    logits, _ = network_fn(images)
  File ""/home/ylzhao/project/models/slim/nets/nets_factory.py"", line 105, in network_fn
    return func(images, num_classes, is_training=is_training)
  File ""/home/ylzhao/project/models/slim/nets/inception_v3.py"", line 481, in inception_v3
    depth_multiplier=depth_multiplier)
  File ""/home/ylzhao/project/models/slim/nets/inception_v3.py"", line 161, in inception_v3_base
    net = tf.concat(3, [branch_0, branch_1, branch_2, branch_3])
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/array_ops.py"", line 1053, in concat
    dtype=dtypes.int32).get_shape(
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 651, in convert_to_tensor
    as_ref=False)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 716, in internal_convert_to_tensor
    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/constant_op.py"", line 176, in _constant_tensor_conversion_function
    return constant(v, dtype=dtype, name=name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/constant_op.py"", line 165, in constant
    tensor_util.make_tensor_proto(value, dtype=dtype, shape=shape, verify_shape=verify_shape))
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/tensor_util.py"", line 367, in make_tensor_proto
    _AssertCompatible(values, dtype)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/tensor_util.py"", line 302, in _AssertCompatible
    (dtype.name, repr(mismatch), type(mismatch).__name__))
TypeError: Expected int32, got list containing Tensors of type '_Message' instead.
```",panovr,b'type:bug',2017-01-25T03:05:00Z,2017-03-23T22:50:28Z,,,,,,,
923,Civar10_train & Cifar10_multi_gpu_train won't run: TypeError: strided_slice() missing 1 required positional argument: 'strides',"I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\stream_executor\dso_loader.cc:128] successfully opened CUDA library cublas64_80.dll locally
I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\stream_executor\dso_loader.cc:128] successfully opened CUDA library cudnn64_5.dll locally
I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\stream_executor\dso_loader.cc:128] successfully opened CUDA library cufft64_80.dll locally
I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\stream_executor\dso_loader.cc:128] successfully opened CUDA library nvcuda.dll locally
I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\stream_executor\dso_loader.cc:128] successfully opened CUDA library curand64_80.dll locally
Traceback (most recent call last):
  File ""C:/Users/TH/PycharmProjects/TensorflowTest/cifar10_3/cifar10_train.py"", line 120, in <module>
    tf.app.run()
  File ""C:\Program Files\Python35\lib\site-packages\tensorflow\python\platform\app.py"", line 43, in run
    sys.exit(main(sys.argv[:1] + flags_passthrough))
  File ""C:/Users/TH/PycharmProjects/TensorflowTest/cifar10_3/cifar10_train.py"", line 116, in main
    train()
  File ""C:/Users/TH/PycharmProjects/TensorflowTest/cifar10_3/cifar10_train.py"", line 63, in train
    images, labels = cifar10.distorted_inputs()
  File ""C:\Users\TH\PycharmProjects\TensorflowTest\cifar10_3\cifar10.py"", line 156, in distorted_inputs
    batch_size=FLAGS.batch_size)
  File ""C:\Users\TH\PycharmProjects\TensorflowTest\cifar10_3\cifar10_input.py"", line 161, in distorted_inputs
    read_input = read_cifar10(filename_queue)
  File ""C:\Users\TH\PycharmProjects\TensorflowTest\cifar10_3\cifar10_input.py"", line 87, in read_cifar10
    tf.strided_slice(record_bytes, [0], [label_bytes]), tf.int32)
TypeError: strided_slice() missing 1 required positional argument: 'strides'",ghost,b'type:bug',2017-01-19T08:58:29Z,2017-01-23T21:28:14Z,,,,,,,
915,docker syntaxnet build failing at configure?,"building the syntaxnet docker image gives me the following output in ubuntu (tailed):

```
Bazel is now installed!

Make sure you have ""/root/bin"" in your path. You can also activate bash
completion by adding the following line to your :
  source /root/.bazel/bin/bazel-complete.bash

See http://bazel.build/docs/getting-started.html to start a new project!
Cloning into 'models'...
Submodule 'tensorflow' (https://github.com/tensorflow/tensorflow.git) registered for path 'syntaxnet/tensorflow'
Cloning into 'syntaxnet/tensorflow'...
Submodule path 'syntaxnet/tensorflow': checked out 'aab099711d7e04034cf742ddb9b00dd15edbe99c'
No Google Cloud Platform support will be enabled for TensorFlow
No Hadoop File System support will be enabled for TensorFlow
Found possible Python library paths:
  /usr/local/lib/python2.7/dist-packages
  /usr/lib/python2.7/dist-packages
Please input the desired Python library path to use.  Default is [/usr/local/lib/python2.7/dist-packages]
Using python library path: /usr/local/lib/python2.7/dist-packages
No OpenCL support will be enabled for TensorFlow
The command '/bin/sh -c mkdir -p $SYNTAXNETDIR     && cd $SYNTAXNETDIR     && apt-get update     && apt-get install git zlib1g-dev file swig python2.7 python-dev python-pip python-mock -y     && pip install --upgrade pip     && pip install -U protobuf==3.0.0     && pip install asciitree     && pip install numpy     && wget https://github.com/bazelbuild/bazel/releases/download/0.4.3/bazel-0.4.3-installer-linux-x86_64.sh     && chmod +x bazel-0.4.3-installer-linux-x86_64.sh     && ./bazel-0.4.3-installer-linux-x86_64.sh --user     && git clone --recursive https://github.com/tensorflow/models.git     && cd $SYNTAXNETDIR/models/syntaxnet/tensorflow     && echo ""\n\n\n\n"" | ./configure     && apt-get autoremove -y     && apt-get clean' returned a non-zero code: 1
```

what's the best way to find more info to debug this error? thank you",bgrayburn,None,2017-01-17T17:16:50Z,2017-01-30T17:01:26Z,,,,,,,
911,Fix bugs and API usage on cifar10 and cifar10_multi_gpu_train,"Make the cifar10 example (especially, multi_gpu_train) work in the recent master version. This PR includes two updates:

- Replace `tf.mul` (which was removed) with `tf.multiply` (#901).
- Correct the usage of variable_scope around the part multi-gpu model construction, so that ""reuse"" on the variable scope becomes not leaky (tensorflow/tensorflow#6220).",wookayin,b'cla: yes',2017-01-17T03:18:03Z,2017-02-13T23:46:54Z,,,,,,,
910,seek() takes exactly 2 arguments (3 given),"## Please let us know which model this issue is about (specify the top-level directory)
In the models/differential_privacy/multiple_teachers I have run this line:

python train_teachers.py --nb_teachers=100 --teacher_id=10 --dataset=mnist --max_steps=300

It ran but when I try and run this line or rerun the previous line:

python train_student.py --nb_teachers=100 --dataset=mnist --stdnt_share=5000

I get the error in the subject line.  If I delete the /tmp files I can rerun the first line again but I can't run the second line.  The problem (I think) is that that in input.py this function is called for both commands:

def extract_mnist_data(filename, num_images, image_size, pixel_depth):
  """"""
  Extract the images into a 4D tensor [image index, y, x, channels].

  Values are rescaled from [0, 255] down to [-0.5, 0.5].
  """"""
  # if not os.path.exists(file):
  if not tf.gfile.Exists(filename+"".npy""):
    with gzip.open(filename) as bytestream:
      bytestream.read(16)
      buf = bytestream.read(image_size * image_size * num_images)
      data = np.frombuffer(buf, dtype=np.uint8).astype(np.float32)
      data = (data - (pixel_depth / 2.0)) / pixel_depth
      data = data.reshape(num_images, image_size, image_size, 1)
      np.save(filename, data)
      return data
  else:
    with tf.gfile.Open(filename+"".npy"", mode='r') as file_obj:
      return np.load(file_obj)

The first time I call train_teachers, the top part of the if runs.  When I call the train_students, the bottom part runs and blows up.  

",j2cunningham,b'stat:awaiting model gardener type:bug',2017-01-16T19:39:06Z,2017-04-13T00:56:09Z,,,,,,,
905,Remove dated Bazel docs in syntaxnet,"This documentation seems to have fallen out of date. I don't see any evidence that syntaxnet requires an older version of Bazel than TensorFlow uses. If it legitimately does, that's a separate bug. It's probably better to remove this documentation so it doesn't drift from the official ones.

Fixes #657 ",jart,b'cla: yes',2017-01-15T23:55:38Z,2017-01-16T02:07:09Z,,,,,,,
901,cifar10_multi_gpu_train.py,"I just used git to download the codes, and tensorflow was installed from nightly build. Then I compiled tensorflow from source.
```
# python cifar10_multi_gpu_train.py --num_gpus=4
I tensorflow/stream_executor/dso_loader.cc:125] successfully opened CUDA library libcublas.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:125] successfully opened CUDA library libcudnn.so.5 locally
I tensorflow/stream_executor/dso_loader.cc:125] successfully opened CUDA library libcufft.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:125] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:125] successfully opened CUDA library libcurand.so.8.0 locally
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
WARNING:tensorflow:From /home/***/Downloads/models/tutorials/image/cifar10/cifar10_input.py:135: image_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.
Instructions for updating:
Please switch to tf.summary.image. Note that tf.summary.image uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, the max_images argument was renamed to max_outputs.
Traceback (most recent call last):
  File ""cifar10_multi_gpu_train.py"", line 273, in <module>
    tf.app.run()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 44, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""cifar10_multi_gpu_train.py"", line 269, in main
    train()
  File ""cifar10_multi_gpu_train.py"", line 171, in train
    loss = tower_loss(scope)
  File ""cifar10_multi_gpu_train.py"", line 78, in tower_loss
    logits = cifar10.inference(images)
  File ""/home/***/Downloads/models/tutorials/image/cifar10/cifar10.py"", line 207, in inference
    wd=0.0)
  File ""/home/***/Downloads/models/tutorials/image/cifar10/cifar10.py"", line 137, in _variable_with_weight_decay
    weight_decay = tf.mul(tf.nn.l2_loss(var), wd, name='weight_loss')
AttributeError: 'module' object has no attribute 'mul'
```",weigei123,b'help wanted type:bug',2017-01-14T20:21:29Z,2017-01-17T14:39:16Z,,,,,,,
893,cifar10_eval.py issue: cannot infer Tensor's rank,"I ran a unmodified version of cifar10_eval.py, here is the error message

Traceback (most recent call last):
  File ""cifar10_eval.py"", line 157, in <module>
    tf.app.run()
  File ""/home/zhisong/tensorflow/tensorflow/python/platform/app.py"", line 44, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""cifar10_eval.py"", line 153, in main
    evaluate()
  File ""cifar10_eval.py"", line 121, in evaluate
    images, labels = cifar10.inputs(eval_data=eval_data)
  File ""/home/zhisong/tensorflow/models/tutorials/image/cifar10/cifar10.py"", line 183, in inputs
    batch_size=FLAGS.batch_size)
  File ""/home/zhisong/tensorflow/models/tutorials/image/cifar10/cifar10_input.py"", line 257, in inputs
    shuffle=False)
  File ""/home/zhisong/tensorflow/models/tutorials/image/cifar10/cifar10_input.py"", line 132, in _generate_image_and_label_batch
    capacity=min_queue_examples + 3 * batch_size)
  File ""/home/zhisong/tensorflow/tensorflow/python/training/input.py"", line 872, in batch
    name=name)
  File ""/home/zhisong/tensorflow/tensorflow/python/training/input.py"", line 655, in _batch
    shapes = _shapes([tensor_list], shapes, enqueue_many)
  File ""/home/zhisong/tensorflow/tensorflow/python/training/input.py"", line 598, in _shapes
    raise ValueError(""Cannot infer Tensor's rank: %s"" % tl[i])
ValueError: Cannot infer Tensor's rank: Tensor(""Cast:0"", dtype=int32)

By comparing to distorted_inputs() in cifar10_input.py, I suspect the following lines are missing in inputs()

float_image.set_shape([height, width, 3])
read_input.label.set_shape([1])

After adding the above two lines, the script works just fine",zhisong,b'type:bug',2017-01-13T04:17:31Z,2017-01-13T23:17:47Z,,,,,,,
892,cifar10_eval issues - tensorflow 0.12,"## tensorflow/models/tutorial/image/cifar10/cifar10_eval.py

When I run cifar10_eval.py alongside the cifar10_train.py script in tensorflow 0.12, it crashes the main training script with the error: 

Out of range: RandomShuffleQueue '_2_shuffle_batch/random_shuffle_queue' is closed and has insufficient elements (requested 128, current size 46)

It does this on both the gpu training code and the cpu code - but this doesn't happen using tensorflow 0.11.  Any ideas?

",al3xsh,b'type:bug',2017-01-12T12:58:27Z,2017-06-28T08:30:33Z,,,,,,,
886,Unable to compile HEAD on Windows with Bazel,"I'm unable to successfully build the current HEAD (or versions 1.0 or 0.12) with Windows and Bazel.

### Environment info
* Operating System: Windows 10
* Installed version of CUDA and cuDNN: None
* Bazel version: 0.4.3 (Build time: Thu Dec 22 12:31:31 2016 (1482409891))

I have done the following

* install prerequisites for Bazel on Windows (https://bazel.build/versions/master/docs/windows.html)
* checked out TF head (I also tried this with release 1.0, and release 0.12)
* run exe C:\tools\msys64\msys2.exe
* set these env variables
** export JAVA_HOME=""$(ls -d C:/Program\ Files/Java/jdk* | sort | tail -n 1)""
** export TMPDIR=""C:/tmp""
** export BAZEL_SH=c:/tools/msys64/usr/bin/bash.exe
** export BAZEL_VS=""C:/Program Files (x86)/Microsoft Visual Studio 14.0""
** export BAZEL_PYTHON=""C:/Users/.../Anaconda3/python.exe""
** export PYTHON_BIN_PATH=""C:/Users/.../Anaconda3/python.exe""
** export PATH=/c/Users/.../Anaconda3/:$PATH
** export PATH=/c/tools/bazel/:$PATH
** export PATH=/c/Program\ Files/CMake/bin/:$PATH
* ./configure
** no GPU, etc, just default options and path to Anaconda
* bazel build -c opt --cpu=x64_windows_msvc //tensorflow/tools/pip_package:build_pip_package

However I get errors after a few minutes of building.
This is reproducible and happens every time. I am following all the default options for the basic build. I would be interested to know if anyone is currently managing to compile on Windows?
I can find a few tutorials using Docker or Cmake, however I'm trying to use the newest method described on TF's website.

INFO: From Linking external/protobuf/pyext/_message.so:
   Creating library bazel-out/vc_14_0_x64-py3-opt/bin/external/protobuf/pyext/_m  essage.lib and object bazel-out/vc_14_0_x64-py3-opt/bin/external/protobuf/pyext/  _message.exp
ERROR: C:/Users/user/Clones/tensorflow/tensorflow/core/BUILD:1013:  1: null failed: protoc.exe failed: error executing command bazel-out/host/bin/ex  ternal/protobuf/protoc.exe --cpp_out=bazel-out/vc_14_0_x64-py3-opt/genfiles/ -I.   -I. -Iexternal/protobuf/src -Ibazel-out/vc_14_0_x64-py3-opt/genfiles/external/p  rotobuf/src ... (remaining 3 argument(s) skipped): com.google.devtools.build.lib  .shell.BadExitStatusException: Process exited with status -1073741515.
ERROR: C:/Users/user/Clones/tensorflow/tensorflow/python/BUILD:208  8:1: output 'tensorflow/python/framework/cpp_shape_inference_pb2.py' was not cre  ated.
ERROR: C:/Users/user/Clones/tensorflow/tensorflow/core/BUILD:163:1  : output 'tensorflow/core/example/example.pb.cc' was not created.
ERROR: C:/Users/user/Clones/tensorflow/tensorflow/core/BUILD:163:1  : output 'tensorflow/core/example/feature.pb.cc' was not created.
ERROR: C:/Users/user/Clones/tensorflow/tensorflow/core/BUILD:163:1  : output 'tensorflow/core/framework/allocation_description.pb.cc' was not create  d.
ERROR: C:/Users/user/Clones/tensorflow/tensorflow/core/BUILD:163:1  : output 'tensorflow/core/framework/attr_value.pb.cc' was not created.
ERROR: C:/Users/user/Clones/tensorflow/tensorflow/core/BUILD:163:1  : output 'tensorflow/core/framework/cost_graph.pb.cc' was not created.
ERROR: C:/Users/user/Clones/tensorflow/tensorflow/core/BUILD:163:1  : output 'tensorflow/core/framework/device_attributes.pb.cc' was not created.
ERROR: C:/Users/user/Clones/tensorflow/tensorflow/core/BUILD:163:1  : output 'tensorflow/core/framework/function.pb.cc' was not created.
ERROR: C:/Users/user/Clones/tensorflow/tensorflow/core/BUILD:163:1  : output 'tensorflow/core/framework/graph.pb.cc' was not created.
ERROR: C:/Users/user/Clones/tensorflow/tensorflow/core/BUILD:163:1  : output 'tensorflow/core/framework/kernel_def.pb.cc' was not created.
ERROR: C:/Users/user/Clones/tensorflow/tensorflow/core/BUILD:163:1  : output 'tensorflow/core/framework/log_memory.pb.cc' was not created.
ERROR: C:/Users/user/Clones/tensorflow/tensorflow/core/BUILD:163:1  : output 'tensorflow/core/framework/node_def.pb.cc' was not created.
ERROR: C:/Users/user/Clones/tensorflow/tensorflow/core/BUILD:163:1  : output 'tensorflow/core/framework/op_def.pb.cc' was not created.
ERROR: C:/Users/user/Clones/tensorflow/tensorflow/core/BUILD:163:1  : output 'tensorflow/core/framework/resource_handle.pb.cc' was not created.
ERROR: C:/Users/user/Clones/tensorflow/tensorflow/core/BUILD:163:1  : output 'tensorflow/core/framework/step_stats.pb.cc' was not created.
ERROR: C:/Users/user/Clones/tensorflow/tensorflow/core/BUILD:163:1  : output 'tensorflow/core/framework/summary.pb.cc' was not created.
ERROR: C:/Users/user/Clones/tensorflow/tensorflow/core/BUILD:163:1  : output 'tensorflow/core/framework/tensor.pb.cc' was not created.
ERROR: C:/Users/user/Clones/tensorflow/tensorflow/core/BUILD:163:1  : output 'tensorflow/core/framework/tensor_description.pb.cc' was not created.
ERROR: C:/Users/user/Clones/tensorflow/tensorflow/core/BUILD:163:1  : output 'tensorflow/core/framework/tensor_shape.pb.cc' was not created.
ERROR: C:/Users/user/Clones/tensorflow/tensorflow/core/BUILD:163:1  : output 'tensorflow/core/framework/tensor_slice.pb.cc' was not created.
ERROR: C:/Users/user/Clones/tensorflow/tensorflow/core/BUILD:163:1  : output 'tensorflow/core/framework/types.pb.cc' was not created.
ERROR: C:/Users/user/Clones/tensorflow/tensorflow/core/BUILD:163:1  : output 'tensorflow/core/framework/versions.pb.cc' was not created.
ERROR: C:/Users/user/Clones/tensorflow/tensorflow/core/BUILD:163:1  : output 'tensorflow/core/lib/core/error_codes.pb.cc' was not created.
ERROR: C:/Users/user/Clones/tensorflow/tensorflow/core/BUILD:163:1  : output 'tensorflow/core/protobuf/config.pb.cc' was not created.
ERROR: C:/Users/user/Clones/tensorflow/tensorflow/core/BUILD:163:1  : output 'tensorflow/core/protobuf/debug.pb.cc' was not created.
ERROR: C:/Users/user/Clones/tensorflow/tensorflow/core/BUILD:163:1  : output 'tensorflow/core/protobuf/tensor_bundle.pb.cc' was not created.
ERROR: C:/Users/user/Clones/tensorflow/tensorflow/core/BUILD:163:1  : output 'tensorflow/core/protobuf/saver.pb.cc' was not created.
ERROR: C:/Users/user/Clones/tensorflow/tensorflow/core/BUILD:163:1  : output 'tensorflow/core/util/memmapped_file_system.pb.cc' was not created.
ERROR: C:/Users/user/Clones/tensorflow/tensorflow/core/BUILD:163:1  : output 'tensorflow/core/util/saved_tensor_slice.pb.cc' was not created.
ERROR: C:/Users/user/Clones/tensorflow/tensorflow/core/BUILD:163:1  : output 'tensorflow/core/example/example_parser_configuration.pb.cc' was not cr  eated.
ERROR: C:/Users/user/Clones/tensorflow/tensorflow/core/BUILD:163:1  : output 'tensorflow/core/framework/variable.pb.cc' was not created.
ERROR: C:/Users/user/Clones/tensorflow/tensorflow/core/BUILD:163:1  : output 'tensorflow/core/protobuf/control_flow.pb.cc' was not created.
ERROR: C:/Users/user/Clones/tensorflow/tensorflow/core/BUILD:163:1  : output 'tensorflow/core/protobuf/meta_graph.pb.cc' was not created.
ERROR: C:/Users/user/Clones/tensorflow/tensorflow/core/BUILD:163:1  : output 'tensorflow/core/protobuf/named_tensor.pb.cc' was not created.
ERROR: C:/Users/user/Clones/tensorflow/tensorflow/core/BUILD:163:1  : output 'tensorflow/core/protobuf/queue_runner.pb.cc' was not created.
ERROR: C:/Users/user/Clones/tensorflow/tensorflow/core/BUILD:163:1  : output 'tensorflow/core/protobuf/saved_model.pb.cc' was not created.
ERROR: C:/Users/user/Clones/tensorflow/tensorflow/core/BUILD:163:1  : output 'tensorflow/core/protobuf/tensorflow_server.pb.cc' was not created.
ERROR: C:/Users/user/Clones/tensorflow/tensorflow/core/BUILD:163:1  : output 'tensorflow/core/util/event.pb.cc' was not created.
ERROR: C:/Users/user/Clones/tensorflow/tensorflow/core/BUILD:163:1  : output 'tensorflow/core/util/test_log.pb.cc' was not created.
ERROR: C:/Users/user/Clones/tensorflow/tensorflow/core/BUILD:163:1  : output 'tensorflow/core/example/example.pb.h' was not created.
ERROR: C:/Users/user/Clones/tensorflow/tensorflow/core/BUILD:163:1  : output 'tensorflow/core/example/feature.pb.h' was not created.
ERROR: C:/Users/user/Clones/tensorflow/tensorflow/core/BUILD:163:1  : output 'tensorflow/core/framework/allocation_description.pb.h' was not created  .
ERROR: C:/Users/user/Clones/tensorflow/tensorflow/core/BUILD:163:1  : output 'tensorflow/core/framework/attr_value.pb.h' was not created.
ERROR: C:/Users/user/Clones/tensorflow/tensorflow/core/BUILD:163:1  : output 'tensorflow/core/framework/cost_graph.pb.h' was not created.
ERROR: C:/Users/user/Clones/tensorflow/tensorflow/core/BUILD:163:1  : output 'tensorflow/core/framework/device_attributes.pb.h' was not created.
ERROR: C:/Users/user/Clones/tensorflow/tensorflow/core/BUILD:163:1  : output 'tensorflow/core/framework/function.pb.h' was not created.
ERROR: C:/Users/user/Clones/tensorflow/tensorflow/core/BUILD:163:1  : output 'tensorflow/core/framework/graph.pb.h' was not created.
ERROR: C:/Users/user/Clones/tensorflow/tensorflow/core/BUILD:163:1  : output 'tensorflow/core/framework/kernel_def.pb.h' was not created.
ERROR: C:/Users/user/Clones/tensorflow/tensorflow/core/BUILD:163:1  : output 'tensorflow/core/framework/log_memory.pb.h' was not created.
ERROR: C:/Users/user/Clones/tensorflow/tensorflow/core/BUILD:163:1  : output 'tensorflow/core/framework/node_def.pb.h' was not created.
ERROR: C:/Users/user/Clones/tensorflow/tensorflow/core/BUILD:163:1  : output 'tensorflow/core/framework/op_def.pb.h' was not created.
ERROR: C:/Users/user/Clones/tensorflow/tensorflow/core/BUILD:163:1  : output 'tensorflow/core/framework/resource_handle.pb.h' was not created.
ERROR: C:/Users/user/Clones/tensorflow/tensorflow/core/BUILD:163:1  : output 'tensorflow/core/framework/step_stats.pb.h' was not created.
ERROR: C:/Users/user/Clones/tensorflow/tensorflow/core/BUILD:163:1  : output 'tensorflow/core/framework/summary.pb.h' was not created.
ERROR: C:/Users/user/Clones/tensorflow/tensorflow/core/BUILD:163:1  : output 'tensorflow/core/framework/tensor.pb.h' was not created.
ERROR: C:/Users/user/Clones/tensorflow/tensorflow/core/BUILD:163:1  : output 'tensorflow/core/framework/tensor_description.pb.h' was not created.
ERROR: C:/Users/user/Clones/tensorflow/tensorflow/core/BUILD:163:1  : output 'tensorflow/core/framework/tensor_shape.pb.h' was not created.
ERROR: C:/Users/user/Clones/tensorflow/tensorflow/core/BUILD:163:1  : output 'tensorflow/core/framework/tensor_slice.pb.h' was not created.
ERROR: C:/Users/user/Clones/tensorflow/tensorflow/core/BUILD:163:1  : output 'tensorflow/core/framework/types.pb.h' was not created.
ERROR: C:/Users/user/Clones/tensorflow/tensorflow/core/BUILD:163:1  : output 'tensorflow/core/framework/versions.pb.h' was not created.
ERROR: C:/Users/user/Clones/tensorflow/tensorflow/core/BUILD:163:1  : output 'tensorflow/core/lib/core/error_codes.pb.h' was not created.
ERROR: C:/Users/user/Clones/tensorflow/tensorflow/core/BUILD:163:1  : output 'tensorflow/core/protobuf/config.pb.h' was not created.
ERROR: C:/Users/user/Clones/tensorflow/tensorflow/core/BUILD:163:1  : output 'tensorflow/core/protobuf/debug.pb.h' was not created.
ERROR: C:/Users/user/Clones/tensorflow/tensorflow/core/BUILD:163:1  : output 'tensorflow/core/protobuf/tensor_bundle.pb.h' was not created.
ERROR: C:/Users/user/Clones/tensorflow/tensorflow/core/BUILD:163:1  : output 'tensorflow/core/protobuf/saver.pb.h' was not created.
ERROR: C:/Users/user/Clones/tensorflow/tensorflow/core/BUILD:163:1  : output 'tensorflow/core/util/memmapped_file_system.pb.h' was not created.
ERROR: C:/Users/user/Clones/tensorflow/tensorflow/core/BUILD:163:1  : output 'tensorflow/core/util/saved_tensor_slice.pb.h' was not created.
ERROR: C:/Users/user/Clones/tensorflow/tensorflow/core/BUILD:163:1  : output 'tensorflow/core/example/example_parser_configuration.pb.h' was not cre  ated.
ERROR: C:/Users/user/Clones/tensorflow/tensorflow/core/BUILD:163:1  : output 'tensorflow/core/framework/variable.pb.h' was not created.
ERROR: C:/Users/user/Clones/tensorflow/tensorflow/core/BUILD:163:1  : output 'tensorflow/core/protobuf/control_flow.pb.h' was not created.
ERROR: C:/Users/user/Clones/tensorflow/tensorflow/core/BUILD:163:1  : output 'tensorflow/core/protobuf/meta_graph.pb.h' was not created.
ERROR: C:/Users/user/Clones/tensorflow/tensorflow/core/BUILD:163:1  : output 'tensorflow/core/protobuf/named_tensor.pb.h' was not created.
ERROR: C:/Users/user/Clones/tensorflow/tensorflow/core/BUILD:163:1  : output 'tensorflow/core/protobuf/queue_runner.pb.h' was not created.
ERROR: C:/Users/user/Clones/tensorflow/tensorflow/core/BUILD:163:1  : output 'tensorflow/core/protobuf/saved_model.pb.h' was not created.
ERROR: C:/Users/user/Clones/tensorflow/tensorflow/core/BUILD:163:1  : output 'tensorflow/core/protobuf/tensorflow_server.pb.h' was not created.
ERROR: C:/Users/user/Clones/tensorflow/tensorflow/core/BUILD:163:1  : output 'tensorflow/core/util/event.pb.h' was not created.
ERROR: C:/Users/user/Clones/tensorflow/tensorflow/core/BUILD:163:1  : output 'tensorflow/core/util/test_log.pb.h' was not created.
Target //tensorflow/tools/pip_package:build_pip_package failed to build
Use --verbose_failures to see the command lines of failed build steps.
INFO: Elapsed time: 187.905s, Critical Path: 171.65s",woodthom2,None,2017-01-11T15:12:19Z,2017-01-11T18:15:40Z,,,,,,,
869,Spatial Transformer output's channel dimension doesn't evaluate to input's channel,"## Transformer (Spatial Transformer)

I used the following code to check the output dimension of spatial transformer
```
import tensorflow as tf
from spatial_transformer import transformer

a = tf.placeholder(tf.float32, shape=(1,299,299,3)) # Input
b = tf.placeholder(tf.float32, shape=(1,6)) # Theta
out_size = (299, 299) # size

h = transformer(a, b, out_size)

print h.shape
```

This evaluates to
`TensorShape([Dimension(None), Dimension(299), Dimension(299), Dimension(None)])`

whereas `h` cant be used as input to other slim layers like conv2d since *channels* is null (should have been 3 - according to input channels) 

Does anyone have any suggestion on how to use this along with other models defined in slim? Is this a bug?",IMG-PRCSNG,b'stat:community support',2017-01-09T12:20:26Z,2018-02-22T19:30:38Z,,,,,,,
859,setting max number of iterations in inception doesn't work!,"While training the inception model, I've set the maximum number of iterations to some small number. In some random runs, the fastest worker would break from the training loop, but the other workers suddenly stuck with no progression. As a result the parameter servers and some of the workers stalls and the training phase never finishes.

I'm training using TensorFlow r.012, using Nvidia K40 on a cluster of machines.

Here is the piece of code responsible for breaking out of loop after certain iterations(Code reside in inception_distributed_train.py):

```
      while not sv.should_stop():
        try:
          start_time = time.time()
          loss_value, step = sess.run([train_op, global_step])
          assert not np.isnan(loss_value), 'Model diverged with loss = NaN'
          if step > FLAGS.max_steps:
            break
          duration = time.time() - start_time

          if step % 30 == 0:
            examples_per_sec = FLAGS.batch_size / float(duration)
            format_str = ('Worker %d: %s: step %d, loss = %.2f'
                          '(%.1f examples/sec; %.3f  sec/batch)')
            tf.logging.info(format_str %
                            (FLAGS.task_id, datetime.now(), step, loss_value,
                             examples_per_sec, duration))

          # Determine if the summary_op should be run on the chief worker.
          if is_chief and next_summary_time < time.time():
            tf.logging.info('Running Summary operation on the chief.')
            summary_str = sess.run(summary_op)
            sv.summary_computed(sess, summary_str)
            tf.logging.info('Finished running Summary operation.')

            # Determine the next time for running the summary.
            next_summary_time += FLAGS.save_summaries_secs
        except:
          if is_chief:
            tf.logging.info('About to execute sync_clean_up_op!')
            sess.run(clean_up_op)
          raise

      # Stop the supervisor.  This also waits for service threads to finish.
      sv.stop()

```

Is it a normal behavior or an anomaly in the code?",saman-aghazadeh,b'type:bug',2017-01-06T23:23:54Z,2018-02-22T19:29:56Z,,,,,,,
857,Isuue with models/tutorials/image/mnist,"The MNIST example seems to have problem in running with Tensorflow:
Hi, I am completely new in TensorFlow. I just built TensorFlow and tried to run models/tutorials/image/imagenet/classify_image.py and it ran. But when I tried MNIST, I found the following error:

abhishek@phoebusdev:~/Documents/Works/models/tutorials/image/mnist$ python convolutional.py --self-test
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz
Traceback (most recent call last):
  File ""convolutional.py"", line 339, in <module>
    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 44, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""convolutional.py"", line 231, in main
    logits, train_labels_node))
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/nn_ops.py"", line 1685, in sparse_softmax_cross_entropy_with_logits
    labels, logits)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/nn_ops.py"", line 1534, in _ensure_xent_args
    ""named arguments (labels=..., logits=..., ...)"" % name)
ValueError: Only call `sparse_softmax_cross_entropy_with_logits` with named arguments (labels=..., logits=..., ...)

Am I doing anything wrong?
",abdasgupta,b'stat:awaiting response type:bug',2017-01-06T06:17:03Z,2019-06-30T03:34:53Z,,,,,,,
847,"im2txt  Name: , Context feature 'image/data' is required but could not be found.","## im2txt

I have used my own files to create the training data using inception/data/build_image_data.py
I can see the tfrecord files generated from the above run.

when i run:

`
bazel-bin/im2txt/train   --input_file_pattern=""${MSCOCO_DIR}/train-?????-of-00002""   --inception_checkpoint_file=""${INCEPTION_CHECKPOINT}""   --train_dir=""${MODEL_DIR}/train""   --train_inception=false
`

I get:
<pre>
Caused by op u'ParseSingleSequenceExample_1/ParseSingleSequenceExample', defined at:
  File ""/home/ubuntu/workspace/models/im2txt/bazel-bin/im2txt/train.runfiles/im2txt/im2txt/train.py"", line 114, in <module>
    tf.app.run()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 43, in run
    sys.exit(main(sys.argv[:1] + flags_passthrough))
  File ""/home/ubuntu/workspace/models/im2txt/bazel-bin/im2txt/train.runfiles/im2txt/im2txt/train.py"", line 65, in main
    model.build()
  File ""/home/ubuntu/workspace/models/im2txt/bazel-bin/im2txt/train.runfiles/im2txt/im2txt/show_and_tell_model.py"", line 352, in build
    self.build_inputs()
  File ""/home/ubuntu/workspace/models/im2txt/bazel-bin/im2txt/train.runfiles/im2txt/im2txt/show_and_tell_model.py"", line 164, in build_inputs
    caption_feature=self.config.caption_feature_name)
  File ""/home/ubuntu/workspace/models/im2txt/bazel-bin/im2txt/train.runfiles/im2txt/im2txt/ops/inputs.py"", line 46, in parse_sequence_example
    caption_feature: tf.FixedLenSequenceFeature([], dtype=tf.int64),
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/parsing_ops.py"", line 636, in parse_single_sequence_example
    feature_list_dense_defaults, example_name, name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/parsing_ops.py"", line 833, in _parse_single_sequence_example_raw
    name=name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_parsing_ops.py"", line 287, in _parse_single_sequence_example
    name=name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py"", line 759, in apply_op
    op_def=op_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 2240, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 1128, in __init__
    self._traceback = _extract_stack()

InvalidArgumentError (see above for traceback): Name: , Context feature 'image/data' is required but could not be found.
	 [[Node: ParseSingleSequenceExample_1/ParseSingleSequenceExample = ParseSingleSequenceExample[Ncontext_dense=1, Ncontext_sparse=0, Nfeature_list_dense=1, Nfeature_list_sparse=0, Tcontext_dense=[DT_STRING], context_dense_shapes=[[]], context_sparse_types=[], feature_list_dense_shapes=[[]], feature_list_dense_types=[DT_INT64], feature_list_sparse_types=[], _device=""/job:localhost/replica:0/task:0/cpu:0""](random_input_queue_Dequeue_1, ParseSingleSequenceExample_1/ParseSingleSequenceExample/feature_list_dense_missing_assumed_empty, ParseSingleSequenceExample_1/ParseSingleSequenceExample/context_dense_keys_0, ParseSingleSequenceExample_1/ParseSingleSequenceExample/feature_list_dense_keys_0, ParseSingleSequenceExample_1/Const, ParseSingleSequenceExample_1/ParseSingleSequenceExample/debug_name)]]
	 [[Node: distort_color_1/adjust_hue/Mod/_1709 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device_incarnation=1, tensor_name=""edge_216_distort_color_1/adjust_hue/Mod"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/gpu:0""]()]]
</pre>

Not sure where to proceed from here...",cosmok,None,2017-01-04T03:04:25Z,2017-01-06T17:35:51Z,,,,,,,
840,Inception / imagenet_train fails with python2.7,"I am trying to train Inception CNN using imagenet in python2.7 but it is failing.

Command run:
```
bazel-bin/inception/imagenet_train --num_gpus=4 --batch_size=32 --train_dir=/tmp/imagenet_train-yo/ --data_dir=/root/host_mount/datasets/imagenet/imagenet-data
```
Log:
```
Traceback (most recent call last):
  File ""/root/host_mount/code/models/inception/bazel-bin/inception/imagenet_train.runfiles/inception/inception/imagenet_train.py"", line 41, in <module>
    tf.app.run()
  File ""/root/tensorflow-py2/local/lib/python2.7/site-packages/tensorflow/python/platform/app.py"", line 43, in run
    sys.exit(main(sys.argv[:1] + flags_passthrough))
  File ""/root/host_mount/code/models/inception/bazel-bin/inception/imagenet_train.runfiles/inception/inception/imagenet_train.py"", line 37, in main
    inception_train.train(dataset)
  File ""/root/host_mount/code/models/inception/bazel-bin/inception/imagenet_train.runfiles/inception/inception/inception_train.py"", line 239, in train
    scope)
  File ""/root/host_mount/code/models/inception/bazel-bin/inception/imagenet_train.runfiles/inception/inception/inception_train.py"", line 124, in _tower_loss
    loss_averages_op = loss_averages.apply(losses + [total_loss])
  File ""/root/tensorflow-py2/local/lib/python2.7/site-packages/tensorflow/python/training/moving_averages.py"", line 391, in apply
    self._averages[var], var, decay, zero_debias=zero_debias))
  File ""/root/tensorflow-py2/local/lib/python2.7/site-packages/tensorflow/python/training/moving_averages.py"", line 70, in assign_moving_average
    update_delta = _zero_debias(variable, value, decay)
  File ""/root/tensorflow-py2/local/lib/python2.7/site-packages/tensorflow/python/training/moving_averages.py"", line 177, in _zero_debias
    trainable=False)
  File ""/root/tensorflow-py2/local/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py"", line 1024, in get_variable
    custom_getter=custom_getter)
  File ""/root/tensorflow-py2/local/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py"", line 850, in get_variable
    custom_getter=custom_getter)
  File ""/root/tensorflow-py2/local/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py"", line 346, in get_variable
    validate_shape=validate_shape)
  File ""/root/tensorflow-py2/local/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py"", line 331, in _true_getter
    caching_device=caching_device, validate_shape=validate_shape)
  File ""/root/tensorflow-py2/local/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py"", line 650, in _get_single_variable
    ""VarScope?"" % name)
ValueError: Variable tower_1/tower_1/CrossEntropyLoss/value/avg/biased does not exist, or was not created with tf.get_variable(). Did you mean to set reuse=None in VarScope?
```
Other Info:
```
python -c ""import tensorflow; print(tensorflow.__version__)""
0.12.1

git rev-parse HEAD
bfa1bb1bf52c4b8eabf7c1766e65dcb04164f778

bazel version
Build label: 0.3.2
Build target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Fri Oct 7 17:25:10 2016 (1475861110)
Build timestamp: 1475861110
Build timestamp as int: 1475861110
```",yogeshg,b'type:bug',2017-01-02T22:36:46Z,2017-03-23T22:50:51Z,,,,,,,
839,im2txt Caption class comparison fails in Python 3.5,"## models/im2txt 

### Caption class comparison fails in Python 3.5 because Python 2's __cmp__ is deprecated in 3+

@cshallue 

I was trying to run #466 on Python 3.5 and I was getting the following error:

> Traceback (most recent call last):
>   File ""test.py"", line 84, in <module>
>     tf.app.run()
>   File ""/data/venvs/tensorflow/lib/python3.5/site-packages/tensorflow/python/platform/app.py"", line 43, in run
>     sys.exit(main(sys.argv[:1] + flags_passthrough))
>   File ""test.py"", line 74, in main
>     captions = generator.beam_search(sess, image)
>   File ""/media/scott/BigHD/Code/tensorflow_ex/im2txt/inference_utils/caption_generator.py"", line 193, in beam_search
>     partial_captions.push(beam)
>   File ""/media/scott/BigHD/Code/tensorflow_ex/im2txt/inference_utils/caption_generator.py"", line 77, in push
>     heapq.heappush(self._data, x)
> TypeError: unorderable types: Caption() < Caption()

The Caption class only implements __cmp__, but needs __lt__ and __eq__ for Python 3. It's a simple addition that would help compatibility between the versions. I'm not sure if you're planning on supporting Python 3, but everything else worked out of the box except this when I ran the run_inference.py file from the repo.

",srome,b'type:bug',2017-01-02T18:46:11Z,2017-01-27T17:52:38Z,,,,,,,
836,tutorials/rnn/translate Matrix multiplication error,"**tensorflow/models/tutorials/rnn/translate/seq2seq_model.py**

Hello everyone, 

When I ran the translate model, I encountered the following issue:

File ""translate.py"", line 294, in main
    train()
  File ""translate.py"", line 153, in train
    model = create_model(sess, False)
  File ""translate.py"", line 132, in create_model
    dtype=dtype)
  File ""/Users/richard_xiong/Documents/DeepLearningMaster/RNN/seq2seq_model.py"", line 181, in __init__
    softmax_loss_function=softmax_loss_function)
  File ""/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/tensorflow/python/ops/seq2seq.py"", line 1130, in model_with_buckets
    softmax_loss_function=softmax_loss_function))
  File ""/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/tensorflow/python/ops/seq2seq.py"", line 1058, in sequence_loss
    softmax_loss_function=softmax_loss_function))
  File ""/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/tensorflow/python/ops/seq2seq.py"", line 1022, in sequence_loss_by_example
    crossent = softmax_loss_function(logit, target)
  File ""/Users/richard_xiong/Documents/DeepLearningMaster/RNN/seq2seq_model.py"", line 117, in sampled_loss
    num_classes=self.target_vocab_size),
  File ""/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/tensorflow/python/ops/nn.py"", line 1412, in sampled_softmax_loss
    name=name)
  File ""/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/tensorflow/python/ops/nn.py"", line 1219, in _compute_sampled_logits
    inputs, sampled_w, transpose_b=True) + sampled_b
  File ""/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/tensorflow/python/ops/math_ops.py"", line 1729, in matmul
    a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)
  File ""/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/tensorflow/python/ops/gen_math_ops.py"", line 1442, in _mat_mul
    transpose_b=transpose_b, name=name)
  File ""/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py"", line 759, in apply_op
    op_def=op_def)
  File ""/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 2242, in create_op
    set_shapes_for_outputs(ret)
  File ""/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 1617, in set_shapes_for_outputs
    shapes = shape_func(op)
  File ""/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 1568, in call_with_requiring
    return call_cpp_shape_fn(op, require_shape_fn=True)
  File ""/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/tensorflow/python/framework/common_shapes.py"", line 610, in call_cpp_shape_fn
    debug_python_shape_fn, require_shape_fn)
  File ""/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/tensorflow/python/framework/common_shapes.py"", line 675, in _call_cpp_shape_fn_impl
    raise ValueError(err.message)
**ValueError**: Shape must be rank 2 but is rank 1 for 'model_with_buckets/sequence_loss/sequence_loss_by_example/sampled_softmax_loss/MatMul_1' (op: 'MatMul') with input shapes: [?], [?,1024].

It seems it's the intrinsic matrix multiplication error in the function 'tf.nn.seq2seq.model_with_buckets()'

Does anyone have any ideas? Thank you!",richardxiong,b'type:bug',2017-01-01T22:33:27Z,2017-03-30T19:25:32Z,,,,,,,
828,Two root nodes for one sentence,"I trying to process next sentence: ""/ / Россия в глобальной политике ."" with model Russian-SynTagRus.

```
echo ""/ / Россия в глобальной политике ."" | syntaxnet/models/parsey_universal/parse.sh /home/tensor/tensorflow/Russian-SynTagRus
```

And I have in result two root nodes (see first and sixth word). I think it is not ok, because it is not tree:

```
1	/	_	PUNCT	/	fPOS=PUNCT++/	0	ROOT	_	_
2	/	_	PUNCT	/	fPOS=PUNCT++/	3	punct	_	_
3	Россия	_	NOUN	_	Animacy=Inan|Case=Nom|Gender=Fem|Number=Sing|fPOS=NOUN++	6	nsubj	_	_
4	в	_	ADP	_	fPOS=ADP++	6	case	_	_
5	глобальной	_	ADJ	_	Case=Loc|Degree=Pos|Gender=Fem|Number=Sing|fPOS=ADJ++	6	amod	_	_
6	политике	_	NOUN	_	Animacy=Inan|Case=Loc|Gender=Fem|Number=Sing|fPOS=NOUN++	0	ROOT	_	_
7	.	_	PUNCT	.	fPOS=PUNCT++.	6	punct	_	_
```",mnvx,b'type:bug',2016-12-29T09:00:31Z,2018-02-22T19:24:15Z,,,,,,,
827,_bytes_feature(encoded_image) will throw an exception,"## Please let us know which model this issue is about (specify the top-level directory)
When I using ptyhon3.5.2 to run script build_mscoco_data,there will throw an exception in line
```

 context = tf.train.Features(feature={
      ""image/image_id"": _int64_feature(image.image_id),
      ""image/data"": _bytes_feature(encoded_image),
  })
```

the debug info before this has no warning,error and exception 

```
Loaded caption metadata for 200 images from /Users/apple1/Desktop/im2txt_new/im2txt/im2txt/data/raw-data/annotations/captions_train2014.json
Proccessing captions.
Finished processing 1000 captions for 200 images in /Users/apple1/Desktop/im2txt_new/im2txt/im2txt/data/raw-data/annotations/captions_train2014.json
Loaded caption metadata for 50 images from /Users/apple1/Desktop/im2txt_new/im2txt/im2txt/data/raw-data/annotations/captions_val2014.json
Proccessing captions.
Finished processing 250 captions for 50 images in /Users/apple1/Desktop/im2txt_new/im2txt/im2txt/data/raw-data/annotations/captions_val2014.json
Creating vocabulary.
Total words: 1601
Words in vocabulary: 463
Wrote vocabulary file: /tmp/word_counts.txt
Launching 8 threads for spacings: [[0, 151], [151, 302], [302, 453], [453, 605], [605, 756], [756, 907], [907, 1058], [1058, 1210]]
```
I only use 200 train images and 50 val images to test, I have processed two json files, captions and images all paired.

when step on 

```
def _bytes_feature(value):
  """"""Wrapper for inserting a bytes Feature into a SequenceExample proto.""""""
  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[str(value)]))
```
there will throw an exception

```
Exception in thread Thread-6:
Traceback (most recent call last):
  File ""/opt/local/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/threading.py"", line 914, in _bootstrap_inner
    self.run()
  File ""/opt/local/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/threading.py"", line 862, in run
    self._target(*self._args, **self._kwargs)
  File ""/Users/apple1/Desktop/im2txt_new/im2txt/im2txt/data/build_mscoco_data.py"", line 278, in _process_image_files
    sequence_example = _to_sequence_example(image, decoder, vocab)
  File ""/Users/apple1/Desktop/im2txt_new/im2txt/im2txt/data/build_mscoco_data.py"", line 224, in _to_sequence_example
    ""image/data"": _bytes_feature(encoded_image),
  File ""/Users/apple1/Desktop/im2txt_new/im2txt/im2txt/data/build_mscoco_data.py"", line 189, in _bytes_feature
    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[str(value)]))
  File ""/opt/local/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/google/protobuf/internal/python_message.py"", line 517, in init
    copy.extend(field_value)
  File ""/opt/local/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/google/protobuf/internal/containers.py"", line 275, in extend
    new_values = [self._type_checker.CheckValue(elem) for elem in elem_seq_iter]
  File ""/opt/local/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/google/protobuf/internal/containers.py"", line 275, in <listcomp>
    new_values = [self._type_checker.CheckValue(elem) for elem in elem_seq_iter]
  File ""/opt/local/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/google/protobuf/internal/type_checkers.py"", line 108, in CheckValue
    raise TypeError(message)
TypeError: 'b\'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x01\\x00d\\x00d\\x00\\x00\\xff\\xe2\\x0cXICC_PROFILE\\x00\\x01\\x01\\x00\\x00\\x0cHLino\\x02\\x10\\x00\\x00mntrRGB XYZ \\x07\\xce\\x00\\x02\\x00\\t\\x00\\x06\\x001\\x00\\x00acspMSFT\\x00\\x00\\x00\\x00IEC sRGB\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\xf6\\xd6\\x00\\x01\\x00\\x00\\x00\\x00\\xd3-HP  \\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x11cprt\\x00\\x00\\x01P\\x00\\x00\\x003desc\\x00\\x00\\x01\\x84\\x00\\x00\\x00lwtpt\\x00\\x00\\x01\\xf0\\x00\\x00\\x00\\x14bkpt\\x00\\x00\\x02\\x04\\x00\\x00\\x00\\x14rXYZ\\x00\\x00\\x02\\x18\\x00\\x00\\x00\\x14gXYZ\\x00\\x00\\x02,\\x00\\x00\\x00\\x14bXYZ\\x00\\x00\\x02@\\x00\\x00\\x00\\x14dmnd\\x00\\x00\\x02T\\x00\\x00\\x00pdmdd\\x00\\x00\\x02\\xc4\\x00\\x00\\x00\\x88vued\\x00\\x00\\x03L\\x00\\x00\\ has type <class 'str'>, but expected one of: ((<class 'bytes'>,),)
```
",PowerAndSpeed,b'stat:awaiting maintainer type:bug',2016-12-29T07:39:24Z,2019-06-10T22:06:11Z,,,,,,,
817,"cifar10_input.py calls tf.strided_slice() with 3 arguments, 4 needed.","## Please let us know which model this issue is about (specify the top-level directory)

models/tutorials/image/cifar10/cifar10_input.py:87

  File ""/mnt/st12tb/models/tutorials/image/cifar10/cifar10_input.py"", line 87, in read_cifar10
    tf.strided_slice(record_bytes, [0], [label_bytes]), tf.int32)

models/tutorials/image/cifar10/cifar10_input.py:93

  File ""/mnt/st12tb/models/tutorials/image/cifar10/cifar10_input.py"", line 93, in read_cifar10
    [label_bytes + image_bytes]),

In both cases, running the script, e.g. with ""python cifar10_train.py"" on TensorFlow v0.12 yields

TypeError: strided_slice() takes at least 4 arguments (3 given)",dweekly,b'type:bug',2016-12-26T23:20:34Z,2017-01-16T02:51:25Z,,,,,,,
815,models.slim.deployment needs to have proper summary operations,"models.slim.deployment, all references to *_summary need to be changed to tf.summary as per latest TF master. 
",aazout,b'type:bug',2016-12-26T05:53:55Z,2017-03-23T22:51:15Z,,,,,,,
796,AttributeError in tutorials/embedding : skipgram_word2vec ,"I am getting the following AttributeError
```
$ python word2vec_optimized.py   --train_data=text8   --eval_data=questions-words.txt   --save_path=/tmp/

Traceback (most recent call last):
  File ""word2vec_optimized.py"", line 439, in <module>
    tf.app.run()
  File ""/Users/cremones/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/platform/app.py"", line 43, in run
    sys.exit(main(sys.argv[:1] + flags_passthrough))
  File ""word2vec_optimized.py"", line 423, in main
    model = Word2Vec(opts, session)
  File ""word2vec_optimized.py"", line 146, in __init__
    self.build_graph()
  File ""word2vec_optimized.py"", line 181, in build_graph
    examples, labels) = word2vec.skipgram_word2vec(filename=opts.train_data,
AttributeError: module 'tensorflow.models.embedding.gen_word2vec' has no attribute 'skipgram_word2vec'
```
using python 3.5.2, tensorflow 0.12.0 and latest master of the models repository ( commit 33bc8b14693d )

Thank you for your help!
",sharkovsky,b'type:bug',2016-12-22T15:57:02Z,2017-11-30T22:24:13Z,,,,,,,
793,installing 'syntaxnet' on Linux,"I am trying to installing ""syntaxnet"" and when I enter:

`bazel test syntaxnet/... util/utf8/...`

in the last step, there is an error occur:

`ERROR:
/home/yixing/.cache/bazel/_bazel_root/b7b504dda51086572cfb8274db950946/external/org_tensorflow/tensorflow/core/debug/BUILD:33:1: null failed: protoc failed: error executing command bazel-out/host/bin/external/protobuf/protoc '--cpp_out=bazel-out/local-opt/genfiles/external/org_tensorflow' '--plugin=protoc-gen-grpc=bazel-out/host/bin/external/grpc/grpc_cpp_plugin' ... (remaining 6 argument(s) skipped): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.`
`bazel-out/local-opt/genfiles/external/protobuf/src: warning: directory does not exist.`
`bazel-out/host/bin/external/grpc/grpc_cpp_plugin: program not found or is not executable`
`--grpc_out: protoc-gen-grpc: Plugin failed with status code 1.`
`INFO: Elapsed time: 1.656s, Critical Path: 0.49s`
`//syntaxnet:arc_standard_transitions_test                             NO STATUS`
`//syntaxnet:beam_reader_ops_test                                      NO STATUS`
`//syntaxnet:binary_segment_state_test                                 NO STATUS`
`//syntaxnet:binary_segment_transitions_test                           NO STATUS`
`//syntaxnet:graph_builder_test                                        NO STATUS`
`//syntaxnet:lexicon_builder_test                                      NO STATUS`
`//syntaxnet:morphology_label_set_test                                 NO STATUS`
`//syntaxnet:parser_features_test                                      NO STATUS`
`//syntaxnet:parser_trainer_test                                       NO STATUS`
`//syntaxnet:reader_ops_test                                           NO STATUS`
`//syntaxnet:segmenter_utils_test                                      NO STATUS`
`//syntaxnet:sentence_features_test                                    NO STATUS`
`//syntaxnet:shared_store_test                                         NO STATUS`
`//syntaxnet:tagger_transitions_test                                   NO STATUS`
`//syntaxnet:text_formats_test                                         NO STATUS`
`//util/utf8:unicodetext_unittest                                      NO STATUS`
`
Executed 0 out of 17 tests: 1 fails to build and 16 were skipped.
`",xiaoshingshing,b'type:build/install',2016-12-22T08:11:23Z,2017-01-15T08:54:53Z,,,,,,,
785,tf.contrib.deprecated elimination bugfix for tf version 12,according to #784  after upgrading tf version to 0.12 tf.contrib.deprecated has been eliminated. This pull request fixes the code to make it work with tf version 0.12.,mrphoenix13,b'cla: yes',2016-12-21T08:05:05Z,2017-01-27T19:28:10Z,,,,,,,
784,tf.contrib.deprecated methods is eliminated in tf version 0.12,"As I mentioned in the title the tf.contrib.deprecated is eliminated in tensorflow version 0.12. So I suggest to edit the code. If it's ok you can make it contribute welcome for me to edit it myself.

## Please let us know which model this issue is about (specify the top-level directory)
image/cifar10
embedding
rnn/ptb",mrphoenix13,b'help wanted type:bug',2016-12-21T07:26:24Z,2018-02-08T00:55:23Z,,,,,,,
782,TF-Slim Walkthrough slim/slim_walkthough.ipynb Doesn't Work With TF 0.12,"The walkthrough has the user use the sum_of_squares() loss function which was removed after TF 0.10 and is no longer present in TF 0.12. Please update the walkthrough to work with TF 0.12.

loss = slim.losses.sum_of_squares(predictions, targets)",dweekly,b'type:bug',2016-12-21T04:44:46Z,2017-03-16T04:39:01Z,,,,,,,
771,Seq-to-Seq tutorial model predicts nothing except _UNK,"Model directory: `tutorials/rnn/translate`

I followed [this tutorial](https://www.tensorflow.org/tutorials/seq2seq/#what-next) with the suggested default parameters and let the network train for 3 days, doing 486800 steps and over 3 epochs. So to train the model, I ran:
```
python translate.py --data_dir /home/user/nn/seq-to-seq/data/en-to-fr --train_dir checkpoints/
```

But when I want to try out the resulting model by running
```
python translate.py --decode --data_dir /home/user/nn/seq-to-seq/data/en-to-fr --train_dir checkpoints/
```
then I get nothing but ""_UNK""s as translations (corresponding to the bucket sizes), e.g.:
```
Reading model parameters from checkpoints/translate.ckpt-486800
> cat
_UNK _UNK
> these are four words
_UNK _UNK _UNK _UNK _UNK _UNK
> There are three cats on the table
_UNK _UNK _UNK _UNK _UNK _UNK _UNK _UNK _UNK _UNK _UNK _UNK
```

I can see nothing wrong with either the data files, vocab files, or anything else created by the script. I made no changes to the code, except for changing the following to lines in `translate.py` and `seq2seq_model.py` so that the script uses the local libs. Without this change, the script [fails while looking for giga-fren.release2.fr.gz](http://lpaste.net/350155), which got renamed to giga-fren.release2.fixed.fr.gz as correctly referenced by the current version of the tutorial.
```
#from tensorflow.models.rnn.translate import data_utils
import data_utils
#from tensorflow.models.rnn.translate import seq2seq_model
import seq2seq_model
```
Can someone confirm the problem? Basically just have TF 0.12 installed, change the imports of data_utils and seq2seq_model to be local and run the commands mentioned higher up to train and try the model. I don't understand what's wrong.

PS: The perplexity during training is suspiciously low, too:
```
global step 400 learning rate 0.5000 step-time 0.51 perplexity 3.12
  eval: bucket 0 perplexity 7.41
  eval: bucket 1 perplexity 2.93
  eval: bucket 2 perplexity 1.63
  eval: bucket 3 perplexity 1.28
global step 600 learning rate 0.5000 step-time 0.45 perplexity 1.25
  eval: bucket 0 perplexity 1.51
  eval: bucket 1 perplexity 1.26
  eval: bucket 2 perplexity 1.19
  eval: bucket 3 perplexity 1.12
global step 800 learning rate 0.5000 step-time 0.48 perplexity 1.18
  eval: bucket 0 perplexity 1.51
  eval: bucket 1 perplexity 1.27
  eval: bucket 2 perplexity 1.19
  eval: bucket 3 perplexity 1.11
global step 1000 learning rate 0.5000 step-time 0.47 perplexity 1.17
  eval: bucket 0 perplexity 1.47
  eval: bucket 1 perplexity 1.28
  eval: bucket 2 perplexity 1.18
  eval: bucket 3 perplexity 1.11
```
...
```
global step 486400 learning rate 0.0011 step-time 0.48 perplexity 1.15
  eval: bucket 0 perplexity 1.47
  eval: bucket 1 perplexity 1.28
  eval: bucket 2 perplexity 1.15
  eval: bucket 3 perplexity 1.10
global step 486600 learning rate 0.0011 step-time 0.48 perplexity 1.15
  eval: bucket 0 perplexity 1.44
  eval: bucket 1 perplexity 1.25
  eval: bucket 2 perplexity 1.16
  eval: bucket 3 perplexity 1.11
```
I don't think it's learning anything.",cshapeshifter,b'stat:awaiting model gardener type:bug',2016-12-19T15:37:10Z,2017-01-09T09:27:23Z,,,,,,,
768,Unable to setup syntaxnet test failed.,"I want to setup syntaxnet and I followed steps given in the description. My OS is ubuntu 16.04, bazel is 0.3.1 and when I ran `bazel test syntaxnet/... util/utf8/...` I get this error

```
ERROR: /root/.cache/bazel/_bazel_root/71c1943a0a3bad4ea0e47880ca4bf10a/external/protobuf/BUILD:113:1: C++ compilation of rule '@protobuf//:protobuf' failed: gcc failed: error executing command /usr/bin/gcc -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -Wall -Wl,-z,-relro,-z,now -B/usr/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 ... (remaining 40 argument(s) skipped): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 4.
gcc: internal compiler error: Killed (program cc1plus)
Please submit a full bug report,
with preprocessed source if appropriate.
See <file:///usr/share/doc/gcc-5/README.Bugs> for instructions.
INFO: Elapsed time: 455.477s, Critical Path: 348.23s
//syntaxnet:arc_standard_transitions_test                             NO STATUS
//syntaxnet:beam_reader_ops_test                                      NO STATUS
//syntaxnet:binary_segment_state_test                                 NO STATUS
//syntaxnet:binary_segment_transitions_test                           NO STATUS
//syntaxnet:char_properties_test                                      NO STATUS
//syntaxnet:graph_builder_test                                        NO STATUS
//syntaxnet:lexicon_builder_test                                      NO STATUS
//syntaxnet:morphology_label_set_test                                 NO STATUS
//syntaxnet:parser_features_test                                      NO STATUS
//syntaxnet:parser_trainer_test                                       NO STATUS
//syntaxnet:reader_ops_test                                           NO STATUS
//syntaxnet:segmenter_utils_test                                      NO STATUS
//syntaxnet:sentence_features_test                                    NO STATUS
//syntaxnet:shared_store_test                                         NO STATUS
//syntaxnet:tagger_transitions_test                                   NO STATUS
//syntaxnet:text_formats_test                                         NO STATUS
//util/utf8:unicodetext_unittest                                      NO STATUS
Executed 0 out of 17 tests: 17 were skipped.
```",Modelizer,b'stat:awaiting response type:build/install',2016-12-18T11:12:48Z,2018-02-08T00:48:45Z,,,,,,,
767,inception model training failing due to a ValueError,"## Please let us know which model this issue is about (specify the top-level directory)
Directory: tensorflow/models/inception

I have been trying to run the inception-net model following the instructions in the README.md.
`$ bazel-bin/inception/imagenet_train --num_gpus=2 --batch_size=128 --train_dir=/data-local/akshayc/imagenet_train --data_dir=""${DATA_DIR}""`
However, I get the following error:
```
Traceback (most recent call last):
  File ""/home/akshayc/tensorflow-source/tensorflow/models/inception/bazel-bin/inception/imagenet_train.runfiles/inception/inception/imagenet_train.py"", line 41, in <module>
    tf.app.run()
  File ""/home/akshayc/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/platform/app.py"", line 43, in run
    sys.exit(main(sys.argv[:1] + flags_passthrough))
  File ""/home/akshayc/tensorflow-source/tensorflow/models/inception/bazel-bin/inception/imagenet_train.runfiles/inception/inception/imagenet_train.py"", line 37, in main
    inception_train.train(dataset)
  File ""/home/akshayc/tensorflow-source/tensorflow/models/inception/bazel-bin/inception/imagenet_train.runfiles/inception/inception/inception_train.py"", line 239, in train
    scope)
  File ""/home/akshayc/tensorflow-source/tensorflow/models/inception/bazel-bin/inception/imagenet_train.runfiles/inception/inception/inception_train.py"", line 124, in _tower_loss
    loss_averages_op = loss_averages.apply(losses + [total_loss])
  File ""/home/akshayc/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/training/moving_averages.py"", line 391, in apply
    self._averages[var], var, decay, zero_debias=zero_debias))
  File ""/home/akshayc/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/training/moving_averages.py"", line 70, in assign_moving_average
    update_delta = _zero_debias(variable, value, decay)
  File ""/home/akshayc/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/training/moving_averages.py"", line 177, in _zero_debias
    trainable=False)
  File ""/home/akshayc/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py"", line 1024, in get_variable
    custom_getter=custom_getter)
  File ""/home/akshayc/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py"", line 850, in get_variable
    custom_getter=custom_getter)
  File ""/home/akshayc/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py"", line 346, in get_variable
    validate_shape=validate_shape)
  File ""/home/akshayc/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py"", line 331, in _true_getter
    caching_device=caching_device, validate_shape=validate_shape)
  File ""/home/akshayc/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py"", line 650, in _get_single_variable
    ""VarScope?"" % name)
ValueError: Variable tower_1/tower_1/CrossEntropyLoss/value/avg/biased does not exist, or was not created with tf.get_variable(). Did you mean to set reuse=None in VarScope?

```

Any idea what is happening here?

Thanks",akshayc11,b'stat:awaiting response type:bug',2016-12-16T23:22:31Z,2017-01-11T19:37:02Z,,,,,,,
766,ERROR: Linking of rule '@highwayhash//:sip_hash' failed,"On Mac OS X 10.11.6, following instructions at https://github.com/tensorflow/models/tree/master/syntaxnet#installation, when I get to the last installation step to run bazel test I receive the following error:

```
ERROR: /private/var/tmp/_bazel_bret/981984f790e2045048b00660e39d3928/external/org_tensorflow/tensorflow/core/debug/BUILD:33:1: null failed: protoc failed: error executing command bazel-out/host/bin/external/protobuf/protoc '--cpp_out=bazel-out/local-opt/genfiles/external/org_tensorflow' '--plugin=protoc-gen-grpc=bazel-out/host/bin/external/grpc/grpc_cpp_plugin' ... (remaining 6 argument(s) skipped): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.
bazel-out/local-opt/genfiles/external/protobuf/src: warning: directory does not exist.
bazel-out/host/bin/external/grpc/grpc_cpp_plugin: program not found or is not executable
--grpc_out: protoc-gen-grpc: Plugin failed with status code 1.
```

```
$ gcc --version
Configured with: --prefix=/Applications/Xcode.app/Contents/Developer/usr --with-gxx-include-dir=/usr/include/c++/4.2.1
Apple LLVM version 8.0.0 (clang-800.0.42.1)
Target: x86_64-apple-darwin15.6.0
Thread model: posix
InstalledDir: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin

$ pip freeze | grep protobuf
protobuf==3.1.0

$ bazel version
Build label: 0.4.2-homebrew
Build target: bazel-out/local-opt/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Thu Dec 8 03:14:36 2016 (1481166876)
Build timestamp: 1481166876
Build timestamp as int: 1481166876
```",bretrouse,b'type:build/install',2016-12-16T23:12:37Z,2018-02-08T00:53:04Z,,,,,,,
764,TypeError: Parameter to MergeFrom() must be instance of same class,"I am trying to run models/resnet but I am getting type error:
TypeError: Parameter to MergeFrom() must be instance of same class: expected Summary got list. for field Event.summar

As I got few warnings about deprecated functions, I had updated them to suggested ones but same type error is still present. I am updated to latest tensorflow and protobuf (previous uninstall).


",frobrd,b'type:bug',2016-12-16T10:55:02Z,2017-01-16T02:42:35Z,,,,,,,
754,fixed bugs/api inconsistencies in resnet,Verified working on tensorflow 0.12rc1,siemanko,b'cla: yes',2016-12-14T07:29:32Z,2017-03-15T01:59:14Z,,,,,,,
728,[DEBUG][PDB] Evaluate a tensor in tf-slim,"FILE: https://github.com/tensorflow/models/blob/master/slim/train_image_classifier.py

In the above python file, when I debug the code using PDB. with the breakpoint  at line 450

```
      images, labels = tf.train.batch(
          [image, label],
          batch_size=FLAGS.batch_size,
          num_threads=FLAGS.num_preprocessing_threads,
          capacity=5 * FLAGS.batch_size)
```

To evaluate the images tensor, if I execute the below code,

(pdb++) sess = tf.Session()
(pdb++) sess.run(images)[0]

It hangs at this point. And outputs nothing ( I need to kill the process)

Can any one point out why this way of debugging does not work in tf-slim ? ",nrupatunga,b'type:support',2016-12-09T09:13:10Z,2018-02-08T00:33:59Z,,,,,,,
719,im2txt train error. (Attempting to use uninitialized value global_step) ,"I am trying to train the im2txt model in README.  Facing this issue:

INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.FailedPreconditionError'>, Attempting to use uninitialized value global_step
         [[Node: _send_global_step_0 = _Send[T=DT_INT32, client_terminated=true, recv_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device_incarnation=6453906879161278131, tensor_name=""global_step:0"", _device=""/job:localhost/replica:0/task:0/cpu:0""](global_step)]]
Traceback (most recent call last):
  File ""/im2txt/bazel-bin/im2txt/train.runfiles/im2txt/im2txt/train.py"", line 115, in <module>
    tf.app.run()
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/platform/app.py"", line 44, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""/im2txt/bazel-bin/im2txt/train.runfiles/im2txt/im2txt/train.py"", line 111, in main
    saver=saver)
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/contrib/slim/python/slim/learning.py"", line 770, in train
    sv.start_standard_services(sess)
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/training/supervisor.py"", line 666, in start_standard_services
    current_step = training_util.global_step(sess, self._global_step)
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/training/training_util.py"", line 54, in global_step
    return int(sess.run(global_step_tensor))
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 767, in run
    run_metadata_ptr)
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 965, in _run
    feed_dict_string, options, run_metadata)
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 1015, in _do_run
    target_list, options, run_metadata)
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 1035, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.FailedPreconditionError: Attempting to use uninitialized value global_step
         [[Node: _send_global_step_0 = _Send[T=DT_INT32, client_terminated=true, recv_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device_incarnation=6453906879161278131, tensor_name=""global_step:0"", _device=""/job:localhost/replica:0/task:0/cpu:0""](global_step)]]

before the error, according to https://github.com/tensorflow/tensorflow/issues/5901, I modified the file and error passed.

thanks
",vangogh0318,b'type:bug',2016-12-07T09:57:15Z,2016-12-08T02:52:31Z,,,,,,,
711,Missing dependency declaration issues when building Syntaxnet: undeclared inclusion(s) in rule '@protobuf//:internal/_api_implementation.so',"#models/syntaxnet

The error msg: 

this rule is missing dependency declarations for the following files included by 'external/protobuf/python/google/protobuf/internal/api_implementation.cc':

his rule is missing dependency declarations for the following files included by 'external/protobuf/python/google/protobuf/internal/api_implementation.cc':
  '/export/apps/python/2.7.11/include/python2.7/Python.h'
  '/export/apps/python/2.7.11/include/python2.7/patchlevel.h'
  '/export/apps/python/2.7.11/include/python2.7/pyconfig.h'
  '/export/apps/python/2.7.11/include/python2.7/pymacconfig.h'
  '/export/apps/python/2.7.11/include/python2.7/pyport.h'
  '/export/apps/python/2.7.11/include/python2.7/pymath.h'
  '/export/apps/python/2.7.11/include/python2.7/pymem.h'
  '/export/apps/python/2.7.11/include/python2.7/object.h'
  '/export/apps/python/2.7.11/include/python2.7/objimpl.h'
  '/export/apps/python/2.7.11/include/python2.7/pydebug.h'
  '/export/apps/python/2.7.11/include/python2.7/unicodeobject.h'
  '/export/apps/python/2.7.11/include/python2.7/intobject.h'
  '/export/apps/python/2.7.11/include/python2.7/boolobject.h'
  '/export/apps/python/2.7.11/include/python2.7/longobject.h'
  '/export/apps/python/2.7.11/include/python2.7/floatobject.h'
  '/export/apps/python/2.7.11/include/python2.7/complexobject.h'
  '/export/apps/python/2.7.11/include/python2.7/rangeobject.h'
  '/export/apps/python/2.7.11/include/python2.7/stringobject.h'
  '/export/apps/python/2.7.11/include/python2.7/memoryobject.h'
  '/export/apps/python/2.7.11/include/python2.7/bufferobject.h'
  '/export/apps/python/2.7.11/include/python2.7/bytesobject.h'
  '/export/apps/python/2.7.11/include/python2.7/bytearrayobject.h'
  '/export/apps/python/2.7.11/include/python2.7/tupleobject.h'
  '/export/apps/python/2.7.11/include/python2.7/listobject.h'
  '/export/apps/python/2.7.11/include/python2.7/dictobject.h'
  '/export/apps/python/2.7.11/include/python2.7/enumobject.h'
  '/export/apps/python/2.7.11/include/python2.7/setobject.h'
  '/export/apps/python/2.7.11/include/python2.7/methodobject.h'
  '/export/apps/python/2.7.11/include/python2.7/moduleobject.h'
  '/export/apps/python/2.7.11/include/python2.7/funcobject.h'
  '/export/apps/python/2.7.11/include/python2.7/classobject.h'

pip list:

asciitree (0.3.3)
enum34 (1.1.6)
funcsigs (1.0.2)
futures (3.0.5)
grpcio (1.0.1)
grpcio-tools (1.0.1)
mock (2.0.0)
nose (1.3.7)
numpy (1.11.2)
pbr (1.10.0)
pip (9.0.1)
protobuf (3.1.0)
setuptools (29.0.1)
six (1.10.0)
tensorflow (0.11.0)
wheel (0.29.0)

bazel version
Build label: 0.4.0-2016-12-02 (@30ae806)
Build target: bazel-out/local-opt/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Fri Dec 2 23:44:21 2016 (1480722261)
Build timestamp: 1480722261
Build timestamp as int: 1480722261

Not sure which dependency or lib is missing?  Any insights?
",thusutoo,b'stat:awaiting response type:build/install',2016-12-03T17:23:29Z,2017-01-16T02:36:42Z,,,,,,,
656,Fix ValueError when processing bbox in XML annotation file,"In some XML annotation files, point values [xmin, ymin, xmax, ymax] relative to bounding box are string type look like a float number. So if want to use int() convert those string to int. The program will raise an ValueError.Such as:
`ValueError: invalid literal for int() with base 10: '64.0994'`

So I fixed this bug by adding an float function before int function.",xionghc,b'cla: yes',2016-11-17T09:03:43Z,2017-03-16T06:08:34Z,,,,,,,
646,Syntaxnet compile error ,"Building syntaxnet according to install instructions.

```
gcc -v
Configured with: --prefix=/Applications/Xcode.app/Contents/Developer/usr --with-gxx-include-dir=/usr/include/c++/4.2.1
Apple LLVM version 6.1.0 (clang-602.0.53) (based on LLVM 3.6.0svn)
Target: x86_64-apple-darwin14.5.0
Thread model: posix
```

```
bazel version
Build label: 0.4.0-homebrew
Build target: bazel-out/local-opt/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Wed Nov 2 19:16:09 2016 (1478114169)
Build timestamp: 1478114169
Build timestamp as int: 1478114169
```

Here is the error message:
```
ERROR: /private/var/tmp/_bazel_altosz/2e0f5f3be228f9872f6c780c6d9ace18/external/org_tensorflow/tensorflow/core/BUILD:311:1: C++ compilation of rule '@org_tensorflow//tensorflow/core:array_ops_op_lib' failed: cc_wrapper.sh failed: error executing command external/local_config_cc/cc_wrapper.sh -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -Wall -Wthread-safety -Wself-assign -fcolor-diagnostics -fno-omit-frame-pointer -g0 -O2 -DNDEBUG ... (remaining 97 argument(s) skipped): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.
external/org_tensorflow/tensorflow/core/ops/array_ops.cc:136:7: error: return type 'const ::tensorflow::Status' must match previous return type '::tensorflow::Status' when lambda expression has unspecified explicit return type
      TF_RETURN_IF_ERROR(GetAxisForPackAndUnpack(c, rank + 1, &axis));
      ^
external/org_tensorflow/tensorflow/core/lib/core/errors.h:43:42: note: expanded from macro 'TF_RETURN_IF_ERROR'
    if (TF_PREDICT_FALSE(!_status.ok())) return _status; \
                                         ^
external/org_tensorflow/tensorflow/core/ops/array_ops.cc:211:7: error: return type 'tensorflow::Status' must match previous return type 'const ::tensorflow::Status' when lambda expression has unspecified explicit return type
      return Status::OK();
      ^
external/org_tensorflow/tensorflow/core/ops/array_ops.cc:185:17: error: no viable conversion from 'tensorflow::(lambda at external/org_tensorflow/tensorflow/core/ops/array_ops.cc:185:17)' to 'tensorflow::Status (*)(shape_inference::InferenceContext *)'
    .SetShapeFn([](InferenceContext* c) {
                ^~~~~~~~~~~~~~~~~~~~~~~~~
external/org_tensorflow/tensorflow/core/ops/array_ops.cc:185:17: note: candidate function
external/org_tensorflow/tensorflow/core/framework/op.h:253:16: note: passing argument to parameter 'fn' here
      Status (*fn)(shape_inference::InferenceContext*)) {
               ^
external/org_tensorflow/tensorflow/core/ops/array_ops.cc:311:9: error: return type '::tensorflow::Status' must match previous return type 'const ::tensorflow::Status' when lambda expression has unspecified explicit return type
        TF_RETURN_WITH_CONTEXT_IF_ERROR(
        ^
external/org_tensorflow/tensorflow/core/lib/core/errors.h:51:7: note: expanded from macro 'TF_RETURN_WITH_CONTEXT_IF_ERROR'
      return _status;                                               \
      ^
external/org_tensorflow/tensorflow/core/ops/array_ops.cc:319:7: error: return type 'tensorflow::Status' must match previous return type 'const ::tensorflow::Status' when lambda expression has unspecified explicit return type
      return Status::OK();
      ^
external/org_tensorflow/tensorflow/core/ops/array_ops.cc:295:17: error: no viable conversion from 'tensorflow::(lambda at external/org_tensorflow/tensorflow/core/ops/array_ops.cc:295:17)' to 'tensorflow::Status (*)(shape_inference::InferenceContext *)'
    .SetShapeFn([](InferenceContext* c) {
                ^~~~~~~~~~~~~~~~~~~~~~~~~
external/org_tensorflow/tensorflow/core/ops/array_ops.cc:295:17: note: candidate function
external/org_tensorflow/tensorflow/core/framework/op.h:253:16: note: passing argument to parameter 'fn' here
      Status (*fn)(shape_inference::InferenceContext*)) {
               ^
external/org_tensorflow/tensorflow/core/ops/array_ops.cc:349:7: error: return type 'tensorflow::Status' must match previous return type 'const ::tensorflow::Status' when lambda expression has unspecified explicit return type
      return Status::OK();
      ^
external/org_tensorflow/tensorflow/core/ops/array_ops.cc:339:17: error: no viable conversion from 'tensorflow::(lambda at external/org_tensorflow/tensorflow/core/ops/array_ops.cc:339:17)' to 'tensorflow::Status (*)(shape_inference::InferenceContext *)'
    .SetShapeFn([](InferenceContext* c) {
                ^~~~~~~~~~~~~~~~~~~~~~~~~
external/org_tensorflow/tensorflow/core/ops/array_ops.cc:339:17: note: candidate function
external/org_tensorflow/tensorflow/core/framework/op.h:253:16: note: passing argument to parameter 'fn' here
      Status (*fn)(shape_inference::InferenceContext*)) {
               ^
external/org_tensorflow/tensorflow/core/ops/array_ops.cc:374:7: error: return type 'tensorflow::Status' must match previous return type 'const ::tensorflow::Status' when lambda expression has unspecified explicit return type
      return Status::OK();
      ^
external/org_tensorflow/tensorflow/core/ops/array_ops.cc:365:17: error: no viable conversion from 'tensorflow::(lambda at external/org_tensorflow/tensorflow/core/ops/array_ops.cc:365:17)' to 'tensorflow::Status (*)(shape_inference::InferenceContext *)'
    .SetShapeFn([](InferenceContext* c) {
                ^~~~~~~~~~~~~~~~~~~~~~~~~
external/org_tensorflow/tensorflow/core/ops/array_ops.cc:365:17: note: candidate function
external/org_tensorflow/tensorflow/core/framework/op.h:253:16: note: passing argument to parameter 'fn' here
      Status (*fn)(shape_inference::InferenceContext*)) {
               ^
external/org_tensorflow/tensorflow/core/ops/array_ops.cc:412:7: error: return type 'tensorflow::Status' must match previous return type 'const ::tensorflow::Status' when lambda expression has unspecified explicit return type
      return Status::OK();
      ^
external/org_tensorflow/tensorflow/core/ops/array_ops.cc:405:17: error: no viable conversion from 'tensorflow::(lambda at external/org_tensorflow/tensorflow/core/ops/array_ops.cc:405:17)' to 'tensorflow::Status (*)(shape_inference::InferenceContext *)'
    .SetShapeFn([](InferenceContext* c) {
                ^~~~~~~~~~~~~~~~~~~~~~~~~
external/org_tensorflow/tensorflow/core/ops/array_ops.cc:405:17: note: candidate function
external/org_tensorflow/tensorflow/core/framework/op.h:253:16: note: passing argument to parameter 'fn' here
      Status (*fn)(shape_inference::InferenceContext*)) {
               ^
external/org_tensorflow/tensorflow/core/ops/array_ops.cc:460:9: error: return type 'const ::tensorflow::Status' must match previous return type 'tensorflow::Status' when lambda expression has unspecified explicit return type
        TF_RETURN_IF_ERROR(
        ^
external/org_tensorflow/tensorflow/core/lib/core/errors.h:43:42: note: expanded from macro 'TF_RETURN_IF_ERROR'
    if (TF_PREDICT_FALSE(!_status.ok())) return _status; \
                                         ^
external/org_tensorflow/tensorflow/core/ops/array_ops.cc:503:9: error: return type 'tensorflow::Status' must match previous return type 'const ::tensorflow::Status' when lambda expression has unspecified explicit return type
        return Status::OK();
        ^
external/org_tensorflow/tensorflow/core/ops/array_ops.cc:510:7: error: return type 'tensorflow::Status' must match previous return type 'const ::tensorflow::Status' when lambda expression has unspecified explicit return type
      return Status::OK();
      ^
external/org_tensorflow/tensorflow/core/ops/array_ops.cc:498:17: error: no viable conversion from 'tensorflow::(lambda at external/org_tensorflow/tensorflow/core/ops/array_ops.cc:498:17)' to 'tensorflow::Status (*)(shape_inference::InferenceContext *)'
    .SetShapeFn([](InferenceContext* c) {
                ^~~~~~~~~~~~~~~~~~~~~~~~~
external/org_tensorflow/tensorflow/core/ops/array_ops.cc:498:17: note: candidate function
external/org_tensorflow/tensorflow/core/framework/op.h:253:16: note: passing argument to parameter 'fn' here
      Status (*fn)(shape_inference::InferenceContext*)) {
               ^
external/org_tensorflow/tensorflow/core/ops/array_ops.cc:568:7: error: return type 'tensorflow::Status' must match previous return type 'const ::tensorflow::Status' when lambda expression has unspecified explicit return type
      return Status::OK();
      ^
external/org_tensorflow/tensorflow/core/ops/array_ops.cc:552:17: error: no viable conversion from 'tensorflow::(lambda at external/org_tensorflow/tensorflow/core/ops/array_ops.cc:552:17)' to 'tensorflow::Status (*)(shape_inference::InferenceContext *)'
    .SetShapeFn([](InferenceContext* c) {
                ^~~~~~~~~~~~~~~~~~~~~~~~~
external/org_tensorflow/tensorflow/core/ops/array_ops.cc:552:17: note: candidate function
external/org_tensorflow/tensorflow/core/framework/op.h:253:16: note: passing argument to parameter 'fn' here
      Status (*fn)(shape_inference::InferenceContext*)) {
               ^
external/org_tensorflow/tensorflow/core/ops/array_ops.cc:602:9: error: return type 'tensorflow::Status' must match previous return type 'const ::tensorflow::Status' when lambda expression has unspecified explicit return type
        return Status::OK();
        ^
```",altosz,b'stat:awaiting response type:build/install',2016-11-15T16:03:10Z,2018-02-22T00:49:30Z,,,,,,,
620,[slim] walkthrough notebook not working,"## Please let us know which model this issue is about (specify the top-level directory)
I was playing with the slim walk through notebook, and working on ""Convolutional neural nets (CNNs)."" section. In the ""Train the model on the Flowers dataset."" subsection, there is code and comment saying `number_of_steps=1, # For speed, we just do 1 epoch`.

- When running the notebook without any changes, the evaluation accuracy is between 0.25 - 0.30.
- When I increase the number of steps to 100 but changes nothing else, and re-run the notebook, I got very similar evaluation accuracy 0.25 - 0.30.

Is this a bug in the notebook? It would also be nice to document in the notebook on approximate expected accuracy when running for X steps.",yxiong,None,2016-11-07T05:31:32Z,2018-02-08T00:17:10Z,,,,,,,
569,SyntaxNet docker image bazel test fails.,"## SyntaxNet docker image bazel test ERROR.

I am trying to build a docker image for SyntaxNet but in the always fails in the bazel test, I try different FROM images: ubuntu:14.04m, java:8 and ubuntu:15.10 but I cant make it work.
Here are the errors:

```
ERROR: /root/.cache/bazel/_bazel_root/7505ae3880f76d218fb2efe040a39a07/external/org_tensorflow/tensorflow/core/BUILD:1280:1: C++ compilation of rule '@org_tensorflow//tensorflow/core:gpu_runtime' failed: gcc failed: error executing command 
  (cd /root/.cache/bazel/_bazel_root/7505ae3880f76d218fb2efe040a39a07/execroot/syntaxnet && \
  exec env - \
    PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/root/bin \
  /usr/bin/gcc -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -Wall -Wl,-z,-relro,-z,now -B/usr/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 -DNDEBUG -ffunction-sections -fdata-sections -funsigned-char '-std=c++0x' -MD -MF bazel-out/local-opt/bin/external/org_tensorflow/tensorflow/core/_objs/gpu_runtime/external/org_tensorflow/tensorflow/core/common_runtime/gpu/gpu_debug_allocator.d '-frandom-seed=bazel-out/local-opt/bin/external/org_tensorflow/tensorflow/core/_objs/gpu_runtime/external/org_tensorflow/tensorflow/core/common_runtime/gpu/gpu_debug_allocator.o' -DEIGEN_MPL2_ONLY -iquote external/org_tensorflow -iquote bazel-out/local-opt/genfiles/external/org_tensorflow -iquote external/protobuf -iquote bazel-out/local-opt/genfiles/external/protobuf -iquote external/bazel_tools -iquote bazel-out/local-opt/genfiles/external/bazel_tools -iquote external/com_googlesource_code_re2 -iquote bazel-out/local-opt/genfiles/external/com_googlesource_code_re2 -iquote external/farmhash_archive -iquote bazel-out/local-opt/genfiles/external/farmhash_archive -iquote external/gif_archive -iquote bazel-out/local-opt/genfiles/external/gif_archive -iquote external/highwayhash -iquote bazel-out/local-opt/genfiles/external/highwayhash -iquote external/jpeg_archive -iquote bazel-out/local-opt/genfiles/external/jpeg_archive -iquote external/png_archive -iquote bazel-out/local-opt/genfiles/external/png_archive -iquote external/zlib_archive -iquote bazel-out/local-opt/genfiles/external/zlib_archive -iquote external/eigen_archive -iquote bazel-out/local-opt/genfiles/external/eigen_archive -iquote external/local_config_cuda -iquote bazel-out/local-opt/genfiles/external/local_config_cuda -isystem external/protobuf/src -isystem bazel-out/local-opt/genfiles/external/protobuf/src -isystem external/bazel_tools/tools/cpp/gcc3 -isystem external/farmhash_archive -isystem bazel-out/local-opt/genfiles/external/farmhash_archive -isystem external/gif_archive -isystem bazel-out/local-opt/genfiles/external/gif_archive -isystem external/highwayhash -isystem bazel-out/local-opt/genfiles/external/highwayhash -isystem external/jpeg_archive -isystem bazel-out/local-opt/genfiles/external/jpeg_archive -isystem external/png_archive -isystem bazel-out/local-opt/genfiles/external/png_archive -isystem external/zlib_archive -isystem bazel-out/local-opt/genfiles/external/zlib_archive -isystem external/eigen_archive -isystem bazel-out/local-opt/genfiles/external/eigen_archive -isystem external/local_config_cuda/cuda -isystem bazel-out/local-opt/genfiles/external/local_config_cuda/cuda -isystem external/local_config_cuda/cuda/include -isystem bazel-out/local-opt/genfiles/external/local_config_cuda/cuda/include -fno-exceptions -DEIGEN_AVOID_STL_ARRAY -pthread -fno-canonical-system-headers -Wno-builtin-macro-redefined '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""' '-D__TIME__=""redacted""' -c external/org_tensorflow/tensorflow/core/common_runtime/gpu/gpu_debug_allocator.cc -o bazel-out/local-opt/bin/external/org_tensorflow/tensorflow/core/_objs/gpu_runtime/external/org_tensorflow/tensorflow/core/common_runtime/gpu/gpu_debug_allocator.o): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.
external/org_tensorflow/tensorflow/core/common_runtime/gpu/gpu_debug_allocator.cc: In member function 'bool tensorflow::GPUDebugAllocator::CheckFooter(void*)':
external/org_tensorflow/tensorflow/core/common_runtime/gpu/gpu_debug_allocator.cc:146:6: internal compiler error: Segmentation fault
 bool GPUDebugAllocator::CheckFooter(void* ptr) {
      ^
Please submit a full bug report,
with preprocessed source if appropriate.
See <file:///usr/share/doc/gcc-4.8/README.Bugs> for instructions.
The bug is not reproducible, so it is likely a hardware or OS problem.
INFO: Elapsed time: 22.815s, Critical Path: 13.23s
//syntaxnet:arc_standard_transitions_test                             NO STATUS
//syntaxnet:beam_reader_ops_test                                      NO STATUS
//syntaxnet:binary_segment_state_test                                 NO STATUS
//syntaxnet:binary_segment_transitions_test                           NO STATUS
//syntaxnet:char_properties_test                                      NO STATUS
//syntaxnet:graph_builder_test                                        NO STATUS
//syntaxnet:lexicon_builder_test                                      NO STATUS
//syntaxnet:morphology_label_set_test                                 NO STATUS
//syntaxnet:parser_features_test                                      NO STATUS
//syntaxnet:parser_trainer_test                                       NO STATUS
//syntaxnet:reader_ops_test                                           NO STATUS
//syntaxnet:segmenter_utils_test                                      NO STATUS
//syntaxnet:sentence_features_test                                    NO STATUS
//syntaxnet:shared_store_test                                         NO STATUS
//syntaxnet:text_formats_test                                         NO STATUS
//util/utf8:unicodetext_unittest                                      NO STATUS

Executed 0 out of 17 tests: 1 fails to build and 16 were skipped.
```

My bazel version is 0.3.1 and ubuntu:14.04.
",TheRealTau,b'stat:awaiting response type:build/install',2016-10-20T21:55:21Z,2016-11-10T18:03:06Z,,,,,,,
560,#Textsum# - Incorrect decode results compared to ref file,"I would first like to know if anyone has successfully been able to run the textsum model recently against their own dataset.  I seem to be hitting wall after wall, and after a week of training I get decode results that don't make sense when comparing the decode and ref files.  I am new to TF and just trying to figure out if the issue is my lack of experience with this, just not enough data or just these strange little bugs I seem to run upon and few others do.

If anyone has been successful and gotten results similar to what is posted, I would love to know what has worked for you...environment, tf build, number of articles.  

I currently have not had luck with 0.11, but have gotten some results with 0.9 however the decode results are similar to those attached below which I have no idea where they are even coming from.  (Results Attached) 

I currently am running Ubuntu 16.04, TF 0.9, CUDA 7.5 and CuDnn 4. I tried TF 0.11 but was dealing with other issues so I went back to 0.9.  It does seem that the decode results are being generated from valid articles, but the reference file and decode file indicies have NO correlation.  

If anyone can provide any help or direction, it would be greatly appreciated.  Otherwise, should I figure anything out, I will post here.

A few final questions.  Regarding the vocab file referenced. Does it at all need to be sorted by word frequency at all?  I never performed anything along these lines when generating it and just wasn't sure if this would throw something off as well.

Finally, I made the assumption in generating the data that the training data articles should be broken down into smaller batches. I separated out the articles into multiple files of 100 articles each. These were then named data-0, data-1, etc.  I assume this was a correct assumption on my part?  I also kept all the vocab in one file which has not seemed to throw any errors. 

Are the above assumptions correct as well? 

Below are the ref and decode results which you can see are quite odd and often seem to have no correlation.

[decode1477264296.txt](https://github.com/tensorflow/models/files/546768/decode1477264296.txt)
[ref1477264296.txt](https://github.com/tensorflow/models/files/546769/ref1477264296.txt)
",xtr33me,None,2016-10-19T00:39:24Z,2016-10-24T20:32:14Z,,,,,,,
541,python classify_image.py not working,"tensorflow/tensorflow/models/image/imagenet/python classify_image.py

I went to the python code bundled along the tensorflow installation on python 3.4, tried runing it the following error messages shown:

[DEBUG ON]

> > > Traceback (most recent call last):
> > >   File ""/usr/local/lib/python3.4/dist-packages/tensorflow/models/image/imagenet/classify_image.py"", line 212, in <module>
> > >     tf.app.run()
> > >   File ""/usr/local/lib/python3.4/dist-packages/tensorflow/python/platform/app.py"", line 30, in run
> > >     sys.exit(main(sys.argv[:1] + flags_passthrough))
> > >   File ""/usr/local/lib/python3.4/dist-packages/tensorflow/models/image/imagenet/classify_image.py"", line 205, in main
> > >     maybe_download_and_extract()
> > >   File ""/usr/local/lib/python3.4/dist-packages/tensorflow/models/image/imagenet/classify_image.py"", line 201, in maybe_download_and_extract
> > >     tarfile.open(filepath, 'r:gz').extractall(dest_directory)
> > >   File ""/usr/lib/python3.4/tarfile.py"", line 1980, in extractall
> > >     self.extract(tarinfo, path, set_attrs=not tarinfo.isdir())
> > >   File ""/usr/lib/python3.4/tarfile.py"", line 2019, in extract
> > >     set_attrs=set_attrs)
> > >   File ""/usr/lib/python3.4/tarfile.py"", line 2088, in _extract_member
> > >     self.makefile(tarinfo, targetpath)
> > >   File ""/usr/lib/python3.4/tarfile.py"", line 2134, in makefile
> > >     copyfileobj(source, target, tarinfo.size)
> > >   File ""/usr/lib/python3.4/tarfile.py"", line 239, in copyfileobj
> > >     buf = src.read(BUFSIZE)
> > >   File ""/usr/lib/python3.4/gzip.py"", line 365, in read
> > >     if not self._read(readsize):
> > >   File ""/usr/lib/python3.4/gzip.py"", line 449, in _read
> > >     self._read_eof()
> > >   File ""/usr/lib/python3.4/gzip.py"", line 482, in _read_eof
> > >     crc32, isize = struct.unpack(""<II"", self._read_exact(8))
> > >   File ""/usr/lib/python3.4/gzip.py"", line 286, in _read_exact
> > >     raise EOFError(""Compressed file ended before the ""
> > > EOFError: Compressed file ended before the end-of-stream marker was reached
",jeffreynghm,b'stat:awaiting response',2016-10-14T08:30:51Z,2019-01-11T13:14:58Z,,,,,,,
506,textsum:: memory bug on multi gpu,"Hi guys,

I tried to play toy example of textsum.
I trained with toy dataset.
When I try to test as following, 
following memory bug was occured.

have any idea?

there was no problem when I tried with other machine (cpu environment)
tensorflow version is 0.9

$bazel-bin/textsum/seq2seq_attention   --mode=decode   --article_key=article   --abstract_key=abstract   --data_path=data/data   --vocab_path=data/vocab   --log_root=textsum/log_root   --decode_dir=textsum/log_root/decode   --beam_size=8

..........

I tensorflow/core/common_runtime/gpu/gpu_device.cc:806] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1080, pci bus id: 0000:02:00.0)
I tensorflow/core/common_runtime/gpu/gpu_device.cc:806] Creating TensorFlow device (/gpu:1) -> (device: 1, name: GeForce GTX 1080, pci bus id: 0000:03:00.0)
I tensorflow/core/common_runtime/gpu/gpu_device.cc:806] Creating TensorFlow device (/gpu:2) -> (device: 2, name: GeForce GTX 1080, pci bus id: 0000:82:00.0)
I tensorflow/core/common_runtime/gpu/gpu_device.cc:806] Creating TensorFlow device (/gpu:3) -> (device: 3, name: GeForce GTX 1080, pci bus id: 0000:83:00.0)

**\* Error in `/usr/bin/python': free(): invalid next size (fast): 0x00007f911c0019b0 ***
",ynchae,b'stat:awaiting response',2016-10-05T07:35:00Z,2016-10-13T05:30:24Z,,,,,,,
490,[slim] performance reduce when train cifarnet with multi-gpu,"I want to train cifarnet on single machine with 4 gpus, but the performance reduces comparing with training with only one gpu.
## [slim] Train cifarnet using the default script slim/scripts/train_cifarnet_on_cifar10.sh

When using the default script the speed is as follow:

```
INFO:tensorflow:global step 13900: loss = 0.7609 (0.06 sec/step)
```
## Modify slim/scripts/train_cifarnet_on_cifar10.sh by set num_clones=4

The speed become slow (I also try change num_preprocessing_threads = 1/2/4/8/16, num_readers=4/8, useless)

```
INFO:tensorflow:global step 14000: loss = 0.7438 (0.26 sec/step)
INFO:tensorflow:global step 14100: loss = 0.6690 (0.26 sec/step)
```
## Hardware

Four Titan X
02:00.0 VGA compatible controller: NVIDIA Corporation Device 17c2 (rev a1)
03:00.0 VGA compatible controller: NVIDIA Corporation Device 17c2 (rev a1)
06:00.0 VGA compatible controller: ASPEED Technology, Inc. ASPEED Graphics Family (rev 30)
82:00.0 VGA compatible controller: NVIDIA Corporation Device 17c2 (rev a1)
83:00.0 VGA compatible controller: NVIDIA Corporation Device 17c2 (rev a1)
+------------------------------------------------------+  
| NVIDIA-SMI 352.30     Driver Version: 352.30         |  
|-----------------------------------+----------------------+------------------------+
| GPU  Name            Persistence-M  | Bus-Id               Disp.A |      Volatile Uncorr. ECC  |
| Fan   Temp    Perf  Pwr:Usage/Cap |            Memory-Usage |   GPU-Util  Compute M. |
|=========================+=================+=================|
|   0     GeForce  GTX TIT...        On   |     0000:02:00.0     Off |                                   N/A |
| 28%   67C         P2      75W / 250W |      228MiB / 12287MiB |                 0%      Default |
+----------------------------------+-----------------------+------------------------+
。。。

32 processor each as follow ：
processor       : 0
vendor_id       : GenuineIntel
cpu family      : 6
model           : 63
model name      : Intel(R) Xeon(R) CPU E5-2630 v3 @ 2.40GHz
## Finally

Could anyone give some advices?
I read some issues about multi-gpu in this rep, but still can't solve this.
I think it caused by IO, because I notice that when train on single gpu the GPU-Util is above 90%( when train with 4 gpus, the GPU-Util is about 20% ).
And I don't think it's due to the hardware performance of my machine.
",D-X-Y,b'stat:awaiting model gardener type:bug',2016-10-02T15:50:56Z,2017-09-25T15:33:03Z,,,,,,,
448,Fix bug caused by signature change of resize_images().,,cshallue,b'cla: yes',2016-09-25T01:13:08Z,2016-09-25T01:49:34Z,,,,,,,
445,Fix a bug in the im2txt code where the Saver is created before the optimizer,,cshallue,b'cla: yes',2016-09-23T20:12:55Z,2016-09-23T20:26:23Z,,,,,,,
441,Add Bazel workspace name to fix bug in relative path of shell scripts.,,cshallue,b'cla: yes',2016-09-22T16:03:05Z,2016-09-22T19:24:36Z,,,,,,,
416,Fix bug in relative path of shell scripts built with bazel.,,cshallue,b'cla: yes',2016-09-14T00:29:50Z,2016-09-22T08:02:13Z,,,,,,,
413,Syntaxnet:C++ compilation of rule '//syntaxnet:term_frequency_map' failed,"Hi,

I'm trying to install Syntaxnet on Mac 10.10.4.

Everything goes right until running `bazel test --linkopt=-headerpad_max_install_names syntaxnet/... util/utf8/...`

`
ERROR: /Users/apple/Downloads/zuotao/syntaxnet/models-master/syntaxnet/syntaxnet/BUILD:269:1: C++ compilation of rule '//syntaxnet:term_frequency_map' failed: osx_cc_wrapper.sh failed: error executing command external/local_config_cc/osx_cc_wrapper.sh -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -Wall -Wthread-safety -Wself-assign -fcolor-diagnostics -fno-omit-frame-pointer -g0 -O2 -DNDEBUG ... (remaining 63 argument(s) skipped): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.

syntaxnet/term_frequency_map.cc:62:73: error: cannot initialize a parameter of type 'tensorflow::RandomAccessFile **' with an rvalue of type 'std::unique_ptrtensorflow::RandomAccessFile *'
  TF_CHECK_OK(tensorflow::Env::Default()->NewRandomAccessFile(filename, &file));
...

syntaxnet/term_frequency_map.cc:123:69: error: cannot initialize a parameter of type 'tensorflow::WritableFile **' with an rvalue of type 'std::unique_ptrtensorflow::WritableFile *'
  TF_CHECK_OK(tensorflow::Env::Default()->NewWritableFile(filename, &file));
...

syntaxnet/term_frequency_map.cc:144:73: error: cannot initialize a parameter of type 'tensorflow::RandomAccessFile **' with an rvalue of type 'std::unique_ptrtensorflow::RandomAccessFile *'
  TF_CHECK_OK(tensorflow::Env::Default()->NewRandomAccessFile(filename, &file));
...

syntaxnet/term_frequency_map.cc:177:69: error: cannot initialize a parameter of type 'tensorflow::WritableFile **' with an rvalue of type 'std::unique_ptrtensorflow::WritableFile *'
  TF_CHECK_OK(tensorflow::Env::Default()->NewWritableFile(filename, &file));
...

4 errors generated.
INFO: Elapsed time: 649.338s, Critical Path: 411.88s
//syntaxnet:arc_standard_transitions_test                             NO STATUS
//syntaxnet:beam_reader_ops_test                                      NO STATUS
//syntaxnet:binary_segment_state_test                                 NO STATUS
//syntaxnet:binary_segment_transitions_test                           NO STATUS
//syntaxnet:char_properties_test                                      NO STATUS
//syntaxnet:graph_builder_test                                        NO STATUS
//syntaxnet:lexicon_builder_test                                      NO STATUS
//syntaxnet:morphology_label_set_test                                 NO STATUS
//syntaxnet:parser_features_test                                      NO STATUS
//syntaxnet:parser_trainer_test                                       NO STATUS
//syntaxnet:reader_ops_test                                           NO STATUS
//syntaxnet:segmenter_utils_test                                      NO STATUS
//syntaxnet:sentence_features_test                                    NO STATUS
//syntaxnet:shared_store_test                                         NO STATUS
//syntaxnet:tagger_transitions_test                                   NO STATUS
//syntaxnet:text_formats_test                                         NO STATUS
//util/utf8:unicodetext_unittest                                      NO STATUS

Executed 0 out of 17 tests: 17 were skipped.
`

Tensorflow r0.9 has already installed on my computer.
The version of Bazel is 0.2.2b.

Does anyone have any ideas for fixing it?
",houned,b'stat:awaiting model gardener',2016-09-13T09:57:34Z,2018-02-07T23:39:50Z,,,,,,,
399,beam search in decode step returns all [UNK],"I am running the decode on a subset of gigaword data. The model was also trained on gigaword data. I checked the original_articles in _Decode() returned by batch_reader.NextBatch(). All looks correct. However the decode outputs are all <UNK>.  I am not sure where to debug such error, so want to check if anyone could provide some insights. 
output=<UNK> <UNK> <UNK> <UNK> <UNK> <UNK>
output=<UNK> <UNK> <UNK> <UNK> <UNK> <UNK>
output=<UNK> <UNK> <UNK> <UNK> <UNK>
output=<UNK> <UNK> <UNK> <UNK> <UNK> <UNK>
output=<UNK> <UNK> <UNK> <UNK> <UNK> <UNK>
output=<UNK> <UNK> <UNK> <UNK> <UNK> <UNK>
output=<UNK> <UNK> <UNK> <UNK> <UNK> <UNK>
output=<UNK> <UNK> <UNK> <UNK> <UNK> <UNK>
output=<UNK> <UNK> <UNK> <UNK> <UNK> <UNK>
",reesemarlin,None,2016-09-09T00:11:47Z,2016-09-09T20:51:18Z,,,,,,,
397,use installled tensorflow,"I can successfully run the file load_parser.py under the dir of  ""models/syntaxnet/bazel-bin/syntaxnet/parser_eval.runfiles/syntaxnet using the tensorflow under the dir of ""models/syntaxnet/bazel-bin/syntaxnet/parser_eval.runfiles/external/org_tensorflow "". But I need to use tensorflow for other purpose. So I pip installed tensorflow. Then the tensorflow is under ""/usr/local/lib/python2.7/.."". Now  I run load_parser.py, it have the error at ""tf.load_op_library(os.path.join(tf.resource_loader.get_data_files_path(),'parser_ops.so'))"", the error is as follows:
tensorflow.framework cannot overwrite a valid watcher with another. 
I debug it , and I find that the error occur at line 302 of pywarp_tensorflow.py. Does it mean the tensorflow under the the dir of ""models/syntaxnet/bazelbin/syntaxnet/parser_eval.runfiles/external/
org_tensorflow "" is different from the one I installed? My tensorflow version is tensorflow-0.8.0. Do you have any idea?@sgn-andot,@calberti 
",qinghua2016,None,2016-09-08T05:30:32Z,2016-09-09T23:23:47Z,,,,,,,
364,Full code refactor and added all networks,"```
• Added slim/nets directory
• Added fine-tuning scripts
• Major overhaul of README.md
• Added slim_walkthrough Jupyter notebook.
• Various file renames
• refactored preprocessing
• Fixed BUILD bug
```
",nathansilberman,b'cla: yes',2016-08-30T04:11:44Z,2016-08-30T04:26:34Z,,,,,,,
351,"Adding cifarnet model, cifarnet preprocessing, logging at INFO level, small bug fixes.","Adding cifarnet model, cifarnet preprocessing, logging at INFO level, various small bug fixes.
",nathansilberman,b'cla: no',2016-08-27T06:18:27Z,2016-08-30T04:03:48Z,,,,,,,
342,[inception] inception_train.py: Multi-GPU Regularization losses bug?,"In the `inception` model,  in `inception_train.py` [line 119](https://github.com/tensorflow/models/blob/master/inception/inception/inception_train.py#L119), regularization losses are being collected without giving the scope. Would this not incorrectly collect losses from _all_ the towers? 
",ankush-me,None,2016-08-25T20:42:31Z,2017-12-11T21:30:53Z,,,,,,,
337,"Syntaxnet: Error running ""bazel test --linkopt=-headerpad_max_install_names syntaxnet/... util/utf8/..."" on Mac OS X 10.11.6","Hi,

I have installed TensorFlow r0.10 version by virtualenv (# Mac OS X, CPU only, Python 2.7: https://www.tensorflow.org/versions/master/get_started/os_setup.html#virtualenv-installation) and no problems in testing the TensorFlow installation (https://www.tensorflow.org/versions/master/get_started/os_setup.html#run-tensorflow-from-the-command-line) and no problems in running a TensorFlow demo model (https://www.tensorflow.org/versions/master/get_started/os_setup.html#run-a-tensorflow-demo-model).

However, when I install and test SyntaxNet (https://github.com/tensorflow/models/tree/master/syntaxnet#installation), I’ve got:
INFO: Found 68 targets and 17 test targets...
ERROR: /private/var/tmp/_bazel_Stephan/eb59...d6/external/protobuf/BUILD:111:1: C++ compilation of rule '@protobuf//:protobuf' failed: osx_cc_wrapper.sh failed: error executing command external/local_config_cc/osx_cc_wrapper.sh -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -Wall -Wthread-safety -Wself-assign -fcolor-diagnostics -fno-omit-frame-pointer -g0 -O2 -DNDEBUG ... (remaining 38 argument(s) skipped): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.
In file included from external/protobuf/src/google/protobuf/descriptor_database.cc:41:
In file included from external/protobuf/src/google/protobuf/stubs/strutil.h:39:
In file included from external/protobuf/src/google/protobuf/stubs/stringpiece.h:152:
external/protobuf/src/google/protobuf/stubs/hash.h:150:11: fatal error: 'tr1/unordered_map' file not found
# include <tr1/unordered_map>

```
      ^
```

1 error generated.
INFO: Elapsed time: 11.005s, Critical Path: 4.63s
//syntaxnet:arc_standard_transitions_test                             NO STATUS
//syntaxnet:beam_reader_ops_test                                      NO STATUS
//syntaxnet:binary_segment_state_test                                 NO STATUS
//syntaxnet:binary_segment_transitions_test                           NO STATUS
//syntaxnet:char_properties_test                                      NO STATUS
//syntaxnet:graph_builder_test                                        NO STATUS
//syntaxnet:lexicon_builder_test                                      NO STATUS
//syntaxnet:morphology_label_set_test                                 NO STATUS
//syntaxnet:parser_features_test                                      NO STATUS
//syntaxnet:parser_trainer_test                                       NO STATUS
//syntaxnet:reader_ops_test                                           NO STATUS
//syntaxnet:segmenter_utils_test                                      NO STATUS
//syntaxnet:sentence_features_test                                    NO STATUS
//syntaxnet:shared_store_test                                         NO STATUS
//syntaxnet:tagger_transitions_test                                   NO STATUS
//syntaxnet:text_formats_test                                         NO STATUS
//util/utf8:unicodetext_unittest                                      NO STATUS

Executed 0 out of 17 tests: 17 were skipped.

My system is:
Mac OS X 10.11.6
Python 2.7.10
bazel release 0.2.2b
Numpy, asciitree, protobuf 3.0.0b2, and swig are all installed.
protobuf==3.0.0b2
numpy-1.11.1-py2.7-macosx-10.11-intel.egg

Can @calberti or @andorardo or anyone help? Thanks.
",stephanobryan,None,2016-08-24T00:31:37Z,2018-07-08T19:35:15Z,,,,,,,
322,Fix bug in inception instructions,"Fixes #59
",aselle,b'cla: yes',2016-08-16T00:35:32Z,2016-08-16T17:59:36Z,,,,,,,
290,Syntaxnet: Couldn't access /usr/bin/java/bin/java,"Here's what I did (on Ubuntu 15.10 64bit vm):
1. (cloned SyntaxNet weeks ago; didn't work then)
2. models> git pull
3. cd syntaxnet/tensorflow/
4. ./configure

>  Please specify the location of python. [Default is /usr/bin/python]: 
>  Do you wish to build TensorFlow with Google Cloud Platform support? [y/N] N
>  No Google Cloud Platform support will be enabled for TensorFlow
>  Do you wish to build TensorFlow with GPU support? [y/N] N
>  No GPU support will be enabled for TensorFlow
>  Configuration finished
1. cd ..
2. bazel test syntaxnet/... util/utf8/...

> Couldn't access /usr/bin/java/bin/java: Not a directory

This appears to be a bug in 'configure' since I don't expect bin/java under java.
",David-dp-,b'stat:community support',2016-07-26T03:56:22Z,2016-10-14T01:28:18Z,,,,,,,
272,fatal error: 'Python.h' file not found,"`
[Praffuls-MacBook-Pro:syntaxnet praffulsahu$ bazel test --linkopt=-headerpad_max_install_names     syntaxnet/... util/utf8/...
WARNING: /private/var/tmp/_bazel_praffulsahu/14ebf9779199393b990056ef72d1139b/external/protobuf/WORKSPACE:1: Workspace name in /private/var/tmp/_bazel_praffulsahu/14ebf9779199393b990056ef72d1139b/external/protobuf/WORKSPACE (@__main__) does not match the name given in the repository's definition (@protobuf); this will cause a build error in future versions.
WARNING: /private/var/tmp/_bazel_praffulsahu/14ebf9779199393b990056ef72d1139b/external/re2/WORKSPACE:1: Workspace name in /private/var/tmp/_bazel_praffulsahu/14ebf9779199393b990056ef72d1139b/external/re2/WORKSPACE (@__main__) does not match the name given in the repository's definition (@re2); this will cause a build error in future versions.
WARNING: /private/var/tmp/_bazel_praffulsahu/14ebf9779199393b990056ef72d1139b/external/highwayhash/WORKSPACE:1: Workspace name in /private/var/tmp/_bazel_praffulsahu/14ebf9779199393b990056ef72d1139b/external/highwayhash/WORKSPACE (@__main__) does not match the name given in the repository's definition (@highwayhash); this will cause a build error in future versions.
INFO: Found 65 targets and 12 test targets...
ERROR: /private/var/tmp/_bazel_praffulsahu/14ebf9779199393b990056ef72d1139b/external/protobuf/BUILD:574:1: C++ compilation of rule '@protobuf//:internal/_api_implementation.so' failed: cc_wrapper.sh failed: error executing command external/local_config_cc/cc_wrapper.sh -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -Wall -Wthread-safety -Wself-assign -fcolor-diagnostics -fno-omit-frame-pointer -g0 -O2 -DNDEBUG ... (remaining 42 argument(s) skipped): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.
external/protobuf/python/google/protobuf/internal/api_implementation.cc:31:10: fatal error: 'Python.h' file not found
# include <Python.h>

```
     ^
```

1 error generated.
INFO: Elapsed time: 8.314s, Critical Path: 6.90s
//syntaxnet:arc_standard_transitions_test                             NO STATUS
//syntaxnet:beam_reader_ops_test                                      NO STATUS
//syntaxnet:graph_builder_test                                        NO STATUS
//syntaxnet:lexicon_builder_test                                      NO STATUS
//syntaxnet:parser_features_test                                      NO STATUS
//syntaxnet:parser_trainer_test                                       NO STATUS
//syntaxnet:reader_ops_test                                           NO STATUS
//syntaxnet:sentence_features_test                                    NO STATUS
//syntaxnet:shared_store_test                                         NO STATUS
//syntaxnet:tagger_transitions_test                                   NO STATUS
//syntaxnet:text_formats_test                                         NO STATUS
//util/utf8:unicodetext_unittest                                      NO STATUS

Executed 0 out of 12 tests: 12 were skipped.
Praffuls-MacBook-Pro:syntaxnet praffulsahu$ '
",prsahu,None,2016-07-16T22:33:18Z,2016-08-26T16:07:07Z,,,,,,,
268,Syntaxnet: Compile error with Docker Script,"## Please let us know which model this issue is about (specify the top-level directory)

I received this error getting latest and attempting to build the docker container. Any advice?

ERROR: /root/.cache/bazel/_bazel_root/5b21cea144c0077ae150bf0330ff61a0/external/org_tensorflow/tensorflow/core/kernels/BUILD:46:1: C++ compilation of rule '@org_tensorflow//tensorflow/core/kernels:strided_slice_op' failed: gcc failed: error executing command /usr/bin/gcc -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -Wall -Wl,-z,-relro,-z,now -B/usr/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 ... (remaining 102 argument(s) skipped): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 4.
gcc: internal compiler error: Killed (program cc1plus)
Please submit a full bug report,
with preprocessed source if appropriate.
See file:///usr/share/doc/gcc-4.9/README.Bugs for instructions.
____Building complete.
____Elapsed time: 1036.365s, Critical Path: 755.27s
//syntaxnet:beam_reader_ops_test                                      NO STATUS
//syntaxnet:graph_builder_test                                        NO STATUS
//syntaxnet:lexicon_builder_test                                      NO STATUS
//syntaxnet:parser_features_test                                      NO STATUS
//syntaxnet:parser_trainer_test                                       NO STATUS
//syntaxnet:reader_ops_test                                           NO STATUS
//syntaxnet:sentence_features_test                                    NO STATUS
//syntaxnet:shared_store_test                                         NO STATUS
//syntaxnet:tagger_transitions_test                                   NO STATUS
//syntaxnet:text_formats_test                                         NO STATUS
//util/utf8:unicodetext_unittest                                      NO STATUS

Executed 0 out of 12 tests: 1 fails to build and 11 were skipped.
The command '/bin/sh -c cd $SYNTAXNETDIR/models/syntaxnet     && bazel test --genrule_strategy=standalone syntaxnet/... util/utf8/...' returned a non-zero code: 1
",peterlamar,b'stat:awaiting response',2016-07-14T05:32:41Z,2017-03-14T15:03:54Z,,,,,,,
265,Changes related to creating .csv file containing bbox information and reading it correctly in build_imagenet_data.py,"Come across bugs in process_bounding_boxes and build_imagenet_data.py.
Changes 
1.process_bounding_boxes
     Creating CSV file and writing bounding box coordinates 
2.build_imagenet_data.py
     Bug fix while parsing file names
",kivijoshi,b'stat:awaiting response',2016-07-10T19:57:18Z,2017-03-16T01:47:40Z,,,,,,,
254,Fixed bug test failed on parser_trainer_test,"Fixed bug file not found ""/syntaxnet/bazel-out/local-opt/bin/syntaxnet/parser_trainer_test.runfiles/syntaxnet/parser_trainer: No such file or directory""
",tinh1115,b'stat:awaiting model gardener',2016-07-03T01:44:29Z,2017-03-16T02:18:05Z,,,,,,,
220,Error compiling Tensorflow,"## ERROR: /home/keyser/.cache/bazel/_bazel_keyser/087b27dd864eba9bace7263243e67e28/external/grpc/BUILD:929:1:

I'm trying to build a pip package by executing
`bazel build -c opt //tensorflow/tools/pip_package:build_pip_package
`
and I get the following error:

```
ERROR: /home/keyser/.cache/bazel/_bazel_keyser/087b27dd864eba9bace7263243e67e28/external/grpc/BUILD:929:1: 
C++ compilation of rule '@grpc//:grpc++_unsecure' failed: gcc failed: error executing command
 /usr/bin/gcc -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -Wall -Wl,-z,-relro,-z,
now -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 -DNDEBUG ... 
(remaining 43 argument(s) skipped): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.
In file included from external/grpc/include/grpc++/impl/call.h:37:0,
                 from external/grpc/include/grpc++/server.h:41,
                 from external/grpc/src/cpp/server/server.cc:34:
external/grpc/include/grpc++/impl/codegen/call.h:287:24: error: expected ';' at end of member declaration
external/grpc/include/grpc++/impl/codegen/call.h:287:26: error: 'override' does not name a type
cc1plus: warning: unrecognized command line option ""-Wno-free-nonheap-object"" [enabled by default]
Target //tensorflow/tools/pip_package:build_pip_package failed to build
```

How to fix this?
",simpsonment,b'stat:awaiting response',2016-06-17T18:05:06Z,2016-07-25T21:56:15Z,,,,,,,
193,Spatial transformer implementation may have a bug somewhere,"So I was trying to plug this ST module into a the write attention part of a DRAW model, and I just couldn't get it to work. After a grueling day of trying every parameter choice, I tried comparing the output of an identity scaling of ST vs scipy interpolation zoom, and that's when I found something interesting.

The code I used is below, adapted from the example.py.

```
from scipy import ndimage
import tensorflow as tf
from spatial_transformer import transformer
import numpy as np
import matplotlib.pyplot as plt

def sigmoid(x):
    return 1.0/(1.0+np.exp(-x))

# %% Create a batch of three images (1600 x 1200)
# %% Image retrieved from:
# %% https://raw.githubusercontent.com/skaae/transformer_network/master/cat.jpg
#im = np.load(""../../datautils/templates/circle/circle.npy"")
#im = im / 255.
im = np.array([-1.2053933, -1.1743802, -0.75044346, -0.74455976, -1.0506268,
 -0.91364104, -0.21054152, 0.1543106, 0.032554384, -0.52717745,
-0.66026419, -0.021319218, -0.060581781, -0.099243492, -0.26127103,
 -0.52252597, 0.1389422, -0.13638327, 0.033274196, -0.20344208,
  -0.53625256, 0.02523746, -0.076311894, 0.10775769, 0.20])
im = im.reshape(1, 5, 5, 1)
im = im.astype('float32')

# %% Let the output size of the transformer be 5 times the image size.
out_size = (30, 30)

# %% Simulate batch
batch = np.append(im, im, axis=0)
batch = np.append(batch, im, axis=0)
num_batch = 3

x = tf.placeholder(tf.float32, [None, 5, 5, 1])
x = tf.cast(batch, 'float32')

# %% Create localisation network and convolutional layer
with tf.variable_scope('spatial_transformer_0'):

    # %% Create a fully-connected layer with 6 output nodes
    n_fc = 6
    W_fc1 = tf.Variable(tf.zeros([5*5*1, n_fc]), name='W_fc1')

    # %% Zoom into the image
    initial = np.array([[1.0, 0, 0.0], [0, 1.0, 0.0]])
    initial = initial.astype('float32')
    initial = initial.flatten()

    b_fc1 = tf.Variable(initial_value=initial, name='b_fc1')
    h_fc1 = tf.matmul(tf.zeros([num_batch, 5*5*1]), W_fc1) + b_fc1
    h_trans = transformer(x, h_fc1, out_size)
    h_trans = tf.sigmoid(h_trans)

# %% Run session
sess = tf.Session()
sess.run(tf.initialize_all_variables())
y = sess.run(h_trans, feed_dict={x: batch})

imgplot = plt.imshow(y[0].reshape(30,30))
imgplot.set_cmap('gray')
plt.savefig(""myfig.png"")

imgplot = plt.imshow(sigmoid(ndimage.interpolation.zoom(im.reshape(5,5),6.0)))
imgplot.set_cmap('gray')
plt.savefig(""myfigorig.png"")
```

The resulting images are the following.

Result of scipy zoom (correct)
![myfigorig](https://cloud.githubusercontent.com/assets/6595222/15995054/f6e1f3a0-310b-11e6-9457-eee4208f90ba.png)

Result of spatial trasnformer
![myfig](https://cloud.githubusercontent.com/assets/6595222/15995058/faf8589e-310b-11e6-99da-8bbf04eecdb4.png)

As you can see the trasnformer output neglects that down and right side, and instead creates a 23x23 (ish) version of the image, when I asked it to create a 30x30 version. This can easily go unnoticed if the background of the image is black itself, which is why it took me so long to notice it.

Let me know what you think,
Miguel
",seuqaj114,b'stat:awaiting model gardener',2016-06-13T01:13:17Z,2018-02-07T23:29:27Z,,,,,,,
192,problem with building syntaxnet (gcc failed: error executing command...),"## Please let us know which model this issue is about (specify the top-level directory)

Hi, we are students of Cognitive Science and would like to use syntaxnet for a project at
university. However, we have some trouble with building syntaxnet.
# setup

We're using:
gcc version 4.9.3 (Ubuntu 4.9.3-8ubuntu2~14.04) bazel-0.2.0-installer-linux-x86_64 (istalled via .sh) python2.7.6 dev SWIG Version 2.0.11 protobuf==3.0.0b2 asciitree numpy

We installed according to https://github.com/tensorflow/models/tree/master/syntaxnet; everything went fine until:
bazel test syntaxnet/... util/utf8/... --jobs 4 (we used jobs 4 because of the suggestion in the following link: bazelbuild/bazel#920)
We get the following error:

ERROR: /home/belinda/.cache/bazel/_bazel_belinda/3fbc93b8c6468b5b4cd80d9bd8565b5a/external/tf/tensorflow/core/kernels/BUILD:934:1: C++ compilation of rule '@tf//tensorflow/core/kernels:cwise_op' failed: gcc failed: error executing command /usr/bin/gcc -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 -DNDEBUG -ffunction-sections ... (remaining 88 argument(s) skipped): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 4. In file included from external/tf/tensorflow/core/kernels/bounds_check.h:22:0, from external/tf/tensorflow/core/kernels/cwise_ops.h:24, from external/tf/tensorflow/core/kernels/cwise_ops_common.h:23, from external/tf/tensorflow/core/kernels/cwise_op_add.cc:16: external/tf/tensorflow/core/platform/default/logging.h: In instantiation of 'std::string\* tensorflow::internal::Check_EQImpl(const T1&, const T2&, const char_) [with T1 = long unsigned int; T2 = int; std::string = std::basic_string<char>]': external/tf/tensorflow/core/util/bcast.h:111:5: required from 'static Eigen::array<long int, NDIMS> tensorflow::BCast::ToIndexArray(const Vec&) [with int NDIMS = 2; tensorflow::BCast::Vec = tensorflow::gtl::InlinedVector<long long int, 4>]' external/tf/tensorflow/core/kernels/cwise_ops_common.h:114:50: required from 'void tensorflow::BinaryOp<Device, Functor>::Compute(tensorflow::OpKernelContext_) [with Device = Eigen::ThreadPoolDevice; Functor = tensorflow::functor::addstd::basic_string<char >]' external/tf/tensorflow/core/kernels/cwise_op_add.cc:37:1: required from here external/tf/tensorflow/core/platform/default/logging.h:194:25: warning: comparison between signed and unsigned integer expressions [-Wsign-compare] == ) // Compilation error with CHECK_EQ(NULL, x)? ^ external/tf/tensorflow/core/platform/macros.h:54:29: note: in definition of macro 'TF_PREDICT_TRUE' #define TF_PREDICT_TRUE(x) (x) ^ external/tf/tensorflow/core/platform/default/logging.h:193:1: note: in expansion of macro 'TF_DEFINE_CHECK_OP_IMPL' TF_DEFINE_CHECK_OP_IMPL(Check_EQ, ^ gcc: internal compiler error: Killed (program cc1plus) Please submit a full bug report, with preprocessed source if appropriate. See file:///usr/share/doc/gcc-4.9/README.Bugs for instructions.
When not using jobs 4 we get the following error message:
ERROR: /home/belinda/.cache/bazel/_bazel_belinda/3fbc93b8c6468b5b4cd80d9bd8565b5a/external/tf/tensorflow/core/kernels/BUILD:934:1: C++ compilation of rule '@tf//tensorflow/core/kernels:cwise_op' failed: gcc failed: error executing command /usr/bin/gcc -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 -DNDEBUG -ffunction-sections ... (remaining 88 argument(s) skipped): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 4. In file included from external/tf/tensorflow/core/kernels/bounds_check.h:22:0, from external/tf/tensorflow/core/kernels/cwise_ops.h:24, from external/tf/tensorflow/core/kernels/cwise_ops_common.h:23, from external/tf/tensorflow/core/kernels/cwise_op_igammas.cc:16: external/tf/tensorflow/core/platform/default/logging.h: In instantiation of 'std::string\* tensorflow::internal::Check_EQImpl(const T1&, const T2&, const char_) [with T1 = long unsigned int; T2 = int; std::string = std::basic_string<char>]': external/tf/tensorflow/core/util/bcast.h:111:5: required from 'static Eigen::array<long int, NDIMS> tensorflow::BCast::ToIndexArray(const Vec&) [with int NDIMS = 2; tensorflow::BCast::Vec = tensorflow::gtl::InlinedVector<long long int, 4>]' external/tf/tensorflow/core/kernels/cwise_ops_common.h:114:50: required from 'void tensorflow::BinaryOp<Device, Functor>::Compute(tensorflow::OpKernelContext_) [with Device = Eigen::ThreadPoolDevice; Functor = tensorflow::functor::igammac<double>]' external/tf/tensorflow/core/kernels/cwise_op_igammas.cc:21:1: required from here external/tf/tensorflow/core/platform/default/logging.h:194:25: warning: comparison between signed and unsigned integer expressions [-Wsign-compare] == ) // Compilation error with CHECK_EQ(NULL, x)? ^ external/tf/tensorflow/core/platform/macros.h:54:29: note: in definition of macro 'TF_PREDICT_TRUE' #define TF_PREDICT_TRUE(x) (x) ^ external/tf/tensorflow/core/platform/default/logging.h:193:1: note: in expansion of macro 'TF_DEFINE_CHECK_OP_IMPL' TF_DEFINE_CHECK_OP_IMPL(Check_EQ, ^ gcc: internal compiler error: Killed (program cc1plus) Please submit a full bug report, with preprocessed source if appropriate. See file:///usr/share/doc/gcc-4.9/README.Bugs for instructions.
Thank you very much for your help
",Chrizzldi,None,2016-06-11T14:13:40Z,2016-07-25T21:29:05Z,,,,,,,
169,training SyntaxNet from parser_trainer_test.sh (ImportError: cannot import name tf_logging),"I am new to python and SyntaxNet and I am trying to train SyntaxNet from [SyntaxNet Tutorial](https://github.com/tensorflow/models/tree/master/syntaxnet). To trained the model I updated [parser_trainer_test.sh](https://github.com/tensorflow/models/blob/master/syntaxnet/syntaxnet/parser_trainer_test.sh) based on The Tutorial. and ran it as follow:

`ubuntu@ubuntu-VirtualBox:~/models/syntaxnet$ syntaxnet/parser_trainer_test.sh`

It gave me this error:

``````
syntaxnet/parser_trainer_test.sh: line 36: /home/ubuntu/models/syntaxnet/syntaxnet/parser_trainer: No such file or directory
Then I updated ""$BINDIR/parser_trainer"" \ in line 35 of parser_trainer_test.sh to ""$BINDIR/parser_trainer.py"" \
``` and ran it again.

And it gave me this error:

``````

File ""/home/ubuntu/models/syntaxnet/syntaxnet/parser_trainer.py"", line 25,in <module>
from tensorflow.python.platform import tf_logging as logging
ImportError: cannot import name tf_logging
I went through tf_logging.py and all other python files in syntaxnet/tensorflow/python/platform
``` I think that's where the error is. But if you want, I can post more.

[parser.trainer.py](https://github.com/tensorflow/models/blob/master/syntaxnet/syntaxnet/parser_trainer.py) :

```
import os
import os.path
import time

import tensorflow as tf
from tensorflow.python.platform import tf_logging as logging # this is where error happens
from tensorflow.python.platform import gfile
```

[tf_logging.py](https://github.com/tensorflow/tensorflow/blob/712e41cf8b316ef2c33c6dd7fd6ade2b4e93ddc0/tensorflow/python/platform/tf_logging.py):

```
import logging
import os
import sys
import time
from logging import DEBUG
from logging import ERROR
from logging import FATAL
from logging import INFO
from logging import WARN
```

There is something that I am suspecious about (I am not perofessional so sorry if it seems silly). I found a file named`logging.h`in path [tensorflow/tensorflow/core/platform](https://github.com/tensorflow/tensorflow/blob/712e41cf8b316ef2c33c6dd7fd6ade2b4e93ddc0/tensorflow/core/platform/logging.h) which defines DEBUG,ERROR,FATAL,.. and I get confused whether the aim of the model is the logging package from python or this logging.h file. If am wrong, which is probable, please help me through this problem.
",Nazanintajik,None,2016-06-01T18:36:52Z,2016-09-06T02:38:54Z,,,,,,,
167,Error in reading full conll line or incorrect sentence batching #Syntaxnet,"I have run a batch of 20000 sentences to the dependency parser. The POS tagger works perfectly fine as expected.
The Parser throws an error in 
<code>
syntaxnet/text_formats.cc:111] Check failed: fields.size() >= 8 (4 vs. 8)Every line has to have at least 8 tab separated fields
</code>

I tried debugging and the input file has required number of tabs but the value passed to the ConvertFromString is incomplete. I didnot try going further however I wonder if the batching handles splitting conll sentences correctly.

Any ideas or notes would help 
",smaransmarty,b'stat:awaiting response',2016-06-01T08:53:02Z,2017-04-23T12:56:43Z,,,,,,,
155,Fix bug in transformer model: Changed the examples to specify the output size,"Although the interface to the transformer was changed in #57, the examples were never updated.

I have made the changes for both the simple example and the cluttered MNIST examples.
",elezar,None,2016-05-26T08:16:42Z,2016-05-31T16:15:20Z,,,,,,,
135,Mac OS-X syntaxnet build error,"I have installed all the dependencies, but I continue to get this error when building:

ERROR: /private/var/tmp/_bazel_root/6555effcb10b293b67ad0bb07fa3a6a3/external/tf/tensorflow/core/kernels/BUILD:159:1: C++ compilation of rule '@tf//tensorflow/core/kernels:queue_base' failed: osx_cc_wrapper.sh failed: error executing command external/local_config_cc/osx_cc_wrapper.sh -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -Wall -Wthread-safety -Wself-assign -fcolor-diagnostics -fno-omit-frame-pointer -g0 -O2 -DNDEBUG ... (remaining 76 argument(s) skipped): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.
In file included from external/tf/tensorflow/core/kernels/queue_base.cc:16:
In file included from external/tf/tensorflow/core/kernels/queue_base.h:22:
In file included from external/tf/tensorflow/core/framework/op_kernel.h:23:
In file included from external/tf/tensorflow/core/framework/cancellation.h:23:
In file included from external/tf/tensorflow/core/lib/core/notification.h:23:
In file included from external/tf/tensorflow/core/platform/mutex.h:31:
external/tf/tensorflow/core/platform/default/mutex.h:39:15: warning: unknown attribute 'acquire_capability' ignored [-Wattributes]
  void lock() ACQUIRE() { std::mutex::lock(); }
              ^
external/tf/tensorflow/core/platform/default/thread_annotations.h:77:33: note: expanded from macro 'ACQUIRE'
  THREAD_ANNOTATION_ATTRIBUTE__(acquire_capability(**VA_ARGS**))
                                ^
external/tf/tensorflow/core/platform/default/thread_annotations.h:42:57: note: expanded from macro 'THREAD_ANNOTATION_ATTRIBUTE__'
# define THREAD_ANNOTATION_ATTRIBUTE__(x) **attribute**((x))
",gpp8p,None,2016-05-20T13:32:05Z,2016-07-25T20:56:44Z,,,,,,,
130,ERROR: C++ compilation of rule '@tf//tensorflow/core/kernels:tensor_array_ops' failed,"I'm trying to get SyntaxNet to run the tests. I run `bazel test --linkopt=-headerpad_max_install_names \
    syntaxnet/... util/utf8/...` But Unfortunately I got the error below, I use mac with python 2.7, bazel 0.2.0, java 1.8.0_91 and clang-602.0.53:

``` ERROR: /private/var/tmp/_bazel_ahmedtouati/973184e4c074c538909febfe48ca7d4e/external/tf/tensorflow/core/kernels/BUILD:596:1: C++ compilation of rule '@tf//tensorflow/core/kernels:tensor_array_ops' failed: cc_wrapper.sh failed: error executing command external/local_config_cc/cc_wrapper.sh -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -Wall -Wthread-safety -Wself-assign -fcolor-diagnostics -fno-omit-frame-pointer -g0 -O2 -DNDEBUG ... (remaining 79 argument(s) skipped): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.
external/tf/tensorflow/core/kernels/tensor_array_ops.cc:244:7: error: return type 'tensorflow::Status' must match previous return type 'const ::tensorflow::Status' when lambda expression has unspecified explicit return type
      return Status::OK();
      ^
In file included from external/tf/tensorflow/core/kernels/tensor_array_ops.cc:23:
In file included from external/tf/third_party/eigen3/unsupported/Eigen/CXX11/Tensor:1:
In file included from external/eigen_archive/eigen-eigen-aaa010b0dd40/unsupported/Eigen/CXX11/Tensor:57:
In file included from external/eigen_archive/eigen-eigen-aaa010b0dd40/unsupported/Eigen/CXX11/ThreadPool:53:
external/eigen_archive/eigen-eigen-aaa010b0dd40/unsupported/Eigen/CXX11/src/ThreadPool/EventCount.h:183:10: warning: private field 'pad_' is not used [-Wunused-private-field]
    char pad_[128];
         ^
1 warning and 1 error generated.
INFO: Elapsed time: 421,789s, Critical Path: 401,75s
//syntaxnet:arc_standard_transitions_test                             NO STATUS
//syntaxnet:beam_reader_ops_test                                      NO STATUS
//syntaxnet:graph_builder_test                                        NO STATUS
//syntaxnet:lexicon_builder_test                                      NO STATUS
//syntaxnet:parser_features_test                                      NO STATUS
//syntaxnet:parser_trainer_test                                       NO STATUS
//syntaxnet:reader_ops_test                                           NO STATUS
//syntaxnet:sentence_features_test                                    NO STATUS
//syntaxnet:shared_store_test                                         NO STATUS
//syntaxnet:tagger_transitions_test                                   NO STATUS
//syntaxnet:text_formats_test                                         NO STATUS
//util/utf8:unicodetext_unittest                                      NO STATUS

Executed 0 out of 12 tests: 12 were skipped. ``` 
",ahmed-touati,b'stat:awaiting response',2016-05-19T18:19:35Z,2016-06-22T18:53:36Z,,,,,,,
129,ERROR: C++ compilation of rule '@grpc//:grpc_unsecure' failed: gcc failed: error executing command,"I'm trying to get SyntaxNet to run the tests and finish them. From models/syntaxnet I run `bazel test syntaxnet/... util/utf8/...`, but every time I get the error below. I have tried using Bazel 0.2.0, 0.2.1, and 0.2.2, but none of them seems to work. I am using Ubuntu 14.04 with the following:

> python 2.7.6
> java 1.8.0_91
> gcc (Ubuntu 4.8.4-2ubuntu1~14.04.3) 4.8.4

At models/syntaxnet/tensorflow/ for the ./configure stage, I selected N to the CPU question and configuration completed successfully. What could be causing this?

`INFO: Found 65 targets and 12 test targets...
ERROR: /home/shane/.cache/bazel/_bazel_shane/2789d2919dff89cbd9f246c4aad3ca85/external/grpc/BUILD:485:1: C++ compilation of rule '@grpc//:grpc_unsecure' failed: gcc failed: error executing command /usr/bin/gcc -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -Wall -Wl,-z,-relro,-z,now -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 -DNDEBUG ... (remaining 37 argument(s) skipped): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.
external/grpc/src/core/compression/message_compress.c:41:18: fatal error: zlib.h: No such file or directory
 #include <zlib.h>
                  ^
compilation terminated.
INFO: Elapsed time: 104.577s, Critical Path: 3.97s
//syntaxnet:arc_standard_transitions_test                             NO STATUS
//syntaxnet:beam_reader_ops_test                                      NO STATUS
//syntaxnet:graph_builder_test                                        NO STATUS
//syntaxnet:lexicon_builder_test                                      NO STATUS
//syntaxnet:parser_features_test                                      NO STATUS
//syntaxnet:parser_trainer_test                                       NO STATUS
//syntaxnet:reader_ops_test                                           NO STATUS
//syntaxnet:sentence_features_test                                    NO STATUS
//syntaxnet:shared_store_test                                         NO STATUS
//syntaxnet:tagger_transitions_test                                   NO STATUS
//syntaxnet:text_formats_test                                         NO STATUS
//util/utf8:unicodetext_unittest                                      NO STATUS

Executed 0 out of 12 tests: 12 were skipped.
`
",shaxtell,None,2016-05-19T15:40:22Z,2016-09-05T15:45:10Z,,,,,,,
127,Trouble building swivel/fastprep.cc on Mac?,"Hey guys, love the Swivel library. That said, prep.py is too slow (on 1B lines of text dataset), so trying to build the fastprep version.

I get stuck on ""rebuild Tensorflow from source"" part. It says to build a pip package, but then I get the error:

bazel-bin/tensorflow/tools/pip_package/build_pip_package  /tmp/tensorflow_pkg
cp: bazel-bin/tensorflow/tools/pip_package/build_pip_package.runfiles/tensorflow: No such file or directory
cp: bazel-bin/tensorflow/tools/pip_package/build_pip_package.runfiles/external: No such file or directory

Indeed, those files do not exist. I could not find this error in the other peoples' bugs. A pointer would be appreciated!

Also... if I have vocab and co-occurrences cached from GloVe, can I skip the prep phase? 

Thanks!
",moscow25,None,2016-05-19T00:11:45Z,2017-02-13T15:47:50Z,,,,,,,
125,error when building syntaxnet dockerfile,"built with `docker build --tag=""syntaxnet-tensorflow"" .` in `syntaxnet/` 
got error (only end of build included)

```
ERROR: /root/.cache/bazel/_bazel_root/5b21cea144c0077ae150bf0330ff61a0/external/tf/tensorflow/core/kernels/BUILD:297:1: C++ compilation of rule '@tf//tensorflow/core/kernels:mirror_pad_op' failed: gcc failed: error executing command /usr/bin/gcc -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -Wall -Wl,-z,-relro,-z,now -B/usr/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 ... (remaining 83 argument(s) skipped): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 4.
gcc: internal compiler error: Killed (program cc1plus)
Please submit a full bug report,
with preprocessed source if appropriate.
See <file:///usr/share/doc/gcc-4.9/README.Bugs> for instructions.
____Building complete.
____Elapsed time: 3957.819s, Critical Path: 3787.39s
//syntaxnet:arc_standard_transitions_test                             NO STATUS
//syntaxnet:beam_reader_ops_test                                      NO STATUS
//syntaxnet:graph_builder_test                                        NO STATUS
//syntaxnet:lexicon_builder_test                                      NO STATUS
//syntaxnet:parser_features_test                                      NO STATUS
//syntaxnet:parser_trainer_test                                       NO STATUS
//syntaxnet:reader_ops_test                                           NO STATUS
//syntaxnet:sentence_features_test                                    NO STATUS
//syntaxnet:shared_store_test                                         NO STATUS
//syntaxnet:tagger_transitions_test                                   NO STATUS
//syntaxnet:text_formats_test                                         NO STATUS
//util/utf8:unicodetext_unittest                                      NO STATUS

Executed 0 out of 12 tests: 12 were skipped.
The command '/bin/sh -c cd $SYNTAXNETDIR/models/syntaxnet     && bazel test --genrule_strategy=standalone syntaxnet/... util/utf8/...     && apt-get autoremove -y     && apt-get clean' returned a non-zero code: 1
```

so it's skipping tests because an error during compilation. is this image working for you at present? Thank you!
",bgrayburn,None,2016-05-18T18:15:54Z,2016-05-18T19:06:31Z,,,,,,,
105,Update Tensorflow Submodule to newest version,"The configure file in the old version of Tensorflow had a bug in the configure file.  The file was looking for the folder ""lib64"" in Cuda directory.  This folder doesn't exist for the OSX version of Cuda library. The newest version of Tesorflow has fixed the bug with the configure file.
",Brok-Bucholtz,None,2016-05-16T22:38:06Z,2016-05-17T20:51:52Z,,,,,,,
80,SyntaxNet and Bazel Tests Error [Linux],"# Description

After installing the correct deps (protobuf, swig, bazel, asciitree), tried running `bazel test syntaxnet/... util/utf8/...`, but after a lote of `notes` and `warnings`, the final output I got this:

``` python-traceback
ERROR: /home/lerax/.cache/bazel/_bazel_lerax/cae2b1799296ff1923cddf0854a31846/external/tf/tensorflow/core/kernels/BUILD:856:1: C++ compilation of rule '@tf//tensorflow/core/kernels:argmax_op' failed: gcc failed: error executing command /usr/bin/gcc -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -Wall -Wl,-z,-relro,-z,now -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 -DNDEBUG ... (remaining 72 argument(s) skipped): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 4.
gcc: internal compiler error: Killed (program cc1plus)
Please submit a full bug report,
with preprocessed source if appropriate.
See <file:///usr/share/doc/gcc-4.8/README.Bugs> for instructions.
INFO: Elapsed time: 552.118s, Critical Path: 428.91s
//syntaxnet:arc_standard_transitions_test                             NO STATUS
//syntaxnet:beam_reader_ops_test                                      NO STATUS
//syntaxnet:graph_builder_test                                        NO STATUS
//syntaxnet:lexicon_builder_test                                      NO STATUS
//syntaxnet:parser_features_test                                      NO STATUS
//syntaxnet:parser_trainer_test                                       NO STATUS
//syntaxnet:reader_ops_test                                           NO STATUS
//syntaxnet:sentence_features_test                                    NO STATUS
//syntaxnet:shared_store_test                                         NO STATUS
//syntaxnet:tagger_transitions_test                                   NO STATUS
//syntaxnet:text_formats_test                                         NO STATUS
//util/utf8:unicodetext_unittest                                      NO STATUS

Executed 0 out of 12 tests: 12 were skipped.
```

Any ideas?
# Environment

| feature | version |
| --- | --- |
| gcc | 4.8.4 |
| python | 3.4.3 |
| bazel | 0.22 |
| swig | 2.0.11 |
| protobuf | 3.0.0b2 |
| asciitree | 0.3.1 |
| OS | GNU/Linux, Distro Ubuntu 14.0 |
",ryukinix,None,2016-05-13T20:45:15Z,2016-06-22T15:08:17Z,,,,,,,
78,Bazel error:  bazel test syntaxnet/... util/utf8/...,"Upon running the command:  bazel test syntaxnet/... util/utf8/...

Any Ideas?  Here is my output

```
bazel test syntaxnet/... util/utf8/...
/home/vertical-3/.cache/bazel/_bazel_vertical-3/0e0937a190400fc5db42694f75128f7d/external/tf/google/protobuf/BUILD:534:1: C++ compilation of rule '@tf//google/protobuf:pyext/_message.so' failed: gcc failed: error executing command /usr/bin/gcc -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -Wall -Wl,-z,-relro,-z,now -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 -DNDEBUG ... (remaining 49 argument(s) skipped): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.
In file included from external/tf/google/protobuf/python/google/protobuf/pyext/repeated_composite_container.cc:34:0:
external/tf/google/protobuf/python/google/protobuf/pyext/repeated_composite_container.h:37:20: fatal error: Python.h: No such file or directory
 #include <Python.h>
                    ^
compilation terminated.
INFO: Elapsed time: 14.267s, Critical Path: 14.07s
```
",chrisplusplus,None,2016-05-13T19:49:31Z,2016-05-13T22:24:10Z,,,,,,,
54,[ distribution ] How to use multiple GPU on each replica ?,"The [Code Here](https://github.com/tensorflow/models/blob/master/inception/inception/imagenet_distributed_train.py) shows how to set each replica which has a single tower that uses one GPU. I'm wondering if there is a way changing this code a little bit to make use of multiple GPU on one machine like [that example](https://github.com/tensorflow/models/blob/master/inception/inception/inception_train.py). 

The way I currently used for using all GPU on a worker machine is starting the number of workers that equal to the number of GPUs. then the workers can communicate to each other as if they are not on one machine. That is slower than if I can start a woker that control more than one GPU. 
",ZhuFengdaaa,b'type:bug',2016-04-26T09:49:21Z,2018-08-28T09:46:01Z,,,,,,,
